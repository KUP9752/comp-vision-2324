{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "# Coursework 2: Image segmentation\n",
    "\n",
    "In this coursework you will develop and train a convolutional neural network for brain tumour image segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
    "\n",
    "```\n",
    "### Insert your code ###\n",
    "...\n",
    "### End of your code ###\n",
    "```\n",
    "\n",
    "## What to do?\n",
    "\n",
    "* Complete and run the code using `jupyter-lab` or `jupyter-notebook` to get the results.\n",
    "\n",
    "* Export (File | S'ave and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
    "\n",
    "* Instead of clicking the Export button, you can also run the following command instead: `jupyter nbconvert coursework.ipynb --to pdf`\n",
    "\n",
    "* If Jupyter complains about some problems in exporting, it is likely that pandoc (https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry.\n",
    "\n",
    "* If Jupyter-lab does not work for you at the end, you can use Google Colab to write the code and export the PDF file.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
    "`pip3 install [package_name]`\n",
    "\n",
    "## GPU resource\n",
    "\n",
    "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
    "\n",
    "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this tutorial.\n",
    "# However, if any other library is needed, please install by yourself.\n",
    "import tarfile\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## 1. Download and visualise the imaging dataset.\n",
    "\n",
    "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
    "\n",
    "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
    "\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mt93oQ8xZkE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-24 12:14:56--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6020:18::a27d:4012\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz [following]\n",
      "--2024-02-24 12:14:57--  https://www.dropbox.com/s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc437731f0a84963946476f86635.dl.dropboxusercontent.com/cd/0/inline/CN6dJr3GtA2b0aK8ikgTth1Sv9yZ0NgdyuQ1_RcHoQ052kPxQpn1OqwL0hmygOrWxxt8yyaW6CPXR7PdYhgwqQ-DIB0Sdanf8pLVfTsIgAhDQF_B7oZa4mtZiZqItnAEnQQ/file# [following]\n",
      "--2024-02-24 12:14:57--  https://uc437731f0a84963946476f86635.dl.dropboxusercontent.com/cd/0/inline/CN6dJr3GtA2b0aK8ikgTth1Sv9yZ0NgdyuQ1_RcHoQ052kPxQpn1OqwL0hmygOrWxxt8yyaW6CPXR7PdYhgwqQ-DIB0Sdanf8pLVfTsIgAhDQF_B7oZa4mtZiZqItnAEnQQ/file\n",
      "Resolving uc437731f0a84963946476f86635.dl.dropboxusercontent.com (uc437731f0a84963946476f86635.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n",
      "Connecting to uc437731f0a84963946476f86635.dl.dropboxusercontent.com (uc437731f0a84963946476f86635.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CN51QMgjQ1lNwPUIaIF9c0alu6GKrm5r_HemBuE8j7VW2oflFV8Vf1Go-vIR2IttFAdMad2spzthow5SSDPrSC8EVbgMS66rYI-2UJIMpKh7i5j92qTc_3DISpAFyO0pNZT4UFcPqmn8LEwmqyO9adx-jruOKB4H1owc9-BahhHjM6D8xDDXmJMA3euqcQwY8vXyZLYrl1SgOPb5_kOHi0NTTc81TF8Hsm4NESYcXZfy95m_sXvVAuDoGUzXeIY0g1A1vZ5C4k5GJP3LtY9y4_znApFA51BLPugTimIQQoAG2g5zNxFtJd4woRVOe7CY4DExRfZuH3oOQdwTEyaujyg5c45KWCCAf1QfJZzef1tS2w/file [following]\n",
      "--2024-02-24 12:14:57--  https://uc437731f0a84963946476f86635.dl.dropboxusercontent.com/cd/0/inline2/CN51QMgjQ1lNwPUIaIF9c0alu6GKrm5r_HemBuE8j7VW2oflFV8Vf1Go-vIR2IttFAdMad2spzthow5SSDPrSC8EVbgMS66rYI-2UJIMpKh7i5j92qTc_3DISpAFyO0pNZT4UFcPqmn8LEwmqyO9adx-jruOKB4H1owc9-BahhHjM6D8xDDXmJMA3euqcQwY8vXyZLYrl1SgOPb5_kOHi0NTTc81TF8Hsm4NESYcXZfy95m_sXvVAuDoGUzXeIY0g1A1vZ5C4k5GJP3LtY9y4_znApFA51BLPugTimIQQoAG2g5zNxFtJd4woRVOe7CY4DExRfZuH3oOQdwTEyaujyg5c45KWCCAf1QfJZzef1tS2w/file\n",
      "Reusing existing connection to uc437731f0a84963946476f86635.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9251149 (8.8M) [application/octet-stream]\n",
      "Saving to: ‘Task01_BrainTumour_2D.tar.gz’\n",
      "\n",
      "Task01_BrainTumour_ 100%[===================>]   8.82M  28.7MB/s    in 0.3s    \n",
      "\n",
      "2024-02-24 12:14:58 (28.7 MB/s) - ‘Task01_BrainTumour_2D.tar.gz’ saved [9251149/9251149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
    "\n",
    "# Unzip the '.tar.gz' file to the current directory\n",
    "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
    "datafile.extractall()\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu_BTL0x6o5a"
   },
   "source": [
    "## Visualise a random set of 4 training images along with their label maps.\n",
    "\n",
    "Suggested colour map for brain MR image:\n",
    "```\n",
    "cmap = 'gray'\n",
    "```\n",
    "\n",
    "Suggested colour map for segmentation map:\n",
    "```\n",
    "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3fgubCRC6m4k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1256/276553290.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(training_img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "cmap_image = \"gray\"\n",
    "cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "\n",
    "zs = [46, 62, 77, 93, 108, 124]\n",
    "IMAGES_FROM = 1\n",
    "IMAGES_TO = 483\n",
    "from random import randint\n",
    "from random import choice\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "\n",
    "# figure = plt.figure(figsize = (4, 2))\n",
    "# img_grid = ImageGrid(figure, 111, nrows_ncols = (4, 2), axes_pad =3)\n",
    "figure, img_grid = plt.subplots(nrows=4, ncols=2, figsize = (5, 10))\n",
    "\n",
    "titles = [\"Training Image\", \"Label\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(img_grid[0], titles)]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"./Task01_BrainTumour_2D/training_images/\", topdown = False):\n",
    "  chosen = []\n",
    "  for _ in range(4):\n",
    "    chosen.append(choice(files))\n",
    "\n",
    "path = \"Task01_BrainTumour_2D\"\n",
    "training_path = \"training_images\"\n",
    "label_path = \"training_labels\"\n",
    "\n",
    "for i, img_path in enumerate(chosen):\n",
    "  training_img_path = f\"{path}/{training_path}/{img_path}\"\n",
    "  label_img_path = f\"{path}/{label_path}/{img_path}\"\n",
    "  \n",
    "  ## Training Image\n",
    "  img = imageio.imread(training_img_path)\n",
    "  img_grid[i, 0].imshow(img, cmap = cmap_image)\n",
    "  img_grid[i, 0].axis(\"off\")\n",
    "  \n",
    "  ## Label Map\n",
    "  label_img= imageio.v3.imread(label_img_path)\n",
    "  \n",
    "  img_grid[i, 1].imshow(label_img, cmap = cmap_segmentation)\n",
    "  img_grid[i, 1].axis(\"off\")\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xWGT3KaML-D"
   },
   "source": [
    "## 2. Implement a dataset class.\n",
    "\n",
    "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6p6wFZ3na5z9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalise_intensity(image, thres_roi=1.0):\n",
    "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
    "    # ROI defines the image foreground\n",
    "    val_l = np.percentile(image, thres_roi)\n",
    "    roi = (image >= val_l)\n",
    "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
    "    eps = 1e-6\n",
    "    image2 = (image - mu) / (sigma + eps)\n",
    "    return image2\n",
    "\n",
    "\n",
    "class BrainImageSet(Dataset):\n",
    "    \"\"\" Brain image set \"\"\"\n",
    "    def __init__(self, image_path, label_path='', deploy=False):\n",
    "        self.image_path = image_path\n",
    "        self.deploy = deploy\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        image_names = sorted(os.listdir(image_path))\n",
    "        for image_name in image_names:\n",
    "            # Read the image\n",
    "            image = imageio.v3.imread(os.path.join(image_path, image_name))\n",
    "            self.images += [image]\n",
    "\n",
    "            # Read the label map\n",
    "            if not self.deploy:\n",
    "                label_name = os.path.join(label_path, image_name)\n",
    "                label = imageio.v3.imread(label_name)\n",
    "                self.labels += [label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get an image and perform intensity normalisation\n",
    "        # Dimension: XY\n",
    "        image = normalise_intensity(self.images[idx])\n",
    "\n",
    "        # Get its label map\n",
    "        # Dimension: XY\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_random_batch(self, batch_size):\n",
    "        # Get a batch of paired images and label maps\n",
    "        # Dimension of images: NCXY\n",
    "        # Dimension of labels: NXY\n",
    "        # images, labels = [], []\n",
    "        \n",
    "        ### Insert your code ###\n",
    "        images = np.array(self.images)\n",
    "        labels = np.array(self.labels)\n",
    "        \n",
    "        seed = np.random.default_rng().integers(low=0, high=2048) # arbitratry range can be changed\n",
    "        \n",
    "        ## shuffle the same way\n",
    "        rg = np.random.default_rng(seed)\n",
    "        rg.shuffle(images)\n",
    "        rg = np.random.default_rng(seed)\n",
    "        rg.shuffle(labels)\n",
    "        \n",
    "        ## Select batch_size many\n",
    "        images, labels = images[:batch_size], labels[:batch_size]\n",
    "        \n",
    "        ## add the greyscale colour channel so conv2d works correctly\n",
    "        images = np.reshape(images, (batch_size, 1, images.shape[1], images.shape[2])) \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "        ### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4ZpawDNmwu"
   },
   "source": [
    "## 3. Build a U-net architecture.\n",
    "\n",
    "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
    "\n",
    "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
    "\n",
    "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IMPmBZVGb1aI"
   },
   "outputs": [],
   "source": [
    "\"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        ### Insert your code ###\n",
    "        n //= 2 # 64\n",
    "        self.upconv5 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 128 -> 64 ch (x2 dims)\n",
    "        self.conv5 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        n //= 2 # 32\n",
    "        self.upconv6 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2 ) # 64 -> 32 ch (x2 dims)\n",
    "        self.conv6 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        n //= 2 # 16\n",
    "        self.upconv7 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 32 -> 16 ch (x2 dims)\n",
    "        self.conv7 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2 , n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, output_channel, kernel_size=1) ## final 1x1 conv\n",
    "        )\n",
    "        ### End of your code ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the convolutional operators defined above to build the U-net\n",
    "        # The encoder part is already done for you.\n",
    "        # You need to complete the decoder part.\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        conv1_skip = x\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        conv2_skip = x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        conv3_skip = x\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Decoder\n",
    "        ### Insert your code ###\n",
    "        x = self.conv5(torch.cat([self.upconv5(x), conv3_skip], dim=1))\n",
    "        \n",
    "        x = self.conv6(torch.cat([self.upconv6(x), conv2_skip], dim=1))\n",
    "        \n",
    "        x = self.conv7(torch.cat([self.upconv7(x), conv1_skip], dim=1))\n",
    "        \n",
    "        ### End of your code ###\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcNWZS08d47P"
   },
   "source": [
    "## 4. Train the segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xaGGkKQndIaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Iteration: 1/10000, Loss: 1.574885606765747\n",
      "Iteration: 2/10000, Loss: 1.5151889324188232\n",
      "Iteration: 3/10000, Loss: 1.4711885452270508\n",
      "Iteration: 4/10000, Loss: 1.4330081939697266\n",
      "Iteration: 5/10000, Loss: 1.4075701236724854\n",
      "Iteration: 6/10000, Loss: 1.3845548629760742\n",
      "Iteration: 7/10000, Loss: 1.3674659729003906\n",
      "Iteration: 8/10000, Loss: 1.3464853763580322\n",
      "Iteration: 9/10000, Loss: 1.335634708404541\n",
      "Iteration: 10/10000, Loss: 1.3277684450149536\n",
      "Iteration: 11/10000, Loss: 1.310430884361267\n",
      "Iteration: 12/10000, Loss: 1.2959926128387451\n",
      "Iteration: 13/10000, Loss: 1.2803008556365967\n",
      "Iteration: 14/10000, Loss: 1.2782859802246094\n",
      "Iteration: 15/10000, Loss: 1.2667704820632935\n",
      "Iteration: 16/10000, Loss: 1.2490646839141846\n",
      "Iteration: 17/10000, Loss: 1.2362267971038818\n",
      "Iteration: 18/10000, Loss: 1.2217903137207031\n",
      "Iteration: 19/10000, Loss: 1.2103559970855713\n",
      "Iteration: 20/10000, Loss: 1.1986569166183472\n",
      "Iteration: 21/10000, Loss: 1.1928025484085083\n",
      "Iteration: 22/10000, Loss: 1.1749305725097656\n",
      "Iteration: 23/10000, Loss: 1.1525028944015503\n",
      "Iteration: 24/10000, Loss: 1.1529977321624756\n",
      "Iteration: 25/10000, Loss: 1.1397125720977783\n",
      "Iteration: 26/10000, Loss: 1.137376070022583\n",
      "Iteration: 27/10000, Loss: 1.1240849494934082\n",
      "Iteration: 28/10000, Loss: 1.1075748205184937\n",
      "Iteration: 29/10000, Loss: 1.1024020910263062\n",
      "Iteration: 30/10000, Loss: 1.092866063117981\n",
      "Iteration: 31/10000, Loss: 1.0820692777633667\n",
      "Iteration: 32/10000, Loss: 1.0788640975952148\n",
      "Iteration: 33/10000, Loss: 1.0619646310806274\n",
      "Iteration: 34/10000, Loss: 1.0586280822753906\n",
      "Iteration: 35/10000, Loss: 1.0683153867721558\n",
      "Iteration: 36/10000, Loss: 1.0467089414596558\n",
      "Iteration: 37/10000, Loss: 1.0310418605804443\n",
      "Iteration: 38/10000, Loss: 1.0153348445892334\n",
      "Iteration: 39/10000, Loss: 1.0123368501663208\n",
      "Iteration: 40/10000, Loss: 0.9965605735778809\n",
      "Iteration: 41/10000, Loss: 1.0052567720413208\n",
      "Iteration: 42/10000, Loss: 0.9831647276878357\n",
      "Iteration: 43/10000, Loss: 0.9733107686042786\n",
      "Iteration: 44/10000, Loss: 0.9664407968521118\n",
      "Iteration: 45/10000, Loss: 0.955096423625946\n",
      "Iteration: 46/10000, Loss: 0.938685953617096\n",
      "Iteration: 47/10000, Loss: 0.9209973812103271\n",
      "Iteration: 48/10000, Loss: 0.9082555770874023\n",
      "Iteration: 49/10000, Loss: 0.898019015789032\n",
      "Iteration: 50/10000, Loss: 0.8917196989059448\n",
      "Iteration: 51/10000, Loss: 0.8756298422813416\n",
      "Iteration: 52/10000, Loss: 0.8699578642845154\n",
      "Iteration: 53/10000, Loss: 0.8667958974838257\n",
      "Iteration: 54/10000, Loss: 0.8608896732330322\n",
      "Iteration: 55/10000, Loss: 0.8450061678886414\n",
      "Iteration: 56/10000, Loss: 0.8283053040504456\n",
      "Iteration: 57/10000, Loss: 0.8268536329269409\n",
      "Iteration: 58/10000, Loss: 0.8126842379570007\n",
      "Iteration: 59/10000, Loss: 0.8068057298660278\n",
      "Iteration: 60/10000, Loss: 0.8028234839439392\n",
      "Iteration: 61/10000, Loss: 0.7830398082733154\n",
      "Iteration: 62/10000, Loss: 0.7810080051422119\n",
      "Iteration: 63/10000, Loss: 0.7807839512825012\n",
      "Iteration: 64/10000, Loss: 0.7760772705078125\n",
      "Iteration: 65/10000, Loss: 0.7623838782310486\n",
      "Iteration: 66/10000, Loss: 0.7507874965667725\n",
      "Iteration: 67/10000, Loss: 0.7444267868995667\n",
      "Iteration: 68/10000, Loss: 0.7483786344528198\n",
      "Iteration: 69/10000, Loss: 0.7341469526290894\n",
      "Iteration: 70/10000, Loss: 0.7296394109725952\n",
      "Iteration: 71/10000, Loss: 0.7157688140869141\n",
      "Iteration: 72/10000, Loss: 0.7006171345710754\n",
      "Iteration: 73/10000, Loss: 0.702750027179718\n",
      "Iteration: 74/10000, Loss: 0.6957595944404602\n",
      "Iteration: 75/10000, Loss: 0.6869015693664551\n",
      "Iteration: 76/10000, Loss: 0.6830728054046631\n",
      "Iteration: 77/10000, Loss: 0.6792393922805786\n",
      "Iteration: 78/10000, Loss: 0.6649217009544373\n",
      "Iteration: 79/10000, Loss: 0.6525141000747681\n",
      "Iteration: 80/10000, Loss: 0.6716864705085754\n",
      "Iteration: 81/10000, Loss: 0.657800555229187\n",
      "Iteration: 82/10000, Loss: 0.65412837266922\n",
      "Iteration: 83/10000, Loss: 0.6462649703025818\n",
      "Iteration: 84/10000, Loss: 0.6306574940681458\n",
      "Iteration: 85/10000, Loss: 0.6231109499931335\n",
      "Iteration: 86/10000, Loss: 0.6267848014831543\n",
      "Iteration: 87/10000, Loss: 0.6112768054008484\n",
      "Iteration: 88/10000, Loss: 0.6229768395423889\n",
      "Iteration: 89/10000, Loss: 0.596983790397644\n",
      "Iteration: 90/10000, Loss: 0.6003542542457581\n",
      "Iteration: 91/10000, Loss: 0.5801731944084167\n",
      "Iteration: 92/10000, Loss: 0.5859127044677734\n",
      "Iteration: 93/10000, Loss: 0.578487753868103\n",
      "Iteration: 94/10000, Loss: 0.5790257453918457\n",
      "Iteration: 95/10000, Loss: 0.5899353623390198\n",
      "Iteration: 96/10000, Loss: 0.5734778046607971\n",
      "Iteration: 97/10000, Loss: 0.5584584474563599\n",
      "Iteration: 98/10000, Loss: 0.5577499866485596\n",
      "Iteration: 99/10000, Loss: 0.5568686127662659\n",
      "Iteration: 100/10000, Loss: 0.5546437501907349\n",
      "Average test loss:  0.0356\n",
      "Iteration: 101/10000, Loss: 0.534012496471405\n",
      "Iteration: 102/10000, Loss: 0.5171025991439819\n",
      "Iteration: 103/10000, Loss: 0.5267073512077332\n",
      "Iteration: 104/10000, Loss: 0.517183780670166\n",
      "Iteration: 105/10000, Loss: 0.5180425047874451\n",
      "Iteration: 106/10000, Loss: 0.5359907150268555\n",
      "Iteration: 107/10000, Loss: 0.5012241005897522\n",
      "Iteration: 108/10000, Loss: 0.5062033534049988\n",
      "Iteration: 109/10000, Loss: 0.4914560317993164\n",
      "Iteration: 110/10000, Loss: 0.5076066255569458\n",
      "Iteration: 111/10000, Loss: 0.49138522148132324\n",
      "Iteration: 112/10000, Loss: 0.4875253736972809\n",
      "Iteration: 113/10000, Loss: 0.47789379954338074\n",
      "Iteration: 114/10000, Loss: 0.48183301091194153\n",
      "Iteration: 115/10000, Loss: 0.47928306460380554\n",
      "Iteration: 116/10000, Loss: 0.45383647084236145\n",
      "Iteration: 117/10000, Loss: 0.4715312421321869\n",
      "Iteration: 118/10000, Loss: 0.4721185266971588\n",
      "Iteration: 119/10000, Loss: 0.4550308585166931\n",
      "Iteration: 120/10000, Loss: 0.4577801823616028\n",
      "Iteration: 121/10000, Loss: 0.44639351963996887\n",
      "Iteration: 122/10000, Loss: 0.43632084131240845\n",
      "Iteration: 123/10000, Loss: 0.43931645154953003\n",
      "Iteration: 124/10000, Loss: 0.444212943315506\n",
      "Iteration: 125/10000, Loss: 0.4173141419887543\n",
      "Iteration: 126/10000, Loss: 0.4295220375061035\n",
      "Iteration: 127/10000, Loss: 0.42044633626937866\n",
      "Iteration: 128/10000, Loss: 0.4094378352165222\n",
      "Iteration: 129/10000, Loss: 0.412380576133728\n",
      "Iteration: 130/10000, Loss: 0.4001843333244324\n",
      "Iteration: 131/10000, Loss: 0.4195711612701416\n",
      "Iteration: 132/10000, Loss: 0.4218727648258209\n",
      "Iteration: 133/10000, Loss: 0.3839152753353119\n",
      "Iteration: 134/10000, Loss: 0.3912754952907562\n",
      "Iteration: 135/10000, Loss: 0.378888875246048\n",
      "Iteration: 136/10000, Loss: 0.3961920738220215\n",
      "Iteration: 137/10000, Loss: 0.3678407669067383\n",
      "Iteration: 138/10000, Loss: 0.3904857039451599\n",
      "Iteration: 139/10000, Loss: 0.38777783513069153\n",
      "Iteration: 140/10000, Loss: 0.3760348856449127\n",
      "Iteration: 141/10000, Loss: 0.3659535050392151\n",
      "Iteration: 142/10000, Loss: 0.3718435764312744\n",
      "Iteration: 143/10000, Loss: 0.3764563798904419\n",
      "Iteration: 144/10000, Loss: 0.35238656401634216\n",
      "Iteration: 145/10000, Loss: 0.36245855689048767\n",
      "Iteration: 146/10000, Loss: 0.3425690233707428\n",
      "Iteration: 147/10000, Loss: 0.33976510167121887\n",
      "Iteration: 148/10000, Loss: 0.34895646572113037\n",
      "Iteration: 149/10000, Loss: 0.34298285841941833\n",
      "Iteration: 150/10000, Loss: 0.33495014905929565\n",
      "Iteration: 151/10000, Loss: 0.3476935923099518\n",
      "Iteration: 152/10000, Loss: 0.3415558636188507\n",
      "Iteration: 153/10000, Loss: 0.31713685393333435\n",
      "Iteration: 154/10000, Loss: 0.3278931975364685\n",
      "Iteration: 155/10000, Loss: 0.3165906071662903\n",
      "Iteration: 156/10000, Loss: 0.32185468077659607\n",
      "Iteration: 157/10000, Loss: 0.3132205307483673\n",
      "Iteration: 158/10000, Loss: 0.3216208219528198\n",
      "Iteration: 159/10000, Loss: 0.3121908903121948\n",
      "Iteration: 160/10000, Loss: 0.30892935395240784\n",
      "Iteration: 161/10000, Loss: 0.30342897772789\n",
      "Iteration: 162/10000, Loss: 0.31584930419921875\n",
      "Iteration: 163/10000, Loss: 0.2930050790309906\n",
      "Iteration: 164/10000, Loss: 0.31723618507385254\n",
      "Iteration: 165/10000, Loss: 0.2928754389286041\n",
      "Iteration: 166/10000, Loss: 0.29103463888168335\n",
      "Iteration: 167/10000, Loss: 0.2831449806690216\n",
      "Iteration: 168/10000, Loss: 0.3074719309806824\n",
      "Iteration: 169/10000, Loss: 0.2834647595882416\n",
      "Iteration: 170/10000, Loss: 0.2730954587459564\n",
      "Iteration: 171/10000, Loss: 0.27988219261169434\n",
      "Iteration: 172/10000, Loss: 0.2815288007259369\n",
      "Iteration: 173/10000, Loss: 0.27345237135887146\n",
      "Iteration: 174/10000, Loss: 0.28860872983932495\n",
      "Iteration: 175/10000, Loss: 0.2474769800901413\n",
      "Iteration: 176/10000, Loss: 0.2617702782154083\n",
      "Iteration: 177/10000, Loss: 0.26549839973449707\n",
      "Iteration: 178/10000, Loss: 0.234535813331604\n",
      "Iteration: 179/10000, Loss: 0.27915626764297485\n",
      "Iteration: 180/10000, Loss: 0.2432054579257965\n",
      "Iteration: 181/10000, Loss: 0.2693512439727783\n",
      "Iteration: 182/10000, Loss: 0.27933555841445923\n",
      "Iteration: 183/10000, Loss: 0.23919352889060974\n",
      "Iteration: 184/10000, Loss: 0.25916656851768494\n",
      "Iteration: 185/10000, Loss: 0.26288551092147827\n",
      "Iteration: 186/10000, Loss: 0.2663235068321228\n",
      "Iteration: 187/10000, Loss: 0.24405792355537415\n",
      "Iteration: 188/10000, Loss: 0.23618143796920776\n",
      "Iteration: 189/10000, Loss: 0.23448097705841064\n",
      "Iteration: 190/10000, Loss: 0.21622347831726074\n",
      "Iteration: 191/10000, Loss: 0.2294854372739792\n",
      "Iteration: 192/10000, Loss: 0.24559369683265686\n",
      "Iteration: 193/10000, Loss: 0.21125954389572144\n",
      "Iteration: 194/10000, Loss: 0.2279801368713379\n",
      "Iteration: 195/10000, Loss: 0.2501334547996521\n",
      "Iteration: 196/10000, Loss: 0.22944965958595276\n",
      "Iteration: 197/10000, Loss: 0.2282201647758484\n",
      "Iteration: 198/10000, Loss: 0.21648231148719788\n",
      "Iteration: 199/10000, Loss: 0.2225452959537506\n",
      "Iteration: 200/10000, Loss: 0.20467010140419006\n",
      "Average test loss:  0.0135\n",
      "Iteration: 201/10000, Loss: 0.23318205773830414\n",
      "Iteration: 202/10000, Loss: 0.22610628604888916\n",
      "Iteration: 203/10000, Loss: 0.21502748131752014\n",
      "Iteration: 204/10000, Loss: 0.2563955783843994\n",
      "Iteration: 205/10000, Loss: 0.21321620047092438\n",
      "Iteration: 206/10000, Loss: 0.2308417707681656\n",
      "Iteration: 207/10000, Loss: 0.2171613574028015\n",
      "Iteration: 208/10000, Loss: 0.21245932579040527\n",
      "Iteration: 209/10000, Loss: 0.2125655859708786\n",
      "Iteration: 210/10000, Loss: 0.2152087539434433\n",
      "Iteration: 211/10000, Loss: 0.22831112146377563\n",
      "Iteration: 212/10000, Loss: 0.1860429346561432\n",
      "Iteration: 213/10000, Loss: 0.2001745104789734\n",
      "Iteration: 214/10000, Loss: 0.19047033786773682\n",
      "Iteration: 215/10000, Loss: 0.19538448750972748\n",
      "Iteration: 216/10000, Loss: 0.2070430964231491\n",
      "Iteration: 217/10000, Loss: 0.21858322620391846\n",
      "Iteration: 218/10000, Loss: 0.20405618846416473\n",
      "Iteration: 219/10000, Loss: 0.18827705085277557\n",
      "Iteration: 220/10000, Loss: 0.19982345402240753\n",
      "Iteration: 221/10000, Loss: 0.18671278655529022\n",
      "Iteration: 222/10000, Loss: 0.21732091903686523\n",
      "Iteration: 223/10000, Loss: 0.20947378873825073\n",
      "Iteration: 224/10000, Loss: 0.1857568919658661\n",
      "Iteration: 225/10000, Loss: 0.1918531060218811\n",
      "Iteration: 226/10000, Loss: 0.20274610817432404\n",
      "Iteration: 227/10000, Loss: 0.1855347752571106\n",
      "Iteration: 228/10000, Loss: 0.22192101180553436\n",
      "Iteration: 229/10000, Loss: 0.17514273524284363\n",
      "Iteration: 230/10000, Loss: 0.19613514840602875\n",
      "Iteration: 231/10000, Loss: 0.17827515304088593\n",
      "Iteration: 232/10000, Loss: 0.16312235593795776\n",
      "Iteration: 233/10000, Loss: 0.17789599299430847\n",
      "Iteration: 234/10000, Loss: 0.20009423792362213\n",
      "Iteration: 235/10000, Loss: 0.15266112983226776\n",
      "Iteration: 236/10000, Loss: 0.17145049571990967\n",
      "Iteration: 237/10000, Loss: 0.17741413414478302\n",
      "Iteration: 238/10000, Loss: 0.1648472100496292\n",
      "Iteration: 239/10000, Loss: 0.17797087132930756\n",
      "Iteration: 240/10000, Loss: 0.168706014752388\n",
      "Iteration: 241/10000, Loss: 0.17572996020317078\n",
      "Iteration: 242/10000, Loss: 0.18003344535827637\n",
      "Iteration: 243/10000, Loss: 0.18946442008018494\n",
      "Iteration: 244/10000, Loss: 0.182968407869339\n",
      "Iteration: 245/10000, Loss: 0.17092379927635193\n",
      "Iteration: 246/10000, Loss: 0.1823311746120453\n",
      "Iteration: 247/10000, Loss: 0.18858133256435394\n",
      "Iteration: 248/10000, Loss: 0.148206427693367\n",
      "Iteration: 249/10000, Loss: 0.17158396542072296\n",
      "Iteration: 250/10000, Loss: 0.15217776596546173\n",
      "Iteration: 251/10000, Loss: 0.15640181303024292\n",
      "Iteration: 252/10000, Loss: 0.15734730660915375\n",
      "Iteration: 253/10000, Loss: 0.16669650375843048\n",
      "Iteration: 254/10000, Loss: 0.15358762443065643\n",
      "Iteration: 255/10000, Loss: 0.15636220574378967\n",
      "Iteration: 256/10000, Loss: 0.19541794061660767\n",
      "Iteration: 257/10000, Loss: 0.14150358736515045\n",
      "Iteration: 258/10000, Loss: 0.18393349647521973\n",
      "Iteration: 259/10000, Loss: 0.16713754832744598\n",
      "Iteration: 260/10000, Loss: 0.16759659349918365\n",
      "Iteration: 261/10000, Loss: 0.14515116810798645\n",
      "Iteration: 262/10000, Loss: 0.1321677416563034\n",
      "Iteration: 263/10000, Loss: 0.1528182029724121\n",
      "Iteration: 264/10000, Loss: 0.1603430062532425\n",
      "Iteration: 265/10000, Loss: 0.1759975552558899\n",
      "Iteration: 266/10000, Loss: 0.1676969677209854\n",
      "Iteration: 267/10000, Loss: 0.1399989128112793\n",
      "Iteration: 268/10000, Loss: 0.15472657978534698\n",
      "Iteration: 269/10000, Loss: 0.16005347669124603\n",
      "Iteration: 270/10000, Loss: 0.17222747206687927\n",
      "Iteration: 271/10000, Loss: 0.1610686033964157\n",
      "Iteration: 272/10000, Loss: 0.1655513346195221\n",
      "Iteration: 273/10000, Loss: 0.14697600901126862\n",
      "Iteration: 274/10000, Loss: 0.13962088525295258\n",
      "Iteration: 275/10000, Loss: 0.13915251195430756\n",
      "Iteration: 276/10000, Loss: 0.135299950838089\n",
      "Iteration: 277/10000, Loss: 0.12843041121959686\n",
      "Iteration: 278/10000, Loss: 0.1472638100385666\n",
      "Iteration: 279/10000, Loss: 0.18004000186920166\n",
      "Iteration: 280/10000, Loss: 0.12206274271011353\n",
      "Iteration: 281/10000, Loss: 0.12658652663230896\n",
      "Iteration: 282/10000, Loss: 0.14723311364650726\n",
      "Iteration: 283/10000, Loss: 0.15031111240386963\n",
      "Iteration: 284/10000, Loss: 0.1320112645626068\n",
      "Iteration: 285/10000, Loss: 0.12836283445358276\n",
      "Iteration: 286/10000, Loss: 0.14219851791858673\n",
      "Iteration: 287/10000, Loss: 0.15864740312099457\n",
      "Iteration: 288/10000, Loss: 0.14965228736400604\n",
      "Iteration: 289/10000, Loss: 0.1268855482339859\n",
      "Iteration: 290/10000, Loss: 0.1540617048740387\n",
      "Iteration: 291/10000, Loss: 0.1452314257621765\n",
      "Iteration: 292/10000, Loss: 0.13735175132751465\n",
      "Iteration: 293/10000, Loss: 0.13238835334777832\n",
      "Iteration: 294/10000, Loss: 0.13926540315151215\n",
      "Iteration: 295/10000, Loss: 0.1358770728111267\n",
      "Iteration: 296/10000, Loss: 0.11877108365297318\n",
      "Iteration: 297/10000, Loss: 0.13736088573932648\n",
      "Iteration: 298/10000, Loss: 0.13837455213069916\n",
      "Iteration: 299/10000, Loss: 0.12031476199626923\n",
      "Iteration: 300/10000, Loss: 0.16778536140918732\n",
      "Average test loss:  0.0065\n",
      "Iteration: 301/10000, Loss: 0.1541443169116974\n",
      "Iteration: 302/10000, Loss: 0.13529877364635468\n",
      "Iteration: 303/10000, Loss: 0.1324097216129303\n",
      "Iteration: 304/10000, Loss: 0.13083092868328094\n",
      "Iteration: 305/10000, Loss: 0.1373283863067627\n",
      "Iteration: 306/10000, Loss: 0.1343902200460434\n",
      "Iteration: 307/10000, Loss: 0.1417461335659027\n",
      "Iteration: 308/10000, Loss: 0.11324240267276764\n",
      "Iteration: 309/10000, Loss: 0.1543738692998886\n",
      "Iteration: 310/10000, Loss: 0.1342862993478775\n",
      "Iteration: 311/10000, Loss: 0.12634198367595673\n",
      "Iteration: 312/10000, Loss: 0.13861186802387238\n",
      "Iteration: 313/10000, Loss: 0.11059029400348663\n",
      "Iteration: 314/10000, Loss: 0.13323825597763062\n",
      "Iteration: 315/10000, Loss: 0.14372822642326355\n",
      "Iteration: 316/10000, Loss: 0.13403542339801788\n",
      "Iteration: 317/10000, Loss: 0.1295253038406372\n",
      "Iteration: 318/10000, Loss: 0.1334608495235443\n",
      "Iteration: 319/10000, Loss: 0.11900471895933151\n",
      "Iteration: 320/10000, Loss: 0.13522551953792572\n",
      "Iteration: 321/10000, Loss: 0.12366508692502975\n",
      "Iteration: 322/10000, Loss: 0.11929915845394135\n",
      "Iteration: 323/10000, Loss: 0.13205039501190186\n",
      "Iteration: 324/10000, Loss: 0.14850163459777832\n",
      "Iteration: 325/10000, Loss: 0.1386459618806839\n",
      "Iteration: 326/10000, Loss: 0.11644912511110306\n",
      "Iteration: 327/10000, Loss: 0.1226830706000328\n",
      "Iteration: 328/10000, Loss: 0.151807963848114\n",
      "Iteration: 329/10000, Loss: 0.12012060731649399\n",
      "Iteration: 330/10000, Loss: 0.1265508532524109\n",
      "Iteration: 331/10000, Loss: 0.13329558074474335\n",
      "Iteration: 332/10000, Loss: 0.1167144924402237\n",
      "Iteration: 333/10000, Loss: 0.12475784868001938\n",
      "Iteration: 334/10000, Loss: 0.14201827347278595\n",
      "Iteration: 335/10000, Loss: 0.1379518210887909\n",
      "Iteration: 336/10000, Loss: 0.129789799451828\n",
      "Iteration: 337/10000, Loss: 0.09489845484495163\n",
      "Iteration: 338/10000, Loss: 0.13865290582180023\n",
      "Iteration: 339/10000, Loss: 0.15537235140800476\n",
      "Iteration: 340/10000, Loss: 0.11800925433635712\n",
      "Iteration: 341/10000, Loss: 0.10652647912502289\n",
      "Iteration: 342/10000, Loss: 0.10875958204269409\n",
      "Iteration: 343/10000, Loss: 0.12133538722991943\n",
      "Iteration: 344/10000, Loss: 0.14861755073070526\n",
      "Iteration: 345/10000, Loss: 0.12362119555473328\n",
      "Iteration: 346/10000, Loss: 0.10420882701873779\n",
      "Iteration: 347/10000, Loss: 0.14874523878097534\n",
      "Iteration: 348/10000, Loss: 0.09453679621219635\n",
      "Iteration: 349/10000, Loss: 0.1341720074415207\n",
      "Iteration: 350/10000, Loss: 0.1410064697265625\n",
      "Iteration: 351/10000, Loss: 0.13165956735610962\n",
      "Iteration: 352/10000, Loss: 0.1409013420343399\n",
      "Iteration: 353/10000, Loss: 0.11396822333335876\n",
      "Iteration: 354/10000, Loss: 0.13734421133995056\n",
      "Iteration: 355/10000, Loss: 0.11544818431138992\n",
      "Iteration: 356/10000, Loss: 0.10763485729694366\n",
      "Iteration: 357/10000, Loss: 0.1159285455942154\n",
      "Iteration: 358/10000, Loss: 0.1273300051689148\n",
      "Iteration: 359/10000, Loss: 0.0983959287405014\n",
      "Iteration: 360/10000, Loss: 0.10823827981948853\n",
      "Iteration: 361/10000, Loss: 0.11691056936979294\n",
      "Iteration: 362/10000, Loss: 0.1615481674671173\n",
      "Iteration: 363/10000, Loss: 0.11435000598430634\n",
      "Iteration: 364/10000, Loss: 0.13179051876068115\n",
      "Iteration: 365/10000, Loss: 0.1216946691274643\n",
      "Iteration: 366/10000, Loss: 0.10216591507196426\n",
      "Iteration: 367/10000, Loss: 0.10131726413965225\n",
      "Iteration: 368/10000, Loss: 0.09526637941598892\n",
      "Iteration: 369/10000, Loss: 0.144112691283226\n",
      "Iteration: 370/10000, Loss: 0.09679137915372849\n",
      "Iteration: 371/10000, Loss: 0.09883725643157959\n",
      "Iteration: 372/10000, Loss: 0.1118168830871582\n",
      "Iteration: 373/10000, Loss: 0.1275760531425476\n",
      "Iteration: 374/10000, Loss: 0.11641208827495575\n",
      "Iteration: 375/10000, Loss: 0.11726976931095123\n",
      "Iteration: 376/10000, Loss: 0.102626271545887\n",
      "Iteration: 377/10000, Loss: 0.09846124798059464\n",
      "Iteration: 378/10000, Loss: 0.09922456741333008\n",
      "Iteration: 379/10000, Loss: 0.11620957404375076\n",
      "Iteration: 380/10000, Loss: 0.15302571654319763\n",
      "Iteration: 381/10000, Loss: 0.1310860961675644\n",
      "Iteration: 382/10000, Loss: 0.1181437075138092\n",
      "Iteration: 383/10000, Loss: 0.10753365606069565\n",
      "Iteration: 384/10000, Loss: 0.12910479307174683\n",
      "Iteration: 385/10000, Loss: 0.11379284411668777\n",
      "Iteration: 386/10000, Loss: 0.09613890945911407\n",
      "Iteration: 387/10000, Loss: 0.10060863941907883\n",
      "Iteration: 388/10000, Loss: 0.11025827378034592\n",
      "Iteration: 389/10000, Loss: 0.11348410695791245\n",
      "Iteration: 390/10000, Loss: 0.1310887187719345\n",
      "Iteration: 391/10000, Loss: 0.11412439495325089\n",
      "Iteration: 392/10000, Loss: 0.10594583302736282\n",
      "Iteration: 393/10000, Loss: 0.11946241557598114\n",
      "Iteration: 394/10000, Loss: 0.09243430942296982\n",
      "Iteration: 395/10000, Loss: 0.11139067262411118\n",
      "Iteration: 396/10000, Loss: 0.1262407749891281\n",
      "Iteration: 397/10000, Loss: 0.1176789402961731\n",
      "Iteration: 398/10000, Loss: 0.09325117617845535\n",
      "Iteration: 399/10000, Loss: 0.12896959483623505\n",
      "Iteration: 400/10000, Loss: 0.08762490749359131\n",
      "Average test loss:  0.0059\n",
      "Iteration: 401/10000, Loss: 0.09503567218780518\n",
      "Iteration: 402/10000, Loss: 0.10476499795913696\n",
      "Iteration: 403/10000, Loss: 0.09621410816907883\n",
      "Iteration: 404/10000, Loss: 0.08611947298049927\n",
      "Iteration: 405/10000, Loss: 0.1210673525929451\n",
      "Iteration: 406/10000, Loss: 0.11383602768182755\n",
      "Iteration: 407/10000, Loss: 0.08386795967817307\n",
      "Iteration: 408/10000, Loss: 0.10227392613887787\n",
      "Iteration: 409/10000, Loss: 0.09577485918998718\n",
      "Iteration: 410/10000, Loss: 0.09877264499664307\n",
      "Iteration: 411/10000, Loss: 0.10188262909650803\n",
      "Iteration: 412/10000, Loss: 0.1321147382259369\n",
      "Iteration: 413/10000, Loss: 0.10703533887863159\n",
      "Iteration: 414/10000, Loss: 0.10553722828626633\n",
      "Iteration: 415/10000, Loss: 0.10974539071321487\n",
      "Iteration: 416/10000, Loss: 0.11037302762269974\n",
      "Iteration: 417/10000, Loss: 0.10474316030740738\n",
      "Iteration: 418/10000, Loss: 0.1084379032254219\n",
      "Iteration: 419/10000, Loss: 0.11662687361240387\n",
      "Iteration: 420/10000, Loss: 0.09336995333433151\n",
      "Iteration: 421/10000, Loss: 0.09268534183502197\n",
      "Iteration: 422/10000, Loss: 0.07623514533042908\n",
      "Iteration: 423/10000, Loss: 0.07488775998353958\n",
      "Iteration: 424/10000, Loss: 0.10710404813289642\n",
      "Iteration: 425/10000, Loss: 0.08860015124082565\n",
      "Iteration: 426/10000, Loss: 0.07810598611831665\n",
      "Iteration: 427/10000, Loss: 0.0813107043504715\n",
      "Iteration: 428/10000, Loss: 0.09427069872617722\n",
      "Iteration: 429/10000, Loss: 0.09364215284585953\n",
      "Iteration: 430/10000, Loss: 0.12050904333591461\n",
      "Iteration: 431/10000, Loss: 0.09138171374797821\n",
      "Iteration: 432/10000, Loss: 0.1101117953658104\n",
      "Iteration: 433/10000, Loss: 0.10206382721662521\n",
      "Iteration: 434/10000, Loss: 0.09136884659528732\n",
      "Iteration: 435/10000, Loss: 0.07791837304830551\n",
      "Iteration: 436/10000, Loss: 0.1061750277876854\n",
      "Iteration: 437/10000, Loss: 0.09543575346469879\n",
      "Iteration: 438/10000, Loss: 0.08020183444023132\n",
      "Iteration: 439/10000, Loss: 0.09587400406599045\n",
      "Iteration: 440/10000, Loss: 0.07014135271310806\n",
      "Iteration: 441/10000, Loss: 0.1075136587023735\n",
      "Iteration: 442/10000, Loss: 0.08332150429487228\n",
      "Iteration: 443/10000, Loss: 0.09038230031728745\n",
      "Iteration: 444/10000, Loss: 0.09501948952674866\n",
      "Iteration: 445/10000, Loss: 0.08338875323534012\n",
      "Iteration: 446/10000, Loss: 0.07792767882347107\n",
      "Iteration: 447/10000, Loss: 0.1313898265361786\n",
      "Iteration: 448/10000, Loss: 0.07849110662937164\n",
      "Iteration: 449/10000, Loss: 0.08862869441509247\n",
      "Iteration: 450/10000, Loss: 0.09659550338983536\n",
      "Iteration: 451/10000, Loss: 0.10758659243583679\n",
      "Iteration: 452/10000, Loss: 0.1376882642507553\n",
      "Iteration: 453/10000, Loss: 0.08633297681808472\n",
      "Iteration: 454/10000, Loss: 0.09621548652648926\n",
      "Iteration: 455/10000, Loss: 0.07874814420938492\n",
      "Iteration: 456/10000, Loss: 0.08360588550567627\n",
      "Iteration: 457/10000, Loss: 0.09621412307024002\n",
      "Iteration: 458/10000, Loss: 0.07910595089197159\n",
      "Iteration: 459/10000, Loss: 0.09291324764490128\n",
      "Iteration: 460/10000, Loss: 0.10195893049240112\n",
      "Iteration: 461/10000, Loss: 0.07126685231924057\n",
      "Iteration: 462/10000, Loss: 0.08421001583337784\n",
      "Iteration: 463/10000, Loss: 0.10915842652320862\n",
      "Iteration: 464/10000, Loss: 0.09747512638568878\n",
      "Iteration: 465/10000, Loss: 0.07915923744440079\n",
      "Iteration: 466/10000, Loss: 0.08558457344770432\n",
      "Iteration: 467/10000, Loss: 0.10390367358922958\n",
      "Iteration: 468/10000, Loss: 0.08042807132005692\n",
      "Iteration: 469/10000, Loss: 0.10138750076293945\n",
      "Iteration: 470/10000, Loss: 0.106402687728405\n",
      "Iteration: 471/10000, Loss: 0.08540767431259155\n",
      "Iteration: 472/10000, Loss: 0.07435344159603119\n",
      "Iteration: 473/10000, Loss: 0.10852101445198059\n",
      "Iteration: 474/10000, Loss: 0.09715721756219864\n",
      "Iteration: 475/10000, Loss: 0.08892019838094711\n",
      "Iteration: 476/10000, Loss: 0.078954316675663\n",
      "Iteration: 477/10000, Loss: 0.08352586627006531\n",
      "Iteration: 478/10000, Loss: 0.08167344331741333\n",
      "Iteration: 479/10000, Loss: 0.07677744328975677\n",
      "Iteration: 480/10000, Loss: 0.09398852288722992\n",
      "Iteration: 481/10000, Loss: 0.06756439059972763\n",
      "Iteration: 482/10000, Loss: 0.10594359785318375\n",
      "Iteration: 483/10000, Loss: 0.0725615844130516\n",
      "Iteration: 484/10000, Loss: 0.07682671397924423\n",
      "Iteration: 485/10000, Loss: 0.10228525102138519\n",
      "Iteration: 486/10000, Loss: 0.09455612301826477\n",
      "Iteration: 487/10000, Loss: 0.08307776600122452\n",
      "Iteration: 488/10000, Loss: 0.08153519034385681\n",
      "Iteration: 489/10000, Loss: 0.09427535533905029\n",
      "Iteration: 490/10000, Loss: 0.08009498566389084\n",
      "Iteration: 491/10000, Loss: 0.08787576109170914\n",
      "Iteration: 492/10000, Loss: 0.0949874222278595\n",
      "Iteration: 493/10000, Loss: 0.07810822874307632\n",
      "Iteration: 494/10000, Loss: 0.1037335991859436\n",
      "Iteration: 495/10000, Loss: 0.0848117545247078\n",
      "Iteration: 496/10000, Loss: 0.07121085375547409\n",
      "Iteration: 497/10000, Loss: 0.07891230285167694\n",
      "Iteration: 498/10000, Loss: 0.10275784879922867\n",
      "Iteration: 499/10000, Loss: 0.09992340952157974\n",
      "Iteration: 500/10000, Loss: 0.0688285231590271\n",
      "Average test loss:  0.0057\n",
      "Iteration: 501/10000, Loss: 0.09513626247644424\n",
      "Iteration: 502/10000, Loss: 0.09744502604007721\n",
      "Iteration: 503/10000, Loss: 0.073609858751297\n",
      "Iteration: 504/10000, Loss: 0.12157882750034332\n",
      "Iteration: 505/10000, Loss: 0.06747320294380188\n",
      "Iteration: 506/10000, Loss: 0.10720887780189514\n",
      "Iteration: 507/10000, Loss: 0.06421063840389252\n",
      "Iteration: 508/10000, Loss: 0.07598797976970673\n",
      "Iteration: 509/10000, Loss: 0.10670818388462067\n",
      "Iteration: 510/10000, Loss: 0.09217407554388046\n",
      "Iteration: 511/10000, Loss: 0.070333331823349\n",
      "Iteration: 512/10000, Loss: 0.07276415824890137\n",
      "Iteration: 513/10000, Loss: 0.07446518540382385\n",
      "Iteration: 514/10000, Loss: 0.09174078702926636\n",
      "Iteration: 515/10000, Loss: 0.10692404955625534\n",
      "Iteration: 516/10000, Loss: 0.07262800633907318\n",
      "Iteration: 517/10000, Loss: 0.07768139988183975\n",
      "Iteration: 518/10000, Loss: 0.09985784441232681\n",
      "Iteration: 519/10000, Loss: 0.08599165081977844\n",
      "Iteration: 520/10000, Loss: 0.06600061058998108\n",
      "Iteration: 521/10000, Loss: 0.08138658106327057\n",
      "Iteration: 522/10000, Loss: 0.09209808707237244\n",
      "Iteration: 523/10000, Loss: 0.07734725624322891\n",
      "Iteration: 524/10000, Loss: 0.13223497569561005\n",
      "Iteration: 525/10000, Loss: 0.06783881783485413\n",
      "Iteration: 526/10000, Loss: 0.06977245956659317\n",
      "Iteration: 527/10000, Loss: 0.07515200972557068\n",
      "Iteration: 528/10000, Loss: 0.06440592557191849\n",
      "Iteration: 529/10000, Loss: 0.06565460562705994\n",
      "Iteration: 530/10000, Loss: 0.05264023691415787\n",
      "Iteration: 531/10000, Loss: 0.09740816056728363\n",
      "Iteration: 532/10000, Loss: 0.11579485237598419\n",
      "Iteration: 533/10000, Loss: 0.06645123660564423\n",
      "Iteration: 534/10000, Loss: 0.07156763225793839\n",
      "Iteration: 535/10000, Loss: 0.0485650859773159\n",
      "Iteration: 536/10000, Loss: 0.08875945210456848\n",
      "Iteration: 537/10000, Loss: 0.07846629619598389\n",
      "Iteration: 538/10000, Loss: 0.07270690053701401\n",
      "Iteration: 539/10000, Loss: 0.09047629684209824\n",
      "Iteration: 540/10000, Loss: 0.06747481226921082\n",
      "Iteration: 541/10000, Loss: 0.08439340442419052\n",
      "Iteration: 542/10000, Loss: 0.0802568569779396\n",
      "Iteration: 543/10000, Loss: 0.1028759777545929\n",
      "Iteration: 544/10000, Loss: 0.08195380866527557\n",
      "Iteration: 545/10000, Loss: 0.0879460871219635\n",
      "Iteration: 546/10000, Loss: 0.10142160952091217\n",
      "Iteration: 547/10000, Loss: 0.0712931677699089\n",
      "Iteration: 548/10000, Loss: 0.07244062423706055\n",
      "Iteration: 549/10000, Loss: 0.06828714162111282\n",
      "Iteration: 550/10000, Loss: 0.09316857159137726\n",
      "Iteration: 551/10000, Loss: 0.07353127002716064\n",
      "Iteration: 552/10000, Loss: 0.06814141571521759\n",
      "Iteration: 553/10000, Loss: 0.07339835911989212\n",
      "Iteration: 554/10000, Loss: 0.07150857150554657\n",
      "Iteration: 555/10000, Loss: 0.06952915340662003\n",
      "Iteration: 556/10000, Loss: 0.06346713751554489\n",
      "Iteration: 557/10000, Loss: 0.09100490063428879\n",
      "Iteration: 558/10000, Loss: 0.08333112299442291\n",
      "Iteration: 559/10000, Loss: 0.06769046932458878\n",
      "Iteration: 560/10000, Loss: 0.07071570307016373\n",
      "Iteration: 561/10000, Loss: 0.09355996549129486\n",
      "Iteration: 562/10000, Loss: 0.0487322062253952\n",
      "Iteration: 563/10000, Loss: 0.07773872464895248\n",
      "Iteration: 564/10000, Loss: 0.059579554945230484\n",
      "Iteration: 565/10000, Loss: 0.09641427546739578\n",
      "Iteration: 566/10000, Loss: 0.07785844802856445\n",
      "Iteration: 567/10000, Loss: 0.07824503630399704\n",
      "Iteration: 568/10000, Loss: 0.08565002679824829\n",
      "Iteration: 569/10000, Loss: 0.0900656133890152\n",
      "Iteration: 570/10000, Loss: 0.0841945931315422\n",
      "Iteration: 571/10000, Loss: 0.07802484184503555\n",
      "Iteration: 572/10000, Loss: 0.06099476292729378\n",
      "Iteration: 573/10000, Loss: 0.07613995671272278\n",
      "Iteration: 574/10000, Loss: 0.08833028376102448\n",
      "Iteration: 575/10000, Loss: 0.06729037314653397\n",
      "Iteration: 576/10000, Loss: 0.07349318265914917\n",
      "Iteration: 577/10000, Loss: 0.0840635672211647\n",
      "Iteration: 578/10000, Loss: 0.08838802576065063\n",
      "Iteration: 579/10000, Loss: 0.07954993844032288\n",
      "Iteration: 580/10000, Loss: 0.0689256340265274\n",
      "Iteration: 581/10000, Loss: 0.06841867417097092\n",
      "Iteration: 582/10000, Loss: 0.08839483559131622\n",
      "Iteration: 583/10000, Loss: 0.05087694525718689\n",
      "Iteration: 584/10000, Loss: 0.08335895091295242\n",
      "Iteration: 585/10000, Loss: 0.08280094712972641\n",
      "Iteration: 586/10000, Loss: 0.08426084369421005\n",
      "Iteration: 587/10000, Loss: 0.10843376815319061\n",
      "Iteration: 588/10000, Loss: 0.06109797954559326\n",
      "Iteration: 589/10000, Loss: 0.07017502933740616\n",
      "Iteration: 590/10000, Loss: 0.07274103909730911\n",
      "Iteration: 591/10000, Loss: 0.07814907282590866\n",
      "Iteration: 592/10000, Loss: 0.08899348229169846\n",
      "Iteration: 593/10000, Loss: 0.0902915820479393\n",
      "Iteration: 594/10000, Loss: 0.09324274957180023\n",
      "Iteration: 595/10000, Loss: 0.06147925928235054\n",
      "Iteration: 596/10000, Loss: 0.09578096866607666\n",
      "Iteration: 597/10000, Loss: 0.07928702235221863\n",
      "Iteration: 598/10000, Loss: 0.06704802066087723\n",
      "Iteration: 599/10000, Loss: 0.0907636508345604\n",
      "Iteration: 600/10000, Loss: 0.0705190896987915\n",
      "Average test loss:  0.0048\n",
      "Iteration: 601/10000, Loss: 0.08337857574224472\n",
      "Iteration: 602/10000, Loss: 0.06764200329780579\n",
      "Iteration: 603/10000, Loss: 0.06119273230433464\n",
      "Iteration: 604/10000, Loss: 0.08074828237295151\n",
      "Iteration: 605/10000, Loss: 0.08355052024126053\n",
      "Iteration: 606/10000, Loss: 0.0748242437839508\n",
      "Iteration: 607/10000, Loss: 0.08451607823371887\n",
      "Iteration: 608/10000, Loss: 0.062226515263319016\n",
      "Iteration: 609/10000, Loss: 0.07961919158697128\n",
      "Iteration: 610/10000, Loss: 0.08733219653367996\n",
      "Iteration: 611/10000, Loss: 0.09398134052753448\n",
      "Iteration: 612/10000, Loss: 0.06781104952096939\n",
      "Iteration: 613/10000, Loss: 0.06351439654827118\n",
      "Iteration: 614/10000, Loss: 0.06744927167892456\n",
      "Iteration: 615/10000, Loss: 0.06914420425891876\n",
      "Iteration: 616/10000, Loss: 0.06724710017442703\n",
      "Iteration: 617/10000, Loss: 0.07701289653778076\n",
      "Iteration: 618/10000, Loss: 0.0591244176030159\n",
      "Iteration: 619/10000, Loss: 0.05295814573764801\n",
      "Iteration: 620/10000, Loss: 0.05518534779548645\n",
      "Iteration: 621/10000, Loss: 0.06155306473374367\n",
      "Iteration: 622/10000, Loss: 0.06923697888851166\n",
      "Iteration: 623/10000, Loss: 0.058812472969293594\n",
      "Iteration: 624/10000, Loss: 0.06655427813529968\n",
      "Iteration: 625/10000, Loss: 0.06925374269485474\n",
      "Iteration: 626/10000, Loss: 0.05853106081485748\n",
      "Iteration: 627/10000, Loss: 0.03843381628394127\n",
      "Iteration: 628/10000, Loss: 0.0703059732913971\n",
      "Iteration: 629/10000, Loss: 0.09490899741649628\n",
      "Iteration: 630/10000, Loss: 0.08765876293182373\n",
      "Iteration: 631/10000, Loss: 0.07105278223752975\n",
      "Iteration: 632/10000, Loss: 0.062043964862823486\n",
      "Iteration: 633/10000, Loss: 0.056328244507312775\n",
      "Iteration: 634/10000, Loss: 0.07021893560886383\n",
      "Iteration: 635/10000, Loss: 0.07419319450855255\n",
      "Iteration: 636/10000, Loss: 0.05815708637237549\n",
      "Iteration: 637/10000, Loss: 0.07580024749040604\n",
      "Iteration: 638/10000, Loss: 0.09078378975391388\n",
      "Iteration: 639/10000, Loss: 0.09445645660161972\n",
      "Iteration: 640/10000, Loss: 0.07212454825639725\n",
      "Iteration: 641/10000, Loss: 0.12212000787258148\n",
      "Iteration: 642/10000, Loss: 0.07185825705528259\n",
      "Iteration: 643/10000, Loss: 0.0736316666007042\n",
      "Iteration: 644/10000, Loss: 0.06981435418128967\n",
      "Iteration: 645/10000, Loss: 0.0782267302274704\n",
      "Iteration: 646/10000, Loss: 0.0637679174542427\n",
      "Iteration: 647/10000, Loss: 0.08215504884719849\n",
      "Iteration: 648/10000, Loss: 0.06450098007917404\n",
      "Iteration: 649/10000, Loss: 0.06793491542339325\n",
      "Iteration: 650/10000, Loss: 0.08585678040981293\n",
      "Iteration: 651/10000, Loss: 0.06035787612199783\n",
      "Iteration: 652/10000, Loss: 0.08831337839365005\n",
      "Iteration: 653/10000, Loss: 0.04827190563082695\n",
      "Iteration: 654/10000, Loss: 0.0690959021449089\n",
      "Iteration: 655/10000, Loss: 0.0575924776494503\n",
      "Iteration: 656/10000, Loss: 0.07072222232818604\n",
      "Iteration: 657/10000, Loss: 0.0639788955450058\n",
      "Iteration: 658/10000, Loss: 0.09978734701871872\n",
      "Iteration: 659/10000, Loss: 0.08719055354595184\n",
      "Iteration: 660/10000, Loss: 0.06023364141583443\n",
      "Iteration: 661/10000, Loss: 0.09395486861467361\n",
      "Iteration: 662/10000, Loss: 0.08425160497426987\n",
      "Iteration: 663/10000, Loss: 0.05790359899401665\n",
      "Iteration: 664/10000, Loss: 0.0602148175239563\n",
      "Iteration: 665/10000, Loss: 0.09062957018613815\n",
      "Iteration: 666/10000, Loss: 0.08071514219045639\n",
      "Iteration: 667/10000, Loss: 0.07969789952039719\n",
      "Iteration: 668/10000, Loss: 0.07007244974374771\n",
      "Iteration: 669/10000, Loss: 0.07469534128904343\n",
      "Iteration: 670/10000, Loss: 0.05514262244105339\n",
      "Iteration: 671/10000, Loss: 0.07670118659734726\n",
      "Iteration: 672/10000, Loss: 0.0784369558095932\n",
      "Iteration: 673/10000, Loss: 0.07709493488073349\n",
      "Iteration: 674/10000, Loss: 0.07269186526536942\n",
      "Iteration: 675/10000, Loss: 0.07308374345302582\n",
      "Iteration: 676/10000, Loss: 0.08253983408212662\n",
      "Iteration: 677/10000, Loss: 0.08153090626001358\n",
      "Iteration: 678/10000, Loss: 0.08205018192529678\n",
      "Iteration: 679/10000, Loss: 0.08922292292118073\n",
      "Iteration: 680/10000, Loss: 0.05430082604289055\n",
      "Iteration: 681/10000, Loss: 0.09671163558959961\n",
      "Iteration: 682/10000, Loss: 0.0704091489315033\n",
      "Iteration: 683/10000, Loss: 0.057009290903806686\n",
      "Iteration: 684/10000, Loss: 0.08083058893680573\n",
      "Iteration: 685/10000, Loss: 0.04818974435329437\n",
      "Iteration: 686/10000, Loss: 0.0712033361196518\n",
      "Iteration: 687/10000, Loss: 0.06788413226604462\n",
      "Iteration: 688/10000, Loss: 0.07830359786748886\n",
      "Iteration: 689/10000, Loss: 0.07439354062080383\n",
      "Iteration: 690/10000, Loss: 0.06441646814346313\n",
      "Iteration: 691/10000, Loss: 0.06387244910001755\n",
      "Iteration: 692/10000, Loss: 0.053378745913505554\n",
      "Iteration: 693/10000, Loss: 0.06790085881948471\n",
      "Iteration: 694/10000, Loss: 0.06231733039021492\n",
      "Iteration: 695/10000, Loss: 0.09046030044555664\n",
      "Iteration: 696/10000, Loss: 0.055059198290109634\n",
      "Iteration: 697/10000, Loss: 0.07797891646623611\n",
      "Iteration: 698/10000, Loss: 0.06376895308494568\n",
      "Iteration: 699/10000, Loss: 0.07759161293506622\n",
      "Iteration: 700/10000, Loss: 0.073589988052845\n",
      "Average test loss:  0.0060\n",
      "Iteration: 701/10000, Loss: 0.09206913411617279\n",
      "Iteration: 702/10000, Loss: 0.07399145513772964\n",
      "Iteration: 703/10000, Loss: 0.07298959791660309\n",
      "Iteration: 704/10000, Loss: 0.06212832033634186\n",
      "Iteration: 705/10000, Loss: 0.04607485979795456\n",
      "Iteration: 706/10000, Loss: 0.0767686665058136\n",
      "Iteration: 707/10000, Loss: 0.0783546045422554\n",
      "Iteration: 708/10000, Loss: 0.06185976788401604\n",
      "Iteration: 709/10000, Loss: 0.05017338693141937\n",
      "Iteration: 710/10000, Loss: 0.07421357184648514\n",
      "Iteration: 711/10000, Loss: 0.0839310884475708\n",
      "Iteration: 712/10000, Loss: 0.08333044499158859\n",
      "Iteration: 713/10000, Loss: 0.08117827028036118\n",
      "Iteration: 714/10000, Loss: 0.06828534603118896\n",
      "Iteration: 715/10000, Loss: 0.061087340116500854\n",
      "Iteration: 716/10000, Loss: 0.06953668594360352\n",
      "Iteration: 717/10000, Loss: 0.055017754435539246\n",
      "Iteration: 718/10000, Loss: 0.06510131806135178\n",
      "Iteration: 719/10000, Loss: 0.07883059978485107\n",
      "Iteration: 720/10000, Loss: 0.04500312730669975\n",
      "Iteration: 721/10000, Loss: 0.06758622825145721\n",
      "Iteration: 722/10000, Loss: 0.0645049661397934\n",
      "Iteration: 723/10000, Loss: 0.052165210247039795\n",
      "Iteration: 724/10000, Loss: 0.053262773901224136\n",
      "Iteration: 725/10000, Loss: 0.06562920659780502\n",
      "Iteration: 726/10000, Loss: 0.060892391949892044\n",
      "Iteration: 727/10000, Loss: 0.06407761573791504\n",
      "Iteration: 728/10000, Loss: 0.0770307257771492\n",
      "Iteration: 729/10000, Loss: 0.03775545209646225\n",
      "Iteration: 730/10000, Loss: 0.042742762714624405\n",
      "Iteration: 731/10000, Loss: 0.08353160321712494\n",
      "Iteration: 732/10000, Loss: 0.05612407997250557\n",
      "Iteration: 733/10000, Loss: 0.061416663229465485\n",
      "Iteration: 734/10000, Loss: 0.07723265141248703\n",
      "Iteration: 735/10000, Loss: 0.06690115481615067\n",
      "Iteration: 736/10000, Loss: 0.059292953461408615\n",
      "Iteration: 737/10000, Loss: 0.05168760567903519\n",
      "Iteration: 738/10000, Loss: 0.06206515058875084\n",
      "Iteration: 739/10000, Loss: 0.053239606320858\n",
      "Iteration: 740/10000, Loss: 0.0695641040802002\n",
      "Iteration: 741/10000, Loss: 0.05864166095852852\n",
      "Iteration: 742/10000, Loss: 0.06432028114795685\n",
      "Iteration: 743/10000, Loss: 0.08511949330568314\n",
      "Iteration: 744/10000, Loss: 0.07219286262989044\n",
      "Iteration: 745/10000, Loss: 0.06428782641887665\n",
      "Iteration: 746/10000, Loss: 0.07503913342952728\n",
      "Iteration: 747/10000, Loss: 0.08683738112449646\n",
      "Iteration: 748/10000, Loss: 0.0620533786714077\n",
      "Iteration: 749/10000, Loss: 0.07782413810491562\n",
      "Iteration: 750/10000, Loss: 0.0658009871840477\n",
      "Iteration: 751/10000, Loss: 0.061943892389535904\n",
      "Iteration: 752/10000, Loss: 0.06848763674497604\n",
      "Iteration: 753/10000, Loss: 0.0557512491941452\n",
      "Iteration: 754/10000, Loss: 0.052714232355356216\n",
      "Iteration: 755/10000, Loss: 0.07149732857942581\n",
      "Iteration: 756/10000, Loss: 0.07504095137119293\n",
      "Iteration: 757/10000, Loss: 0.0876058042049408\n",
      "Iteration: 758/10000, Loss: 0.0657057985663414\n",
      "Iteration: 759/10000, Loss: 0.06730131059885025\n",
      "Iteration: 760/10000, Loss: 0.05917111784219742\n",
      "Iteration: 761/10000, Loss: 0.0655774474143982\n",
      "Iteration: 762/10000, Loss: 0.05197235569357872\n",
      "Iteration: 763/10000, Loss: 0.05163570120930672\n",
      "Iteration: 764/10000, Loss: 0.0635296031832695\n",
      "Iteration: 765/10000, Loss: 0.049105651676654816\n",
      "Iteration: 766/10000, Loss: 0.07238899916410446\n",
      "Iteration: 767/10000, Loss: 0.08373107016086578\n",
      "Iteration: 768/10000, Loss: 0.052146267145872116\n",
      "Iteration: 769/10000, Loss: 0.10646901279687881\n",
      "Iteration: 770/10000, Loss: 0.059827979654073715\n",
      "Iteration: 771/10000, Loss: 0.06975886970758438\n",
      "Iteration: 772/10000, Loss: 0.06544952839612961\n",
      "Iteration: 773/10000, Loss: 0.06452780961990356\n",
      "Iteration: 774/10000, Loss: 0.0687313973903656\n",
      "Iteration: 775/10000, Loss: 0.07852689176797867\n",
      "Iteration: 776/10000, Loss: 0.041128769516944885\n",
      "Iteration: 777/10000, Loss: 0.05079737305641174\n",
      "Iteration: 778/10000, Loss: 0.07330233603715897\n",
      "Iteration: 779/10000, Loss: 0.04385149106383324\n",
      "Iteration: 780/10000, Loss: 0.056731753051280975\n",
      "Iteration: 781/10000, Loss: 0.04921941086649895\n",
      "Iteration: 782/10000, Loss: 0.040980104357004166\n",
      "Iteration: 783/10000, Loss: 0.09278194606304169\n",
      "Iteration: 784/10000, Loss: 0.05994683876633644\n",
      "Iteration: 785/10000, Loss: 0.06387638300657272\n",
      "Iteration: 786/10000, Loss: 0.05874107405543327\n",
      "Iteration: 787/10000, Loss: 0.05649421364068985\n",
      "Iteration: 788/10000, Loss: 0.0689103901386261\n",
      "Iteration: 789/10000, Loss: 0.059500645846128464\n",
      "Iteration: 790/10000, Loss: 0.061250533908605576\n",
      "Iteration: 791/10000, Loss: 0.05951933562755585\n",
      "Iteration: 792/10000, Loss: 0.07914382964372635\n",
      "Iteration: 793/10000, Loss: 0.07156231999397278\n",
      "Iteration: 794/10000, Loss: 0.05908404290676117\n",
      "Iteration: 795/10000, Loss: 0.08896250277757645\n",
      "Iteration: 796/10000, Loss: 0.053217969834804535\n",
      "Iteration: 797/10000, Loss: 0.06955119222402573\n",
      "Iteration: 798/10000, Loss: 0.07746727764606476\n",
      "Iteration: 799/10000, Loss: 0.06032441183924675\n",
      "Iteration: 800/10000, Loss: 0.05803770199418068\n",
      "Average test loss:  0.0035\n",
      "Iteration: 801/10000, Loss: 0.04949818179011345\n",
      "Iteration: 802/10000, Loss: 0.045803796499967575\n",
      "Iteration: 803/10000, Loss: 0.07958340644836426\n",
      "Iteration: 804/10000, Loss: 0.07046585530042648\n",
      "Iteration: 805/10000, Loss: 0.07768154889345169\n",
      "Iteration: 806/10000, Loss: 0.07951442152261734\n",
      "Iteration: 807/10000, Loss: 0.07516074180603027\n",
      "Iteration: 808/10000, Loss: 0.053525906056165695\n",
      "Iteration: 809/10000, Loss: 0.044225823134183884\n",
      "Iteration: 810/10000, Loss: 0.04744080826640129\n",
      "Iteration: 811/10000, Loss: 0.06597121804952621\n",
      "Iteration: 812/10000, Loss: 0.06955092400312424\n",
      "Iteration: 813/10000, Loss: 0.05026264861226082\n",
      "Iteration: 814/10000, Loss: 0.04822670295834541\n",
      "Iteration: 815/10000, Loss: 0.057745784521102905\n",
      "Iteration: 816/10000, Loss: 0.06836366653442383\n",
      "Iteration: 817/10000, Loss: 0.042776890099048615\n",
      "Iteration: 818/10000, Loss: 0.06714202463626862\n",
      "Iteration: 819/10000, Loss: 0.09525766968727112\n",
      "Iteration: 820/10000, Loss: 0.09101805090904236\n",
      "Iteration: 821/10000, Loss: 0.0721985250711441\n",
      "Iteration: 822/10000, Loss: 0.08069019764661789\n",
      "Iteration: 823/10000, Loss: 0.06009397655725479\n",
      "Iteration: 824/10000, Loss: 0.05507060885429382\n",
      "Iteration: 825/10000, Loss: 0.08057752996683121\n",
      "Iteration: 826/10000, Loss: 0.059444308280944824\n",
      "Iteration: 827/10000, Loss: 0.04808221757411957\n",
      "Iteration: 828/10000, Loss: 0.06932706385850906\n",
      "Iteration: 829/10000, Loss: 0.0663447380065918\n",
      "Iteration: 830/10000, Loss: 0.0650978535413742\n",
      "Iteration: 831/10000, Loss: 0.041464388370513916\n",
      "Iteration: 832/10000, Loss: 0.05597178265452385\n",
      "Iteration: 833/10000, Loss: 0.05656927451491356\n",
      "Iteration: 834/10000, Loss: 0.0641343966126442\n",
      "Iteration: 835/10000, Loss: 0.05697847157716751\n",
      "Iteration: 836/10000, Loss: 0.060737334191799164\n",
      "Iteration: 837/10000, Loss: 0.07103327661752701\n",
      "Iteration: 838/10000, Loss: 0.06789448112249374\n",
      "Iteration: 839/10000, Loss: 0.10074117034673691\n",
      "Iteration: 840/10000, Loss: 0.058932092040777206\n",
      "Iteration: 841/10000, Loss: 0.06614618748426437\n",
      "Iteration: 842/10000, Loss: 0.047741539776325226\n",
      "Iteration: 843/10000, Loss: 0.06916254013776779\n",
      "Iteration: 844/10000, Loss: 0.05636419355869293\n",
      "Iteration: 845/10000, Loss: 0.061777275055646896\n",
      "Iteration: 846/10000, Loss: 0.05658510699868202\n",
      "Iteration: 847/10000, Loss: 0.06165598705410957\n",
      "Iteration: 848/10000, Loss: 0.052592091262340546\n",
      "Iteration: 849/10000, Loss: 0.03805041313171387\n",
      "Iteration: 850/10000, Loss: 0.06758752465248108\n",
      "Iteration: 851/10000, Loss: 0.08374388515949249\n",
      "Iteration: 852/10000, Loss: 0.06788207590579987\n",
      "Iteration: 853/10000, Loss: 0.05793548747897148\n",
      "Iteration: 854/10000, Loss: 0.07520994544029236\n",
      "Iteration: 855/10000, Loss: 0.05460261180996895\n",
      "Iteration: 856/10000, Loss: 0.0692419782280922\n",
      "Iteration: 857/10000, Loss: 0.06039106473326683\n",
      "Iteration: 858/10000, Loss: 0.04552096873521805\n",
      "Iteration: 859/10000, Loss: 0.05622291937470436\n",
      "Iteration: 860/10000, Loss: 0.05384732037782669\n",
      "Iteration: 861/10000, Loss: 0.07035066932439804\n",
      "Iteration: 862/10000, Loss: 0.07616760581731796\n",
      "Iteration: 863/10000, Loss: 0.0634772852063179\n",
      "Iteration: 864/10000, Loss: 0.059621136635541916\n",
      "Iteration: 865/10000, Loss: 0.040285397320985794\n",
      "Iteration: 866/10000, Loss: 0.06283284723758698\n",
      "Iteration: 867/10000, Loss: 0.051943156868219376\n",
      "Iteration: 868/10000, Loss: 0.053498201072216034\n",
      "Iteration: 869/10000, Loss: 0.07195498794317245\n",
      "Iteration: 870/10000, Loss: 0.0564405657351017\n",
      "Iteration: 871/10000, Loss: 0.0610600970685482\n",
      "Iteration: 872/10000, Loss: 0.054198283702135086\n",
      "Iteration: 873/10000, Loss: 0.07549985498189926\n",
      "Iteration: 874/10000, Loss: 0.07062114775180817\n",
      "Iteration: 875/10000, Loss: 0.05380933731794357\n",
      "Iteration: 876/10000, Loss: 0.08243489265441895\n",
      "Iteration: 877/10000, Loss: 0.05724964290857315\n",
      "Iteration: 878/10000, Loss: 0.05504436045885086\n",
      "Iteration: 879/10000, Loss: 0.05959036573767662\n",
      "Iteration: 880/10000, Loss: 0.049119431525468826\n",
      "Iteration: 881/10000, Loss: 0.04299432039260864\n",
      "Iteration: 882/10000, Loss: 0.07185631990432739\n",
      "Iteration: 883/10000, Loss: 0.06608473509550095\n",
      "Iteration: 884/10000, Loss: 0.08770222216844559\n",
      "Iteration: 885/10000, Loss: 0.06387408077716827\n",
      "Iteration: 886/10000, Loss: 0.0491892509162426\n",
      "Iteration: 887/10000, Loss: 0.062079161405563354\n",
      "Iteration: 888/10000, Loss: 0.056633614003658295\n",
      "Iteration: 889/10000, Loss: 0.0532095767557621\n",
      "Iteration: 890/10000, Loss: 0.04829656332731247\n",
      "Iteration: 891/10000, Loss: 0.051971208304166794\n",
      "Iteration: 892/10000, Loss: 0.06815841794013977\n",
      "Iteration: 893/10000, Loss: 0.06747280806303024\n",
      "Iteration: 894/10000, Loss: 0.06002124026417732\n",
      "Iteration: 895/10000, Loss: 0.05817441642284393\n",
      "Iteration: 896/10000, Loss: 0.04542699456214905\n",
      "Iteration: 897/10000, Loss: 0.046678327023983\n",
      "Iteration: 898/10000, Loss: 0.06383994966745377\n",
      "Iteration: 899/10000, Loss: 0.059892840683460236\n",
      "Iteration: 900/10000, Loss: 0.06573463976383209\n",
      "Average test loss:  0.0042\n",
      "Iteration: 901/10000, Loss: 0.05859990417957306\n",
      "Iteration: 902/10000, Loss: 0.046548403799533844\n",
      "Iteration: 903/10000, Loss: 0.07242751866579056\n",
      "Iteration: 904/10000, Loss: 0.05322791263461113\n",
      "Iteration: 905/10000, Loss: 0.041782937943935394\n",
      "Iteration: 906/10000, Loss: 0.04930797219276428\n",
      "Iteration: 907/10000, Loss: 0.07565924525260925\n",
      "Iteration: 908/10000, Loss: 0.052341483533382416\n",
      "Iteration: 909/10000, Loss: 0.04992881789803505\n",
      "Iteration: 910/10000, Loss: 0.045464012771844864\n",
      "Iteration: 911/10000, Loss: 0.0450851172208786\n",
      "Iteration: 912/10000, Loss: 0.05013503506779671\n",
      "Iteration: 913/10000, Loss: 0.047655344009399414\n",
      "Iteration: 914/10000, Loss: 0.056004080921411514\n",
      "Iteration: 915/10000, Loss: 0.05513949319720268\n",
      "Iteration: 916/10000, Loss: 0.05998638644814491\n",
      "Iteration: 917/10000, Loss: 0.04726744443178177\n",
      "Iteration: 918/10000, Loss: 0.042343080043792725\n",
      "Iteration: 919/10000, Loss: 0.06216717138886452\n",
      "Iteration: 920/10000, Loss: 0.05919051542878151\n",
      "Iteration: 921/10000, Loss: 0.059010498225688934\n",
      "Iteration: 922/10000, Loss: 0.07479659467935562\n",
      "Iteration: 923/10000, Loss: 0.07177088409662247\n",
      "Iteration: 924/10000, Loss: 0.05896802246570587\n",
      "Iteration: 925/10000, Loss: 0.05799203738570213\n",
      "Iteration: 926/10000, Loss: 0.051359329372644424\n",
      "Iteration: 927/10000, Loss: 0.044960182160139084\n",
      "Iteration: 928/10000, Loss: 0.04472191631793976\n",
      "Iteration: 929/10000, Loss: 0.03818300738930702\n",
      "Iteration: 930/10000, Loss: 0.05576922371983528\n",
      "Iteration: 931/10000, Loss: 0.04292380064725876\n",
      "Iteration: 932/10000, Loss: 0.04333736374974251\n",
      "Iteration: 933/10000, Loss: 0.08095739781856537\n",
      "Iteration: 934/10000, Loss: 0.04694969952106476\n",
      "Iteration: 935/10000, Loss: 0.05185147002339363\n",
      "Iteration: 936/10000, Loss: 0.04536142200231552\n",
      "Iteration: 937/10000, Loss: 0.05725122615695\n",
      "Iteration: 938/10000, Loss: 0.03922482952475548\n",
      "Iteration: 939/10000, Loss: 0.040670592337846756\n",
      "Iteration: 940/10000, Loss: 0.06247206777334213\n",
      "Iteration: 941/10000, Loss: 0.06371252983808517\n",
      "Iteration: 942/10000, Loss: 0.05250483378767967\n",
      "Iteration: 943/10000, Loss: 0.05853511765599251\n",
      "Iteration: 944/10000, Loss: 0.06534283608198166\n",
      "Iteration: 945/10000, Loss: 0.048143286257982254\n",
      "Iteration: 946/10000, Loss: 0.033526986837387085\n",
      "Iteration: 947/10000, Loss: 0.08593590557575226\n",
      "Iteration: 948/10000, Loss: 0.044052720069885254\n",
      "Iteration: 949/10000, Loss: 0.04477769508957863\n",
      "Iteration: 950/10000, Loss: 0.0817224308848381\n",
      "Iteration: 951/10000, Loss: 0.07454722374677658\n",
      "Iteration: 952/10000, Loss: 0.04979446157813072\n",
      "Iteration: 953/10000, Loss: 0.060499463230371475\n",
      "Iteration: 954/10000, Loss: 0.04344839230179787\n",
      "Iteration: 955/10000, Loss: 0.048895105719566345\n",
      "Iteration: 956/10000, Loss: 0.06356635689735413\n",
      "Iteration: 957/10000, Loss: 0.05353093147277832\n",
      "Iteration: 958/10000, Loss: 0.06909066438674927\n",
      "Iteration: 959/10000, Loss: 0.0569458045065403\n",
      "Iteration: 960/10000, Loss: 0.05399065092206001\n",
      "Iteration: 961/10000, Loss: 0.03165438771247864\n",
      "Iteration: 962/10000, Loss: 0.042484547942876816\n",
      "Iteration: 963/10000, Loss: 0.03923391178250313\n",
      "Iteration: 964/10000, Loss: 0.10226708650588989\n",
      "Iteration: 965/10000, Loss: 0.05993012338876724\n",
      "Iteration: 966/10000, Loss: 0.0351877324283123\n",
      "Iteration: 967/10000, Loss: 0.06279638409614563\n",
      "Iteration: 968/10000, Loss: 0.06648992747068405\n",
      "Iteration: 969/10000, Loss: 0.05729752779006958\n",
      "Iteration: 970/10000, Loss: 0.06321964412927628\n",
      "Iteration: 971/10000, Loss: 0.04389370232820511\n",
      "Iteration: 972/10000, Loss: 0.0502341128885746\n",
      "Iteration: 973/10000, Loss: 0.05035629868507385\n",
      "Iteration: 974/10000, Loss: 0.04859524592757225\n",
      "Iteration: 975/10000, Loss: 0.059457506984472275\n",
      "Iteration: 976/10000, Loss: 0.1014767736196518\n",
      "Iteration: 977/10000, Loss: 0.05680044740438461\n",
      "Iteration: 978/10000, Loss: 0.04683171957731247\n",
      "Iteration: 979/10000, Loss: 0.04412013292312622\n",
      "Iteration: 980/10000, Loss: 0.051364827901124954\n",
      "Iteration: 981/10000, Loss: 0.031519439071416855\n",
      "Iteration: 982/10000, Loss: 0.05390089377760887\n",
      "Iteration: 983/10000, Loss: 0.07979471981525421\n",
      "Iteration: 984/10000, Loss: 0.06518059968948364\n",
      "Iteration: 985/10000, Loss: 0.0634736716747284\n",
      "Iteration: 986/10000, Loss: 0.059395354241132736\n",
      "Iteration: 987/10000, Loss: 0.07571281492710114\n",
      "Iteration: 988/10000, Loss: 0.03738173097372055\n",
      "Iteration: 989/10000, Loss: 0.062017034739255905\n",
      "Iteration: 990/10000, Loss: 0.0616290383040905\n",
      "Iteration: 991/10000, Loss: 0.04782174527645111\n",
      "Iteration: 992/10000, Loss: 0.055550556629896164\n",
      "Iteration: 993/10000, Loss: 0.054057858884334564\n",
      "Iteration: 994/10000, Loss: 0.04152125492691994\n",
      "Iteration: 995/10000, Loss: 0.06231256201863289\n",
      "Iteration: 996/10000, Loss: 0.08262623846530914\n",
      "Iteration: 997/10000, Loss: 0.05598607659339905\n",
      "Iteration: 998/10000, Loss: 0.03932047262787819\n",
      "Iteration: 999/10000, Loss: 0.05320722237229347\n",
      "Iteration: 1000/10000, Loss: 0.054001856595277786\n",
      "Average test loss:  0.0044\n",
      "Iteration: 1001/10000, Loss: 0.06954049319028854\n",
      "Iteration: 1002/10000, Loss: 0.058517999947071075\n",
      "Iteration: 1003/10000, Loss: 0.050965454429388046\n",
      "Iteration: 1004/10000, Loss: 0.045317213982343674\n",
      "Iteration: 1005/10000, Loss: 0.0465247817337513\n",
      "Iteration: 1006/10000, Loss: 0.050305623561143875\n",
      "Iteration: 1007/10000, Loss: 0.04433822259306908\n",
      "Iteration: 1008/10000, Loss: 0.07180409878492355\n",
      "Iteration: 1009/10000, Loss: 0.05791027843952179\n",
      "Iteration: 1010/10000, Loss: 0.049126479774713516\n",
      "Iteration: 1011/10000, Loss: 0.04822572320699692\n",
      "Iteration: 1012/10000, Loss: 0.04974919185042381\n",
      "Iteration: 1013/10000, Loss: 0.05611226335167885\n",
      "Iteration: 1014/10000, Loss: 0.041286651045084\n",
      "Iteration: 1015/10000, Loss: 0.047905005514621735\n",
      "Iteration: 1016/10000, Loss: 0.07437800616025925\n",
      "Iteration: 1017/10000, Loss: 0.051305968314409256\n",
      "Iteration: 1018/10000, Loss: 0.08007923513650894\n",
      "Iteration: 1019/10000, Loss: 0.06301481276750565\n",
      "Iteration: 1020/10000, Loss: 0.06295204162597656\n",
      "Iteration: 1021/10000, Loss: 0.0451546311378479\n",
      "Iteration: 1022/10000, Loss: 0.04426848888397217\n",
      "Iteration: 1023/10000, Loss: 0.05790156498551369\n",
      "Iteration: 1024/10000, Loss: 0.0821387767791748\n",
      "Iteration: 1025/10000, Loss: 0.047213114798069\n",
      "Iteration: 1026/10000, Loss: 0.0663418397307396\n",
      "Iteration: 1027/10000, Loss: 0.041421547532081604\n",
      "Iteration: 1028/10000, Loss: 0.08066824078559875\n",
      "Iteration: 1029/10000, Loss: 0.04169554263353348\n",
      "Iteration: 1030/10000, Loss: 0.06180115416646004\n",
      "Iteration: 1031/10000, Loss: 0.04208832234144211\n",
      "Iteration: 1032/10000, Loss: 0.03880821913480759\n",
      "Iteration: 1033/10000, Loss: 0.05081520229578018\n",
      "Iteration: 1034/10000, Loss: 0.06510458886623383\n",
      "Iteration: 1035/10000, Loss: 0.05056338384747505\n",
      "Iteration: 1036/10000, Loss: 0.04036460071802139\n",
      "Iteration: 1037/10000, Loss: 0.054688889533281326\n",
      "Iteration: 1038/10000, Loss: 0.05637049302458763\n",
      "Iteration: 1039/10000, Loss: 0.04057471826672554\n",
      "Iteration: 1040/10000, Loss: 0.058833055198192596\n",
      "Iteration: 1041/10000, Loss: 0.056783515959978104\n",
      "Iteration: 1042/10000, Loss: 0.044985733926296234\n",
      "Iteration: 1043/10000, Loss: 0.04854610934853554\n",
      "Iteration: 1044/10000, Loss: 0.04086901247501373\n",
      "Iteration: 1045/10000, Loss: 0.04641781374812126\n",
      "Iteration: 1046/10000, Loss: 0.06528720259666443\n",
      "Iteration: 1047/10000, Loss: 0.048912163823843\n",
      "Iteration: 1048/10000, Loss: 0.04216236248612404\n",
      "Iteration: 1049/10000, Loss: 0.044195786118507385\n",
      "Iteration: 1050/10000, Loss: 0.052357736974954605\n",
      "Iteration: 1051/10000, Loss: 0.05216571316123009\n",
      "Iteration: 1052/10000, Loss: 0.028948567807674408\n",
      "Iteration: 1053/10000, Loss: 0.06978125125169754\n",
      "Iteration: 1054/10000, Loss: 0.05338192731142044\n",
      "Iteration: 1055/10000, Loss: 0.0607447475194931\n",
      "Iteration: 1056/10000, Loss: 0.0581519789993763\n",
      "Iteration: 1057/10000, Loss: 0.03047892637550831\n",
      "Iteration: 1058/10000, Loss: 0.06318230926990509\n",
      "Iteration: 1059/10000, Loss: 0.052938226610422134\n",
      "Iteration: 1060/10000, Loss: 0.050552234053611755\n",
      "Iteration: 1061/10000, Loss: 0.0658406913280487\n",
      "Iteration: 1062/10000, Loss: 0.052531007677316666\n",
      "Iteration: 1063/10000, Loss: 0.04715173691511154\n",
      "Iteration: 1064/10000, Loss: 0.04043581709265709\n",
      "Iteration: 1065/10000, Loss: 0.05781767889857292\n",
      "Iteration: 1066/10000, Loss: 0.0489366315305233\n",
      "Iteration: 1067/10000, Loss: 0.05002059414982796\n",
      "Iteration: 1068/10000, Loss: 0.04756249859929085\n",
      "Iteration: 1069/10000, Loss: 0.049065276980400085\n",
      "Iteration: 1070/10000, Loss: 0.043384209275245667\n",
      "Iteration: 1071/10000, Loss: 0.0438130684196949\n",
      "Iteration: 1072/10000, Loss: 0.03908810019493103\n",
      "Iteration: 1073/10000, Loss: 0.045261483639478683\n",
      "Iteration: 1074/10000, Loss: 0.034312255680561066\n",
      "Iteration: 1075/10000, Loss: 0.05942239984869957\n",
      "Iteration: 1076/10000, Loss: 0.041452985256910324\n",
      "Iteration: 1077/10000, Loss: 0.04582938551902771\n",
      "Iteration: 1078/10000, Loss: 0.043190859258174896\n",
      "Iteration: 1079/10000, Loss: 0.05489002540707588\n",
      "Iteration: 1080/10000, Loss: 0.04793424904346466\n",
      "Iteration: 1081/10000, Loss: 0.05310763418674469\n",
      "Iteration: 1082/10000, Loss: 0.045856572687625885\n",
      "Iteration: 1083/10000, Loss: 0.040303248912096024\n",
      "Iteration: 1084/10000, Loss: 0.05394228547811508\n",
      "Iteration: 1085/10000, Loss: 0.05278034508228302\n",
      "Iteration: 1086/10000, Loss: 0.04184586554765701\n",
      "Iteration: 1087/10000, Loss: 0.05671674385666847\n",
      "Iteration: 1088/10000, Loss: 0.055636778473854065\n",
      "Iteration: 1089/10000, Loss: 0.04317402467131615\n",
      "Iteration: 1090/10000, Loss: 0.057330600917339325\n",
      "Iteration: 1091/10000, Loss: 0.05218909680843353\n",
      "Iteration: 1092/10000, Loss: 0.07343174517154694\n",
      "Iteration: 1093/10000, Loss: 0.04893283173441887\n",
      "Iteration: 1094/10000, Loss: 0.04184889420866966\n",
      "Iteration: 1095/10000, Loss: 0.05565540865063667\n",
      "Iteration: 1096/10000, Loss: 0.05448025092482567\n",
      "Iteration: 1097/10000, Loss: 0.0454341396689415\n",
      "Iteration: 1098/10000, Loss: 0.04931219667196274\n",
      "Iteration: 1099/10000, Loss: 0.04216520115733147\n",
      "Iteration: 1100/10000, Loss: 0.047026626765728\n",
      "Average test loss:  0.0026\n",
      "Iteration: 1101/10000, Loss: 0.06991726160049438\n",
      "Iteration: 1102/10000, Loss: 0.05618087947368622\n",
      "Iteration: 1103/10000, Loss: 0.04254383221268654\n",
      "Iteration: 1104/10000, Loss: 0.059195198118686676\n",
      "Iteration: 1105/10000, Loss: 0.05339145287871361\n",
      "Iteration: 1106/10000, Loss: 0.056824829429388046\n",
      "Iteration: 1107/10000, Loss: 0.05549145117402077\n",
      "Iteration: 1108/10000, Loss: 0.037869829684495926\n",
      "Iteration: 1109/10000, Loss: 0.054087813943624496\n",
      "Iteration: 1110/10000, Loss: 0.04983721300959587\n",
      "Iteration: 1111/10000, Loss: 0.047954950481653214\n",
      "Iteration: 1112/10000, Loss: 0.046353530138731\n",
      "Iteration: 1113/10000, Loss: 0.05776822566986084\n",
      "Iteration: 1114/10000, Loss: 0.03924793004989624\n",
      "Iteration: 1115/10000, Loss: 0.04416659101843834\n",
      "Iteration: 1116/10000, Loss: 0.0471908301115036\n",
      "Iteration: 1117/10000, Loss: 0.028476949781179428\n",
      "Iteration: 1118/10000, Loss: 0.06135374680161476\n",
      "Iteration: 1119/10000, Loss: 0.07730605453252792\n",
      "Iteration: 1120/10000, Loss: 0.06647716462612152\n",
      "Iteration: 1121/10000, Loss: 0.07406029105186462\n",
      "Iteration: 1122/10000, Loss: 0.05166051909327507\n",
      "Iteration: 1123/10000, Loss: 0.04717981442809105\n",
      "Iteration: 1124/10000, Loss: 0.043406013399362564\n",
      "Iteration: 1125/10000, Loss: 0.041523195803165436\n",
      "Iteration: 1126/10000, Loss: 0.05475196987390518\n",
      "Iteration: 1127/10000, Loss: 0.07130784541368484\n",
      "Iteration: 1128/10000, Loss: 0.03738924115896225\n",
      "Iteration: 1129/10000, Loss: 0.05355577543377876\n",
      "Iteration: 1130/10000, Loss: 0.06574420630931854\n",
      "Iteration: 1131/10000, Loss: 0.06777919828891754\n",
      "Iteration: 1132/10000, Loss: 0.05470050498843193\n",
      "Iteration: 1133/10000, Loss: 0.05208611860871315\n",
      "Iteration: 1134/10000, Loss: 0.03551464155316353\n",
      "Iteration: 1135/10000, Loss: 0.048993293195962906\n",
      "Iteration: 1136/10000, Loss: 0.06345830857753754\n",
      "Iteration: 1137/10000, Loss: 0.08035513013601303\n",
      "Iteration: 1138/10000, Loss: 0.056992556899785995\n",
      "Iteration: 1139/10000, Loss: 0.03804829344153404\n",
      "Iteration: 1140/10000, Loss: 0.04589343070983887\n",
      "Iteration: 1141/10000, Loss: 0.047175295650959015\n",
      "Iteration: 1142/10000, Loss: 0.05419599637389183\n",
      "Iteration: 1143/10000, Loss: 0.046129852533340454\n",
      "Iteration: 1144/10000, Loss: 0.055715519934892654\n",
      "Iteration: 1145/10000, Loss: 0.0496857725083828\n",
      "Iteration: 1146/10000, Loss: 0.04732266068458557\n",
      "Iteration: 1147/10000, Loss: 0.04502200707793236\n",
      "Iteration: 1148/10000, Loss: 0.0475420281291008\n",
      "Iteration: 1149/10000, Loss: 0.056057751178741455\n",
      "Iteration: 1150/10000, Loss: 0.04370845481753349\n",
      "Iteration: 1151/10000, Loss: 0.04720347374677658\n",
      "Iteration: 1152/10000, Loss: 0.04208787530660629\n",
      "Iteration: 1153/10000, Loss: 0.0540957972407341\n",
      "Iteration: 1154/10000, Loss: 0.07473700493574142\n",
      "Iteration: 1155/10000, Loss: 0.060117386281490326\n",
      "Iteration: 1156/10000, Loss: 0.038245249539613724\n",
      "Iteration: 1157/10000, Loss: 0.06884681433439255\n",
      "Iteration: 1158/10000, Loss: 0.05247170478105545\n",
      "Iteration: 1159/10000, Loss: 0.04421719163656235\n",
      "Iteration: 1160/10000, Loss: 0.05200287327170372\n",
      "Iteration: 1161/10000, Loss: 0.05585384741425514\n",
      "Iteration: 1162/10000, Loss: 0.06418025493621826\n",
      "Iteration: 1163/10000, Loss: 0.03787045553326607\n",
      "Iteration: 1164/10000, Loss: 0.06205561384558678\n",
      "Iteration: 1165/10000, Loss: 0.05848650261759758\n",
      "Iteration: 1166/10000, Loss: 0.047151174396276474\n",
      "Iteration: 1167/10000, Loss: 0.05186532437801361\n",
      "Iteration: 1168/10000, Loss: 0.042684514075517654\n",
      "Iteration: 1169/10000, Loss: 0.06115690991282463\n",
      "Iteration: 1170/10000, Loss: 0.07807990163564682\n",
      "Iteration: 1171/10000, Loss: 0.04614623636007309\n",
      "Iteration: 1172/10000, Loss: 0.04653564840555191\n",
      "Iteration: 1173/10000, Loss: 0.05464024841785431\n",
      "Iteration: 1174/10000, Loss: 0.05848478525876999\n",
      "Iteration: 1175/10000, Loss: 0.05598245561122894\n",
      "Iteration: 1176/10000, Loss: 0.04548913240432739\n",
      "Iteration: 1177/10000, Loss: 0.03472975268959999\n",
      "Iteration: 1178/10000, Loss: 0.04750005528330803\n",
      "Iteration: 1179/10000, Loss: 0.04391981288790703\n",
      "Iteration: 1180/10000, Loss: 0.03808261454105377\n",
      "Iteration: 1181/10000, Loss: 0.05034374073147774\n",
      "Iteration: 1182/10000, Loss: 0.03182241693139076\n",
      "Iteration: 1183/10000, Loss: 0.05337747186422348\n",
      "Iteration: 1184/10000, Loss: 0.05882525071501732\n",
      "Iteration: 1185/10000, Loss: 0.05493209883570671\n",
      "Iteration: 1186/10000, Loss: 0.05175406485795975\n",
      "Iteration: 1187/10000, Loss: 0.07707539200782776\n",
      "Iteration: 1188/10000, Loss: 0.04214850440621376\n",
      "Iteration: 1189/10000, Loss: 0.05327669903635979\n",
      "Iteration: 1190/10000, Loss: 0.0670301616191864\n",
      "Iteration: 1191/10000, Loss: 0.040630169212818146\n",
      "Iteration: 1192/10000, Loss: 0.05130687355995178\n",
      "Iteration: 1193/10000, Loss: 0.03965245932340622\n",
      "Iteration: 1194/10000, Loss: 0.05042598769068718\n",
      "Iteration: 1195/10000, Loss: 0.04702921584248543\n",
      "Iteration: 1196/10000, Loss: 0.0529450848698616\n",
      "Iteration: 1197/10000, Loss: 0.05502326786518097\n",
      "Iteration: 1198/10000, Loss: 0.05070457607507706\n",
      "Iteration: 1199/10000, Loss: 0.04344724863767624\n",
      "Iteration: 1200/10000, Loss: 0.05559759959578514\n",
      "Average test loss:  0.0028\n",
      "Iteration: 1201/10000, Loss: 0.059069808572530746\n",
      "Iteration: 1202/10000, Loss: 0.037995465099811554\n",
      "Iteration: 1203/10000, Loss: 0.04050503671169281\n",
      "Iteration: 1204/10000, Loss: 0.05799597129225731\n",
      "Iteration: 1205/10000, Loss: 0.05363302305340767\n",
      "Iteration: 1206/10000, Loss: 0.0421600304543972\n",
      "Iteration: 1207/10000, Loss: 0.04767432063817978\n",
      "Iteration: 1208/10000, Loss: 0.0434320904314518\n",
      "Iteration: 1209/10000, Loss: 0.03045685589313507\n",
      "Iteration: 1210/10000, Loss: 0.04578592628240585\n",
      "Iteration: 1211/10000, Loss: 0.05986293405294418\n",
      "Iteration: 1212/10000, Loss: 0.042372360825538635\n",
      "Iteration: 1213/10000, Loss: 0.038293126970529556\n",
      "Iteration: 1214/10000, Loss: 0.07028944045305252\n",
      "Iteration: 1215/10000, Loss: 0.04212170094251633\n",
      "Iteration: 1216/10000, Loss: 0.03539520129561424\n",
      "Iteration: 1217/10000, Loss: 0.03524249047040939\n",
      "Iteration: 1218/10000, Loss: 0.05244842916727066\n",
      "Iteration: 1219/10000, Loss: 0.0588899664580822\n",
      "Iteration: 1220/10000, Loss: 0.03544994816184044\n",
      "Iteration: 1221/10000, Loss: 0.03121243417263031\n",
      "Iteration: 1222/10000, Loss: 0.03729540854692459\n",
      "Iteration: 1223/10000, Loss: 0.0547889769077301\n",
      "Iteration: 1224/10000, Loss: 0.02439570613205433\n",
      "Iteration: 1225/10000, Loss: 0.03395216166973114\n",
      "Iteration: 1226/10000, Loss: 0.04195026308298111\n",
      "Iteration: 1227/10000, Loss: 0.0689968392252922\n",
      "Iteration: 1228/10000, Loss: 0.04360899701714516\n",
      "Iteration: 1229/10000, Loss: 0.061501652002334595\n",
      "Iteration: 1230/10000, Loss: 0.052703969180583954\n",
      "Iteration: 1231/10000, Loss: 0.03719554841518402\n",
      "Iteration: 1232/10000, Loss: 0.059955697506666183\n",
      "Iteration: 1233/10000, Loss: 0.03629911690950394\n",
      "Iteration: 1234/10000, Loss: 0.044675666838884354\n",
      "Iteration: 1235/10000, Loss: 0.04636364057660103\n",
      "Iteration: 1236/10000, Loss: 0.038453612476587296\n",
      "Iteration: 1237/10000, Loss: 0.049184512346982956\n",
      "Iteration: 1238/10000, Loss: 0.051189620047807693\n",
      "Iteration: 1239/10000, Loss: 0.05430232733488083\n",
      "Iteration: 1240/10000, Loss: 0.044769760221242905\n",
      "Iteration: 1241/10000, Loss: 0.06932594627141953\n",
      "Iteration: 1242/10000, Loss: 0.05974774435162544\n",
      "Iteration: 1243/10000, Loss: 0.05978412553668022\n",
      "Iteration: 1244/10000, Loss: 0.04313191398978233\n",
      "Iteration: 1245/10000, Loss: 0.03410406410694122\n",
      "Iteration: 1246/10000, Loss: 0.05056722089648247\n",
      "Iteration: 1247/10000, Loss: 0.04525042325258255\n",
      "Iteration: 1248/10000, Loss: 0.04327768087387085\n",
      "Iteration: 1249/10000, Loss: 0.046290699392557144\n",
      "Iteration: 1250/10000, Loss: 0.0338127501308918\n",
      "Iteration: 1251/10000, Loss: 0.050235483795404434\n",
      "Iteration: 1252/10000, Loss: 0.04583706706762314\n",
      "Iteration: 1253/10000, Loss: 0.045256759971380234\n",
      "Iteration: 1254/10000, Loss: 0.0639893114566803\n",
      "Iteration: 1255/10000, Loss: 0.04266142472624779\n",
      "Iteration: 1256/10000, Loss: 0.03744884207844734\n",
      "Iteration: 1257/10000, Loss: 0.039079148322343826\n",
      "Iteration: 1258/10000, Loss: 0.04504401609301567\n",
      "Iteration: 1259/10000, Loss: 0.03519057482481003\n",
      "Iteration: 1260/10000, Loss: 0.047071635723114014\n",
      "Iteration: 1261/10000, Loss: 0.04690037667751312\n",
      "Iteration: 1262/10000, Loss: 0.04134254902601242\n",
      "Iteration: 1263/10000, Loss: 0.043905146420001984\n",
      "Iteration: 1264/10000, Loss: 0.044406451284885406\n",
      "Iteration: 1265/10000, Loss: 0.06550303846597672\n",
      "Iteration: 1266/10000, Loss: 0.049370668828487396\n",
      "Iteration: 1267/10000, Loss: 0.03927681967616081\n",
      "Iteration: 1268/10000, Loss: 0.042612310498952866\n",
      "Iteration: 1269/10000, Loss: 0.03244746848940849\n",
      "Iteration: 1270/10000, Loss: 0.037771232426166534\n",
      "Iteration: 1271/10000, Loss: 0.039147183299064636\n",
      "Iteration: 1272/10000, Loss: 0.034714825451374054\n",
      "Iteration: 1273/10000, Loss: 0.03636494651436806\n",
      "Iteration: 1274/10000, Loss: 0.04140639677643776\n",
      "Iteration: 1275/10000, Loss: 0.04531773179769516\n",
      "Iteration: 1276/10000, Loss: 0.052498914301395416\n",
      "Iteration: 1277/10000, Loss: 0.0366874560713768\n",
      "Iteration: 1278/10000, Loss: 0.05159848555922508\n",
      "Iteration: 1279/10000, Loss: 0.032179635018110275\n",
      "Iteration: 1280/10000, Loss: 0.04759185016155243\n",
      "Iteration: 1281/10000, Loss: 0.04099211469292641\n",
      "Iteration: 1282/10000, Loss: 0.04789299890398979\n",
      "Iteration: 1283/10000, Loss: 0.03935648873448372\n",
      "Iteration: 1284/10000, Loss: 0.04315578565001488\n",
      "Iteration: 1285/10000, Loss: 0.043861277401447296\n",
      "Iteration: 1286/10000, Loss: 0.044582754373550415\n",
      "Iteration: 1287/10000, Loss: 0.04930548742413521\n",
      "Iteration: 1288/10000, Loss: 0.05179774761199951\n",
      "Iteration: 1289/10000, Loss: 0.046792369335889816\n",
      "Iteration: 1290/10000, Loss: 0.05231408774852753\n",
      "Iteration: 1291/10000, Loss: 0.05250316113233566\n",
      "Iteration: 1292/10000, Loss: 0.04269891232252121\n",
      "Iteration: 1293/10000, Loss: 0.0569181963801384\n",
      "Iteration: 1294/10000, Loss: 0.03342613950371742\n",
      "Iteration: 1295/10000, Loss: 0.04568467289209366\n",
      "Iteration: 1296/10000, Loss: 0.037025608122348785\n",
      "Iteration: 1297/10000, Loss: 0.03309987485408783\n",
      "Iteration: 1298/10000, Loss: 0.04735983908176422\n",
      "Iteration: 1299/10000, Loss: 0.050618935376405716\n",
      "Iteration: 1300/10000, Loss: 0.05611593276262283\n",
      "Average test loss:  0.0030\n",
      "Iteration: 1301/10000, Loss: 0.07668167352676392\n",
      "Iteration: 1302/10000, Loss: 0.046555887907743454\n",
      "Iteration: 1303/10000, Loss: 0.04103755205869675\n",
      "Iteration: 1304/10000, Loss: 0.05661313235759735\n",
      "Iteration: 1305/10000, Loss: 0.04688319191336632\n",
      "Iteration: 1306/10000, Loss: 0.041396789252758026\n",
      "Iteration: 1307/10000, Loss: 0.04902784898877144\n",
      "Iteration: 1308/10000, Loss: 0.0781126394867897\n",
      "Iteration: 1309/10000, Loss: 0.03921348974108696\n",
      "Iteration: 1310/10000, Loss: 0.04612337052822113\n",
      "Iteration: 1311/10000, Loss: 0.04282796382904053\n",
      "Iteration: 1312/10000, Loss: 0.06439746171236038\n",
      "Iteration: 1313/10000, Loss: 0.04733062908053398\n",
      "Iteration: 1314/10000, Loss: 0.04145459830760956\n",
      "Iteration: 1315/10000, Loss: 0.04467901587486267\n",
      "Iteration: 1316/10000, Loss: 0.04571891203522682\n",
      "Iteration: 1317/10000, Loss: 0.06897087395191193\n",
      "Iteration: 1318/10000, Loss: 0.054877057671546936\n",
      "Iteration: 1319/10000, Loss: 0.06470710784196854\n",
      "Iteration: 1320/10000, Loss: 0.047542769461870193\n",
      "Iteration: 1321/10000, Loss: 0.03320588544011116\n",
      "Iteration: 1322/10000, Loss: 0.038522109389305115\n",
      "Iteration: 1323/10000, Loss: 0.04885704815387726\n",
      "Iteration: 1324/10000, Loss: 0.03991369158029556\n",
      "Iteration: 1325/10000, Loss: 0.03481237590312958\n",
      "Iteration: 1326/10000, Loss: 0.042428549379110336\n",
      "Iteration: 1327/10000, Loss: 0.030980775132775307\n",
      "Iteration: 1328/10000, Loss: 0.05459395423531532\n",
      "Iteration: 1329/10000, Loss: 0.03088538348674774\n",
      "Iteration: 1330/10000, Loss: 0.043413642793893814\n",
      "Iteration: 1331/10000, Loss: 0.036092616617679596\n",
      "Iteration: 1332/10000, Loss: 0.05742108076810837\n",
      "Iteration: 1333/10000, Loss: 0.0495302751660347\n",
      "Iteration: 1334/10000, Loss: 0.044544801115989685\n",
      "Iteration: 1335/10000, Loss: 0.04218348115682602\n",
      "Iteration: 1336/10000, Loss: 0.04715627059340477\n",
      "Iteration: 1337/10000, Loss: 0.026088407263159752\n",
      "Iteration: 1338/10000, Loss: 0.0752425566315651\n",
      "Iteration: 1339/10000, Loss: 0.051808807998895645\n",
      "Iteration: 1340/10000, Loss: 0.04161149635910988\n",
      "Iteration: 1341/10000, Loss: 0.030736474320292473\n",
      "Iteration: 1342/10000, Loss: 0.04250308498740196\n",
      "Iteration: 1343/10000, Loss: 0.04801809787750244\n",
      "Iteration: 1344/10000, Loss: 0.032682664692401886\n",
      "Iteration: 1345/10000, Loss: 0.05017709359526634\n",
      "Iteration: 1346/10000, Loss: 0.05011337995529175\n",
      "Iteration: 1347/10000, Loss: 0.0407390370965004\n",
      "Iteration: 1348/10000, Loss: 0.041364073753356934\n",
      "Iteration: 1349/10000, Loss: 0.036967694759368896\n",
      "Iteration: 1350/10000, Loss: 0.056027960032224655\n",
      "Iteration: 1351/10000, Loss: 0.05010559409856796\n",
      "Iteration: 1352/10000, Loss: 0.036334723234176636\n",
      "Iteration: 1353/10000, Loss: 0.030315039679408073\n",
      "Iteration: 1354/10000, Loss: 0.034259140491485596\n",
      "Iteration: 1355/10000, Loss: 0.056840620934963226\n",
      "Iteration: 1356/10000, Loss: 0.043218400329351425\n",
      "Iteration: 1357/10000, Loss: 0.03675076365470886\n",
      "Iteration: 1358/10000, Loss: 0.04154638946056366\n",
      "Iteration: 1359/10000, Loss: 0.04009326174855232\n",
      "Iteration: 1360/10000, Loss: 0.04544703662395477\n",
      "Iteration: 1361/10000, Loss: 0.053656402975320816\n",
      "Iteration: 1362/10000, Loss: 0.0632580891251564\n",
      "Iteration: 1363/10000, Loss: 0.03616378828883171\n",
      "Iteration: 1364/10000, Loss: 0.04549182578921318\n",
      "Iteration: 1365/10000, Loss: 0.05411788821220398\n",
      "Iteration: 1366/10000, Loss: 0.041204556822776794\n",
      "Iteration: 1367/10000, Loss: 0.03440472483634949\n",
      "Iteration: 1368/10000, Loss: 0.04455271735787392\n",
      "Iteration: 1369/10000, Loss: 0.05140550434589386\n",
      "Iteration: 1370/10000, Loss: 0.0430440679192543\n",
      "Iteration: 1371/10000, Loss: 0.04590364545583725\n",
      "Iteration: 1372/10000, Loss: 0.04545194283127785\n",
      "Iteration: 1373/10000, Loss: 0.04925304651260376\n",
      "Iteration: 1374/10000, Loss: 0.03161885216832161\n",
      "Iteration: 1375/10000, Loss: 0.04283443093299866\n",
      "Iteration: 1376/10000, Loss: 0.05015181750059128\n",
      "Iteration: 1377/10000, Loss: 0.04557298868894577\n",
      "Iteration: 1378/10000, Loss: 0.03458716347813606\n",
      "Iteration: 1379/10000, Loss: 0.048775218427181244\n",
      "Iteration: 1380/10000, Loss: 0.04895852506160736\n",
      "Iteration: 1381/10000, Loss: 0.03849675506353378\n",
      "Iteration: 1382/10000, Loss: 0.041189610958099365\n",
      "Iteration: 1383/10000, Loss: 0.043377283960580826\n",
      "Iteration: 1384/10000, Loss: 0.038525067269802094\n",
      "Iteration: 1385/10000, Loss: 0.06481672078371048\n",
      "Iteration: 1386/10000, Loss: 0.039273034781217575\n",
      "Iteration: 1387/10000, Loss: 0.041848957538604736\n",
      "Iteration: 1388/10000, Loss: 0.03701755031943321\n",
      "Iteration: 1389/10000, Loss: 0.0374789796769619\n",
      "Iteration: 1390/10000, Loss: 0.04601437598466873\n",
      "Iteration: 1391/10000, Loss: 0.0331110879778862\n",
      "Iteration: 1392/10000, Loss: 0.05684364587068558\n",
      "Iteration: 1393/10000, Loss: 0.045441292226314545\n",
      "Iteration: 1394/10000, Loss: 0.051754459738731384\n",
      "Iteration: 1395/10000, Loss: 0.04964036867022514\n",
      "Iteration: 1396/10000, Loss: 0.03701759874820709\n",
      "Iteration: 1397/10000, Loss: 0.04576565697789192\n",
      "Iteration: 1398/10000, Loss: 0.034260500222444534\n",
      "Iteration: 1399/10000, Loss: 0.0452716238796711\n",
      "Iteration: 1400/10000, Loss: 0.02473362907767296\n",
      "Average test loss:  0.0027\n",
      "Iteration: 1401/10000, Loss: 0.038502514362335205\n",
      "Iteration: 1402/10000, Loss: 0.033975549042224884\n",
      "Iteration: 1403/10000, Loss: 0.0470699667930603\n",
      "Iteration: 1404/10000, Loss: 0.06283967941999435\n",
      "Iteration: 1405/10000, Loss: 0.047034598886966705\n",
      "Iteration: 1406/10000, Loss: 0.03873046860098839\n",
      "Iteration: 1407/10000, Loss: 0.03720816969871521\n",
      "Iteration: 1408/10000, Loss: 0.05476221442222595\n",
      "Iteration: 1409/10000, Loss: 0.047757863998413086\n",
      "Iteration: 1410/10000, Loss: 0.04724859446287155\n",
      "Iteration: 1411/10000, Loss: 0.035812463611364365\n",
      "Iteration: 1412/10000, Loss: 0.06481052935123444\n",
      "Iteration: 1413/10000, Loss: 0.05200160667300224\n",
      "Iteration: 1414/10000, Loss: 0.06831539422273636\n",
      "Iteration: 1415/10000, Loss: 0.030907144770026207\n",
      "Iteration: 1416/10000, Loss: 0.031306538730859756\n",
      "Iteration: 1417/10000, Loss: 0.03148071840405464\n",
      "Iteration: 1418/10000, Loss: 0.0353504978120327\n",
      "Iteration: 1419/10000, Loss: 0.044520165771245956\n",
      "Iteration: 1420/10000, Loss: 0.0337076298892498\n",
      "Iteration: 1421/10000, Loss: 0.054892901331186295\n",
      "Iteration: 1422/10000, Loss: 0.03870408236980438\n",
      "Iteration: 1423/10000, Loss: 0.028640175238251686\n",
      "Iteration: 1424/10000, Loss: 0.04260793328285217\n",
      "Iteration: 1425/10000, Loss: 0.04250514507293701\n",
      "Iteration: 1426/10000, Loss: 0.06561598181724548\n",
      "Iteration: 1427/10000, Loss: 0.03882293775677681\n",
      "Iteration: 1428/10000, Loss: 0.04062031954526901\n",
      "Iteration: 1429/10000, Loss: 0.042010094970464706\n",
      "Iteration: 1430/10000, Loss: 0.05515594780445099\n",
      "Iteration: 1431/10000, Loss: 0.04696297645568848\n",
      "Iteration: 1432/10000, Loss: 0.0340447723865509\n",
      "Iteration: 1433/10000, Loss: 0.05333254486322403\n",
      "Iteration: 1434/10000, Loss: 0.04223623499274254\n",
      "Iteration: 1435/10000, Loss: 0.05618023872375488\n",
      "Iteration: 1436/10000, Loss: 0.03653886541724205\n",
      "Iteration: 1437/10000, Loss: 0.058222364634275436\n",
      "Iteration: 1438/10000, Loss: 0.0527476966381073\n",
      "Iteration: 1439/10000, Loss: 0.04599727690219879\n",
      "Iteration: 1440/10000, Loss: 0.0685872882604599\n",
      "Iteration: 1441/10000, Loss: 0.04427246004343033\n",
      "Iteration: 1442/10000, Loss: 0.04268025606870651\n",
      "Iteration: 1443/10000, Loss: 0.039661720395088196\n",
      "Iteration: 1444/10000, Loss: 0.04688386246562004\n",
      "Iteration: 1445/10000, Loss: 0.04239211976528168\n",
      "Iteration: 1446/10000, Loss: 0.03245094418525696\n",
      "Iteration: 1447/10000, Loss: 0.041484933346509933\n",
      "Iteration: 1448/10000, Loss: 0.05492935702204704\n",
      "Iteration: 1449/10000, Loss: 0.04541414603590965\n",
      "Iteration: 1450/10000, Loss: 0.02972206100821495\n",
      "Iteration: 1451/10000, Loss: 0.04193345457315445\n",
      "Iteration: 1452/10000, Loss: 0.03165790066123009\n",
      "Iteration: 1453/10000, Loss: 0.05215518921613693\n",
      "Iteration: 1454/10000, Loss: 0.044863373041152954\n",
      "Iteration: 1455/10000, Loss: 0.0439029335975647\n",
      "Iteration: 1456/10000, Loss: 0.0485723540186882\n",
      "Iteration: 1457/10000, Loss: 0.040966808795928955\n",
      "Iteration: 1458/10000, Loss: 0.06011981889605522\n",
      "Iteration: 1459/10000, Loss: 0.035748761147260666\n",
      "Iteration: 1460/10000, Loss: 0.03306705132126808\n",
      "Iteration: 1461/10000, Loss: 0.04708932340145111\n",
      "Iteration: 1462/10000, Loss: 0.03414124250411987\n",
      "Iteration: 1463/10000, Loss: 0.03700641542673111\n",
      "Iteration: 1464/10000, Loss: 0.04721970111131668\n",
      "Iteration: 1465/10000, Loss: 0.05688926950097084\n",
      "Iteration: 1466/10000, Loss: 0.04002276435494423\n",
      "Iteration: 1467/10000, Loss: 0.03722121939063072\n",
      "Iteration: 1468/10000, Loss: 0.04496070370078087\n",
      "Iteration: 1469/10000, Loss: 0.037358567118644714\n",
      "Iteration: 1470/10000, Loss: 0.040345706045627594\n",
      "Iteration: 1471/10000, Loss: 0.031157197430729866\n",
      "Iteration: 1472/10000, Loss: 0.048656679689884186\n",
      "Iteration: 1473/10000, Loss: 0.04421364143490791\n",
      "Iteration: 1474/10000, Loss: 0.03516623377799988\n",
      "Iteration: 1475/10000, Loss: 0.039037588983774185\n",
      "Iteration: 1476/10000, Loss: 0.051023732870817184\n",
      "Iteration: 1477/10000, Loss: 0.04315071552991867\n",
      "Iteration: 1478/10000, Loss: 0.04878440499305725\n",
      "Iteration: 1479/10000, Loss: 0.060028187930583954\n",
      "Iteration: 1480/10000, Loss: 0.030438803136348724\n",
      "Iteration: 1481/10000, Loss: 0.037940215319395065\n",
      "Iteration: 1482/10000, Loss: 0.04649408534169197\n",
      "Iteration: 1483/10000, Loss: 0.03892165422439575\n",
      "Iteration: 1484/10000, Loss: 0.03815516084432602\n",
      "Iteration: 1485/10000, Loss: 0.03311198949813843\n",
      "Iteration: 1486/10000, Loss: 0.043731190264225006\n",
      "Iteration: 1487/10000, Loss: 0.039434369653463364\n",
      "Iteration: 1488/10000, Loss: 0.05385206267237663\n",
      "Iteration: 1489/10000, Loss: 0.027780530974268913\n",
      "Iteration: 1490/10000, Loss: 0.0367666594684124\n",
      "Iteration: 1491/10000, Loss: 0.04675940051674843\n",
      "Iteration: 1492/10000, Loss: 0.03226860612630844\n",
      "Iteration: 1493/10000, Loss: 0.04897221177816391\n",
      "Iteration: 1494/10000, Loss: 0.028429262340068817\n",
      "Iteration: 1495/10000, Loss: 0.046970609575510025\n",
      "Iteration: 1496/10000, Loss: 0.03647853806614876\n",
      "Iteration: 1497/10000, Loss: 0.033391330391168594\n",
      "Iteration: 1498/10000, Loss: 0.041500262916088104\n",
      "Iteration: 1499/10000, Loss: 0.04575520381331444\n",
      "Iteration: 1500/10000, Loss: 0.04655680060386658\n",
      "Average test loss:  0.0023\n",
      "Iteration: 1501/10000, Loss: 0.06671351939439774\n",
      "Iteration: 1502/10000, Loss: 0.04146655648946762\n",
      "Iteration: 1503/10000, Loss: 0.05123971775174141\n",
      "Iteration: 1504/10000, Loss: 0.03423023596405983\n",
      "Iteration: 1505/10000, Loss: 0.03924338147044182\n",
      "Iteration: 1506/10000, Loss: 0.024887647479772568\n",
      "Iteration: 1507/10000, Loss: 0.024108897894620895\n",
      "Iteration: 1508/10000, Loss: 0.03210893273353577\n",
      "Iteration: 1509/10000, Loss: 0.038959700614213943\n",
      "Iteration: 1510/10000, Loss: 0.042308732867240906\n",
      "Iteration: 1511/10000, Loss: 0.03727596253156662\n",
      "Iteration: 1512/10000, Loss: 0.02656610868871212\n",
      "Iteration: 1513/10000, Loss: 0.026014601811766624\n",
      "Iteration: 1514/10000, Loss: 0.026909347623586655\n",
      "Iteration: 1515/10000, Loss: 0.028559435158967972\n",
      "Iteration: 1516/10000, Loss: 0.05103134736418724\n",
      "Iteration: 1517/10000, Loss: 0.04541068896651268\n",
      "Iteration: 1518/10000, Loss: 0.036236949265003204\n",
      "Iteration: 1519/10000, Loss: 0.03721433877944946\n",
      "Iteration: 1520/10000, Loss: 0.05026859790086746\n",
      "Iteration: 1521/10000, Loss: 0.030441172420978546\n",
      "Iteration: 1522/10000, Loss: 0.02107647806406021\n",
      "Iteration: 1523/10000, Loss: 0.04877499118447304\n",
      "Iteration: 1524/10000, Loss: 0.02726154588162899\n",
      "Iteration: 1525/10000, Loss: 0.048470426350831985\n",
      "Iteration: 1526/10000, Loss: 0.07632125169038773\n",
      "Iteration: 1527/10000, Loss: 0.04204270616173744\n",
      "Iteration: 1528/10000, Loss: 0.050756871700286865\n",
      "Iteration: 1529/10000, Loss: 0.0456802174448967\n",
      "Iteration: 1530/10000, Loss: 0.03145746886730194\n",
      "Iteration: 1531/10000, Loss: 0.03804885596036911\n",
      "Iteration: 1532/10000, Loss: 0.04422207549214363\n",
      "Iteration: 1533/10000, Loss: 0.04781908169388771\n",
      "Iteration: 1534/10000, Loss: 0.049576207995414734\n",
      "Iteration: 1535/10000, Loss: 0.03549419343471527\n",
      "Iteration: 1536/10000, Loss: 0.05197113752365112\n",
      "Iteration: 1537/10000, Loss: 0.05109386146068573\n",
      "Iteration: 1538/10000, Loss: 0.02263881452381611\n",
      "Iteration: 1539/10000, Loss: 0.062199175357818604\n",
      "Iteration: 1540/10000, Loss: 0.042397741228342056\n",
      "Iteration: 1541/10000, Loss: 0.038108281791210175\n",
      "Iteration: 1542/10000, Loss: 0.05147213116288185\n",
      "Iteration: 1543/10000, Loss: 0.044765740633010864\n",
      "Iteration: 1544/10000, Loss: 0.029264511540532112\n",
      "Iteration: 1545/10000, Loss: 0.04302193969488144\n",
      "Iteration: 1546/10000, Loss: 0.029002057388424873\n",
      "Iteration: 1547/10000, Loss: 0.031649455428123474\n",
      "Iteration: 1548/10000, Loss: 0.04396362230181694\n",
      "Iteration: 1549/10000, Loss: 0.03286994993686676\n",
      "Iteration: 1550/10000, Loss: 0.03321322426199913\n",
      "Iteration: 1551/10000, Loss: 0.03750874847173691\n",
      "Iteration: 1552/10000, Loss: 0.06382980197668076\n",
      "Iteration: 1553/10000, Loss: 0.047033678740262985\n",
      "Iteration: 1554/10000, Loss: 0.06888283789157867\n",
      "Iteration: 1555/10000, Loss: 0.03137870505452156\n",
      "Iteration: 1556/10000, Loss: 0.025210043415427208\n",
      "Iteration: 1557/10000, Loss: 0.03599175810813904\n",
      "Iteration: 1558/10000, Loss: 0.030769526958465576\n",
      "Iteration: 1559/10000, Loss: 0.040052641183137894\n",
      "Iteration: 1560/10000, Loss: 0.03997492417693138\n",
      "Iteration: 1561/10000, Loss: 0.03978528082370758\n",
      "Iteration: 1562/10000, Loss: 0.03209565207362175\n",
      "Iteration: 1563/10000, Loss: 0.04181705787777901\n",
      "Iteration: 1564/10000, Loss: 0.03831857815384865\n",
      "Iteration: 1565/10000, Loss: 0.043378185480833054\n",
      "Iteration: 1566/10000, Loss: 0.04217546805739403\n",
      "Iteration: 1567/10000, Loss: 0.03761124238371849\n",
      "Iteration: 1568/10000, Loss: 0.05670347437262535\n",
      "Iteration: 1569/10000, Loss: 0.03842276334762573\n",
      "Iteration: 1570/10000, Loss: 0.031000623479485512\n",
      "Iteration: 1571/10000, Loss: 0.041879381984472275\n",
      "Iteration: 1572/10000, Loss: 0.03736191242933273\n",
      "Iteration: 1573/10000, Loss: 0.04220670834183693\n",
      "Iteration: 1574/10000, Loss: 0.03552181273698807\n",
      "Iteration: 1575/10000, Loss: 0.036096904426813126\n",
      "Iteration: 1576/10000, Loss: 0.036276932805776596\n",
      "Iteration: 1577/10000, Loss: 0.03298182785511017\n",
      "Iteration: 1578/10000, Loss: 0.04361208900809288\n",
      "Iteration: 1579/10000, Loss: 0.040840018540620804\n",
      "Iteration: 1580/10000, Loss: 0.06934322416782379\n",
      "Iteration: 1581/10000, Loss: 0.0352444164454937\n",
      "Iteration: 1582/10000, Loss: 0.038336608558893204\n",
      "Iteration: 1583/10000, Loss: 0.02429930865764618\n",
      "Iteration: 1584/10000, Loss: 0.043262138962745667\n",
      "Iteration: 1585/10000, Loss: 0.03972029313445091\n",
      "Iteration: 1586/10000, Loss: 0.04183519259095192\n",
      "Iteration: 1587/10000, Loss: 0.05163732171058655\n",
      "Iteration: 1588/10000, Loss: 0.01797202229499817\n",
      "Iteration: 1589/10000, Loss: 0.053511667996644974\n",
      "Iteration: 1590/10000, Loss: 0.055011022835969925\n",
      "Iteration: 1591/10000, Loss: 0.03326159343123436\n",
      "Iteration: 1592/10000, Loss: 0.04301886260509491\n",
      "Iteration: 1593/10000, Loss: 0.0507984533905983\n",
      "Iteration: 1594/10000, Loss: 0.03570609912276268\n",
      "Iteration: 1595/10000, Loss: 0.03828606754541397\n",
      "Iteration: 1596/10000, Loss: 0.04645159840583801\n",
      "Iteration: 1597/10000, Loss: 0.04032761976122856\n",
      "Iteration: 1598/10000, Loss: 0.034682076424360275\n",
      "Iteration: 1599/10000, Loss: 0.07849859446287155\n",
      "Iteration: 1600/10000, Loss: 0.050336163491010666\n",
      "Average test loss:  0.0029\n",
      "Iteration: 1601/10000, Loss: 0.03886746987700462\n",
      "Iteration: 1602/10000, Loss: 0.05058223754167557\n",
      "Iteration: 1603/10000, Loss: 0.03246373310685158\n",
      "Iteration: 1604/10000, Loss: 0.033555373549461365\n",
      "Iteration: 1605/10000, Loss: 0.04291306436061859\n",
      "Iteration: 1606/10000, Loss: 0.04229044169187546\n",
      "Iteration: 1607/10000, Loss: 0.047876544296741486\n",
      "Iteration: 1608/10000, Loss: 0.039354726672172546\n",
      "Iteration: 1609/10000, Loss: 0.03332464024424553\n",
      "Iteration: 1610/10000, Loss: 0.03967371582984924\n",
      "Iteration: 1611/10000, Loss: 0.042763955891132355\n",
      "Iteration: 1612/10000, Loss: 0.04776628687977791\n",
      "Iteration: 1613/10000, Loss: 0.07108806818723679\n",
      "Iteration: 1614/10000, Loss: 0.04206855595111847\n",
      "Iteration: 1615/10000, Loss: 0.04391287639737129\n",
      "Iteration: 1616/10000, Loss: 0.04203895479440689\n",
      "Iteration: 1617/10000, Loss: 0.04804636165499687\n",
      "Iteration: 1618/10000, Loss: 0.03858551010489464\n",
      "Iteration: 1619/10000, Loss: 0.05243813991546631\n",
      "Iteration: 1620/10000, Loss: 0.03713620826601982\n",
      "Iteration: 1621/10000, Loss: 0.033698324114084244\n",
      "Iteration: 1622/10000, Loss: 0.03859207034111023\n",
      "Iteration: 1623/10000, Loss: 0.03138332813978195\n",
      "Iteration: 1624/10000, Loss: 0.038584593683481216\n",
      "Iteration: 1625/10000, Loss: 0.029125992208719254\n",
      "Iteration: 1626/10000, Loss: 0.04151798412203789\n",
      "Iteration: 1627/10000, Loss: 0.0292582456022501\n",
      "Iteration: 1628/10000, Loss: 0.037535183131694794\n",
      "Iteration: 1629/10000, Loss: 0.0445772223174572\n",
      "Iteration: 1630/10000, Loss: 0.05861853435635567\n",
      "Iteration: 1631/10000, Loss: 0.03007514961063862\n",
      "Iteration: 1632/10000, Loss: 0.03386414796113968\n",
      "Iteration: 1633/10000, Loss: 0.03378695994615555\n",
      "Iteration: 1634/10000, Loss: 0.050384264439344406\n",
      "Iteration: 1635/10000, Loss: 0.04172128066420555\n",
      "Iteration: 1636/10000, Loss: 0.04152543842792511\n",
      "Iteration: 1637/10000, Loss: 0.03766385093331337\n",
      "Iteration: 1638/10000, Loss: 0.05940307676792145\n",
      "Iteration: 1639/10000, Loss: 0.03433123230934143\n",
      "Iteration: 1640/10000, Loss: 0.04506115987896919\n",
      "Iteration: 1641/10000, Loss: 0.037493523210287094\n",
      "Iteration: 1642/10000, Loss: 0.04308949410915375\n",
      "Iteration: 1643/10000, Loss: 0.04547147452831268\n",
      "Iteration: 1644/10000, Loss: 0.028157932683825493\n",
      "Iteration: 1645/10000, Loss: 0.04558431729674339\n",
      "Iteration: 1646/10000, Loss: 0.04081209376454353\n",
      "Iteration: 1647/10000, Loss: 0.041258081793785095\n",
      "Iteration: 1648/10000, Loss: 0.051682718098163605\n",
      "Iteration: 1649/10000, Loss: 0.036166273057460785\n",
      "Iteration: 1650/10000, Loss: 0.0398225300014019\n",
      "Iteration: 1651/10000, Loss: 0.0673263669013977\n",
      "Iteration: 1652/10000, Loss: 0.0340227447450161\n",
      "Iteration: 1653/10000, Loss: 0.02792520821094513\n",
      "Iteration: 1654/10000, Loss: 0.02704702503979206\n",
      "Iteration: 1655/10000, Loss: 0.03936874493956566\n",
      "Iteration: 1656/10000, Loss: 0.056548137217760086\n",
      "Iteration: 1657/10000, Loss: 0.04708501324057579\n",
      "Iteration: 1658/10000, Loss: 0.032449573278427124\n",
      "Iteration: 1659/10000, Loss: 0.02832844667136669\n",
      "Iteration: 1660/10000, Loss: 0.049281537532806396\n",
      "Iteration: 1661/10000, Loss: 0.03220045194029808\n",
      "Iteration: 1662/10000, Loss: 0.022059712558984756\n",
      "Iteration: 1663/10000, Loss: 0.03307969123125076\n",
      "Iteration: 1664/10000, Loss: 0.025239724665880203\n",
      "Iteration: 1665/10000, Loss: 0.03565153852105141\n",
      "Iteration: 1666/10000, Loss: 0.03747931867837906\n",
      "Iteration: 1667/10000, Loss: 0.032243818044662476\n",
      "Iteration: 1668/10000, Loss: 0.025595366954803467\n",
      "Iteration: 1669/10000, Loss: 0.03744001314043999\n",
      "Iteration: 1670/10000, Loss: 0.0347568579018116\n",
      "Iteration: 1671/10000, Loss: 0.03964386135339737\n",
      "Iteration: 1672/10000, Loss: 0.052141182124614716\n",
      "Iteration: 1673/10000, Loss: 0.03362791985273361\n",
      "Iteration: 1674/10000, Loss: 0.0330100916326046\n",
      "Iteration: 1675/10000, Loss: 0.038961052894592285\n",
      "Iteration: 1676/10000, Loss: 0.031179239973425865\n",
      "Iteration: 1677/10000, Loss: 0.03928913176059723\n",
      "Iteration: 1678/10000, Loss: 0.029002681374549866\n",
      "Iteration: 1679/10000, Loss: 0.03958573192358017\n",
      "Iteration: 1680/10000, Loss: 0.044929418712854385\n",
      "Iteration: 1681/10000, Loss: 0.028612546622753143\n",
      "Iteration: 1682/10000, Loss: 0.05274520814418793\n",
      "Iteration: 1683/10000, Loss: 0.03726658597588539\n",
      "Iteration: 1684/10000, Loss: 0.06326276063919067\n",
      "Iteration: 1685/10000, Loss: 0.04434698820114136\n",
      "Iteration: 1686/10000, Loss: 0.023868100717663765\n",
      "Iteration: 1687/10000, Loss: 0.04873201996088028\n",
      "Iteration: 1688/10000, Loss: 0.03893487900495529\n",
      "Iteration: 1689/10000, Loss: 0.032952915877103806\n",
      "Iteration: 1690/10000, Loss: 0.030140597373247147\n",
      "Iteration: 1691/10000, Loss: 0.03650350868701935\n",
      "Iteration: 1692/10000, Loss: 0.048736825585365295\n",
      "Iteration: 1693/10000, Loss: 0.03877909481525421\n",
      "Iteration: 1694/10000, Loss: 0.053587254136800766\n",
      "Iteration: 1695/10000, Loss: 0.049521252512931824\n",
      "Iteration: 1696/10000, Loss: 0.0391644686460495\n",
      "Iteration: 1697/10000, Loss: 0.04586068540811539\n",
      "Iteration: 1698/10000, Loss: 0.03416144847869873\n",
      "Iteration: 1699/10000, Loss: 0.0388161838054657\n",
      "Iteration: 1700/10000, Loss: 0.03731568530201912\n",
      "Average test loss:  0.0027\n",
      "Iteration: 1701/10000, Loss: 0.045318178832530975\n",
      "Iteration: 1702/10000, Loss: 0.03937666490674019\n",
      "Iteration: 1703/10000, Loss: 0.0319368839263916\n",
      "Iteration: 1704/10000, Loss: 0.02839267998933792\n",
      "Iteration: 1705/10000, Loss: 0.05536961182951927\n",
      "Iteration: 1706/10000, Loss: 0.029651714488863945\n",
      "Iteration: 1707/10000, Loss: 0.034211285412311554\n",
      "Iteration: 1708/10000, Loss: 0.05149201676249504\n",
      "Iteration: 1709/10000, Loss: 0.038169246166944504\n",
      "Iteration: 1710/10000, Loss: 0.03427588939666748\n",
      "Iteration: 1711/10000, Loss: 0.04325329512357712\n",
      "Iteration: 1712/10000, Loss: 0.02601129561662674\n",
      "Iteration: 1713/10000, Loss: 0.03031298518180847\n",
      "Iteration: 1714/10000, Loss: 0.03893650323152542\n",
      "Iteration: 1715/10000, Loss: 0.025971539318561554\n",
      "Iteration: 1716/10000, Loss: 0.042215704917907715\n",
      "Iteration: 1717/10000, Loss: 0.03431950509548187\n",
      "Iteration: 1718/10000, Loss: 0.03567053750157356\n",
      "Iteration: 1719/10000, Loss: 0.03851861134171486\n",
      "Iteration: 1720/10000, Loss: 0.05803203582763672\n",
      "Iteration: 1721/10000, Loss: 0.02793101593852043\n",
      "Iteration: 1722/10000, Loss: 0.03676866367459297\n",
      "Iteration: 1723/10000, Loss: 0.04278676211833954\n",
      "Iteration: 1724/10000, Loss: 0.043672893196344376\n",
      "Iteration: 1725/10000, Loss: 0.032099898904561996\n",
      "Iteration: 1726/10000, Loss: 0.03554324805736542\n",
      "Iteration: 1727/10000, Loss: 0.034354522824287415\n",
      "Iteration: 1728/10000, Loss: 0.0372457392513752\n",
      "Iteration: 1729/10000, Loss: 0.04511910676956177\n",
      "Iteration: 1730/10000, Loss: 0.042928170412778854\n",
      "Iteration: 1731/10000, Loss: 0.044127319008111954\n",
      "Iteration: 1732/10000, Loss: 0.02576756849884987\n",
      "Iteration: 1733/10000, Loss: 0.031562287360429764\n",
      "Iteration: 1734/10000, Loss: 0.03278109058737755\n",
      "Iteration: 1735/10000, Loss: 0.02936357632279396\n",
      "Iteration: 1736/10000, Loss: 0.044310763478279114\n",
      "Iteration: 1737/10000, Loss: 0.042559996247291565\n",
      "Iteration: 1738/10000, Loss: 0.0326775498688221\n",
      "Iteration: 1739/10000, Loss: 0.0525430329144001\n",
      "Iteration: 1740/10000, Loss: 0.03026735782623291\n",
      "Iteration: 1741/10000, Loss: 0.031352072954177856\n",
      "Iteration: 1742/10000, Loss: 0.02907564863562584\n",
      "Iteration: 1743/10000, Loss: 0.040710918605327606\n",
      "Iteration: 1744/10000, Loss: 0.045046500861644745\n",
      "Iteration: 1745/10000, Loss: 0.05825114622712135\n",
      "Iteration: 1746/10000, Loss: 0.024303004145622253\n",
      "Iteration: 1747/10000, Loss: 0.03409695625305176\n",
      "Iteration: 1748/10000, Loss: 0.037379514425992966\n",
      "Iteration: 1749/10000, Loss: 0.04223986715078354\n",
      "Iteration: 1750/10000, Loss: 0.022978784516453743\n",
      "Iteration: 1751/10000, Loss: 0.021061129868030548\n",
      "Iteration: 1752/10000, Loss: 0.028485216200351715\n",
      "Iteration: 1753/10000, Loss: 0.032354071736335754\n",
      "Iteration: 1754/10000, Loss: 0.03884168341755867\n",
      "Iteration: 1755/10000, Loss: 0.036381322890520096\n",
      "Iteration: 1756/10000, Loss: 0.024892931804060936\n",
      "Iteration: 1757/10000, Loss: 0.0333753377199173\n",
      "Iteration: 1758/10000, Loss: 0.031209109351038933\n",
      "Iteration: 1759/10000, Loss: 0.03121267817914486\n",
      "Iteration: 1760/10000, Loss: 0.04270486906170845\n",
      "Iteration: 1761/10000, Loss: 0.028955232352018356\n",
      "Iteration: 1762/10000, Loss: 0.034252673387527466\n",
      "Iteration: 1763/10000, Loss: 0.03079400025308132\n",
      "Iteration: 1764/10000, Loss: 0.034230731427669525\n",
      "Iteration: 1765/10000, Loss: 0.029584191739559174\n",
      "Iteration: 1766/10000, Loss: 0.03795701637864113\n",
      "Iteration: 1767/10000, Loss: 0.037264786660671234\n",
      "Iteration: 1768/10000, Loss: 0.04772583767771721\n",
      "Iteration: 1769/10000, Loss: 0.026278000324964523\n",
      "Iteration: 1770/10000, Loss: 0.02579965814948082\n",
      "Iteration: 1771/10000, Loss: 0.02491087093949318\n",
      "Iteration: 1772/10000, Loss: 0.019595136865973473\n",
      "Iteration: 1773/10000, Loss: 0.03566558659076691\n",
      "Iteration: 1774/10000, Loss: 0.026808585971593857\n",
      "Iteration: 1775/10000, Loss: 0.02792663499712944\n",
      "Iteration: 1776/10000, Loss: 0.02857593074440956\n",
      "Iteration: 1777/10000, Loss: 0.030520504340529442\n",
      "Iteration: 1778/10000, Loss: 0.05060992017388344\n",
      "Iteration: 1779/10000, Loss: 0.028501510620117188\n",
      "Iteration: 1780/10000, Loss: 0.030885018408298492\n",
      "Iteration: 1781/10000, Loss: 0.030944406986236572\n",
      "Iteration: 1782/10000, Loss: 0.03307593986392021\n",
      "Iteration: 1783/10000, Loss: 0.03432106599211693\n",
      "Iteration: 1784/10000, Loss: 0.030266698449850082\n",
      "Iteration: 1785/10000, Loss: 0.03085225448012352\n",
      "Iteration: 1786/10000, Loss: 0.027849677950143814\n",
      "Iteration: 1787/10000, Loss: 0.03885272145271301\n",
      "Iteration: 1788/10000, Loss: 0.035301707684993744\n",
      "Iteration: 1789/10000, Loss: 0.03230646625161171\n",
      "Iteration: 1790/10000, Loss: 0.023579353466629982\n",
      "Iteration: 1791/10000, Loss: 0.04102092608809471\n",
      "Iteration: 1792/10000, Loss: 0.0536118745803833\n",
      "Iteration: 1793/10000, Loss: 0.039278652518987656\n",
      "Iteration: 1794/10000, Loss: 0.046662963926792145\n",
      "Iteration: 1795/10000, Loss: 0.032979682087898254\n",
      "Iteration: 1796/10000, Loss: 0.0374089851975441\n",
      "Iteration: 1797/10000, Loss: 0.0489225871860981\n",
      "Iteration: 1798/10000, Loss: 0.04196150600910187\n",
      "Iteration: 1799/10000, Loss: 0.03341753035783768\n",
      "Iteration: 1800/10000, Loss: 0.033944498747587204\n",
      "Average test loss:  0.0024\n",
      "Iteration: 1801/10000, Loss: 0.031983986496925354\n",
      "Iteration: 1802/10000, Loss: 0.04253654181957245\n",
      "Iteration: 1803/10000, Loss: 0.02846558950841427\n",
      "Iteration: 1804/10000, Loss: 0.020834101364016533\n",
      "Iteration: 1805/10000, Loss: 0.034572355449199677\n",
      "Iteration: 1806/10000, Loss: 0.044962551444768906\n",
      "Iteration: 1807/10000, Loss: 0.02390618994832039\n",
      "Iteration: 1808/10000, Loss: 0.03839070349931717\n",
      "Iteration: 1809/10000, Loss: 0.026906507089734077\n",
      "Iteration: 1810/10000, Loss: 0.03502459451556206\n",
      "Iteration: 1811/10000, Loss: 0.03714671730995178\n",
      "Iteration: 1812/10000, Loss: 0.029246732592582703\n",
      "Iteration: 1813/10000, Loss: 0.0313679501414299\n",
      "Iteration: 1814/10000, Loss: 0.048930197954177856\n",
      "Iteration: 1815/10000, Loss: 0.047900453209877014\n",
      "Iteration: 1816/10000, Loss: 0.03563384339213371\n",
      "Iteration: 1817/10000, Loss: 0.040407031774520874\n",
      "Iteration: 1818/10000, Loss: 0.0370490588247776\n",
      "Iteration: 1819/10000, Loss: 0.036269377917051315\n",
      "Iteration: 1820/10000, Loss: 0.03242121636867523\n",
      "Iteration: 1821/10000, Loss: 0.041508130729198456\n",
      "Iteration: 1822/10000, Loss: 0.030191708356142044\n",
      "Iteration: 1823/10000, Loss: 0.03326510265469551\n",
      "Iteration: 1824/10000, Loss: 0.04783397540450096\n",
      "Iteration: 1825/10000, Loss: 0.030115177854895592\n",
      "Iteration: 1826/10000, Loss: 0.03645598515868187\n",
      "Iteration: 1827/10000, Loss: 0.029476728290319443\n",
      "Iteration: 1828/10000, Loss: 0.03083275631070137\n",
      "Iteration: 1829/10000, Loss: 0.05467968061566353\n",
      "Iteration: 1830/10000, Loss: 0.03624828904867172\n",
      "Iteration: 1831/10000, Loss: 0.0504448264837265\n",
      "Iteration: 1832/10000, Loss: 0.031752683222293854\n",
      "Iteration: 1833/10000, Loss: 0.04648568481206894\n",
      "Iteration: 1834/10000, Loss: 0.039893463253974915\n",
      "Iteration: 1835/10000, Loss: 0.028449753299355507\n",
      "Iteration: 1836/10000, Loss: 0.030609130859375\n",
      "Iteration: 1837/10000, Loss: 0.031775373965501785\n",
      "Iteration: 1838/10000, Loss: 0.026680640876293182\n",
      "Iteration: 1839/10000, Loss: 0.03772381693124771\n",
      "Iteration: 1840/10000, Loss: 0.05199536308646202\n",
      "Iteration: 1841/10000, Loss: 0.04134240746498108\n",
      "Iteration: 1842/10000, Loss: 0.028496762737631798\n",
      "Iteration: 1843/10000, Loss: 0.042408522218465805\n",
      "Iteration: 1844/10000, Loss: 0.02752409316599369\n",
      "Iteration: 1845/10000, Loss: 0.040487632155418396\n",
      "Iteration: 1846/10000, Loss: 0.02794509008526802\n",
      "Iteration: 1847/10000, Loss: 0.038598429411649704\n",
      "Iteration: 1848/10000, Loss: 0.0326058566570282\n",
      "Iteration: 1849/10000, Loss: 0.05225270614027977\n",
      "Iteration: 1850/10000, Loss: 0.028898373246192932\n",
      "Iteration: 1851/10000, Loss: 0.03680422157049179\n",
      "Iteration: 1852/10000, Loss: 0.025781985372304916\n",
      "Iteration: 1853/10000, Loss: 0.03930605575442314\n",
      "Iteration: 1854/10000, Loss: 0.04197344928979874\n",
      "Iteration: 1855/10000, Loss: 0.05260084941983223\n",
      "Iteration: 1856/10000, Loss: 0.03541819006204605\n",
      "Iteration: 1857/10000, Loss: 0.032053034752607346\n",
      "Iteration: 1858/10000, Loss: 0.051845401525497437\n",
      "Iteration: 1859/10000, Loss: 0.056562043726444244\n",
      "Iteration: 1860/10000, Loss: 0.032121192663908005\n",
      "Iteration: 1861/10000, Loss: 0.039069175720214844\n",
      "Iteration: 1862/10000, Loss: 0.03172266483306885\n",
      "Iteration: 1863/10000, Loss: 0.053049057722091675\n",
      "Iteration: 1864/10000, Loss: 0.0493832565844059\n",
      "Iteration: 1865/10000, Loss: 0.034231968224048615\n",
      "Iteration: 1866/10000, Loss: 0.04241953790187836\n",
      "Iteration: 1867/10000, Loss: 0.03342704102396965\n",
      "Iteration: 1868/10000, Loss: 0.03141960874199867\n",
      "Iteration: 1869/10000, Loss: 0.03731508553028107\n",
      "Iteration: 1870/10000, Loss: 0.026439126580953598\n",
      "Iteration: 1871/10000, Loss: 0.03733086958527565\n",
      "Iteration: 1872/10000, Loss: 0.03795849159359932\n",
      "Iteration: 1873/10000, Loss: 0.02252897433936596\n",
      "Iteration: 1874/10000, Loss: 0.031629811972379684\n",
      "Iteration: 1875/10000, Loss: 0.03640037029981613\n",
      "Iteration: 1876/10000, Loss: 0.04280102252960205\n",
      "Iteration: 1877/10000, Loss: 0.03434110805392265\n",
      "Iteration: 1878/10000, Loss: 0.022644903510808945\n",
      "Iteration: 1879/10000, Loss: 0.023457318544387817\n",
      "Iteration: 1880/10000, Loss: 0.02870473638176918\n",
      "Iteration: 1881/10000, Loss: 0.027005674317479134\n",
      "Iteration: 1882/10000, Loss: 0.032964035868644714\n",
      "Iteration: 1883/10000, Loss: 0.04019118472933769\n",
      "Iteration: 1884/10000, Loss: 0.028741156682372093\n",
      "Iteration: 1885/10000, Loss: 0.04193252697587013\n",
      "Iteration: 1886/10000, Loss: 0.0346924252808094\n",
      "Iteration: 1887/10000, Loss: 0.024284712970256805\n",
      "Iteration: 1888/10000, Loss: 0.02641683630645275\n",
      "Iteration: 1889/10000, Loss: 0.04796493425965309\n",
      "Iteration: 1890/10000, Loss: 0.036466315388679504\n",
      "Iteration: 1891/10000, Loss: 0.0485980398952961\n",
      "Iteration: 1892/10000, Loss: 0.028689218685030937\n",
      "Iteration: 1893/10000, Loss: 0.025097696110606194\n",
      "Iteration: 1894/10000, Loss: 0.0373925119638443\n",
      "Iteration: 1895/10000, Loss: 0.03098319284617901\n",
      "Iteration: 1896/10000, Loss: 0.03800651431083679\n",
      "Iteration: 1897/10000, Loss: 0.029152968898415565\n",
      "Iteration: 1898/10000, Loss: 0.025439290329813957\n",
      "Iteration: 1899/10000, Loss: 0.037420034408569336\n",
      "Iteration: 1900/10000, Loss: 0.02840833179652691\n",
      "Average test loss:  0.0033\n",
      "Iteration: 1901/10000, Loss: 0.04111228510737419\n",
      "Iteration: 1902/10000, Loss: 0.05040404573082924\n",
      "Iteration: 1903/10000, Loss: 0.04398118332028389\n",
      "Iteration: 1904/10000, Loss: 0.038470324128866196\n",
      "Iteration: 1905/10000, Loss: 0.039615776389837265\n",
      "Iteration: 1906/10000, Loss: 0.0315314456820488\n",
      "Iteration: 1907/10000, Loss: 0.03197633847594261\n",
      "Iteration: 1908/10000, Loss: 0.03723461925983429\n",
      "Iteration: 1909/10000, Loss: 0.029818013310432434\n",
      "Iteration: 1910/10000, Loss: 0.026598747819662094\n",
      "Iteration: 1911/10000, Loss: 0.03082866035401821\n",
      "Iteration: 1912/10000, Loss: 0.05222884565591812\n",
      "Iteration: 1913/10000, Loss: 0.03719658404588699\n",
      "Iteration: 1914/10000, Loss: 0.028622660785913467\n",
      "Iteration: 1915/10000, Loss: 0.03470679372549057\n",
      "Iteration: 1916/10000, Loss: 0.03006112203001976\n",
      "Iteration: 1917/10000, Loss: 0.03551637753844261\n",
      "Iteration: 1918/10000, Loss: 0.03632599860429764\n",
      "Iteration: 1919/10000, Loss: 0.028760772198438644\n",
      "Iteration: 1920/10000, Loss: 0.0392809733748436\n",
      "Iteration: 1921/10000, Loss: 0.030988290905952454\n",
      "Iteration: 1922/10000, Loss: 0.03723464906215668\n",
      "Iteration: 1923/10000, Loss: 0.04368915036320686\n",
      "Iteration: 1924/10000, Loss: 0.03711341693997383\n",
      "Iteration: 1925/10000, Loss: 0.04314853623509407\n",
      "Iteration: 1926/10000, Loss: 0.024679090827703476\n",
      "Iteration: 1927/10000, Loss: 0.057294100522994995\n",
      "Iteration: 1928/10000, Loss: 0.027883097529411316\n",
      "Iteration: 1929/10000, Loss: 0.02789834700524807\n",
      "Iteration: 1930/10000, Loss: 0.03221139311790466\n",
      "Iteration: 1931/10000, Loss: 0.03757806867361069\n",
      "Iteration: 1932/10000, Loss: 0.03297615423798561\n",
      "Iteration: 1933/10000, Loss: 0.024077728390693665\n",
      "Iteration: 1934/10000, Loss: 0.02399548701941967\n",
      "Iteration: 1935/10000, Loss: 0.03308391198515892\n",
      "Iteration: 1936/10000, Loss: 0.03191232308745384\n",
      "Iteration: 1937/10000, Loss: 0.05398881435394287\n",
      "Iteration: 1938/10000, Loss: 0.03428623452782631\n",
      "Iteration: 1939/10000, Loss: 0.02915949933230877\n",
      "Iteration: 1940/10000, Loss: 0.03736216574907303\n",
      "Iteration: 1941/10000, Loss: 0.03776351362466812\n",
      "Iteration: 1942/10000, Loss: 0.04173872992396355\n",
      "Iteration: 1943/10000, Loss: 0.031629614531993866\n",
      "Iteration: 1944/10000, Loss: 0.02507721818983555\n",
      "Iteration: 1945/10000, Loss: 0.031001150608062744\n",
      "Iteration: 1946/10000, Loss: 0.03819214552640915\n",
      "Iteration: 1947/10000, Loss: 0.03387700766324997\n",
      "Iteration: 1948/10000, Loss: 0.04488087445497513\n",
      "Iteration: 1949/10000, Loss: 0.04880174994468689\n",
      "Iteration: 1950/10000, Loss: 0.03455992788076401\n",
      "Iteration: 1951/10000, Loss: 0.0312642976641655\n",
      "Iteration: 1952/10000, Loss: 0.027461465448141098\n",
      "Iteration: 1953/10000, Loss: 0.029030857607722282\n",
      "Iteration: 1954/10000, Loss: 0.031436216086149216\n",
      "Iteration: 1955/10000, Loss: 0.029807595536112785\n",
      "Iteration: 1956/10000, Loss: 0.036151207983493805\n",
      "Iteration: 1957/10000, Loss: 0.036646004766225815\n",
      "Iteration: 1958/10000, Loss: 0.04360829293727875\n",
      "Iteration: 1959/10000, Loss: 0.06710944324731827\n",
      "Iteration: 1960/10000, Loss: 0.043741192668676376\n",
      "Iteration: 1961/10000, Loss: 0.03236525505781174\n",
      "Iteration: 1962/10000, Loss: 0.030867040157318115\n",
      "Iteration: 1963/10000, Loss: 0.04672423377633095\n",
      "Iteration: 1964/10000, Loss: 0.040562380105257034\n",
      "Iteration: 1965/10000, Loss: 0.031295061111450195\n",
      "Iteration: 1966/10000, Loss: 0.035203494131565094\n",
      "Iteration: 1967/10000, Loss: 0.027357397601008415\n",
      "Iteration: 1968/10000, Loss: 0.03503391146659851\n",
      "Iteration: 1969/10000, Loss: 0.02840101532638073\n",
      "Iteration: 1970/10000, Loss: 0.029443109408020973\n",
      "Iteration: 1971/10000, Loss: 0.03217363730072975\n",
      "Iteration: 1972/10000, Loss: 0.020143045112490654\n",
      "Iteration: 1973/10000, Loss: 0.0451338067650795\n",
      "Iteration: 1974/10000, Loss: 0.03442317992448807\n",
      "Iteration: 1975/10000, Loss: 0.05745469406247139\n",
      "Iteration: 1976/10000, Loss: 0.0376519151031971\n",
      "Iteration: 1977/10000, Loss: 0.03446921333670616\n",
      "Iteration: 1978/10000, Loss: 0.03876519948244095\n",
      "Iteration: 1979/10000, Loss: 0.03705273196101189\n",
      "Iteration: 1980/10000, Loss: 0.04351579025387764\n",
      "Iteration: 1981/10000, Loss: 0.03304828330874443\n",
      "Iteration: 1982/10000, Loss: 0.0498618558049202\n",
      "Iteration: 1983/10000, Loss: 0.03918568417429924\n",
      "Iteration: 1984/10000, Loss: 0.04545576870441437\n",
      "Iteration: 1985/10000, Loss: 0.03929829224944115\n",
      "Iteration: 1986/10000, Loss: 0.032597146928310394\n",
      "Iteration: 1987/10000, Loss: 0.02651997096836567\n",
      "Iteration: 1988/10000, Loss: 0.027014629915356636\n",
      "Iteration: 1989/10000, Loss: 0.04838528856635094\n",
      "Iteration: 1990/10000, Loss: 0.04466446861624718\n",
      "Iteration: 1991/10000, Loss: 0.034509897232055664\n",
      "Iteration: 1992/10000, Loss: 0.028215479105710983\n",
      "Iteration: 1993/10000, Loss: 0.026553943753242493\n",
      "Iteration: 1994/10000, Loss: 0.03313622623682022\n",
      "Iteration: 1995/10000, Loss: 0.033959608525037766\n",
      "Iteration: 1996/10000, Loss: 0.025368891656398773\n",
      "Iteration: 1997/10000, Loss: 0.027578236535191536\n",
      "Iteration: 1998/10000, Loss: 0.032410670071840286\n",
      "Iteration: 1999/10000, Loss: 0.03961801156401634\n",
      "Iteration: 2000/10000, Loss: 0.039220042526721954\n",
      "Average test loss:  0.0025\n",
      "Iteration: 2001/10000, Loss: 0.0370769165456295\n",
      "Iteration: 2002/10000, Loss: 0.031788554042577744\n",
      "Iteration: 2003/10000, Loss: 0.03587472811341286\n",
      "Iteration: 2004/10000, Loss: 0.04040652513504028\n",
      "Iteration: 2005/10000, Loss: 0.03465710207819939\n",
      "Iteration: 2006/10000, Loss: 0.02443424053490162\n",
      "Iteration: 2007/10000, Loss: 0.04404781758785248\n",
      "Iteration: 2008/10000, Loss: 0.037040986120700836\n",
      "Iteration: 2009/10000, Loss: 0.025862354785203934\n",
      "Iteration: 2010/10000, Loss: 0.03761858493089676\n",
      "Iteration: 2011/10000, Loss: 0.03338200971484184\n",
      "Iteration: 2012/10000, Loss: 0.030970333144068718\n",
      "Iteration: 2013/10000, Loss: 0.03199243173003197\n",
      "Iteration: 2014/10000, Loss: 0.04365004599094391\n",
      "Iteration: 2015/10000, Loss: 0.03210470825433731\n",
      "Iteration: 2016/10000, Loss: 0.03207400068640709\n",
      "Iteration: 2017/10000, Loss: 0.027135996147990227\n",
      "Iteration: 2018/10000, Loss: 0.046400368213653564\n",
      "Iteration: 2019/10000, Loss: 0.031276606023311615\n",
      "Iteration: 2020/10000, Loss: 0.03611648082733154\n",
      "Iteration: 2021/10000, Loss: 0.03485732525587082\n",
      "Iteration: 2022/10000, Loss: 0.04448829963803291\n",
      "Iteration: 2023/10000, Loss: 0.030950136482715607\n",
      "Iteration: 2024/10000, Loss: 0.04886007681488991\n",
      "Iteration: 2025/10000, Loss: 0.02404669299721718\n",
      "Iteration: 2026/10000, Loss: 0.02911052666604519\n",
      "Iteration: 2027/10000, Loss: 0.043421655893325806\n",
      "Iteration: 2028/10000, Loss: 0.039229389280080795\n",
      "Iteration: 2029/10000, Loss: 0.029478352516889572\n",
      "Iteration: 2030/10000, Loss: 0.03129349648952484\n",
      "Iteration: 2031/10000, Loss: 0.03040780872106552\n",
      "Iteration: 2032/10000, Loss: 0.031247327104210854\n",
      "Iteration: 2033/10000, Loss: 0.027252551168203354\n",
      "Iteration: 2034/10000, Loss: 0.03213046118617058\n",
      "Iteration: 2035/10000, Loss: 0.03720012307167053\n",
      "Iteration: 2036/10000, Loss: 0.037191711366176605\n",
      "Iteration: 2037/10000, Loss: 0.036781225353479385\n",
      "Iteration: 2038/10000, Loss: 0.020744411274790764\n",
      "Iteration: 2039/10000, Loss: 0.03424880653619766\n",
      "Iteration: 2040/10000, Loss: 0.028544623404741287\n",
      "Iteration: 2041/10000, Loss: 0.05290954187512398\n",
      "Iteration: 2042/10000, Loss: 0.026155520230531693\n",
      "Iteration: 2043/10000, Loss: 0.03188430517911911\n",
      "Iteration: 2044/10000, Loss: 0.030101943761110306\n",
      "Iteration: 2045/10000, Loss: 0.027878649532794952\n",
      "Iteration: 2046/10000, Loss: 0.027742590755224228\n",
      "Iteration: 2047/10000, Loss: 0.026950210332870483\n",
      "Iteration: 2048/10000, Loss: 0.02906101383268833\n",
      "Iteration: 2049/10000, Loss: 0.043073397129774094\n",
      "Iteration: 2050/10000, Loss: 0.03822784125804901\n",
      "Iteration: 2051/10000, Loss: 0.03539257496595383\n",
      "Iteration: 2052/10000, Loss: 0.03141575679183006\n",
      "Iteration: 2053/10000, Loss: 0.035043999552726746\n",
      "Iteration: 2054/10000, Loss: 0.029091009870171547\n",
      "Iteration: 2055/10000, Loss: 0.029563745483756065\n",
      "Iteration: 2056/10000, Loss: 0.03537970408797264\n",
      "Iteration: 2057/10000, Loss: 0.031205853447318077\n",
      "Iteration: 2058/10000, Loss: 0.027559202164411545\n",
      "Iteration: 2059/10000, Loss: 0.02744901180267334\n",
      "Iteration: 2060/10000, Loss: 0.0314505361020565\n",
      "Iteration: 2061/10000, Loss: 0.03123338520526886\n",
      "Iteration: 2062/10000, Loss: 0.02311178483068943\n",
      "Iteration: 2063/10000, Loss: 0.02489851787686348\n",
      "Iteration: 2064/10000, Loss: 0.035151734948158264\n",
      "Iteration: 2065/10000, Loss: 0.03902288153767586\n",
      "Iteration: 2066/10000, Loss: 0.018970606848597527\n",
      "Iteration: 2067/10000, Loss: 0.02437780238687992\n",
      "Iteration: 2068/10000, Loss: 0.029310770332813263\n",
      "Iteration: 2069/10000, Loss: 0.032963406294584274\n",
      "Iteration: 2070/10000, Loss: 0.03624989837408066\n",
      "Iteration: 2071/10000, Loss: 0.03022056072950363\n",
      "Iteration: 2072/10000, Loss: 0.031020071357488632\n",
      "Iteration: 2073/10000, Loss: 0.030343838036060333\n",
      "Iteration: 2074/10000, Loss: 0.03451233729720116\n",
      "Iteration: 2075/10000, Loss: 0.026391925290226936\n",
      "Iteration: 2076/10000, Loss: 0.041358355432748795\n",
      "Iteration: 2077/10000, Loss: 0.02473890781402588\n",
      "Iteration: 2078/10000, Loss: 0.028538769111037254\n",
      "Iteration: 2079/10000, Loss: 0.0471227765083313\n",
      "Iteration: 2080/10000, Loss: 0.035459499806165695\n",
      "Iteration: 2081/10000, Loss: 0.029999317601323128\n",
      "Iteration: 2082/10000, Loss: 0.023947544395923615\n",
      "Iteration: 2083/10000, Loss: 0.036717940121889114\n",
      "Iteration: 2084/10000, Loss: 0.03609616681933403\n",
      "Iteration: 2085/10000, Loss: 0.028732364997267723\n",
      "Iteration: 2086/10000, Loss: 0.030070753768086433\n",
      "Iteration: 2087/10000, Loss: 0.029239388182759285\n",
      "Iteration: 2088/10000, Loss: 0.03335953876376152\n",
      "Iteration: 2089/10000, Loss: 0.040050044655799866\n",
      "Iteration: 2090/10000, Loss: 0.030192650854587555\n",
      "Iteration: 2091/10000, Loss: 0.024301117286086082\n",
      "Iteration: 2092/10000, Loss: 0.031016813591122627\n",
      "Iteration: 2093/10000, Loss: 0.028925731778144836\n",
      "Iteration: 2094/10000, Loss: 0.03376346081495285\n",
      "Iteration: 2095/10000, Loss: 0.028016718104481697\n",
      "Iteration: 2096/10000, Loss: 0.02902689203619957\n",
      "Iteration: 2097/10000, Loss: 0.027499064803123474\n",
      "Iteration: 2098/10000, Loss: 0.03326600044965744\n",
      "Iteration: 2099/10000, Loss: 0.022064605727791786\n",
      "Iteration: 2100/10000, Loss: 0.03344331681728363\n",
      "Average test loss:  0.0032\n",
      "Iteration: 2101/10000, Loss: 0.025711428374052048\n",
      "Iteration: 2102/10000, Loss: 0.0402504988014698\n",
      "Iteration: 2103/10000, Loss: 0.025221649557352066\n",
      "Iteration: 2104/10000, Loss: 0.02649279497563839\n",
      "Iteration: 2105/10000, Loss: 0.01979292742908001\n",
      "Iteration: 2106/10000, Loss: 0.04313645511865616\n",
      "Iteration: 2107/10000, Loss: 0.02102101780474186\n",
      "Iteration: 2108/10000, Loss: 0.026797546073794365\n",
      "Iteration: 2109/10000, Loss: 0.0364302322268486\n",
      "Iteration: 2110/10000, Loss: 0.025429554283618927\n",
      "Iteration: 2111/10000, Loss: 0.03249073401093483\n",
      "Iteration: 2112/10000, Loss: 0.02450818195939064\n",
      "Iteration: 2113/10000, Loss: 0.034202076494693756\n",
      "Iteration: 2114/10000, Loss: 0.02614274062216282\n",
      "Iteration: 2115/10000, Loss: 0.03251409903168678\n",
      "Iteration: 2116/10000, Loss: 0.026166176423430443\n",
      "Iteration: 2117/10000, Loss: 0.02630113624036312\n",
      "Iteration: 2118/10000, Loss: 0.035462021827697754\n",
      "Iteration: 2119/10000, Loss: 0.0304536372423172\n",
      "Iteration: 2120/10000, Loss: 0.02532302401959896\n",
      "Iteration: 2121/10000, Loss: 0.02658741921186447\n",
      "Iteration: 2122/10000, Loss: 0.020393099635839462\n",
      "Iteration: 2123/10000, Loss: 0.031619638204574585\n",
      "Iteration: 2124/10000, Loss: 0.025609461590647697\n",
      "Iteration: 2125/10000, Loss: 0.039216142147779465\n",
      "Iteration: 2126/10000, Loss: 0.02599944733083248\n",
      "Iteration: 2127/10000, Loss: 0.028699180111289024\n",
      "Iteration: 2128/10000, Loss: 0.021173426881432533\n",
      "Iteration: 2129/10000, Loss: 0.025467514991760254\n",
      "Iteration: 2130/10000, Loss: 0.02307412587106228\n",
      "Iteration: 2131/10000, Loss: 0.023502813652157784\n",
      "Iteration: 2132/10000, Loss: 0.030223384499549866\n",
      "Iteration: 2133/10000, Loss: 0.0359576940536499\n",
      "Iteration: 2134/10000, Loss: 0.025485258549451828\n",
      "Iteration: 2135/10000, Loss: 0.02438853122293949\n",
      "Iteration: 2136/10000, Loss: 0.02397848851978779\n",
      "Iteration: 2137/10000, Loss: 0.02182679995894432\n",
      "Iteration: 2138/10000, Loss: 0.035665638744831085\n",
      "Iteration: 2139/10000, Loss: 0.028847042471170425\n",
      "Iteration: 2140/10000, Loss: 0.025007214397192\n",
      "Iteration: 2141/10000, Loss: 0.02575111947953701\n",
      "Iteration: 2142/10000, Loss: 0.032450757920742035\n",
      "Iteration: 2143/10000, Loss: 0.03772243484854698\n",
      "Iteration: 2144/10000, Loss: 0.02013278193771839\n",
      "Iteration: 2145/10000, Loss: 0.022350363433361053\n",
      "Iteration: 2146/10000, Loss: 0.02950984798371792\n",
      "Iteration: 2147/10000, Loss: 0.02840706892311573\n",
      "Iteration: 2148/10000, Loss: 0.02661832980811596\n",
      "Iteration: 2149/10000, Loss: 0.04052944853901863\n",
      "Iteration: 2150/10000, Loss: 0.030995624139904976\n",
      "Iteration: 2151/10000, Loss: 0.03670279681682587\n",
      "Iteration: 2152/10000, Loss: 0.01849880814552307\n",
      "Iteration: 2153/10000, Loss: 0.025564143434166908\n",
      "Iteration: 2154/10000, Loss: 0.033355921506881714\n",
      "Iteration: 2155/10000, Loss: 0.035344310104846954\n",
      "Iteration: 2156/10000, Loss: 0.030725015327334404\n",
      "Iteration: 2157/10000, Loss: 0.022886810824275017\n",
      "Iteration: 2158/10000, Loss: 0.024143122136592865\n",
      "Iteration: 2159/10000, Loss: 0.03728887811303139\n",
      "Iteration: 2160/10000, Loss: 0.023616502061486244\n",
      "Iteration: 2161/10000, Loss: 0.023923693224787712\n",
      "Iteration: 2162/10000, Loss: 0.034595128148794174\n",
      "Iteration: 2163/10000, Loss: 0.035039935261011124\n",
      "Iteration: 2164/10000, Loss: 0.018439503386616707\n",
      "Iteration: 2165/10000, Loss: 0.030043888837099075\n",
      "Iteration: 2166/10000, Loss: 0.024680722504854202\n",
      "Iteration: 2167/10000, Loss: 0.03361978009343147\n",
      "Iteration: 2168/10000, Loss: 0.044179197400808334\n",
      "Iteration: 2169/10000, Loss: 0.02360892854630947\n",
      "Iteration: 2170/10000, Loss: 0.03138251230120659\n",
      "Iteration: 2171/10000, Loss: 0.028068123385310173\n",
      "Iteration: 2172/10000, Loss: 0.0416225828230381\n",
      "Iteration: 2173/10000, Loss: 0.025015350431203842\n",
      "Iteration: 2174/10000, Loss: 0.0382227823138237\n",
      "Iteration: 2175/10000, Loss: 0.038447096943855286\n",
      "Iteration: 2176/10000, Loss: 0.03707706928253174\n",
      "Iteration: 2177/10000, Loss: 0.03811408579349518\n",
      "Iteration: 2178/10000, Loss: 0.02829493023455143\n",
      "Iteration: 2179/10000, Loss: 0.029245935380458832\n",
      "Iteration: 2180/10000, Loss: 0.04551228880882263\n",
      "Iteration: 2181/10000, Loss: 0.040508050471544266\n",
      "Iteration: 2182/10000, Loss: 0.022468557581305504\n",
      "Iteration: 2183/10000, Loss: 0.028236323967576027\n",
      "Iteration: 2184/10000, Loss: 0.04322992265224457\n",
      "Iteration: 2185/10000, Loss: 0.040025487542152405\n",
      "Iteration: 2186/10000, Loss: 0.032297421246767044\n",
      "Iteration: 2187/10000, Loss: 0.03797522932291031\n",
      "Iteration: 2188/10000, Loss: 0.02931128442287445\n",
      "Iteration: 2189/10000, Loss: 0.034466784447431564\n",
      "Iteration: 2190/10000, Loss: 0.03936145827174187\n",
      "Iteration: 2191/10000, Loss: 0.04861165210604668\n",
      "Iteration: 2192/10000, Loss: 0.03900350630283356\n",
      "Iteration: 2193/10000, Loss: 0.016467012465000153\n",
      "Iteration: 2194/10000, Loss: 0.03551853820681572\n",
      "Iteration: 2195/10000, Loss: 0.030578577890992165\n",
      "Iteration: 2196/10000, Loss: 0.028682321310043335\n",
      "Iteration: 2197/10000, Loss: 0.03985927999019623\n",
      "Iteration: 2198/10000, Loss: 0.03517434373497963\n",
      "Iteration: 2199/10000, Loss: 0.02020537108182907\n",
      "Iteration: 2200/10000, Loss: 0.028980664908885956\n",
      "Average test loss:  0.0029\n",
      "Iteration: 2201/10000, Loss: 0.02777787484228611\n",
      "Iteration: 2202/10000, Loss: 0.039580509066581726\n",
      "Iteration: 2203/10000, Loss: 0.023361850529909134\n",
      "Iteration: 2204/10000, Loss: 0.03117910772562027\n",
      "Iteration: 2205/10000, Loss: 0.04363774135708809\n",
      "Iteration: 2206/10000, Loss: 0.03418034315109253\n",
      "Iteration: 2207/10000, Loss: 0.026227621361613274\n",
      "Iteration: 2208/10000, Loss: 0.03165699914097786\n",
      "Iteration: 2209/10000, Loss: 0.025130698457360268\n",
      "Iteration: 2210/10000, Loss: 0.0303764920681715\n",
      "Iteration: 2211/10000, Loss: 0.05461469292640686\n",
      "Iteration: 2212/10000, Loss: 0.02126729115843773\n",
      "Iteration: 2213/10000, Loss: 0.03345277160406113\n",
      "Iteration: 2214/10000, Loss: 0.05262691527605057\n",
      "Iteration: 2215/10000, Loss: 0.032094404101371765\n",
      "Iteration: 2216/10000, Loss: 0.02992459200322628\n",
      "Iteration: 2217/10000, Loss: 0.023299982771277428\n",
      "Iteration: 2218/10000, Loss: 0.025996388867497444\n",
      "Iteration: 2219/10000, Loss: 0.031111543998122215\n",
      "Iteration: 2220/10000, Loss: 0.022546157240867615\n",
      "Iteration: 2221/10000, Loss: 0.026093466207385063\n",
      "Iteration: 2222/10000, Loss: 0.0298698078840971\n",
      "Iteration: 2223/10000, Loss: 0.03173861652612686\n",
      "Iteration: 2224/10000, Loss: 0.021739112213253975\n",
      "Iteration: 2225/10000, Loss: 0.03115798532962799\n",
      "Iteration: 2226/10000, Loss: 0.028483964502811432\n",
      "Iteration: 2227/10000, Loss: 0.03077293187379837\n",
      "Iteration: 2228/10000, Loss: 0.027584685012698174\n",
      "Iteration: 2229/10000, Loss: 0.028901025652885437\n",
      "Iteration: 2230/10000, Loss: 0.02908218465745449\n",
      "Iteration: 2231/10000, Loss: 0.01954781822860241\n",
      "Iteration: 2232/10000, Loss: 0.03338378667831421\n",
      "Iteration: 2233/10000, Loss: 0.030291492119431496\n",
      "Iteration: 2234/10000, Loss: 0.03440570831298828\n",
      "Iteration: 2235/10000, Loss: 0.03174728900194168\n",
      "Iteration: 2236/10000, Loss: 0.023479096591472626\n",
      "Iteration: 2237/10000, Loss: 0.029695237055420876\n",
      "Iteration: 2238/10000, Loss: 0.024959450587630272\n",
      "Iteration: 2239/10000, Loss: 0.0353463813662529\n",
      "Iteration: 2240/10000, Loss: 0.029675669968128204\n",
      "Iteration: 2241/10000, Loss: 0.03883213549852371\n",
      "Iteration: 2242/10000, Loss: 0.03358611464500427\n",
      "Iteration: 2243/10000, Loss: 0.03230849653482437\n",
      "Iteration: 2244/10000, Loss: 0.0391208790242672\n",
      "Iteration: 2245/10000, Loss: 0.037385109812021255\n",
      "Iteration: 2246/10000, Loss: 0.03856919705867767\n",
      "Iteration: 2247/10000, Loss: 0.02001730538904667\n",
      "Iteration: 2248/10000, Loss: 0.026132341474294662\n",
      "Iteration: 2249/10000, Loss: 0.029255788773298264\n",
      "Iteration: 2250/10000, Loss: 0.03067743219435215\n",
      "Iteration: 2251/10000, Loss: 0.027744797989726067\n",
      "Iteration: 2252/10000, Loss: 0.03540300205349922\n",
      "Iteration: 2253/10000, Loss: 0.04812518507242203\n",
      "Iteration: 2254/10000, Loss: 0.04345659539103508\n",
      "Iteration: 2255/10000, Loss: 0.03625832870602608\n",
      "Iteration: 2256/10000, Loss: 0.027174504473805428\n",
      "Iteration: 2257/10000, Loss: 0.036186039447784424\n",
      "Iteration: 2258/10000, Loss: 0.027070455253124237\n",
      "Iteration: 2259/10000, Loss: 0.022281842306256294\n",
      "Iteration: 2260/10000, Loss: 0.05323898047208786\n",
      "Iteration: 2261/10000, Loss: 0.03309665247797966\n",
      "Iteration: 2262/10000, Loss: 0.04369480535387993\n",
      "Iteration: 2263/10000, Loss: 0.035829316824674606\n",
      "Iteration: 2264/10000, Loss: 0.037261467427015305\n",
      "Iteration: 2265/10000, Loss: 0.03483622521162033\n",
      "Iteration: 2266/10000, Loss: 0.0335066094994545\n",
      "Iteration: 2267/10000, Loss: 0.03387419879436493\n",
      "Iteration: 2268/10000, Loss: 0.044835735112428665\n",
      "Iteration: 2269/10000, Loss: 0.02510705031454563\n",
      "Iteration: 2270/10000, Loss: 0.03663378953933716\n",
      "Iteration: 2271/10000, Loss: 0.02627393789589405\n",
      "Iteration: 2272/10000, Loss: 0.037907782942056656\n",
      "Iteration: 2273/10000, Loss: 0.027031630277633667\n",
      "Iteration: 2274/10000, Loss: 0.024899356067180634\n",
      "Iteration: 2275/10000, Loss: 0.022678805515170097\n",
      "Iteration: 2276/10000, Loss: 0.02601243369281292\n",
      "Iteration: 2277/10000, Loss: 0.04698571190237999\n",
      "Iteration: 2278/10000, Loss: 0.057610392570495605\n",
      "Iteration: 2279/10000, Loss: 0.02920323982834816\n",
      "Iteration: 2280/10000, Loss: 0.033031709492206573\n",
      "Iteration: 2281/10000, Loss: 0.037774503231048584\n",
      "Iteration: 2282/10000, Loss: 0.040070343762636185\n",
      "Iteration: 2283/10000, Loss: 0.030802007764577866\n",
      "Iteration: 2284/10000, Loss: 0.042519841343164444\n",
      "Iteration: 2285/10000, Loss: 0.021924009546637535\n",
      "Iteration: 2286/10000, Loss: 0.029765203595161438\n",
      "Iteration: 2287/10000, Loss: 0.03051992505788803\n",
      "Iteration: 2288/10000, Loss: 0.029067158699035645\n",
      "Iteration: 2289/10000, Loss: 0.03612709417939186\n",
      "Iteration: 2290/10000, Loss: 0.025082213804125786\n",
      "Iteration: 2291/10000, Loss: 0.02196054719388485\n",
      "Iteration: 2292/10000, Loss: 0.035232048481702805\n",
      "Iteration: 2293/10000, Loss: 0.02687043510377407\n",
      "Iteration: 2294/10000, Loss: 0.030500110238790512\n",
      "Iteration: 2295/10000, Loss: 0.025226665660738945\n",
      "Iteration: 2296/10000, Loss: 0.02637094259262085\n",
      "Iteration: 2297/10000, Loss: 0.032180242240428925\n",
      "Iteration: 2298/10000, Loss: 0.02897239662706852\n",
      "Iteration: 2299/10000, Loss: 0.03319238871335983\n",
      "Iteration: 2300/10000, Loss: 0.03207919001579285\n",
      "Average test loss:  0.0018\n",
      "Iteration: 2301/10000, Loss: 0.030962787568569183\n",
      "Iteration: 2302/10000, Loss: 0.040764741599559784\n",
      "Iteration: 2303/10000, Loss: 0.02255817875266075\n",
      "Iteration: 2304/10000, Loss: 0.020050784572958946\n",
      "Iteration: 2305/10000, Loss: 0.027135953307151794\n",
      "Iteration: 2306/10000, Loss: 0.016167903319001198\n",
      "Iteration: 2307/10000, Loss: 0.02731892094016075\n",
      "Iteration: 2308/10000, Loss: 0.024447143077850342\n",
      "Iteration: 2309/10000, Loss: 0.03489552065730095\n",
      "Iteration: 2310/10000, Loss: 0.055673740804195404\n",
      "Iteration: 2311/10000, Loss: 0.0272498931735754\n",
      "Iteration: 2312/10000, Loss: 0.029082588851451874\n",
      "Iteration: 2313/10000, Loss: 0.02535613626241684\n",
      "Iteration: 2314/10000, Loss: 0.03227468952536583\n",
      "Iteration: 2315/10000, Loss: 0.024769963696599007\n",
      "Iteration: 2316/10000, Loss: 0.042614731937646866\n",
      "Iteration: 2317/10000, Loss: 0.023407602682709694\n",
      "Iteration: 2318/10000, Loss: 0.02712954208254814\n",
      "Iteration: 2319/10000, Loss: 0.021562958136200905\n",
      "Iteration: 2320/10000, Loss: 0.022410573437809944\n",
      "Iteration: 2321/10000, Loss: 0.023666707798838615\n",
      "Iteration: 2322/10000, Loss: 0.023555612191557884\n",
      "Iteration: 2323/10000, Loss: 0.020030219107866287\n",
      "Iteration: 2324/10000, Loss: 0.029703952372074127\n",
      "Iteration: 2325/10000, Loss: 0.0345647819340229\n",
      "Iteration: 2326/10000, Loss: 0.04931103065609932\n",
      "Iteration: 2327/10000, Loss: 0.05178690701723099\n",
      "Iteration: 2328/10000, Loss: 0.02713635377585888\n",
      "Iteration: 2329/10000, Loss: 0.030332602560520172\n",
      "Iteration: 2330/10000, Loss: 0.04016171023249626\n",
      "Iteration: 2331/10000, Loss: 0.033235277980566025\n",
      "Iteration: 2332/10000, Loss: 0.02862381748855114\n",
      "Iteration: 2333/10000, Loss: 0.03678472712635994\n",
      "Iteration: 2334/10000, Loss: 0.02839824929833412\n",
      "Iteration: 2335/10000, Loss: 0.025448326021432877\n",
      "Iteration: 2336/10000, Loss: 0.02744317427277565\n",
      "Iteration: 2337/10000, Loss: 0.02619173936545849\n",
      "Iteration: 2338/10000, Loss: 0.023846805095672607\n",
      "Iteration: 2339/10000, Loss: 0.02353583462536335\n",
      "Iteration: 2340/10000, Loss: 0.02745078317821026\n",
      "Iteration: 2341/10000, Loss: 0.03593671694397926\n",
      "Iteration: 2342/10000, Loss: 0.022673193365335464\n",
      "Iteration: 2343/10000, Loss: 0.059528086334466934\n",
      "Iteration: 2344/10000, Loss: 0.030988188460469246\n",
      "Iteration: 2345/10000, Loss: 0.0293502788990736\n",
      "Iteration: 2346/10000, Loss: 0.021078985184431076\n",
      "Iteration: 2347/10000, Loss: 0.033818937838077545\n",
      "Iteration: 2348/10000, Loss: 0.032334957271814346\n",
      "Iteration: 2349/10000, Loss: 0.02357623353600502\n",
      "Iteration: 2350/10000, Loss: 0.029240921139717102\n",
      "Iteration: 2351/10000, Loss: 0.027115289121866226\n",
      "Iteration: 2352/10000, Loss: 0.032707374542951584\n",
      "Iteration: 2353/10000, Loss: 0.028282230719923973\n",
      "Iteration: 2354/10000, Loss: 0.023697108030319214\n",
      "Iteration: 2355/10000, Loss: 0.023422008380293846\n",
      "Iteration: 2356/10000, Loss: 0.020632287487387657\n",
      "Iteration: 2357/10000, Loss: 0.018245214596390724\n",
      "Iteration: 2358/10000, Loss: 0.018840117380023003\n",
      "Iteration: 2359/10000, Loss: 0.02805497497320175\n",
      "Iteration: 2360/10000, Loss: 0.019023509696125984\n",
      "Iteration: 2361/10000, Loss: 0.018469998612999916\n",
      "Iteration: 2362/10000, Loss: 0.02844427153468132\n",
      "Iteration: 2363/10000, Loss: 0.023420192301273346\n",
      "Iteration: 2364/10000, Loss: 0.02305751107633114\n",
      "Iteration: 2365/10000, Loss: 0.02991054765880108\n",
      "Iteration: 2366/10000, Loss: 0.0394955649971962\n",
      "Iteration: 2367/10000, Loss: 0.03289957344532013\n",
      "Iteration: 2368/10000, Loss: 0.03349435329437256\n",
      "Iteration: 2369/10000, Loss: 0.030398866161704063\n",
      "Iteration: 2370/10000, Loss: 0.040320854634046555\n",
      "Iteration: 2371/10000, Loss: 0.028772534802556038\n",
      "Iteration: 2372/10000, Loss: 0.025195181369781494\n",
      "Iteration: 2373/10000, Loss: 0.028436563909053802\n",
      "Iteration: 2374/10000, Loss: 0.024217037484049797\n",
      "Iteration: 2375/10000, Loss: 0.023231249302625656\n",
      "Iteration: 2376/10000, Loss: 0.033223532140254974\n",
      "Iteration: 2377/10000, Loss: 0.019865360110998154\n",
      "Iteration: 2378/10000, Loss: 0.016649294644594193\n",
      "Iteration: 2379/10000, Loss: 0.030110327526926994\n",
      "Iteration: 2380/10000, Loss: 0.024659106507897377\n",
      "Iteration: 2381/10000, Loss: 0.030582329258322716\n",
      "Iteration: 2382/10000, Loss: 0.023662570863962173\n",
      "Iteration: 2383/10000, Loss: 0.04528581723570824\n",
      "Iteration: 2384/10000, Loss: 0.03821457922458649\n",
      "Iteration: 2385/10000, Loss: 0.0275363028049469\n",
      "Iteration: 2386/10000, Loss: 0.030826356261968613\n",
      "Iteration: 2387/10000, Loss: 0.03491327166557312\n",
      "Iteration: 2388/10000, Loss: 0.023287156596779823\n",
      "Iteration: 2389/10000, Loss: 0.03304245322942734\n",
      "Iteration: 2390/10000, Loss: 0.022633925080299377\n",
      "Iteration: 2391/10000, Loss: 0.02921088971197605\n",
      "Iteration: 2392/10000, Loss: 0.026758337393403053\n",
      "Iteration: 2393/10000, Loss: 0.03182798624038696\n",
      "Iteration: 2394/10000, Loss: 0.040162891149520874\n",
      "Iteration: 2395/10000, Loss: 0.03289869800209999\n",
      "Iteration: 2396/10000, Loss: 0.02357563003897667\n",
      "Iteration: 2397/10000, Loss: 0.022196142002940178\n",
      "Iteration: 2398/10000, Loss: 0.034980710595846176\n",
      "Iteration: 2399/10000, Loss: 0.027291426435112953\n",
      "Iteration: 2400/10000, Loss: 0.032698169350624084\n",
      "Average test loss:  0.0043\n",
      "Iteration: 2401/10000, Loss: 0.029539383947849274\n",
      "Iteration: 2402/10000, Loss: 0.026454266160726547\n",
      "Iteration: 2403/10000, Loss: 0.018903380259871483\n",
      "Iteration: 2404/10000, Loss: 0.05243874713778496\n",
      "Iteration: 2405/10000, Loss: 0.02189415879547596\n",
      "Iteration: 2406/10000, Loss: 0.03015434741973877\n",
      "Iteration: 2407/10000, Loss: 0.03748016804456711\n",
      "Iteration: 2408/10000, Loss: 0.026280328631401062\n",
      "Iteration: 2409/10000, Loss: 0.03112800233066082\n",
      "Iteration: 2410/10000, Loss: 0.024861203506588936\n",
      "Iteration: 2411/10000, Loss: 0.025263946503400803\n",
      "Iteration: 2412/10000, Loss: 0.03256544470787048\n",
      "Iteration: 2413/10000, Loss: 0.02856259234249592\n",
      "Iteration: 2414/10000, Loss: 0.01946929842233658\n",
      "Iteration: 2415/10000, Loss: 0.017684930935502052\n",
      "Iteration: 2416/10000, Loss: 0.04632027819752693\n",
      "Iteration: 2417/10000, Loss: 0.02456558309495449\n",
      "Iteration: 2418/10000, Loss: 0.03334139660000801\n",
      "Iteration: 2419/10000, Loss: 0.0356610082089901\n",
      "Iteration: 2420/10000, Loss: 0.03556567057967186\n",
      "Iteration: 2421/10000, Loss: 0.030206484720110893\n",
      "Iteration: 2422/10000, Loss: 0.031830333173274994\n",
      "Iteration: 2423/10000, Loss: 0.018214065581560135\n",
      "Iteration: 2424/10000, Loss: 0.025992250069975853\n",
      "Iteration: 2425/10000, Loss: 0.028594350442290306\n",
      "Iteration: 2426/10000, Loss: 0.02761353738605976\n",
      "Iteration: 2427/10000, Loss: 0.028194501996040344\n",
      "Iteration: 2428/10000, Loss: 0.019964231178164482\n",
      "Iteration: 2429/10000, Loss: 0.021114492788910866\n",
      "Iteration: 2430/10000, Loss: 0.02654869295656681\n",
      "Iteration: 2431/10000, Loss: 0.019187629222869873\n",
      "Iteration: 2432/10000, Loss: 0.020607883110642433\n",
      "Iteration: 2433/10000, Loss: 0.022365711629390717\n",
      "Iteration: 2434/10000, Loss: 0.026016980409622192\n",
      "Iteration: 2435/10000, Loss: 0.03213679790496826\n",
      "Iteration: 2436/10000, Loss: 0.022101951763033867\n",
      "Iteration: 2437/10000, Loss: 0.033515386283397675\n",
      "Iteration: 2438/10000, Loss: 0.022142531350255013\n",
      "Iteration: 2439/10000, Loss: 0.03660755977034569\n",
      "Iteration: 2440/10000, Loss: 0.024717651307582855\n",
      "Iteration: 2441/10000, Loss: 0.029132504016160965\n",
      "Iteration: 2442/10000, Loss: 0.03255362808704376\n",
      "Iteration: 2443/10000, Loss: 0.029447510838508606\n",
      "Iteration: 2444/10000, Loss: 0.029057342559099197\n",
      "Iteration: 2445/10000, Loss: 0.03810197114944458\n",
      "Iteration: 2446/10000, Loss: 0.02998628281056881\n",
      "Iteration: 2447/10000, Loss: 0.030799217522144318\n",
      "Iteration: 2448/10000, Loss: 0.04649975150823593\n",
      "Iteration: 2449/10000, Loss: 0.022121939808130264\n",
      "Iteration: 2450/10000, Loss: 0.038317322731018066\n",
      "Iteration: 2451/10000, Loss: 0.0273415707051754\n",
      "Iteration: 2452/10000, Loss: 0.03459189087152481\n",
      "Iteration: 2453/10000, Loss: 0.029440633952617645\n",
      "Iteration: 2454/10000, Loss: 0.024370575323700905\n",
      "Iteration: 2455/10000, Loss: 0.04225900024175644\n",
      "Iteration: 2456/10000, Loss: 0.03352869674563408\n",
      "Iteration: 2457/10000, Loss: 0.031755853444337845\n",
      "Iteration: 2458/10000, Loss: 0.027115987613797188\n",
      "Iteration: 2459/10000, Loss: 0.036438457667827606\n",
      "Iteration: 2460/10000, Loss: 0.023872539401054382\n",
      "Iteration: 2461/10000, Loss: 0.015458217822015285\n",
      "Iteration: 2462/10000, Loss: 0.02910907380282879\n",
      "Iteration: 2463/10000, Loss: 0.022125348448753357\n",
      "Iteration: 2464/10000, Loss: 0.02222551219165325\n",
      "Iteration: 2465/10000, Loss: 0.028757993131875992\n",
      "Iteration: 2466/10000, Loss: 0.018591545522212982\n",
      "Iteration: 2467/10000, Loss: 0.037440355867147446\n",
      "Iteration: 2468/10000, Loss: 0.02224382758140564\n",
      "Iteration: 2469/10000, Loss: 0.02517678588628769\n",
      "Iteration: 2470/10000, Loss: 0.03268194571137428\n",
      "Iteration: 2471/10000, Loss: 0.025881176814436913\n",
      "Iteration: 2472/10000, Loss: 0.02324965037405491\n",
      "Iteration: 2473/10000, Loss: 0.03189701959490776\n",
      "Iteration: 2474/10000, Loss: 0.02593655325472355\n",
      "Iteration: 2475/10000, Loss: 0.02846800908446312\n",
      "Iteration: 2476/10000, Loss: 0.019627287983894348\n",
      "Iteration: 2477/10000, Loss: 0.036285728216171265\n",
      "Iteration: 2478/10000, Loss: 0.027112605050206184\n",
      "Iteration: 2479/10000, Loss: 0.02268926426768303\n",
      "Iteration: 2480/10000, Loss: 0.027828391641378403\n",
      "Iteration: 2481/10000, Loss: 0.033747464418411255\n",
      "Iteration: 2482/10000, Loss: 0.019988028332591057\n",
      "Iteration: 2483/10000, Loss: 0.04311821982264519\n",
      "Iteration: 2484/10000, Loss: 0.01679058000445366\n",
      "Iteration: 2485/10000, Loss: 0.03338494524359703\n",
      "Iteration: 2486/10000, Loss: 0.028775101527571678\n",
      "Iteration: 2487/10000, Loss: 0.025531183928251266\n",
      "Iteration: 2488/10000, Loss: 0.024031085893511772\n",
      "Iteration: 2489/10000, Loss: 0.02489871345460415\n",
      "Iteration: 2490/10000, Loss: 0.02469673380255699\n",
      "Iteration: 2491/10000, Loss: 0.021949103102087975\n",
      "Iteration: 2492/10000, Loss: 0.026204053312540054\n",
      "Iteration: 2493/10000, Loss: 0.015681708231568336\n",
      "Iteration: 2494/10000, Loss: 0.03680979087948799\n",
      "Iteration: 2495/10000, Loss: 0.04609758034348488\n",
      "Iteration: 2496/10000, Loss: 0.02257939614355564\n",
      "Iteration: 2497/10000, Loss: 0.027080731466412544\n",
      "Iteration: 2498/10000, Loss: 0.04400286450982094\n",
      "Iteration: 2499/10000, Loss: 0.029555747285485268\n",
      "Iteration: 2500/10000, Loss: 0.02791418693959713\n",
      "Average test loss:  0.0024\n",
      "Iteration: 2501/10000, Loss: 0.019287647679448128\n",
      "Iteration: 2502/10000, Loss: 0.03497442975640297\n",
      "Iteration: 2503/10000, Loss: 0.019167548045516014\n",
      "Iteration: 2504/10000, Loss: 0.030064880847930908\n",
      "Iteration: 2505/10000, Loss: 0.026220902800559998\n",
      "Iteration: 2506/10000, Loss: 0.032940808683633804\n",
      "Iteration: 2507/10000, Loss: 0.017101449891924858\n",
      "Iteration: 2508/10000, Loss: 0.025165341794490814\n",
      "Iteration: 2509/10000, Loss: 0.028175652027130127\n",
      "Iteration: 2510/10000, Loss: 0.026582466438412666\n",
      "Iteration: 2511/10000, Loss: 0.024036239832639694\n",
      "Iteration: 2512/10000, Loss: 0.027079572901129723\n",
      "Iteration: 2513/10000, Loss: 0.03294212371110916\n",
      "Iteration: 2514/10000, Loss: 0.023670483380556107\n",
      "Iteration: 2515/10000, Loss: 0.03672638535499573\n",
      "Iteration: 2516/10000, Loss: 0.038984134793281555\n",
      "Iteration: 2517/10000, Loss: 0.026319198310375214\n",
      "Iteration: 2518/10000, Loss: 0.020364295691251755\n",
      "Iteration: 2519/10000, Loss: 0.02153911255300045\n",
      "Iteration: 2520/10000, Loss: 0.02928696759045124\n",
      "Iteration: 2521/10000, Loss: 0.020243940874934196\n",
      "Iteration: 2522/10000, Loss: 0.020914196968078613\n",
      "Iteration: 2523/10000, Loss: 0.027617638930678368\n",
      "Iteration: 2524/10000, Loss: 0.023956777527928352\n",
      "Iteration: 2525/10000, Loss: 0.030526818707585335\n",
      "Iteration: 2526/10000, Loss: 0.02650989033281803\n",
      "Iteration: 2527/10000, Loss: 0.03145070746541023\n",
      "Iteration: 2528/10000, Loss: 0.03123200312256813\n",
      "Iteration: 2529/10000, Loss: 0.03389492630958557\n",
      "Iteration: 2530/10000, Loss: 0.022865552455186844\n",
      "Iteration: 2531/10000, Loss: 0.031923599541187286\n",
      "Iteration: 2532/10000, Loss: 0.02261422760784626\n",
      "Iteration: 2533/10000, Loss: 0.03256300836801529\n",
      "Iteration: 2534/10000, Loss: 0.025696802884340286\n",
      "Iteration: 2535/10000, Loss: 0.03079686127603054\n",
      "Iteration: 2536/10000, Loss: 0.0309798214584589\n",
      "Iteration: 2537/10000, Loss: 0.021418612450361252\n",
      "Iteration: 2538/10000, Loss: 0.02539476379752159\n",
      "Iteration: 2539/10000, Loss: 0.03314182534813881\n",
      "Iteration: 2540/10000, Loss: 0.02777191810309887\n",
      "Iteration: 2541/10000, Loss: 0.028034042567014694\n",
      "Iteration: 2542/10000, Loss: 0.027490895241498947\n",
      "Iteration: 2543/10000, Loss: 0.02275906689465046\n",
      "Iteration: 2544/10000, Loss: 0.021398713812232018\n",
      "Iteration: 2545/10000, Loss: 0.018053987994790077\n",
      "Iteration: 2546/10000, Loss: 0.020004989579319954\n",
      "Iteration: 2547/10000, Loss: 0.03507358953356743\n",
      "Iteration: 2548/10000, Loss: 0.026693331077694893\n",
      "Iteration: 2549/10000, Loss: 0.035110682249069214\n",
      "Iteration: 2550/10000, Loss: 0.02555793896317482\n",
      "Iteration: 2551/10000, Loss: 0.017642047256231308\n",
      "Iteration: 2552/10000, Loss: 0.02298549935221672\n",
      "Iteration: 2553/10000, Loss: 0.03091610036790371\n",
      "Iteration: 2554/10000, Loss: 0.024264561012387276\n",
      "Iteration: 2555/10000, Loss: 0.020493675023317337\n",
      "Iteration: 2556/10000, Loss: 0.0367024727165699\n",
      "Iteration: 2557/10000, Loss: 0.02448209747672081\n",
      "Iteration: 2558/10000, Loss: 0.0303985383361578\n",
      "Iteration: 2559/10000, Loss: 0.02013080008327961\n",
      "Iteration: 2560/10000, Loss: 0.02375563606619835\n",
      "Iteration: 2561/10000, Loss: 0.02482091635465622\n",
      "Iteration: 2562/10000, Loss: 0.024061111733317375\n",
      "Iteration: 2563/10000, Loss: 0.020410751923918724\n",
      "Iteration: 2564/10000, Loss: 0.02630409225821495\n",
      "Iteration: 2565/10000, Loss: 0.02802135981619358\n",
      "Iteration: 2566/10000, Loss: 0.024877484887838364\n",
      "Iteration: 2567/10000, Loss: 0.021439123898744583\n",
      "Iteration: 2568/10000, Loss: 0.025296000763773918\n",
      "Iteration: 2569/10000, Loss: 0.029334958642721176\n",
      "Iteration: 2570/10000, Loss: 0.029224928468465805\n",
      "Iteration: 2571/10000, Loss: 0.02299477346241474\n",
      "Iteration: 2572/10000, Loss: 0.020487572997808456\n",
      "Iteration: 2573/10000, Loss: 0.023598218336701393\n",
      "Iteration: 2574/10000, Loss: 0.03103155829012394\n",
      "Iteration: 2575/10000, Loss: 0.021228116005659103\n",
      "Iteration: 2576/10000, Loss: 0.030722301453351974\n",
      "Iteration: 2577/10000, Loss: 0.026239506900310516\n",
      "Iteration: 2578/10000, Loss: 0.02234138548374176\n",
      "Iteration: 2579/10000, Loss: 0.026826079934835434\n",
      "Iteration: 2580/10000, Loss: 0.02712893672287464\n",
      "Iteration: 2581/10000, Loss: 0.028400685638189316\n",
      "Iteration: 2582/10000, Loss: 0.02751968428492546\n",
      "Iteration: 2583/10000, Loss: 0.0273033007979393\n",
      "Iteration: 2584/10000, Loss: 0.028355134651064873\n",
      "Iteration: 2585/10000, Loss: 0.023778483271598816\n",
      "Iteration: 2586/10000, Loss: 0.016926990821957588\n",
      "Iteration: 2587/10000, Loss: 0.01685452088713646\n",
      "Iteration: 2588/10000, Loss: 0.023148011416196823\n",
      "Iteration: 2589/10000, Loss: 0.028001338243484497\n",
      "Iteration: 2590/10000, Loss: 0.01963178627192974\n",
      "Iteration: 2591/10000, Loss: 0.025533517822623253\n",
      "Iteration: 2592/10000, Loss: 0.028515465557575226\n",
      "Iteration: 2593/10000, Loss: 0.014848865568637848\n",
      "Iteration: 2594/10000, Loss: 0.022043295204639435\n",
      "Iteration: 2595/10000, Loss: 0.02861764095723629\n",
      "Iteration: 2596/10000, Loss: 0.025130175054073334\n",
      "Iteration: 2597/10000, Loss: 0.026418592780828476\n",
      "Iteration: 2598/10000, Loss: 0.0172959603369236\n",
      "Iteration: 2599/10000, Loss: 0.01435371395200491\n",
      "Iteration: 2600/10000, Loss: 0.022659514099359512\n",
      "Average test loss:  0.0012\n",
      "Iteration: 2601/10000, Loss: 0.02400558814406395\n",
      "Iteration: 2602/10000, Loss: 0.019513040781021118\n",
      "Iteration: 2603/10000, Loss: 0.023805169388651848\n",
      "Iteration: 2604/10000, Loss: 0.03150222823023796\n",
      "Iteration: 2605/10000, Loss: 0.018587298691272736\n",
      "Iteration: 2606/10000, Loss: 0.023239629343152046\n",
      "Iteration: 2607/10000, Loss: 0.01672264002263546\n",
      "Iteration: 2608/10000, Loss: 0.01801677979528904\n",
      "Iteration: 2609/10000, Loss: 0.029713444411754608\n",
      "Iteration: 2610/10000, Loss: 0.024132084101438522\n",
      "Iteration: 2611/10000, Loss: 0.022351166233420372\n",
      "Iteration: 2612/10000, Loss: 0.018166406080126762\n",
      "Iteration: 2613/10000, Loss: 0.014028997160494328\n",
      "Iteration: 2614/10000, Loss: 0.037214841693639755\n",
      "Iteration: 2615/10000, Loss: 0.026855990290641785\n",
      "Iteration: 2616/10000, Loss: 0.028128163889050484\n",
      "Iteration: 2617/10000, Loss: 0.017513154074549675\n",
      "Iteration: 2618/10000, Loss: 0.016038598492741585\n",
      "Iteration: 2619/10000, Loss: 0.015207245945930481\n",
      "Iteration: 2620/10000, Loss: 0.01843240298330784\n",
      "Iteration: 2621/10000, Loss: 0.039730869233608246\n",
      "Iteration: 2622/10000, Loss: 0.04011915251612663\n",
      "Iteration: 2623/10000, Loss: 0.034031860530376434\n",
      "Iteration: 2624/10000, Loss: 0.03388310223817825\n",
      "Iteration: 2625/10000, Loss: 0.02704649791121483\n",
      "Iteration: 2626/10000, Loss: 0.025241032242774963\n",
      "Iteration: 2627/10000, Loss: 0.03186364471912384\n",
      "Iteration: 2628/10000, Loss: 0.02496076561510563\n",
      "Iteration: 2629/10000, Loss: 0.024163872003555298\n",
      "Iteration: 2630/10000, Loss: 0.0266047865152359\n",
      "Iteration: 2631/10000, Loss: 0.02038109302520752\n",
      "Iteration: 2632/10000, Loss: 0.03338433429598808\n",
      "Iteration: 2633/10000, Loss: 0.03504188731312752\n",
      "Iteration: 2634/10000, Loss: 0.028119424358010292\n",
      "Iteration: 2635/10000, Loss: 0.028841368854045868\n",
      "Iteration: 2636/10000, Loss: 0.03419255465269089\n",
      "Iteration: 2637/10000, Loss: 0.021199529990553856\n",
      "Iteration: 2638/10000, Loss: 0.022122539579868317\n",
      "Iteration: 2639/10000, Loss: 0.020356085151433945\n",
      "Iteration: 2640/10000, Loss: 0.019632559269666672\n",
      "Iteration: 2641/10000, Loss: 0.030371813103556633\n",
      "Iteration: 2642/10000, Loss: 0.03330245241522789\n",
      "Iteration: 2643/10000, Loss: 0.037142056971788406\n",
      "Iteration: 2644/10000, Loss: 0.02223416604101658\n",
      "Iteration: 2645/10000, Loss: 0.033260371536016464\n",
      "Iteration: 2646/10000, Loss: 0.02226552553474903\n",
      "Iteration: 2647/10000, Loss: 0.017968174070119858\n",
      "Iteration: 2648/10000, Loss: 0.02813027985394001\n",
      "Iteration: 2649/10000, Loss: 0.027884792536497116\n",
      "Iteration: 2650/10000, Loss: 0.026137813925743103\n",
      "Iteration: 2651/10000, Loss: 0.026697224006056786\n",
      "Iteration: 2652/10000, Loss: 0.031438663601875305\n",
      "Iteration: 2653/10000, Loss: 0.0266916174441576\n",
      "Iteration: 2654/10000, Loss: 0.014556076377630234\n",
      "Iteration: 2655/10000, Loss: 0.022920088842511177\n",
      "Iteration: 2656/10000, Loss: 0.01799246296286583\n",
      "Iteration: 2657/10000, Loss: 0.023113740608096123\n",
      "Iteration: 2658/10000, Loss: 0.024954523891210556\n",
      "Iteration: 2659/10000, Loss: 0.020279910415410995\n",
      "Iteration: 2660/10000, Loss: 0.019398201256990433\n",
      "Iteration: 2661/10000, Loss: 0.022991139441728592\n",
      "Iteration: 2662/10000, Loss: 0.02681339904665947\n",
      "Iteration: 2663/10000, Loss: 0.041860055178403854\n",
      "Iteration: 2664/10000, Loss: 0.02771441638469696\n",
      "Iteration: 2665/10000, Loss: 0.028940677642822266\n",
      "Iteration: 2666/10000, Loss: 0.02832888998091221\n",
      "Iteration: 2667/10000, Loss: 0.03149504214525223\n",
      "Iteration: 2668/10000, Loss: 0.018850082531571388\n",
      "Iteration: 2669/10000, Loss: 0.028349194675683975\n",
      "Iteration: 2670/10000, Loss: 0.024900728836655617\n",
      "Iteration: 2671/10000, Loss: 0.028171338140964508\n",
      "Iteration: 2672/10000, Loss: 0.02349786087870598\n",
      "Iteration: 2673/10000, Loss: 0.016306962817907333\n",
      "Iteration: 2674/10000, Loss: 0.035574790090322495\n",
      "Iteration: 2675/10000, Loss: 0.0283735990524292\n",
      "Iteration: 2676/10000, Loss: 0.01991351693868637\n",
      "Iteration: 2677/10000, Loss: 0.026739733293652534\n",
      "Iteration: 2678/10000, Loss: 0.01656288094818592\n",
      "Iteration: 2679/10000, Loss: 0.022025443613529205\n",
      "Iteration: 2680/10000, Loss: 0.020850272849202156\n",
      "Iteration: 2681/10000, Loss: 0.03094364143908024\n",
      "Iteration: 2682/10000, Loss: 0.02271021343767643\n",
      "Iteration: 2683/10000, Loss: 0.021555306389927864\n",
      "Iteration: 2684/10000, Loss: 0.03281119838356972\n",
      "Iteration: 2685/10000, Loss: 0.03472533077001572\n",
      "Iteration: 2686/10000, Loss: 0.024908585473895073\n",
      "Iteration: 2687/10000, Loss: 0.023516017943620682\n",
      "Iteration: 2688/10000, Loss: 0.01854315772652626\n",
      "Iteration: 2689/10000, Loss: 0.02601759321987629\n",
      "Iteration: 2690/10000, Loss: 0.020454680547118187\n",
      "Iteration: 2691/10000, Loss: 0.02219780907034874\n",
      "Iteration: 2692/10000, Loss: 0.02299606241285801\n",
      "Iteration: 2693/10000, Loss: 0.021148748695850372\n",
      "Iteration: 2694/10000, Loss: 0.03841840848326683\n",
      "Iteration: 2695/10000, Loss: 0.025322988629341125\n",
      "Iteration: 2696/10000, Loss: 0.02197928912937641\n",
      "Iteration: 2697/10000, Loss: 0.026965508237481117\n",
      "Iteration: 2698/10000, Loss: 0.021158084273338318\n",
      "Iteration: 2699/10000, Loss: 0.019966982305049896\n",
      "Iteration: 2700/10000, Loss: 0.02504005841910839\n",
      "Average test loss:  0.0023\n",
      "Iteration: 2701/10000, Loss: 0.02526685781776905\n",
      "Iteration: 2702/10000, Loss: 0.023964552208781242\n",
      "Iteration: 2703/10000, Loss: 0.015753231942653656\n",
      "Iteration: 2704/10000, Loss: 0.018901430070400238\n",
      "Iteration: 2705/10000, Loss: 0.029765956103801727\n",
      "Iteration: 2706/10000, Loss: 0.022317375987768173\n",
      "Iteration: 2707/10000, Loss: 0.021632730960845947\n",
      "Iteration: 2708/10000, Loss: 0.02804432064294815\n",
      "Iteration: 2709/10000, Loss: 0.02093406952917576\n",
      "Iteration: 2710/10000, Loss: 0.02840476483106613\n",
      "Iteration: 2711/10000, Loss: 0.02292746677994728\n",
      "Iteration: 2712/10000, Loss: 0.01708589307963848\n",
      "Iteration: 2713/10000, Loss: 0.023711616173386574\n",
      "Iteration: 2714/10000, Loss: 0.022364182397723198\n",
      "Iteration: 2715/10000, Loss: 0.03400682285428047\n",
      "Iteration: 2716/10000, Loss: 0.031418316066265106\n",
      "Iteration: 2717/10000, Loss: 0.025703247636556625\n",
      "Iteration: 2718/10000, Loss: 0.028390435501933098\n",
      "Iteration: 2719/10000, Loss: 0.02179715596139431\n",
      "Iteration: 2720/10000, Loss: 0.026145432144403458\n",
      "Iteration: 2721/10000, Loss: 0.02150014601647854\n",
      "Iteration: 2722/10000, Loss: 0.02064088173210621\n",
      "Iteration: 2723/10000, Loss: 0.03092656098306179\n",
      "Iteration: 2724/10000, Loss: 0.017667196691036224\n",
      "Iteration: 2725/10000, Loss: 0.02803632989525795\n",
      "Iteration: 2726/10000, Loss: 0.020689405500888824\n",
      "Iteration: 2727/10000, Loss: 0.023791717365384102\n",
      "Iteration: 2728/10000, Loss: 0.023077890276908875\n",
      "Iteration: 2729/10000, Loss: 0.02305927500128746\n",
      "Iteration: 2730/10000, Loss: 0.01849927194416523\n",
      "Iteration: 2731/10000, Loss: 0.0192839577794075\n",
      "Iteration: 2732/10000, Loss: 0.030373945832252502\n",
      "Iteration: 2733/10000, Loss: 0.03445810452103615\n",
      "Iteration: 2734/10000, Loss: 0.02681911177933216\n",
      "Iteration: 2735/10000, Loss: 0.022400561720132828\n",
      "Iteration: 2736/10000, Loss: 0.020389080047607422\n",
      "Iteration: 2737/10000, Loss: 0.02494874596595764\n",
      "Iteration: 2738/10000, Loss: 0.025890134274959564\n",
      "Iteration: 2739/10000, Loss: 0.017402462661266327\n",
      "Iteration: 2740/10000, Loss: 0.02053370326757431\n",
      "Iteration: 2741/10000, Loss: 0.023527270182967186\n",
      "Iteration: 2742/10000, Loss: 0.03241521865129471\n",
      "Iteration: 2743/10000, Loss: 0.0179031603038311\n",
      "Iteration: 2744/10000, Loss: 0.023132825270295143\n",
      "Iteration: 2745/10000, Loss: 0.020479362457990646\n",
      "Iteration: 2746/10000, Loss: 0.030172036960721016\n",
      "Iteration: 2747/10000, Loss: 0.023248130455613136\n",
      "Iteration: 2748/10000, Loss: 0.01954955980181694\n",
      "Iteration: 2749/10000, Loss: 0.024517567828297615\n",
      "Iteration: 2750/10000, Loss: 0.021947046741843224\n",
      "Iteration: 2751/10000, Loss: 0.023929676041007042\n",
      "Iteration: 2752/10000, Loss: 0.02177596278488636\n",
      "Iteration: 2753/10000, Loss: 0.04288921877741814\n",
      "Iteration: 2754/10000, Loss: 0.02576429210603237\n",
      "Iteration: 2755/10000, Loss: 0.027159711346030235\n",
      "Iteration: 2756/10000, Loss: 0.025524018332362175\n",
      "Iteration: 2757/10000, Loss: 0.017473166808485985\n",
      "Iteration: 2758/10000, Loss: 0.03709615394473076\n",
      "Iteration: 2759/10000, Loss: 0.023750513792037964\n",
      "Iteration: 2760/10000, Loss: 0.024315739050507545\n",
      "Iteration: 2761/10000, Loss: 0.021640675142407417\n",
      "Iteration: 2762/10000, Loss: 0.01761261560022831\n",
      "Iteration: 2763/10000, Loss: 0.019093573093414307\n",
      "Iteration: 2764/10000, Loss: 0.02399340458214283\n",
      "Iteration: 2765/10000, Loss: 0.021112440153956413\n",
      "Iteration: 2766/10000, Loss: 0.022302966564893723\n",
      "Iteration: 2767/10000, Loss: 0.021407922729849815\n",
      "Iteration: 2768/10000, Loss: 0.03399033099412918\n",
      "Iteration: 2769/10000, Loss: 0.034087203443050385\n",
      "Iteration: 2770/10000, Loss: 0.022766483947634697\n",
      "Iteration: 2771/10000, Loss: 0.027683602645993233\n",
      "Iteration: 2772/10000, Loss: 0.02439519204199314\n",
      "Iteration: 2773/10000, Loss: 0.029625756666064262\n",
      "Iteration: 2774/10000, Loss: 0.026802849024534225\n",
      "Iteration: 2775/10000, Loss: 0.026445450261235237\n",
      "Iteration: 2776/10000, Loss: 0.02335020899772644\n",
      "Iteration: 2777/10000, Loss: 0.024011146277189255\n",
      "Iteration: 2778/10000, Loss: 0.02556125819683075\n",
      "Iteration: 2779/10000, Loss: 0.020197268575429916\n",
      "Iteration: 2780/10000, Loss: 0.021737966686487198\n",
      "Iteration: 2781/10000, Loss: 0.01972433552145958\n",
      "Iteration: 2782/10000, Loss: 0.025326453149318695\n",
      "Iteration: 2783/10000, Loss: 0.024797217920422554\n",
      "Iteration: 2784/10000, Loss: 0.02328462339937687\n",
      "Iteration: 2785/10000, Loss: 0.020944861695170403\n",
      "Iteration: 2786/10000, Loss: 0.017170177772641182\n",
      "Iteration: 2787/10000, Loss: 0.02315606363117695\n",
      "Iteration: 2788/10000, Loss: 0.024341892451047897\n",
      "Iteration: 2789/10000, Loss: 0.028128070756793022\n",
      "Iteration: 2790/10000, Loss: 0.019634341821074486\n",
      "Iteration: 2791/10000, Loss: 0.021326866000890732\n",
      "Iteration: 2792/10000, Loss: 0.02251177467405796\n",
      "Iteration: 2793/10000, Loss: 0.01683439314365387\n",
      "Iteration: 2794/10000, Loss: 0.01886623352766037\n",
      "Iteration: 2795/10000, Loss: 0.03632364049553871\n",
      "Iteration: 2796/10000, Loss: 0.020355060696601868\n",
      "Iteration: 2797/10000, Loss: 0.022300932556390762\n",
      "Iteration: 2798/10000, Loss: 0.02279326692223549\n",
      "Iteration: 2799/10000, Loss: 0.018158063292503357\n",
      "Iteration: 2800/10000, Loss: 0.028234200552105904\n",
      "Average test loss:  0.0029\n",
      "Iteration: 2801/10000, Loss: 0.02081834152340889\n",
      "Iteration: 2802/10000, Loss: 0.027388470247387886\n",
      "Iteration: 2803/10000, Loss: 0.020459823310375214\n",
      "Iteration: 2804/10000, Loss: 0.013527745380997658\n",
      "Iteration: 2805/10000, Loss: 0.02551582083106041\n",
      "Iteration: 2806/10000, Loss: 0.02994312345981598\n",
      "Iteration: 2807/10000, Loss: 0.026919275522232056\n",
      "Iteration: 2808/10000, Loss: 0.027944928035140038\n",
      "Iteration: 2809/10000, Loss: 0.013117244467139244\n",
      "Iteration: 2810/10000, Loss: 0.021099034696817398\n",
      "Iteration: 2811/10000, Loss: 0.02150905132293701\n",
      "Iteration: 2812/10000, Loss: 0.0268242284655571\n",
      "Iteration: 2813/10000, Loss: 0.0286923386156559\n",
      "Iteration: 2814/10000, Loss: 0.023123955354094505\n",
      "Iteration: 2815/10000, Loss: 0.029240451753139496\n",
      "Iteration: 2816/10000, Loss: 0.011228813789784908\n",
      "Iteration: 2817/10000, Loss: 0.021887216717004776\n",
      "Iteration: 2818/10000, Loss: 0.01944727450609207\n",
      "Iteration: 2819/10000, Loss: 0.029026610776782036\n",
      "Iteration: 2820/10000, Loss: 0.030197331681847572\n",
      "Iteration: 2821/10000, Loss: 0.028315097093582153\n",
      "Iteration: 2822/10000, Loss: 0.024966178461909294\n",
      "Iteration: 2823/10000, Loss: 0.02504037506878376\n",
      "Iteration: 2824/10000, Loss: 0.026057465001940727\n",
      "Iteration: 2825/10000, Loss: 0.01931547373533249\n",
      "Iteration: 2826/10000, Loss: 0.02819986641407013\n",
      "Iteration: 2827/10000, Loss: 0.024608703330159187\n",
      "Iteration: 2828/10000, Loss: 0.02012193761765957\n",
      "Iteration: 2829/10000, Loss: 0.02867129258811474\n",
      "Iteration: 2830/10000, Loss: 0.018079543486237526\n",
      "Iteration: 2831/10000, Loss: 0.023653754964470863\n",
      "Iteration: 2832/10000, Loss: 0.022550787776708603\n",
      "Iteration: 2833/10000, Loss: 0.033405378460884094\n",
      "Iteration: 2834/10000, Loss: 0.026668675243854523\n",
      "Iteration: 2835/10000, Loss: 0.015398209914565086\n",
      "Iteration: 2836/10000, Loss: 0.02464391104876995\n",
      "Iteration: 2837/10000, Loss: 0.023065704852342606\n",
      "Iteration: 2838/10000, Loss: 0.01565476320683956\n",
      "Iteration: 2839/10000, Loss: 0.02476327121257782\n",
      "Iteration: 2840/10000, Loss: 0.020564327016472816\n",
      "Iteration: 2841/10000, Loss: 0.020310353487730026\n",
      "Iteration: 2842/10000, Loss: 0.01915445737540722\n",
      "Iteration: 2843/10000, Loss: 0.01953987590968609\n",
      "Iteration: 2844/10000, Loss: 0.020636392757296562\n",
      "Iteration: 2845/10000, Loss: 0.02193167805671692\n",
      "Iteration: 2846/10000, Loss: 0.020050430670380592\n",
      "Iteration: 2847/10000, Loss: 0.022837884724140167\n",
      "Iteration: 2848/10000, Loss: 0.039711613208055496\n",
      "Iteration: 2849/10000, Loss: 0.03646817058324814\n",
      "Iteration: 2850/10000, Loss: 0.02870313636958599\n",
      "Iteration: 2851/10000, Loss: 0.022281769663095474\n",
      "Iteration: 2852/10000, Loss: 0.029065148904919624\n",
      "Iteration: 2853/10000, Loss: 0.025762422010302544\n",
      "Iteration: 2854/10000, Loss: 0.02390061505138874\n",
      "Iteration: 2855/10000, Loss: 0.021436471492052078\n",
      "Iteration: 2856/10000, Loss: 0.028825143352150917\n",
      "Iteration: 2857/10000, Loss: 0.027205821126699448\n",
      "Iteration: 2858/10000, Loss: 0.021685229614377022\n",
      "Iteration: 2859/10000, Loss: 0.01679489016532898\n",
      "Iteration: 2860/10000, Loss: 0.030043188482522964\n",
      "Iteration: 2861/10000, Loss: 0.02596406079828739\n",
      "Iteration: 2862/10000, Loss: 0.02909599058330059\n",
      "Iteration: 2863/10000, Loss: 0.02479713410139084\n",
      "Iteration: 2864/10000, Loss: 0.022103838622570038\n",
      "Iteration: 2865/10000, Loss: 0.019135015085339546\n",
      "Iteration: 2866/10000, Loss: 0.02147967927157879\n",
      "Iteration: 2867/10000, Loss: 0.015044903382658958\n",
      "Iteration: 2868/10000, Loss: 0.0258613433688879\n",
      "Iteration: 2869/10000, Loss: 0.019947288557887077\n",
      "Iteration: 2870/10000, Loss: 0.01919522136449814\n",
      "Iteration: 2871/10000, Loss: 0.02213997021317482\n",
      "Iteration: 2872/10000, Loss: 0.026326369494199753\n",
      "Iteration: 2873/10000, Loss: 0.01750294864177704\n",
      "Iteration: 2874/10000, Loss: 0.01862413063645363\n",
      "Iteration: 2875/10000, Loss: 0.022705771028995514\n",
      "Iteration: 2876/10000, Loss: 0.022639011964201927\n",
      "Iteration: 2877/10000, Loss: 0.028304407373070717\n",
      "Iteration: 2878/10000, Loss: 0.027152864262461662\n",
      "Iteration: 2879/10000, Loss: 0.023020083084702492\n",
      "Iteration: 2880/10000, Loss: 0.01832449994981289\n",
      "Iteration: 2881/10000, Loss: 0.02183263748884201\n",
      "Iteration: 2882/10000, Loss: 0.022224251180887222\n",
      "Iteration: 2883/10000, Loss: 0.016482029110193253\n",
      "Iteration: 2884/10000, Loss: 0.02836543880403042\n",
      "Iteration: 2885/10000, Loss: 0.014409145340323448\n",
      "Iteration: 2886/10000, Loss: 0.03946064040064812\n",
      "Iteration: 2887/10000, Loss: 0.022040938958525658\n",
      "Iteration: 2888/10000, Loss: 0.024428509175777435\n",
      "Iteration: 2889/10000, Loss: 0.02475583553314209\n",
      "Iteration: 2890/10000, Loss: 0.019489556550979614\n",
      "Iteration: 2891/10000, Loss: 0.02585126832127571\n",
      "Iteration: 2892/10000, Loss: 0.02172897942364216\n",
      "Iteration: 2893/10000, Loss: 0.01712685637176037\n",
      "Iteration: 2894/10000, Loss: 0.018215293064713478\n",
      "Iteration: 2895/10000, Loss: 0.023287320509552956\n",
      "Iteration: 2896/10000, Loss: 0.02208460494875908\n",
      "Iteration: 2897/10000, Loss: 0.025529004633426666\n",
      "Iteration: 2898/10000, Loss: 0.022628234699368477\n",
      "Iteration: 2899/10000, Loss: 0.01428407896310091\n",
      "Iteration: 2900/10000, Loss: 0.02018076553940773\n",
      "Average test loss:  0.0015\n",
      "Iteration: 2901/10000, Loss: 0.028023095801472664\n",
      "Iteration: 2902/10000, Loss: 0.022311735898256302\n",
      "Iteration: 2903/10000, Loss: 0.03005487471818924\n",
      "Iteration: 2904/10000, Loss: 0.024633746594190598\n",
      "Iteration: 2905/10000, Loss: 0.029067937284708023\n",
      "Iteration: 2906/10000, Loss: 0.021743878722190857\n",
      "Iteration: 2907/10000, Loss: 0.03084445931017399\n",
      "Iteration: 2908/10000, Loss: 0.026527632027864456\n",
      "Iteration: 2909/10000, Loss: 0.017414234578609467\n",
      "Iteration: 2910/10000, Loss: 0.01931856758892536\n",
      "Iteration: 2911/10000, Loss: 0.01961989514529705\n",
      "Iteration: 2912/10000, Loss: 0.01663918048143387\n",
      "Iteration: 2913/10000, Loss: 0.02247598208487034\n",
      "Iteration: 2914/10000, Loss: 0.025623459368944168\n",
      "Iteration: 2915/10000, Loss: 0.02223789691925049\n",
      "Iteration: 2916/10000, Loss: 0.020189281553030014\n",
      "Iteration: 2917/10000, Loss: 0.016468817368149757\n",
      "Iteration: 2918/10000, Loss: 0.01751471683382988\n",
      "Iteration: 2919/10000, Loss: 0.013439825735986233\n",
      "Iteration: 2920/10000, Loss: 0.020948199555277824\n",
      "Iteration: 2921/10000, Loss: 0.0285508930683136\n",
      "Iteration: 2922/10000, Loss: 0.02384096384048462\n",
      "Iteration: 2923/10000, Loss: 0.04188469424843788\n",
      "Iteration: 2924/10000, Loss: 0.016642138361930847\n",
      "Iteration: 2925/10000, Loss: 0.02830100990831852\n",
      "Iteration: 2926/10000, Loss: 0.02328186109662056\n",
      "Iteration: 2927/10000, Loss: 0.02410913072526455\n",
      "Iteration: 2928/10000, Loss: 0.02703092433512211\n",
      "Iteration: 2929/10000, Loss: 0.03219449892640114\n",
      "Iteration: 2930/10000, Loss: 0.031329117715358734\n",
      "Iteration: 2931/10000, Loss: 0.025999628007411957\n",
      "Iteration: 2932/10000, Loss: 0.027133429422974586\n",
      "Iteration: 2933/10000, Loss: 0.02942354790866375\n",
      "Iteration: 2934/10000, Loss: 0.023040201514959335\n",
      "Iteration: 2935/10000, Loss: 0.018323425203561783\n",
      "Iteration: 2936/10000, Loss: 0.022545138373970985\n",
      "Iteration: 2937/10000, Loss: 0.033829543739557266\n",
      "Iteration: 2938/10000, Loss: 0.02553512528538704\n",
      "Iteration: 2939/10000, Loss: 0.02175021544098854\n",
      "Iteration: 2940/10000, Loss: 0.02110361121594906\n",
      "Iteration: 2941/10000, Loss: 0.021078580990433693\n",
      "Iteration: 2942/10000, Loss: 0.017997244372963905\n",
      "Iteration: 2943/10000, Loss: 0.01573191210627556\n",
      "Iteration: 2944/10000, Loss: 0.02365812659263611\n",
      "Iteration: 2945/10000, Loss: 0.014967626892030239\n",
      "Iteration: 2946/10000, Loss: 0.01664610393345356\n",
      "Iteration: 2947/10000, Loss: 0.01939932070672512\n",
      "Iteration: 2948/10000, Loss: 0.02343873120844364\n",
      "Iteration: 2949/10000, Loss: 0.01837427169084549\n",
      "Iteration: 2950/10000, Loss: 0.020138250663876534\n",
      "Iteration: 2951/10000, Loss: 0.02781335450708866\n",
      "Iteration: 2952/10000, Loss: 0.01577013172209263\n",
      "Iteration: 2953/10000, Loss: 0.023626741021871567\n",
      "Iteration: 2954/10000, Loss: 0.019032714888453484\n",
      "Iteration: 2955/10000, Loss: 0.019364073872566223\n",
      "Iteration: 2956/10000, Loss: 0.016197578981518745\n",
      "Iteration: 2957/10000, Loss: 0.016548998653888702\n",
      "Iteration: 2958/10000, Loss: 0.02471453696489334\n",
      "Iteration: 2959/10000, Loss: 0.034368034452199936\n",
      "Iteration: 2960/10000, Loss: 0.0178899634629488\n",
      "Iteration: 2961/10000, Loss: 0.023145342245697975\n",
      "Iteration: 2962/10000, Loss: 0.01901790127158165\n",
      "Iteration: 2963/10000, Loss: 0.019072646275162697\n",
      "Iteration: 2964/10000, Loss: 0.022969089448451996\n",
      "Iteration: 2965/10000, Loss: 0.027346143499016762\n",
      "Iteration: 2966/10000, Loss: 0.020569726824760437\n",
      "Iteration: 2967/10000, Loss: 0.01793072372674942\n",
      "Iteration: 2968/10000, Loss: 0.017682604491710663\n",
      "Iteration: 2969/10000, Loss: 0.02347472682595253\n",
      "Iteration: 2970/10000, Loss: 0.03467578440904617\n",
      "Iteration: 2971/10000, Loss: 0.018280506134033203\n",
      "Iteration: 2972/10000, Loss: 0.015146139077842236\n",
      "Iteration: 2973/10000, Loss: 0.01716373860836029\n",
      "Iteration: 2974/10000, Loss: 0.020036516711115837\n",
      "Iteration: 2975/10000, Loss: 0.018392197787761688\n",
      "Iteration: 2976/10000, Loss: 0.025782741606235504\n",
      "Iteration: 2977/10000, Loss: 0.023824471980333328\n",
      "Iteration: 2978/10000, Loss: 0.02004200965166092\n",
      "Iteration: 2979/10000, Loss: 0.020043285563588142\n",
      "Iteration: 2980/10000, Loss: 0.036853063851594925\n",
      "Iteration: 2981/10000, Loss: 0.01929738186299801\n",
      "Iteration: 2982/10000, Loss: 0.01648368313908577\n",
      "Iteration: 2983/10000, Loss: 0.020921912044286728\n",
      "Iteration: 2984/10000, Loss: 0.021125076338648796\n",
      "Iteration: 2985/10000, Loss: 0.024059880524873734\n",
      "Iteration: 2986/10000, Loss: 0.027973201125860214\n",
      "Iteration: 2987/10000, Loss: 0.01809607446193695\n",
      "Iteration: 2988/10000, Loss: 0.024956751614809036\n",
      "Iteration: 2989/10000, Loss: 0.018769389018416405\n",
      "Iteration: 2990/10000, Loss: 0.019135983660817146\n",
      "Iteration: 2991/10000, Loss: 0.021879691630601883\n",
      "Iteration: 2992/10000, Loss: 0.018224133178591728\n",
      "Iteration: 2993/10000, Loss: 0.01903199590742588\n",
      "Iteration: 2994/10000, Loss: 0.02452130615711212\n",
      "Iteration: 2995/10000, Loss: 0.02736409567296505\n",
      "Iteration: 2996/10000, Loss: 0.02570725791156292\n",
      "Iteration: 2997/10000, Loss: 0.020797159522771835\n",
      "Iteration: 2998/10000, Loss: 0.01750153675675392\n",
      "Iteration: 2999/10000, Loss: 0.025301652029156685\n",
      "Iteration: 3000/10000, Loss: 0.01948925480246544\n",
      "Average test loss:  0.0020\n",
      "Iteration: 3001/10000, Loss: 0.019543396309018135\n",
      "Iteration: 3002/10000, Loss: 0.022568127140402794\n",
      "Iteration: 3003/10000, Loss: 0.02760976180434227\n",
      "Iteration: 3004/10000, Loss: 0.025132551789283752\n",
      "Iteration: 3005/10000, Loss: 0.028361069038510323\n",
      "Iteration: 3006/10000, Loss: 0.022837623953819275\n",
      "Iteration: 3007/10000, Loss: 0.026247061789035797\n",
      "Iteration: 3008/10000, Loss: 0.018529418855905533\n",
      "Iteration: 3009/10000, Loss: 0.034602269530296326\n",
      "Iteration: 3010/10000, Loss: 0.01974242553114891\n",
      "Iteration: 3011/10000, Loss: 0.02245183102786541\n",
      "Iteration: 3012/10000, Loss: 0.025768937543034554\n",
      "Iteration: 3013/10000, Loss: 0.01922614499926567\n",
      "Iteration: 3014/10000, Loss: 0.02722708322107792\n",
      "Iteration: 3015/10000, Loss: 0.020864317193627357\n",
      "Iteration: 3016/10000, Loss: 0.018683191388845444\n",
      "Iteration: 3017/10000, Loss: 0.022714504972100258\n",
      "Iteration: 3018/10000, Loss: 0.026774978265166283\n",
      "Iteration: 3019/10000, Loss: 0.02330370992422104\n",
      "Iteration: 3020/10000, Loss: 0.016206055879592896\n",
      "Iteration: 3021/10000, Loss: 0.03181486204266548\n",
      "Iteration: 3022/10000, Loss: 0.02228453755378723\n",
      "Iteration: 3023/10000, Loss: 0.02522234432399273\n",
      "Iteration: 3024/10000, Loss: 0.01846035197377205\n",
      "Iteration: 3025/10000, Loss: 0.030766455456614494\n",
      "Iteration: 3026/10000, Loss: 0.01903389021754265\n",
      "Iteration: 3027/10000, Loss: 0.025793416425585747\n",
      "Iteration: 3028/10000, Loss: 0.020428376272320747\n",
      "Iteration: 3029/10000, Loss: 0.03006681613624096\n",
      "Iteration: 3030/10000, Loss: 0.020322740077972412\n",
      "Iteration: 3031/10000, Loss: 0.02771839126944542\n",
      "Iteration: 3032/10000, Loss: 0.01936543732881546\n",
      "Iteration: 3033/10000, Loss: 0.03543517366051674\n",
      "Iteration: 3034/10000, Loss: 0.02109956368803978\n",
      "Iteration: 3035/10000, Loss: 0.019267400726675987\n",
      "Iteration: 3036/10000, Loss: 0.02241707220673561\n",
      "Iteration: 3037/10000, Loss: 0.020432399585843086\n",
      "Iteration: 3038/10000, Loss: 0.03392800688743591\n",
      "Iteration: 3039/10000, Loss: 0.018523911014199257\n",
      "Iteration: 3040/10000, Loss: 0.02276000566780567\n",
      "Iteration: 3041/10000, Loss: 0.020546015352010727\n",
      "Iteration: 3042/10000, Loss: 0.01879735291004181\n",
      "Iteration: 3043/10000, Loss: 0.029852261766791344\n",
      "Iteration: 3044/10000, Loss: 0.01819252409040928\n",
      "Iteration: 3045/10000, Loss: 0.02222379855811596\n",
      "Iteration: 3046/10000, Loss: 0.03366159275174141\n",
      "Iteration: 3047/10000, Loss: 0.032188598066568375\n",
      "Iteration: 3048/10000, Loss: 0.011764517053961754\n",
      "Iteration: 3049/10000, Loss: 0.027415292337536812\n",
      "Iteration: 3050/10000, Loss: 0.01192314364016056\n",
      "Iteration: 3051/10000, Loss: 0.02107199653983116\n",
      "Iteration: 3052/10000, Loss: 0.03041652962565422\n",
      "Iteration: 3053/10000, Loss: 0.01697780191898346\n",
      "Iteration: 3054/10000, Loss: 0.020103588700294495\n",
      "Iteration: 3055/10000, Loss: 0.02829860709607601\n",
      "Iteration: 3056/10000, Loss: 0.020645316690206528\n",
      "Iteration: 3057/10000, Loss: 0.022208964452147484\n",
      "Iteration: 3058/10000, Loss: 0.02242625690996647\n",
      "Iteration: 3059/10000, Loss: 0.01766199804842472\n",
      "Iteration: 3060/10000, Loss: 0.020527178421616554\n",
      "Iteration: 3061/10000, Loss: 0.018790684640407562\n",
      "Iteration: 3062/10000, Loss: 0.021296575665473938\n",
      "Iteration: 3063/10000, Loss: 0.024131404235959053\n",
      "Iteration: 3064/10000, Loss: 0.018519029021263123\n",
      "Iteration: 3065/10000, Loss: 0.031737133860588074\n",
      "Iteration: 3066/10000, Loss: 0.020028408616781235\n",
      "Iteration: 3067/10000, Loss: 0.014840219169855118\n",
      "Iteration: 3068/10000, Loss: 0.023403750732541084\n",
      "Iteration: 3069/10000, Loss: 0.0242103673517704\n",
      "Iteration: 3070/10000, Loss: 0.020541787147521973\n",
      "Iteration: 3071/10000, Loss: 0.019755013287067413\n",
      "Iteration: 3072/10000, Loss: 0.01565992273390293\n",
      "Iteration: 3073/10000, Loss: 0.01723240688443184\n",
      "Iteration: 3074/10000, Loss: 0.026101013645529747\n",
      "Iteration: 3075/10000, Loss: 0.014249018393456936\n",
      "Iteration: 3076/10000, Loss: 0.027884358540177345\n",
      "Iteration: 3077/10000, Loss: 0.015219666995108128\n",
      "Iteration: 3078/10000, Loss: 0.016430212184786797\n",
      "Iteration: 3079/10000, Loss: 0.021807514131069183\n",
      "Iteration: 3080/10000, Loss: 0.016476640477776527\n",
      "Iteration: 3081/10000, Loss: 0.020517423748970032\n",
      "Iteration: 3082/10000, Loss: 0.02322959527373314\n",
      "Iteration: 3083/10000, Loss: 0.02468365989625454\n",
      "Iteration: 3084/10000, Loss: 0.017331743612885475\n",
      "Iteration: 3085/10000, Loss: 0.02580949105322361\n",
      "Iteration: 3086/10000, Loss: 0.038494981825351715\n",
      "Iteration: 3087/10000, Loss: 0.01620744727551937\n",
      "Iteration: 3088/10000, Loss: 0.023781942203640938\n",
      "Iteration: 3089/10000, Loss: 0.02536797896027565\n",
      "Iteration: 3090/10000, Loss: 0.02035721391439438\n",
      "Iteration: 3091/10000, Loss: 0.013935839757323265\n",
      "Iteration: 3092/10000, Loss: 0.024522215127944946\n",
      "Iteration: 3093/10000, Loss: 0.029714282602071762\n",
      "Iteration: 3094/10000, Loss: 0.01838253065943718\n",
      "Iteration: 3095/10000, Loss: 0.031003879383206367\n",
      "Iteration: 3096/10000, Loss: 0.03558057174086571\n",
      "Iteration: 3097/10000, Loss: 0.031202886253595352\n",
      "Iteration: 3098/10000, Loss: 0.02739572897553444\n",
      "Iteration: 3099/10000, Loss: 0.027628932148218155\n",
      "Iteration: 3100/10000, Loss: 0.02478393167257309\n",
      "Average test loss:  0.0017\n",
      "Iteration: 3101/10000, Loss: 0.018813906237483025\n",
      "Iteration: 3102/10000, Loss: 0.013936720788478851\n",
      "Iteration: 3103/10000, Loss: 0.021386627107858658\n",
      "Iteration: 3104/10000, Loss: 0.02952943742275238\n",
      "Iteration: 3105/10000, Loss: 0.01073248591274023\n",
      "Iteration: 3106/10000, Loss: 0.026387184858322144\n",
      "Iteration: 3107/10000, Loss: 0.0291256345808506\n",
      "Iteration: 3108/10000, Loss: 0.01977860927581787\n",
      "Iteration: 3109/10000, Loss: 0.018545348197221756\n",
      "Iteration: 3110/10000, Loss: 0.016812484711408615\n",
      "Iteration: 3111/10000, Loss: 0.024152524769306183\n",
      "Iteration: 3112/10000, Loss: 0.024066755548119545\n",
      "Iteration: 3113/10000, Loss: 0.025790024548768997\n",
      "Iteration: 3114/10000, Loss: 0.016356179490685463\n",
      "Iteration: 3115/10000, Loss: 0.022464090958237648\n",
      "Iteration: 3116/10000, Loss: 0.023104317486286163\n",
      "Iteration: 3117/10000, Loss: 0.011063575744628906\n",
      "Iteration: 3118/10000, Loss: 0.021139031276106834\n",
      "Iteration: 3119/10000, Loss: 0.023015284910798073\n",
      "Iteration: 3120/10000, Loss: 0.02050100825726986\n",
      "Iteration: 3121/10000, Loss: 0.021231383085250854\n",
      "Iteration: 3122/10000, Loss: 0.02286066859960556\n",
      "Iteration: 3123/10000, Loss: 0.020699674263596535\n",
      "Iteration: 3124/10000, Loss: 0.018470121547579765\n",
      "Iteration: 3125/10000, Loss: 0.01724647544324398\n",
      "Iteration: 3126/10000, Loss: 0.020853949710726738\n",
      "Iteration: 3127/10000, Loss: 0.020703135058283806\n",
      "Iteration: 3128/10000, Loss: 0.017460279166698456\n",
      "Iteration: 3129/10000, Loss: 0.0180892962962389\n",
      "Iteration: 3130/10000, Loss: 0.025539632886648178\n",
      "Iteration: 3131/10000, Loss: 0.01797209121286869\n",
      "Iteration: 3132/10000, Loss: 0.01408170722424984\n",
      "Iteration: 3133/10000, Loss: 0.014802658930420876\n",
      "Iteration: 3134/10000, Loss: 0.018731936812400818\n",
      "Iteration: 3135/10000, Loss: 0.02057993970811367\n",
      "Iteration: 3136/10000, Loss: 0.036798883229494095\n",
      "Iteration: 3137/10000, Loss: 0.02438240498304367\n",
      "Iteration: 3138/10000, Loss: 0.021474897861480713\n",
      "Iteration: 3139/10000, Loss: 0.02386273257434368\n",
      "Iteration: 3140/10000, Loss: 0.019526422023773193\n",
      "Iteration: 3141/10000, Loss: 0.014872221276164055\n",
      "Iteration: 3142/10000, Loss: 0.02290336787700653\n",
      "Iteration: 3143/10000, Loss: 0.021062592044472694\n",
      "Iteration: 3144/10000, Loss: 0.019125105813145638\n",
      "Iteration: 3145/10000, Loss: 0.01798437535762787\n",
      "Iteration: 3146/10000, Loss: 0.02346031181514263\n",
      "Iteration: 3147/10000, Loss: 0.009831137023866177\n",
      "Iteration: 3148/10000, Loss: 0.020160628482699394\n",
      "Iteration: 3149/10000, Loss: 0.019823547452688217\n",
      "Iteration: 3150/10000, Loss: 0.019143760204315186\n",
      "Iteration: 3151/10000, Loss: 0.01621299982070923\n",
      "Iteration: 3152/10000, Loss: 0.021327165886759758\n",
      "Iteration: 3153/10000, Loss: 0.01792060397565365\n",
      "Iteration: 3154/10000, Loss: 0.028404220938682556\n",
      "Iteration: 3155/10000, Loss: 0.02354726381599903\n",
      "Iteration: 3156/10000, Loss: 0.022276801988482475\n",
      "Iteration: 3157/10000, Loss: 0.02321108803153038\n",
      "Iteration: 3158/10000, Loss: 0.02701333351433277\n",
      "Iteration: 3159/10000, Loss: 0.021058037877082825\n",
      "Iteration: 3160/10000, Loss: 0.022257201373577118\n",
      "Iteration: 3161/10000, Loss: 0.015254166908562183\n",
      "Iteration: 3162/10000, Loss: 0.013733827508985996\n",
      "Iteration: 3163/10000, Loss: 0.01542887557297945\n",
      "Iteration: 3164/10000, Loss: 0.013690914958715439\n",
      "Iteration: 3165/10000, Loss: 0.024709483608603477\n",
      "Iteration: 3166/10000, Loss: 0.024422841146588326\n",
      "Iteration: 3167/10000, Loss: 0.021359117701649666\n",
      "Iteration: 3168/10000, Loss: 0.020591525360941887\n",
      "Iteration: 3169/10000, Loss: 0.02037208341062069\n",
      "Iteration: 3170/10000, Loss: 0.02943587675690651\n",
      "Iteration: 3171/10000, Loss: 0.03288466855883598\n",
      "Iteration: 3172/10000, Loss: 0.02983127348124981\n",
      "Iteration: 3173/10000, Loss: 0.02682637982070446\n",
      "Iteration: 3174/10000, Loss: 0.032002177089452744\n",
      "Iteration: 3175/10000, Loss: 0.028882160782814026\n",
      "Iteration: 3176/10000, Loss: 0.026908494532108307\n",
      "Iteration: 3177/10000, Loss: 0.02506335638463497\n",
      "Iteration: 3178/10000, Loss: 0.017266301438212395\n",
      "Iteration: 3179/10000, Loss: 0.02507263608276844\n",
      "Iteration: 3180/10000, Loss: 0.011502985842525959\n",
      "Iteration: 3181/10000, Loss: 0.02446713298559189\n",
      "Iteration: 3182/10000, Loss: 0.015690069645643234\n",
      "Iteration: 3183/10000, Loss: 0.01788000762462616\n",
      "Iteration: 3184/10000, Loss: 0.0304569099098444\n",
      "Iteration: 3185/10000, Loss: 0.018732860684394836\n",
      "Iteration: 3186/10000, Loss: 0.019515693187713623\n",
      "Iteration: 3187/10000, Loss: 0.01879238151013851\n",
      "Iteration: 3188/10000, Loss: 0.017212580889463425\n",
      "Iteration: 3189/10000, Loss: 0.01837163232266903\n",
      "Iteration: 3190/10000, Loss: 0.021519219502806664\n",
      "Iteration: 3191/10000, Loss: 0.031222838908433914\n",
      "Iteration: 3192/10000, Loss: 0.02007903717458248\n",
      "Iteration: 3193/10000, Loss: 0.02608976699411869\n",
      "Iteration: 3194/10000, Loss: 0.0265717264264822\n",
      "Iteration: 3195/10000, Loss: 0.02389451116323471\n",
      "Iteration: 3196/10000, Loss: 0.031305111944675446\n",
      "Iteration: 3197/10000, Loss: 0.020690901204943657\n",
      "Iteration: 3198/10000, Loss: 0.0195639505982399\n",
      "Iteration: 3199/10000, Loss: 0.022262994199991226\n",
      "Iteration: 3200/10000, Loss: 0.024326661601662636\n",
      "Average test loss:  0.0024\n",
      "Iteration: 3201/10000, Loss: 0.022385679185390472\n",
      "Iteration: 3202/10000, Loss: 0.025553615763783455\n",
      "Iteration: 3203/10000, Loss: 0.01554702129215002\n",
      "Iteration: 3204/10000, Loss: 0.02545984834432602\n",
      "Iteration: 3205/10000, Loss: 0.01701733097434044\n",
      "Iteration: 3206/10000, Loss: 0.024005305022001266\n",
      "Iteration: 3207/10000, Loss: 0.018976600840687752\n",
      "Iteration: 3208/10000, Loss: 0.014751221984624863\n",
      "Iteration: 3209/10000, Loss: 0.013831484131515026\n",
      "Iteration: 3210/10000, Loss: 0.020202308893203735\n",
      "Iteration: 3211/10000, Loss: 0.028312021866440773\n",
      "Iteration: 3212/10000, Loss: 0.02099892683327198\n",
      "Iteration: 3213/10000, Loss: 0.020327258855104446\n",
      "Iteration: 3214/10000, Loss: 0.01651456579566002\n",
      "Iteration: 3215/10000, Loss: 0.026172246783971786\n",
      "Iteration: 3216/10000, Loss: 0.022737031802535057\n",
      "Iteration: 3217/10000, Loss: 0.026300281286239624\n",
      "Iteration: 3218/10000, Loss: 0.014296924695372581\n",
      "Iteration: 3219/10000, Loss: 0.02143421396613121\n",
      "Iteration: 3220/10000, Loss: 0.024859433993697166\n",
      "Iteration: 3221/10000, Loss: 0.02066006511449814\n",
      "Iteration: 3222/10000, Loss: 0.013809413649141788\n",
      "Iteration: 3223/10000, Loss: 0.029994744807481766\n",
      "Iteration: 3224/10000, Loss: 0.0379401370882988\n",
      "Iteration: 3225/10000, Loss: 0.029767325147986412\n",
      "Iteration: 3226/10000, Loss: 0.014064980670809746\n",
      "Iteration: 3227/10000, Loss: 0.02123059518635273\n",
      "Iteration: 3228/10000, Loss: 0.020759114995598793\n",
      "Iteration: 3229/10000, Loss: 0.021214453503489494\n",
      "Iteration: 3230/10000, Loss: 0.022610362619161606\n",
      "Iteration: 3231/10000, Loss: 0.019957320764660835\n",
      "Iteration: 3232/10000, Loss: 0.023256804794073105\n",
      "Iteration: 3233/10000, Loss: 0.019664183259010315\n",
      "Iteration: 3234/10000, Loss: 0.03381146490573883\n",
      "Iteration: 3235/10000, Loss: 0.022819699719548225\n",
      "Iteration: 3236/10000, Loss: 0.02089674212038517\n",
      "Iteration: 3237/10000, Loss: 0.02026699110865593\n",
      "Iteration: 3238/10000, Loss: 0.023547496646642685\n",
      "Iteration: 3239/10000, Loss: 0.027694905176758766\n",
      "Iteration: 3240/10000, Loss: 0.0279660876840353\n",
      "Iteration: 3241/10000, Loss: 0.024956881999969482\n",
      "Iteration: 3242/10000, Loss: 0.017362385988235474\n",
      "Iteration: 3243/10000, Loss: 0.01719377562403679\n",
      "Iteration: 3244/10000, Loss: 0.0190225001424551\n",
      "Iteration: 3245/10000, Loss: 0.01657077856361866\n",
      "Iteration: 3246/10000, Loss: 0.012927224859595299\n",
      "Iteration: 3247/10000, Loss: 0.018124639987945557\n",
      "Iteration: 3248/10000, Loss: 0.013971231877803802\n",
      "Iteration: 3249/10000, Loss: 0.020463017746806145\n",
      "Iteration: 3250/10000, Loss: 0.019407454878091812\n",
      "Iteration: 3251/10000, Loss: 0.028712976723909378\n",
      "Iteration: 3252/10000, Loss: 0.028871919959783554\n",
      "Iteration: 3253/10000, Loss: 0.013660263270139694\n",
      "Iteration: 3254/10000, Loss: 0.020389925688505173\n",
      "Iteration: 3255/10000, Loss: 0.038737572729587555\n",
      "Iteration: 3256/10000, Loss: 0.023047441616654396\n",
      "Iteration: 3257/10000, Loss: 0.02234349399805069\n",
      "Iteration: 3258/10000, Loss: 0.017777863889932632\n",
      "Iteration: 3259/10000, Loss: 0.03331328555941582\n",
      "Iteration: 3260/10000, Loss: 0.02250528894364834\n",
      "Iteration: 3261/10000, Loss: 0.017628813162446022\n",
      "Iteration: 3262/10000, Loss: 0.020989544689655304\n",
      "Iteration: 3263/10000, Loss: 0.021667055785655975\n",
      "Iteration: 3264/10000, Loss: 0.016491519287228584\n",
      "Iteration: 3265/10000, Loss: 0.021376149728894234\n",
      "Iteration: 3266/10000, Loss: 0.0216781385242939\n",
      "Iteration: 3267/10000, Loss: 0.016742421314120293\n",
      "Iteration: 3268/10000, Loss: 0.015338053926825523\n",
      "Iteration: 3269/10000, Loss: 0.021760551258921623\n",
      "Iteration: 3270/10000, Loss: 0.026003411039710045\n",
      "Iteration: 3271/10000, Loss: 0.014250332489609718\n",
      "Iteration: 3272/10000, Loss: 0.022231964394450188\n",
      "Iteration: 3273/10000, Loss: 0.011603043414652348\n",
      "Iteration: 3274/10000, Loss: 0.024522703140974045\n",
      "Iteration: 3275/10000, Loss: 0.018664328381419182\n",
      "Iteration: 3276/10000, Loss: 0.017229590564966202\n",
      "Iteration: 3277/10000, Loss: 0.020311828702688217\n",
      "Iteration: 3278/10000, Loss: 0.025856154039502144\n",
      "Iteration: 3279/10000, Loss: 0.015651868656277657\n",
      "Iteration: 3280/10000, Loss: 0.014848858118057251\n",
      "Iteration: 3281/10000, Loss: 0.02269032411277294\n",
      "Iteration: 3282/10000, Loss: 0.022049877792596817\n",
      "Iteration: 3283/10000, Loss: 0.02193700149655342\n",
      "Iteration: 3284/10000, Loss: 0.018622111529111862\n",
      "Iteration: 3285/10000, Loss: 0.015178642235696316\n",
      "Iteration: 3286/10000, Loss: 0.012720007449388504\n",
      "Iteration: 3287/10000, Loss: 0.025676487013697624\n",
      "Iteration: 3288/10000, Loss: 0.014931353740394115\n",
      "Iteration: 3289/10000, Loss: 0.02139567956328392\n",
      "Iteration: 3290/10000, Loss: 0.03347727283835411\n",
      "Iteration: 3291/10000, Loss: 0.01909721828997135\n",
      "Iteration: 3292/10000, Loss: 0.015950242057442665\n",
      "Iteration: 3293/10000, Loss: 0.020594969391822815\n",
      "Iteration: 3294/10000, Loss: 0.017685530707240105\n",
      "Iteration: 3295/10000, Loss: 0.02708134800195694\n",
      "Iteration: 3296/10000, Loss: 0.020509611815214157\n",
      "Iteration: 3297/10000, Loss: 0.016806339845061302\n",
      "Iteration: 3298/10000, Loss: 0.01964588835835457\n",
      "Iteration: 3299/10000, Loss: 0.024821225553750992\n",
      "Iteration: 3300/10000, Loss: 0.024859631434082985\n",
      "Average test loss:  0.0028\n",
      "Iteration: 3301/10000, Loss: 0.0217989981174469\n",
      "Iteration: 3302/10000, Loss: 0.021621951833367348\n",
      "Iteration: 3303/10000, Loss: 0.017245588824152946\n",
      "Iteration: 3304/10000, Loss: 0.017398109659552574\n",
      "Iteration: 3305/10000, Loss: 0.029212752357125282\n",
      "Iteration: 3306/10000, Loss: 0.01961449533700943\n",
      "Iteration: 3307/10000, Loss: 0.01216303464025259\n",
      "Iteration: 3308/10000, Loss: 0.019776279106736183\n",
      "Iteration: 3309/10000, Loss: 0.01721511036157608\n",
      "Iteration: 3310/10000, Loss: 0.01895626075565815\n",
      "Iteration: 3311/10000, Loss: 0.027013318613171577\n",
      "Iteration: 3312/10000, Loss: 0.02819383144378662\n",
      "Iteration: 3313/10000, Loss: 0.02405500039458275\n",
      "Iteration: 3314/10000, Loss: 0.02661079540848732\n",
      "Iteration: 3315/10000, Loss: 0.015295916236937046\n",
      "Iteration: 3316/10000, Loss: 0.014688543044030666\n",
      "Iteration: 3317/10000, Loss: 0.024205109104514122\n",
      "Iteration: 3318/10000, Loss: 0.01993737183511257\n",
      "Iteration: 3319/10000, Loss: 0.0146526750177145\n",
      "Iteration: 3320/10000, Loss: 0.020769838243722916\n",
      "Iteration: 3321/10000, Loss: 0.011863486841320992\n",
      "Iteration: 3322/10000, Loss: 0.008738230913877487\n",
      "Iteration: 3323/10000, Loss: 0.017785947769880295\n",
      "Iteration: 3324/10000, Loss: 0.022587807849049568\n",
      "Iteration: 3325/10000, Loss: 0.030657587572932243\n",
      "Iteration: 3326/10000, Loss: 0.015182777307927608\n",
      "Iteration: 3327/10000, Loss: 0.02028375118970871\n",
      "Iteration: 3328/10000, Loss: 0.02679603174328804\n",
      "Iteration: 3329/10000, Loss: 0.019107183441519737\n",
      "Iteration: 3330/10000, Loss: 0.0162318404763937\n",
      "Iteration: 3331/10000, Loss: 0.01933695748448372\n",
      "Iteration: 3332/10000, Loss: 0.0183420367538929\n",
      "Iteration: 3333/10000, Loss: 0.02013123407959938\n",
      "Iteration: 3334/10000, Loss: 0.0209647323936224\n",
      "Iteration: 3335/10000, Loss: 0.013865306042134762\n",
      "Iteration: 3336/10000, Loss: 0.02002742514014244\n",
      "Iteration: 3337/10000, Loss: 0.02201138436794281\n",
      "Iteration: 3338/10000, Loss: 0.018210584297776222\n",
      "Iteration: 3339/10000, Loss: 0.02629978395998478\n",
      "Iteration: 3340/10000, Loss: 0.013864916749298573\n",
      "Iteration: 3341/10000, Loss: 0.027002347633242607\n",
      "Iteration: 3342/10000, Loss: 0.01987290009856224\n",
      "Iteration: 3343/10000, Loss: 0.016247278079390526\n",
      "Iteration: 3344/10000, Loss: 0.02078992687165737\n",
      "Iteration: 3345/10000, Loss: 0.016448145732283592\n",
      "Iteration: 3346/10000, Loss: 0.022029617801308632\n",
      "Iteration: 3347/10000, Loss: 0.027965495362877846\n",
      "Iteration: 3348/10000, Loss: 0.02179708331823349\n",
      "Iteration: 3349/10000, Loss: 0.027064282447099686\n",
      "Iteration: 3350/10000, Loss: 0.023808611556887627\n",
      "Iteration: 3351/10000, Loss: 0.017583515495061874\n",
      "Iteration: 3352/10000, Loss: 0.029920347034931183\n",
      "Iteration: 3353/10000, Loss: 0.018393781036138535\n",
      "Iteration: 3354/10000, Loss: 0.018219653517007828\n",
      "Iteration: 3355/10000, Loss: 0.018316878005862236\n",
      "Iteration: 3356/10000, Loss: 0.027961915358901024\n",
      "Iteration: 3357/10000, Loss: 0.019957736134529114\n",
      "Iteration: 3358/10000, Loss: 0.01909804157912731\n",
      "Iteration: 3359/10000, Loss: 0.02696680650115013\n",
      "Iteration: 3360/10000, Loss: 0.017348695546388626\n",
      "Iteration: 3361/10000, Loss: 0.02677275985479355\n",
      "Iteration: 3362/10000, Loss: 0.018998511135578156\n",
      "Iteration: 3363/10000, Loss: 0.023828938603401184\n",
      "Iteration: 3364/10000, Loss: 0.01691523939371109\n",
      "Iteration: 3365/10000, Loss: 0.01935713179409504\n",
      "Iteration: 3366/10000, Loss: 0.01631329581141472\n",
      "Iteration: 3367/10000, Loss: 0.014871851541101933\n",
      "Iteration: 3368/10000, Loss: 0.015272063203155994\n",
      "Iteration: 3369/10000, Loss: 0.02438836544752121\n",
      "Iteration: 3370/10000, Loss: 0.014387081377208233\n",
      "Iteration: 3371/10000, Loss: 0.02063240483403206\n",
      "Iteration: 3372/10000, Loss: 0.016094837337732315\n",
      "Iteration: 3373/10000, Loss: 0.024854592978954315\n",
      "Iteration: 3374/10000, Loss: 0.026167014613747597\n",
      "Iteration: 3375/10000, Loss: 0.017794812098145485\n",
      "Iteration: 3376/10000, Loss: 0.018004432320594788\n",
      "Iteration: 3377/10000, Loss: 0.01605827547609806\n",
      "Iteration: 3378/10000, Loss: 0.01856575906276703\n",
      "Iteration: 3379/10000, Loss: 0.027316806837916374\n",
      "Iteration: 3380/10000, Loss: 0.016929971054196358\n",
      "Iteration: 3381/10000, Loss: 0.01763935573399067\n",
      "Iteration: 3382/10000, Loss: 0.02917042002081871\n",
      "Iteration: 3383/10000, Loss: 0.011160125955939293\n",
      "Iteration: 3384/10000, Loss: 0.018075594678521156\n",
      "Iteration: 3385/10000, Loss: 0.026755638420581818\n",
      "Iteration: 3386/10000, Loss: 0.015615169890224934\n",
      "Iteration: 3387/10000, Loss: 0.02010023035109043\n",
      "Iteration: 3388/10000, Loss: 0.017725501209497452\n",
      "Iteration: 3389/10000, Loss: 0.015751691535115242\n",
      "Iteration: 3390/10000, Loss: 0.016706909984350204\n",
      "Iteration: 3391/10000, Loss: 0.016302920877933502\n",
      "Iteration: 3392/10000, Loss: 0.02354980632662773\n",
      "Iteration: 3393/10000, Loss: 0.023078899830579758\n",
      "Iteration: 3394/10000, Loss: 0.02380686067044735\n",
      "Iteration: 3395/10000, Loss: 0.018183579668402672\n",
      "Iteration: 3396/10000, Loss: 0.011658331379294395\n",
      "Iteration: 3397/10000, Loss: 0.02225915528833866\n",
      "Iteration: 3398/10000, Loss: 0.01657092571258545\n",
      "Iteration: 3399/10000, Loss: 0.020677369087934494\n",
      "Iteration: 3400/10000, Loss: 0.026801414787769318\n",
      "Average test loss:  0.0036\n",
      "Iteration: 3401/10000, Loss: 0.028119945898652077\n",
      "Iteration: 3402/10000, Loss: 0.023386022076010704\n",
      "Iteration: 3403/10000, Loss: 0.016851380467414856\n",
      "Iteration: 3404/10000, Loss: 0.016576819121837616\n",
      "Iteration: 3405/10000, Loss: 0.0185600146651268\n",
      "Iteration: 3406/10000, Loss: 0.02527575008571148\n",
      "Iteration: 3407/10000, Loss: 0.02225063182413578\n",
      "Iteration: 3408/10000, Loss: 0.01717406138777733\n",
      "Iteration: 3409/10000, Loss: 0.018069466575980186\n",
      "Iteration: 3410/10000, Loss: 0.018171966075897217\n",
      "Iteration: 3411/10000, Loss: 0.01614801026880741\n",
      "Iteration: 3412/10000, Loss: 0.012965633533895016\n",
      "Iteration: 3413/10000, Loss: 0.022072110325098038\n",
      "Iteration: 3414/10000, Loss: 0.023175684735178947\n",
      "Iteration: 3415/10000, Loss: 0.01717228814959526\n",
      "Iteration: 3416/10000, Loss: 0.011680105701088905\n",
      "Iteration: 3417/10000, Loss: 0.020232435315847397\n",
      "Iteration: 3418/10000, Loss: 0.031112506985664368\n",
      "Iteration: 3419/10000, Loss: 0.02096799574792385\n",
      "Iteration: 3420/10000, Loss: 0.022308407351374626\n",
      "Iteration: 3421/10000, Loss: 0.01660013198852539\n",
      "Iteration: 3422/10000, Loss: 0.014132796786725521\n",
      "Iteration: 3423/10000, Loss: 0.01719609834253788\n",
      "Iteration: 3424/10000, Loss: 0.01811443269252777\n",
      "Iteration: 3425/10000, Loss: 0.02368815988302231\n",
      "Iteration: 3426/10000, Loss: 0.019522426649928093\n",
      "Iteration: 3427/10000, Loss: 0.022381629794836044\n",
      "Iteration: 3428/10000, Loss: 0.022173268720507622\n",
      "Iteration: 3429/10000, Loss: 0.01202333439141512\n",
      "Iteration: 3430/10000, Loss: 0.023444751277565956\n",
      "Iteration: 3431/10000, Loss: 0.010133814066648483\n",
      "Iteration: 3432/10000, Loss: 0.02039686031639576\n",
      "Iteration: 3433/10000, Loss: 0.020431825891137123\n",
      "Iteration: 3434/10000, Loss: 0.026958521455526352\n",
      "Iteration: 3435/10000, Loss: 0.01363669615238905\n",
      "Iteration: 3436/10000, Loss: 0.018166648223996162\n",
      "Iteration: 3437/10000, Loss: 0.029475856572389603\n",
      "Iteration: 3438/10000, Loss: 0.01917991228401661\n",
      "Iteration: 3439/10000, Loss: 0.01980968751013279\n",
      "Iteration: 3440/10000, Loss: 0.01638087071478367\n",
      "Iteration: 3441/10000, Loss: 0.017199024558067322\n",
      "Iteration: 3442/10000, Loss: 0.021797440946102142\n",
      "Iteration: 3443/10000, Loss: 0.02445465326309204\n",
      "Iteration: 3444/10000, Loss: 0.015055042691528797\n",
      "Iteration: 3445/10000, Loss: 0.026999037712812424\n",
      "Iteration: 3446/10000, Loss: 0.016200633719563484\n",
      "Iteration: 3447/10000, Loss: 0.017066650092601776\n",
      "Iteration: 3448/10000, Loss: 0.018092229962348938\n",
      "Iteration: 3449/10000, Loss: 0.01359048392623663\n",
      "Iteration: 3450/10000, Loss: 0.018713874742388725\n",
      "Iteration: 3451/10000, Loss: 0.015016196295619011\n",
      "Iteration: 3452/10000, Loss: 0.02203669212758541\n",
      "Iteration: 3453/10000, Loss: 0.023170089349150658\n",
      "Iteration: 3454/10000, Loss: 0.014431139454245567\n",
      "Iteration: 3455/10000, Loss: 0.02526252344250679\n",
      "Iteration: 3456/10000, Loss: 0.01717287115752697\n",
      "Iteration: 3457/10000, Loss: 0.021829575300216675\n",
      "Iteration: 3458/10000, Loss: 0.015136594884097576\n",
      "Iteration: 3459/10000, Loss: 0.017454056069254875\n",
      "Iteration: 3460/10000, Loss: 0.016861841082572937\n",
      "Iteration: 3461/10000, Loss: 0.016100870445370674\n",
      "Iteration: 3462/10000, Loss: 0.013999145478010178\n",
      "Iteration: 3463/10000, Loss: 0.021316127851605415\n",
      "Iteration: 3464/10000, Loss: 0.02479783073067665\n",
      "Iteration: 3465/10000, Loss: 0.023363308981060982\n",
      "Iteration: 3466/10000, Loss: 0.02214241400361061\n",
      "Iteration: 3467/10000, Loss: 0.02282540127635002\n",
      "Iteration: 3468/10000, Loss: 0.01727413944900036\n",
      "Iteration: 3469/10000, Loss: 0.019169313833117485\n",
      "Iteration: 3470/10000, Loss: 0.016189418733119965\n",
      "Iteration: 3471/10000, Loss: 0.01948358118534088\n",
      "Iteration: 3472/10000, Loss: 0.023514430969953537\n",
      "Iteration: 3473/10000, Loss: 0.027115602046251297\n",
      "Iteration: 3474/10000, Loss: 0.01721147820353508\n",
      "Iteration: 3475/10000, Loss: 0.018075404688715935\n",
      "Iteration: 3476/10000, Loss: 0.03229966014623642\n",
      "Iteration: 3477/10000, Loss: 0.019212694838643074\n",
      "Iteration: 3478/10000, Loss: 0.01862482726573944\n",
      "Iteration: 3479/10000, Loss: 0.01624445430934429\n",
      "Iteration: 3480/10000, Loss: 0.013252580538392067\n",
      "Iteration: 3481/10000, Loss: 0.011652668006718159\n",
      "Iteration: 3482/10000, Loss: 0.011458411812782288\n",
      "Iteration: 3483/10000, Loss: 0.023613300174474716\n",
      "Iteration: 3484/10000, Loss: 0.021697930991649628\n",
      "Iteration: 3485/10000, Loss: 0.011560041457414627\n",
      "Iteration: 3486/10000, Loss: 0.02520652301609516\n",
      "Iteration: 3487/10000, Loss: 0.014607804827392101\n",
      "Iteration: 3488/10000, Loss: 0.026338685303926468\n",
      "Iteration: 3489/10000, Loss: 0.015439450740814209\n",
      "Iteration: 3490/10000, Loss: 0.02436027117073536\n",
      "Iteration: 3491/10000, Loss: 0.018654840067029\n",
      "Iteration: 3492/10000, Loss: 0.022473812103271484\n",
      "Iteration: 3493/10000, Loss: 0.010780701413750648\n",
      "Iteration: 3494/10000, Loss: 0.027434300631284714\n",
      "Iteration: 3495/10000, Loss: 0.01716437377035618\n",
      "Iteration: 3496/10000, Loss: 0.015471028164029121\n",
      "Iteration: 3497/10000, Loss: 0.020566875115036964\n",
      "Iteration: 3498/10000, Loss: 0.02297148108482361\n",
      "Iteration: 3499/10000, Loss: 0.01725258119404316\n",
      "Iteration: 3500/10000, Loss: 0.023359376937150955\n",
      "Average test loss:  0.0022\n",
      "Iteration: 3501/10000, Loss: 0.02221294678747654\n",
      "Iteration: 3502/10000, Loss: 0.017283014953136444\n",
      "Iteration: 3503/10000, Loss: 0.019876115024089813\n",
      "Iteration: 3504/10000, Loss: 0.021624937653541565\n",
      "Iteration: 3505/10000, Loss: 0.019263077527284622\n",
      "Iteration: 3506/10000, Loss: 0.018644049763679504\n",
      "Iteration: 3507/10000, Loss: 0.021053941920399666\n",
      "Iteration: 3508/10000, Loss: 0.011085780337452888\n",
      "Iteration: 3509/10000, Loss: 0.015613468363881111\n",
      "Iteration: 3510/10000, Loss: 0.01519862748682499\n",
      "Iteration: 3511/10000, Loss: 0.01302253920584917\n",
      "Iteration: 3512/10000, Loss: 0.012848139740526676\n",
      "Iteration: 3513/10000, Loss: 0.02870970591902733\n",
      "Iteration: 3514/10000, Loss: 0.021292710676789284\n",
      "Iteration: 3515/10000, Loss: 0.022187691181898117\n",
      "Iteration: 3516/10000, Loss: 0.018518924713134766\n",
      "Iteration: 3517/10000, Loss: 0.021915730088949203\n",
      "Iteration: 3518/10000, Loss: 0.023468652740120888\n",
      "Iteration: 3519/10000, Loss: 0.016790887340903282\n",
      "Iteration: 3520/10000, Loss: 0.022662771865725517\n",
      "Iteration: 3521/10000, Loss: 0.01569279097020626\n",
      "Iteration: 3522/10000, Loss: 0.03615163266658783\n",
      "Iteration: 3523/10000, Loss: 0.024735232815146446\n",
      "Iteration: 3524/10000, Loss: 0.02143288590013981\n",
      "Iteration: 3525/10000, Loss: 0.01757890172302723\n",
      "Iteration: 3526/10000, Loss: 0.03192558139562607\n",
      "Iteration: 3527/10000, Loss: 0.019885791465640068\n",
      "Iteration: 3528/10000, Loss: 0.01793983206152916\n",
      "Iteration: 3529/10000, Loss: 0.01759493164718151\n",
      "Iteration: 3530/10000, Loss: 0.0219621192663908\n",
      "Iteration: 3531/10000, Loss: 0.02095794305205345\n",
      "Iteration: 3532/10000, Loss: 0.014450613409280777\n",
      "Iteration: 3533/10000, Loss: 0.017849482595920563\n",
      "Iteration: 3534/10000, Loss: 0.01824711635708809\n",
      "Iteration: 3535/10000, Loss: 0.024383043870329857\n",
      "Iteration: 3536/10000, Loss: 0.020174916833639145\n",
      "Iteration: 3537/10000, Loss: 0.014197370037436485\n",
      "Iteration: 3538/10000, Loss: 0.01421932689845562\n",
      "Iteration: 3539/10000, Loss: 0.01275313924998045\n",
      "Iteration: 3540/10000, Loss: 0.010231577791273594\n",
      "Iteration: 3541/10000, Loss: 0.02404244989156723\n",
      "Iteration: 3542/10000, Loss: 0.023867210373282433\n",
      "Iteration: 3543/10000, Loss: 0.019088800996541977\n",
      "Iteration: 3544/10000, Loss: 0.023678673431277275\n",
      "Iteration: 3545/10000, Loss: 0.02087080478668213\n",
      "Iteration: 3546/10000, Loss: 0.015135563910007477\n",
      "Iteration: 3547/10000, Loss: 0.026363003998994827\n",
      "Iteration: 3548/10000, Loss: 0.01652228832244873\n",
      "Iteration: 3549/10000, Loss: 0.019419634714722633\n",
      "Iteration: 3550/10000, Loss: 0.017768340185284615\n",
      "Iteration: 3551/10000, Loss: 0.021455025300383568\n",
      "Iteration: 3552/10000, Loss: 0.01759115234017372\n",
      "Iteration: 3553/10000, Loss: 0.015627974644303322\n",
      "Iteration: 3554/10000, Loss: 0.013705659657716751\n",
      "Iteration: 3555/10000, Loss: 0.018531540408730507\n",
      "Iteration: 3556/10000, Loss: 0.030028047040104866\n",
      "Iteration: 3557/10000, Loss: 0.016778431832790375\n",
      "Iteration: 3558/10000, Loss: 0.011120691895484924\n",
      "Iteration: 3559/10000, Loss: 0.014428272843360901\n",
      "Iteration: 3560/10000, Loss: 0.012684062123298645\n",
      "Iteration: 3561/10000, Loss: 0.016538778319954872\n",
      "Iteration: 3562/10000, Loss: 0.01491580717265606\n",
      "Iteration: 3563/10000, Loss: 0.020817182958126068\n",
      "Iteration: 3564/10000, Loss: 0.021163007244467735\n",
      "Iteration: 3565/10000, Loss: 0.018540922552347183\n",
      "Iteration: 3566/10000, Loss: 0.019277876242995262\n",
      "Iteration: 3567/10000, Loss: 0.018836069852113724\n",
      "Iteration: 3568/10000, Loss: 0.012552186846733093\n",
      "Iteration: 3569/10000, Loss: 0.01888299360871315\n",
      "Iteration: 3570/10000, Loss: 0.019937945529818535\n",
      "Iteration: 3571/10000, Loss: 0.024587111547589302\n",
      "Iteration: 3572/10000, Loss: 0.022938314825296402\n",
      "Iteration: 3573/10000, Loss: 0.021372299641370773\n",
      "Iteration: 3574/10000, Loss: 0.013673368841409683\n",
      "Iteration: 3575/10000, Loss: 0.021207895129919052\n",
      "Iteration: 3576/10000, Loss: 0.015941528603434563\n",
      "Iteration: 3577/10000, Loss: 0.023040739819407463\n",
      "Iteration: 3578/10000, Loss: 0.009828138165175915\n",
      "Iteration: 3579/10000, Loss: 0.022291310131549835\n",
      "Iteration: 3580/10000, Loss: 0.021497000008821487\n",
      "Iteration: 3581/10000, Loss: 0.021221410483121872\n",
      "Iteration: 3582/10000, Loss: 0.018478574231266975\n",
      "Iteration: 3583/10000, Loss: 0.022529272362589836\n",
      "Iteration: 3584/10000, Loss: 0.013509871438145638\n",
      "Iteration: 3585/10000, Loss: 0.02290414460003376\n",
      "Iteration: 3586/10000, Loss: 0.019015708938241005\n",
      "Iteration: 3587/10000, Loss: 0.017966575920581818\n",
      "Iteration: 3588/10000, Loss: 0.020109130069613457\n",
      "Iteration: 3589/10000, Loss: 0.01563773863017559\n",
      "Iteration: 3590/10000, Loss: 0.018016427755355835\n",
      "Iteration: 3591/10000, Loss: 0.011626326479017735\n",
      "Iteration: 3592/10000, Loss: 0.019541265442967415\n",
      "Iteration: 3593/10000, Loss: 0.023814037442207336\n",
      "Iteration: 3594/10000, Loss: 0.020608529448509216\n",
      "Iteration: 3595/10000, Loss: 0.01966840587556362\n",
      "Iteration: 3596/10000, Loss: 0.01987445540726185\n",
      "Iteration: 3597/10000, Loss: 0.018633253872394562\n",
      "Iteration: 3598/10000, Loss: 0.01526813954114914\n",
      "Iteration: 3599/10000, Loss: 0.01867450214922428\n",
      "Iteration: 3600/10000, Loss: 0.015446385368704796\n",
      "Average test loss:  0.0025\n",
      "Iteration: 3601/10000, Loss: 0.014884538017213345\n",
      "Iteration: 3602/10000, Loss: 0.024048732593655586\n",
      "Iteration: 3603/10000, Loss: 0.013138573616743088\n",
      "Iteration: 3604/10000, Loss: 0.01823340728878975\n",
      "Iteration: 3605/10000, Loss: 0.01571013033390045\n",
      "Iteration: 3606/10000, Loss: 0.02681688964366913\n",
      "Iteration: 3607/10000, Loss: 0.022301752120256424\n",
      "Iteration: 3608/10000, Loss: 0.017914054915308952\n",
      "Iteration: 3609/10000, Loss: 0.012478013522922993\n",
      "Iteration: 3610/10000, Loss: 0.014571244828402996\n",
      "Iteration: 3611/10000, Loss: 0.015645282343029976\n",
      "Iteration: 3612/10000, Loss: 0.01643088459968567\n",
      "Iteration: 3613/10000, Loss: 0.019745253026485443\n",
      "Iteration: 3614/10000, Loss: 0.01185368187725544\n",
      "Iteration: 3615/10000, Loss: 0.011573104187846184\n",
      "Iteration: 3616/10000, Loss: 0.01753082126379013\n",
      "Iteration: 3617/10000, Loss: 0.02093556709587574\n",
      "Iteration: 3618/10000, Loss: 0.015284258872270584\n",
      "Iteration: 3619/10000, Loss: 0.015371175482869148\n",
      "Iteration: 3620/10000, Loss: 0.022231582552194595\n",
      "Iteration: 3621/10000, Loss: 0.020997129380702972\n",
      "Iteration: 3622/10000, Loss: 0.016019027680158615\n",
      "Iteration: 3623/10000, Loss: 0.015193457715213299\n",
      "Iteration: 3624/10000, Loss: 0.02307157777249813\n",
      "Iteration: 3625/10000, Loss: 0.021551042795181274\n",
      "Iteration: 3626/10000, Loss: 0.015835925936698914\n",
      "Iteration: 3627/10000, Loss: 0.015765108168125153\n",
      "Iteration: 3628/10000, Loss: 0.01626095362007618\n",
      "Iteration: 3629/10000, Loss: 0.019629742950201035\n",
      "Iteration: 3630/10000, Loss: 0.015152336098253727\n",
      "Iteration: 3631/10000, Loss: 0.02071189507842064\n",
      "Iteration: 3632/10000, Loss: 0.013065546751022339\n",
      "Iteration: 3633/10000, Loss: 0.02004442922770977\n",
      "Iteration: 3634/10000, Loss: 0.014547931030392647\n",
      "Iteration: 3635/10000, Loss: 0.01920190639793873\n",
      "Iteration: 3636/10000, Loss: 0.019033847376704216\n",
      "Iteration: 3637/10000, Loss: 0.011108877137303352\n",
      "Iteration: 3638/10000, Loss: 0.012187530286610126\n",
      "Iteration: 3639/10000, Loss: 0.02316364087164402\n",
      "Iteration: 3640/10000, Loss: 0.01961296983063221\n",
      "Iteration: 3641/10000, Loss: 0.015113919973373413\n",
      "Iteration: 3642/10000, Loss: 0.02493838593363762\n",
      "Iteration: 3643/10000, Loss: 0.016395049169659615\n",
      "Iteration: 3644/10000, Loss: 0.030123112723231316\n",
      "Iteration: 3645/10000, Loss: 0.01750735193490982\n",
      "Iteration: 3646/10000, Loss: 0.020448772236704826\n",
      "Iteration: 3647/10000, Loss: 0.020645812153816223\n",
      "Iteration: 3648/10000, Loss: 0.020714910700917244\n",
      "Iteration: 3649/10000, Loss: 0.029677297919988632\n",
      "Iteration: 3650/10000, Loss: 0.021702732890844345\n",
      "Iteration: 3651/10000, Loss: 0.01661566272377968\n",
      "Iteration: 3652/10000, Loss: 0.015758126974105835\n",
      "Iteration: 3653/10000, Loss: 0.014072825200855732\n",
      "Iteration: 3654/10000, Loss: 0.01304967887699604\n",
      "Iteration: 3655/10000, Loss: 0.026842275634407997\n",
      "Iteration: 3656/10000, Loss: 0.015709806233644485\n",
      "Iteration: 3657/10000, Loss: 0.016301127150654793\n",
      "Iteration: 3658/10000, Loss: 0.024275721982121468\n",
      "Iteration: 3659/10000, Loss: 0.022374223917722702\n",
      "Iteration: 3660/10000, Loss: 0.015401560813188553\n",
      "Iteration: 3661/10000, Loss: 0.016308264806866646\n",
      "Iteration: 3662/10000, Loss: 0.017864568158984184\n",
      "Iteration: 3663/10000, Loss: 0.029634512960910797\n",
      "Iteration: 3664/10000, Loss: 0.018173253163695335\n",
      "Iteration: 3665/10000, Loss: 0.010438516736030579\n",
      "Iteration: 3666/10000, Loss: 0.01838676631450653\n",
      "Iteration: 3667/10000, Loss: 0.019041739404201508\n",
      "Iteration: 3668/10000, Loss: 0.016277261078357697\n",
      "Iteration: 3669/10000, Loss: 0.014882825314998627\n",
      "Iteration: 3670/10000, Loss: 0.016982339322566986\n",
      "Iteration: 3671/10000, Loss: 0.015957031399011612\n",
      "Iteration: 3672/10000, Loss: 0.024880439043045044\n",
      "Iteration: 3673/10000, Loss: 0.01642685942351818\n",
      "Iteration: 3674/10000, Loss: 0.01760089583694935\n",
      "Iteration: 3675/10000, Loss: 0.019319159910082817\n",
      "Iteration: 3676/10000, Loss: 0.03024500235915184\n",
      "Iteration: 3677/10000, Loss: 0.0177643820643425\n",
      "Iteration: 3678/10000, Loss: 0.0191812627017498\n",
      "Iteration: 3679/10000, Loss: 0.02334715984761715\n",
      "Iteration: 3680/10000, Loss: 0.017454342916607857\n",
      "Iteration: 3681/10000, Loss: 0.01278205681592226\n",
      "Iteration: 3682/10000, Loss: 0.016809826716780663\n",
      "Iteration: 3683/10000, Loss: 0.02048473060131073\n",
      "Iteration: 3684/10000, Loss: 0.020145637914538383\n",
      "Iteration: 3685/10000, Loss: 0.03163398802280426\n",
      "Iteration: 3686/10000, Loss: 0.02282150276005268\n",
      "Iteration: 3687/10000, Loss: 0.017872178927063942\n",
      "Iteration: 3688/10000, Loss: 0.021663101390004158\n",
      "Iteration: 3689/10000, Loss: 0.02084788680076599\n",
      "Iteration: 3690/10000, Loss: 0.025293108075857162\n",
      "Iteration: 3691/10000, Loss: 0.021572111174464226\n",
      "Iteration: 3692/10000, Loss: 0.014635429717600346\n",
      "Iteration: 3693/10000, Loss: 0.01759074255824089\n",
      "Iteration: 3694/10000, Loss: 0.016590416431427002\n",
      "Iteration: 3695/10000, Loss: 0.014789698645472527\n",
      "Iteration: 3696/10000, Loss: 0.011611409485340118\n",
      "Iteration: 3697/10000, Loss: 0.013778118416666985\n",
      "Iteration: 3698/10000, Loss: 0.0134834423661232\n",
      "Iteration: 3699/10000, Loss: 0.02059665322303772\n",
      "Iteration: 3700/10000, Loss: 0.020318925380706787\n",
      "Average test loss:  0.0029\n",
      "Iteration: 3701/10000, Loss: 0.024202991276979446\n",
      "Iteration: 3702/10000, Loss: 0.021096451207995415\n",
      "Iteration: 3703/10000, Loss: 0.014553990215063095\n",
      "Iteration: 3704/10000, Loss: 0.025705277919769287\n",
      "Iteration: 3705/10000, Loss: 0.023265039548277855\n",
      "Iteration: 3706/10000, Loss: 0.018540631979703903\n",
      "Iteration: 3707/10000, Loss: 0.019465072080492973\n",
      "Iteration: 3708/10000, Loss: 0.015415936708450317\n",
      "Iteration: 3709/10000, Loss: 0.022100375965237617\n",
      "Iteration: 3710/10000, Loss: 0.016924407333135605\n",
      "Iteration: 3711/10000, Loss: 0.015128661878407001\n",
      "Iteration: 3712/10000, Loss: 0.015898678451776505\n",
      "Iteration: 3713/10000, Loss: 0.02086951583623886\n",
      "Iteration: 3714/10000, Loss: 0.01825236901640892\n",
      "Iteration: 3715/10000, Loss: 0.013503621332347393\n",
      "Iteration: 3716/10000, Loss: 0.019640864804387093\n",
      "Iteration: 3717/10000, Loss: 0.014867769554257393\n",
      "Iteration: 3718/10000, Loss: 0.021206190809607506\n",
      "Iteration: 3719/10000, Loss: 0.02102997526526451\n",
      "Iteration: 3720/10000, Loss: 0.015373059548437595\n",
      "Iteration: 3721/10000, Loss: 0.02560284361243248\n",
      "Iteration: 3722/10000, Loss: 0.02045474387705326\n",
      "Iteration: 3723/10000, Loss: 0.01708698645234108\n",
      "Iteration: 3724/10000, Loss: 0.014557001180946827\n",
      "Iteration: 3725/10000, Loss: 0.018953969702124596\n",
      "Iteration: 3726/10000, Loss: 0.033701639622449875\n",
      "Iteration: 3727/10000, Loss: 0.013794142752885818\n",
      "Iteration: 3728/10000, Loss: 0.02130318246781826\n",
      "Iteration: 3729/10000, Loss: 0.016385206952691078\n",
      "Iteration: 3730/10000, Loss: 0.018403641879558563\n",
      "Iteration: 3731/10000, Loss: 0.016463370993733406\n",
      "Iteration: 3732/10000, Loss: 0.025614891201257706\n",
      "Iteration: 3733/10000, Loss: 0.015357298776507378\n",
      "Iteration: 3734/10000, Loss: 0.014543483965098858\n",
      "Iteration: 3735/10000, Loss: 0.014823205769062042\n",
      "Iteration: 3736/10000, Loss: 0.021573467180132866\n",
      "Iteration: 3737/10000, Loss: 0.020382512360811234\n",
      "Iteration: 3738/10000, Loss: 0.013597287237644196\n",
      "Iteration: 3739/10000, Loss: 0.022429484874010086\n",
      "Iteration: 3740/10000, Loss: 0.015213234350085258\n",
      "Iteration: 3741/10000, Loss: 0.01483327616006136\n",
      "Iteration: 3742/10000, Loss: 0.017951516434550285\n",
      "Iteration: 3743/10000, Loss: 0.019322965294122696\n",
      "Iteration: 3744/10000, Loss: 0.02386096678674221\n",
      "Iteration: 3745/10000, Loss: 0.022257694974541664\n",
      "Iteration: 3746/10000, Loss: 0.015156121924519539\n",
      "Iteration: 3747/10000, Loss: 0.01552815455943346\n",
      "Iteration: 3748/10000, Loss: 0.014371033757925034\n",
      "Iteration: 3749/10000, Loss: 0.018606018275022507\n",
      "Iteration: 3750/10000, Loss: 0.018333517014980316\n",
      "Iteration: 3751/10000, Loss: 0.013486348092556\n",
      "Iteration: 3752/10000, Loss: 0.027128377929329872\n",
      "Iteration: 3753/10000, Loss: 0.014044479466974735\n",
      "Iteration: 3754/10000, Loss: 0.011939742602407932\n",
      "Iteration: 3755/10000, Loss: 0.019028322771191597\n",
      "Iteration: 3756/10000, Loss: 0.017287764698266983\n",
      "Iteration: 3757/10000, Loss: 0.015334750525653362\n",
      "Iteration: 3758/10000, Loss: 0.013455611653625965\n",
      "Iteration: 3759/10000, Loss: 0.012774349190294743\n",
      "Iteration: 3760/10000, Loss: 0.018886752426624298\n",
      "Iteration: 3761/10000, Loss: 0.01643257960677147\n",
      "Iteration: 3762/10000, Loss: 0.029334643855690956\n",
      "Iteration: 3763/10000, Loss: 0.015826238319277763\n",
      "Iteration: 3764/10000, Loss: 0.017553331330418587\n",
      "Iteration: 3765/10000, Loss: 0.01656503789126873\n",
      "Iteration: 3766/10000, Loss: 0.015740422531962395\n",
      "Iteration: 3767/10000, Loss: 0.01866033487021923\n",
      "Iteration: 3768/10000, Loss: 0.019027777016162872\n",
      "Iteration: 3769/10000, Loss: 0.014577144756913185\n",
      "Iteration: 3770/10000, Loss: 0.01583384908735752\n",
      "Iteration: 3771/10000, Loss: 0.013445706106722355\n",
      "Iteration: 3772/10000, Loss: 0.01445855014026165\n",
      "Iteration: 3773/10000, Loss: 0.01635798066854477\n",
      "Iteration: 3774/10000, Loss: 0.011327230371534824\n",
      "Iteration: 3775/10000, Loss: 0.016955504193902016\n",
      "Iteration: 3776/10000, Loss: 0.012268473394215107\n",
      "Iteration: 3777/10000, Loss: 0.026120595633983612\n",
      "Iteration: 3778/10000, Loss: 0.014019056223332882\n",
      "Iteration: 3779/10000, Loss: 0.016988109797239304\n",
      "Iteration: 3780/10000, Loss: 0.016954410821199417\n",
      "Iteration: 3781/10000, Loss: 0.01419870462268591\n",
      "Iteration: 3782/10000, Loss: 0.021680288016796112\n",
      "Iteration: 3783/10000, Loss: 0.016182666644454002\n",
      "Iteration: 3784/10000, Loss: 0.01647857390344143\n",
      "Iteration: 3785/10000, Loss: 0.01963929645717144\n",
      "Iteration: 3786/10000, Loss: 0.01631961762905121\n",
      "Iteration: 3787/10000, Loss: 0.019022546708583832\n",
      "Iteration: 3788/10000, Loss: 0.0169453676789999\n",
      "Iteration: 3789/10000, Loss: 0.01925564929842949\n",
      "Iteration: 3790/10000, Loss: 0.019916558638215065\n",
      "Iteration: 3791/10000, Loss: 0.014041059650480747\n",
      "Iteration: 3792/10000, Loss: 0.019618351012468338\n",
      "Iteration: 3793/10000, Loss: 0.014822355471551418\n",
      "Iteration: 3794/10000, Loss: 0.020795254036784172\n",
      "Iteration: 3795/10000, Loss: 0.015803711488842964\n",
      "Iteration: 3796/10000, Loss: 0.012981315143406391\n",
      "Iteration: 3797/10000, Loss: 0.015160907991230488\n",
      "Iteration: 3798/10000, Loss: 0.019388757646083832\n",
      "Iteration: 3799/10000, Loss: 0.0126148397102952\n",
      "Iteration: 3800/10000, Loss: 0.017297836020588875\n",
      "Average test loss:  0.0025\n",
      "Iteration: 3801/10000, Loss: 0.015719596296548843\n",
      "Iteration: 3802/10000, Loss: 0.016717413440346718\n",
      "Iteration: 3803/10000, Loss: 0.015672573819756508\n",
      "Iteration: 3804/10000, Loss: 0.0212265457957983\n",
      "Iteration: 3805/10000, Loss: 0.017300572246313095\n",
      "Iteration: 3806/10000, Loss: 0.01909783110022545\n",
      "Iteration: 3807/10000, Loss: 0.014231400564312935\n",
      "Iteration: 3808/10000, Loss: 0.011666734702885151\n",
      "Iteration: 3809/10000, Loss: 0.01646125689148903\n",
      "Iteration: 3810/10000, Loss: 0.024941880255937576\n",
      "Iteration: 3811/10000, Loss: 0.01318252645432949\n",
      "Iteration: 3812/10000, Loss: 0.01693515107035637\n",
      "Iteration: 3813/10000, Loss: 0.011859802529215813\n",
      "Iteration: 3814/10000, Loss: 0.02042558044195175\n",
      "Iteration: 3815/10000, Loss: 0.017197897657752037\n",
      "Iteration: 3816/10000, Loss: 0.02185451053082943\n",
      "Iteration: 3817/10000, Loss: 0.016226142644882202\n",
      "Iteration: 3818/10000, Loss: 0.012359154410660267\n",
      "Iteration: 3819/10000, Loss: 0.01750822737812996\n",
      "Iteration: 3820/10000, Loss: 0.017869558185338974\n",
      "Iteration: 3821/10000, Loss: 0.012791912071406841\n",
      "Iteration: 3822/10000, Loss: 0.014672948978841305\n",
      "Iteration: 3823/10000, Loss: 0.019602758809924126\n",
      "Iteration: 3824/10000, Loss: 0.019657298922538757\n",
      "Iteration: 3825/10000, Loss: 0.018191320821642876\n",
      "Iteration: 3826/10000, Loss: 0.010799655690789223\n",
      "Iteration: 3827/10000, Loss: 0.024841483682394028\n",
      "Iteration: 3828/10000, Loss: 0.012414292432367802\n",
      "Iteration: 3829/10000, Loss: 0.021020686253905296\n",
      "Iteration: 3830/10000, Loss: 0.019301118329167366\n",
      "Iteration: 3831/10000, Loss: 0.010150277055799961\n",
      "Iteration: 3832/10000, Loss: 0.015463748946785927\n",
      "Iteration: 3833/10000, Loss: 0.01319824531674385\n",
      "Iteration: 3834/10000, Loss: 0.0191663708537817\n",
      "Iteration: 3835/10000, Loss: 0.0094619020819664\n",
      "Iteration: 3836/10000, Loss: 0.01627231389284134\n",
      "Iteration: 3837/10000, Loss: 0.011904227547347546\n",
      "Iteration: 3838/10000, Loss: 0.020069411024451256\n",
      "Iteration: 3839/10000, Loss: 0.019873125478625298\n",
      "Iteration: 3840/10000, Loss: 0.014678813517093658\n",
      "Iteration: 3841/10000, Loss: 0.016046928241848946\n",
      "Iteration: 3842/10000, Loss: 0.025543902069330215\n",
      "Iteration: 3843/10000, Loss: 0.01875440403819084\n",
      "Iteration: 3844/10000, Loss: 0.011675846762955189\n",
      "Iteration: 3845/10000, Loss: 0.014548485167324543\n",
      "Iteration: 3846/10000, Loss: 0.01751553826034069\n",
      "Iteration: 3847/10000, Loss: 0.022996952757239342\n",
      "Iteration: 3848/10000, Loss: 0.011745428666472435\n",
      "Iteration: 3849/10000, Loss: 0.018455175682902336\n",
      "Iteration: 3850/10000, Loss: 0.021139254793524742\n",
      "Iteration: 3851/10000, Loss: 0.015872469171881676\n",
      "Iteration: 3852/10000, Loss: 0.02911367267370224\n",
      "Iteration: 3853/10000, Loss: 0.012975126504898071\n",
      "Iteration: 3854/10000, Loss: 0.00819337647408247\n",
      "Iteration: 3855/10000, Loss: 0.015500004403293133\n",
      "Iteration: 3856/10000, Loss: 0.01770729385316372\n",
      "Iteration: 3857/10000, Loss: 0.013240078464150429\n",
      "Iteration: 3858/10000, Loss: 0.01773678883910179\n",
      "Iteration: 3859/10000, Loss: 0.014947120100259781\n",
      "Iteration: 3860/10000, Loss: 0.02042645774781704\n",
      "Iteration: 3861/10000, Loss: 0.015020488761365414\n",
      "Iteration: 3862/10000, Loss: 0.01366253849118948\n",
      "Iteration: 3863/10000, Loss: 0.014854572713375092\n",
      "Iteration: 3864/10000, Loss: 0.01582750305533409\n",
      "Iteration: 3865/10000, Loss: 0.016866443678736687\n",
      "Iteration: 3866/10000, Loss: 0.009331339038908482\n",
      "Iteration: 3867/10000, Loss: 0.016320474445819855\n",
      "Iteration: 3868/10000, Loss: 0.023438086733222008\n",
      "Iteration: 3869/10000, Loss: 0.01310670468956232\n",
      "Iteration: 3870/10000, Loss: 0.01746559329330921\n",
      "Iteration: 3871/10000, Loss: 0.01700778491795063\n",
      "Iteration: 3872/10000, Loss: 0.020893177017569542\n",
      "Iteration: 3873/10000, Loss: 0.014944258145987988\n",
      "Iteration: 3874/10000, Loss: 0.016738073900341988\n",
      "Iteration: 3875/10000, Loss: 0.020891238003969193\n",
      "Iteration: 3876/10000, Loss: 0.010729549452662468\n",
      "Iteration: 3877/10000, Loss: 0.007977244444191456\n",
      "Iteration: 3878/10000, Loss: 0.015752898529171944\n",
      "Iteration: 3879/10000, Loss: 0.018344074487686157\n",
      "Iteration: 3880/10000, Loss: 0.011694948188960552\n",
      "Iteration: 3881/10000, Loss: 0.014938008971512318\n",
      "Iteration: 3882/10000, Loss: 0.017785320058465004\n",
      "Iteration: 3883/10000, Loss: 0.030106453225016594\n",
      "Iteration: 3884/10000, Loss: 0.018773844465613365\n",
      "Iteration: 3885/10000, Loss: 0.00735997362062335\n",
      "Iteration: 3886/10000, Loss: 0.013582414016127586\n",
      "Iteration: 3887/10000, Loss: 0.021186411380767822\n",
      "Iteration: 3888/10000, Loss: 0.016822973266243935\n",
      "Iteration: 3889/10000, Loss: 0.022570302709937096\n",
      "Iteration: 3890/10000, Loss: 0.011699493043124676\n",
      "Iteration: 3891/10000, Loss: 0.012320593930780888\n",
      "Iteration: 3892/10000, Loss: 0.019046103581786156\n",
      "Iteration: 3893/10000, Loss: 0.02538304589688778\n",
      "Iteration: 3894/10000, Loss: 0.01574869267642498\n",
      "Iteration: 3895/10000, Loss: 0.015450316481292248\n",
      "Iteration: 3896/10000, Loss: 0.01430075615644455\n",
      "Iteration: 3897/10000, Loss: 0.01679513417184353\n",
      "Iteration: 3898/10000, Loss: 0.018381983041763306\n",
      "Iteration: 3899/10000, Loss: 0.010143592953681946\n",
      "Iteration: 3900/10000, Loss: 0.018503539264202118\n",
      "Average test loss:  0.0035\n",
      "Iteration: 3901/10000, Loss: 0.01171137671917677\n",
      "Iteration: 3902/10000, Loss: 0.017064038664102554\n",
      "Iteration: 3903/10000, Loss: 0.01742270030081272\n",
      "Iteration: 3904/10000, Loss: 0.013224325142800808\n",
      "Iteration: 3905/10000, Loss: 0.025163186714053154\n",
      "Iteration: 3906/10000, Loss: 0.014906653203070164\n",
      "Iteration: 3907/10000, Loss: 0.025059334933757782\n",
      "Iteration: 3908/10000, Loss: 0.01712527871131897\n",
      "Iteration: 3909/10000, Loss: 0.021401695907115936\n",
      "Iteration: 3910/10000, Loss: 0.020765271037817\n",
      "Iteration: 3911/10000, Loss: 0.016920598223805428\n",
      "Iteration: 3912/10000, Loss: 0.018139392137527466\n",
      "Iteration: 3913/10000, Loss: 0.0224157702177763\n",
      "Iteration: 3914/10000, Loss: 0.017361346632242203\n",
      "Iteration: 3915/10000, Loss: 0.017096340656280518\n",
      "Iteration: 3916/10000, Loss: 0.022413186728954315\n",
      "Iteration: 3917/10000, Loss: 0.013916129246354103\n",
      "Iteration: 3918/10000, Loss: 0.02164495177567005\n",
      "Iteration: 3919/10000, Loss: 0.01870657689869404\n",
      "Iteration: 3920/10000, Loss: 0.01761150360107422\n",
      "Iteration: 3921/10000, Loss: 0.02470570057630539\n",
      "Iteration: 3922/10000, Loss: 0.016147056594491005\n",
      "Iteration: 3923/10000, Loss: 0.01790744811296463\n",
      "Iteration: 3924/10000, Loss: 0.017443565651774406\n",
      "Iteration: 3925/10000, Loss: 0.012824732810258865\n",
      "Iteration: 3926/10000, Loss: 0.015144339762628078\n",
      "Iteration: 3927/10000, Loss: 0.014000201597809792\n",
      "Iteration: 3928/10000, Loss: 0.012890656478703022\n",
      "Iteration: 3929/10000, Loss: 0.02377711795270443\n",
      "Iteration: 3930/10000, Loss: 0.014362892135977745\n",
      "Iteration: 3931/10000, Loss: 0.01666826382279396\n",
      "Iteration: 3932/10000, Loss: 0.020242901518940926\n",
      "Iteration: 3933/10000, Loss: 0.010928291827440262\n",
      "Iteration: 3934/10000, Loss: 0.018208006396889687\n",
      "Iteration: 3935/10000, Loss: 0.01920446939766407\n",
      "Iteration: 3936/10000, Loss: 0.014597817324101925\n",
      "Iteration: 3937/10000, Loss: 0.019755050539970398\n",
      "Iteration: 3938/10000, Loss: 0.020005691796541214\n",
      "Iteration: 3939/10000, Loss: 0.018814319744706154\n",
      "Iteration: 3940/10000, Loss: 0.01609409786760807\n",
      "Iteration: 3941/10000, Loss: 0.01748570427298546\n",
      "Iteration: 3942/10000, Loss: 0.016857782378792763\n",
      "Iteration: 3943/10000, Loss: 0.022081423550844193\n",
      "Iteration: 3944/10000, Loss: 0.009582128375768661\n",
      "Iteration: 3945/10000, Loss: 0.01701011136174202\n",
      "Iteration: 3946/10000, Loss: 0.01010890956968069\n",
      "Iteration: 3947/10000, Loss: 0.01345115341246128\n",
      "Iteration: 3948/10000, Loss: 0.014006032608449459\n",
      "Iteration: 3949/10000, Loss: 0.016877245157957077\n",
      "Iteration: 3950/10000, Loss: 0.010719025507569313\n",
      "Iteration: 3951/10000, Loss: 0.02287239022552967\n",
      "Iteration: 3952/10000, Loss: 0.015400283969938755\n",
      "Iteration: 3953/10000, Loss: 0.01945013552904129\n",
      "Iteration: 3954/10000, Loss: 0.014461103826761246\n",
      "Iteration: 3955/10000, Loss: 0.0186767540872097\n",
      "Iteration: 3956/10000, Loss: 0.016283715143799782\n",
      "Iteration: 3957/10000, Loss: 0.01889493502676487\n",
      "Iteration: 3958/10000, Loss: 0.014138477854430676\n",
      "Iteration: 3959/10000, Loss: 0.017746420577168465\n",
      "Iteration: 3960/10000, Loss: 0.0148458331823349\n",
      "Iteration: 3961/10000, Loss: 0.020906807854771614\n",
      "Iteration: 3962/10000, Loss: 0.01139430794864893\n",
      "Iteration: 3963/10000, Loss: 0.021196424961090088\n",
      "Iteration: 3964/10000, Loss: 0.02262870781123638\n",
      "Iteration: 3965/10000, Loss: 0.020201971754431725\n",
      "Iteration: 3966/10000, Loss: 0.021091420203447342\n",
      "Iteration: 3967/10000, Loss: 0.018753839656710625\n",
      "Iteration: 3968/10000, Loss: 0.015510600060224533\n",
      "Iteration: 3969/10000, Loss: 0.0169978104531765\n",
      "Iteration: 3970/10000, Loss: 0.011993072926998138\n",
      "Iteration: 3971/10000, Loss: 0.013322415761649609\n",
      "Iteration: 3972/10000, Loss: 0.014883242547512054\n",
      "Iteration: 3973/10000, Loss: 0.011397341266274452\n",
      "Iteration: 3974/10000, Loss: 0.022192969918251038\n",
      "Iteration: 3975/10000, Loss: 0.014700938016176224\n",
      "Iteration: 3976/10000, Loss: 0.01588139869272709\n",
      "Iteration: 3977/10000, Loss: 0.016256112605333328\n",
      "Iteration: 3978/10000, Loss: 0.012109212577342987\n",
      "Iteration: 3979/10000, Loss: 0.01989416964352131\n",
      "Iteration: 3980/10000, Loss: 0.015998274087905884\n",
      "Iteration: 3981/10000, Loss: 0.012548845261335373\n",
      "Iteration: 3982/10000, Loss: 0.019523154944181442\n",
      "Iteration: 3983/10000, Loss: 0.019568433985114098\n",
      "Iteration: 3984/10000, Loss: 0.019887549802660942\n",
      "Iteration: 3985/10000, Loss: 0.012952650897204876\n",
      "Iteration: 3986/10000, Loss: 0.011173908598721027\n",
      "Iteration: 3987/10000, Loss: 0.021825898438692093\n",
      "Iteration: 3988/10000, Loss: 0.019935982301831245\n",
      "Iteration: 3989/10000, Loss: 0.03479495272040367\n",
      "Iteration: 3990/10000, Loss: 0.019452448934316635\n",
      "Iteration: 3991/10000, Loss: 0.020551985129714012\n",
      "Iteration: 3992/10000, Loss: 0.02348867990076542\n",
      "Iteration: 3993/10000, Loss: 0.012916987761855125\n",
      "Iteration: 3994/10000, Loss: 0.01543062087148428\n",
      "Iteration: 3995/10000, Loss: 0.016563544049859047\n",
      "Iteration: 3996/10000, Loss: 0.01649518683552742\n",
      "Iteration: 3997/10000, Loss: 0.01667747274041176\n",
      "Iteration: 3998/10000, Loss: 0.01211603358387947\n",
      "Iteration: 3999/10000, Loss: 0.027844233438372612\n",
      "Iteration: 4000/10000, Loss: 0.015625549480319023\n",
      "Average test loss:  0.0024\n",
      "Iteration: 4001/10000, Loss: 0.01656697504222393\n",
      "Iteration: 4002/10000, Loss: 0.01689649559557438\n",
      "Iteration: 4003/10000, Loss: 0.01429660152643919\n",
      "Iteration: 4004/10000, Loss: 0.014821411110460758\n",
      "Iteration: 4005/10000, Loss: 0.013366647064685822\n",
      "Iteration: 4006/10000, Loss: 0.016772782430052757\n",
      "Iteration: 4007/10000, Loss: 0.020072124898433685\n",
      "Iteration: 4008/10000, Loss: 0.015986131504178047\n",
      "Iteration: 4009/10000, Loss: 0.01177980750799179\n",
      "Iteration: 4010/10000, Loss: 0.011189584620296955\n",
      "Iteration: 4011/10000, Loss: 0.02849128469824791\n",
      "Iteration: 4012/10000, Loss: 0.017211031168699265\n",
      "Iteration: 4013/10000, Loss: 0.015551241114735603\n",
      "Iteration: 4014/10000, Loss: 0.018398785963654518\n",
      "Iteration: 4015/10000, Loss: 0.025066610425710678\n",
      "Iteration: 4016/10000, Loss: 0.01384630799293518\n",
      "Iteration: 4017/10000, Loss: 0.015668679028749466\n",
      "Iteration: 4018/10000, Loss: 0.015625756233930588\n",
      "Iteration: 4019/10000, Loss: 0.013697806745767593\n",
      "Iteration: 4020/10000, Loss: 0.02353651449084282\n",
      "Iteration: 4021/10000, Loss: 0.015612037852406502\n",
      "Iteration: 4022/10000, Loss: 0.015034622512757778\n",
      "Iteration: 4023/10000, Loss: 0.01226767897605896\n",
      "Iteration: 4024/10000, Loss: 0.02145623229444027\n",
      "Iteration: 4025/10000, Loss: 0.014912770129740238\n",
      "Iteration: 4026/10000, Loss: 0.012684717774391174\n",
      "Iteration: 4027/10000, Loss: 0.013641067780554295\n",
      "Iteration: 4028/10000, Loss: 0.013465681113302708\n",
      "Iteration: 4029/10000, Loss: 0.016748636960983276\n",
      "Iteration: 4030/10000, Loss: 0.018481789156794548\n",
      "Iteration: 4031/10000, Loss: 0.01836708001792431\n",
      "Iteration: 4032/10000, Loss: 0.01773366518318653\n",
      "Iteration: 4033/10000, Loss: 0.012323531322181225\n",
      "Iteration: 4034/10000, Loss: 0.018793044611811638\n",
      "Iteration: 4035/10000, Loss: 0.014327599667012691\n",
      "Iteration: 4036/10000, Loss: 0.0094282366335392\n",
      "Iteration: 4037/10000, Loss: 0.01167098619043827\n",
      "Iteration: 4038/10000, Loss: 0.01817641593515873\n",
      "Iteration: 4039/10000, Loss: 0.01669955439865589\n",
      "Iteration: 4040/10000, Loss: 0.011075773276388645\n",
      "Iteration: 4041/10000, Loss: 0.021366268396377563\n",
      "Iteration: 4042/10000, Loss: 0.02086847461760044\n",
      "Iteration: 4043/10000, Loss: 0.01502555888146162\n",
      "Iteration: 4044/10000, Loss: 0.023923641070723534\n",
      "Iteration: 4045/10000, Loss: 0.017438605427742004\n",
      "Iteration: 4046/10000, Loss: 0.02215895988047123\n",
      "Iteration: 4047/10000, Loss: 0.015104376710951328\n",
      "Iteration: 4048/10000, Loss: 0.019829805940389633\n",
      "Iteration: 4049/10000, Loss: 0.01333677675575018\n",
      "Iteration: 4050/10000, Loss: 0.01743296906352043\n",
      "Iteration: 4051/10000, Loss: 0.009449249133467674\n",
      "Iteration: 4052/10000, Loss: 0.013167839497327805\n",
      "Iteration: 4053/10000, Loss: 0.028045732527971268\n",
      "Iteration: 4054/10000, Loss: 0.01825685426592827\n",
      "Iteration: 4055/10000, Loss: 0.015972761437296867\n",
      "Iteration: 4056/10000, Loss: 0.013337467797100544\n",
      "Iteration: 4057/10000, Loss: 0.01690676249563694\n",
      "Iteration: 4058/10000, Loss: 0.013290720991790295\n",
      "Iteration: 4059/10000, Loss: 0.018571976572275162\n",
      "Iteration: 4060/10000, Loss: 0.021237680688500404\n",
      "Iteration: 4061/10000, Loss: 0.01567680947482586\n",
      "Iteration: 4062/10000, Loss: 0.021628420799970627\n",
      "Iteration: 4063/10000, Loss: 0.013919192366302013\n",
      "Iteration: 4064/10000, Loss: 0.017014801502227783\n",
      "Iteration: 4065/10000, Loss: 0.011353001929819584\n",
      "Iteration: 4066/10000, Loss: 0.012876373715698719\n",
      "Iteration: 4067/10000, Loss: 0.012352123856544495\n",
      "Iteration: 4068/10000, Loss: 0.016646593809127808\n",
      "Iteration: 4069/10000, Loss: 0.022327059879899025\n",
      "Iteration: 4070/10000, Loss: 0.02560446783900261\n",
      "Iteration: 4071/10000, Loss: 0.023903820663690567\n",
      "Iteration: 4072/10000, Loss: 0.011221556924283504\n",
      "Iteration: 4073/10000, Loss: 0.018305091187357903\n",
      "Iteration: 4074/10000, Loss: 0.014106267131865025\n",
      "Iteration: 4075/10000, Loss: 0.018699143081903458\n",
      "Iteration: 4076/10000, Loss: 0.011605316773056984\n",
      "Iteration: 4077/10000, Loss: 0.01660652458667755\n",
      "Iteration: 4078/10000, Loss: 0.01123044453561306\n",
      "Iteration: 4079/10000, Loss: 0.029829388484358788\n",
      "Iteration: 4080/10000, Loss: 0.01124986819922924\n",
      "Iteration: 4081/10000, Loss: 0.014708475209772587\n",
      "Iteration: 4082/10000, Loss: 0.019422346726059914\n",
      "Iteration: 4083/10000, Loss: 0.01944568194448948\n",
      "Iteration: 4084/10000, Loss: 0.018912235274910927\n",
      "Iteration: 4085/10000, Loss: 0.019719617441296577\n",
      "Iteration: 4086/10000, Loss: 0.013170041143894196\n",
      "Iteration: 4087/10000, Loss: 0.015218089334666729\n",
      "Iteration: 4088/10000, Loss: 0.010216177441179752\n",
      "Iteration: 4089/10000, Loss: 0.016277484595775604\n",
      "Iteration: 4090/10000, Loss: 0.014694209210574627\n",
      "Iteration: 4091/10000, Loss: 0.010243967175483704\n",
      "Iteration: 4092/10000, Loss: 0.013106690719723701\n",
      "Iteration: 4093/10000, Loss: 0.009513158351182938\n",
      "Iteration: 4094/10000, Loss: 0.02329021878540516\n",
      "Iteration: 4095/10000, Loss: 0.02007647044956684\n",
      "Iteration: 4096/10000, Loss: 0.012518818490207195\n",
      "Iteration: 4097/10000, Loss: 0.020068423822522163\n",
      "Iteration: 4098/10000, Loss: 0.01523806806653738\n",
      "Iteration: 4099/10000, Loss: 0.01564699597656727\n",
      "Iteration: 4100/10000, Loss: 0.015415670350193977\n",
      "Average test loss:  0.0034\n",
      "Iteration: 4101/10000, Loss: 0.021595021709799767\n",
      "Iteration: 4102/10000, Loss: 0.02162146009504795\n",
      "Iteration: 4103/10000, Loss: 0.009807884693145752\n",
      "Iteration: 4104/10000, Loss: 0.016278594732284546\n",
      "Iteration: 4105/10000, Loss: 0.01916113682091236\n",
      "Iteration: 4106/10000, Loss: 0.018247725442051888\n",
      "Iteration: 4107/10000, Loss: 0.014566503465175629\n",
      "Iteration: 4108/10000, Loss: 0.01791480928659439\n",
      "Iteration: 4109/10000, Loss: 0.021274948492646217\n",
      "Iteration: 4110/10000, Loss: 0.017261376604437828\n",
      "Iteration: 4111/10000, Loss: 0.016926031559705734\n",
      "Iteration: 4112/10000, Loss: 0.018132654950022697\n",
      "Iteration: 4113/10000, Loss: 0.017949746921658516\n",
      "Iteration: 4114/10000, Loss: 0.011418706737458706\n",
      "Iteration: 4115/10000, Loss: 0.013024120591580868\n",
      "Iteration: 4116/10000, Loss: 0.009576480835676193\n",
      "Iteration: 4117/10000, Loss: 0.021487411111593246\n",
      "Iteration: 4118/10000, Loss: 0.011837729252874851\n",
      "Iteration: 4119/10000, Loss: 0.016515621915459633\n",
      "Iteration: 4120/10000, Loss: 0.018174033612012863\n",
      "Iteration: 4121/10000, Loss: 0.01539083756506443\n",
      "Iteration: 4122/10000, Loss: 0.022417819127440453\n",
      "Iteration: 4123/10000, Loss: 0.02134559117257595\n",
      "Iteration: 4124/10000, Loss: 0.014409624971449375\n",
      "Iteration: 4125/10000, Loss: 0.01816515251994133\n",
      "Iteration: 4126/10000, Loss: 0.018789388239383698\n",
      "Iteration: 4127/10000, Loss: 0.014192603528499603\n",
      "Iteration: 4128/10000, Loss: 0.02015727572143078\n",
      "Iteration: 4129/10000, Loss: 0.016140179708600044\n",
      "Iteration: 4130/10000, Loss: 0.027124378830194473\n",
      "Iteration: 4131/10000, Loss: 0.020220480859279633\n",
      "Iteration: 4132/10000, Loss: 0.010600530542433262\n",
      "Iteration: 4133/10000, Loss: 0.01741647534072399\n",
      "Iteration: 4134/10000, Loss: 0.015072016976773739\n",
      "Iteration: 4135/10000, Loss: 0.013110421597957611\n",
      "Iteration: 4136/10000, Loss: 0.016934501007199287\n",
      "Iteration: 4137/10000, Loss: 0.014126536436378956\n",
      "Iteration: 4138/10000, Loss: 0.01851739175617695\n",
      "Iteration: 4139/10000, Loss: 0.01060279831290245\n",
      "Iteration: 4140/10000, Loss: 0.014257138594985008\n",
      "Iteration: 4141/10000, Loss: 0.014535759575664997\n",
      "Iteration: 4142/10000, Loss: 0.018265528604388237\n",
      "Iteration: 4143/10000, Loss: 0.017684079706668854\n",
      "Iteration: 4144/10000, Loss: 0.012820226140320301\n",
      "Iteration: 4145/10000, Loss: 0.009801918640732765\n",
      "Iteration: 4146/10000, Loss: 0.016316542401909828\n",
      "Iteration: 4147/10000, Loss: 0.013102821074426174\n",
      "Iteration: 4148/10000, Loss: 0.015449494123458862\n",
      "Iteration: 4149/10000, Loss: 0.01345754973590374\n",
      "Iteration: 4150/10000, Loss: 0.020339930430054665\n",
      "Iteration: 4151/10000, Loss: 0.011923241429030895\n",
      "Iteration: 4152/10000, Loss: 0.011060935445129871\n",
      "Iteration: 4153/10000, Loss: 0.021798908710479736\n",
      "Iteration: 4154/10000, Loss: 0.011965179815888405\n",
      "Iteration: 4155/10000, Loss: 0.018564466387033463\n",
      "Iteration: 4156/10000, Loss: 0.011970490217208862\n",
      "Iteration: 4157/10000, Loss: 0.0136951245367527\n",
      "Iteration: 4158/10000, Loss: 0.022745177149772644\n",
      "Iteration: 4159/10000, Loss: 0.017433974891901016\n",
      "Iteration: 4160/10000, Loss: 0.016853056848049164\n",
      "Iteration: 4161/10000, Loss: 0.012606934644281864\n",
      "Iteration: 4162/10000, Loss: 0.014332764782011509\n",
      "Iteration: 4163/10000, Loss: 0.010833513922989368\n",
      "Iteration: 4164/10000, Loss: 0.014128563925623894\n",
      "Iteration: 4165/10000, Loss: 0.011077366769313812\n",
      "Iteration: 4166/10000, Loss: 0.01936046965420246\n",
      "Iteration: 4167/10000, Loss: 0.013424151577055454\n",
      "Iteration: 4168/10000, Loss: 0.012061682529747486\n",
      "Iteration: 4169/10000, Loss: 0.01824280247092247\n",
      "Iteration: 4170/10000, Loss: 0.01731582172214985\n",
      "Iteration: 4171/10000, Loss: 0.017757069319486618\n",
      "Iteration: 4172/10000, Loss: 0.015082275494933128\n",
      "Iteration: 4173/10000, Loss: 0.0218055360019207\n",
      "Iteration: 4174/10000, Loss: 0.017376407980918884\n",
      "Iteration: 4175/10000, Loss: 0.01819819211959839\n",
      "Iteration: 4176/10000, Loss: 0.014849132858216763\n",
      "Iteration: 4177/10000, Loss: 0.016184763982892036\n",
      "Iteration: 4178/10000, Loss: 0.021224841475486755\n",
      "Iteration: 4179/10000, Loss: 0.02120179496705532\n",
      "Iteration: 4180/10000, Loss: 0.009042160585522652\n",
      "Iteration: 4181/10000, Loss: 0.014309326186776161\n",
      "Iteration: 4182/10000, Loss: 0.011068252846598625\n",
      "Iteration: 4183/10000, Loss: 0.009289574809372425\n",
      "Iteration: 4184/10000, Loss: 0.007710937410593033\n",
      "Iteration: 4185/10000, Loss: 0.013505128212273121\n",
      "Iteration: 4186/10000, Loss: 0.017348868772387505\n",
      "Iteration: 4187/10000, Loss: 0.011652961373329163\n",
      "Iteration: 4188/10000, Loss: 0.020051002502441406\n",
      "Iteration: 4189/10000, Loss: 0.014883819036185741\n",
      "Iteration: 4190/10000, Loss: 0.01879558153450489\n",
      "Iteration: 4191/10000, Loss: 0.014807316474616528\n",
      "Iteration: 4192/10000, Loss: 0.011586584150791168\n",
      "Iteration: 4193/10000, Loss: 0.01643654704093933\n",
      "Iteration: 4194/10000, Loss: 0.010726390406489372\n",
      "Iteration: 4195/10000, Loss: 0.012620282359421253\n",
      "Iteration: 4196/10000, Loss: 0.017240868881344795\n",
      "Iteration: 4197/10000, Loss: 0.012863743118941784\n",
      "Iteration: 4198/10000, Loss: 0.016912339255213737\n",
      "Iteration: 4199/10000, Loss: 0.016450071707367897\n",
      "Iteration: 4200/10000, Loss: 0.014558648690581322\n",
      "Average test loss:  0.0030\n",
      "Iteration: 4201/10000, Loss: 0.017890900373458862\n",
      "Iteration: 4202/10000, Loss: 0.006999536417424679\n",
      "Iteration: 4203/10000, Loss: 0.010725375264883041\n",
      "Iteration: 4204/10000, Loss: 0.014086837880313396\n",
      "Iteration: 4205/10000, Loss: 0.015804003924131393\n",
      "Iteration: 4206/10000, Loss: 0.021555449813604355\n",
      "Iteration: 4207/10000, Loss: 0.01937180384993553\n",
      "Iteration: 4208/10000, Loss: 0.009906413033604622\n",
      "Iteration: 4209/10000, Loss: 0.014846592210233212\n",
      "Iteration: 4210/10000, Loss: 0.014361374080181122\n",
      "Iteration: 4211/10000, Loss: 0.018811307847499847\n",
      "Iteration: 4212/10000, Loss: 0.014324380084872246\n",
      "Iteration: 4213/10000, Loss: 0.013975963927805424\n",
      "Iteration: 4214/10000, Loss: 0.013869186863303185\n",
      "Iteration: 4215/10000, Loss: 0.017387326806783676\n",
      "Iteration: 4216/10000, Loss: 0.009509578347206116\n",
      "Iteration: 4217/10000, Loss: 0.02012566477060318\n",
      "Iteration: 4218/10000, Loss: 0.015366938896477222\n",
      "Iteration: 4219/10000, Loss: 0.01013695728033781\n",
      "Iteration: 4220/10000, Loss: 0.013393825851380825\n",
      "Iteration: 4221/10000, Loss: 0.02132965438067913\n",
      "Iteration: 4222/10000, Loss: 0.014333540573716164\n",
      "Iteration: 4223/10000, Loss: 0.01677410863339901\n",
      "Iteration: 4224/10000, Loss: 0.01333682145923376\n",
      "Iteration: 4225/10000, Loss: 0.012749861925840378\n",
      "Iteration: 4226/10000, Loss: 0.019878916442394257\n",
      "Iteration: 4227/10000, Loss: 0.013679658994078636\n",
      "Iteration: 4228/10000, Loss: 0.01917845569550991\n",
      "Iteration: 4229/10000, Loss: 0.0171089768409729\n",
      "Iteration: 4230/10000, Loss: 0.017239386215806007\n",
      "Iteration: 4231/10000, Loss: 0.018552174791693687\n",
      "Iteration: 4232/10000, Loss: 0.011384346522390842\n",
      "Iteration: 4233/10000, Loss: 0.014773767441511154\n",
      "Iteration: 4234/10000, Loss: 0.01789810322225094\n",
      "Iteration: 4235/10000, Loss: 0.011867128312587738\n",
      "Iteration: 4236/10000, Loss: 0.015270128846168518\n",
      "Iteration: 4237/10000, Loss: 0.012714271433651447\n",
      "Iteration: 4238/10000, Loss: 0.014480744488537312\n",
      "Iteration: 4239/10000, Loss: 0.013209065422415733\n",
      "Iteration: 4240/10000, Loss: 0.014364571310579777\n",
      "Iteration: 4241/10000, Loss: 0.010435989126563072\n",
      "Iteration: 4242/10000, Loss: 0.020045101642608643\n",
      "Iteration: 4243/10000, Loss: 0.016389494761824608\n",
      "Iteration: 4244/10000, Loss: 0.015470540151000023\n",
      "Iteration: 4245/10000, Loss: 0.02098548412322998\n",
      "Iteration: 4246/10000, Loss: 0.01420942135155201\n",
      "Iteration: 4247/10000, Loss: 0.01863626018166542\n",
      "Iteration: 4248/10000, Loss: 0.0139219481498003\n",
      "Iteration: 4249/10000, Loss: 0.016821375116705894\n",
      "Iteration: 4250/10000, Loss: 0.01250521931797266\n",
      "Iteration: 4251/10000, Loss: 0.0119102718308568\n",
      "Iteration: 4252/10000, Loss: 0.022366659715771675\n",
      "Iteration: 4253/10000, Loss: 0.016124816611409187\n",
      "Iteration: 4254/10000, Loss: 0.018060512840747833\n",
      "Iteration: 4255/10000, Loss: 0.015232210047543049\n",
      "Iteration: 4256/10000, Loss: 0.018990082666277885\n",
      "Iteration: 4257/10000, Loss: 0.012730508111417294\n",
      "Iteration: 4258/10000, Loss: 0.012742520309984684\n",
      "Iteration: 4259/10000, Loss: 0.012499837204813957\n",
      "Iteration: 4260/10000, Loss: 0.019739363342523575\n",
      "Iteration: 4261/10000, Loss: 0.016922375187277794\n",
      "Iteration: 4262/10000, Loss: 0.025577042251825333\n",
      "Iteration: 4263/10000, Loss: 0.011765035800635815\n",
      "Iteration: 4264/10000, Loss: 0.015234223566949368\n",
      "Iteration: 4265/10000, Loss: 0.01086585596203804\n",
      "Iteration: 4266/10000, Loss: 0.01919192634522915\n",
      "Iteration: 4267/10000, Loss: 0.017555072903633118\n",
      "Iteration: 4268/10000, Loss: 0.012487229891121387\n",
      "Iteration: 4269/10000, Loss: 0.01198513898998499\n",
      "Iteration: 4270/10000, Loss: 0.01856795884668827\n",
      "Iteration: 4271/10000, Loss: 0.014393365010619164\n",
      "Iteration: 4272/10000, Loss: 0.019253145903348923\n",
      "Iteration: 4273/10000, Loss: 0.017559142783284187\n",
      "Iteration: 4274/10000, Loss: 0.014497767202556133\n",
      "Iteration: 4275/10000, Loss: 0.014078063890337944\n",
      "Iteration: 4276/10000, Loss: 0.015491592697799206\n",
      "Iteration: 4277/10000, Loss: 0.01761453039944172\n",
      "Iteration: 4278/10000, Loss: 0.01605239510536194\n",
      "Iteration: 4279/10000, Loss: 0.014596376568078995\n",
      "Iteration: 4280/10000, Loss: 0.024642053991556168\n",
      "Iteration: 4281/10000, Loss: 0.013303548097610474\n",
      "Iteration: 4282/10000, Loss: 0.025597233325242996\n",
      "Iteration: 4283/10000, Loss: 0.014249387197196484\n",
      "Iteration: 4284/10000, Loss: 0.013609010726213455\n",
      "Iteration: 4285/10000, Loss: 0.014082133769989014\n",
      "Iteration: 4286/10000, Loss: 0.016293317079544067\n",
      "Iteration: 4287/10000, Loss: 0.013279102742671967\n",
      "Iteration: 4288/10000, Loss: 0.01391616091132164\n",
      "Iteration: 4289/10000, Loss: 0.018229059875011444\n",
      "Iteration: 4290/10000, Loss: 0.011243990622460842\n",
      "Iteration: 4291/10000, Loss: 0.014834364876151085\n",
      "Iteration: 4292/10000, Loss: 0.012757239863276482\n",
      "Iteration: 4293/10000, Loss: 0.014746861532330513\n",
      "Iteration: 4294/10000, Loss: 0.011666255071759224\n",
      "Iteration: 4295/10000, Loss: 0.017062006518244743\n",
      "Iteration: 4296/10000, Loss: 0.01832694374024868\n",
      "Iteration: 4297/10000, Loss: 0.011147812008857727\n",
      "Iteration: 4298/10000, Loss: 0.01314662117511034\n",
      "Iteration: 4299/10000, Loss: 0.019777392968535423\n",
      "Iteration: 4300/10000, Loss: 0.012176492251455784\n",
      "Average test loss:  0.0016\n",
      "Iteration: 4301/10000, Loss: 0.016390815377235413\n",
      "Iteration: 4302/10000, Loss: 0.010891091078519821\n",
      "Iteration: 4303/10000, Loss: 0.013598661869764328\n",
      "Iteration: 4304/10000, Loss: 0.008164815604686737\n",
      "Iteration: 4305/10000, Loss: 0.014420106075704098\n",
      "Iteration: 4306/10000, Loss: 0.016519617289304733\n",
      "Iteration: 4307/10000, Loss: 0.019420085474848747\n",
      "Iteration: 4308/10000, Loss: 0.013408945873379707\n",
      "Iteration: 4309/10000, Loss: 0.014379101805388927\n",
      "Iteration: 4310/10000, Loss: 0.025985825806856155\n",
      "Iteration: 4311/10000, Loss: 0.016943033784627914\n",
      "Iteration: 4312/10000, Loss: 0.015475073829293251\n",
      "Iteration: 4313/10000, Loss: 0.01741710864007473\n",
      "Iteration: 4314/10000, Loss: 0.022816024720668793\n",
      "Iteration: 4315/10000, Loss: 0.011860856786370277\n",
      "Iteration: 4316/10000, Loss: 0.020734960213303566\n",
      "Iteration: 4317/10000, Loss: 0.014175886288285255\n",
      "Iteration: 4318/10000, Loss: 0.015403748489916325\n",
      "Iteration: 4319/10000, Loss: 0.015341856516897678\n",
      "Iteration: 4320/10000, Loss: 0.023900574073195457\n",
      "Iteration: 4321/10000, Loss: 0.013551825657486916\n",
      "Iteration: 4322/10000, Loss: 0.011455344967544079\n",
      "Iteration: 4323/10000, Loss: 0.022471608594059944\n",
      "Iteration: 4324/10000, Loss: 0.01698482781648636\n",
      "Iteration: 4325/10000, Loss: 0.012914852239191532\n",
      "Iteration: 4326/10000, Loss: 0.04001592844724655\n",
      "Iteration: 4327/10000, Loss: 0.021435189992189407\n",
      "Iteration: 4328/10000, Loss: 0.01648147590458393\n",
      "Iteration: 4329/10000, Loss: 0.022281941026449203\n",
      "Iteration: 4330/10000, Loss: 0.01766604371368885\n",
      "Iteration: 4331/10000, Loss: 0.013558595441281796\n",
      "Iteration: 4332/10000, Loss: 0.022284967824816704\n",
      "Iteration: 4333/10000, Loss: 0.017496705055236816\n",
      "Iteration: 4334/10000, Loss: 0.014982831664383411\n",
      "Iteration: 4335/10000, Loss: 0.01177329570055008\n",
      "Iteration: 4336/10000, Loss: 0.0214257650077343\n",
      "Iteration: 4337/10000, Loss: 0.01708224229514599\n",
      "Iteration: 4338/10000, Loss: 0.021528353914618492\n",
      "Iteration: 4339/10000, Loss: 0.01604166440665722\n",
      "Iteration: 4340/10000, Loss: 0.014097103849053383\n",
      "Iteration: 4341/10000, Loss: 0.015119616873562336\n",
      "Iteration: 4342/10000, Loss: 0.014973280020058155\n",
      "Iteration: 4343/10000, Loss: 0.020610297098755836\n",
      "Iteration: 4344/10000, Loss: 0.01789947785437107\n",
      "Iteration: 4345/10000, Loss: 0.01679570972919464\n",
      "Iteration: 4346/10000, Loss: 0.016786720603704453\n",
      "Iteration: 4347/10000, Loss: 0.018472760915756226\n",
      "Iteration: 4348/10000, Loss: 0.015704002231359482\n",
      "Iteration: 4349/10000, Loss: 0.017468586564064026\n",
      "Iteration: 4350/10000, Loss: 0.011553535237908363\n",
      "Iteration: 4351/10000, Loss: 0.01667715236544609\n",
      "Iteration: 4352/10000, Loss: 0.01884867623448372\n",
      "Iteration: 4353/10000, Loss: 0.02106649987399578\n",
      "Iteration: 4354/10000, Loss: 0.01204866822808981\n",
      "Iteration: 4355/10000, Loss: 0.017731450498104095\n",
      "Iteration: 4356/10000, Loss: 0.01493881642818451\n",
      "Iteration: 4357/10000, Loss: 0.015013494528830051\n",
      "Iteration: 4358/10000, Loss: 0.013206420466303825\n",
      "Iteration: 4359/10000, Loss: 0.016589561477303505\n",
      "Iteration: 4360/10000, Loss: 0.01883098855614662\n",
      "Iteration: 4361/10000, Loss: 0.020039698109030724\n",
      "Iteration: 4362/10000, Loss: 0.01230602152645588\n",
      "Iteration: 4363/10000, Loss: 0.01697147823870182\n",
      "Iteration: 4364/10000, Loss: 0.024727236479520798\n",
      "Iteration: 4365/10000, Loss: 0.01845230720937252\n",
      "Iteration: 4366/10000, Loss: 0.02011534385383129\n",
      "Iteration: 4367/10000, Loss: 0.014281783252954483\n",
      "Iteration: 4368/10000, Loss: 0.011889103800058365\n",
      "Iteration: 4369/10000, Loss: 0.014221969060599804\n",
      "Iteration: 4370/10000, Loss: 0.01835598237812519\n",
      "Iteration: 4371/10000, Loss: 0.020059291273355484\n",
      "Iteration: 4372/10000, Loss: 0.02418992482125759\n",
      "Iteration: 4373/10000, Loss: 0.01941034197807312\n",
      "Iteration: 4374/10000, Loss: 0.01961326412856579\n",
      "Iteration: 4375/10000, Loss: 0.015033104456961155\n",
      "Iteration: 4376/10000, Loss: 0.01171216182410717\n",
      "Iteration: 4377/10000, Loss: 0.024324653670191765\n",
      "Iteration: 4378/10000, Loss: 0.00952831283211708\n",
      "Iteration: 4379/10000, Loss: 0.018536778166890144\n",
      "Iteration: 4380/10000, Loss: 0.025329070165753365\n",
      "Iteration: 4381/10000, Loss: 0.02716771699488163\n",
      "Iteration: 4382/10000, Loss: 0.0175136961042881\n",
      "Iteration: 4383/10000, Loss: 0.0189400315284729\n",
      "Iteration: 4384/10000, Loss: 0.016720471903681755\n",
      "Iteration: 4385/10000, Loss: 0.02106688730418682\n",
      "Iteration: 4386/10000, Loss: 0.014797771349549294\n",
      "Iteration: 4387/10000, Loss: 0.01737993396818638\n",
      "Iteration: 4388/10000, Loss: 0.015766290947794914\n",
      "Iteration: 4389/10000, Loss: 0.018616385757923126\n",
      "Iteration: 4390/10000, Loss: 0.018533846363425255\n",
      "Iteration: 4391/10000, Loss: 0.014510470442473888\n",
      "Iteration: 4392/10000, Loss: 0.017837729305028915\n",
      "Iteration: 4393/10000, Loss: 0.008020495064556599\n",
      "Iteration: 4394/10000, Loss: 0.01700514741241932\n",
      "Iteration: 4395/10000, Loss: 0.012872639112174511\n",
      "Iteration: 4396/10000, Loss: 0.017967889085412025\n",
      "Iteration: 4397/10000, Loss: 0.020160701125860214\n",
      "Iteration: 4398/10000, Loss: 0.02630167454481125\n",
      "Iteration: 4399/10000, Loss: 0.014494063332676888\n",
      "Iteration: 4400/10000, Loss: 0.010714148171246052\n",
      "Average test loss:  0.0041\n",
      "Iteration: 4401/10000, Loss: 0.01060362346470356\n",
      "Iteration: 4402/10000, Loss: 0.014964355155825615\n",
      "Iteration: 4403/10000, Loss: 0.014567502774298191\n",
      "Iteration: 4404/10000, Loss: 0.014576907269656658\n",
      "Iteration: 4405/10000, Loss: 0.024781499058008194\n",
      "Iteration: 4406/10000, Loss: 0.014778499491512775\n",
      "Iteration: 4407/10000, Loss: 0.01945357210934162\n",
      "Iteration: 4408/10000, Loss: 0.01721239648759365\n",
      "Iteration: 4409/10000, Loss: 0.014873441308736801\n",
      "Iteration: 4410/10000, Loss: 0.019126979634165764\n",
      "Iteration: 4411/10000, Loss: 0.015304003842175007\n",
      "Iteration: 4412/10000, Loss: 0.012256529182195663\n",
      "Iteration: 4413/10000, Loss: 0.020365796983242035\n",
      "Iteration: 4414/10000, Loss: 0.01752331294119358\n",
      "Iteration: 4415/10000, Loss: 0.017122415825724602\n",
      "Iteration: 4416/10000, Loss: 0.017134176567196846\n",
      "Iteration: 4417/10000, Loss: 0.023965999484062195\n",
      "Iteration: 4418/10000, Loss: 0.015184094198048115\n",
      "Iteration: 4419/10000, Loss: 0.013529174961149693\n",
      "Iteration: 4420/10000, Loss: 0.02070615068078041\n",
      "Iteration: 4421/10000, Loss: 0.01683572120964527\n",
      "Iteration: 4422/10000, Loss: 0.01616259291768074\n",
      "Iteration: 4423/10000, Loss: 0.01630515046417713\n",
      "Iteration: 4424/10000, Loss: 0.024974321946501732\n",
      "Iteration: 4425/10000, Loss: 0.01243260595947504\n",
      "Iteration: 4426/10000, Loss: 0.02303888276219368\n",
      "Iteration: 4427/10000, Loss: 0.013588222675025463\n",
      "Iteration: 4428/10000, Loss: 0.017136115580797195\n",
      "Iteration: 4429/10000, Loss: 0.015250226482748985\n",
      "Iteration: 4430/10000, Loss: 0.012610649690032005\n",
      "Iteration: 4431/10000, Loss: 0.0135857118293643\n",
      "Iteration: 4432/10000, Loss: 0.021492542698979378\n",
      "Iteration: 4433/10000, Loss: 0.01348140463232994\n",
      "Iteration: 4434/10000, Loss: 0.014397558756172657\n",
      "Iteration: 4435/10000, Loss: 0.013440004549920559\n",
      "Iteration: 4436/10000, Loss: 0.026536136865615845\n",
      "Iteration: 4437/10000, Loss: 0.018475579097867012\n",
      "Iteration: 4438/10000, Loss: 0.01150715071707964\n",
      "Iteration: 4439/10000, Loss: 0.011103500612080097\n",
      "Iteration: 4440/10000, Loss: 0.012586343102157116\n",
      "Iteration: 4441/10000, Loss: 0.008347747847437859\n",
      "Iteration: 4442/10000, Loss: 0.011919397860765457\n",
      "Iteration: 4443/10000, Loss: 0.017429471015930176\n",
      "Iteration: 4444/10000, Loss: 0.014503588899970055\n",
      "Iteration: 4445/10000, Loss: 0.030537819489836693\n",
      "Iteration: 4446/10000, Loss: 0.01636543497443199\n",
      "Iteration: 4447/10000, Loss: 0.013922709971666336\n",
      "Iteration: 4448/10000, Loss: 0.010395010001957417\n",
      "Iteration: 4449/10000, Loss: 0.01167832501232624\n",
      "Iteration: 4450/10000, Loss: 0.017357254400849342\n",
      "Iteration: 4451/10000, Loss: 0.01402879785746336\n",
      "Iteration: 4452/10000, Loss: 0.02005069889128208\n",
      "Iteration: 4453/10000, Loss: 0.019571799784898758\n",
      "Iteration: 4454/10000, Loss: 0.015056189149618149\n",
      "Iteration: 4455/10000, Loss: 0.017923448234796524\n",
      "Iteration: 4456/10000, Loss: 0.01603635773062706\n",
      "Iteration: 4457/10000, Loss: 0.013390394859015942\n",
      "Iteration: 4458/10000, Loss: 0.01649639382958412\n",
      "Iteration: 4459/10000, Loss: 0.01487994659692049\n",
      "Iteration: 4460/10000, Loss: 0.018518047407269478\n",
      "Iteration: 4461/10000, Loss: 0.012683143839240074\n",
      "Iteration: 4462/10000, Loss: 0.020916063338518143\n",
      "Iteration: 4463/10000, Loss: 0.0124326441437006\n",
      "Iteration: 4464/10000, Loss: 0.007193848956376314\n",
      "Iteration: 4465/10000, Loss: 0.011874514631927013\n",
      "Iteration: 4466/10000, Loss: 0.015482350252568722\n",
      "Iteration: 4467/10000, Loss: 0.019480213522911072\n",
      "Iteration: 4468/10000, Loss: 0.0172119103372097\n",
      "Iteration: 4469/10000, Loss: 0.02465461939573288\n",
      "Iteration: 4470/10000, Loss: 0.015839051455259323\n",
      "Iteration: 4471/10000, Loss: 0.013769708573818207\n",
      "Iteration: 4472/10000, Loss: 0.019286924973130226\n",
      "Iteration: 4473/10000, Loss: 0.016839992254972458\n",
      "Iteration: 4474/10000, Loss: 0.011334182694554329\n",
      "Iteration: 4475/10000, Loss: 0.018018141388893127\n",
      "Iteration: 4476/10000, Loss: 0.012477608397603035\n",
      "Iteration: 4477/10000, Loss: 0.014629571698606014\n",
      "Iteration: 4478/10000, Loss: 0.014065100811421871\n",
      "Iteration: 4479/10000, Loss: 0.018211862072348595\n",
      "Iteration: 4480/10000, Loss: 0.023512234911322594\n",
      "Iteration: 4481/10000, Loss: 0.017812687903642654\n",
      "Iteration: 4482/10000, Loss: 0.010772180743515491\n",
      "Iteration: 4483/10000, Loss: 0.02658718265593052\n",
      "Iteration: 4484/10000, Loss: 0.02020483836531639\n",
      "Iteration: 4485/10000, Loss: 0.02009647525846958\n",
      "Iteration: 4486/10000, Loss: 0.011838437058031559\n",
      "Iteration: 4487/10000, Loss: 0.019250795245170593\n",
      "Iteration: 4488/10000, Loss: 0.01196384523063898\n",
      "Iteration: 4489/10000, Loss: 0.015285925939679146\n",
      "Iteration: 4490/10000, Loss: 0.016476597636938095\n",
      "Iteration: 4491/10000, Loss: 0.010430864058434963\n",
      "Iteration: 4492/10000, Loss: 0.016846319660544395\n",
      "Iteration: 4493/10000, Loss: 0.01863826997578144\n",
      "Iteration: 4494/10000, Loss: 0.01248739380389452\n",
      "Iteration: 4495/10000, Loss: 0.016359740868210793\n",
      "Iteration: 4496/10000, Loss: 0.021393224596977234\n",
      "Iteration: 4497/10000, Loss: 0.016407735645771027\n",
      "Iteration: 4498/10000, Loss: 0.010694305412471294\n",
      "Iteration: 4499/10000, Loss: 0.010265403427183628\n",
      "Iteration: 4500/10000, Loss: 0.01925021782517433\n",
      "Average test loss:  0.0038\n",
      "Iteration: 4501/10000, Loss: 0.013941733166575432\n",
      "Iteration: 4502/10000, Loss: 0.014861661940813065\n",
      "Iteration: 4503/10000, Loss: 0.018160702660679817\n",
      "Iteration: 4504/10000, Loss: 0.020353889092803\n",
      "Iteration: 4505/10000, Loss: 0.014982243999838829\n",
      "Iteration: 4506/10000, Loss: 0.018641378730535507\n",
      "Iteration: 4507/10000, Loss: 0.018592115491628647\n",
      "Iteration: 4508/10000, Loss: 0.016315462067723274\n",
      "Iteration: 4509/10000, Loss: 0.014245619997382164\n",
      "Iteration: 4510/10000, Loss: 0.015636567026376724\n",
      "Iteration: 4511/10000, Loss: 0.018037721514701843\n",
      "Iteration: 4512/10000, Loss: 0.024907654151320457\n",
      "Iteration: 4513/10000, Loss: 0.016955798491835594\n",
      "Iteration: 4514/10000, Loss: 0.01668759435415268\n",
      "Iteration: 4515/10000, Loss: 0.02204258367419243\n",
      "Iteration: 4516/10000, Loss: 0.0147573696449399\n",
      "Iteration: 4517/10000, Loss: 0.015776045620441437\n",
      "Iteration: 4518/10000, Loss: 0.01754166930913925\n",
      "Iteration: 4519/10000, Loss: 0.01559237577021122\n",
      "Iteration: 4520/10000, Loss: 0.011599630117416382\n",
      "Iteration: 4521/10000, Loss: 0.019322974607348442\n",
      "Iteration: 4522/10000, Loss: 0.012789889238774776\n",
      "Iteration: 4523/10000, Loss: 0.013022150844335556\n",
      "Iteration: 4524/10000, Loss: 0.01370370015501976\n",
      "Iteration: 4525/10000, Loss: 0.017924051731824875\n",
      "Iteration: 4526/10000, Loss: 0.016414575278759003\n",
      "Iteration: 4527/10000, Loss: 0.02502141334116459\n",
      "Iteration: 4528/10000, Loss: 0.015031151473522186\n",
      "Iteration: 4529/10000, Loss: 0.017180059105157852\n",
      "Iteration: 4530/10000, Loss: 0.013749094679951668\n",
      "Iteration: 4531/10000, Loss: 0.015138313174247742\n",
      "Iteration: 4532/10000, Loss: 0.013031027279794216\n",
      "Iteration: 4533/10000, Loss: 0.014203039929270744\n",
      "Iteration: 4534/10000, Loss: 0.020636340603232384\n",
      "Iteration: 4535/10000, Loss: 0.011823018081486225\n",
      "Iteration: 4536/10000, Loss: 0.017809158191084862\n",
      "Iteration: 4537/10000, Loss: 0.011829447001218796\n",
      "Iteration: 4538/10000, Loss: 0.0164438895881176\n",
      "Iteration: 4539/10000, Loss: 0.015039495192468166\n",
      "Iteration: 4540/10000, Loss: 0.0173348281532526\n",
      "Iteration: 4541/10000, Loss: 0.01847512274980545\n",
      "Iteration: 4542/10000, Loss: 0.012113302946090698\n",
      "Iteration: 4543/10000, Loss: 0.011318919248878956\n",
      "Iteration: 4544/10000, Loss: 0.017940619960427284\n",
      "Iteration: 4545/10000, Loss: 0.008185851387679577\n",
      "Iteration: 4546/10000, Loss: 0.008849560283124447\n",
      "Iteration: 4547/10000, Loss: 0.010327767580747604\n",
      "Iteration: 4548/10000, Loss: 0.016839468851685524\n",
      "Iteration: 4549/10000, Loss: 0.015320376493036747\n",
      "Iteration: 4550/10000, Loss: 0.012291112914681435\n",
      "Iteration: 4551/10000, Loss: 0.017560023814439774\n",
      "Iteration: 4552/10000, Loss: 0.013729379512369633\n",
      "Iteration: 4553/10000, Loss: 0.015381946228444576\n",
      "Iteration: 4554/10000, Loss: 0.01825672760605812\n",
      "Iteration: 4555/10000, Loss: 0.015080422163009644\n",
      "Iteration: 4556/10000, Loss: 0.01621599867939949\n",
      "Iteration: 4557/10000, Loss: 0.016819577664136887\n",
      "Iteration: 4558/10000, Loss: 0.010960802435874939\n",
      "Iteration: 4559/10000, Loss: 0.01804201491177082\n",
      "Iteration: 4560/10000, Loss: 0.012040695175528526\n",
      "Iteration: 4561/10000, Loss: 0.020989201962947845\n",
      "Iteration: 4562/10000, Loss: 0.017012299969792366\n",
      "Iteration: 4563/10000, Loss: 0.022723233327269554\n",
      "Iteration: 4564/10000, Loss: 0.017475664615631104\n",
      "Iteration: 4565/10000, Loss: 0.012877633795142174\n",
      "Iteration: 4566/10000, Loss: 0.01491097267717123\n",
      "Iteration: 4567/10000, Loss: 0.020372789353132248\n",
      "Iteration: 4568/10000, Loss: 0.010158263146877289\n",
      "Iteration: 4569/10000, Loss: 0.013668427243828773\n",
      "Iteration: 4570/10000, Loss: 0.012332841753959656\n",
      "Iteration: 4571/10000, Loss: 0.00762775307521224\n",
      "Iteration: 4572/10000, Loss: 0.013179827481508255\n",
      "Iteration: 4573/10000, Loss: 0.01907201297581196\n",
      "Iteration: 4574/10000, Loss: 0.0264471136033535\n",
      "Iteration: 4575/10000, Loss: 0.0203077532351017\n",
      "Iteration: 4576/10000, Loss: 0.013662409037351608\n",
      "Iteration: 4577/10000, Loss: 0.01401152927428484\n",
      "Iteration: 4578/10000, Loss: 0.015317087061703205\n",
      "Iteration: 4579/10000, Loss: 0.01576174609363079\n",
      "Iteration: 4580/10000, Loss: 0.018502390012145042\n",
      "Iteration: 4581/10000, Loss: 0.0208330936729908\n",
      "Iteration: 4582/10000, Loss: 0.014112452045083046\n",
      "Iteration: 4583/10000, Loss: 0.01556883379817009\n",
      "Iteration: 4584/10000, Loss: 0.009393801912665367\n",
      "Iteration: 4585/10000, Loss: 0.011578365229070187\n",
      "Iteration: 4586/10000, Loss: 0.017309274524450302\n",
      "Iteration: 4587/10000, Loss: 0.018571315333247185\n",
      "Iteration: 4588/10000, Loss: 0.01370114367455244\n",
      "Iteration: 4589/10000, Loss: 0.010715238749980927\n",
      "Iteration: 4590/10000, Loss: 0.012797802686691284\n",
      "Iteration: 4591/10000, Loss: 0.014969579875469208\n",
      "Iteration: 4592/10000, Loss: 0.014220784418284893\n",
      "Iteration: 4593/10000, Loss: 0.013392028398811817\n",
      "Iteration: 4594/10000, Loss: 0.016218841075897217\n",
      "Iteration: 4595/10000, Loss: 0.016184983775019646\n",
      "Iteration: 4596/10000, Loss: 0.01829744502902031\n",
      "Iteration: 4597/10000, Loss: 0.02016189508140087\n",
      "Iteration: 4598/10000, Loss: 0.01581422984600067\n",
      "Iteration: 4599/10000, Loss: 0.012937969528138638\n",
      "Iteration: 4600/10000, Loss: 0.009581075049936771\n",
      "Average test loss:  0.0032\n",
      "Iteration: 4601/10000, Loss: 0.012882339768111706\n",
      "Iteration: 4602/10000, Loss: 0.016599435359239578\n",
      "Iteration: 4603/10000, Loss: 0.009103585034608841\n",
      "Iteration: 4604/10000, Loss: 0.010612270794808865\n",
      "Iteration: 4605/10000, Loss: 0.010074618272483349\n",
      "Iteration: 4606/10000, Loss: 0.02472318522632122\n",
      "Iteration: 4607/10000, Loss: 0.01834947243332863\n",
      "Iteration: 4608/10000, Loss: 0.02080090157687664\n",
      "Iteration: 4609/10000, Loss: 0.01038924977183342\n",
      "Iteration: 4610/10000, Loss: 0.012395214289426804\n",
      "Iteration: 4611/10000, Loss: 0.01301011722534895\n",
      "Iteration: 4612/10000, Loss: 0.012223241850733757\n",
      "Iteration: 4613/10000, Loss: 0.015920603647828102\n",
      "Iteration: 4614/10000, Loss: 0.013025432825088501\n",
      "Iteration: 4615/10000, Loss: 0.007129485718905926\n",
      "Iteration: 4616/10000, Loss: 0.006118801422417164\n",
      "Iteration: 4617/10000, Loss: 0.014950600452721119\n",
      "Iteration: 4618/10000, Loss: 0.015081756748259068\n",
      "Iteration: 4619/10000, Loss: 0.019344234839081764\n",
      "Iteration: 4620/10000, Loss: 0.011202598921954632\n",
      "Iteration: 4621/10000, Loss: 0.009114855900406837\n",
      "Iteration: 4622/10000, Loss: 0.01297610905021429\n",
      "Iteration: 4623/10000, Loss: 0.012240317650139332\n",
      "Iteration: 4624/10000, Loss: 0.01950571872293949\n",
      "Iteration: 4625/10000, Loss: 0.024733800441026688\n",
      "Iteration: 4626/10000, Loss: 0.015364701859652996\n",
      "Iteration: 4627/10000, Loss: 0.019559338688850403\n",
      "Iteration: 4628/10000, Loss: 0.01395794190466404\n",
      "Iteration: 4629/10000, Loss: 0.018609579652547836\n",
      "Iteration: 4630/10000, Loss: 0.014401561580598354\n",
      "Iteration: 4631/10000, Loss: 0.010767941363155842\n",
      "Iteration: 4632/10000, Loss: 0.01285003125667572\n",
      "Iteration: 4633/10000, Loss: 0.0159329641610384\n",
      "Iteration: 4634/10000, Loss: 0.013796919956803322\n",
      "Iteration: 4635/10000, Loss: 0.018110470846295357\n",
      "Iteration: 4636/10000, Loss: 0.015320739708840847\n",
      "Iteration: 4637/10000, Loss: 0.016881590709090233\n",
      "Iteration: 4638/10000, Loss: 0.009235634468495846\n",
      "Iteration: 4639/10000, Loss: 0.01061137393116951\n",
      "Iteration: 4640/10000, Loss: 0.014888404868543148\n",
      "Iteration: 4641/10000, Loss: 0.023383140563964844\n",
      "Iteration: 4642/10000, Loss: 0.015017530880868435\n",
      "Iteration: 4643/10000, Loss: 0.016812164336442947\n",
      "Iteration: 4644/10000, Loss: 0.01614651083946228\n",
      "Iteration: 4645/10000, Loss: 0.014977401122450829\n",
      "Iteration: 4646/10000, Loss: 0.013051819056272507\n",
      "Iteration: 4647/10000, Loss: 0.010205447673797607\n",
      "Iteration: 4648/10000, Loss: 0.01116946991533041\n",
      "Iteration: 4649/10000, Loss: 0.015428880229592323\n",
      "Iteration: 4650/10000, Loss: 0.01613643579185009\n",
      "Iteration: 4651/10000, Loss: 0.024772686883807182\n",
      "Iteration: 4652/10000, Loss: 0.018585361540317535\n",
      "Iteration: 4653/10000, Loss: 0.017674418166279793\n",
      "Iteration: 4654/10000, Loss: 0.011210153810679913\n",
      "Iteration: 4655/10000, Loss: 0.017446082085371017\n",
      "Iteration: 4656/10000, Loss: 0.016194859519600868\n",
      "Iteration: 4657/10000, Loss: 0.018370985984802246\n",
      "Iteration: 4658/10000, Loss: 0.011722248047590256\n",
      "Iteration: 4659/10000, Loss: 0.012090828269720078\n",
      "Iteration: 4660/10000, Loss: 0.011742040514945984\n",
      "Iteration: 4661/10000, Loss: 0.012940624728798866\n",
      "Iteration: 4662/10000, Loss: 0.020977579057216644\n",
      "Iteration: 4663/10000, Loss: 0.0138969412073493\n",
      "Iteration: 4664/10000, Loss: 0.01786099746823311\n",
      "Iteration: 4665/10000, Loss: 0.013768451288342476\n",
      "Iteration: 4666/10000, Loss: 0.017496226355433464\n",
      "Iteration: 4667/10000, Loss: 0.016901306807994843\n",
      "Iteration: 4668/10000, Loss: 0.014633734710514545\n",
      "Iteration: 4669/10000, Loss: 0.014329064637422562\n",
      "Iteration: 4670/10000, Loss: 0.01688639260828495\n",
      "Iteration: 4671/10000, Loss: 0.01830509677529335\n",
      "Iteration: 4672/10000, Loss: 0.019396871328353882\n",
      "Iteration: 4673/10000, Loss: 0.00803188607096672\n",
      "Iteration: 4674/10000, Loss: 0.007974348962306976\n",
      "Iteration: 4675/10000, Loss: 0.016140569001436234\n",
      "Iteration: 4676/10000, Loss: 0.015729546546936035\n",
      "Iteration: 4677/10000, Loss: 0.014130976051092148\n",
      "Iteration: 4678/10000, Loss: 0.01804611273109913\n",
      "Iteration: 4679/10000, Loss: 0.012294440530240536\n",
      "Iteration: 4680/10000, Loss: 0.009822016581892967\n",
      "Iteration: 4681/10000, Loss: 0.012400385923683643\n",
      "Iteration: 4682/10000, Loss: 0.015581289306282997\n",
      "Iteration: 4683/10000, Loss: 0.016962019726634026\n",
      "Iteration: 4684/10000, Loss: 0.014563054777681828\n",
      "Iteration: 4685/10000, Loss: 0.010575550608336926\n",
      "Iteration: 4686/10000, Loss: 0.025497233495116234\n",
      "Iteration: 4687/10000, Loss: 0.015356499701738358\n",
      "Iteration: 4688/10000, Loss: 0.013687441125512123\n",
      "Iteration: 4689/10000, Loss: 0.018712706863880157\n",
      "Iteration: 4690/10000, Loss: 0.00945968460291624\n",
      "Iteration: 4691/10000, Loss: 0.014703133143484592\n",
      "Iteration: 4692/10000, Loss: 0.014329439960420132\n",
      "Iteration: 4693/10000, Loss: 0.013383271172642708\n",
      "Iteration: 4694/10000, Loss: 0.016114214435219765\n",
      "Iteration: 4695/10000, Loss: 0.01055530272424221\n",
      "Iteration: 4696/10000, Loss: 0.015288124792277813\n",
      "Iteration: 4697/10000, Loss: 0.016544794663786888\n",
      "Iteration: 4698/10000, Loss: 0.01251955796033144\n",
      "Iteration: 4699/10000, Loss: 0.014527512714266777\n",
      "Iteration: 4700/10000, Loss: 0.01438666321337223\n",
      "Average test loss:  0.0020\n",
      "Iteration: 4701/10000, Loss: 0.013630690984427929\n",
      "Iteration: 4702/10000, Loss: 0.016832755878567696\n",
      "Iteration: 4703/10000, Loss: 0.020235728472471237\n",
      "Iteration: 4704/10000, Loss: 0.010112886317074299\n",
      "Iteration: 4705/10000, Loss: 0.017615865916013718\n",
      "Iteration: 4706/10000, Loss: 0.011378010734915733\n",
      "Iteration: 4707/10000, Loss: 0.007093205116689205\n",
      "Iteration: 4708/10000, Loss: 0.012980877421796322\n",
      "Iteration: 4709/10000, Loss: 0.015638401731848717\n",
      "Iteration: 4710/10000, Loss: 0.012276390567421913\n",
      "Iteration: 4711/10000, Loss: 0.009173138998448849\n",
      "Iteration: 4712/10000, Loss: 0.019761979579925537\n",
      "Iteration: 4713/10000, Loss: 0.006419073324650526\n",
      "Iteration: 4714/10000, Loss: 0.008656853809952736\n",
      "Iteration: 4715/10000, Loss: 0.019045032560825348\n",
      "Iteration: 4716/10000, Loss: 0.011469130404293537\n",
      "Iteration: 4717/10000, Loss: 0.0191341582685709\n",
      "Iteration: 4718/10000, Loss: 0.015690738335251808\n",
      "Iteration: 4719/10000, Loss: 0.01565772294998169\n",
      "Iteration: 4720/10000, Loss: 0.019303366541862488\n",
      "Iteration: 4721/10000, Loss: 0.008773156441748142\n",
      "Iteration: 4722/10000, Loss: 0.016040459275245667\n",
      "Iteration: 4723/10000, Loss: 0.020868999883532524\n",
      "Iteration: 4724/10000, Loss: 0.013861674815416336\n",
      "Iteration: 4725/10000, Loss: 0.01621856354176998\n",
      "Iteration: 4726/10000, Loss: 0.011537616141140461\n",
      "Iteration: 4727/10000, Loss: 0.00820714607834816\n",
      "Iteration: 4728/10000, Loss: 0.015498083084821701\n",
      "Iteration: 4729/10000, Loss: 0.015757352113723755\n",
      "Iteration: 4730/10000, Loss: 0.01050555519759655\n",
      "Iteration: 4731/10000, Loss: 0.012980863451957703\n",
      "Iteration: 4732/10000, Loss: 0.018107321113348007\n",
      "Iteration: 4733/10000, Loss: 0.009244210086762905\n",
      "Iteration: 4734/10000, Loss: 0.013649363070726395\n",
      "Iteration: 4735/10000, Loss: 0.009816007688641548\n",
      "Iteration: 4736/10000, Loss: 0.013550803065299988\n",
      "Iteration: 4737/10000, Loss: 0.017230411991477013\n",
      "Iteration: 4738/10000, Loss: 0.016029784455895424\n",
      "Iteration: 4739/10000, Loss: 0.01105314027518034\n",
      "Iteration: 4740/10000, Loss: 0.012661785818636417\n",
      "Iteration: 4741/10000, Loss: 0.009876491501927376\n",
      "Iteration: 4742/10000, Loss: 0.008810615167021751\n",
      "Iteration: 4743/10000, Loss: 0.01036859955638647\n",
      "Iteration: 4744/10000, Loss: 0.00751508167013526\n",
      "Iteration: 4745/10000, Loss: 0.020058969035744667\n",
      "Iteration: 4746/10000, Loss: 0.014373749494552612\n",
      "Iteration: 4747/10000, Loss: 0.012191351503133774\n",
      "Iteration: 4748/10000, Loss: 0.012507154606282711\n",
      "Iteration: 4749/10000, Loss: 0.019688308238983154\n",
      "Iteration: 4750/10000, Loss: 0.016110608354210854\n",
      "Iteration: 4751/10000, Loss: 0.0175621397793293\n",
      "Iteration: 4752/10000, Loss: 0.016771988943219185\n",
      "Iteration: 4753/10000, Loss: 0.013909131288528442\n",
      "Iteration: 4754/10000, Loss: 0.02065081149339676\n",
      "Iteration: 4755/10000, Loss: 0.01152704656124115\n",
      "Iteration: 4756/10000, Loss: 0.013751096092164516\n",
      "Iteration: 4757/10000, Loss: 0.020921694114804268\n",
      "Iteration: 4758/10000, Loss: 0.012729737907648087\n",
      "Iteration: 4759/10000, Loss: 0.012237956747412682\n",
      "Iteration: 4760/10000, Loss: 0.011639087460935116\n",
      "Iteration: 4761/10000, Loss: 0.020976075902581215\n",
      "Iteration: 4762/10000, Loss: 0.016394194215536118\n",
      "Iteration: 4763/10000, Loss: 0.013936972245573997\n",
      "Iteration: 4764/10000, Loss: 0.014122829772531986\n",
      "Iteration: 4765/10000, Loss: 0.015140444040298462\n",
      "Iteration: 4766/10000, Loss: 0.01267851609736681\n",
      "Iteration: 4767/10000, Loss: 0.011014687828719616\n",
      "Iteration: 4768/10000, Loss: 0.01960749551653862\n",
      "Iteration: 4769/10000, Loss: 0.020121660083532333\n",
      "Iteration: 4770/10000, Loss: 0.019479060545563698\n",
      "Iteration: 4771/10000, Loss: 0.014418075792491436\n",
      "Iteration: 4772/10000, Loss: 0.013349669054150581\n",
      "Iteration: 4773/10000, Loss: 0.012154974043369293\n",
      "Iteration: 4774/10000, Loss: 0.013915007933974266\n",
      "Iteration: 4775/10000, Loss: 0.01715092919766903\n",
      "Iteration: 4776/10000, Loss: 0.010972374118864536\n",
      "Iteration: 4777/10000, Loss: 0.014097334817051888\n",
      "Iteration: 4778/10000, Loss: 0.010706726461648941\n",
      "Iteration: 4779/10000, Loss: 0.007910520769655704\n",
      "Iteration: 4780/10000, Loss: 0.012411155737936497\n",
      "Iteration: 4781/10000, Loss: 0.0100118862465024\n",
      "Iteration: 4782/10000, Loss: 0.017580822110176086\n",
      "Iteration: 4783/10000, Loss: 0.01662932150065899\n",
      "Iteration: 4784/10000, Loss: 0.009722830727696419\n",
      "Iteration: 4785/10000, Loss: 0.013281545601785183\n",
      "Iteration: 4786/10000, Loss: 0.01181904599070549\n",
      "Iteration: 4787/10000, Loss: 0.018274541944265366\n",
      "Iteration: 4788/10000, Loss: 0.0087528545409441\n",
      "Iteration: 4789/10000, Loss: 0.016431448981165886\n",
      "Iteration: 4790/10000, Loss: 0.015121866017580032\n",
      "Iteration: 4791/10000, Loss: 0.010655367746949196\n",
      "Iteration: 4792/10000, Loss: 0.009763720445334911\n",
      "Iteration: 4793/10000, Loss: 0.009092294611036777\n",
      "Iteration: 4794/10000, Loss: 0.013616232201457024\n",
      "Iteration: 4795/10000, Loss: 0.011809609830379486\n",
      "Iteration: 4796/10000, Loss: 0.014582136645913124\n",
      "Iteration: 4797/10000, Loss: 0.02603301778435707\n",
      "Iteration: 4798/10000, Loss: 0.015693524852395058\n",
      "Iteration: 4799/10000, Loss: 0.011467785574495792\n",
      "Iteration: 4800/10000, Loss: 0.017525944858789444\n",
      "Average test loss:  0.0037\n",
      "Iteration: 4801/10000, Loss: 0.017810359597206116\n",
      "Iteration: 4802/10000, Loss: 0.013137255795300007\n",
      "Iteration: 4803/10000, Loss: 0.011225667782127857\n",
      "Iteration: 4804/10000, Loss: 0.01512433122843504\n",
      "Iteration: 4805/10000, Loss: 0.013828885741531849\n",
      "Iteration: 4806/10000, Loss: 0.010543152689933777\n",
      "Iteration: 4807/10000, Loss: 0.011305240914225578\n",
      "Iteration: 4808/10000, Loss: 0.008453174494206905\n",
      "Iteration: 4809/10000, Loss: 0.011962499469518661\n",
      "Iteration: 4810/10000, Loss: 0.013581153005361557\n",
      "Iteration: 4811/10000, Loss: 0.019047750160098076\n",
      "Iteration: 4812/10000, Loss: 0.014543343335390091\n",
      "Iteration: 4813/10000, Loss: 0.015018060803413391\n",
      "Iteration: 4814/10000, Loss: 0.009912223555147648\n",
      "Iteration: 4815/10000, Loss: 0.018264498561620712\n",
      "Iteration: 4816/10000, Loss: 0.0147141357883811\n",
      "Iteration: 4817/10000, Loss: 0.012429147958755493\n",
      "Iteration: 4818/10000, Loss: 0.017878424376249313\n",
      "Iteration: 4819/10000, Loss: 0.018447307869791985\n",
      "Iteration: 4820/10000, Loss: 0.011930298991501331\n",
      "Iteration: 4821/10000, Loss: 0.013187997974455357\n",
      "Iteration: 4822/10000, Loss: 0.018687866628170013\n",
      "Iteration: 4823/10000, Loss: 0.01703120395541191\n",
      "Iteration: 4824/10000, Loss: 0.01565411314368248\n",
      "Iteration: 4825/10000, Loss: 0.012834941036999226\n",
      "Iteration: 4826/10000, Loss: 0.01631695032119751\n",
      "Iteration: 4827/10000, Loss: 0.016232697293162346\n",
      "Iteration: 4828/10000, Loss: 0.01661553978919983\n",
      "Iteration: 4829/10000, Loss: 0.01694188453257084\n",
      "Iteration: 4830/10000, Loss: 0.013986005447804928\n",
      "Iteration: 4831/10000, Loss: 0.019375376403331757\n",
      "Iteration: 4832/10000, Loss: 0.01311434619128704\n",
      "Iteration: 4833/10000, Loss: 0.015467354096472263\n",
      "Iteration: 4834/10000, Loss: 0.01810801401734352\n",
      "Iteration: 4835/10000, Loss: 0.01955696940422058\n",
      "Iteration: 4836/10000, Loss: 0.014605805277824402\n",
      "Iteration: 4837/10000, Loss: 0.017672203481197357\n",
      "Iteration: 4838/10000, Loss: 0.01599881425499916\n",
      "Iteration: 4839/10000, Loss: 0.012852871790528297\n",
      "Iteration: 4840/10000, Loss: 0.014512095600366592\n",
      "Iteration: 4841/10000, Loss: 0.017582545056939125\n",
      "Iteration: 4842/10000, Loss: 0.01356872171163559\n",
      "Iteration: 4843/10000, Loss: 0.011471351608633995\n",
      "Iteration: 4844/10000, Loss: 0.014727762900292873\n",
      "Iteration: 4845/10000, Loss: 0.015167281031608582\n",
      "Iteration: 4846/10000, Loss: 0.01587393507361412\n",
      "Iteration: 4847/10000, Loss: 0.012559128925204277\n",
      "Iteration: 4848/10000, Loss: 0.01713797077536583\n",
      "Iteration: 4849/10000, Loss: 0.016551919281482697\n",
      "Iteration: 4850/10000, Loss: 0.00993794109672308\n",
      "Iteration: 4851/10000, Loss: 0.015054561197757721\n",
      "Iteration: 4852/10000, Loss: 0.009490042924880981\n",
      "Iteration: 4853/10000, Loss: 0.012513542547821999\n",
      "Iteration: 4854/10000, Loss: 0.02136976271867752\n",
      "Iteration: 4855/10000, Loss: 0.019538065418601036\n",
      "Iteration: 4856/10000, Loss: 0.011756287887692451\n",
      "Iteration: 4857/10000, Loss: 0.013749437406659126\n",
      "Iteration: 4858/10000, Loss: 0.014050736092031002\n",
      "Iteration: 4859/10000, Loss: 0.013950621709227562\n",
      "Iteration: 4860/10000, Loss: 0.018525613471865654\n",
      "Iteration: 4861/10000, Loss: 0.01438283920288086\n",
      "Iteration: 4862/10000, Loss: 0.011502283625304699\n",
      "Iteration: 4863/10000, Loss: 0.008981822989881039\n",
      "Iteration: 4864/10000, Loss: 0.010850916616618633\n",
      "Iteration: 4865/10000, Loss: 0.02279464527964592\n",
      "Iteration: 4866/10000, Loss: 0.016858015209436417\n",
      "Iteration: 4867/10000, Loss: 0.009290158748626709\n",
      "Iteration: 4868/10000, Loss: 0.013071000576019287\n",
      "Iteration: 4869/10000, Loss: 0.01683228835463524\n",
      "Iteration: 4870/10000, Loss: 0.02295488864183426\n",
      "Iteration: 4871/10000, Loss: 0.01610511913895607\n",
      "Iteration: 4872/10000, Loss: 0.016296647489070892\n",
      "Iteration: 4873/10000, Loss: 0.016141723841428757\n",
      "Iteration: 4874/10000, Loss: 0.012805664911866188\n",
      "Iteration: 4875/10000, Loss: 0.01724179834127426\n",
      "Iteration: 4876/10000, Loss: 0.015263751149177551\n",
      "Iteration: 4877/10000, Loss: 0.01471987646073103\n",
      "Iteration: 4878/10000, Loss: 0.015047624707221985\n",
      "Iteration: 4879/10000, Loss: 0.008890208788216114\n",
      "Iteration: 4880/10000, Loss: 0.012361771427094936\n",
      "Iteration: 4881/10000, Loss: 0.009991131722927094\n",
      "Iteration: 4882/10000, Loss: 0.01130463182926178\n",
      "Iteration: 4883/10000, Loss: 0.01734156906604767\n",
      "Iteration: 4884/10000, Loss: 0.012046758085489273\n",
      "Iteration: 4885/10000, Loss: 0.013772877864539623\n",
      "Iteration: 4886/10000, Loss: 0.013705756515264511\n",
      "Iteration: 4887/10000, Loss: 0.014161786995828152\n",
      "Iteration: 4888/10000, Loss: 0.01688215509057045\n",
      "Iteration: 4889/10000, Loss: 0.013578358106315136\n",
      "Iteration: 4890/10000, Loss: 0.015549344941973686\n",
      "Iteration: 4891/10000, Loss: 0.01105700433254242\n",
      "Iteration: 4892/10000, Loss: 0.014856724999845028\n",
      "Iteration: 4893/10000, Loss: 0.016525866463780403\n",
      "Iteration: 4894/10000, Loss: 0.01295920368283987\n",
      "Iteration: 4895/10000, Loss: 0.0186216551810503\n",
      "Iteration: 4896/10000, Loss: 0.014754504896700382\n",
      "Iteration: 4897/10000, Loss: 0.014198594726622105\n",
      "Iteration: 4898/10000, Loss: 0.008223418146371841\n",
      "Iteration: 4899/10000, Loss: 0.011563852429389954\n",
      "Iteration: 4900/10000, Loss: 0.015143949538469315\n",
      "Average test loss:  0.0025\n",
      "Iteration: 4901/10000, Loss: 0.016136517748236656\n",
      "Iteration: 4902/10000, Loss: 0.012351025827229023\n",
      "Iteration: 4903/10000, Loss: 0.009464374743402004\n",
      "Iteration: 4904/10000, Loss: 0.013957798480987549\n",
      "Iteration: 4905/10000, Loss: 0.01320494245737791\n",
      "Iteration: 4906/10000, Loss: 0.009089311584830284\n",
      "Iteration: 4907/10000, Loss: 0.01344563439488411\n",
      "Iteration: 4908/10000, Loss: 0.013367578387260437\n",
      "Iteration: 4909/10000, Loss: 0.016967030242085457\n",
      "Iteration: 4910/10000, Loss: 0.015547654591500759\n",
      "Iteration: 4911/10000, Loss: 0.012962487526237965\n",
      "Iteration: 4912/10000, Loss: 0.01693381927907467\n",
      "Iteration: 4913/10000, Loss: 0.01646910421550274\n",
      "Iteration: 4914/10000, Loss: 0.007744430564343929\n",
      "Iteration: 4915/10000, Loss: 0.01016614492982626\n",
      "Iteration: 4916/10000, Loss: 0.013312461785972118\n",
      "Iteration: 4917/10000, Loss: 0.011099876835942268\n",
      "Iteration: 4918/10000, Loss: 0.012003757990896702\n",
      "Iteration: 4919/10000, Loss: 0.015296168625354767\n",
      "Iteration: 4920/10000, Loss: 0.01634931191802025\n",
      "Iteration: 4921/10000, Loss: 0.021679511293768883\n",
      "Iteration: 4922/10000, Loss: 0.013817115686833858\n",
      "Iteration: 4923/10000, Loss: 0.010392937809228897\n",
      "Iteration: 4924/10000, Loss: 0.01473736111074686\n",
      "Iteration: 4925/10000, Loss: 0.010919899679720402\n",
      "Iteration: 4926/10000, Loss: 0.0183264072984457\n",
      "Iteration: 4927/10000, Loss: 0.013655515387654305\n",
      "Iteration: 4928/10000, Loss: 0.011774756014347076\n",
      "Iteration: 4929/10000, Loss: 0.008493672125041485\n",
      "Iteration: 4930/10000, Loss: 0.010574504733085632\n",
      "Iteration: 4931/10000, Loss: 0.013078233227133751\n",
      "Iteration: 4932/10000, Loss: 0.02050992287695408\n",
      "Iteration: 4933/10000, Loss: 0.019492369145154953\n",
      "Iteration: 4934/10000, Loss: 0.010908485390245914\n",
      "Iteration: 4935/10000, Loss: 0.01809418573975563\n",
      "Iteration: 4936/10000, Loss: 0.014204968698322773\n",
      "Iteration: 4937/10000, Loss: 0.017797298729419708\n",
      "Iteration: 4938/10000, Loss: 0.0146129559725523\n",
      "Iteration: 4939/10000, Loss: 0.012901859357953072\n",
      "Iteration: 4940/10000, Loss: 0.007753496523946524\n",
      "Iteration: 4941/10000, Loss: 0.0143981222063303\n",
      "Iteration: 4942/10000, Loss: 0.010476511903107166\n",
      "Iteration: 4943/10000, Loss: 0.012590779922902584\n",
      "Iteration: 4944/10000, Loss: 0.019431665539741516\n",
      "Iteration: 4945/10000, Loss: 0.012003259733319283\n",
      "Iteration: 4946/10000, Loss: 0.015474901534616947\n",
      "Iteration: 4947/10000, Loss: 0.01668676547706127\n",
      "Iteration: 4948/10000, Loss: 0.010622483678162098\n",
      "Iteration: 4949/10000, Loss: 0.016611268743872643\n",
      "Iteration: 4950/10000, Loss: 0.013257338665425777\n",
      "Iteration: 4951/10000, Loss: 0.018199274316430092\n",
      "Iteration: 4952/10000, Loss: 0.014262214303016663\n",
      "Iteration: 4953/10000, Loss: 0.011126591823995113\n",
      "Iteration: 4954/10000, Loss: 0.010909630917012691\n",
      "Iteration: 4955/10000, Loss: 0.007923334836959839\n",
      "Iteration: 4956/10000, Loss: 0.009320026263594627\n",
      "Iteration: 4957/10000, Loss: 0.020513638854026794\n",
      "Iteration: 4958/10000, Loss: 0.01469774916768074\n",
      "Iteration: 4959/10000, Loss: 0.01145884208381176\n",
      "Iteration: 4960/10000, Loss: 0.013470739126205444\n",
      "Iteration: 4961/10000, Loss: 0.012716379016637802\n",
      "Iteration: 4962/10000, Loss: 0.009397661313414574\n",
      "Iteration: 4963/10000, Loss: 0.013395072892308235\n",
      "Iteration: 4964/10000, Loss: 0.01265299879014492\n",
      "Iteration: 4965/10000, Loss: 0.014326055534183979\n",
      "Iteration: 4966/10000, Loss: 0.017742399126291275\n",
      "Iteration: 4967/10000, Loss: 0.011776327155530453\n",
      "Iteration: 4968/10000, Loss: 0.009051158092916012\n",
      "Iteration: 4969/10000, Loss: 0.013451781123876572\n",
      "Iteration: 4970/10000, Loss: 0.01741369441151619\n",
      "Iteration: 4971/10000, Loss: 0.010935388505458832\n",
      "Iteration: 4972/10000, Loss: 0.01665564253926277\n",
      "Iteration: 4973/10000, Loss: 0.01884438842535019\n",
      "Iteration: 4974/10000, Loss: 0.02242058515548706\n",
      "Iteration: 4975/10000, Loss: 0.009537353180348873\n",
      "Iteration: 4976/10000, Loss: 0.008335110731422901\n",
      "Iteration: 4977/10000, Loss: 0.015990251675248146\n",
      "Iteration: 4978/10000, Loss: 0.011722705326974392\n",
      "Iteration: 4979/10000, Loss: 0.012463322840631008\n",
      "Iteration: 4980/10000, Loss: 0.00903908722102642\n",
      "Iteration: 4981/10000, Loss: 0.011109979823231697\n",
      "Iteration: 4982/10000, Loss: 0.014649948105216026\n",
      "Iteration: 4983/10000, Loss: 0.024701455608010292\n",
      "Iteration: 4984/10000, Loss: 0.012657755985856056\n",
      "Iteration: 4985/10000, Loss: 0.013606641441583633\n",
      "Iteration: 4986/10000, Loss: 0.008541450835764408\n",
      "Iteration: 4987/10000, Loss: 0.008609957993030548\n",
      "Iteration: 4988/10000, Loss: 0.019192242994904518\n",
      "Iteration: 4989/10000, Loss: 0.018950307741761208\n",
      "Iteration: 4990/10000, Loss: 0.014926634728908539\n",
      "Iteration: 4991/10000, Loss: 0.011005583219230175\n",
      "Iteration: 4992/10000, Loss: 0.012923380360007286\n",
      "Iteration: 4993/10000, Loss: 0.008789829909801483\n",
      "Iteration: 4994/10000, Loss: 0.013994061388075352\n",
      "Iteration: 4995/10000, Loss: 0.0127448420971632\n",
      "Iteration: 4996/10000, Loss: 0.010855996049940586\n",
      "Iteration: 4997/10000, Loss: 0.01124144159257412\n",
      "Iteration: 4998/10000, Loss: 0.01082671619951725\n",
      "Iteration: 4999/10000, Loss: 0.007713972590863705\n",
      "Iteration: 5000/10000, Loss: 0.018350830301642418\n",
      "Average test loss:  0.0030\n",
      "Iteration: 5001/10000, Loss: 0.01199965551495552\n",
      "Iteration: 5002/10000, Loss: 0.017638901248574257\n",
      "Iteration: 5003/10000, Loss: 0.013248135335743427\n",
      "Iteration: 5004/10000, Loss: 0.013965250924229622\n",
      "Iteration: 5005/10000, Loss: 0.016728363931179047\n",
      "Iteration: 5006/10000, Loss: 0.008767200633883476\n",
      "Iteration: 5007/10000, Loss: 0.009233936667442322\n",
      "Iteration: 5008/10000, Loss: 0.0172550231218338\n",
      "Iteration: 5009/10000, Loss: 0.010275357402861118\n",
      "Iteration: 5010/10000, Loss: 0.01456400752067566\n",
      "Iteration: 5011/10000, Loss: 0.015304853208363056\n",
      "Iteration: 5012/10000, Loss: 0.015250185504555702\n",
      "Iteration: 5013/10000, Loss: 0.016727428883314133\n",
      "Iteration: 5014/10000, Loss: 0.013542520813643932\n",
      "Iteration: 5015/10000, Loss: 0.01077214814722538\n",
      "Iteration: 5016/10000, Loss: 0.012342024594545364\n",
      "Iteration: 5017/10000, Loss: 0.009864235296845436\n",
      "Iteration: 5018/10000, Loss: 0.011033219285309315\n",
      "Iteration: 5019/10000, Loss: 0.012121674604713917\n",
      "Iteration: 5020/10000, Loss: 0.018261447548866272\n",
      "Iteration: 5021/10000, Loss: 0.014017995446920395\n",
      "Iteration: 5022/10000, Loss: 0.016828209161758423\n",
      "Iteration: 5023/10000, Loss: 0.02063719928264618\n",
      "Iteration: 5024/10000, Loss: 0.0136914337053895\n",
      "Iteration: 5025/10000, Loss: 0.01341948751360178\n",
      "Iteration: 5026/10000, Loss: 0.013148095458745956\n",
      "Iteration: 5027/10000, Loss: 0.016972452402114868\n",
      "Iteration: 5028/10000, Loss: 0.010714362375438213\n",
      "Iteration: 5029/10000, Loss: 0.011456703767180443\n",
      "Iteration: 5030/10000, Loss: 0.020778456702828407\n",
      "Iteration: 5031/10000, Loss: 0.01590535044670105\n",
      "Iteration: 5032/10000, Loss: 0.01422545313835144\n",
      "Iteration: 5033/10000, Loss: 0.012516109272837639\n",
      "Iteration: 5034/10000, Loss: 0.011941793374717236\n",
      "Iteration: 5035/10000, Loss: 0.011678820475935936\n",
      "Iteration: 5036/10000, Loss: 0.014264319092035294\n",
      "Iteration: 5037/10000, Loss: 0.013007484376430511\n",
      "Iteration: 5038/10000, Loss: 0.010484919883310795\n",
      "Iteration: 5039/10000, Loss: 0.011712022125720978\n",
      "Iteration: 5040/10000, Loss: 0.012532851658761501\n",
      "Iteration: 5041/10000, Loss: 0.013711584731936455\n",
      "Iteration: 5042/10000, Loss: 0.012804592959582806\n",
      "Iteration: 5043/10000, Loss: 0.019161446020007133\n",
      "Iteration: 5044/10000, Loss: 0.014969093725085258\n",
      "Iteration: 5045/10000, Loss: 0.015070558525621891\n",
      "Iteration: 5046/10000, Loss: 0.012330489233136177\n",
      "Iteration: 5047/10000, Loss: 0.011836615391075611\n",
      "Iteration: 5048/10000, Loss: 0.006728583015501499\n",
      "Iteration: 5049/10000, Loss: 0.010141374543309212\n",
      "Iteration: 5050/10000, Loss: 0.014163841493427753\n",
      "Iteration: 5051/10000, Loss: 0.00829073041677475\n",
      "Iteration: 5052/10000, Loss: 0.016994936391711235\n",
      "Iteration: 5053/10000, Loss: 0.01359885185956955\n",
      "Iteration: 5054/10000, Loss: 0.009121532551944256\n",
      "Iteration: 5055/10000, Loss: 0.0074658626690506935\n",
      "Iteration: 5056/10000, Loss: 0.013980742543935776\n",
      "Iteration: 5057/10000, Loss: 0.0099478829652071\n",
      "Iteration: 5058/10000, Loss: 0.011490734294056892\n",
      "Iteration: 5059/10000, Loss: 0.011130854487419128\n",
      "Iteration: 5060/10000, Loss: 0.009960299357771873\n",
      "Iteration: 5061/10000, Loss: 0.017311103641986847\n",
      "Iteration: 5062/10000, Loss: 0.011399068869650364\n",
      "Iteration: 5063/10000, Loss: 0.015220063738524914\n",
      "Iteration: 5064/10000, Loss: 0.01245427317917347\n",
      "Iteration: 5065/10000, Loss: 0.01253514364361763\n",
      "Iteration: 5066/10000, Loss: 0.014584958553314209\n",
      "Iteration: 5067/10000, Loss: 0.014184175059199333\n",
      "Iteration: 5068/10000, Loss: 0.016230151057243347\n",
      "Iteration: 5069/10000, Loss: 0.013791978359222412\n",
      "Iteration: 5070/10000, Loss: 0.014892686158418655\n",
      "Iteration: 5071/10000, Loss: 0.01172336284071207\n",
      "Iteration: 5072/10000, Loss: 0.013458957895636559\n",
      "Iteration: 5073/10000, Loss: 0.017383480444550514\n",
      "Iteration: 5074/10000, Loss: 0.016454676166176796\n",
      "Iteration: 5075/10000, Loss: 0.016323553398251534\n",
      "Iteration: 5076/10000, Loss: 0.012927446514368057\n",
      "Iteration: 5077/10000, Loss: 0.009682532399892807\n",
      "Iteration: 5078/10000, Loss: 0.010877073742449284\n",
      "Iteration: 5079/10000, Loss: 0.01754164509475231\n",
      "Iteration: 5080/10000, Loss: 0.011777181178331375\n",
      "Iteration: 5081/10000, Loss: 0.012612449936568737\n",
      "Iteration: 5082/10000, Loss: 0.014087457209825516\n",
      "Iteration: 5083/10000, Loss: 0.02476160228252411\n",
      "Iteration: 5084/10000, Loss: 0.014575089327991009\n",
      "Iteration: 5085/10000, Loss: 0.016741953790187836\n",
      "Iteration: 5086/10000, Loss: 0.012620346620678902\n",
      "Iteration: 5087/10000, Loss: 0.01269112154841423\n",
      "Iteration: 5088/10000, Loss: 0.013341514393687248\n",
      "Iteration: 5089/10000, Loss: 0.015002363361418247\n",
      "Iteration: 5090/10000, Loss: 0.01727145165205002\n",
      "Iteration: 5091/10000, Loss: 0.007969256490468979\n",
      "Iteration: 5092/10000, Loss: 0.013271371833980083\n",
      "Iteration: 5093/10000, Loss: 0.012050640769302845\n",
      "Iteration: 5094/10000, Loss: 0.0170349832624197\n",
      "Iteration: 5095/10000, Loss: 0.013101770542562008\n",
      "Iteration: 5096/10000, Loss: 0.013407831080257893\n",
      "Iteration: 5097/10000, Loss: 0.01621801033616066\n",
      "Iteration: 5098/10000, Loss: 0.010900869965553284\n",
      "Iteration: 5099/10000, Loss: 0.013445389457046986\n",
      "Iteration: 5100/10000, Loss: 0.013398580253124237\n",
      "Average test loss:  0.0028\n",
      "Iteration: 5101/10000, Loss: 0.015307225286960602\n",
      "Iteration: 5102/10000, Loss: 0.014268945902585983\n",
      "Iteration: 5103/10000, Loss: 0.011720375157892704\n",
      "Iteration: 5104/10000, Loss: 0.012356390245258808\n",
      "Iteration: 5105/10000, Loss: 0.0183088518679142\n",
      "Iteration: 5106/10000, Loss: 0.02105351909995079\n",
      "Iteration: 5107/10000, Loss: 0.007254722528159618\n",
      "Iteration: 5108/10000, Loss: 0.020228825509548187\n",
      "Iteration: 5109/10000, Loss: 0.007855293340981007\n",
      "Iteration: 5110/10000, Loss: 0.015026446431875229\n",
      "Iteration: 5111/10000, Loss: 0.01560704130679369\n",
      "Iteration: 5112/10000, Loss: 0.011654172092676163\n",
      "Iteration: 5113/10000, Loss: 0.011670933105051517\n",
      "Iteration: 5114/10000, Loss: 0.013619808480143547\n",
      "Iteration: 5115/10000, Loss: 0.01925528049468994\n",
      "Iteration: 5116/10000, Loss: 0.01279135700315237\n",
      "Iteration: 5117/10000, Loss: 0.010850424878299236\n",
      "Iteration: 5118/10000, Loss: 0.01398666575551033\n",
      "Iteration: 5119/10000, Loss: 0.011808967217803001\n",
      "Iteration: 5120/10000, Loss: 0.016465382650494576\n",
      "Iteration: 5121/10000, Loss: 0.008254645392298698\n",
      "Iteration: 5122/10000, Loss: 0.017514580860733986\n",
      "Iteration: 5123/10000, Loss: 0.01627247966825962\n",
      "Iteration: 5124/10000, Loss: 0.016353443264961243\n",
      "Iteration: 5125/10000, Loss: 0.012848122976720333\n",
      "Iteration: 5126/10000, Loss: 0.019111966714262962\n",
      "Iteration: 5127/10000, Loss: 0.008289256133139133\n",
      "Iteration: 5128/10000, Loss: 0.008798481896519661\n",
      "Iteration: 5129/10000, Loss: 0.019469957798719406\n",
      "Iteration: 5130/10000, Loss: 0.013720797374844551\n",
      "Iteration: 5131/10000, Loss: 0.016383016481995583\n",
      "Iteration: 5132/10000, Loss: 0.013245203532278538\n",
      "Iteration: 5133/10000, Loss: 0.017673414200544357\n",
      "Iteration: 5134/10000, Loss: 0.010624822229146957\n",
      "Iteration: 5135/10000, Loss: 0.011847957037389278\n",
      "Iteration: 5136/10000, Loss: 0.018680822104215622\n",
      "Iteration: 5137/10000, Loss: 0.017164528369903564\n",
      "Iteration: 5138/10000, Loss: 0.010609188117086887\n",
      "Iteration: 5139/10000, Loss: 0.012495581991970539\n",
      "Iteration: 5140/10000, Loss: 0.018077991902828217\n",
      "Iteration: 5141/10000, Loss: 0.015560857020318508\n",
      "Iteration: 5142/10000, Loss: 0.012582430616021156\n",
      "Iteration: 5143/10000, Loss: 0.01403895579278469\n",
      "Iteration: 5144/10000, Loss: 0.012896583415567875\n",
      "Iteration: 5145/10000, Loss: 0.011650146916508675\n",
      "Iteration: 5146/10000, Loss: 0.013135907240211964\n",
      "Iteration: 5147/10000, Loss: 0.01646895706653595\n",
      "Iteration: 5148/10000, Loss: 0.012156246230006218\n",
      "Iteration: 5149/10000, Loss: 0.011497643776237965\n",
      "Iteration: 5150/10000, Loss: 0.011113769374787807\n",
      "Iteration: 5151/10000, Loss: 0.010314959101378918\n",
      "Iteration: 5152/10000, Loss: 0.014201157726347446\n",
      "Iteration: 5153/10000, Loss: 0.013692568056285381\n",
      "Iteration: 5154/10000, Loss: 0.015408783219754696\n",
      "Iteration: 5155/10000, Loss: 0.00955488532781601\n",
      "Iteration: 5156/10000, Loss: 0.016286136582493782\n",
      "Iteration: 5157/10000, Loss: 0.008048947900533676\n",
      "Iteration: 5158/10000, Loss: 0.01807035692036152\n",
      "Iteration: 5159/10000, Loss: 0.012302146293222904\n",
      "Iteration: 5160/10000, Loss: 0.014532659202814102\n",
      "Iteration: 5161/10000, Loss: 0.011724395677447319\n",
      "Iteration: 5162/10000, Loss: 0.0075407568365335464\n",
      "Iteration: 5163/10000, Loss: 0.015109662897884846\n",
      "Iteration: 5164/10000, Loss: 0.009499650448560715\n",
      "Iteration: 5165/10000, Loss: 0.015284900553524494\n",
      "Iteration: 5166/10000, Loss: 0.007663806434720755\n",
      "Iteration: 5167/10000, Loss: 0.01586855761706829\n",
      "Iteration: 5168/10000, Loss: 0.010358518920838833\n",
      "Iteration: 5169/10000, Loss: 0.015035247430205345\n",
      "Iteration: 5170/10000, Loss: 0.01581921987235546\n",
      "Iteration: 5171/10000, Loss: 0.012091116979718208\n",
      "Iteration: 5172/10000, Loss: 0.014990635216236115\n",
      "Iteration: 5173/10000, Loss: 0.011963206343352795\n",
      "Iteration: 5174/10000, Loss: 0.014546635560691357\n",
      "Iteration: 5175/10000, Loss: 0.011617625132203102\n",
      "Iteration: 5176/10000, Loss: 0.014916998334228992\n",
      "Iteration: 5177/10000, Loss: 0.01845012791454792\n",
      "Iteration: 5178/10000, Loss: 0.014927376993000507\n",
      "Iteration: 5179/10000, Loss: 0.011109084822237492\n",
      "Iteration: 5180/10000, Loss: 0.020330393686890602\n",
      "Iteration: 5181/10000, Loss: 0.005542535800486803\n",
      "Iteration: 5182/10000, Loss: 0.013403384014964104\n",
      "Iteration: 5183/10000, Loss: 0.012433578260242939\n",
      "Iteration: 5184/10000, Loss: 0.010671591386198997\n",
      "Iteration: 5185/10000, Loss: 0.016536375507712364\n",
      "Iteration: 5186/10000, Loss: 0.020679611712694168\n",
      "Iteration: 5187/10000, Loss: 0.010639631189405918\n",
      "Iteration: 5188/10000, Loss: 0.013148241676390171\n",
      "Iteration: 5189/10000, Loss: 0.009784271009266376\n",
      "Iteration: 5190/10000, Loss: 0.013266073539853096\n",
      "Iteration: 5191/10000, Loss: 0.014358061365783215\n",
      "Iteration: 5192/10000, Loss: 0.008852066472172737\n",
      "Iteration: 5193/10000, Loss: 0.010908025316894054\n",
      "Iteration: 5194/10000, Loss: 0.01564635895192623\n",
      "Iteration: 5195/10000, Loss: 0.01669028401374817\n",
      "Iteration: 5196/10000, Loss: 0.018258223310112953\n",
      "Iteration: 5197/10000, Loss: 0.01001685205847025\n",
      "Iteration: 5198/10000, Loss: 0.016162406653165817\n",
      "Iteration: 5199/10000, Loss: 0.013805077411234379\n",
      "Iteration: 5200/10000, Loss: 0.011736277490854263\n",
      "Average test loss:  0.0023\n",
      "Iteration: 5201/10000, Loss: 0.018237965181469917\n",
      "Iteration: 5202/10000, Loss: 0.01443171501159668\n",
      "Iteration: 5203/10000, Loss: 0.006100967060774565\n",
      "Iteration: 5204/10000, Loss: 0.013854981400072575\n",
      "Iteration: 5205/10000, Loss: 0.011793174780905247\n",
      "Iteration: 5206/10000, Loss: 0.016261326149106026\n",
      "Iteration: 5207/10000, Loss: 0.013157342560589314\n",
      "Iteration: 5208/10000, Loss: 0.01593998447060585\n",
      "Iteration: 5209/10000, Loss: 0.013898525387048721\n",
      "Iteration: 5210/10000, Loss: 0.009726542979478836\n",
      "Iteration: 5211/10000, Loss: 0.01661222241818905\n",
      "Iteration: 5212/10000, Loss: 0.011587518267333508\n",
      "Iteration: 5213/10000, Loss: 0.01586911454796791\n",
      "Iteration: 5214/10000, Loss: 0.014634989202022552\n",
      "Iteration: 5215/10000, Loss: 0.013155789114534855\n",
      "Iteration: 5216/10000, Loss: 0.013469510711729527\n",
      "Iteration: 5217/10000, Loss: 0.012268050573766232\n",
      "Iteration: 5218/10000, Loss: 0.016178129240870476\n",
      "Iteration: 5219/10000, Loss: 0.011111395433545113\n",
      "Iteration: 5220/10000, Loss: 0.010414489544928074\n",
      "Iteration: 5221/10000, Loss: 0.014322205446660519\n",
      "Iteration: 5222/10000, Loss: 0.012875985354185104\n",
      "Iteration: 5223/10000, Loss: 0.01211046613752842\n",
      "Iteration: 5224/10000, Loss: 0.022647252306342125\n",
      "Iteration: 5225/10000, Loss: 0.01615656353533268\n",
      "Iteration: 5226/10000, Loss: 0.013718219473958015\n",
      "Iteration: 5227/10000, Loss: 0.014127328991889954\n",
      "Iteration: 5228/10000, Loss: 0.007102975156158209\n",
      "Iteration: 5229/10000, Loss: 0.01202898658812046\n",
      "Iteration: 5230/10000, Loss: 0.011808999814093113\n",
      "Iteration: 5231/10000, Loss: 0.015419323928654194\n",
      "Iteration: 5232/10000, Loss: 0.014759943820536137\n",
      "Iteration: 5233/10000, Loss: 0.01422303169965744\n",
      "Iteration: 5234/10000, Loss: 0.011800481006503105\n",
      "Iteration: 5235/10000, Loss: 0.018342291936278343\n",
      "Iteration: 5236/10000, Loss: 0.00935720931738615\n",
      "Iteration: 5237/10000, Loss: 0.013453622348606586\n",
      "Iteration: 5238/10000, Loss: 0.011783847585320473\n",
      "Iteration: 5239/10000, Loss: 0.008903475478291512\n",
      "Iteration: 5240/10000, Loss: 0.014409972354769707\n",
      "Iteration: 5241/10000, Loss: 0.013535366393625736\n",
      "Iteration: 5242/10000, Loss: 0.015570981428027153\n",
      "Iteration: 5243/10000, Loss: 0.007880409248173237\n",
      "Iteration: 5244/10000, Loss: 0.013757550157606602\n",
      "Iteration: 5245/10000, Loss: 0.011065645143389702\n",
      "Iteration: 5246/10000, Loss: 0.015831798315048218\n",
      "Iteration: 5247/10000, Loss: 0.012480898760259151\n",
      "Iteration: 5248/10000, Loss: 0.013909826055169106\n",
      "Iteration: 5249/10000, Loss: 0.015530179254710674\n",
      "Iteration: 5250/10000, Loss: 0.009589270688593388\n",
      "Iteration: 5251/10000, Loss: 0.007164253853261471\n",
      "Iteration: 5252/10000, Loss: 0.016089757904410362\n",
      "Iteration: 5253/10000, Loss: 0.010638050734996796\n",
      "Iteration: 5254/10000, Loss: 0.017929639667272568\n",
      "Iteration: 5255/10000, Loss: 0.015452147461473942\n",
      "Iteration: 5256/10000, Loss: 0.013203498907387257\n",
      "Iteration: 5257/10000, Loss: 0.010985828004777431\n",
      "Iteration: 5258/10000, Loss: 0.011863145045936108\n",
      "Iteration: 5259/10000, Loss: 0.010828372091054916\n",
      "Iteration: 5260/10000, Loss: 0.013268704526126385\n",
      "Iteration: 5261/10000, Loss: 0.012795602902770042\n",
      "Iteration: 5262/10000, Loss: 0.013559732586145401\n",
      "Iteration: 5263/10000, Loss: 0.017016848549246788\n",
      "Iteration: 5264/10000, Loss: 0.01435806043446064\n",
      "Iteration: 5265/10000, Loss: 0.01440403237938881\n",
      "Iteration: 5266/10000, Loss: 0.016303136944770813\n",
      "Iteration: 5267/10000, Loss: 0.01619745045900345\n",
      "Iteration: 5268/10000, Loss: 0.010914384387433529\n",
      "Iteration: 5269/10000, Loss: 0.0113003458827734\n",
      "Iteration: 5270/10000, Loss: 0.015498245134949684\n",
      "Iteration: 5271/10000, Loss: 0.00869421660900116\n",
      "Iteration: 5272/10000, Loss: 0.008987351320683956\n",
      "Iteration: 5273/10000, Loss: 0.016768723726272583\n",
      "Iteration: 5274/10000, Loss: 0.017791850492358208\n",
      "Iteration: 5275/10000, Loss: 0.01272191759198904\n",
      "Iteration: 5276/10000, Loss: 0.01680023781955242\n",
      "Iteration: 5277/10000, Loss: 0.014671619050204754\n",
      "Iteration: 5278/10000, Loss: 0.01608334481716156\n",
      "Iteration: 5279/10000, Loss: 0.011979777365922928\n",
      "Iteration: 5280/10000, Loss: 0.011277295649051666\n",
      "Iteration: 5281/10000, Loss: 0.010376734659075737\n",
      "Iteration: 5282/10000, Loss: 0.013732022605836391\n",
      "Iteration: 5283/10000, Loss: 0.014674906618893147\n",
      "Iteration: 5284/10000, Loss: 0.010738206095993519\n",
      "Iteration: 5285/10000, Loss: 0.02039741724729538\n",
      "Iteration: 5286/10000, Loss: 0.015737945213913918\n",
      "Iteration: 5287/10000, Loss: 0.02066993899643421\n",
      "Iteration: 5288/10000, Loss: 0.012395346537232399\n",
      "Iteration: 5289/10000, Loss: 0.01070496253669262\n",
      "Iteration: 5290/10000, Loss: 0.013714497908949852\n",
      "Iteration: 5291/10000, Loss: 0.012493708170950413\n",
      "Iteration: 5292/10000, Loss: 0.012083570472896099\n",
      "Iteration: 5293/10000, Loss: 0.010005494579672813\n",
      "Iteration: 5294/10000, Loss: 0.011109561659395695\n",
      "Iteration: 5295/10000, Loss: 0.01245984435081482\n",
      "Iteration: 5296/10000, Loss: 0.008580920286476612\n",
      "Iteration: 5297/10000, Loss: 0.011917075142264366\n",
      "Iteration: 5298/10000, Loss: 0.015005410648882389\n",
      "Iteration: 5299/10000, Loss: 0.012455684132874012\n",
      "Iteration: 5300/10000, Loss: 0.010048890486359596\n",
      "Average test loss:  0.0040\n",
      "Iteration: 5301/10000, Loss: 0.013330335728824139\n",
      "Iteration: 5302/10000, Loss: 0.009770638309419155\n",
      "Iteration: 5303/10000, Loss: 0.01051295455545187\n",
      "Iteration: 5304/10000, Loss: 0.01165754720568657\n",
      "Iteration: 5305/10000, Loss: 0.013452532701194286\n",
      "Iteration: 5306/10000, Loss: 0.013141298666596413\n",
      "Iteration: 5307/10000, Loss: 0.012700006365776062\n",
      "Iteration: 5308/10000, Loss: 0.0069857994094491005\n",
      "Iteration: 5309/10000, Loss: 0.015558525919914246\n",
      "Iteration: 5310/10000, Loss: 0.019277621060609818\n",
      "Iteration: 5311/10000, Loss: 0.009299438446760178\n",
      "Iteration: 5312/10000, Loss: 0.01143703144043684\n",
      "Iteration: 5313/10000, Loss: 0.012700806371867657\n",
      "Iteration: 5314/10000, Loss: 0.010756268166005611\n",
      "Iteration: 5315/10000, Loss: 0.013088202103972435\n",
      "Iteration: 5316/10000, Loss: 0.015086082741618156\n",
      "Iteration: 5317/10000, Loss: 0.012161212041974068\n",
      "Iteration: 5318/10000, Loss: 0.01726016402244568\n",
      "Iteration: 5319/10000, Loss: 0.009669279679656029\n",
      "Iteration: 5320/10000, Loss: 0.010916722007095814\n",
      "Iteration: 5321/10000, Loss: 0.01270261313766241\n",
      "Iteration: 5322/10000, Loss: 0.013380502350628376\n",
      "Iteration: 5323/10000, Loss: 0.011479952372610569\n",
      "Iteration: 5324/10000, Loss: 0.012722283601760864\n",
      "Iteration: 5325/10000, Loss: 0.016292458400130272\n",
      "Iteration: 5326/10000, Loss: 0.01110856980085373\n",
      "Iteration: 5327/10000, Loss: 0.01501151267439127\n",
      "Iteration: 5328/10000, Loss: 0.01482514850795269\n",
      "Iteration: 5329/10000, Loss: 0.016429387032985687\n",
      "Iteration: 5330/10000, Loss: 0.009182368405163288\n",
      "Iteration: 5331/10000, Loss: 0.012719339691102505\n",
      "Iteration: 5332/10000, Loss: 0.01578695699572563\n",
      "Iteration: 5333/10000, Loss: 0.012350945733487606\n",
      "Iteration: 5334/10000, Loss: 0.019139809533953667\n",
      "Iteration: 5335/10000, Loss: 0.008925697766244411\n",
      "Iteration: 5336/10000, Loss: 0.00957472063601017\n",
      "Iteration: 5337/10000, Loss: 0.010687519796192646\n",
      "Iteration: 5338/10000, Loss: 0.018322709947824478\n",
      "Iteration: 5339/10000, Loss: 0.013749097473919392\n",
      "Iteration: 5340/10000, Loss: 0.01703847199678421\n",
      "Iteration: 5341/10000, Loss: 0.020459730178117752\n",
      "Iteration: 5342/10000, Loss: 0.009121126495301723\n",
      "Iteration: 5343/10000, Loss: 0.01229703240096569\n",
      "Iteration: 5344/10000, Loss: 0.006819165777415037\n",
      "Iteration: 5345/10000, Loss: 0.00926455482840538\n",
      "Iteration: 5346/10000, Loss: 0.015651416033506393\n",
      "Iteration: 5347/10000, Loss: 0.012146619148552418\n",
      "Iteration: 5348/10000, Loss: 0.014447014778852463\n",
      "Iteration: 5349/10000, Loss: 0.009724250994622707\n",
      "Iteration: 5350/10000, Loss: 0.013505552895367146\n",
      "Iteration: 5351/10000, Loss: 0.015856603160500526\n",
      "Iteration: 5352/10000, Loss: 0.01493636891245842\n",
      "Iteration: 5353/10000, Loss: 0.013367170467972755\n",
      "Iteration: 5354/10000, Loss: 0.008584447205066681\n",
      "Iteration: 5355/10000, Loss: 0.010229134932160378\n",
      "Iteration: 5356/10000, Loss: 0.010658405721187592\n",
      "Iteration: 5357/10000, Loss: 0.01530237216502428\n",
      "Iteration: 5358/10000, Loss: 0.010473423637449741\n",
      "Iteration: 5359/10000, Loss: 0.015642331913113594\n",
      "Iteration: 5360/10000, Loss: 0.005820115562528372\n",
      "Iteration: 5361/10000, Loss: 0.0110322879627347\n",
      "Iteration: 5362/10000, Loss: 0.011277548037469387\n",
      "Iteration: 5363/10000, Loss: 0.01014735084027052\n",
      "Iteration: 5364/10000, Loss: 0.011000513099133968\n",
      "Iteration: 5365/10000, Loss: 0.011153968051075935\n",
      "Iteration: 5366/10000, Loss: 0.012355420738458633\n",
      "Iteration: 5367/10000, Loss: 0.013797608204185963\n",
      "Iteration: 5368/10000, Loss: 0.015453176572918892\n",
      "Iteration: 5369/10000, Loss: 0.006999289151281118\n",
      "Iteration: 5370/10000, Loss: 0.013794424012303352\n",
      "Iteration: 5371/10000, Loss: 0.013327465392649174\n",
      "Iteration: 5372/10000, Loss: 0.01633656583726406\n",
      "Iteration: 5373/10000, Loss: 0.01712717115879059\n",
      "Iteration: 5374/10000, Loss: 0.012821044772863388\n",
      "Iteration: 5375/10000, Loss: 0.01582629606127739\n",
      "Iteration: 5376/10000, Loss: 0.010966846719384193\n",
      "Iteration: 5377/10000, Loss: 0.012978791259229183\n",
      "Iteration: 5378/10000, Loss: 0.01234196126461029\n",
      "Iteration: 5379/10000, Loss: 0.007817639037966728\n",
      "Iteration: 5380/10000, Loss: 0.011605655774474144\n",
      "Iteration: 5381/10000, Loss: 0.013268384151160717\n",
      "Iteration: 5382/10000, Loss: 0.013234477490186691\n",
      "Iteration: 5383/10000, Loss: 0.011706492863595486\n",
      "Iteration: 5384/10000, Loss: 0.011158705689013004\n",
      "Iteration: 5385/10000, Loss: 0.015307113528251648\n",
      "Iteration: 5386/10000, Loss: 0.014715963043272495\n",
      "Iteration: 5387/10000, Loss: 0.009881429374217987\n",
      "Iteration: 5388/10000, Loss: 0.013831047341227531\n",
      "Iteration: 5389/10000, Loss: 0.019785186275839806\n",
      "Iteration: 5390/10000, Loss: 0.013089101761579514\n",
      "Iteration: 5391/10000, Loss: 0.008331882767379284\n",
      "Iteration: 5392/10000, Loss: 0.014817123301327229\n",
      "Iteration: 5393/10000, Loss: 0.017966987565159798\n",
      "Iteration: 5394/10000, Loss: 0.004774800967425108\n",
      "Iteration: 5395/10000, Loss: 0.010478656738996506\n",
      "Iteration: 5396/10000, Loss: 0.010194016620516777\n",
      "Iteration: 5397/10000, Loss: 0.014100631698966026\n",
      "Iteration: 5398/10000, Loss: 0.01028007734566927\n",
      "Iteration: 5399/10000, Loss: 0.010924837552011013\n",
      "Iteration: 5400/10000, Loss: 0.011060330085456371\n",
      "Average test loss:  0.0027\n",
      "Iteration: 5401/10000, Loss: 0.015114562585949898\n",
      "Iteration: 5402/10000, Loss: 0.009685279801487923\n",
      "Iteration: 5403/10000, Loss: 0.015235129743814468\n",
      "Iteration: 5404/10000, Loss: 0.011979467235505581\n",
      "Iteration: 5405/10000, Loss: 0.009084553457796574\n",
      "Iteration: 5406/10000, Loss: 0.013623212464153767\n",
      "Iteration: 5407/10000, Loss: 0.009078028611838818\n",
      "Iteration: 5408/10000, Loss: 0.015450255014002323\n",
      "Iteration: 5409/10000, Loss: 0.017428692430257797\n",
      "Iteration: 5410/10000, Loss: 0.015123527497053146\n",
      "Iteration: 5411/10000, Loss: 0.009806757792830467\n",
      "Iteration: 5412/10000, Loss: 0.012122697196900845\n",
      "Iteration: 5413/10000, Loss: 0.010315069928765297\n",
      "Iteration: 5414/10000, Loss: 0.01732104830443859\n",
      "Iteration: 5415/10000, Loss: 0.015102493576705456\n",
      "Iteration: 5416/10000, Loss: 0.010477511212229729\n",
      "Iteration: 5417/10000, Loss: 0.01610052026808262\n",
      "Iteration: 5418/10000, Loss: 0.007237347308546305\n",
      "Iteration: 5419/10000, Loss: 0.00826860312372446\n",
      "Iteration: 5420/10000, Loss: 0.011313207447528839\n",
      "Iteration: 5421/10000, Loss: 0.013623683713376522\n",
      "Iteration: 5422/10000, Loss: 0.011229892261326313\n",
      "Iteration: 5423/10000, Loss: 0.016414733603596687\n",
      "Iteration: 5424/10000, Loss: 0.017536016181111336\n",
      "Iteration: 5425/10000, Loss: 0.009929508902132511\n",
      "Iteration: 5426/10000, Loss: 0.009912711568176746\n",
      "Iteration: 5427/10000, Loss: 0.01008437667042017\n",
      "Iteration: 5428/10000, Loss: 0.01671457663178444\n",
      "Iteration: 5429/10000, Loss: 0.00965461228042841\n",
      "Iteration: 5430/10000, Loss: 0.017129087820649147\n",
      "Iteration: 5431/10000, Loss: 0.013628020882606506\n",
      "Iteration: 5432/10000, Loss: 0.012322433292865753\n",
      "Iteration: 5433/10000, Loss: 0.01618047244846821\n",
      "Iteration: 5434/10000, Loss: 0.01123643945902586\n",
      "Iteration: 5435/10000, Loss: 0.014443904161453247\n",
      "Iteration: 5436/10000, Loss: 0.01280217058956623\n",
      "Iteration: 5437/10000, Loss: 0.009915126487612724\n",
      "Iteration: 5438/10000, Loss: 0.010501492768526077\n",
      "Iteration: 5439/10000, Loss: 0.017013540491461754\n",
      "Iteration: 5440/10000, Loss: 0.007607473060488701\n",
      "Iteration: 5441/10000, Loss: 0.012667866423726082\n",
      "Iteration: 5442/10000, Loss: 0.019970405846834183\n",
      "Iteration: 5443/10000, Loss: 0.013048447668552399\n",
      "Iteration: 5444/10000, Loss: 0.01790820248425007\n",
      "Iteration: 5445/10000, Loss: 0.016037574037909508\n",
      "Iteration: 5446/10000, Loss: 0.012755254283547401\n",
      "Iteration: 5447/10000, Loss: 0.012359126470983028\n",
      "Iteration: 5448/10000, Loss: 0.006918884348124266\n",
      "Iteration: 5449/10000, Loss: 0.013618526048958302\n",
      "Iteration: 5450/10000, Loss: 0.012817843817174435\n",
      "Iteration: 5451/10000, Loss: 0.009590987116098404\n",
      "Iteration: 5452/10000, Loss: 0.01748214103281498\n",
      "Iteration: 5453/10000, Loss: 0.01482977531850338\n",
      "Iteration: 5454/10000, Loss: 0.010964660905301571\n",
      "Iteration: 5455/10000, Loss: 0.017774095758795738\n",
      "Iteration: 5456/10000, Loss: 0.012744124978780746\n",
      "Iteration: 5457/10000, Loss: 0.014357469975948334\n",
      "Iteration: 5458/10000, Loss: 0.013550905510783195\n",
      "Iteration: 5459/10000, Loss: 0.011814294382929802\n",
      "Iteration: 5460/10000, Loss: 0.018738577142357826\n",
      "Iteration: 5461/10000, Loss: 0.011814727447926998\n",
      "Iteration: 5462/10000, Loss: 0.017494671046733856\n",
      "Iteration: 5463/10000, Loss: 0.0130712129175663\n",
      "Iteration: 5464/10000, Loss: 0.015875445678830147\n",
      "Iteration: 5465/10000, Loss: 0.010514060035347939\n",
      "Iteration: 5466/10000, Loss: 0.012114224955439568\n",
      "Iteration: 5467/10000, Loss: 0.015483962371945381\n",
      "Iteration: 5468/10000, Loss: 0.019060762599110603\n",
      "Iteration: 5469/10000, Loss: 0.014540310949087143\n",
      "Iteration: 5470/10000, Loss: 0.014730975963175297\n",
      "Iteration: 5471/10000, Loss: 0.022420909255743027\n",
      "Iteration: 5472/10000, Loss: 0.015163891948759556\n",
      "Iteration: 5473/10000, Loss: 0.013170501217246056\n",
      "Iteration: 5474/10000, Loss: 0.015001448802649975\n",
      "Iteration: 5475/10000, Loss: 0.008752440102398396\n",
      "Iteration: 5476/10000, Loss: 0.009980694390833378\n",
      "Iteration: 5477/10000, Loss: 0.01517175231128931\n",
      "Iteration: 5478/10000, Loss: 0.013484349474310875\n",
      "Iteration: 5479/10000, Loss: 0.018100906163454056\n",
      "Iteration: 5480/10000, Loss: 0.010128764435648918\n",
      "Iteration: 5481/10000, Loss: 0.013122356496751308\n",
      "Iteration: 5482/10000, Loss: 0.011933942325413227\n",
      "Iteration: 5483/10000, Loss: 0.015937093645334244\n",
      "Iteration: 5484/10000, Loss: 0.017280327156186104\n",
      "Iteration: 5485/10000, Loss: 0.01440356858074665\n",
      "Iteration: 5486/10000, Loss: 0.01087859645485878\n",
      "Iteration: 5487/10000, Loss: 0.01239076629281044\n",
      "Iteration: 5488/10000, Loss: 0.013195892795920372\n",
      "Iteration: 5489/10000, Loss: 0.01442403718829155\n",
      "Iteration: 5490/10000, Loss: 0.010881498456001282\n",
      "Iteration: 5491/10000, Loss: 0.01556010264903307\n",
      "Iteration: 5492/10000, Loss: 0.008639466017484665\n",
      "Iteration: 5493/10000, Loss: 0.016205066815018654\n",
      "Iteration: 5494/10000, Loss: 0.009460090659558773\n",
      "Iteration: 5495/10000, Loss: 0.013689449988305569\n",
      "Iteration: 5496/10000, Loss: 0.010462850332260132\n",
      "Iteration: 5497/10000, Loss: 0.010568375699222088\n",
      "Iteration: 5498/10000, Loss: 0.020176667720079422\n",
      "Iteration: 5499/10000, Loss: 0.013269844464957714\n",
      "Iteration: 5500/10000, Loss: 0.011634688824415207\n",
      "Average test loss:  0.0029\n",
      "Iteration: 5501/10000, Loss: 0.012540560215711594\n",
      "Iteration: 5502/10000, Loss: 0.018940987065434456\n",
      "Iteration: 5503/10000, Loss: 0.016149120405316353\n",
      "Iteration: 5504/10000, Loss: 0.01394294947385788\n",
      "Iteration: 5505/10000, Loss: 0.011338784359395504\n",
      "Iteration: 5506/10000, Loss: 0.015261296182870865\n",
      "Iteration: 5507/10000, Loss: 0.014208003878593445\n",
      "Iteration: 5508/10000, Loss: 0.009492234326899052\n",
      "Iteration: 5509/10000, Loss: 0.008540011011064053\n",
      "Iteration: 5510/10000, Loss: 0.013503865338861942\n",
      "Iteration: 5511/10000, Loss: 0.019608130678534508\n",
      "Iteration: 5512/10000, Loss: 0.011469128541648388\n",
      "Iteration: 5513/10000, Loss: 0.01454427931457758\n",
      "Iteration: 5514/10000, Loss: 0.017838388681411743\n",
      "Iteration: 5515/10000, Loss: 0.013643770478665829\n",
      "Iteration: 5516/10000, Loss: 0.009256813675165176\n",
      "Iteration: 5517/10000, Loss: 0.01160093117505312\n",
      "Iteration: 5518/10000, Loss: 0.008679484017193317\n",
      "Iteration: 5519/10000, Loss: 0.006208730395883322\n",
      "Iteration: 5520/10000, Loss: 0.011447431519627571\n",
      "Iteration: 5521/10000, Loss: 0.012794838286936283\n",
      "Iteration: 5522/10000, Loss: 0.01648302562534809\n",
      "Iteration: 5523/10000, Loss: 0.009931758046150208\n",
      "Iteration: 5524/10000, Loss: 0.013683979399502277\n",
      "Iteration: 5525/10000, Loss: 0.010598245076835155\n",
      "Iteration: 5526/10000, Loss: 0.011103867553174496\n",
      "Iteration: 5527/10000, Loss: 0.013322252780199051\n",
      "Iteration: 5528/10000, Loss: 0.01160865556448698\n",
      "Iteration: 5529/10000, Loss: 0.011867467314004898\n",
      "Iteration: 5530/10000, Loss: 0.012049534358084202\n",
      "Iteration: 5531/10000, Loss: 0.005710563622415066\n",
      "Iteration: 5532/10000, Loss: 0.015677984803915024\n",
      "Iteration: 5533/10000, Loss: 0.008714577183127403\n",
      "Iteration: 5534/10000, Loss: 0.01352004799991846\n",
      "Iteration: 5535/10000, Loss: 0.01312562171369791\n",
      "Iteration: 5536/10000, Loss: 0.011466682888567448\n",
      "Iteration: 5537/10000, Loss: 0.01125621609389782\n",
      "Iteration: 5538/10000, Loss: 0.010578691028058529\n",
      "Iteration: 5539/10000, Loss: 0.013075819239020348\n",
      "Iteration: 5540/10000, Loss: 0.015040487982332706\n",
      "Iteration: 5541/10000, Loss: 0.010319211520254612\n",
      "Iteration: 5542/10000, Loss: 0.013568080961704254\n",
      "Iteration: 5543/10000, Loss: 0.007905831560492516\n",
      "Iteration: 5544/10000, Loss: 0.008049843832850456\n",
      "Iteration: 5545/10000, Loss: 0.016452360898256302\n",
      "Iteration: 5546/10000, Loss: 0.01085567381232977\n",
      "Iteration: 5547/10000, Loss: 0.01094781793653965\n",
      "Iteration: 5548/10000, Loss: 0.011457868851721287\n",
      "Iteration: 5549/10000, Loss: 0.010794938541948795\n",
      "Iteration: 5550/10000, Loss: 0.015884865075349808\n",
      "Iteration: 5551/10000, Loss: 0.011562746949493885\n",
      "Iteration: 5552/10000, Loss: 0.013507399708032608\n",
      "Iteration: 5553/10000, Loss: 0.011818557977676392\n",
      "Iteration: 5554/10000, Loss: 0.018067847937345505\n",
      "Iteration: 5555/10000, Loss: 0.012261527590453625\n",
      "Iteration: 5556/10000, Loss: 0.013339748606085777\n",
      "Iteration: 5557/10000, Loss: 0.017731687054038048\n",
      "Iteration: 5558/10000, Loss: 0.010276822373270988\n",
      "Iteration: 5559/10000, Loss: 0.021394802257418633\n",
      "Iteration: 5560/10000, Loss: 0.008659739047288895\n",
      "Iteration: 5561/10000, Loss: 0.009585627354681492\n",
      "Iteration: 5562/10000, Loss: 0.009527847170829773\n",
      "Iteration: 5563/10000, Loss: 0.009933714754879475\n",
      "Iteration: 5564/10000, Loss: 0.010448584333062172\n",
      "Iteration: 5565/10000, Loss: 0.014543205499649048\n",
      "Iteration: 5566/10000, Loss: 0.012759624980390072\n",
      "Iteration: 5567/10000, Loss: 0.011553372256457806\n",
      "Iteration: 5568/10000, Loss: 0.018039528280496597\n",
      "Iteration: 5569/10000, Loss: 0.010561799630522728\n",
      "Iteration: 5570/10000, Loss: 0.009623107500374317\n",
      "Iteration: 5571/10000, Loss: 0.012543764896690845\n",
      "Iteration: 5572/10000, Loss: 0.010830771178007126\n",
      "Iteration: 5573/10000, Loss: 0.0110557172447443\n",
      "Iteration: 5574/10000, Loss: 0.01630951650440693\n",
      "Iteration: 5575/10000, Loss: 0.016666585579514503\n",
      "Iteration: 5576/10000, Loss: 0.01298392005264759\n",
      "Iteration: 5577/10000, Loss: 0.013358000665903091\n",
      "Iteration: 5578/10000, Loss: 0.011288449168205261\n",
      "Iteration: 5579/10000, Loss: 0.010404485277831554\n",
      "Iteration: 5580/10000, Loss: 0.01199650950729847\n",
      "Iteration: 5581/10000, Loss: 0.014332979917526245\n",
      "Iteration: 5582/10000, Loss: 0.023668626323342323\n",
      "Iteration: 5583/10000, Loss: 0.017957916483283043\n",
      "Iteration: 5584/10000, Loss: 0.016494067385792732\n",
      "Iteration: 5585/10000, Loss: 0.012597838416695595\n",
      "Iteration: 5586/10000, Loss: 0.025551406666636467\n",
      "Iteration: 5587/10000, Loss: 0.01530667208135128\n",
      "Iteration: 5588/10000, Loss: 0.011256415396928787\n",
      "Iteration: 5589/10000, Loss: 0.007434766739606857\n",
      "Iteration: 5590/10000, Loss: 0.011394541710615158\n",
      "Iteration: 5591/10000, Loss: 0.021410081535577774\n",
      "Iteration: 5592/10000, Loss: 0.013852634467184544\n",
      "Iteration: 5593/10000, Loss: 0.012878061272203922\n",
      "Iteration: 5594/10000, Loss: 0.007906084880232811\n",
      "Iteration: 5595/10000, Loss: 0.0073218923062086105\n",
      "Iteration: 5596/10000, Loss: 0.019221195951104164\n",
      "Iteration: 5597/10000, Loss: 0.012680736370384693\n",
      "Iteration: 5598/10000, Loss: 0.012093436904251575\n",
      "Iteration: 5599/10000, Loss: 0.015013600699603558\n",
      "Iteration: 5600/10000, Loss: 0.008780807256698608\n",
      "Average test loss:  0.0031\n",
      "Iteration: 5601/10000, Loss: 0.013165456242859364\n",
      "Iteration: 5602/10000, Loss: 0.01518222875893116\n",
      "Iteration: 5603/10000, Loss: 0.011188462376594543\n",
      "Iteration: 5604/10000, Loss: 0.014452068135142326\n",
      "Iteration: 5605/10000, Loss: 0.019245391711592674\n",
      "Iteration: 5606/10000, Loss: 0.013514558784663677\n",
      "Iteration: 5607/10000, Loss: 0.013818704523146152\n",
      "Iteration: 5608/10000, Loss: 0.006542486138641834\n",
      "Iteration: 5609/10000, Loss: 0.016899622976779938\n",
      "Iteration: 5610/10000, Loss: 0.013945979066193104\n",
      "Iteration: 5611/10000, Loss: 0.0044153109192848206\n",
      "Iteration: 5612/10000, Loss: 0.013783324509859085\n",
      "Iteration: 5613/10000, Loss: 0.019210122525691986\n",
      "Iteration: 5614/10000, Loss: 0.018450045958161354\n",
      "Iteration: 5615/10000, Loss: 0.014020644128322601\n",
      "Iteration: 5616/10000, Loss: 0.01486673578619957\n",
      "Iteration: 5617/10000, Loss: 0.015813160687685013\n",
      "Iteration: 5618/10000, Loss: 0.014056038111448288\n",
      "Iteration: 5619/10000, Loss: 0.014893980696797371\n",
      "Iteration: 5620/10000, Loss: 0.016647547483444214\n",
      "Iteration: 5621/10000, Loss: 0.01707109808921814\n",
      "Iteration: 5622/10000, Loss: 0.009045056998729706\n",
      "Iteration: 5623/10000, Loss: 0.015871195122599602\n",
      "Iteration: 5624/10000, Loss: 0.008141993544995785\n",
      "Iteration: 5625/10000, Loss: 0.009989690035581589\n",
      "Iteration: 5626/10000, Loss: 0.012971102260053158\n",
      "Iteration: 5627/10000, Loss: 0.009874707087874413\n",
      "Iteration: 5628/10000, Loss: 0.011545980349183083\n",
      "Iteration: 5629/10000, Loss: 0.011163052171468735\n",
      "Iteration: 5630/10000, Loss: 0.015606633387506008\n",
      "Iteration: 5631/10000, Loss: 0.011653967201709747\n",
      "Iteration: 5632/10000, Loss: 0.008000160567462444\n",
      "Iteration: 5633/10000, Loss: 0.012808375060558319\n",
      "Iteration: 5634/10000, Loss: 0.013468245044350624\n",
      "Iteration: 5635/10000, Loss: 0.007701165042817593\n",
      "Iteration: 5636/10000, Loss: 0.010825447738170624\n",
      "Iteration: 5637/10000, Loss: 0.011823325417935848\n",
      "Iteration: 5638/10000, Loss: 0.009662698954343796\n",
      "Iteration: 5639/10000, Loss: 0.018390236422419548\n",
      "Iteration: 5640/10000, Loss: 0.011533830314874649\n",
      "Iteration: 5641/10000, Loss: 0.01170491985976696\n",
      "Iteration: 5642/10000, Loss: 0.008317995816469193\n",
      "Iteration: 5643/10000, Loss: 0.012537850067019463\n",
      "Iteration: 5644/10000, Loss: 0.011642837896943092\n",
      "Iteration: 5645/10000, Loss: 0.011614423245191574\n",
      "Iteration: 5646/10000, Loss: 0.00826658122241497\n",
      "Iteration: 5647/10000, Loss: 0.014815131202340126\n",
      "Iteration: 5648/10000, Loss: 0.009273329749703407\n",
      "Iteration: 5649/10000, Loss: 0.013228695839643478\n",
      "Iteration: 5650/10000, Loss: 0.012033815495669842\n",
      "Iteration: 5651/10000, Loss: 0.013112299144268036\n",
      "Iteration: 5652/10000, Loss: 0.01353053841739893\n",
      "Iteration: 5653/10000, Loss: 0.010193390771746635\n",
      "Iteration: 5654/10000, Loss: 0.014561106450855732\n",
      "Iteration: 5655/10000, Loss: 0.01360469963401556\n",
      "Iteration: 5656/10000, Loss: 0.012070856988430023\n",
      "Iteration: 5657/10000, Loss: 0.013388918712735176\n",
      "Iteration: 5658/10000, Loss: 0.010881025344133377\n",
      "Iteration: 5659/10000, Loss: 0.013817168772220612\n",
      "Iteration: 5660/10000, Loss: 0.00837770476937294\n",
      "Iteration: 5661/10000, Loss: 0.01608213223516941\n",
      "Iteration: 5662/10000, Loss: 0.015543199144303799\n",
      "Iteration: 5663/10000, Loss: 0.01435589138418436\n",
      "Iteration: 5664/10000, Loss: 0.013746070675551891\n",
      "Iteration: 5665/10000, Loss: 0.0152082908898592\n",
      "Iteration: 5666/10000, Loss: 0.009686456061899662\n",
      "Iteration: 5667/10000, Loss: 0.015303685329854488\n",
      "Iteration: 5668/10000, Loss: 0.008687037043273449\n",
      "Iteration: 5669/10000, Loss: 0.012366734445095062\n",
      "Iteration: 5670/10000, Loss: 0.0163399837911129\n",
      "Iteration: 5671/10000, Loss: 0.01083197258412838\n",
      "Iteration: 5672/10000, Loss: 0.013803905807435513\n",
      "Iteration: 5673/10000, Loss: 0.011029974557459354\n",
      "Iteration: 5674/10000, Loss: 0.01136366743594408\n",
      "Iteration: 5675/10000, Loss: 0.012160531245172024\n",
      "Iteration: 5676/10000, Loss: 0.014688416384160519\n",
      "Iteration: 5677/10000, Loss: 0.012708327732980251\n",
      "Iteration: 5678/10000, Loss: 0.011340409517288208\n",
      "Iteration: 5679/10000, Loss: 0.010411973111331463\n",
      "Iteration: 5680/10000, Loss: 0.011357741430401802\n",
      "Iteration: 5681/10000, Loss: 0.014873876236379147\n",
      "Iteration: 5682/10000, Loss: 0.010458497330546379\n",
      "Iteration: 5683/10000, Loss: 0.013619132339954376\n",
      "Iteration: 5684/10000, Loss: 0.016648191958665848\n",
      "Iteration: 5685/10000, Loss: 0.012238724157214165\n",
      "Iteration: 5686/10000, Loss: 0.014055253937840462\n",
      "Iteration: 5687/10000, Loss: 0.00830430444329977\n",
      "Iteration: 5688/10000, Loss: 0.015537707135081291\n",
      "Iteration: 5689/10000, Loss: 0.013194586150348186\n",
      "Iteration: 5690/10000, Loss: 0.016517089679837227\n",
      "Iteration: 5691/10000, Loss: 0.015189778991043568\n",
      "Iteration: 5692/10000, Loss: 0.008975949138402939\n",
      "Iteration: 5693/10000, Loss: 0.010309578850865364\n",
      "Iteration: 5694/10000, Loss: 0.013952400535345078\n",
      "Iteration: 5695/10000, Loss: 0.013629418797791004\n",
      "Iteration: 5696/10000, Loss: 0.014856139197945595\n",
      "Iteration: 5697/10000, Loss: 0.0077198706567287445\n",
      "Iteration: 5698/10000, Loss: 0.009051910601556301\n",
      "Iteration: 5699/10000, Loss: 0.012482107616961002\n",
      "Iteration: 5700/10000, Loss: 0.014750273898243904\n",
      "Average test loss:  0.0027\n",
      "Iteration: 5701/10000, Loss: 0.013984807766973972\n",
      "Iteration: 5702/10000, Loss: 0.01160513237118721\n",
      "Iteration: 5703/10000, Loss: 0.009440720081329346\n",
      "Iteration: 5704/10000, Loss: 0.014426636509597301\n",
      "Iteration: 5705/10000, Loss: 0.013204011134803295\n",
      "Iteration: 5706/10000, Loss: 0.010926606133580208\n",
      "Iteration: 5707/10000, Loss: 0.009776762686669827\n",
      "Iteration: 5708/10000, Loss: 0.008585763163864613\n",
      "Iteration: 5709/10000, Loss: 0.010256362147629261\n",
      "Iteration: 5710/10000, Loss: 0.010322552174329758\n",
      "Iteration: 5711/10000, Loss: 0.015233931131660938\n",
      "Iteration: 5712/10000, Loss: 0.016864709556102753\n",
      "Iteration: 5713/10000, Loss: 0.010272372514009476\n",
      "Iteration: 5714/10000, Loss: 0.010842032730579376\n",
      "Iteration: 5715/10000, Loss: 0.011693715117871761\n",
      "Iteration: 5716/10000, Loss: 0.011793559417128563\n",
      "Iteration: 5717/10000, Loss: 0.015912353992462158\n",
      "Iteration: 5718/10000, Loss: 0.01684536412358284\n",
      "Iteration: 5719/10000, Loss: 0.016560932621359825\n",
      "Iteration: 5720/10000, Loss: 0.015038001351058483\n",
      "Iteration: 5721/10000, Loss: 0.010904697701334953\n",
      "Iteration: 5722/10000, Loss: 0.014369377866387367\n",
      "Iteration: 5723/10000, Loss: 0.012176118791103363\n",
      "Iteration: 5724/10000, Loss: 0.010189800523221493\n",
      "Iteration: 5725/10000, Loss: 0.015035014599561691\n",
      "Iteration: 5726/10000, Loss: 0.015342924743890762\n",
      "Iteration: 5727/10000, Loss: 0.014126141555607319\n",
      "Iteration: 5728/10000, Loss: 0.009330008178949356\n",
      "Iteration: 5729/10000, Loss: 0.014199769124388695\n",
      "Iteration: 5730/10000, Loss: 0.01258228998631239\n",
      "Iteration: 5731/10000, Loss: 0.010877142660319805\n",
      "Iteration: 5732/10000, Loss: 0.010767266154289246\n",
      "Iteration: 5733/10000, Loss: 0.009208861738443375\n",
      "Iteration: 5734/10000, Loss: 0.00459076976403594\n",
      "Iteration: 5735/10000, Loss: 0.01578522101044655\n",
      "Iteration: 5736/10000, Loss: 0.017268851399421692\n",
      "Iteration: 5737/10000, Loss: 0.014655825681984425\n",
      "Iteration: 5738/10000, Loss: 0.01435301173478365\n",
      "Iteration: 5739/10000, Loss: 0.014898774214088917\n",
      "Iteration: 5740/10000, Loss: 0.009523477405309677\n",
      "Iteration: 5741/10000, Loss: 0.014354449696838856\n",
      "Iteration: 5742/10000, Loss: 0.006327952723950148\n",
      "Iteration: 5743/10000, Loss: 0.014867758378386497\n",
      "Iteration: 5744/10000, Loss: 0.017868749797344208\n",
      "Iteration: 5745/10000, Loss: 0.011361069045960903\n",
      "Iteration: 5746/10000, Loss: 0.01054783258587122\n",
      "Iteration: 5747/10000, Loss: 0.012551194056868553\n",
      "Iteration: 5748/10000, Loss: 0.00924847275018692\n",
      "Iteration: 5749/10000, Loss: 0.009203442372381687\n",
      "Iteration: 5750/10000, Loss: 0.013090955093502998\n",
      "Iteration: 5751/10000, Loss: 0.013894249685108662\n",
      "Iteration: 5752/10000, Loss: 0.019332140684127808\n",
      "Iteration: 5753/10000, Loss: 0.016484694555401802\n",
      "Iteration: 5754/10000, Loss: 0.009122609160840511\n",
      "Iteration: 5755/10000, Loss: 0.015083154663443565\n",
      "Iteration: 5756/10000, Loss: 0.011561797000467777\n",
      "Iteration: 5757/10000, Loss: 0.008902457542717457\n",
      "Iteration: 5758/10000, Loss: 0.014031071215867996\n",
      "Iteration: 5759/10000, Loss: 0.01442213449627161\n",
      "Iteration: 5760/10000, Loss: 0.007161237765103579\n",
      "Iteration: 5761/10000, Loss: 0.010125258006155491\n",
      "Iteration: 5762/10000, Loss: 0.013003106229007244\n",
      "Iteration: 5763/10000, Loss: 0.015435709618031979\n",
      "Iteration: 5764/10000, Loss: 0.011216339655220509\n",
      "Iteration: 5765/10000, Loss: 0.018248524516820908\n",
      "Iteration: 5766/10000, Loss: 0.016655655577778816\n",
      "Iteration: 5767/10000, Loss: 0.009933225810527802\n",
      "Iteration: 5768/10000, Loss: 0.011681895703077316\n",
      "Iteration: 5769/10000, Loss: 0.016751009970903397\n",
      "Iteration: 5770/10000, Loss: 0.01627008244395256\n",
      "Iteration: 5771/10000, Loss: 0.0166382547467947\n",
      "Iteration: 5772/10000, Loss: 0.017517978325486183\n",
      "Iteration: 5773/10000, Loss: 0.01656215824186802\n",
      "Iteration: 5774/10000, Loss: 0.010546358302235603\n",
      "Iteration: 5775/10000, Loss: 0.012964766472578049\n",
      "Iteration: 5776/10000, Loss: 0.007298230659216642\n",
      "Iteration: 5777/10000, Loss: 0.010054286569356918\n",
      "Iteration: 5778/10000, Loss: 0.013061966747045517\n",
      "Iteration: 5779/10000, Loss: 0.010872052051126957\n",
      "Iteration: 5780/10000, Loss: 0.009153714403510094\n",
      "Iteration: 5781/10000, Loss: 0.010384296998381615\n",
      "Iteration: 5782/10000, Loss: 0.014058404602110386\n",
      "Iteration: 5783/10000, Loss: 0.017022229731082916\n",
      "Iteration: 5784/10000, Loss: 0.012986492365598679\n",
      "Iteration: 5785/10000, Loss: 0.012769302353262901\n",
      "Iteration: 5786/10000, Loss: 0.010487649589776993\n",
      "Iteration: 5787/10000, Loss: 0.011538492515683174\n",
      "Iteration: 5788/10000, Loss: 0.018271632492542267\n",
      "Iteration: 5789/10000, Loss: 0.011020105332136154\n",
      "Iteration: 5790/10000, Loss: 0.010769383050501347\n",
      "Iteration: 5791/10000, Loss: 0.004846853204071522\n",
      "Iteration: 5792/10000, Loss: 0.01480654813349247\n",
      "Iteration: 5793/10000, Loss: 0.013311238028109074\n",
      "Iteration: 5794/10000, Loss: 0.011090853251516819\n",
      "Iteration: 5795/10000, Loss: 0.012178213335573673\n",
      "Iteration: 5796/10000, Loss: 0.010265490040183067\n",
      "Iteration: 5797/10000, Loss: 0.01010662317276001\n",
      "Iteration: 5798/10000, Loss: 0.009417121298611164\n",
      "Iteration: 5799/10000, Loss: 0.017672929912805557\n",
      "Iteration: 5800/10000, Loss: 0.010176683776080608\n",
      "Average test loss:  0.0016\n",
      "Iteration: 5801/10000, Loss: 0.007332923356443644\n",
      "Iteration: 5802/10000, Loss: 0.012923491187393665\n",
      "Iteration: 5803/10000, Loss: 0.009173976257443428\n",
      "Iteration: 5804/10000, Loss: 0.012805118225514889\n",
      "Iteration: 5805/10000, Loss: 0.012140728533267975\n",
      "Iteration: 5806/10000, Loss: 0.012965564616024494\n",
      "Iteration: 5807/10000, Loss: 0.012487349100410938\n",
      "Iteration: 5808/10000, Loss: 0.019416917115449905\n",
      "Iteration: 5809/10000, Loss: 0.010893009603023529\n",
      "Iteration: 5810/10000, Loss: 0.009078700095415115\n",
      "Iteration: 5811/10000, Loss: 0.007883768528699875\n",
      "Iteration: 5812/10000, Loss: 0.010686099529266357\n",
      "Iteration: 5813/10000, Loss: 0.011160441674292088\n",
      "Iteration: 5814/10000, Loss: 0.016652675345540047\n",
      "Iteration: 5815/10000, Loss: 0.010053263045847416\n",
      "Iteration: 5816/10000, Loss: 0.010044357739388943\n",
      "Iteration: 5817/10000, Loss: 0.00974260549992323\n",
      "Iteration: 5818/10000, Loss: 0.018257468938827515\n",
      "Iteration: 5819/10000, Loss: 0.01154173631221056\n",
      "Iteration: 5820/10000, Loss: 0.012520243413746357\n",
      "Iteration: 5821/10000, Loss: 0.011744292452931404\n",
      "Iteration: 5822/10000, Loss: 0.013655113987624645\n",
      "Iteration: 5823/10000, Loss: 0.012434952892363071\n",
      "Iteration: 5824/10000, Loss: 0.01900673843920231\n",
      "Iteration: 5825/10000, Loss: 0.017250725999474525\n",
      "Iteration: 5826/10000, Loss: 0.01565191149711609\n",
      "Iteration: 5827/10000, Loss: 0.014063403941690922\n",
      "Iteration: 5828/10000, Loss: 0.00765440845862031\n",
      "Iteration: 5829/10000, Loss: 0.010777264833450317\n",
      "Iteration: 5830/10000, Loss: 0.00860612466931343\n",
      "Iteration: 5831/10000, Loss: 0.014129010029137135\n",
      "Iteration: 5832/10000, Loss: 0.015878096222877502\n",
      "Iteration: 5833/10000, Loss: 0.010750294663012028\n",
      "Iteration: 5834/10000, Loss: 0.010762006975710392\n",
      "Iteration: 5835/10000, Loss: 0.011971359141170979\n",
      "Iteration: 5836/10000, Loss: 0.01525917463004589\n",
      "Iteration: 5837/10000, Loss: 0.014962387271225452\n",
      "Iteration: 5838/10000, Loss: 0.00830706674605608\n",
      "Iteration: 5839/10000, Loss: 0.013180619105696678\n",
      "Iteration: 5840/10000, Loss: 0.009633614681661129\n",
      "Iteration: 5841/10000, Loss: 0.015773525461554527\n",
      "Iteration: 5842/10000, Loss: 0.015235803090035915\n",
      "Iteration: 5843/10000, Loss: 0.010744222439825535\n",
      "Iteration: 5844/10000, Loss: 0.009373810142278671\n",
      "Iteration: 5845/10000, Loss: 0.009663667529821396\n",
      "Iteration: 5846/10000, Loss: 0.017668776214122772\n",
      "Iteration: 5847/10000, Loss: 0.018613891676068306\n",
      "Iteration: 5848/10000, Loss: 0.014454447664320469\n",
      "Iteration: 5849/10000, Loss: 0.013640855439007282\n",
      "Iteration: 5850/10000, Loss: 0.008235215209424496\n",
      "Iteration: 5851/10000, Loss: 0.011491198092699051\n",
      "Iteration: 5852/10000, Loss: 0.015852218493819237\n",
      "Iteration: 5853/10000, Loss: 0.014800949953496456\n",
      "Iteration: 5854/10000, Loss: 0.01620040275156498\n",
      "Iteration: 5855/10000, Loss: 0.009639078751206398\n",
      "Iteration: 5856/10000, Loss: 0.012478451244533062\n",
      "Iteration: 5857/10000, Loss: 0.007019868120551109\n",
      "Iteration: 5858/10000, Loss: 0.01353366393595934\n",
      "Iteration: 5859/10000, Loss: 0.009931843727827072\n",
      "Iteration: 5860/10000, Loss: 0.014186919666826725\n",
      "Iteration: 5861/10000, Loss: 0.014010610990226269\n",
      "Iteration: 5862/10000, Loss: 0.011493729427456856\n",
      "Iteration: 5863/10000, Loss: 0.015050974674522877\n",
      "Iteration: 5864/10000, Loss: 0.013077802024781704\n",
      "Iteration: 5865/10000, Loss: 0.013459865935146809\n",
      "Iteration: 5866/10000, Loss: 0.015408880077302456\n",
      "Iteration: 5867/10000, Loss: 0.014749241061508656\n",
      "Iteration: 5868/10000, Loss: 0.010034493170678616\n",
      "Iteration: 5869/10000, Loss: 0.01155876461416483\n",
      "Iteration: 5870/10000, Loss: 0.012622331269085407\n",
      "Iteration: 5871/10000, Loss: 0.009516467340290546\n",
      "Iteration: 5872/10000, Loss: 0.00977039523422718\n",
      "Iteration: 5873/10000, Loss: 0.00945662148296833\n",
      "Iteration: 5874/10000, Loss: 0.013902232050895691\n",
      "Iteration: 5875/10000, Loss: 0.011289173737168312\n",
      "Iteration: 5876/10000, Loss: 0.01360179204493761\n",
      "Iteration: 5877/10000, Loss: 0.012101337313652039\n",
      "Iteration: 5878/10000, Loss: 0.013669167645275593\n",
      "Iteration: 5879/10000, Loss: 0.009117416106164455\n",
      "Iteration: 5880/10000, Loss: 0.007646122481673956\n",
      "Iteration: 5881/10000, Loss: 0.012357937172055244\n",
      "Iteration: 5882/10000, Loss: 0.014228933490812778\n",
      "Iteration: 5883/10000, Loss: 0.01044398918747902\n",
      "Iteration: 5884/10000, Loss: 0.011153049767017365\n",
      "Iteration: 5885/10000, Loss: 0.01487297099083662\n",
      "Iteration: 5886/10000, Loss: 0.015409090556204319\n",
      "Iteration: 5887/10000, Loss: 0.013775108382105827\n",
      "Iteration: 5888/10000, Loss: 0.007782897911965847\n",
      "Iteration: 5889/10000, Loss: 0.009345786646008492\n",
      "Iteration: 5890/10000, Loss: 0.01633492484688759\n",
      "Iteration: 5891/10000, Loss: 0.0087510384619236\n",
      "Iteration: 5892/10000, Loss: 0.01534461509436369\n",
      "Iteration: 5893/10000, Loss: 0.010940751992166042\n",
      "Iteration: 5894/10000, Loss: 0.010601245798170567\n",
      "Iteration: 5895/10000, Loss: 0.008083141408860683\n",
      "Iteration: 5896/10000, Loss: 0.015161573886871338\n",
      "Iteration: 5897/10000, Loss: 0.008219028823077679\n",
      "Iteration: 5898/10000, Loss: 0.013410629704594612\n",
      "Iteration: 5899/10000, Loss: 0.011982609517872334\n",
      "Iteration: 5900/10000, Loss: 0.015641339123249054\n",
      "Average test loss:  0.0021\n",
      "Iteration: 5901/10000, Loss: 0.012848052196204662\n",
      "Iteration: 5902/10000, Loss: 0.017072590067982674\n",
      "Iteration: 5903/10000, Loss: 0.010696987621486187\n",
      "Iteration: 5904/10000, Loss: 0.010869338177144527\n",
      "Iteration: 5905/10000, Loss: 0.008029666729271412\n",
      "Iteration: 5906/10000, Loss: 0.007708282675594091\n",
      "Iteration: 5907/10000, Loss: 0.009317870251834393\n",
      "Iteration: 5908/10000, Loss: 0.012526695616543293\n",
      "Iteration: 5909/10000, Loss: 0.017663639038801193\n",
      "Iteration: 5910/10000, Loss: 0.01425769180059433\n",
      "Iteration: 5911/10000, Loss: 0.014119310304522514\n",
      "Iteration: 5912/10000, Loss: 0.016964653506875038\n",
      "Iteration: 5913/10000, Loss: 0.012835931032896042\n",
      "Iteration: 5914/10000, Loss: 0.013418014161288738\n",
      "Iteration: 5915/10000, Loss: 0.008721842430531979\n",
      "Iteration: 5916/10000, Loss: 0.014349108561873436\n",
      "Iteration: 5917/10000, Loss: 0.01652911864221096\n",
      "Iteration: 5918/10000, Loss: 0.01362026296555996\n",
      "Iteration: 5919/10000, Loss: 0.01806211657822132\n",
      "Iteration: 5920/10000, Loss: 0.00988546572625637\n",
      "Iteration: 5921/10000, Loss: 0.013756662607192993\n",
      "Iteration: 5922/10000, Loss: 0.011891832575201988\n",
      "Iteration: 5923/10000, Loss: 0.00799718126654625\n",
      "Iteration: 5924/10000, Loss: 0.011917212046682835\n",
      "Iteration: 5925/10000, Loss: 0.01182513777166605\n",
      "Iteration: 5926/10000, Loss: 0.010712751187384129\n",
      "Iteration: 5927/10000, Loss: 0.00901723001152277\n",
      "Iteration: 5928/10000, Loss: 0.016646327450871468\n",
      "Iteration: 5929/10000, Loss: 0.015931271016597748\n",
      "Iteration: 5930/10000, Loss: 0.019535040482878685\n",
      "Iteration: 5931/10000, Loss: 0.012482987716794014\n",
      "Iteration: 5932/10000, Loss: 0.011573740281164646\n",
      "Iteration: 5933/10000, Loss: 0.008602477610111237\n",
      "Iteration: 5934/10000, Loss: 0.012191134504973888\n",
      "Iteration: 5935/10000, Loss: 0.009779504500329494\n",
      "Iteration: 5936/10000, Loss: 0.01388630736619234\n",
      "Iteration: 5937/10000, Loss: 0.013113996013998985\n",
      "Iteration: 5938/10000, Loss: 0.008898699656128883\n",
      "Iteration: 5939/10000, Loss: 0.010848145931959152\n",
      "Iteration: 5940/10000, Loss: 0.011492403224110603\n",
      "Iteration: 5941/10000, Loss: 0.012745668180286884\n",
      "Iteration: 5942/10000, Loss: 0.01369429100304842\n",
      "Iteration: 5943/10000, Loss: 0.012100358493626118\n",
      "Iteration: 5944/10000, Loss: 0.013619649223983288\n",
      "Iteration: 5945/10000, Loss: 0.015370486304163933\n",
      "Iteration: 5946/10000, Loss: 0.01312944944947958\n",
      "Iteration: 5947/10000, Loss: 0.0133633678779006\n",
      "Iteration: 5948/10000, Loss: 0.013890357688069344\n",
      "Iteration: 5949/10000, Loss: 0.011973779648542404\n",
      "Iteration: 5950/10000, Loss: 0.011691924184560776\n",
      "Iteration: 5951/10000, Loss: 0.016690153628587723\n",
      "Iteration: 5952/10000, Loss: 0.010240393690764904\n",
      "Iteration: 5953/10000, Loss: 0.008991794660687447\n",
      "Iteration: 5954/10000, Loss: 0.012826891615986824\n",
      "Iteration: 5955/10000, Loss: 0.007746330928057432\n",
      "Iteration: 5956/10000, Loss: 0.009593849070370197\n",
      "Iteration: 5957/10000, Loss: 0.011045827530324459\n",
      "Iteration: 5958/10000, Loss: 0.014108057133853436\n",
      "Iteration: 5959/10000, Loss: 0.011002571322023869\n",
      "Iteration: 5960/10000, Loss: 0.01509255263954401\n",
      "Iteration: 5961/10000, Loss: 0.01279496867209673\n",
      "Iteration: 5962/10000, Loss: 0.007820338942110538\n",
      "Iteration: 5963/10000, Loss: 0.014998959377408028\n",
      "Iteration: 5964/10000, Loss: 0.006478770636022091\n",
      "Iteration: 5965/10000, Loss: 0.009904933162033558\n",
      "Iteration: 5966/10000, Loss: 0.010387156158685684\n",
      "Iteration: 5967/10000, Loss: 0.014605092816054821\n",
      "Iteration: 5968/10000, Loss: 0.009094182401895523\n",
      "Iteration: 5969/10000, Loss: 0.015063540078699589\n",
      "Iteration: 5970/10000, Loss: 0.012649361044168472\n",
      "Iteration: 5971/10000, Loss: 0.009454391896724701\n",
      "Iteration: 5972/10000, Loss: 0.009909012354910374\n",
      "Iteration: 5973/10000, Loss: 0.008943955413997173\n",
      "Iteration: 5974/10000, Loss: 0.011903301812708378\n",
      "Iteration: 5975/10000, Loss: 0.01475494634360075\n",
      "Iteration: 5976/10000, Loss: 0.011307531967759132\n",
      "Iteration: 5977/10000, Loss: 0.013210656121373177\n",
      "Iteration: 5978/10000, Loss: 0.010776819661259651\n",
      "Iteration: 5979/10000, Loss: 0.01331491582095623\n",
      "Iteration: 5980/10000, Loss: 0.016216186806559563\n",
      "Iteration: 5981/10000, Loss: 0.010674802586436272\n",
      "Iteration: 5982/10000, Loss: 0.014634978026151657\n",
      "Iteration: 5983/10000, Loss: 0.013803088106215\n",
      "Iteration: 5984/10000, Loss: 0.007859455421566963\n",
      "Iteration: 5985/10000, Loss: 0.0114915044978261\n",
      "Iteration: 5986/10000, Loss: 0.01012431364506483\n",
      "Iteration: 5987/10000, Loss: 0.01050935871899128\n",
      "Iteration: 5988/10000, Loss: 0.010418836027383804\n",
      "Iteration: 5989/10000, Loss: 0.010864526964724064\n",
      "Iteration: 5990/10000, Loss: 0.01469480898231268\n",
      "Iteration: 5991/10000, Loss: 0.008921387605369091\n",
      "Iteration: 5992/10000, Loss: 0.008925830945372581\n",
      "Iteration: 5993/10000, Loss: 0.008081629872322083\n",
      "Iteration: 5994/10000, Loss: 0.01234667468816042\n",
      "Iteration: 5995/10000, Loss: 0.011403542011976242\n",
      "Iteration: 5996/10000, Loss: 0.01089802198112011\n",
      "Iteration: 5997/10000, Loss: 0.015694791451096535\n",
      "Iteration: 5998/10000, Loss: 0.010664594359695911\n",
      "Iteration: 5999/10000, Loss: 0.009194042533636093\n",
      "Iteration: 6000/10000, Loss: 0.014622218906879425\n",
      "Average test loss:  0.0050\n",
      "Iteration: 6001/10000, Loss: 0.016287708654999733\n",
      "Iteration: 6002/10000, Loss: 0.010976312682032585\n",
      "Iteration: 6003/10000, Loss: 0.016902435570955276\n",
      "Iteration: 6004/10000, Loss: 0.016560666263103485\n",
      "Iteration: 6005/10000, Loss: 0.014561674557626247\n",
      "Iteration: 6006/10000, Loss: 0.012483932077884674\n",
      "Iteration: 6007/10000, Loss: 0.011454015038907528\n",
      "Iteration: 6008/10000, Loss: 0.013827724382281303\n",
      "Iteration: 6009/10000, Loss: 0.00929420068860054\n",
      "Iteration: 6010/10000, Loss: 0.018353810533881187\n",
      "Iteration: 6011/10000, Loss: 0.008277727290987968\n",
      "Iteration: 6012/10000, Loss: 0.00927989836782217\n",
      "Iteration: 6013/10000, Loss: 0.008547971956431866\n",
      "Iteration: 6014/10000, Loss: 0.015704812481999397\n",
      "Iteration: 6015/10000, Loss: 0.009381053037941456\n",
      "Iteration: 6016/10000, Loss: 0.010143903084099293\n",
      "Iteration: 6017/10000, Loss: 0.010643349029123783\n",
      "Iteration: 6018/10000, Loss: 0.012862131930887699\n",
      "Iteration: 6019/10000, Loss: 0.014607436023652554\n",
      "Iteration: 6020/10000, Loss: 0.016195280477404594\n",
      "Iteration: 6021/10000, Loss: 0.0105438819155097\n",
      "Iteration: 6022/10000, Loss: 0.01377861201763153\n",
      "Iteration: 6023/10000, Loss: 0.013704098761081696\n",
      "Iteration: 6024/10000, Loss: 0.014113742858171463\n",
      "Iteration: 6025/10000, Loss: 0.015473725274205208\n",
      "Iteration: 6026/10000, Loss: 0.009073898196220398\n",
      "Iteration: 6027/10000, Loss: 0.011875157244503498\n",
      "Iteration: 6028/10000, Loss: 0.00984213501214981\n",
      "Iteration: 6029/10000, Loss: 0.012436321936547756\n",
      "Iteration: 6030/10000, Loss: 0.007373616565018892\n",
      "Iteration: 6031/10000, Loss: 0.005898645147681236\n",
      "Iteration: 6032/10000, Loss: 0.011635132133960724\n",
      "Iteration: 6033/10000, Loss: 0.008087851107120514\n",
      "Iteration: 6034/10000, Loss: 0.0121575016528368\n",
      "Iteration: 6035/10000, Loss: 0.008566020987927914\n",
      "Iteration: 6036/10000, Loss: 0.00711942370980978\n",
      "Iteration: 6037/10000, Loss: 0.004158084746450186\n",
      "Iteration: 6038/10000, Loss: 0.009995468892157078\n",
      "Iteration: 6039/10000, Loss: 0.010998062789440155\n",
      "Iteration: 6040/10000, Loss: 0.016121624037623405\n",
      "Iteration: 6041/10000, Loss: 0.011597859673202038\n",
      "Iteration: 6042/10000, Loss: 0.011298959143459797\n",
      "Iteration: 6043/10000, Loss: 0.013692768290638924\n",
      "Iteration: 6044/10000, Loss: 0.004136807285249233\n",
      "Iteration: 6045/10000, Loss: 0.0091850059106946\n",
      "Iteration: 6046/10000, Loss: 0.01098946388810873\n",
      "Iteration: 6047/10000, Loss: 0.011315674521028996\n",
      "Iteration: 6048/10000, Loss: 0.009216655045747757\n",
      "Iteration: 6049/10000, Loss: 0.007985037751495838\n",
      "Iteration: 6050/10000, Loss: 0.010256552137434483\n",
      "Iteration: 6051/10000, Loss: 0.00838781800121069\n",
      "Iteration: 6052/10000, Loss: 0.009498213417828083\n",
      "Iteration: 6053/10000, Loss: 0.015503235161304474\n",
      "Iteration: 6054/10000, Loss: 0.008785338141024113\n",
      "Iteration: 6055/10000, Loss: 0.0111720971763134\n",
      "Iteration: 6056/10000, Loss: 0.011433054693043232\n",
      "Iteration: 6057/10000, Loss: 0.008238975889980793\n",
      "Iteration: 6058/10000, Loss: 0.016349876299500465\n",
      "Iteration: 6059/10000, Loss: 0.013165676966309547\n",
      "Iteration: 6060/10000, Loss: 0.0136567996814847\n",
      "Iteration: 6061/10000, Loss: 0.01433816459029913\n",
      "Iteration: 6062/10000, Loss: 0.009621587581932545\n",
      "Iteration: 6063/10000, Loss: 0.010927204973995686\n",
      "Iteration: 6064/10000, Loss: 0.013318900018930435\n",
      "Iteration: 6065/10000, Loss: 0.0075819846242666245\n",
      "Iteration: 6066/10000, Loss: 0.007890508510172367\n",
      "Iteration: 6067/10000, Loss: 0.013095921836793423\n",
      "Iteration: 6068/10000, Loss: 0.011998268775641918\n",
      "Iteration: 6069/10000, Loss: 0.009199723601341248\n",
      "Iteration: 6070/10000, Loss: 0.010062115266919136\n",
      "Iteration: 6071/10000, Loss: 0.010651948861777782\n",
      "Iteration: 6072/10000, Loss: 0.015755800530314445\n",
      "Iteration: 6073/10000, Loss: 0.009504127316176891\n",
      "Iteration: 6074/10000, Loss: 0.010893197730183601\n",
      "Iteration: 6075/10000, Loss: 0.011837529949843884\n",
      "Iteration: 6076/10000, Loss: 0.013077367097139359\n",
      "Iteration: 6077/10000, Loss: 0.014789233915507793\n",
      "Iteration: 6078/10000, Loss: 0.01295413076877594\n",
      "Iteration: 6079/10000, Loss: 0.012466846033930779\n",
      "Iteration: 6080/10000, Loss: 0.014206483960151672\n",
      "Iteration: 6081/10000, Loss: 0.00831521488726139\n",
      "Iteration: 6082/10000, Loss: 0.009821482002735138\n",
      "Iteration: 6083/10000, Loss: 0.00835172925144434\n",
      "Iteration: 6084/10000, Loss: 0.009321563877165318\n",
      "Iteration: 6085/10000, Loss: 0.011339678429067135\n",
      "Iteration: 6086/10000, Loss: 0.01032953429967165\n",
      "Iteration: 6087/10000, Loss: 0.014453672803938389\n",
      "Iteration: 6088/10000, Loss: 0.012460848316550255\n",
      "Iteration: 6089/10000, Loss: 0.013218633830547333\n",
      "Iteration: 6090/10000, Loss: 0.009719503112137318\n",
      "Iteration: 6091/10000, Loss: 0.010814185254275799\n",
      "Iteration: 6092/10000, Loss: 0.008890487253665924\n",
      "Iteration: 6093/10000, Loss: 0.006914643105119467\n",
      "Iteration: 6094/10000, Loss: 0.010921112261712551\n",
      "Iteration: 6095/10000, Loss: 0.00998036377131939\n",
      "Iteration: 6096/10000, Loss: 0.010090099647641182\n",
      "Iteration: 6097/10000, Loss: 0.011909151449799538\n",
      "Iteration: 6098/10000, Loss: 0.01776915229856968\n",
      "Iteration: 6099/10000, Loss: 0.008814605884253979\n",
      "Iteration: 6100/10000, Loss: 0.006969908718019724\n",
      "Average test loss:  0.0025\n",
      "Iteration: 6101/10000, Loss: 0.01164444163441658\n",
      "Iteration: 6102/10000, Loss: 0.013020320795476437\n",
      "Iteration: 6103/10000, Loss: 0.008326292969286442\n",
      "Iteration: 6104/10000, Loss: 0.008409005589783192\n",
      "Iteration: 6105/10000, Loss: 0.005661354400217533\n",
      "Iteration: 6106/10000, Loss: 0.013308889232575893\n",
      "Iteration: 6107/10000, Loss: 0.011339251883327961\n",
      "Iteration: 6108/10000, Loss: 0.010785119608044624\n",
      "Iteration: 6109/10000, Loss: 0.013667390681803226\n",
      "Iteration: 6110/10000, Loss: 0.01165922824293375\n",
      "Iteration: 6111/10000, Loss: 0.010760229080915451\n",
      "Iteration: 6112/10000, Loss: 0.012896770611405373\n",
      "Iteration: 6113/10000, Loss: 0.012293408624827862\n",
      "Iteration: 6114/10000, Loss: 0.0133600989356637\n",
      "Iteration: 6115/10000, Loss: 0.01461951807141304\n",
      "Iteration: 6116/10000, Loss: 0.012319525703787804\n",
      "Iteration: 6117/10000, Loss: 0.012003147974610329\n",
      "Iteration: 6118/10000, Loss: 0.01006461400538683\n",
      "Iteration: 6119/10000, Loss: 0.007079496514052153\n",
      "Iteration: 6120/10000, Loss: 0.009103409014642239\n",
      "Iteration: 6121/10000, Loss: 0.014426109381020069\n",
      "Iteration: 6122/10000, Loss: 0.009182373061776161\n",
      "Iteration: 6123/10000, Loss: 0.01673707738518715\n",
      "Iteration: 6124/10000, Loss: 0.009352542459964752\n",
      "Iteration: 6125/10000, Loss: 0.01136308629065752\n",
      "Iteration: 6126/10000, Loss: 0.008574699983000755\n",
      "Iteration: 6127/10000, Loss: 0.014025403186678886\n",
      "Iteration: 6128/10000, Loss: 0.01871989294886589\n",
      "Iteration: 6129/10000, Loss: 0.01241182629019022\n",
      "Iteration: 6130/10000, Loss: 0.010698347352445126\n",
      "Iteration: 6131/10000, Loss: 0.008067358285188675\n",
      "Iteration: 6132/10000, Loss: 0.01113072782754898\n",
      "Iteration: 6133/10000, Loss: 0.01001085713505745\n",
      "Iteration: 6134/10000, Loss: 0.007877825759351254\n",
      "Iteration: 6135/10000, Loss: 0.009769191034138203\n",
      "Iteration: 6136/10000, Loss: 0.015685684978961945\n",
      "Iteration: 6137/10000, Loss: 0.011600988917052746\n",
      "Iteration: 6138/10000, Loss: 0.015460429713129997\n",
      "Iteration: 6139/10000, Loss: 0.010786169208586216\n",
      "Iteration: 6140/10000, Loss: 0.010144484229385853\n",
      "Iteration: 6141/10000, Loss: 0.009579965844750404\n",
      "Iteration: 6142/10000, Loss: 0.013200054876506329\n",
      "Iteration: 6143/10000, Loss: 0.00861049722880125\n",
      "Iteration: 6144/10000, Loss: 0.012969042174518108\n",
      "Iteration: 6145/10000, Loss: 0.015190115198493004\n",
      "Iteration: 6146/10000, Loss: 0.013090092688798904\n",
      "Iteration: 6147/10000, Loss: 0.010418979451060295\n",
      "Iteration: 6148/10000, Loss: 0.013288121670484543\n",
      "Iteration: 6149/10000, Loss: 0.013920201919972897\n",
      "Iteration: 6150/10000, Loss: 0.01374540850520134\n",
      "Iteration: 6151/10000, Loss: 0.0077552590519189835\n",
      "Iteration: 6152/10000, Loss: 0.01356720644980669\n",
      "Iteration: 6153/10000, Loss: 0.014731698669493198\n",
      "Iteration: 6154/10000, Loss: 0.00978677999228239\n",
      "Iteration: 6155/10000, Loss: 0.01188571099191904\n",
      "Iteration: 6156/10000, Loss: 0.0086396848782897\n",
      "Iteration: 6157/10000, Loss: 0.013290802016854286\n",
      "Iteration: 6158/10000, Loss: 0.010168217122554779\n",
      "Iteration: 6159/10000, Loss: 0.014118772000074387\n",
      "Iteration: 6160/10000, Loss: 0.01458484772592783\n",
      "Iteration: 6161/10000, Loss: 0.012165605090558529\n",
      "Iteration: 6162/10000, Loss: 0.006563856266438961\n",
      "Iteration: 6163/10000, Loss: 0.009794250130653381\n",
      "Iteration: 6164/10000, Loss: 0.0133488355204463\n",
      "Iteration: 6165/10000, Loss: 0.008279211819171906\n",
      "Iteration: 6166/10000, Loss: 0.01010600384324789\n",
      "Iteration: 6167/10000, Loss: 0.009763882495462894\n",
      "Iteration: 6168/10000, Loss: 0.01123963575810194\n",
      "Iteration: 6169/10000, Loss: 0.01460176706314087\n",
      "Iteration: 6170/10000, Loss: 0.006922356318682432\n",
      "Iteration: 6171/10000, Loss: 0.008269277401268482\n",
      "Iteration: 6172/10000, Loss: 0.008622176013886929\n",
      "Iteration: 6173/10000, Loss: 0.008237374015152454\n",
      "Iteration: 6174/10000, Loss: 0.013911809772253036\n",
      "Iteration: 6175/10000, Loss: 0.014544565230607986\n",
      "Iteration: 6176/10000, Loss: 0.008079958148300648\n",
      "Iteration: 6177/10000, Loss: 0.012912559323012829\n",
      "Iteration: 6178/10000, Loss: 0.015452992171049118\n",
      "Iteration: 6179/10000, Loss: 0.014064119197428226\n",
      "Iteration: 6180/10000, Loss: 0.007021167315542698\n",
      "Iteration: 6181/10000, Loss: 0.012883125804364681\n",
      "Iteration: 6182/10000, Loss: 0.013171364553272724\n",
      "Iteration: 6183/10000, Loss: 0.008844605647027493\n",
      "Iteration: 6184/10000, Loss: 0.009666068479418755\n",
      "Iteration: 6185/10000, Loss: 0.007764540612697601\n",
      "Iteration: 6186/10000, Loss: 0.006160425953567028\n",
      "Iteration: 6187/10000, Loss: 0.012304435484111309\n",
      "Iteration: 6188/10000, Loss: 0.01741737313568592\n",
      "Iteration: 6189/10000, Loss: 0.013046997599303722\n",
      "Iteration: 6190/10000, Loss: 0.01768207922577858\n",
      "Iteration: 6191/10000, Loss: 0.012484287843108177\n",
      "Iteration: 6192/10000, Loss: 0.009577891789376736\n",
      "Iteration: 6193/10000, Loss: 0.012212059460580349\n",
      "Iteration: 6194/10000, Loss: 0.013326063752174377\n",
      "Iteration: 6195/10000, Loss: 0.013651877641677856\n",
      "Iteration: 6196/10000, Loss: 0.013569940812885761\n",
      "Iteration: 6197/10000, Loss: 0.014238771051168442\n",
      "Iteration: 6198/10000, Loss: 0.011710140854120255\n",
      "Iteration: 6199/10000, Loss: 0.009954063221812248\n",
      "Iteration: 6200/10000, Loss: 0.011938381008803844\n",
      "Average test loss:  0.0030\n",
      "Iteration: 6201/10000, Loss: 0.015325314365327358\n",
      "Iteration: 6202/10000, Loss: 0.011863208375871181\n",
      "Iteration: 6203/10000, Loss: 0.015213590115308762\n",
      "Iteration: 6204/10000, Loss: 0.01343747228384018\n",
      "Iteration: 6205/10000, Loss: 0.012793480418622494\n",
      "Iteration: 6206/10000, Loss: 0.008872218430042267\n",
      "Iteration: 6207/10000, Loss: 0.015607509762048721\n",
      "Iteration: 6208/10000, Loss: 0.012685328722000122\n",
      "Iteration: 6209/10000, Loss: 0.00874977558851242\n",
      "Iteration: 6210/10000, Loss: 0.011577513068914413\n",
      "Iteration: 6211/10000, Loss: 0.011609595268964767\n",
      "Iteration: 6212/10000, Loss: 0.0074013168923556805\n",
      "Iteration: 6213/10000, Loss: 0.01263077836483717\n",
      "Iteration: 6214/10000, Loss: 0.015771614387631416\n",
      "Iteration: 6215/10000, Loss: 0.010700108483433723\n",
      "Iteration: 6216/10000, Loss: 0.01266462728381157\n",
      "Iteration: 6217/10000, Loss: 0.01037510298192501\n",
      "Iteration: 6218/10000, Loss: 0.008466542698442936\n",
      "Iteration: 6219/10000, Loss: 0.012736200354993343\n",
      "Iteration: 6220/10000, Loss: 0.009427833370864391\n",
      "Iteration: 6221/10000, Loss: 0.010534747503697872\n",
      "Iteration: 6222/10000, Loss: 0.012456017546355724\n",
      "Iteration: 6223/10000, Loss: 0.008877894841134548\n",
      "Iteration: 6224/10000, Loss: 0.009311474859714508\n",
      "Iteration: 6225/10000, Loss: 0.00979431439191103\n",
      "Iteration: 6226/10000, Loss: 0.011605254374444485\n",
      "Iteration: 6227/10000, Loss: 0.008988390676677227\n",
      "Iteration: 6228/10000, Loss: 0.010684389621019363\n",
      "Iteration: 6229/10000, Loss: 0.011986545287072659\n",
      "Iteration: 6230/10000, Loss: 0.009390839375555515\n",
      "Iteration: 6231/10000, Loss: 0.013833283446729183\n",
      "Iteration: 6232/10000, Loss: 0.007801658473908901\n",
      "Iteration: 6233/10000, Loss: 0.00940564926713705\n",
      "Iteration: 6234/10000, Loss: 0.012473070062696934\n",
      "Iteration: 6235/10000, Loss: 0.008573456667363644\n",
      "Iteration: 6236/10000, Loss: 0.013999364338815212\n",
      "Iteration: 6237/10000, Loss: 0.01395699568092823\n",
      "Iteration: 6238/10000, Loss: 0.009947499260306358\n",
      "Iteration: 6239/10000, Loss: 0.008033648133277893\n",
      "Iteration: 6240/10000, Loss: 0.01413725782185793\n",
      "Iteration: 6241/10000, Loss: 0.01647280715405941\n",
      "Iteration: 6242/10000, Loss: 0.012809297069907188\n",
      "Iteration: 6243/10000, Loss: 0.008906975388526917\n",
      "Iteration: 6244/10000, Loss: 0.016048189252614975\n",
      "Iteration: 6245/10000, Loss: 0.01355713326483965\n",
      "Iteration: 6246/10000, Loss: 0.015851685777306557\n",
      "Iteration: 6247/10000, Loss: 0.00928238220512867\n",
      "Iteration: 6248/10000, Loss: 0.011822400614619255\n",
      "Iteration: 6249/10000, Loss: 0.011938164941966534\n",
      "Iteration: 6250/10000, Loss: 0.01453374233096838\n",
      "Iteration: 6251/10000, Loss: 0.0107542984187603\n",
      "Iteration: 6252/10000, Loss: 0.0090621467679739\n",
      "Iteration: 6253/10000, Loss: 0.010457978583872318\n",
      "Iteration: 6254/10000, Loss: 0.012118954211473465\n",
      "Iteration: 6255/10000, Loss: 0.01344901043921709\n",
      "Iteration: 6256/10000, Loss: 0.009886017069220543\n",
      "Iteration: 6257/10000, Loss: 0.0169571153819561\n",
      "Iteration: 6258/10000, Loss: 0.013127214275300503\n",
      "Iteration: 6259/10000, Loss: 0.014089861884713173\n",
      "Iteration: 6260/10000, Loss: 0.01122396532446146\n",
      "Iteration: 6261/10000, Loss: 0.010053081437945366\n",
      "Iteration: 6262/10000, Loss: 0.010040814988315105\n",
      "Iteration: 6263/10000, Loss: 0.007159066386520863\n",
      "Iteration: 6264/10000, Loss: 0.009082158096134663\n",
      "Iteration: 6265/10000, Loss: 0.017147598788142204\n",
      "Iteration: 6266/10000, Loss: 0.009340115822851658\n",
      "Iteration: 6267/10000, Loss: 0.013309542089700699\n",
      "Iteration: 6268/10000, Loss: 0.01195274107158184\n",
      "Iteration: 6269/10000, Loss: 0.011263237334787846\n",
      "Iteration: 6270/10000, Loss: 0.011369631625711918\n",
      "Iteration: 6271/10000, Loss: 0.009437056258320808\n",
      "Iteration: 6272/10000, Loss: 0.012642454355955124\n",
      "Iteration: 6273/10000, Loss: 0.010915982536971569\n",
      "Iteration: 6274/10000, Loss: 0.012029873207211494\n",
      "Iteration: 6275/10000, Loss: 0.014659509062767029\n",
      "Iteration: 6276/10000, Loss: 0.014195089228451252\n",
      "Iteration: 6277/10000, Loss: 0.010144604369997978\n",
      "Iteration: 6278/10000, Loss: 0.008975699543952942\n",
      "Iteration: 6279/10000, Loss: 0.00796041451394558\n",
      "Iteration: 6280/10000, Loss: 0.009879155084490776\n",
      "Iteration: 6281/10000, Loss: 0.011828631162643433\n",
      "Iteration: 6282/10000, Loss: 0.011142938397824764\n",
      "Iteration: 6283/10000, Loss: 0.014862382784485817\n",
      "Iteration: 6284/10000, Loss: 0.010619092732667923\n",
      "Iteration: 6285/10000, Loss: 0.011059573851525784\n",
      "Iteration: 6286/10000, Loss: 0.014125363901257515\n",
      "Iteration: 6287/10000, Loss: 0.006068426184356213\n",
      "Iteration: 6288/10000, Loss: 0.009851668030023575\n",
      "Iteration: 6289/10000, Loss: 0.011067342944443226\n",
      "Iteration: 6290/10000, Loss: 0.011512027122080326\n",
      "Iteration: 6291/10000, Loss: 0.012468216940760612\n",
      "Iteration: 6292/10000, Loss: 0.012056970968842506\n",
      "Iteration: 6293/10000, Loss: 0.011343187652528286\n",
      "Iteration: 6294/10000, Loss: 0.011904152110219002\n",
      "Iteration: 6295/10000, Loss: 0.013989202678203583\n",
      "Iteration: 6296/10000, Loss: 0.011003578081727028\n",
      "Iteration: 6297/10000, Loss: 0.012858569622039795\n",
      "Iteration: 6298/10000, Loss: 0.0095090102404356\n",
      "Iteration: 6299/10000, Loss: 0.01113869994878769\n",
      "Iteration: 6300/10000, Loss: 0.008848423138260841\n",
      "Average test loss:  0.0032\n",
      "Iteration: 6301/10000, Loss: 0.0162181556224823\n",
      "Iteration: 6302/10000, Loss: 0.011186422780156136\n",
      "Iteration: 6303/10000, Loss: 0.011525176465511322\n",
      "Iteration: 6304/10000, Loss: 0.014876574277877808\n",
      "Iteration: 6305/10000, Loss: 0.012505644001066685\n",
      "Iteration: 6306/10000, Loss: 0.01158489566296339\n",
      "Iteration: 6307/10000, Loss: 0.012074208818376064\n",
      "Iteration: 6308/10000, Loss: 0.008862280286848545\n",
      "Iteration: 6309/10000, Loss: 0.010575100779533386\n",
      "Iteration: 6310/10000, Loss: 0.010771834291517735\n",
      "Iteration: 6311/10000, Loss: 0.01160357054322958\n",
      "Iteration: 6312/10000, Loss: 0.009895604103803635\n",
      "Iteration: 6313/10000, Loss: 0.01774645783007145\n",
      "Iteration: 6314/10000, Loss: 0.011730574071407318\n",
      "Iteration: 6315/10000, Loss: 0.010384622029960155\n",
      "Iteration: 6316/10000, Loss: 0.01106044091284275\n",
      "Iteration: 6317/10000, Loss: 0.013445235788822174\n",
      "Iteration: 6318/10000, Loss: 0.011964504607021809\n",
      "Iteration: 6319/10000, Loss: 0.012594341300427914\n",
      "Iteration: 6320/10000, Loss: 0.009027967229485512\n",
      "Iteration: 6321/10000, Loss: 0.01736028678715229\n",
      "Iteration: 6322/10000, Loss: 0.010881219059228897\n",
      "Iteration: 6323/10000, Loss: 0.009506914764642715\n",
      "Iteration: 6324/10000, Loss: 0.008297741413116455\n",
      "Iteration: 6325/10000, Loss: 0.007253636140376329\n",
      "Iteration: 6326/10000, Loss: 0.01131273154169321\n",
      "Iteration: 6327/10000, Loss: 0.008464585058391094\n",
      "Iteration: 6328/10000, Loss: 0.008850844576954842\n",
      "Iteration: 6329/10000, Loss: 0.011125828139483929\n",
      "Iteration: 6330/10000, Loss: 0.010293384082615376\n",
      "Iteration: 6331/10000, Loss: 0.012119685299694538\n",
      "Iteration: 6332/10000, Loss: 0.009868815541267395\n",
      "Iteration: 6333/10000, Loss: 0.012072478421032429\n",
      "Iteration: 6334/10000, Loss: 0.013250645250082016\n",
      "Iteration: 6335/10000, Loss: 0.012102743610739708\n",
      "Iteration: 6336/10000, Loss: 0.015242494642734528\n",
      "Iteration: 6337/10000, Loss: 0.011245290748775005\n",
      "Iteration: 6338/10000, Loss: 0.011197313666343689\n",
      "Iteration: 6339/10000, Loss: 0.00906591210514307\n",
      "Iteration: 6340/10000, Loss: 0.008700371719896793\n",
      "Iteration: 6341/10000, Loss: 0.010087447240948677\n",
      "Iteration: 6342/10000, Loss: 0.010126723907887936\n",
      "Iteration: 6343/10000, Loss: 0.012721440754830837\n",
      "Iteration: 6344/10000, Loss: 0.01094042044132948\n",
      "Iteration: 6345/10000, Loss: 0.0062334914691746235\n",
      "Iteration: 6346/10000, Loss: 0.011430410668253899\n",
      "Iteration: 6347/10000, Loss: 0.011904885992407799\n",
      "Iteration: 6348/10000, Loss: 0.005314464680850506\n",
      "Iteration: 6349/10000, Loss: 0.006031949073076248\n",
      "Iteration: 6350/10000, Loss: 0.009348608553409576\n",
      "Iteration: 6351/10000, Loss: 0.012368262745440006\n",
      "Iteration: 6352/10000, Loss: 0.015538185834884644\n",
      "Iteration: 6353/10000, Loss: 0.010887675918638706\n",
      "Iteration: 6354/10000, Loss: 0.008670540526509285\n",
      "Iteration: 6355/10000, Loss: 0.010648827068507671\n",
      "Iteration: 6356/10000, Loss: 0.009378551505506039\n",
      "Iteration: 6357/10000, Loss: 0.010527820326387882\n",
      "Iteration: 6358/10000, Loss: 0.012873577885329723\n",
      "Iteration: 6359/10000, Loss: 0.013104826211929321\n",
      "Iteration: 6360/10000, Loss: 0.008834043517708778\n",
      "Iteration: 6361/10000, Loss: 0.01268772967159748\n",
      "Iteration: 6362/10000, Loss: 0.008186554536223412\n",
      "Iteration: 6363/10000, Loss: 0.012005380354821682\n",
      "Iteration: 6364/10000, Loss: 0.012914041057229042\n",
      "Iteration: 6365/10000, Loss: 0.011467855423688889\n",
      "Iteration: 6366/10000, Loss: 0.013575900346040726\n",
      "Iteration: 6367/10000, Loss: 0.006229035090655088\n",
      "Iteration: 6368/10000, Loss: 0.007135114166885614\n",
      "Iteration: 6369/10000, Loss: 0.009523485787212849\n",
      "Iteration: 6370/10000, Loss: 0.010020370595157146\n",
      "Iteration: 6371/10000, Loss: 0.011723910458385944\n",
      "Iteration: 6372/10000, Loss: 0.015523054637014866\n",
      "Iteration: 6373/10000, Loss: 0.010616224259138107\n",
      "Iteration: 6374/10000, Loss: 0.013033618219196796\n",
      "Iteration: 6375/10000, Loss: 0.011486527509987354\n",
      "Iteration: 6376/10000, Loss: 0.011864999309182167\n",
      "Iteration: 6377/10000, Loss: 0.009172283113002777\n",
      "Iteration: 6378/10000, Loss: 0.013280344195663929\n",
      "Iteration: 6379/10000, Loss: 0.013013639487326145\n",
      "Iteration: 6380/10000, Loss: 0.014147242531180382\n",
      "Iteration: 6381/10000, Loss: 0.013521692715585232\n",
      "Iteration: 6382/10000, Loss: 0.009692790918052197\n",
      "Iteration: 6383/10000, Loss: 0.01203609723597765\n",
      "Iteration: 6384/10000, Loss: 0.02036139741539955\n",
      "Iteration: 6385/10000, Loss: 0.011418591253459454\n",
      "Iteration: 6386/10000, Loss: 0.011489732190966606\n",
      "Iteration: 6387/10000, Loss: 0.012842840515077114\n",
      "Iteration: 6388/10000, Loss: 0.01010805368423462\n",
      "Iteration: 6389/10000, Loss: 0.013768821023404598\n",
      "Iteration: 6390/10000, Loss: 0.013730488717556\n",
      "Iteration: 6391/10000, Loss: 0.009759273380041122\n",
      "Iteration: 6392/10000, Loss: 0.008151239715516567\n",
      "Iteration: 6393/10000, Loss: 0.00830247811973095\n",
      "Iteration: 6394/10000, Loss: 0.012711722403764725\n",
      "Iteration: 6395/10000, Loss: 0.011232370510697365\n",
      "Iteration: 6396/10000, Loss: 0.00872831791639328\n",
      "Iteration: 6397/10000, Loss: 0.011878601275384426\n",
      "Iteration: 6398/10000, Loss: 0.013729659840464592\n",
      "Iteration: 6399/10000, Loss: 0.011678480543196201\n",
      "Iteration: 6400/10000, Loss: 0.007399169262498617\n",
      "Average test loss:  0.0021\n",
      "Iteration: 6401/10000, Loss: 0.015414956025779247\n",
      "Iteration: 6402/10000, Loss: 0.008434771560132504\n",
      "Iteration: 6403/10000, Loss: 0.009078231640160084\n",
      "Iteration: 6404/10000, Loss: 0.012476697564125061\n",
      "Iteration: 6405/10000, Loss: 0.00736745772883296\n",
      "Iteration: 6406/10000, Loss: 0.008412881754338741\n",
      "Iteration: 6407/10000, Loss: 0.013240866363048553\n",
      "Iteration: 6408/10000, Loss: 0.024066219106316566\n",
      "Iteration: 6409/10000, Loss: 0.01851077564060688\n",
      "Iteration: 6410/10000, Loss: 0.013561118394136429\n",
      "Iteration: 6411/10000, Loss: 0.015136218629777431\n",
      "Iteration: 6412/10000, Loss: 0.017047202214598656\n",
      "Iteration: 6413/10000, Loss: 0.013903032056987286\n",
      "Iteration: 6414/10000, Loss: 0.01204877533018589\n",
      "Iteration: 6415/10000, Loss: 0.006208561360836029\n",
      "Iteration: 6416/10000, Loss: 0.013778232969343662\n",
      "Iteration: 6417/10000, Loss: 0.026847798377275467\n",
      "Iteration: 6418/10000, Loss: 0.009335039183497429\n",
      "Iteration: 6419/10000, Loss: 0.0071829804219305515\n",
      "Iteration: 6420/10000, Loss: 0.009921367280185223\n",
      "Iteration: 6421/10000, Loss: 0.012207222171127796\n",
      "Iteration: 6422/10000, Loss: 0.008752505294978619\n",
      "Iteration: 6423/10000, Loss: 0.011596325784921646\n",
      "Iteration: 6424/10000, Loss: 0.0070351664908230305\n",
      "Iteration: 6425/10000, Loss: 0.012203292921185493\n",
      "Iteration: 6426/10000, Loss: 0.008885283023118973\n",
      "Iteration: 6427/10000, Loss: 0.012301739305257797\n",
      "Iteration: 6428/10000, Loss: 0.01185261644423008\n",
      "Iteration: 6429/10000, Loss: 0.011839696206152439\n",
      "Iteration: 6430/10000, Loss: 0.015859954059123993\n",
      "Iteration: 6431/10000, Loss: 0.01851046457886696\n",
      "Iteration: 6432/10000, Loss: 0.007858592085540295\n",
      "Iteration: 6433/10000, Loss: 0.013639509677886963\n",
      "Iteration: 6434/10000, Loss: 0.012525251135230064\n",
      "Iteration: 6435/10000, Loss: 0.016530532389879227\n",
      "Iteration: 6436/10000, Loss: 0.010773535817861557\n",
      "Iteration: 6437/10000, Loss: 0.014176378957927227\n",
      "Iteration: 6438/10000, Loss: 0.012314190156757832\n",
      "Iteration: 6439/10000, Loss: 0.008970624767243862\n",
      "Iteration: 6440/10000, Loss: 0.00831142533570528\n",
      "Iteration: 6441/10000, Loss: 0.01202536839991808\n",
      "Iteration: 6442/10000, Loss: 0.010114316828548908\n",
      "Iteration: 6443/10000, Loss: 0.008007808588445187\n",
      "Iteration: 6444/10000, Loss: 0.00906047597527504\n",
      "Iteration: 6445/10000, Loss: 0.008537798188626766\n",
      "Iteration: 6446/10000, Loss: 0.011895371600985527\n",
      "Iteration: 6447/10000, Loss: 0.014299340546131134\n",
      "Iteration: 6448/10000, Loss: 0.008387453854084015\n",
      "Iteration: 6449/10000, Loss: 0.006259456276893616\n",
      "Iteration: 6450/10000, Loss: 0.010332646779716015\n",
      "Iteration: 6451/10000, Loss: 0.008829745464026928\n",
      "Iteration: 6452/10000, Loss: 0.015060525387525558\n",
      "Iteration: 6453/10000, Loss: 0.008835402317345142\n",
      "Iteration: 6454/10000, Loss: 0.009890386834740639\n",
      "Iteration: 6455/10000, Loss: 0.008550046011805534\n",
      "Iteration: 6456/10000, Loss: 0.007664353586733341\n",
      "Iteration: 6457/10000, Loss: 0.009016141295433044\n",
      "Iteration: 6458/10000, Loss: 0.01064884290099144\n",
      "Iteration: 6459/10000, Loss: 0.004812538158148527\n",
      "Iteration: 6460/10000, Loss: 0.014771375805139542\n",
      "Iteration: 6461/10000, Loss: 0.009342129342257977\n",
      "Iteration: 6462/10000, Loss: 0.007519511040300131\n",
      "Iteration: 6463/10000, Loss: 0.009626762941479683\n",
      "Iteration: 6464/10000, Loss: 0.014422223903238773\n",
      "Iteration: 6465/10000, Loss: 0.009702717885375023\n",
      "Iteration: 6466/10000, Loss: 0.00791262648999691\n",
      "Iteration: 6467/10000, Loss: 0.01105867512524128\n",
      "Iteration: 6468/10000, Loss: 0.017330637201666832\n",
      "Iteration: 6469/10000, Loss: 0.013747245073318481\n",
      "Iteration: 6470/10000, Loss: 0.01654551550745964\n",
      "Iteration: 6471/10000, Loss: 0.015020634979009628\n",
      "Iteration: 6472/10000, Loss: 0.012708796188235283\n",
      "Iteration: 6473/10000, Loss: 0.01444172952324152\n",
      "Iteration: 6474/10000, Loss: 0.006855586543679237\n",
      "Iteration: 6475/10000, Loss: 0.014378495514392853\n",
      "Iteration: 6476/10000, Loss: 0.014098241925239563\n",
      "Iteration: 6477/10000, Loss: 0.010953029617667198\n",
      "Iteration: 6478/10000, Loss: 0.010349364019930363\n",
      "Iteration: 6479/10000, Loss: 0.011588084511458874\n",
      "Iteration: 6480/10000, Loss: 0.01704014651477337\n",
      "Iteration: 6481/10000, Loss: 0.015210823155939579\n",
      "Iteration: 6482/10000, Loss: 0.012354793958365917\n",
      "Iteration: 6483/10000, Loss: 0.016907095909118652\n",
      "Iteration: 6484/10000, Loss: 0.009489254094660282\n",
      "Iteration: 6485/10000, Loss: 0.009114504791796207\n",
      "Iteration: 6486/10000, Loss: 0.008697191253304482\n",
      "Iteration: 6487/10000, Loss: 0.01355781964957714\n",
      "Iteration: 6488/10000, Loss: 0.005822193343192339\n",
      "Iteration: 6489/10000, Loss: 0.01193273440003395\n",
      "Iteration: 6490/10000, Loss: 0.0090989014133811\n",
      "Iteration: 6491/10000, Loss: 0.014352777972817421\n",
      "Iteration: 6492/10000, Loss: 0.013105369172990322\n",
      "Iteration: 6493/10000, Loss: 0.014912149868905544\n",
      "Iteration: 6494/10000, Loss: 0.010664637200534344\n",
      "Iteration: 6495/10000, Loss: 0.009422576054930687\n",
      "Iteration: 6496/10000, Loss: 0.009453630074858665\n",
      "Iteration: 6497/10000, Loss: 0.007348763290792704\n",
      "Iteration: 6498/10000, Loss: 0.01462375558912754\n",
      "Iteration: 6499/10000, Loss: 0.011718851514160633\n",
      "Iteration: 6500/10000, Loss: 0.007740755099803209\n",
      "Average test loss:  0.0035\n",
      "Iteration: 6501/10000, Loss: 0.011050800792872906\n",
      "Iteration: 6502/10000, Loss: 0.01723959669470787\n",
      "Iteration: 6503/10000, Loss: 0.015294239856302738\n",
      "Iteration: 6504/10000, Loss: 0.010787749662995338\n",
      "Iteration: 6505/10000, Loss: 0.01733916625380516\n",
      "Iteration: 6506/10000, Loss: 0.01410948671400547\n",
      "Iteration: 6507/10000, Loss: 0.009848146699368954\n",
      "Iteration: 6508/10000, Loss: 0.014329478144645691\n",
      "Iteration: 6509/10000, Loss: 0.014868410304188728\n",
      "Iteration: 6510/10000, Loss: 0.011054113507270813\n",
      "Iteration: 6511/10000, Loss: 0.010612157173454762\n",
      "Iteration: 6512/10000, Loss: 0.01106404047459364\n",
      "Iteration: 6513/10000, Loss: 0.009931876324117184\n",
      "Iteration: 6514/10000, Loss: 0.011609836481511593\n",
      "Iteration: 6515/10000, Loss: 0.014672433957457542\n",
      "Iteration: 6516/10000, Loss: 0.012826929800212383\n",
      "Iteration: 6517/10000, Loss: 0.014118406921625137\n",
      "Iteration: 6518/10000, Loss: 0.010372509248554707\n",
      "Iteration: 6519/10000, Loss: 0.008777245879173279\n",
      "Iteration: 6520/10000, Loss: 0.009864697232842445\n",
      "Iteration: 6521/10000, Loss: 0.011547470465302467\n",
      "Iteration: 6522/10000, Loss: 0.008686410263180733\n",
      "Iteration: 6523/10000, Loss: 0.014358866959810257\n",
      "Iteration: 6524/10000, Loss: 0.009177183732390404\n",
      "Iteration: 6525/10000, Loss: 0.008730039931833744\n",
      "Iteration: 6526/10000, Loss: 0.013481710106134415\n",
      "Iteration: 6527/10000, Loss: 0.017541423439979553\n",
      "Iteration: 6528/10000, Loss: 0.007233278825879097\n",
      "Iteration: 6529/10000, Loss: 0.012875156477093697\n",
      "Iteration: 6530/10000, Loss: 0.011672848835587502\n",
      "Iteration: 6531/10000, Loss: 0.009288818575441837\n",
      "Iteration: 6532/10000, Loss: 0.011054598726332188\n",
      "Iteration: 6533/10000, Loss: 0.011732787825167179\n",
      "Iteration: 6534/10000, Loss: 0.01567022129893303\n",
      "Iteration: 6535/10000, Loss: 0.019241850823163986\n",
      "Iteration: 6536/10000, Loss: 0.009173001162707806\n",
      "Iteration: 6537/10000, Loss: 0.009035059250891209\n",
      "Iteration: 6538/10000, Loss: 0.012608642689883709\n",
      "Iteration: 6539/10000, Loss: 0.01116905827075243\n",
      "Iteration: 6540/10000, Loss: 0.010492537170648575\n",
      "Iteration: 6541/10000, Loss: 0.010585474781692028\n",
      "Iteration: 6542/10000, Loss: 0.016909845173358917\n",
      "Iteration: 6543/10000, Loss: 0.009210104122757912\n",
      "Iteration: 6544/10000, Loss: 0.0076722558587789536\n",
      "Iteration: 6545/10000, Loss: 0.01154237613081932\n",
      "Iteration: 6546/10000, Loss: 0.007938009686768055\n",
      "Iteration: 6547/10000, Loss: 0.011140599846839905\n",
      "Iteration: 6548/10000, Loss: 0.011560275219380856\n",
      "Iteration: 6549/10000, Loss: 0.010783917270600796\n",
      "Iteration: 6550/10000, Loss: 0.009203688241541386\n",
      "Iteration: 6551/10000, Loss: 0.012300893664360046\n",
      "Iteration: 6552/10000, Loss: 0.009226933121681213\n",
      "Iteration: 6553/10000, Loss: 0.009424992837011814\n",
      "Iteration: 6554/10000, Loss: 0.008579247631132603\n",
      "Iteration: 6555/10000, Loss: 0.006501697935163975\n",
      "Iteration: 6556/10000, Loss: 0.006580380257219076\n",
      "Iteration: 6557/10000, Loss: 0.010252551175653934\n",
      "Iteration: 6558/10000, Loss: 0.017440155148506165\n",
      "Iteration: 6559/10000, Loss: 0.012435667216777802\n",
      "Iteration: 6560/10000, Loss: 0.014275281690061092\n",
      "Iteration: 6561/10000, Loss: 0.015632059425115585\n",
      "Iteration: 6562/10000, Loss: 0.008102551102638245\n",
      "Iteration: 6563/10000, Loss: 0.009265960194170475\n",
      "Iteration: 6564/10000, Loss: 0.011075480841100216\n",
      "Iteration: 6565/10000, Loss: 0.012758067809045315\n",
      "Iteration: 6566/10000, Loss: 0.009225158020853996\n",
      "Iteration: 6567/10000, Loss: 0.009165548719465733\n",
      "Iteration: 6568/10000, Loss: 0.00782199576497078\n",
      "Iteration: 6569/10000, Loss: 0.014956626109778881\n",
      "Iteration: 6570/10000, Loss: 0.020012734457850456\n",
      "Iteration: 6571/10000, Loss: 0.009252945892512798\n",
      "Iteration: 6572/10000, Loss: 0.011787286959588528\n",
      "Iteration: 6573/10000, Loss: 0.009064631536602974\n",
      "Iteration: 6574/10000, Loss: 0.01836075633764267\n",
      "Iteration: 6575/10000, Loss: 0.01575232483446598\n",
      "Iteration: 6576/10000, Loss: 0.01540878415107727\n",
      "Iteration: 6577/10000, Loss: 0.01225751917809248\n",
      "Iteration: 6578/10000, Loss: 0.01271024253219366\n",
      "Iteration: 6579/10000, Loss: 0.010806990787386894\n",
      "Iteration: 6580/10000, Loss: 0.012030807323753834\n",
      "Iteration: 6581/10000, Loss: 0.011676926165819168\n",
      "Iteration: 6582/10000, Loss: 0.01579064317047596\n",
      "Iteration: 6583/10000, Loss: 0.01598341390490532\n",
      "Iteration: 6584/10000, Loss: 0.008714347146451473\n",
      "Iteration: 6585/10000, Loss: 0.009844967164099216\n",
      "Iteration: 6586/10000, Loss: 0.009576023556292057\n",
      "Iteration: 6587/10000, Loss: 0.007873140275478363\n",
      "Iteration: 6588/10000, Loss: 0.014975663274526596\n",
      "Iteration: 6589/10000, Loss: 0.0078490125015378\n",
      "Iteration: 6590/10000, Loss: 0.009685235098004341\n",
      "Iteration: 6591/10000, Loss: 0.01586790196597576\n",
      "Iteration: 6592/10000, Loss: 0.018514828756451607\n",
      "Iteration: 6593/10000, Loss: 0.009294259361922741\n",
      "Iteration: 6594/10000, Loss: 0.012578045949339867\n",
      "Iteration: 6595/10000, Loss: 0.011762377806007862\n",
      "Iteration: 6596/10000, Loss: 0.008185410872101784\n",
      "Iteration: 6597/10000, Loss: 0.0069354744628071785\n",
      "Iteration: 6598/10000, Loss: 0.01143284048885107\n",
      "Iteration: 6599/10000, Loss: 0.0078004891984164715\n",
      "Iteration: 6600/10000, Loss: 0.014454386197030544\n",
      "Average test loss:  0.0035\n",
      "Iteration: 6601/10000, Loss: 0.007815511897206306\n",
      "Iteration: 6602/10000, Loss: 0.014473045244812965\n",
      "Iteration: 6603/10000, Loss: 0.011610884219408035\n",
      "Iteration: 6604/10000, Loss: 0.010828124359250069\n",
      "Iteration: 6605/10000, Loss: 0.008663925342261791\n",
      "Iteration: 6606/10000, Loss: 0.010485480539500713\n",
      "Iteration: 6607/10000, Loss: 0.012051154859364033\n",
      "Iteration: 6608/10000, Loss: 0.01886553317308426\n",
      "Iteration: 6609/10000, Loss: 0.0076667689718306065\n",
      "Iteration: 6610/10000, Loss: 0.010678337886929512\n",
      "Iteration: 6611/10000, Loss: 0.008708175271749496\n",
      "Iteration: 6612/10000, Loss: 0.012720616534352303\n",
      "Iteration: 6613/10000, Loss: 0.01794217713177204\n",
      "Iteration: 6614/10000, Loss: 0.011776391416788101\n",
      "Iteration: 6615/10000, Loss: 0.006676326971501112\n",
      "Iteration: 6616/10000, Loss: 0.009613359346985817\n",
      "Iteration: 6617/10000, Loss: 0.007281598635017872\n",
      "Iteration: 6618/10000, Loss: 0.011990494094789028\n",
      "Iteration: 6619/10000, Loss: 0.011862164363265038\n",
      "Iteration: 6620/10000, Loss: 0.008573329076170921\n",
      "Iteration: 6621/10000, Loss: 0.007208122871816158\n",
      "Iteration: 6622/10000, Loss: 0.011413825675845146\n",
      "Iteration: 6623/10000, Loss: 0.013387678191065788\n",
      "Iteration: 6624/10000, Loss: 0.011014116927981377\n",
      "Iteration: 6625/10000, Loss: 0.011978701688349247\n",
      "Iteration: 6626/10000, Loss: 0.007358953822404146\n",
      "Iteration: 6627/10000, Loss: 0.010621817782521248\n",
      "Iteration: 6628/10000, Loss: 0.010232556611299515\n",
      "Iteration: 6629/10000, Loss: 0.011617296375334263\n",
      "Iteration: 6630/10000, Loss: 0.014429655857384205\n",
      "Iteration: 6631/10000, Loss: 0.007557351142168045\n",
      "Iteration: 6632/10000, Loss: 0.009187085554003716\n",
      "Iteration: 6633/10000, Loss: 0.014498420059680939\n",
      "Iteration: 6634/10000, Loss: 0.015513409860432148\n",
      "Iteration: 6635/10000, Loss: 0.013102607801556587\n",
      "Iteration: 6636/10000, Loss: 0.012415354140102863\n",
      "Iteration: 6637/10000, Loss: 0.005436689592897892\n",
      "Iteration: 6638/10000, Loss: 0.012158340774476528\n",
      "Iteration: 6639/10000, Loss: 0.01152646355330944\n",
      "Iteration: 6640/10000, Loss: 0.006885552313178778\n",
      "Iteration: 6641/10000, Loss: 0.0073274606838822365\n",
      "Iteration: 6642/10000, Loss: 0.008875725790858269\n",
      "Iteration: 6643/10000, Loss: 0.013442344032227993\n",
      "Iteration: 6644/10000, Loss: 0.007510405965149403\n",
      "Iteration: 6645/10000, Loss: 0.013270541094243526\n",
      "Iteration: 6646/10000, Loss: 0.008419702760875225\n",
      "Iteration: 6647/10000, Loss: 0.010190567001700401\n",
      "Iteration: 6648/10000, Loss: 0.008600675500929356\n",
      "Iteration: 6649/10000, Loss: 0.010605919174849987\n",
      "Iteration: 6650/10000, Loss: 0.008321519009768963\n",
      "Iteration: 6651/10000, Loss: 0.011181545443832874\n",
      "Iteration: 6652/10000, Loss: 0.013052497059106827\n",
      "Iteration: 6653/10000, Loss: 0.015466831624507904\n",
      "Iteration: 6654/10000, Loss: 0.009319273754954338\n",
      "Iteration: 6655/10000, Loss: 0.008222525008022785\n",
      "Iteration: 6656/10000, Loss: 0.01524527557194233\n",
      "Iteration: 6657/10000, Loss: 0.00919258687645197\n",
      "Iteration: 6658/10000, Loss: 0.010589421726763248\n",
      "Iteration: 6659/10000, Loss: 0.006129040848463774\n",
      "Iteration: 6660/10000, Loss: 0.012211790308356285\n",
      "Iteration: 6661/10000, Loss: 0.007763783447444439\n",
      "Iteration: 6662/10000, Loss: 0.003907578065991402\n",
      "Iteration: 6663/10000, Loss: 0.010336700826883316\n",
      "Iteration: 6664/10000, Loss: 0.009992598555982113\n",
      "Iteration: 6665/10000, Loss: 0.011304007843136787\n",
      "Iteration: 6666/10000, Loss: 0.009276408702135086\n",
      "Iteration: 6667/10000, Loss: 0.011637157760560513\n",
      "Iteration: 6668/10000, Loss: 0.016756100580096245\n",
      "Iteration: 6669/10000, Loss: 0.012353886850178242\n",
      "Iteration: 6670/10000, Loss: 0.007160831242799759\n",
      "Iteration: 6671/10000, Loss: 0.014348222874104977\n",
      "Iteration: 6672/10000, Loss: 0.012580971233546734\n",
      "Iteration: 6673/10000, Loss: 0.010098211467266083\n",
      "Iteration: 6674/10000, Loss: 0.012149134650826454\n",
      "Iteration: 6675/10000, Loss: 0.0095358332619071\n",
      "Iteration: 6676/10000, Loss: 0.009620437398552895\n",
      "Iteration: 6677/10000, Loss: 0.008361867628991604\n",
      "Iteration: 6678/10000, Loss: 0.015040791593492031\n",
      "Iteration: 6679/10000, Loss: 0.01222471334040165\n",
      "Iteration: 6680/10000, Loss: 0.012662779539823532\n",
      "Iteration: 6681/10000, Loss: 0.009006298147141933\n",
      "Iteration: 6682/10000, Loss: 0.010949378833174706\n",
      "Iteration: 6683/10000, Loss: 0.015155504457652569\n",
      "Iteration: 6684/10000, Loss: 0.0112069146707654\n",
      "Iteration: 6685/10000, Loss: 0.007744623813778162\n",
      "Iteration: 6686/10000, Loss: 0.009427779354155064\n",
      "Iteration: 6687/10000, Loss: 0.01352272555232048\n",
      "Iteration: 6688/10000, Loss: 0.00988706760108471\n",
      "Iteration: 6689/10000, Loss: 0.012013490311801434\n",
      "Iteration: 6690/10000, Loss: 0.013379690237343311\n",
      "Iteration: 6691/10000, Loss: 0.011592143215239048\n",
      "Iteration: 6692/10000, Loss: 0.009535792283713818\n",
      "Iteration: 6693/10000, Loss: 0.01142109278589487\n",
      "Iteration: 6694/10000, Loss: 0.015653017908334732\n",
      "Iteration: 6695/10000, Loss: 0.012585621327161789\n",
      "Iteration: 6696/10000, Loss: 0.0113914143294096\n",
      "Iteration: 6697/10000, Loss: 0.01239936426281929\n",
      "Iteration: 6698/10000, Loss: 0.009964990429580212\n",
      "Iteration: 6699/10000, Loss: 0.009346626698970795\n",
      "Iteration: 6700/10000, Loss: 0.011374820955097675\n",
      "Average test loss:  0.0043\n",
      "Iteration: 6701/10000, Loss: 0.011783478781580925\n",
      "Iteration: 6702/10000, Loss: 0.012921532616019249\n",
      "Iteration: 6703/10000, Loss: 0.010800314135849476\n",
      "Iteration: 6704/10000, Loss: 0.014935510233044624\n",
      "Iteration: 6705/10000, Loss: 0.008485378697514534\n",
      "Iteration: 6706/10000, Loss: 0.0092783123254776\n",
      "Iteration: 6707/10000, Loss: 0.011691519059240818\n",
      "Iteration: 6708/10000, Loss: 0.008618460036814213\n",
      "Iteration: 6709/10000, Loss: 0.010006439872086048\n",
      "Iteration: 6710/10000, Loss: 0.011133632622659206\n",
      "Iteration: 6711/10000, Loss: 0.014195677824318409\n",
      "Iteration: 6712/10000, Loss: 0.012158606201410294\n",
      "Iteration: 6713/10000, Loss: 0.008415073156356812\n",
      "Iteration: 6714/10000, Loss: 0.008094336837530136\n",
      "Iteration: 6715/10000, Loss: 0.008832011371850967\n",
      "Iteration: 6716/10000, Loss: 0.014036411419510841\n",
      "Iteration: 6717/10000, Loss: 0.012063466012477875\n",
      "Iteration: 6718/10000, Loss: 0.018206212669610977\n",
      "Iteration: 6719/10000, Loss: 0.010620429180562496\n",
      "Iteration: 6720/10000, Loss: 0.010777083225548267\n",
      "Iteration: 6721/10000, Loss: 0.008649361319839954\n",
      "Iteration: 6722/10000, Loss: 0.009475791826844215\n",
      "Iteration: 6723/10000, Loss: 0.01619078405201435\n",
      "Iteration: 6724/10000, Loss: 0.009220968931913376\n",
      "Iteration: 6725/10000, Loss: 0.010981735773384571\n",
      "Iteration: 6726/10000, Loss: 0.009764591231942177\n",
      "Iteration: 6727/10000, Loss: 0.01654699444770813\n",
      "Iteration: 6728/10000, Loss: 0.008071312680840492\n",
      "Iteration: 6729/10000, Loss: 0.015045530162751675\n",
      "Iteration: 6730/10000, Loss: 0.011894571594893932\n",
      "Iteration: 6731/10000, Loss: 0.009610516019165516\n",
      "Iteration: 6732/10000, Loss: 0.014001681469380856\n",
      "Iteration: 6733/10000, Loss: 0.009723002091050148\n",
      "Iteration: 6734/10000, Loss: 0.010517589747905731\n",
      "Iteration: 6735/10000, Loss: 0.015594967640936375\n",
      "Iteration: 6736/10000, Loss: 0.008620495907962322\n",
      "Iteration: 6737/10000, Loss: 0.010637715458869934\n",
      "Iteration: 6738/10000, Loss: 0.014155002310872078\n",
      "Iteration: 6739/10000, Loss: 0.009492717683315277\n",
      "Iteration: 6740/10000, Loss: 0.008843137882649899\n",
      "Iteration: 6741/10000, Loss: 0.010045687668025494\n",
      "Iteration: 6742/10000, Loss: 0.012644059956073761\n",
      "Iteration: 6743/10000, Loss: 0.004545664414763451\n",
      "Iteration: 6744/10000, Loss: 0.01349139865487814\n",
      "Iteration: 6745/10000, Loss: 0.013232899829745293\n",
      "Iteration: 6746/10000, Loss: 0.008454516530036926\n",
      "Iteration: 6747/10000, Loss: 0.007537064142525196\n",
      "Iteration: 6748/10000, Loss: 0.014800245873630047\n",
      "Iteration: 6749/10000, Loss: 0.010823826305568218\n",
      "Iteration: 6750/10000, Loss: 0.010971044190227985\n",
      "Iteration: 6751/10000, Loss: 0.015399079769849777\n",
      "Iteration: 6752/10000, Loss: 0.011541225016117096\n",
      "Iteration: 6753/10000, Loss: 0.010648857802152634\n",
      "Iteration: 6754/10000, Loss: 0.009639408439397812\n",
      "Iteration: 6755/10000, Loss: 0.012866176664829254\n",
      "Iteration: 6756/10000, Loss: 0.01146999653428793\n",
      "Iteration: 6757/10000, Loss: 0.010788969695568085\n",
      "Iteration: 6758/10000, Loss: 0.010913830250501633\n",
      "Iteration: 6759/10000, Loss: 0.009928856045007706\n",
      "Iteration: 6760/10000, Loss: 0.01256648637354374\n",
      "Iteration: 6761/10000, Loss: 0.01147844735532999\n",
      "Iteration: 6762/10000, Loss: 0.011288954876363277\n",
      "Iteration: 6763/10000, Loss: 0.01158829778432846\n",
      "Iteration: 6764/10000, Loss: 0.010438845492899418\n",
      "Iteration: 6765/10000, Loss: 0.009706882759928703\n",
      "Iteration: 6766/10000, Loss: 0.01040045078843832\n",
      "Iteration: 6767/10000, Loss: 0.012981560081243515\n",
      "Iteration: 6768/10000, Loss: 0.014170549809932709\n",
      "Iteration: 6769/10000, Loss: 0.011763283051550388\n",
      "Iteration: 6770/10000, Loss: 0.008785819634795189\n",
      "Iteration: 6771/10000, Loss: 0.00839851051568985\n",
      "Iteration: 6772/10000, Loss: 0.007990316487848759\n",
      "Iteration: 6773/10000, Loss: 0.013972814194858074\n",
      "Iteration: 6774/10000, Loss: 0.009220225736498833\n",
      "Iteration: 6775/10000, Loss: 0.013022846542298794\n",
      "Iteration: 6776/10000, Loss: 0.011726695112884045\n",
      "Iteration: 6777/10000, Loss: 0.008541465736925602\n",
      "Iteration: 6778/10000, Loss: 0.012535138987004757\n",
      "Iteration: 6779/10000, Loss: 0.010939139872789383\n",
      "Iteration: 6780/10000, Loss: 0.011059646494686604\n",
      "Iteration: 6781/10000, Loss: 0.01472962275147438\n",
      "Iteration: 6782/10000, Loss: 0.012578331865370274\n",
      "Iteration: 6783/10000, Loss: 0.00764764379709959\n",
      "Iteration: 6784/10000, Loss: 0.010949875228106976\n",
      "Iteration: 6785/10000, Loss: 0.014731338247656822\n",
      "Iteration: 6786/10000, Loss: 0.01058561634272337\n",
      "Iteration: 6787/10000, Loss: 0.013324389234185219\n",
      "Iteration: 6788/10000, Loss: 0.009886023588478565\n",
      "Iteration: 6789/10000, Loss: 0.011333032511174679\n",
      "Iteration: 6790/10000, Loss: 0.015587891452014446\n",
      "Iteration: 6791/10000, Loss: 0.007235837634652853\n",
      "Iteration: 6792/10000, Loss: 0.01254519447684288\n",
      "Iteration: 6793/10000, Loss: 0.009994450956583023\n",
      "Iteration: 6794/10000, Loss: 0.01039053313434124\n",
      "Iteration: 6795/10000, Loss: 0.011500447988510132\n",
      "Iteration: 6796/10000, Loss: 0.006355442572385073\n",
      "Iteration: 6797/10000, Loss: 0.010815687477588654\n",
      "Iteration: 6798/10000, Loss: 0.012290382757782936\n",
      "Iteration: 6799/10000, Loss: 0.011710992082953453\n",
      "Iteration: 6800/10000, Loss: 0.007921320386230946\n",
      "Average test loss:  0.0052\n",
      "Iteration: 6801/10000, Loss: 0.011317959986627102\n",
      "Iteration: 6802/10000, Loss: 0.012192049995064735\n",
      "Iteration: 6803/10000, Loss: 0.0133712999522686\n",
      "Iteration: 6804/10000, Loss: 0.008293707855045795\n",
      "Iteration: 6805/10000, Loss: 0.011045382358133793\n",
      "Iteration: 6806/10000, Loss: 0.011833785101771355\n",
      "Iteration: 6807/10000, Loss: 0.013166653923690319\n",
      "Iteration: 6808/10000, Loss: 0.013480018824338913\n",
      "Iteration: 6809/10000, Loss: 0.00688593927770853\n",
      "Iteration: 6810/10000, Loss: 0.006962209939956665\n",
      "Iteration: 6811/10000, Loss: 0.01392762828618288\n",
      "Iteration: 6812/10000, Loss: 0.010687279514968395\n",
      "Iteration: 6813/10000, Loss: 0.013561650179326534\n",
      "Iteration: 6814/10000, Loss: 0.011666047386825085\n",
      "Iteration: 6815/10000, Loss: 0.009791115298867226\n",
      "Iteration: 6816/10000, Loss: 0.012046733871102333\n",
      "Iteration: 6817/10000, Loss: 0.008562344126403332\n",
      "Iteration: 6818/10000, Loss: 0.014218956232070923\n",
      "Iteration: 6819/10000, Loss: 0.014857702888548374\n",
      "Iteration: 6820/10000, Loss: 0.010136228986084461\n",
      "Iteration: 6821/10000, Loss: 0.010334291495382786\n",
      "Iteration: 6822/10000, Loss: 0.00982945878058672\n",
      "Iteration: 6823/10000, Loss: 0.009364418685436249\n",
      "Iteration: 6824/10000, Loss: 0.007499434053897858\n",
      "Iteration: 6825/10000, Loss: 0.010311479680240154\n",
      "Iteration: 6826/10000, Loss: 0.01645323634147644\n",
      "Iteration: 6827/10000, Loss: 0.01136728748679161\n",
      "Iteration: 6828/10000, Loss: 0.010216418653726578\n",
      "Iteration: 6829/10000, Loss: 0.014172852039337158\n",
      "Iteration: 6830/10000, Loss: 0.010343729518353939\n",
      "Iteration: 6831/10000, Loss: 0.00923917442560196\n",
      "Iteration: 6832/10000, Loss: 0.008680861443281174\n",
      "Iteration: 6833/10000, Loss: 0.016448095440864563\n",
      "Iteration: 6834/10000, Loss: 0.01685199700295925\n",
      "Iteration: 6835/10000, Loss: 0.012618468143045902\n",
      "Iteration: 6836/10000, Loss: 0.010328462347388268\n",
      "Iteration: 6837/10000, Loss: 0.009358301758766174\n",
      "Iteration: 6838/10000, Loss: 0.01481731329113245\n",
      "Iteration: 6839/10000, Loss: 0.01202426292002201\n",
      "Iteration: 6840/10000, Loss: 0.007950464263558388\n",
      "Iteration: 6841/10000, Loss: 0.010325934737920761\n",
      "Iteration: 6842/10000, Loss: 0.010484239086508751\n",
      "Iteration: 6843/10000, Loss: 0.012731553986668587\n",
      "Iteration: 6844/10000, Loss: 0.007960105314850807\n",
      "Iteration: 6845/10000, Loss: 0.009639330208301544\n",
      "Iteration: 6846/10000, Loss: 0.008565523661673069\n",
      "Iteration: 6847/10000, Loss: 0.016309469938278198\n",
      "Iteration: 6848/10000, Loss: 0.013003361411392689\n",
      "Iteration: 6849/10000, Loss: 0.00938329566270113\n",
      "Iteration: 6850/10000, Loss: 0.008583673276007175\n",
      "Iteration: 6851/10000, Loss: 0.013198698870837688\n",
      "Iteration: 6852/10000, Loss: 0.009484844282269478\n",
      "Iteration: 6853/10000, Loss: 0.007105419412255287\n",
      "Iteration: 6854/10000, Loss: 0.010226988233625889\n",
      "Iteration: 6855/10000, Loss: 0.007067415863275528\n",
      "Iteration: 6856/10000, Loss: 0.014447099529206753\n",
      "Iteration: 6857/10000, Loss: 0.009168711490929127\n",
      "Iteration: 6858/10000, Loss: 0.010574819520115852\n",
      "Iteration: 6859/10000, Loss: 0.01037402544170618\n",
      "Iteration: 6860/10000, Loss: 0.011230559088289738\n",
      "Iteration: 6861/10000, Loss: 0.007297796662896872\n",
      "Iteration: 6862/10000, Loss: 0.015617173165082932\n",
      "Iteration: 6863/10000, Loss: 0.009496462531387806\n",
      "Iteration: 6864/10000, Loss: 0.00992095097899437\n",
      "Iteration: 6865/10000, Loss: 0.008627203293144703\n",
      "Iteration: 6866/10000, Loss: 0.011823936365544796\n",
      "Iteration: 6867/10000, Loss: 0.01306269969791174\n",
      "Iteration: 6868/10000, Loss: 0.010049538686871529\n",
      "Iteration: 6869/10000, Loss: 0.007866153493523598\n",
      "Iteration: 6870/10000, Loss: 0.00799613818526268\n",
      "Iteration: 6871/10000, Loss: 0.014668530784547329\n",
      "Iteration: 6872/10000, Loss: 0.012316719628870487\n",
      "Iteration: 6873/10000, Loss: 0.014223746955394745\n",
      "Iteration: 6874/10000, Loss: 0.009394550696015358\n",
      "Iteration: 6875/10000, Loss: 0.008465610444545746\n",
      "Iteration: 6876/10000, Loss: 0.009411785751581192\n",
      "Iteration: 6877/10000, Loss: 0.014891070313751698\n",
      "Iteration: 6878/10000, Loss: 0.008479421958327293\n",
      "Iteration: 6879/10000, Loss: 0.01286874059587717\n",
      "Iteration: 6880/10000, Loss: 0.009764286689460278\n",
      "Iteration: 6881/10000, Loss: 0.007454642094671726\n",
      "Iteration: 6882/10000, Loss: 0.008186603896319866\n",
      "Iteration: 6883/10000, Loss: 0.009213494136929512\n",
      "Iteration: 6884/10000, Loss: 0.006818437948822975\n",
      "Iteration: 6885/10000, Loss: 0.013771947473287582\n",
      "Iteration: 6886/10000, Loss: 0.005508457310497761\n",
      "Iteration: 6887/10000, Loss: 0.012434668838977814\n",
      "Iteration: 6888/10000, Loss: 0.009572869166731834\n",
      "Iteration: 6889/10000, Loss: 0.010157025419175625\n",
      "Iteration: 6890/10000, Loss: 0.009804881177842617\n",
      "Iteration: 6891/10000, Loss: 0.011812708340585232\n",
      "Iteration: 6892/10000, Loss: 0.01150151714682579\n",
      "Iteration: 6893/10000, Loss: 0.00975879281759262\n",
      "Iteration: 6894/10000, Loss: 0.01719994843006134\n",
      "Iteration: 6895/10000, Loss: 0.011318844743072987\n",
      "Iteration: 6896/10000, Loss: 0.012471120804548264\n",
      "Iteration: 6897/10000, Loss: 0.010280114598572254\n",
      "Iteration: 6898/10000, Loss: 0.006729846354573965\n",
      "Iteration: 6899/10000, Loss: 0.00852164439857006\n",
      "Iteration: 6900/10000, Loss: 0.009821007959544659\n",
      "Average test loss:  0.0035\n",
      "Iteration: 6901/10000, Loss: 0.010950230062007904\n",
      "Iteration: 6902/10000, Loss: 0.011491747573018074\n",
      "Iteration: 6903/10000, Loss: 0.014361795969307423\n",
      "Iteration: 6904/10000, Loss: 0.008774977177381516\n",
      "Iteration: 6905/10000, Loss: 0.013249143026769161\n",
      "Iteration: 6906/10000, Loss: 0.012253337539732456\n",
      "Iteration: 6907/10000, Loss: 0.01376739889383316\n",
      "Iteration: 6908/10000, Loss: 0.012868085876107216\n",
      "Iteration: 6909/10000, Loss: 0.005731484852731228\n",
      "Iteration: 6910/10000, Loss: 0.006727002095431089\n",
      "Iteration: 6911/10000, Loss: 0.009473114274442196\n",
      "Iteration: 6912/10000, Loss: 0.0071576181799173355\n",
      "Iteration: 6913/10000, Loss: 0.00984739325940609\n",
      "Iteration: 6914/10000, Loss: 0.012330900877714157\n",
      "Iteration: 6915/10000, Loss: 0.013225129805505276\n",
      "Iteration: 6916/10000, Loss: 0.007289187051355839\n",
      "Iteration: 6917/10000, Loss: 0.012853316962718964\n",
      "Iteration: 6918/10000, Loss: 0.009210001677274704\n",
      "Iteration: 6919/10000, Loss: 0.010813540779054165\n",
      "Iteration: 6920/10000, Loss: 0.010256875306367874\n",
      "Iteration: 6921/10000, Loss: 0.009331325069069862\n",
      "Iteration: 6922/10000, Loss: 0.01028565876185894\n",
      "Iteration: 6923/10000, Loss: 0.009130118414759636\n",
      "Iteration: 6924/10000, Loss: 0.007936853915452957\n",
      "Iteration: 6925/10000, Loss: 0.012294917367398739\n",
      "Iteration: 6926/10000, Loss: 0.01095894630998373\n",
      "Iteration: 6927/10000, Loss: 0.008056020364165306\n",
      "Iteration: 6928/10000, Loss: 0.010522519238293171\n",
      "Iteration: 6929/10000, Loss: 0.010048714466392994\n",
      "Iteration: 6930/10000, Loss: 0.012698914855718613\n",
      "Iteration: 6931/10000, Loss: 0.015445788390934467\n",
      "Iteration: 6932/10000, Loss: 0.013951276428997517\n",
      "Iteration: 6933/10000, Loss: 0.013921438716351986\n",
      "Iteration: 6934/10000, Loss: 0.012267791666090488\n",
      "Iteration: 6935/10000, Loss: 0.009526921436190605\n",
      "Iteration: 6936/10000, Loss: 0.009766626171767712\n",
      "Iteration: 6937/10000, Loss: 0.010976099409162998\n",
      "Iteration: 6938/10000, Loss: 0.006142599508166313\n",
      "Iteration: 6939/10000, Loss: 0.01456326525658369\n",
      "Iteration: 6940/10000, Loss: 0.011754723265767097\n",
      "Iteration: 6941/10000, Loss: 0.01216540951281786\n",
      "Iteration: 6942/10000, Loss: 0.007991173304617405\n",
      "Iteration: 6943/10000, Loss: 0.009998264722526073\n",
      "Iteration: 6944/10000, Loss: 0.011008692905306816\n",
      "Iteration: 6945/10000, Loss: 0.011518980376422405\n",
      "Iteration: 6946/10000, Loss: 0.008646051399409771\n",
      "Iteration: 6947/10000, Loss: 0.010875617153942585\n",
      "Iteration: 6948/10000, Loss: 0.012307187542319298\n",
      "Iteration: 6949/10000, Loss: 0.010215875692665577\n",
      "Iteration: 6950/10000, Loss: 0.01110338419675827\n",
      "Iteration: 6951/10000, Loss: 0.012956742197275162\n",
      "Iteration: 6952/10000, Loss: 0.008904227055609226\n",
      "Iteration: 6953/10000, Loss: 0.008348547853529453\n",
      "Iteration: 6954/10000, Loss: 0.007999573834240437\n",
      "Iteration: 6955/10000, Loss: 0.007990961894392967\n",
      "Iteration: 6956/10000, Loss: 0.01193294208496809\n",
      "Iteration: 6957/10000, Loss: 0.009374870918691158\n",
      "Iteration: 6958/10000, Loss: 0.012736107222735882\n",
      "Iteration: 6959/10000, Loss: 0.009936314076185226\n",
      "Iteration: 6960/10000, Loss: 0.007550651673227549\n",
      "Iteration: 6961/10000, Loss: 0.008126864209771156\n",
      "Iteration: 6962/10000, Loss: 0.009041101671755314\n",
      "Iteration: 6963/10000, Loss: 0.0047441041097044945\n",
      "Iteration: 6964/10000, Loss: 0.0067598652094602585\n",
      "Iteration: 6965/10000, Loss: 0.006271653808653355\n",
      "Iteration: 6966/10000, Loss: 0.009615072049200535\n",
      "Iteration: 6967/10000, Loss: 0.006919078528881073\n",
      "Iteration: 6968/10000, Loss: 0.01155663188546896\n",
      "Iteration: 6969/10000, Loss: 0.012867460958659649\n",
      "Iteration: 6970/10000, Loss: 0.014272195287048817\n",
      "Iteration: 6971/10000, Loss: 0.008481248281896114\n",
      "Iteration: 6972/10000, Loss: 0.01079382561147213\n",
      "Iteration: 6973/10000, Loss: 0.013669812120497227\n",
      "Iteration: 6974/10000, Loss: 0.006938087288290262\n",
      "Iteration: 6975/10000, Loss: 0.010002100840210915\n",
      "Iteration: 6976/10000, Loss: 0.006593672093003988\n",
      "Iteration: 6977/10000, Loss: 0.01570657640695572\n",
      "Iteration: 6978/10000, Loss: 0.00828899722546339\n",
      "Iteration: 6979/10000, Loss: 0.010154902003705502\n",
      "Iteration: 6980/10000, Loss: 0.01092204824090004\n",
      "Iteration: 6981/10000, Loss: 0.00787561759352684\n",
      "Iteration: 6982/10000, Loss: 0.011880050413310528\n",
      "Iteration: 6983/10000, Loss: 0.010895652696490288\n",
      "Iteration: 6984/10000, Loss: 0.006272133905440569\n",
      "Iteration: 6985/10000, Loss: 0.0076444922015070915\n",
      "Iteration: 6986/10000, Loss: 0.016946006566286087\n",
      "Iteration: 6987/10000, Loss: 0.013579314574599266\n",
      "Iteration: 6988/10000, Loss: 0.009945577941834927\n",
      "Iteration: 6989/10000, Loss: 0.007695961743593216\n",
      "Iteration: 6990/10000, Loss: 0.008238011971116066\n",
      "Iteration: 6991/10000, Loss: 0.011012902483344078\n",
      "Iteration: 6992/10000, Loss: 0.008355584926903248\n",
      "Iteration: 6993/10000, Loss: 0.006689852569252253\n",
      "Iteration: 6994/10000, Loss: 0.005747607443481684\n",
      "Iteration: 6995/10000, Loss: 0.0071320910938084126\n",
      "Iteration: 6996/10000, Loss: 0.01168642658740282\n",
      "Iteration: 6997/10000, Loss: 0.009539194405078888\n",
      "Iteration: 6998/10000, Loss: 0.011549602262675762\n",
      "Iteration: 6999/10000, Loss: 0.009472903795540333\n",
      "Iteration: 7000/10000, Loss: 0.0076283300295472145\n",
      "Average test loss:  0.0025\n",
      "Iteration: 7001/10000, Loss: 0.010248721577227116\n",
      "Iteration: 7002/10000, Loss: 0.013165822252631187\n",
      "Iteration: 7003/10000, Loss: 0.011389179155230522\n",
      "Iteration: 7004/10000, Loss: 0.012861783616244793\n",
      "Iteration: 7005/10000, Loss: 0.010802702978253365\n",
      "Iteration: 7006/10000, Loss: 0.012497122399508953\n",
      "Iteration: 7007/10000, Loss: 0.010627839714288712\n",
      "Iteration: 7008/10000, Loss: 0.007579161785542965\n",
      "Iteration: 7009/10000, Loss: 0.009487587958574295\n",
      "Iteration: 7010/10000, Loss: 0.010961858555674553\n",
      "Iteration: 7011/10000, Loss: 0.011825663968920708\n",
      "Iteration: 7012/10000, Loss: 0.009582060389220715\n",
      "Iteration: 7013/10000, Loss: 0.007969786413013935\n",
      "Iteration: 7014/10000, Loss: 0.00942116230726242\n",
      "Iteration: 7015/10000, Loss: 0.016572587192058563\n",
      "Iteration: 7016/10000, Loss: 0.008901186287403107\n",
      "Iteration: 7017/10000, Loss: 0.00892188586294651\n",
      "Iteration: 7018/10000, Loss: 0.010087991133332253\n",
      "Iteration: 7019/10000, Loss: 0.010523185133934021\n",
      "Iteration: 7020/10000, Loss: 0.013226740062236786\n",
      "Iteration: 7021/10000, Loss: 0.007752086501568556\n",
      "Iteration: 7022/10000, Loss: 0.01045029517263174\n",
      "Iteration: 7023/10000, Loss: 0.007308152969926596\n",
      "Iteration: 7024/10000, Loss: 0.01390165090560913\n",
      "Iteration: 7025/10000, Loss: 0.007931319065392017\n",
      "Iteration: 7026/10000, Loss: 0.009084498509764671\n",
      "Iteration: 7027/10000, Loss: 0.00847546011209488\n",
      "Iteration: 7028/10000, Loss: 0.013818016275763512\n",
      "Iteration: 7029/10000, Loss: 0.008069108240306377\n",
      "Iteration: 7030/10000, Loss: 0.007100229151546955\n",
      "Iteration: 7031/10000, Loss: 0.009514509700238705\n",
      "Iteration: 7032/10000, Loss: 0.011053910478949547\n",
      "Iteration: 7033/10000, Loss: 0.011060724034905434\n",
      "Iteration: 7034/10000, Loss: 0.010080261155962944\n",
      "Iteration: 7035/10000, Loss: 0.009056171402335167\n",
      "Iteration: 7036/10000, Loss: 0.00830958504229784\n",
      "Iteration: 7037/10000, Loss: 0.011227489449083805\n",
      "Iteration: 7038/10000, Loss: 0.005699526518583298\n",
      "Iteration: 7039/10000, Loss: 0.012107988819479942\n",
      "Iteration: 7040/10000, Loss: 0.010458875447511673\n",
      "Iteration: 7041/10000, Loss: 0.0102964723482728\n",
      "Iteration: 7042/10000, Loss: 0.011896577663719654\n",
      "Iteration: 7043/10000, Loss: 0.010664139874279499\n",
      "Iteration: 7044/10000, Loss: 0.012630285695195198\n",
      "Iteration: 7045/10000, Loss: 0.011851539835333824\n",
      "Iteration: 7046/10000, Loss: 0.009332298301160336\n",
      "Iteration: 7047/10000, Loss: 0.014075362123548985\n",
      "Iteration: 7048/10000, Loss: 0.010457132942974567\n",
      "Iteration: 7049/10000, Loss: 0.01193215511739254\n",
      "Iteration: 7050/10000, Loss: 0.006730895955115557\n",
      "Iteration: 7051/10000, Loss: 0.011885224841535091\n",
      "Iteration: 7052/10000, Loss: 0.010915440507233143\n",
      "Iteration: 7053/10000, Loss: 0.013016719371080399\n",
      "Iteration: 7054/10000, Loss: 0.00919399969279766\n",
      "Iteration: 7055/10000, Loss: 0.009283782914280891\n",
      "Iteration: 7056/10000, Loss: 0.010359209962189198\n",
      "Iteration: 7057/10000, Loss: 0.009103027172386646\n",
      "Iteration: 7058/10000, Loss: 0.007817315869033337\n",
      "Iteration: 7059/10000, Loss: 0.008286789059638977\n",
      "Iteration: 7060/10000, Loss: 0.007720635738223791\n",
      "Iteration: 7061/10000, Loss: 0.008962476626038551\n",
      "Iteration: 7062/10000, Loss: 0.019245250150561333\n",
      "Iteration: 7063/10000, Loss: 0.010618455708026886\n",
      "Iteration: 7064/10000, Loss: 0.004867155104875565\n",
      "Iteration: 7065/10000, Loss: 0.005837737582623959\n",
      "Iteration: 7066/10000, Loss: 0.007999945431947708\n",
      "Iteration: 7067/10000, Loss: 0.01328953169286251\n",
      "Iteration: 7068/10000, Loss: 0.014622663147747517\n",
      "Iteration: 7069/10000, Loss: 0.00863135326653719\n",
      "Iteration: 7070/10000, Loss: 0.010032855905592442\n",
      "Iteration: 7071/10000, Loss: 0.008095731027424335\n",
      "Iteration: 7072/10000, Loss: 0.011111349798738956\n",
      "Iteration: 7073/10000, Loss: 0.010698209516704082\n",
      "Iteration: 7074/10000, Loss: 0.012760508805513382\n",
      "Iteration: 7075/10000, Loss: 0.012143977917730808\n",
      "Iteration: 7076/10000, Loss: 0.010601167567074299\n",
      "Iteration: 7077/10000, Loss: 0.008722206577658653\n",
      "Iteration: 7078/10000, Loss: 0.009116271510720253\n",
      "Iteration: 7079/10000, Loss: 0.007893280126154423\n",
      "Iteration: 7080/10000, Loss: 0.007094373926520348\n",
      "Iteration: 7081/10000, Loss: 0.008144200779497623\n",
      "Iteration: 7082/10000, Loss: 0.007188716437667608\n",
      "Iteration: 7083/10000, Loss: 0.010166413150727749\n",
      "Iteration: 7084/10000, Loss: 0.008295197039842606\n",
      "Iteration: 7085/10000, Loss: 0.013814284466207027\n",
      "Iteration: 7086/10000, Loss: 0.008141973987221718\n",
      "Iteration: 7087/10000, Loss: 0.008215902373194695\n",
      "Iteration: 7088/10000, Loss: 0.006924082059413195\n",
      "Iteration: 7089/10000, Loss: 0.008396162651479244\n",
      "Iteration: 7090/10000, Loss: 0.006260990165174007\n",
      "Iteration: 7091/10000, Loss: 0.014759866520762444\n",
      "Iteration: 7092/10000, Loss: 0.011716583743691444\n",
      "Iteration: 7093/10000, Loss: 0.013485821895301342\n",
      "Iteration: 7094/10000, Loss: 0.01627439446747303\n",
      "Iteration: 7095/10000, Loss: 0.009111233986914158\n",
      "Iteration: 7096/10000, Loss: 0.013144413009285927\n",
      "Iteration: 7097/10000, Loss: 0.012989385053515434\n",
      "Iteration: 7098/10000, Loss: 0.011648868210613728\n",
      "Iteration: 7099/10000, Loss: 0.007988297380506992\n",
      "Iteration: 7100/10000, Loss: 0.003992835991084576\n",
      "Average test loss:  0.0031\n",
      "Iteration: 7101/10000, Loss: 0.011277712881565094\n",
      "Iteration: 7102/10000, Loss: 0.012519708834588528\n",
      "Iteration: 7103/10000, Loss: 0.008737093769013882\n",
      "Iteration: 7104/10000, Loss: 0.008632207289338112\n",
      "Iteration: 7105/10000, Loss: 0.013369730673730373\n",
      "Iteration: 7106/10000, Loss: 0.010711513459682465\n",
      "Iteration: 7107/10000, Loss: 0.00782762560993433\n",
      "Iteration: 7108/10000, Loss: 0.01372204814106226\n",
      "Iteration: 7109/10000, Loss: 0.009104902856051922\n",
      "Iteration: 7110/10000, Loss: 0.011159028857946396\n",
      "Iteration: 7111/10000, Loss: 0.019225088879466057\n",
      "Iteration: 7112/10000, Loss: 0.009697883389890194\n",
      "Iteration: 7113/10000, Loss: 0.012920089066028595\n",
      "Iteration: 7114/10000, Loss: 0.007654269225895405\n",
      "Iteration: 7115/10000, Loss: 0.00769962789490819\n",
      "Iteration: 7116/10000, Loss: 0.010506901890039444\n",
      "Iteration: 7117/10000, Loss: 0.013435238040983677\n",
      "Iteration: 7118/10000, Loss: 0.01464892365038395\n",
      "Iteration: 7119/10000, Loss: 0.01013232208788395\n",
      "Iteration: 7120/10000, Loss: 0.008056560531258583\n",
      "Iteration: 7121/10000, Loss: 0.010255810804665089\n",
      "Iteration: 7122/10000, Loss: 0.009751776233315468\n",
      "Iteration: 7123/10000, Loss: 0.012913012877106667\n",
      "Iteration: 7124/10000, Loss: 0.010646171867847443\n",
      "Iteration: 7125/10000, Loss: 0.009658491238951683\n",
      "Iteration: 7126/10000, Loss: 0.010913101024925709\n",
      "Iteration: 7127/10000, Loss: 0.01056426577270031\n",
      "Iteration: 7128/10000, Loss: 0.008128665387630463\n",
      "Iteration: 7129/10000, Loss: 0.007583233993500471\n",
      "Iteration: 7130/10000, Loss: 0.00831178855150938\n",
      "Iteration: 7131/10000, Loss: 0.012363131158053875\n",
      "Iteration: 7132/10000, Loss: 0.008966874331235886\n",
      "Iteration: 7133/10000, Loss: 0.011554760858416557\n",
      "Iteration: 7134/10000, Loss: 0.01113430317491293\n",
      "Iteration: 7135/10000, Loss: 0.012499096803367138\n",
      "Iteration: 7136/10000, Loss: 0.008064513094723225\n",
      "Iteration: 7137/10000, Loss: 0.017016950994729996\n",
      "Iteration: 7138/10000, Loss: 0.0129231633618474\n",
      "Iteration: 7139/10000, Loss: 0.008857009001076221\n",
      "Iteration: 7140/10000, Loss: 0.010744065977633\n",
      "Iteration: 7141/10000, Loss: 0.007904994301497936\n",
      "Iteration: 7142/10000, Loss: 0.013822807930409908\n",
      "Iteration: 7143/10000, Loss: 0.008399460464715958\n",
      "Iteration: 7144/10000, Loss: 0.009346064180135727\n",
      "Iteration: 7145/10000, Loss: 0.011327811516821384\n",
      "Iteration: 7146/10000, Loss: 0.005881141405552626\n",
      "Iteration: 7147/10000, Loss: 0.01674669422209263\n",
      "Iteration: 7148/10000, Loss: 0.013708319514989853\n",
      "Iteration: 7149/10000, Loss: 0.007837449200451374\n",
      "Iteration: 7150/10000, Loss: 0.01005172822624445\n",
      "Iteration: 7151/10000, Loss: 0.011864326894283295\n",
      "Iteration: 7152/10000, Loss: 0.006843946874141693\n",
      "Iteration: 7153/10000, Loss: 0.010269179940223694\n",
      "Iteration: 7154/10000, Loss: 0.010625692084431648\n",
      "Iteration: 7155/10000, Loss: 0.013214570470154285\n",
      "Iteration: 7156/10000, Loss: 0.007543033920228481\n",
      "Iteration: 7157/10000, Loss: 0.013572772033512592\n",
      "Iteration: 7158/10000, Loss: 0.008774183690547943\n",
      "Iteration: 7159/10000, Loss: 0.008243096061050892\n",
      "Iteration: 7160/10000, Loss: 0.008900007233023643\n",
      "Iteration: 7161/10000, Loss: 0.007674121763557196\n",
      "Iteration: 7162/10000, Loss: 0.01305317785590887\n",
      "Iteration: 7163/10000, Loss: 0.013544349931180477\n",
      "Iteration: 7164/10000, Loss: 0.008969244547188282\n",
      "Iteration: 7165/10000, Loss: 0.011999493464827538\n",
      "Iteration: 7166/10000, Loss: 0.009366849437355995\n",
      "Iteration: 7167/10000, Loss: 0.008974522352218628\n",
      "Iteration: 7168/10000, Loss: 0.009296925738453865\n",
      "Iteration: 7169/10000, Loss: 0.010698477737605572\n",
      "Iteration: 7170/10000, Loss: 0.008914018981158733\n",
      "Iteration: 7171/10000, Loss: 0.015078476630151272\n",
      "Iteration: 7172/10000, Loss: 0.005651720799505711\n",
      "Iteration: 7173/10000, Loss: 0.011684325523674488\n",
      "Iteration: 7174/10000, Loss: 0.01178094744682312\n",
      "Iteration: 7175/10000, Loss: 0.010439075529575348\n",
      "Iteration: 7176/10000, Loss: 0.010450550355017185\n",
      "Iteration: 7177/10000, Loss: 0.013848711736500263\n",
      "Iteration: 7178/10000, Loss: 0.006291466765105724\n",
      "Iteration: 7179/10000, Loss: 0.0065870126709342\n",
      "Iteration: 7180/10000, Loss: 0.008839110843837261\n",
      "Iteration: 7181/10000, Loss: 0.012084394693374634\n",
      "Iteration: 7182/10000, Loss: 0.008651049807667732\n",
      "Iteration: 7183/10000, Loss: 0.009321268647909164\n",
      "Iteration: 7184/10000, Loss: 0.009879069402813911\n",
      "Iteration: 7185/10000, Loss: 0.0127513837069273\n",
      "Iteration: 7186/10000, Loss: 0.009996793232858181\n",
      "Iteration: 7187/10000, Loss: 0.009233168326318264\n",
      "Iteration: 7188/10000, Loss: 0.014824967831373215\n",
      "Iteration: 7189/10000, Loss: 0.012210225686430931\n",
      "Iteration: 7190/10000, Loss: 0.008639153093099594\n",
      "Iteration: 7191/10000, Loss: 0.015977120026946068\n",
      "Iteration: 7192/10000, Loss: 0.00952819362282753\n",
      "Iteration: 7193/10000, Loss: 0.009205575101077557\n",
      "Iteration: 7194/10000, Loss: 0.014588764868676662\n",
      "Iteration: 7195/10000, Loss: 0.007645122706890106\n",
      "Iteration: 7196/10000, Loss: 0.007623129989951849\n",
      "Iteration: 7197/10000, Loss: 0.009015670977532864\n",
      "Iteration: 7198/10000, Loss: 0.0148177994415164\n",
      "Iteration: 7199/10000, Loss: 0.013685451820492744\n",
      "Iteration: 7200/10000, Loss: 0.013388010673224926\n",
      "Average test loss:  0.0031\n",
      "Iteration: 7201/10000, Loss: 0.005087649915367365\n",
      "Iteration: 7202/10000, Loss: 0.009464411996304989\n",
      "Iteration: 7203/10000, Loss: 0.011472794227302074\n",
      "Iteration: 7204/10000, Loss: 0.008645717054605484\n",
      "Iteration: 7205/10000, Loss: 0.013384188525378704\n",
      "Iteration: 7206/10000, Loss: 0.01033044047653675\n",
      "Iteration: 7207/10000, Loss: 0.011655018664896488\n",
      "Iteration: 7208/10000, Loss: 0.011262435466051102\n",
      "Iteration: 7209/10000, Loss: 0.01385438907891512\n",
      "Iteration: 7210/10000, Loss: 0.009155113250017166\n",
      "Iteration: 7211/10000, Loss: 0.01124251913279295\n",
      "Iteration: 7212/10000, Loss: 0.011335563845932484\n",
      "Iteration: 7213/10000, Loss: 0.011911099776625633\n",
      "Iteration: 7214/10000, Loss: 0.017370305955410004\n",
      "Iteration: 7215/10000, Loss: 0.008554154075682163\n",
      "Iteration: 7216/10000, Loss: 0.011882920749485493\n",
      "Iteration: 7217/10000, Loss: 0.008381473831832409\n",
      "Iteration: 7218/10000, Loss: 0.00647719344124198\n",
      "Iteration: 7219/10000, Loss: 0.007142178248614073\n",
      "Iteration: 7220/10000, Loss: 0.007788314949721098\n",
      "Iteration: 7221/10000, Loss: 0.006126341409981251\n",
      "Iteration: 7222/10000, Loss: 0.008291746489703655\n",
      "Iteration: 7223/10000, Loss: 0.010491148568689823\n",
      "Iteration: 7224/10000, Loss: 0.010759185999631882\n",
      "Iteration: 7225/10000, Loss: 0.005717193707823753\n",
      "Iteration: 7226/10000, Loss: 0.007875035516917706\n",
      "Iteration: 7227/10000, Loss: 0.007975895889103413\n",
      "Iteration: 7228/10000, Loss: 0.01289396733045578\n",
      "Iteration: 7229/10000, Loss: 0.01750260777771473\n",
      "Iteration: 7230/10000, Loss: 0.00909646786749363\n",
      "Iteration: 7231/10000, Loss: 0.016578948125243187\n",
      "Iteration: 7232/10000, Loss: 0.018767189234495163\n",
      "Iteration: 7233/10000, Loss: 0.008421472273766994\n",
      "Iteration: 7234/10000, Loss: 0.013678076677024364\n",
      "Iteration: 7235/10000, Loss: 0.013014591298997402\n",
      "Iteration: 7236/10000, Loss: 0.008605514653027058\n",
      "Iteration: 7237/10000, Loss: 0.00799562782049179\n",
      "Iteration: 7238/10000, Loss: 0.013554844073951244\n",
      "Iteration: 7239/10000, Loss: 0.014597143977880478\n",
      "Iteration: 7240/10000, Loss: 0.010264573618769646\n",
      "Iteration: 7241/10000, Loss: 0.013418134301900864\n",
      "Iteration: 7242/10000, Loss: 0.009069464169442654\n",
      "Iteration: 7243/10000, Loss: 0.011417478322982788\n",
      "Iteration: 7244/10000, Loss: 0.0074568456038832664\n",
      "Iteration: 7245/10000, Loss: 0.008148403838276863\n",
      "Iteration: 7246/10000, Loss: 0.00427183136343956\n",
      "Iteration: 7247/10000, Loss: 0.00758053082972765\n",
      "Iteration: 7248/10000, Loss: 0.010641181841492653\n",
      "Iteration: 7249/10000, Loss: 0.011346543207764626\n",
      "Iteration: 7250/10000, Loss: 0.006710789166390896\n",
      "Iteration: 7251/10000, Loss: 0.013504776172339916\n",
      "Iteration: 7252/10000, Loss: 0.012847421690821648\n",
      "Iteration: 7253/10000, Loss: 0.013135607354342937\n",
      "Iteration: 7254/10000, Loss: 0.011873055249452591\n",
      "Iteration: 7255/10000, Loss: 0.010177217423915863\n",
      "Iteration: 7256/10000, Loss: 0.014413016848266125\n",
      "Iteration: 7257/10000, Loss: 0.00980485137552023\n",
      "Iteration: 7258/10000, Loss: 0.005574497859925032\n",
      "Iteration: 7259/10000, Loss: 0.015670567750930786\n",
      "Iteration: 7260/10000, Loss: 0.012079078704118729\n",
      "Iteration: 7261/10000, Loss: 0.01328124850988388\n",
      "Iteration: 7262/10000, Loss: 0.008751021698117256\n",
      "Iteration: 7263/10000, Loss: 0.008788790553808212\n",
      "Iteration: 7264/10000, Loss: 0.008163089863955975\n",
      "Iteration: 7265/10000, Loss: 0.007633193861693144\n",
      "Iteration: 7266/10000, Loss: 0.015208829194307327\n",
      "Iteration: 7267/10000, Loss: 0.01656404882669449\n",
      "Iteration: 7268/10000, Loss: 0.010580175556242466\n",
      "Iteration: 7269/10000, Loss: 0.0125000374391675\n",
      "Iteration: 7270/10000, Loss: 0.012531129643321037\n",
      "Iteration: 7271/10000, Loss: 0.006403566338121891\n",
      "Iteration: 7272/10000, Loss: 0.0152243347838521\n",
      "Iteration: 7273/10000, Loss: 0.011018101125955582\n",
      "Iteration: 7274/10000, Loss: 0.014595309272408485\n",
      "Iteration: 7275/10000, Loss: 0.011142016388475895\n",
      "Iteration: 7276/10000, Loss: 0.008876720443367958\n",
      "Iteration: 7277/10000, Loss: 0.006848521064966917\n",
      "Iteration: 7278/10000, Loss: 0.009209668263792992\n",
      "Iteration: 7279/10000, Loss: 0.011789395473897457\n",
      "Iteration: 7280/10000, Loss: 0.010728135704994202\n",
      "Iteration: 7281/10000, Loss: 0.01367601566016674\n",
      "Iteration: 7282/10000, Loss: 0.010871697217226028\n",
      "Iteration: 7283/10000, Loss: 0.015148214995861053\n",
      "Iteration: 7284/10000, Loss: 0.01162833720445633\n",
      "Iteration: 7285/10000, Loss: 0.008246972225606441\n",
      "Iteration: 7286/10000, Loss: 0.013218238018453121\n",
      "Iteration: 7287/10000, Loss: 0.008969994261860847\n",
      "Iteration: 7288/10000, Loss: 0.01258716732263565\n",
      "Iteration: 7289/10000, Loss: 0.012237343937158585\n",
      "Iteration: 7290/10000, Loss: 0.01325311977416277\n",
      "Iteration: 7291/10000, Loss: 0.011297653429210186\n",
      "Iteration: 7292/10000, Loss: 0.007109181955456734\n",
      "Iteration: 7293/10000, Loss: 0.01584530808031559\n",
      "Iteration: 7294/10000, Loss: 0.011448475532233715\n",
      "Iteration: 7295/10000, Loss: 0.008985803462564945\n",
      "Iteration: 7296/10000, Loss: 0.010840390808880329\n",
      "Iteration: 7297/10000, Loss: 0.012833412736654282\n",
      "Iteration: 7298/10000, Loss: 0.0061489432118833065\n",
      "Iteration: 7299/10000, Loss: 0.010729552246630192\n",
      "Iteration: 7300/10000, Loss: 0.010881256312131882\n",
      "Average test loss:  0.0040\n",
      "Iteration: 7301/10000, Loss: 0.01141043659299612\n",
      "Iteration: 7302/10000, Loss: 0.011361176148056984\n",
      "Iteration: 7303/10000, Loss: 0.014144732616841793\n",
      "Iteration: 7304/10000, Loss: 0.010197608731687069\n",
      "Iteration: 7305/10000, Loss: 0.012513203546404839\n",
      "Iteration: 7306/10000, Loss: 0.00994283426553011\n",
      "Iteration: 7307/10000, Loss: 0.012418779544532299\n",
      "Iteration: 7308/10000, Loss: 0.013148353435099125\n",
      "Iteration: 7309/10000, Loss: 0.010976123623549938\n",
      "Iteration: 7310/10000, Loss: 0.011814987286925316\n",
      "Iteration: 7311/10000, Loss: 0.011914490722119808\n",
      "Iteration: 7312/10000, Loss: 0.010722849518060684\n",
      "Iteration: 7313/10000, Loss: 0.010381878353655338\n",
      "Iteration: 7314/10000, Loss: 0.008684961125254631\n",
      "Iteration: 7315/10000, Loss: 0.009709053672850132\n",
      "Iteration: 7316/10000, Loss: 0.01194408442825079\n",
      "Iteration: 7317/10000, Loss: 0.010546538047492504\n",
      "Iteration: 7318/10000, Loss: 0.012288963422179222\n",
      "Iteration: 7319/10000, Loss: 0.01274102833122015\n",
      "Iteration: 7320/10000, Loss: 0.013310532085597515\n",
      "Iteration: 7321/10000, Loss: 0.008024990558624268\n",
      "Iteration: 7322/10000, Loss: 0.012498771771788597\n",
      "Iteration: 7323/10000, Loss: 0.008306634612381458\n",
      "Iteration: 7324/10000, Loss: 0.009040199220180511\n",
      "Iteration: 7325/10000, Loss: 0.01024467684328556\n",
      "Iteration: 7326/10000, Loss: 0.01036069355905056\n",
      "Iteration: 7327/10000, Loss: 0.008191391825675964\n",
      "Iteration: 7328/10000, Loss: 0.011849288828670979\n",
      "Iteration: 7329/10000, Loss: 0.009717048145830631\n",
      "Iteration: 7330/10000, Loss: 0.01771697588264942\n",
      "Iteration: 7331/10000, Loss: 0.008519927971065044\n",
      "Iteration: 7332/10000, Loss: 0.012871557846665382\n",
      "Iteration: 7333/10000, Loss: 0.009973650798201561\n",
      "Iteration: 7334/10000, Loss: 0.013144980184733868\n",
      "Iteration: 7335/10000, Loss: 0.013869432732462883\n",
      "Iteration: 7336/10000, Loss: 0.010700409300625324\n",
      "Iteration: 7337/10000, Loss: 0.011203001253306866\n",
      "Iteration: 7338/10000, Loss: 0.016358699649572372\n",
      "Iteration: 7339/10000, Loss: 0.011211312375962734\n",
      "Iteration: 7340/10000, Loss: 0.011431385762989521\n",
      "Iteration: 7341/10000, Loss: 0.013098696246743202\n",
      "Iteration: 7342/10000, Loss: 0.00723210908472538\n",
      "Iteration: 7343/10000, Loss: 0.012563073076307774\n",
      "Iteration: 7344/10000, Loss: 0.010829131118953228\n",
      "Iteration: 7345/10000, Loss: 0.007647787220776081\n",
      "Iteration: 7346/10000, Loss: 0.010649685747921467\n",
      "Iteration: 7347/10000, Loss: 0.011628653854131699\n",
      "Iteration: 7348/10000, Loss: 0.015694186091423035\n",
      "Iteration: 7349/10000, Loss: 0.012152674607932568\n",
      "Iteration: 7350/10000, Loss: 0.007283066865056753\n",
      "Iteration: 7351/10000, Loss: 0.011438742280006409\n",
      "Iteration: 7352/10000, Loss: 0.01239892840385437\n",
      "Iteration: 7353/10000, Loss: 0.008136003278195858\n",
      "Iteration: 7354/10000, Loss: 0.010686710476875305\n",
      "Iteration: 7355/10000, Loss: 0.011241043917834759\n",
      "Iteration: 7356/10000, Loss: 0.00683982390910387\n",
      "Iteration: 7357/10000, Loss: 0.00551024591550231\n",
      "Iteration: 7358/10000, Loss: 0.008624687790870667\n",
      "Iteration: 7359/10000, Loss: 0.00839079450815916\n",
      "Iteration: 7360/10000, Loss: 0.009562444873154163\n",
      "Iteration: 7361/10000, Loss: 0.01125660166144371\n",
      "Iteration: 7362/10000, Loss: 0.008491159416735172\n",
      "Iteration: 7363/10000, Loss: 0.00801344495266676\n",
      "Iteration: 7364/10000, Loss: 0.01737370900809765\n",
      "Iteration: 7365/10000, Loss: 0.009907428175210953\n",
      "Iteration: 7366/10000, Loss: 0.010371661745011806\n",
      "Iteration: 7367/10000, Loss: 0.010209478437900543\n",
      "Iteration: 7368/10000, Loss: 0.011231550946831703\n",
      "Iteration: 7369/10000, Loss: 0.011679709888994694\n",
      "Iteration: 7370/10000, Loss: 0.011787740513682365\n",
      "Iteration: 7371/10000, Loss: 0.01108689233660698\n",
      "Iteration: 7372/10000, Loss: 0.008200004696846008\n",
      "Iteration: 7373/10000, Loss: 0.012780649587512016\n",
      "Iteration: 7374/10000, Loss: 0.011512413620948792\n",
      "Iteration: 7375/10000, Loss: 0.01134369894862175\n",
      "Iteration: 7376/10000, Loss: 0.010083449073135853\n",
      "Iteration: 7377/10000, Loss: 0.012485817074775696\n",
      "Iteration: 7378/10000, Loss: 0.008935266174376011\n",
      "Iteration: 7379/10000, Loss: 0.01293694693595171\n",
      "Iteration: 7380/10000, Loss: 0.0075837899930775166\n",
      "Iteration: 7381/10000, Loss: 0.009099403396248817\n",
      "Iteration: 7382/10000, Loss: 0.011895155534148216\n",
      "Iteration: 7383/10000, Loss: 0.015206508338451385\n",
      "Iteration: 7384/10000, Loss: 0.012718779034912586\n",
      "Iteration: 7385/10000, Loss: 0.009497520513832569\n",
      "Iteration: 7386/10000, Loss: 0.008620998822152615\n",
      "Iteration: 7387/10000, Loss: 0.008664624765515327\n",
      "Iteration: 7388/10000, Loss: 0.010615820065140724\n",
      "Iteration: 7389/10000, Loss: 0.015081287361681461\n",
      "Iteration: 7390/10000, Loss: 0.008769303560256958\n",
      "Iteration: 7391/10000, Loss: 0.010902537032961845\n",
      "Iteration: 7392/10000, Loss: 0.00877784937620163\n",
      "Iteration: 7393/10000, Loss: 0.010347418487071991\n",
      "Iteration: 7394/10000, Loss: 0.0047805835492908955\n",
      "Iteration: 7395/10000, Loss: 0.009165870025753975\n",
      "Iteration: 7396/10000, Loss: 0.015162374824285507\n",
      "Iteration: 7397/10000, Loss: 0.011362415738403797\n",
      "Iteration: 7398/10000, Loss: 0.010242007672786713\n",
      "Iteration: 7399/10000, Loss: 0.01060860138386488\n",
      "Iteration: 7400/10000, Loss: 0.013717708177864552\n",
      "Average test loss:  0.0027\n",
      "Iteration: 7401/10000, Loss: 0.013315225020051003\n",
      "Iteration: 7402/10000, Loss: 0.008925076574087143\n",
      "Iteration: 7403/10000, Loss: 0.010660325177013874\n",
      "Iteration: 7404/10000, Loss: 0.015618511475622654\n",
      "Iteration: 7405/10000, Loss: 0.009273819625377655\n",
      "Iteration: 7406/10000, Loss: 0.010821997188031673\n",
      "Iteration: 7407/10000, Loss: 0.01375975739210844\n",
      "Iteration: 7408/10000, Loss: 0.011129532940685749\n",
      "Iteration: 7409/10000, Loss: 0.009672034531831741\n",
      "Iteration: 7410/10000, Loss: 0.010421911254525185\n",
      "Iteration: 7411/10000, Loss: 0.005020826123654842\n",
      "Iteration: 7412/10000, Loss: 0.008157508447766304\n",
      "Iteration: 7413/10000, Loss: 0.010110003873705864\n",
      "Iteration: 7414/10000, Loss: 0.009402883239090443\n",
      "Iteration: 7415/10000, Loss: 0.012669703923165798\n",
      "Iteration: 7416/10000, Loss: 0.013502687215805054\n",
      "Iteration: 7417/10000, Loss: 0.009308132342994213\n",
      "Iteration: 7418/10000, Loss: 0.007791290059685707\n",
      "Iteration: 7419/10000, Loss: 0.015217806212604046\n",
      "Iteration: 7420/10000, Loss: 0.012437710538506508\n",
      "Iteration: 7421/10000, Loss: 0.010831325314939022\n",
      "Iteration: 7422/10000, Loss: 0.009715085849165916\n",
      "Iteration: 7423/10000, Loss: 0.010549419559538364\n",
      "Iteration: 7424/10000, Loss: 0.008039484731853008\n",
      "Iteration: 7425/10000, Loss: 0.011643397621810436\n",
      "Iteration: 7426/10000, Loss: 0.008691019378602505\n",
      "Iteration: 7427/10000, Loss: 0.012510547414422035\n",
      "Iteration: 7428/10000, Loss: 0.009824302047491074\n",
      "Iteration: 7429/10000, Loss: 0.009958687238395214\n",
      "Iteration: 7430/10000, Loss: 0.006603684276342392\n",
      "Iteration: 7431/10000, Loss: 0.012133084237575531\n",
      "Iteration: 7432/10000, Loss: 0.005954123102128506\n",
      "Iteration: 7433/10000, Loss: 0.010037466883659363\n",
      "Iteration: 7434/10000, Loss: 0.006954104173928499\n",
      "Iteration: 7435/10000, Loss: 0.005982780829071999\n",
      "Iteration: 7436/10000, Loss: 0.013110886327922344\n",
      "Iteration: 7437/10000, Loss: 0.013650864362716675\n",
      "Iteration: 7438/10000, Loss: 0.014349475502967834\n",
      "Iteration: 7439/10000, Loss: 0.013020855374634266\n",
      "Iteration: 7440/10000, Loss: 0.009301168844103813\n",
      "Iteration: 7441/10000, Loss: 0.008022532798349857\n",
      "Iteration: 7442/10000, Loss: 0.010649265721440315\n",
      "Iteration: 7443/10000, Loss: 0.012313944287598133\n",
      "Iteration: 7444/10000, Loss: 0.009783054701983929\n",
      "Iteration: 7445/10000, Loss: 0.009553913958370686\n",
      "Iteration: 7446/10000, Loss: 0.00944451056420803\n",
      "Iteration: 7447/10000, Loss: 0.011137654073536396\n",
      "Iteration: 7448/10000, Loss: 0.008545568212866783\n",
      "Iteration: 7449/10000, Loss: 0.007692440412938595\n",
      "Iteration: 7450/10000, Loss: 0.017550284042954445\n",
      "Iteration: 7451/10000, Loss: 0.011921805329620838\n",
      "Iteration: 7452/10000, Loss: 0.0060083805583417416\n",
      "Iteration: 7453/10000, Loss: 0.0097980797290802\n",
      "Iteration: 7454/10000, Loss: 0.008578955195844173\n",
      "Iteration: 7455/10000, Loss: 0.013578555546700954\n",
      "Iteration: 7456/10000, Loss: 0.006791404448449612\n",
      "Iteration: 7457/10000, Loss: 0.010946210473775864\n",
      "Iteration: 7458/10000, Loss: 0.0064480421133339405\n",
      "Iteration: 7459/10000, Loss: 0.011328015476465225\n",
      "Iteration: 7460/10000, Loss: 0.008531995117664337\n",
      "Iteration: 7461/10000, Loss: 0.014503254555165768\n",
      "Iteration: 7462/10000, Loss: 0.013705207034945488\n",
      "Iteration: 7463/10000, Loss: 0.01034997496753931\n",
      "Iteration: 7464/10000, Loss: 0.009512068703770638\n",
      "Iteration: 7465/10000, Loss: 0.012053200043737888\n",
      "Iteration: 7466/10000, Loss: 0.009125599637627602\n",
      "Iteration: 7467/10000, Loss: 0.008231306448578835\n",
      "Iteration: 7468/10000, Loss: 0.011510072275996208\n",
      "Iteration: 7469/10000, Loss: 0.01261074934154749\n",
      "Iteration: 7470/10000, Loss: 0.008071188814938068\n",
      "Iteration: 7471/10000, Loss: 0.010633066296577454\n",
      "Iteration: 7472/10000, Loss: 0.00836346484720707\n",
      "Iteration: 7473/10000, Loss: 0.006491091568022966\n",
      "Iteration: 7474/10000, Loss: 0.006452080328017473\n",
      "Iteration: 7475/10000, Loss: 0.007102394942194223\n",
      "Iteration: 7476/10000, Loss: 0.010066645219922066\n",
      "Iteration: 7477/10000, Loss: 0.00920608825981617\n",
      "Iteration: 7478/10000, Loss: 0.012461472302675247\n",
      "Iteration: 7479/10000, Loss: 0.009161710739135742\n",
      "Iteration: 7480/10000, Loss: 0.012605708092451096\n",
      "Iteration: 7481/10000, Loss: 0.007875563576817513\n",
      "Iteration: 7482/10000, Loss: 0.009531471878290176\n",
      "Iteration: 7483/10000, Loss: 0.00994995329529047\n",
      "Iteration: 7484/10000, Loss: 0.006231780629605055\n",
      "Iteration: 7485/10000, Loss: 0.00874241627752781\n",
      "Iteration: 7486/10000, Loss: 0.00826274324208498\n",
      "Iteration: 7487/10000, Loss: 0.014314287342131138\n",
      "Iteration: 7488/10000, Loss: 0.0102584483101964\n",
      "Iteration: 7489/10000, Loss: 0.010168357752263546\n",
      "Iteration: 7490/10000, Loss: 0.008396434597671032\n",
      "Iteration: 7491/10000, Loss: 0.009283710271120071\n",
      "Iteration: 7492/10000, Loss: 0.009622623212635517\n",
      "Iteration: 7493/10000, Loss: 0.008151297457516193\n",
      "Iteration: 7494/10000, Loss: 0.009007229469716549\n",
      "Iteration: 7495/10000, Loss: 0.01366567611694336\n",
      "Iteration: 7496/10000, Loss: 0.008202790282666683\n",
      "Iteration: 7497/10000, Loss: 0.011483238078653812\n",
      "Iteration: 7498/10000, Loss: 0.01107501145452261\n",
      "Iteration: 7499/10000, Loss: 0.011775502935051918\n",
      "Iteration: 7500/10000, Loss: 0.012606569565832615\n",
      "Average test loss:  0.0027\n",
      "Iteration: 7501/10000, Loss: 0.011492867022752762\n",
      "Iteration: 7502/10000, Loss: 0.009732796810567379\n",
      "Iteration: 7503/10000, Loss: 0.01319725252687931\n",
      "Iteration: 7504/10000, Loss: 0.006283210590481758\n",
      "Iteration: 7505/10000, Loss: 0.011350802145898342\n",
      "Iteration: 7506/10000, Loss: 0.010134240612387657\n",
      "Iteration: 7507/10000, Loss: 0.011759748682379723\n",
      "Iteration: 7508/10000, Loss: 0.009335586801171303\n",
      "Iteration: 7509/10000, Loss: 0.012457593344151974\n",
      "Iteration: 7510/10000, Loss: 0.0052158101461827755\n",
      "Iteration: 7511/10000, Loss: 0.006912568584084511\n",
      "Iteration: 7512/10000, Loss: 0.008582173846662045\n",
      "Iteration: 7513/10000, Loss: 0.017358876764774323\n",
      "Iteration: 7514/10000, Loss: 0.009932534769177437\n",
      "Iteration: 7515/10000, Loss: 0.010115147568285465\n",
      "Iteration: 7516/10000, Loss: 0.012457177974283695\n",
      "Iteration: 7517/10000, Loss: 0.010245244018733501\n",
      "Iteration: 7518/10000, Loss: 0.013312003575265408\n",
      "Iteration: 7519/10000, Loss: 0.01189047284424305\n",
      "Iteration: 7520/10000, Loss: 0.006375886965543032\n",
      "Iteration: 7521/10000, Loss: 0.011641381308436394\n",
      "Iteration: 7522/10000, Loss: 0.010988603346049786\n",
      "Iteration: 7523/10000, Loss: 0.008088595233857632\n",
      "Iteration: 7524/10000, Loss: 0.011443916708230972\n",
      "Iteration: 7525/10000, Loss: 0.008406225591897964\n",
      "Iteration: 7526/10000, Loss: 0.009011262096464634\n",
      "Iteration: 7527/10000, Loss: 0.017070798203349113\n",
      "Iteration: 7528/10000, Loss: 0.00812846515327692\n",
      "Iteration: 7529/10000, Loss: 0.009841373190283775\n",
      "Iteration: 7530/10000, Loss: 0.009648684412240982\n",
      "Iteration: 7531/10000, Loss: 0.0074264234863221645\n",
      "Iteration: 7532/10000, Loss: 0.011398863978683949\n",
      "Iteration: 7533/10000, Loss: 0.008110707625746727\n",
      "Iteration: 7534/10000, Loss: 0.014362119138240814\n",
      "Iteration: 7535/10000, Loss: 0.009574814699590206\n",
      "Iteration: 7536/10000, Loss: 0.010207701474428177\n",
      "Iteration: 7537/10000, Loss: 0.014071600511670113\n",
      "Iteration: 7538/10000, Loss: 0.01206107810139656\n",
      "Iteration: 7539/10000, Loss: 0.006317690946161747\n",
      "Iteration: 7540/10000, Loss: 0.007166543509811163\n",
      "Iteration: 7541/10000, Loss: 0.006824885960668325\n",
      "Iteration: 7542/10000, Loss: 0.006400508340448141\n",
      "Iteration: 7543/10000, Loss: 0.008833839558064938\n",
      "Iteration: 7544/10000, Loss: 0.010675323195755482\n",
      "Iteration: 7545/10000, Loss: 0.012826932594180107\n",
      "Iteration: 7546/10000, Loss: 0.006426955107599497\n",
      "Iteration: 7547/10000, Loss: 0.007983846589922905\n",
      "Iteration: 7548/10000, Loss: 0.012177616357803345\n",
      "Iteration: 7549/10000, Loss: 0.01226687990128994\n",
      "Iteration: 7550/10000, Loss: 0.009287157095968723\n",
      "Iteration: 7551/10000, Loss: 0.009003926999866962\n",
      "Iteration: 7552/10000, Loss: 0.00909726694226265\n",
      "Iteration: 7553/10000, Loss: 0.009408660233020782\n",
      "Iteration: 7554/10000, Loss: 0.007121523842215538\n",
      "Iteration: 7555/10000, Loss: 0.011326974257826805\n",
      "Iteration: 7556/10000, Loss: 0.011114975437521935\n",
      "Iteration: 7557/10000, Loss: 0.009216400794684887\n",
      "Iteration: 7558/10000, Loss: 0.011745925061404705\n",
      "Iteration: 7559/10000, Loss: 0.006524294149130583\n",
      "Iteration: 7560/10000, Loss: 0.006932549644261599\n",
      "Iteration: 7561/10000, Loss: 0.009924910962581635\n",
      "Iteration: 7562/10000, Loss: 0.01143023744225502\n",
      "Iteration: 7563/10000, Loss: 0.011395708657801151\n",
      "Iteration: 7564/10000, Loss: 0.010625948198139668\n",
      "Iteration: 7565/10000, Loss: 0.00872878823429346\n",
      "Iteration: 7566/10000, Loss: 0.007009547203779221\n",
      "Iteration: 7567/10000, Loss: 0.01057400181889534\n",
      "Iteration: 7568/10000, Loss: 0.004372194409370422\n",
      "Iteration: 7569/10000, Loss: 0.010890753008425236\n",
      "Iteration: 7570/10000, Loss: 0.008488448336720467\n",
      "Iteration: 7571/10000, Loss: 0.010100438259541988\n",
      "Iteration: 7572/10000, Loss: 0.015007911249995232\n",
      "Iteration: 7573/10000, Loss: 0.010059034451842308\n",
      "Iteration: 7574/10000, Loss: 0.01485309936106205\n",
      "Iteration: 7575/10000, Loss: 0.00993298925459385\n",
      "Iteration: 7576/10000, Loss: 0.012023301795125008\n",
      "Iteration: 7577/10000, Loss: 0.011874807998538017\n",
      "Iteration: 7578/10000, Loss: 0.013219082728028297\n",
      "Iteration: 7579/10000, Loss: 0.012083171866834164\n",
      "Iteration: 7580/10000, Loss: 0.007092259358614683\n",
      "Iteration: 7581/10000, Loss: 0.008230413310229778\n",
      "Iteration: 7582/10000, Loss: 0.012276606634259224\n",
      "Iteration: 7583/10000, Loss: 0.011768080294132233\n",
      "Iteration: 7584/10000, Loss: 0.006963677238672972\n",
      "Iteration: 7585/10000, Loss: 0.01260121539235115\n",
      "Iteration: 7586/10000, Loss: 0.007538598030805588\n",
      "Iteration: 7587/10000, Loss: 0.008597465232014656\n",
      "Iteration: 7588/10000, Loss: 0.010261356830596924\n",
      "Iteration: 7589/10000, Loss: 0.009230457246303558\n",
      "Iteration: 7590/10000, Loss: 0.011359061114490032\n",
      "Iteration: 7591/10000, Loss: 0.012808501720428467\n",
      "Iteration: 7592/10000, Loss: 0.010687046684324741\n",
      "Iteration: 7593/10000, Loss: 0.01399629469960928\n",
      "Iteration: 7594/10000, Loss: 0.006825489457696676\n",
      "Iteration: 7595/10000, Loss: 0.0050231171771883965\n",
      "Iteration: 7596/10000, Loss: 0.009607169777154922\n",
      "Iteration: 7597/10000, Loss: 0.013995325192809105\n",
      "Iteration: 7598/10000, Loss: 0.009215278550982475\n",
      "Iteration: 7599/10000, Loss: 0.011767097748816013\n",
      "Iteration: 7600/10000, Loss: 0.007808538153767586\n",
      "Average test loss:  0.0026\n",
      "Iteration: 7601/10000, Loss: 0.007226419635117054\n",
      "Iteration: 7602/10000, Loss: 0.014509521424770355\n",
      "Iteration: 7603/10000, Loss: 0.00788654014468193\n",
      "Iteration: 7604/10000, Loss: 0.0076302699744701385\n",
      "Iteration: 7605/10000, Loss: 0.012604149989783764\n",
      "Iteration: 7606/10000, Loss: 0.008442705497145653\n",
      "Iteration: 7607/10000, Loss: 0.007696664426475763\n",
      "Iteration: 7608/10000, Loss: 0.015392818488180637\n",
      "Iteration: 7609/10000, Loss: 0.008407963439822197\n",
      "Iteration: 7610/10000, Loss: 0.010591501370072365\n",
      "Iteration: 7611/10000, Loss: 0.0112163620069623\n",
      "Iteration: 7612/10000, Loss: 0.00859762541949749\n",
      "Iteration: 7613/10000, Loss: 0.011940053664147854\n",
      "Iteration: 7614/10000, Loss: 0.007629909086972475\n",
      "Iteration: 7615/10000, Loss: 0.008251930586993694\n",
      "Iteration: 7616/10000, Loss: 0.01660049334168434\n",
      "Iteration: 7617/10000, Loss: 0.01302262768149376\n",
      "Iteration: 7618/10000, Loss: 0.00557940686121583\n",
      "Iteration: 7619/10000, Loss: 0.013127252459526062\n",
      "Iteration: 7620/10000, Loss: 0.011382213793694973\n",
      "Iteration: 7621/10000, Loss: 0.008795027621090412\n",
      "Iteration: 7622/10000, Loss: 0.00985875353217125\n",
      "Iteration: 7623/10000, Loss: 0.008842730894684792\n",
      "Iteration: 7624/10000, Loss: 0.010614495724439621\n",
      "Iteration: 7625/10000, Loss: 0.00507692527025938\n",
      "Iteration: 7626/10000, Loss: 0.007021784782409668\n",
      "Iteration: 7627/10000, Loss: 0.008872888050973415\n",
      "Iteration: 7628/10000, Loss: 0.00856967642903328\n",
      "Iteration: 7629/10000, Loss: 0.00981325376778841\n",
      "Iteration: 7630/10000, Loss: 0.01492794044315815\n",
      "Iteration: 7631/10000, Loss: 0.011511949822306633\n",
      "Iteration: 7632/10000, Loss: 0.008682288229465485\n",
      "Iteration: 7633/10000, Loss: 0.011690451763570309\n",
      "Iteration: 7634/10000, Loss: 0.005309922620654106\n",
      "Iteration: 7635/10000, Loss: 0.009068996645510197\n",
      "Iteration: 7636/10000, Loss: 0.0051941219717264175\n",
      "Iteration: 7637/10000, Loss: 0.012792048044502735\n",
      "Iteration: 7638/10000, Loss: 0.013413914479315281\n",
      "Iteration: 7639/10000, Loss: 0.009686230681836605\n",
      "Iteration: 7640/10000, Loss: 0.009211862459778786\n",
      "Iteration: 7641/10000, Loss: 0.010635040700435638\n",
      "Iteration: 7642/10000, Loss: 0.01349856797605753\n",
      "Iteration: 7643/10000, Loss: 0.010078060440719128\n",
      "Iteration: 7644/10000, Loss: 0.008854171261191368\n",
      "Iteration: 7645/10000, Loss: 0.011586599983274937\n",
      "Iteration: 7646/10000, Loss: 0.008021137677133083\n",
      "Iteration: 7647/10000, Loss: 0.010325432755053043\n",
      "Iteration: 7648/10000, Loss: 0.007141717243939638\n",
      "Iteration: 7649/10000, Loss: 0.01205629762262106\n",
      "Iteration: 7650/10000, Loss: 0.008502883836627007\n",
      "Iteration: 7651/10000, Loss: 0.009126611985266209\n",
      "Iteration: 7652/10000, Loss: 0.010404225438833237\n",
      "Iteration: 7653/10000, Loss: 0.0071012405678629875\n",
      "Iteration: 7654/10000, Loss: 0.011659965850412846\n",
      "Iteration: 7655/10000, Loss: 0.007908781990408897\n",
      "Iteration: 7656/10000, Loss: 0.012354818172752857\n",
      "Iteration: 7657/10000, Loss: 0.009781550616025925\n",
      "Iteration: 7658/10000, Loss: 0.010297562927007675\n",
      "Iteration: 7659/10000, Loss: 0.009297292679548264\n",
      "Iteration: 7660/10000, Loss: 0.007791861426085234\n",
      "Iteration: 7661/10000, Loss: 0.00964792538434267\n",
      "Iteration: 7662/10000, Loss: 0.011373195797204971\n",
      "Iteration: 7663/10000, Loss: 0.009276154451072216\n",
      "Iteration: 7664/10000, Loss: 0.007505454123020172\n",
      "Iteration: 7665/10000, Loss: 0.01263504009693861\n",
      "Iteration: 7666/10000, Loss: 0.014616303145885468\n",
      "Iteration: 7667/10000, Loss: 0.011827957816421986\n",
      "Iteration: 7668/10000, Loss: 0.008987766690552235\n",
      "Iteration: 7669/10000, Loss: 0.008777518756687641\n",
      "Iteration: 7670/10000, Loss: 0.006440714001655579\n",
      "Iteration: 7671/10000, Loss: 0.010833418928086758\n",
      "Iteration: 7672/10000, Loss: 0.009818384423851967\n",
      "Iteration: 7673/10000, Loss: 0.008902665227651596\n",
      "Iteration: 7674/10000, Loss: 0.010634182021021843\n",
      "Iteration: 7675/10000, Loss: 0.0095719825476408\n",
      "Iteration: 7676/10000, Loss: 0.010593190789222717\n",
      "Iteration: 7677/10000, Loss: 0.007383138872683048\n",
      "Iteration: 7678/10000, Loss: 0.014299946837127209\n",
      "Iteration: 7679/10000, Loss: 0.01075004693120718\n",
      "Iteration: 7680/10000, Loss: 0.009449937380850315\n",
      "Iteration: 7681/10000, Loss: 0.006224611774086952\n",
      "Iteration: 7682/10000, Loss: 0.009655345231294632\n",
      "Iteration: 7683/10000, Loss: 0.006791436579078436\n",
      "Iteration: 7684/10000, Loss: 0.011421002447605133\n",
      "Iteration: 7685/10000, Loss: 0.010665780864655972\n",
      "Iteration: 7686/10000, Loss: 0.0075453720055520535\n",
      "Iteration: 7687/10000, Loss: 0.011038878001272678\n",
      "Iteration: 7688/10000, Loss: 0.011306839063763618\n",
      "Iteration: 7689/10000, Loss: 0.010383542627096176\n",
      "Iteration: 7690/10000, Loss: 0.012090089730918407\n",
      "Iteration: 7691/10000, Loss: 0.012826219201087952\n",
      "Iteration: 7692/10000, Loss: 0.010113885626196861\n",
      "Iteration: 7693/10000, Loss: 0.012586742639541626\n",
      "Iteration: 7694/10000, Loss: 0.010030201636254787\n",
      "Iteration: 7695/10000, Loss: 0.011555969715118408\n",
      "Iteration: 7696/10000, Loss: 0.013069624081254005\n",
      "Iteration: 7697/10000, Loss: 0.011291082948446274\n",
      "Iteration: 7698/10000, Loss: 0.00659524742513895\n",
      "Iteration: 7699/10000, Loss: 0.01036926917731762\n",
      "Iteration: 7700/10000, Loss: 0.009508677758276463\n",
      "Average test loss:  0.0043\n",
      "Iteration: 7701/10000, Loss: 0.014492355287075043\n",
      "Iteration: 7702/10000, Loss: 0.013175759464502335\n",
      "Iteration: 7703/10000, Loss: 0.008779156021773815\n",
      "Iteration: 7704/10000, Loss: 0.01282196119427681\n",
      "Iteration: 7705/10000, Loss: 0.013287014327943325\n",
      "Iteration: 7706/10000, Loss: 0.008071869611740112\n",
      "Iteration: 7707/10000, Loss: 0.012546355836093426\n",
      "Iteration: 7708/10000, Loss: 0.012002069503068924\n",
      "Iteration: 7709/10000, Loss: 0.005135947838425636\n",
      "Iteration: 7710/10000, Loss: 0.008892374113202095\n",
      "Iteration: 7711/10000, Loss: 0.013152746483683586\n",
      "Iteration: 7712/10000, Loss: 0.0136105390265584\n",
      "Iteration: 7713/10000, Loss: 0.008230844512581825\n",
      "Iteration: 7714/10000, Loss: 0.011104998178780079\n",
      "Iteration: 7715/10000, Loss: 0.00984819233417511\n",
      "Iteration: 7716/10000, Loss: 0.008578636683523655\n",
      "Iteration: 7717/10000, Loss: 0.009034746326506138\n",
      "Iteration: 7718/10000, Loss: 0.01230476051568985\n",
      "Iteration: 7719/10000, Loss: 0.0105112474411726\n",
      "Iteration: 7720/10000, Loss: 0.010133937932550907\n",
      "Iteration: 7721/10000, Loss: 0.009909077547490597\n",
      "Iteration: 7722/10000, Loss: 0.012499514035880566\n",
      "Iteration: 7723/10000, Loss: 0.01012454740703106\n",
      "Iteration: 7724/10000, Loss: 0.01003981288522482\n",
      "Iteration: 7725/10000, Loss: 0.011977830901741982\n",
      "Iteration: 7726/10000, Loss: 0.009076318703591824\n",
      "Iteration: 7727/10000, Loss: 0.011648801155388355\n",
      "Iteration: 7728/10000, Loss: 0.00904962606728077\n",
      "Iteration: 7729/10000, Loss: 0.010639258660376072\n",
      "Iteration: 7730/10000, Loss: 0.00944816879928112\n",
      "Iteration: 7731/10000, Loss: 0.011860216036438942\n",
      "Iteration: 7732/10000, Loss: 0.009506545960903168\n",
      "Iteration: 7733/10000, Loss: 0.009695290587842464\n",
      "Iteration: 7734/10000, Loss: 0.0073997704312205315\n",
      "Iteration: 7735/10000, Loss: 0.006005920469760895\n",
      "Iteration: 7736/10000, Loss: 0.007818414829671383\n",
      "Iteration: 7737/10000, Loss: 0.010164719074964523\n",
      "Iteration: 7738/10000, Loss: 0.010863257572054863\n",
      "Iteration: 7739/10000, Loss: 0.01605452597141266\n",
      "Iteration: 7740/10000, Loss: 0.010202472098171711\n",
      "Iteration: 7741/10000, Loss: 0.011878849938511848\n",
      "Iteration: 7742/10000, Loss: 0.008223415352404118\n",
      "Iteration: 7743/10000, Loss: 0.009318757802248001\n",
      "Iteration: 7744/10000, Loss: 0.011057477444410324\n",
      "Iteration: 7745/10000, Loss: 0.008305096067488194\n",
      "Iteration: 7746/10000, Loss: 0.012838946655392647\n",
      "Iteration: 7747/10000, Loss: 0.009602143429219723\n",
      "Iteration: 7748/10000, Loss: 0.011566516943275928\n",
      "Iteration: 7749/10000, Loss: 0.007297685369849205\n",
      "Iteration: 7750/10000, Loss: 0.009190843440592289\n",
      "Iteration: 7751/10000, Loss: 0.012034429237246513\n",
      "Iteration: 7752/10000, Loss: 0.01069158036261797\n",
      "Iteration: 7753/10000, Loss: 0.010377817787230015\n",
      "Iteration: 7754/10000, Loss: 0.011235924437642097\n",
      "Iteration: 7755/10000, Loss: 0.010424827225506306\n",
      "Iteration: 7756/10000, Loss: 0.010808425024151802\n",
      "Iteration: 7757/10000, Loss: 0.013445655815303326\n",
      "Iteration: 7758/10000, Loss: 0.010389016009867191\n",
      "Iteration: 7759/10000, Loss: 0.00838693417608738\n",
      "Iteration: 7760/10000, Loss: 0.0076505159959197044\n",
      "Iteration: 7761/10000, Loss: 0.009475993923842907\n",
      "Iteration: 7762/10000, Loss: 0.008824650198221207\n",
      "Iteration: 7763/10000, Loss: 0.012093782424926758\n",
      "Iteration: 7764/10000, Loss: 0.011712851002812386\n",
      "Iteration: 7765/10000, Loss: 0.009139291942119598\n",
      "Iteration: 7766/10000, Loss: 0.011421270668506622\n",
      "Iteration: 7767/10000, Loss: 0.010891899466514587\n",
      "Iteration: 7768/10000, Loss: 0.01319322269409895\n",
      "Iteration: 7769/10000, Loss: 0.014335627667605877\n",
      "Iteration: 7770/10000, Loss: 0.010835184715688229\n",
      "Iteration: 7771/10000, Loss: 0.009565547108650208\n",
      "Iteration: 7772/10000, Loss: 0.009529012255370617\n",
      "Iteration: 7773/10000, Loss: 0.009536297991871834\n",
      "Iteration: 7774/10000, Loss: 0.008938522078096867\n",
      "Iteration: 7775/10000, Loss: 0.01061956211924553\n",
      "Iteration: 7776/10000, Loss: 0.011274158954620361\n",
      "Iteration: 7777/10000, Loss: 0.012032002210617065\n",
      "Iteration: 7778/10000, Loss: 0.011619269847869873\n",
      "Iteration: 7779/10000, Loss: 0.008953701704740524\n",
      "Iteration: 7780/10000, Loss: 0.008139255456626415\n",
      "Iteration: 7781/10000, Loss: 0.009009447880089283\n",
      "Iteration: 7782/10000, Loss: 0.010132369585335255\n",
      "Iteration: 7783/10000, Loss: 0.006848812568932772\n",
      "Iteration: 7784/10000, Loss: 0.006169169209897518\n",
      "Iteration: 7785/10000, Loss: 0.012226360850036144\n",
      "Iteration: 7786/10000, Loss: 0.010881592519581318\n",
      "Iteration: 7787/10000, Loss: 0.007529371418058872\n",
      "Iteration: 7788/10000, Loss: 0.009765398688614368\n",
      "Iteration: 7789/10000, Loss: 0.01064428873360157\n",
      "Iteration: 7790/10000, Loss: 0.007004246581345797\n",
      "Iteration: 7791/10000, Loss: 0.011327280662953854\n",
      "Iteration: 7792/10000, Loss: 0.00889503676444292\n",
      "Iteration: 7793/10000, Loss: 0.006743896286934614\n",
      "Iteration: 7794/10000, Loss: 0.01199254859238863\n",
      "Iteration: 7795/10000, Loss: 0.010961255989968777\n",
      "Iteration: 7796/10000, Loss: 0.010526277124881744\n",
      "Iteration: 7797/10000, Loss: 0.010289862751960754\n",
      "Iteration: 7798/10000, Loss: 0.010876918211579323\n",
      "Iteration: 7799/10000, Loss: 0.013333910144865513\n",
      "Iteration: 7800/10000, Loss: 0.008334015496075153\n",
      "Average test loss:  0.0046\n",
      "Iteration: 7801/10000, Loss: 0.011719674803316593\n",
      "Iteration: 7802/10000, Loss: 0.010590611957013607\n",
      "Iteration: 7803/10000, Loss: 0.008702745661139488\n",
      "Iteration: 7804/10000, Loss: 0.011606107465922832\n",
      "Iteration: 7805/10000, Loss: 0.00971679575741291\n",
      "Iteration: 7806/10000, Loss: 0.007772214710712433\n",
      "Iteration: 7807/10000, Loss: 0.00817051064223051\n",
      "Iteration: 7808/10000, Loss: 0.009187030605971813\n",
      "Iteration: 7809/10000, Loss: 0.007662048563361168\n",
      "Iteration: 7810/10000, Loss: 0.007811835967004299\n",
      "Iteration: 7811/10000, Loss: 0.006924233864992857\n",
      "Iteration: 7812/10000, Loss: 0.007241095416247845\n",
      "Iteration: 7813/10000, Loss: 0.009889309294521809\n",
      "Iteration: 7814/10000, Loss: 0.009861337952315807\n",
      "Iteration: 7815/10000, Loss: 0.011059422045946121\n",
      "Iteration: 7816/10000, Loss: 0.009397412650287151\n",
      "Iteration: 7817/10000, Loss: 0.01007166225463152\n",
      "Iteration: 7818/10000, Loss: 0.007435402367264032\n",
      "Iteration: 7819/10000, Loss: 0.00949593260884285\n",
      "Iteration: 7820/10000, Loss: 0.0085073197260499\n",
      "Iteration: 7821/10000, Loss: 0.011401280760765076\n",
      "Iteration: 7822/10000, Loss: 0.009489026851952076\n",
      "Iteration: 7823/10000, Loss: 0.01254149992018938\n",
      "Iteration: 7824/10000, Loss: 0.009185342118144035\n",
      "Iteration: 7825/10000, Loss: 0.01135934330523014\n",
      "Iteration: 7826/10000, Loss: 0.00882801041007042\n",
      "Iteration: 7827/10000, Loss: 0.011049480177462101\n",
      "Iteration: 7828/10000, Loss: 0.015248262323439121\n",
      "Iteration: 7829/10000, Loss: 0.015591093339025974\n",
      "Iteration: 7830/10000, Loss: 0.008975432254374027\n",
      "Iteration: 7831/10000, Loss: 0.0062449779361486435\n",
      "Iteration: 7832/10000, Loss: 0.011960119940340519\n",
      "Iteration: 7833/10000, Loss: 0.008130393922328949\n",
      "Iteration: 7834/10000, Loss: 0.008811738342046738\n",
      "Iteration: 7835/10000, Loss: 0.012788950465619564\n",
      "Iteration: 7836/10000, Loss: 0.012444959953427315\n",
      "Iteration: 7837/10000, Loss: 0.010977545753121376\n",
      "Iteration: 7838/10000, Loss: 0.010834329761564732\n",
      "Iteration: 7839/10000, Loss: 0.007658583112061024\n",
      "Iteration: 7840/10000, Loss: 0.009471836499869823\n",
      "Iteration: 7841/10000, Loss: 0.010434490628540516\n",
      "Iteration: 7842/10000, Loss: 0.011727854609489441\n",
      "Iteration: 7843/10000, Loss: 0.012721431441605091\n",
      "Iteration: 7844/10000, Loss: 0.010120292194187641\n",
      "Iteration: 7845/10000, Loss: 0.017414450645446777\n",
      "Iteration: 7846/10000, Loss: 0.009013512171804905\n",
      "Iteration: 7847/10000, Loss: 0.015043738298118114\n",
      "Iteration: 7848/10000, Loss: 0.010883617214858532\n",
      "Iteration: 7849/10000, Loss: 0.010049114935100079\n",
      "Iteration: 7850/10000, Loss: 0.009935739450156689\n",
      "Iteration: 7851/10000, Loss: 0.0113075478002429\n",
      "Iteration: 7852/10000, Loss: 0.015650974586606026\n",
      "Iteration: 7853/10000, Loss: 0.015058783814311028\n",
      "Iteration: 7854/10000, Loss: 0.010814049281179905\n",
      "Iteration: 7855/10000, Loss: 0.014141527935862541\n",
      "Iteration: 7856/10000, Loss: 0.011011376976966858\n",
      "Iteration: 7857/10000, Loss: 0.012352564372122288\n",
      "Iteration: 7858/10000, Loss: 0.01361043844372034\n",
      "Iteration: 7859/10000, Loss: 0.009849423542618752\n",
      "Iteration: 7860/10000, Loss: 0.008604749105870724\n",
      "Iteration: 7861/10000, Loss: 0.010130179114639759\n",
      "Iteration: 7862/10000, Loss: 0.011187773197889328\n",
      "Iteration: 7863/10000, Loss: 0.00937453843653202\n",
      "Iteration: 7864/10000, Loss: 0.011867266148328781\n",
      "Iteration: 7865/10000, Loss: 0.00903642363846302\n",
      "Iteration: 7866/10000, Loss: 0.006444547791033983\n",
      "Iteration: 7867/10000, Loss: 0.012108742259442806\n",
      "Iteration: 7868/10000, Loss: 0.00973336212337017\n",
      "Iteration: 7869/10000, Loss: 0.008633257821202278\n",
      "Iteration: 7870/10000, Loss: 0.011338923126459122\n",
      "Iteration: 7871/10000, Loss: 0.013624765910208225\n",
      "Iteration: 7872/10000, Loss: 0.015180290676653385\n",
      "Iteration: 7873/10000, Loss: 0.007031937595456839\n",
      "Iteration: 7874/10000, Loss: 0.00819739792495966\n",
      "Iteration: 7875/10000, Loss: 0.010605281218886375\n",
      "Iteration: 7876/10000, Loss: 0.01175809744745493\n",
      "Iteration: 7877/10000, Loss: 0.015286742709577084\n",
      "Iteration: 7878/10000, Loss: 0.009466728195548058\n",
      "Iteration: 7879/10000, Loss: 0.008437131531536579\n",
      "Iteration: 7880/10000, Loss: 0.018152516335248947\n",
      "Iteration: 7881/10000, Loss: 0.007351503241807222\n",
      "Iteration: 7882/10000, Loss: 0.011764561757445335\n",
      "Iteration: 7883/10000, Loss: 0.01169187668710947\n",
      "Iteration: 7884/10000, Loss: 0.009970209561288357\n",
      "Iteration: 7885/10000, Loss: 0.007452731020748615\n",
      "Iteration: 7886/10000, Loss: 0.007097897119820118\n",
      "Iteration: 7887/10000, Loss: 0.012117580510675907\n",
      "Iteration: 7888/10000, Loss: 0.017227813601493835\n",
      "Iteration: 7889/10000, Loss: 0.012393287383019924\n",
      "Iteration: 7890/10000, Loss: 0.015909237787127495\n",
      "Iteration: 7891/10000, Loss: 0.007727656047791243\n",
      "Iteration: 7892/10000, Loss: 0.011094926856458187\n",
      "Iteration: 7893/10000, Loss: 0.013142570853233337\n",
      "Iteration: 7894/10000, Loss: 0.007197659928351641\n",
      "Iteration: 7895/10000, Loss: 0.01415816880762577\n",
      "Iteration: 7896/10000, Loss: 0.010858849622309208\n",
      "Iteration: 7897/10000, Loss: 0.005908148363232613\n",
      "Iteration: 7898/10000, Loss: 0.012952342629432678\n",
      "Iteration: 7899/10000, Loss: 0.012796381488442421\n",
      "Iteration: 7900/10000, Loss: 0.007123492192476988\n",
      "Average test loss:  0.0039\n",
      "Iteration: 7901/10000, Loss: 0.016047371551394463\n",
      "Iteration: 7902/10000, Loss: 0.012741109356284142\n",
      "Iteration: 7903/10000, Loss: 0.011637966148555279\n",
      "Iteration: 7904/10000, Loss: 0.015629589557647705\n",
      "Iteration: 7905/10000, Loss: 0.01022958755493164\n",
      "Iteration: 7906/10000, Loss: 0.013541577383875847\n",
      "Iteration: 7907/10000, Loss: 0.008468029089272022\n",
      "Iteration: 7908/10000, Loss: 0.011646387167274952\n",
      "Iteration: 7909/10000, Loss: 0.00549901369959116\n",
      "Iteration: 7910/10000, Loss: 0.01176575105637312\n",
      "Iteration: 7911/10000, Loss: 0.010092809796333313\n",
      "Iteration: 7912/10000, Loss: 0.012779920361936092\n",
      "Iteration: 7913/10000, Loss: 0.011053502559661865\n",
      "Iteration: 7914/10000, Loss: 0.012215258553624153\n",
      "Iteration: 7915/10000, Loss: 0.010683449916541576\n",
      "Iteration: 7916/10000, Loss: 0.015015051700174809\n",
      "Iteration: 7917/10000, Loss: 0.008573319762945175\n",
      "Iteration: 7918/10000, Loss: 0.009138439781963825\n",
      "Iteration: 7919/10000, Loss: 0.008707806468009949\n",
      "Iteration: 7920/10000, Loss: 0.011721190996468067\n",
      "Iteration: 7921/10000, Loss: 0.005960310809314251\n",
      "Iteration: 7922/10000, Loss: 0.010682353749871254\n",
      "Iteration: 7923/10000, Loss: 0.013585076667368412\n",
      "Iteration: 7924/10000, Loss: 0.008465654216706753\n",
      "Iteration: 7925/10000, Loss: 0.011625099927186966\n",
      "Iteration: 7926/10000, Loss: 0.012829725630581379\n",
      "Iteration: 7927/10000, Loss: 0.0072593046352267265\n",
      "Iteration: 7928/10000, Loss: 0.009869229979813099\n",
      "Iteration: 7929/10000, Loss: 0.005639346782118082\n",
      "Iteration: 7930/10000, Loss: 0.012153401970863342\n",
      "Iteration: 7931/10000, Loss: 0.008498571813106537\n",
      "Iteration: 7932/10000, Loss: 0.008535672910511494\n",
      "Iteration: 7933/10000, Loss: 0.0050745271146297455\n",
      "Iteration: 7934/10000, Loss: 0.012733292765915394\n",
      "Iteration: 7935/10000, Loss: 0.01460993941873312\n",
      "Iteration: 7936/10000, Loss: 0.007267825771123171\n",
      "Iteration: 7937/10000, Loss: 0.00843408890068531\n",
      "Iteration: 7938/10000, Loss: 0.010109931230545044\n",
      "Iteration: 7939/10000, Loss: 0.009160877205431461\n",
      "Iteration: 7940/10000, Loss: 0.012547961436212063\n",
      "Iteration: 7941/10000, Loss: 0.010077225975692272\n",
      "Iteration: 7942/10000, Loss: 0.010149200446903706\n",
      "Iteration: 7943/10000, Loss: 0.013991878367960453\n",
      "Iteration: 7944/10000, Loss: 0.010436405427753925\n",
      "Iteration: 7945/10000, Loss: 0.00889530684798956\n",
      "Iteration: 7946/10000, Loss: 0.008601098321378231\n",
      "Iteration: 7947/10000, Loss: 0.008737758733332157\n",
      "Iteration: 7948/10000, Loss: 0.004824073053896427\n",
      "Iteration: 7949/10000, Loss: 0.00768674723803997\n",
      "Iteration: 7950/10000, Loss: 0.009532827883958817\n",
      "Iteration: 7951/10000, Loss: 0.011427614837884903\n",
      "Iteration: 7952/10000, Loss: 0.008297133259475231\n",
      "Iteration: 7953/10000, Loss: 0.010619783774018288\n",
      "Iteration: 7954/10000, Loss: 0.00988864153623581\n",
      "Iteration: 7955/10000, Loss: 0.009844866581261158\n",
      "Iteration: 7956/10000, Loss: 0.011448611505329609\n",
      "Iteration: 7957/10000, Loss: 0.012079079635441303\n",
      "Iteration: 7958/10000, Loss: 0.008676309138536453\n",
      "Iteration: 7959/10000, Loss: 0.00876680575311184\n",
      "Iteration: 7960/10000, Loss: 0.01504203025251627\n",
      "Iteration: 7961/10000, Loss: 0.012726501561701298\n",
      "Iteration: 7962/10000, Loss: 0.00622194167226553\n",
      "Iteration: 7963/10000, Loss: 0.005953511688858271\n",
      "Iteration: 7964/10000, Loss: 0.008276869542896748\n",
      "Iteration: 7965/10000, Loss: 0.009925211779773235\n",
      "Iteration: 7966/10000, Loss: 0.010306302458047867\n",
      "Iteration: 7967/10000, Loss: 0.008254462853074074\n",
      "Iteration: 7968/10000, Loss: 0.005887655541300774\n",
      "Iteration: 7969/10000, Loss: 0.012683244422078133\n",
      "Iteration: 7970/10000, Loss: 0.008221125230193138\n",
      "Iteration: 7971/10000, Loss: 0.005370947998017073\n",
      "Iteration: 7972/10000, Loss: 0.009233214892446995\n",
      "Iteration: 7973/10000, Loss: 0.00886569544672966\n",
      "Iteration: 7974/10000, Loss: 0.010819748044013977\n",
      "Iteration: 7975/10000, Loss: 0.01319355983287096\n",
      "Iteration: 7976/10000, Loss: 0.012420588172972202\n",
      "Iteration: 7977/10000, Loss: 0.0060142893344163895\n",
      "Iteration: 7978/10000, Loss: 0.012414880096912384\n",
      "Iteration: 7979/10000, Loss: 0.007718639448285103\n",
      "Iteration: 7980/10000, Loss: 0.008104847744107246\n",
      "Iteration: 7981/10000, Loss: 0.007744730915874243\n",
      "Iteration: 7982/10000, Loss: 0.008986517786979675\n",
      "Iteration: 7983/10000, Loss: 0.009370985440909863\n",
      "Iteration: 7984/10000, Loss: 0.012426750734448433\n",
      "Iteration: 7985/10000, Loss: 0.004976733587682247\n",
      "Iteration: 7986/10000, Loss: 0.014296595007181168\n",
      "Iteration: 7987/10000, Loss: 0.006578980479389429\n",
      "Iteration: 7988/10000, Loss: 0.008917000144720078\n",
      "Iteration: 7989/10000, Loss: 0.008290157653391361\n",
      "Iteration: 7990/10000, Loss: 0.01212088018655777\n",
      "Iteration: 7991/10000, Loss: 0.004220878705382347\n",
      "Iteration: 7992/10000, Loss: 0.011011021211743355\n",
      "Iteration: 7993/10000, Loss: 0.012007166631519794\n",
      "Iteration: 7994/10000, Loss: 0.011765454895794392\n",
      "Iteration: 7995/10000, Loss: 0.012975893914699554\n",
      "Iteration: 7996/10000, Loss: 0.009424150921404362\n",
      "Iteration: 7997/10000, Loss: 0.009623175486922264\n",
      "Iteration: 7998/10000, Loss: 0.00675031915307045\n",
      "Iteration: 7999/10000, Loss: 0.009604845196008682\n",
      "Iteration: 8000/10000, Loss: 0.01042403094470501\n",
      "Average test loss:  0.0040\n",
      "Iteration: 8001/10000, Loss: 0.012447336688637733\n",
      "Iteration: 8002/10000, Loss: 0.011266051791608334\n",
      "Iteration: 8003/10000, Loss: 0.01396655011922121\n",
      "Iteration: 8004/10000, Loss: 0.010232672095298767\n",
      "Iteration: 8005/10000, Loss: 0.0039387838914990425\n",
      "Iteration: 8006/10000, Loss: 0.008808479644358158\n",
      "Iteration: 8007/10000, Loss: 0.010675238445401192\n",
      "Iteration: 8008/10000, Loss: 0.007341388147324324\n",
      "Iteration: 8009/10000, Loss: 0.010175756178796291\n",
      "Iteration: 8010/10000, Loss: 0.010476464405655861\n",
      "Iteration: 8011/10000, Loss: 0.008233235217630863\n",
      "Iteration: 8012/10000, Loss: 0.01286010816693306\n",
      "Iteration: 8013/10000, Loss: 0.009627564810216427\n",
      "Iteration: 8014/10000, Loss: 0.009578024968504906\n",
      "Iteration: 8015/10000, Loss: 0.010701088234782219\n",
      "Iteration: 8016/10000, Loss: 0.01029862929135561\n",
      "Iteration: 8017/10000, Loss: 0.009861363098025322\n",
      "Iteration: 8018/10000, Loss: 0.01263304241001606\n",
      "Iteration: 8019/10000, Loss: 0.010466046631336212\n",
      "Iteration: 8020/10000, Loss: 0.012254566885530949\n",
      "Iteration: 8021/10000, Loss: 0.010821888223290443\n",
      "Iteration: 8022/10000, Loss: 0.006792991887778044\n",
      "Iteration: 8023/10000, Loss: 0.010194683447480202\n",
      "Iteration: 8024/10000, Loss: 0.013343570753932\n",
      "Iteration: 8025/10000, Loss: 0.009444492869079113\n",
      "Iteration: 8026/10000, Loss: 0.005881008226424456\n",
      "Iteration: 8027/10000, Loss: 0.00954887829720974\n",
      "Iteration: 8028/10000, Loss: 0.016090909019112587\n",
      "Iteration: 8029/10000, Loss: 0.009445710107684135\n",
      "Iteration: 8030/10000, Loss: 0.012409153394401073\n",
      "Iteration: 8031/10000, Loss: 0.00875343382358551\n",
      "Iteration: 8032/10000, Loss: 0.009223652072250843\n",
      "Iteration: 8033/10000, Loss: 0.011372561566531658\n",
      "Iteration: 8034/10000, Loss: 0.008852456696331501\n",
      "Iteration: 8035/10000, Loss: 0.01028111856430769\n",
      "Iteration: 8036/10000, Loss: 0.011231712996959686\n",
      "Iteration: 8037/10000, Loss: 0.011044515296816826\n",
      "Iteration: 8038/10000, Loss: 0.01139158383011818\n",
      "Iteration: 8039/10000, Loss: 0.013446039520204067\n",
      "Iteration: 8040/10000, Loss: 0.014531273394823074\n",
      "Iteration: 8041/10000, Loss: 0.00967718567699194\n",
      "Iteration: 8042/10000, Loss: 0.006797328591346741\n",
      "Iteration: 8043/10000, Loss: 0.010819361545145512\n",
      "Iteration: 8044/10000, Loss: 0.01202944666147232\n",
      "Iteration: 8045/10000, Loss: 0.01036040112376213\n",
      "Iteration: 8046/10000, Loss: 0.010425252839922905\n",
      "Iteration: 8047/10000, Loss: 0.018323419615626335\n",
      "Iteration: 8048/10000, Loss: 0.007660035975277424\n",
      "Iteration: 8049/10000, Loss: 0.010978872887790203\n",
      "Iteration: 8050/10000, Loss: 0.009529730305075645\n",
      "Iteration: 8051/10000, Loss: 0.0056190695613622665\n",
      "Iteration: 8052/10000, Loss: 0.006251112092286348\n",
      "Iteration: 8053/10000, Loss: 0.007839426398277283\n",
      "Iteration: 8054/10000, Loss: 0.006088969297707081\n",
      "Iteration: 8055/10000, Loss: 0.009617123752832413\n",
      "Iteration: 8056/10000, Loss: 0.00872106198221445\n",
      "Iteration: 8057/10000, Loss: 0.012212598696351051\n",
      "Iteration: 8058/10000, Loss: 0.007997723296284676\n",
      "Iteration: 8059/10000, Loss: 0.01098884642124176\n",
      "Iteration: 8060/10000, Loss: 0.007494303863495588\n",
      "Iteration: 8061/10000, Loss: 0.010613173246383667\n",
      "Iteration: 8062/10000, Loss: 0.009727094322443008\n",
      "Iteration: 8063/10000, Loss: 0.014742514118552208\n",
      "Iteration: 8064/10000, Loss: 0.009507207199931145\n",
      "Iteration: 8065/10000, Loss: 0.008233504369854927\n",
      "Iteration: 8066/10000, Loss: 0.010058172978460789\n",
      "Iteration: 8067/10000, Loss: 0.009192532859742641\n",
      "Iteration: 8068/10000, Loss: 0.012884793803095818\n",
      "Iteration: 8069/10000, Loss: 0.013009784743189812\n",
      "Iteration: 8070/10000, Loss: 0.008157673291862011\n",
      "Iteration: 8071/10000, Loss: 0.015071423724293709\n",
      "Iteration: 8072/10000, Loss: 0.011080432683229446\n",
      "Iteration: 8073/10000, Loss: 0.00972770992666483\n",
      "Iteration: 8074/10000, Loss: 0.012922728434205055\n",
      "Iteration: 8075/10000, Loss: 0.01036275364458561\n",
      "Iteration: 8076/10000, Loss: 0.008708512410521507\n",
      "Iteration: 8077/10000, Loss: 0.010904013179242611\n",
      "Iteration: 8078/10000, Loss: 0.007766093127429485\n",
      "Iteration: 8079/10000, Loss: 0.009012590162456036\n",
      "Iteration: 8080/10000, Loss: 0.009386159479618073\n",
      "Iteration: 8081/10000, Loss: 0.00930724572390318\n",
      "Iteration: 8082/10000, Loss: 0.01208552811294794\n",
      "Iteration: 8083/10000, Loss: 0.009319627657532692\n",
      "Iteration: 8084/10000, Loss: 0.011759480461478233\n",
      "Iteration: 8085/10000, Loss: 0.012473907321691513\n",
      "Iteration: 8086/10000, Loss: 0.012239181436598301\n",
      "Iteration: 8087/10000, Loss: 0.01347742322832346\n",
      "Iteration: 8088/10000, Loss: 0.01733900047838688\n",
      "Iteration: 8089/10000, Loss: 0.010388612747192383\n",
      "Iteration: 8090/10000, Loss: 0.007588383741676807\n",
      "Iteration: 8091/10000, Loss: 0.009657713584601879\n",
      "Iteration: 8092/10000, Loss: 0.010715169832110405\n",
      "Iteration: 8093/10000, Loss: 0.006882259156554937\n",
      "Iteration: 8094/10000, Loss: 0.009735630825161934\n",
      "Iteration: 8095/10000, Loss: 0.01303810440003872\n",
      "Iteration: 8096/10000, Loss: 0.011603043414652348\n",
      "Iteration: 8097/10000, Loss: 0.00786395464092493\n",
      "Iteration: 8098/10000, Loss: 0.006940628867596388\n",
      "Iteration: 8099/10000, Loss: 0.006690616253763437\n",
      "Iteration: 8100/10000, Loss: 0.00938913319259882\n",
      "Average test loss:  0.0033\n",
      "Iteration: 8101/10000, Loss: 0.006246639881283045\n",
      "Iteration: 8102/10000, Loss: 0.00858105719089508\n",
      "Iteration: 8103/10000, Loss: 0.011548394337296486\n",
      "Iteration: 8104/10000, Loss: 0.013480118475854397\n",
      "Iteration: 8105/10000, Loss: 0.010673255659639835\n",
      "Iteration: 8106/10000, Loss: 0.008409683592617512\n",
      "Iteration: 8107/10000, Loss: 0.010311616584658623\n",
      "Iteration: 8108/10000, Loss: 0.013468294404447079\n",
      "Iteration: 8109/10000, Loss: 0.00798939261585474\n",
      "Iteration: 8110/10000, Loss: 0.010331152938306332\n",
      "Iteration: 8111/10000, Loss: 0.008750167675316334\n",
      "Iteration: 8112/10000, Loss: 0.016774149611592293\n",
      "Iteration: 8113/10000, Loss: 0.010890204459428787\n",
      "Iteration: 8114/10000, Loss: 0.009650800377130508\n",
      "Iteration: 8115/10000, Loss: 0.006158463191241026\n",
      "Iteration: 8116/10000, Loss: 0.007365994621068239\n",
      "Iteration: 8117/10000, Loss: 0.00909715797752142\n",
      "Iteration: 8118/10000, Loss: 0.013873309828341007\n",
      "Iteration: 8119/10000, Loss: 0.009209901094436646\n",
      "Iteration: 8120/10000, Loss: 0.012232308275997639\n",
      "Iteration: 8121/10000, Loss: 0.007261231541633606\n",
      "Iteration: 8122/10000, Loss: 0.009804470464587212\n",
      "Iteration: 8123/10000, Loss: 0.006464023143053055\n",
      "Iteration: 8124/10000, Loss: 0.00852220132946968\n",
      "Iteration: 8125/10000, Loss: 0.008462432771921158\n",
      "Iteration: 8126/10000, Loss: 0.008577975444495678\n",
      "Iteration: 8127/10000, Loss: 0.010469057597219944\n",
      "Iteration: 8128/10000, Loss: 0.01045277900993824\n",
      "Iteration: 8129/10000, Loss: 0.008735563606023788\n",
      "Iteration: 8130/10000, Loss: 0.012189351953566074\n",
      "Iteration: 8131/10000, Loss: 0.004750378895550966\n",
      "Iteration: 8132/10000, Loss: 0.009459803812205791\n",
      "Iteration: 8133/10000, Loss: 0.007666273973882198\n",
      "Iteration: 8134/10000, Loss: 0.005953238345682621\n",
      "Iteration: 8135/10000, Loss: 0.009449714794754982\n",
      "Iteration: 8136/10000, Loss: 0.008421189151704311\n",
      "Iteration: 8137/10000, Loss: 0.012816711328923702\n",
      "Iteration: 8138/10000, Loss: 0.006281831301748753\n",
      "Iteration: 8139/10000, Loss: 0.01023088674992323\n",
      "Iteration: 8140/10000, Loss: 0.0106538450345397\n",
      "Iteration: 8141/10000, Loss: 0.013847006484866142\n",
      "Iteration: 8142/10000, Loss: 0.008891464211046696\n",
      "Iteration: 8143/10000, Loss: 0.008438016287982464\n",
      "Iteration: 8144/10000, Loss: 0.006932531949132681\n",
      "Iteration: 8145/10000, Loss: 0.008261224254965782\n",
      "Iteration: 8146/10000, Loss: 0.01093396358191967\n",
      "Iteration: 8147/10000, Loss: 0.006578073836863041\n",
      "Iteration: 8148/10000, Loss: 0.012826278805732727\n",
      "Iteration: 8149/10000, Loss: 0.012442250736057758\n",
      "Iteration: 8150/10000, Loss: 0.009668231941759586\n",
      "Iteration: 8151/10000, Loss: 0.008016330190002918\n",
      "Iteration: 8152/10000, Loss: 0.006020910572260618\n",
      "Iteration: 8153/10000, Loss: 0.009286395274102688\n",
      "Iteration: 8154/10000, Loss: 0.00982745736837387\n",
      "Iteration: 8155/10000, Loss: 0.00868002325296402\n",
      "Iteration: 8156/10000, Loss: 0.006587666925042868\n",
      "Iteration: 8157/10000, Loss: 0.010131942108273506\n",
      "Iteration: 8158/10000, Loss: 0.007711419835686684\n",
      "Iteration: 8159/10000, Loss: 0.010418770834803581\n",
      "Iteration: 8160/10000, Loss: 0.011762036010622978\n",
      "Iteration: 8161/10000, Loss: 0.008014935068786144\n",
      "Iteration: 8162/10000, Loss: 0.0095600550994277\n",
      "Iteration: 8163/10000, Loss: 0.009086460806429386\n",
      "Iteration: 8164/10000, Loss: 0.011543802917003632\n",
      "Iteration: 8165/10000, Loss: 0.007038401439785957\n",
      "Iteration: 8166/10000, Loss: 0.01043326873332262\n",
      "Iteration: 8167/10000, Loss: 0.009469093754887581\n",
      "Iteration: 8168/10000, Loss: 0.005391591694205999\n",
      "Iteration: 8169/10000, Loss: 0.006864175666123629\n",
      "Iteration: 8170/10000, Loss: 0.012683196924626827\n",
      "Iteration: 8171/10000, Loss: 0.010909742675721645\n",
      "Iteration: 8172/10000, Loss: 0.008009093813598156\n",
      "Iteration: 8173/10000, Loss: 0.006961068604141474\n",
      "Iteration: 8174/10000, Loss: 0.008129127323627472\n",
      "Iteration: 8175/10000, Loss: 0.007649475242942572\n",
      "Iteration: 8176/10000, Loss: 0.008683491498231888\n",
      "Iteration: 8177/10000, Loss: 0.009005977772176266\n",
      "Iteration: 8178/10000, Loss: 0.013335319235920906\n",
      "Iteration: 8179/10000, Loss: 0.01057527307420969\n",
      "Iteration: 8180/10000, Loss: 0.006976519711315632\n",
      "Iteration: 8181/10000, Loss: 0.007498872932046652\n",
      "Iteration: 8182/10000, Loss: 0.006302278488874435\n",
      "Iteration: 8183/10000, Loss: 0.01010737381875515\n",
      "Iteration: 8184/10000, Loss: 0.0071506802923977375\n",
      "Iteration: 8185/10000, Loss: 0.009008650667965412\n",
      "Iteration: 8186/10000, Loss: 0.00991989765316248\n",
      "Iteration: 8187/10000, Loss: 0.009613796137273312\n",
      "Iteration: 8188/10000, Loss: 0.01034755539149046\n",
      "Iteration: 8189/10000, Loss: 0.0041747186332941055\n",
      "Iteration: 8190/10000, Loss: 0.009535244666039944\n",
      "Iteration: 8191/10000, Loss: 0.007068962324410677\n",
      "Iteration: 8192/10000, Loss: 0.007656746078282595\n",
      "Iteration: 8193/10000, Loss: 0.008491486310958862\n",
      "Iteration: 8194/10000, Loss: 0.009776070713996887\n",
      "Iteration: 8195/10000, Loss: 0.010064257308840752\n",
      "Iteration: 8196/10000, Loss: 0.01343633234500885\n",
      "Iteration: 8197/10000, Loss: 0.01273711770772934\n",
      "Iteration: 8198/10000, Loss: 0.00982639379799366\n",
      "Iteration: 8199/10000, Loss: 0.009943121112883091\n",
      "Iteration: 8200/10000, Loss: 0.013151951134204865\n",
      "Average test loss:  0.0054\n",
      "Iteration: 8201/10000, Loss: 0.009335881099104881\n",
      "Iteration: 8202/10000, Loss: 0.009426283650100231\n",
      "Iteration: 8203/10000, Loss: 0.008458844386041164\n",
      "Iteration: 8204/10000, Loss: 0.006110580638051033\n",
      "Iteration: 8205/10000, Loss: 0.008028190582990646\n",
      "Iteration: 8206/10000, Loss: 0.007797640282660723\n",
      "Iteration: 8207/10000, Loss: 0.009974543005228043\n",
      "Iteration: 8208/10000, Loss: 0.008045906201004982\n",
      "Iteration: 8209/10000, Loss: 0.00740059744566679\n",
      "Iteration: 8210/10000, Loss: 0.010534176602959633\n",
      "Iteration: 8211/10000, Loss: 0.009331116452813148\n",
      "Iteration: 8212/10000, Loss: 0.00931747816503048\n",
      "Iteration: 8213/10000, Loss: 0.004055044613778591\n",
      "Iteration: 8214/10000, Loss: 0.011925246566534042\n",
      "Iteration: 8215/10000, Loss: 0.006061044055968523\n",
      "Iteration: 8216/10000, Loss: 0.011446635238826275\n",
      "Iteration: 8217/10000, Loss: 0.006399468518793583\n",
      "Iteration: 8218/10000, Loss: 0.00989102479070425\n",
      "Iteration: 8219/10000, Loss: 0.01417046133428812\n",
      "Iteration: 8220/10000, Loss: 0.00809901487082243\n",
      "Iteration: 8221/10000, Loss: 0.011777195148169994\n",
      "Iteration: 8222/10000, Loss: 0.012537757866084576\n",
      "Iteration: 8223/10000, Loss: 0.008885235525667667\n",
      "Iteration: 8224/10000, Loss: 0.00814773142337799\n",
      "Iteration: 8225/10000, Loss: 0.0077943457290530205\n",
      "Iteration: 8226/10000, Loss: 0.0085760448127985\n",
      "Iteration: 8227/10000, Loss: 0.003999906592071056\n",
      "Iteration: 8228/10000, Loss: 0.0049470034427940845\n",
      "Iteration: 8229/10000, Loss: 0.011973563581705093\n",
      "Iteration: 8230/10000, Loss: 0.009892486035823822\n",
      "Iteration: 8231/10000, Loss: 0.0112407635897398\n",
      "Iteration: 8232/10000, Loss: 0.012780068442225456\n",
      "Iteration: 8233/10000, Loss: 0.01123312022536993\n",
      "Iteration: 8234/10000, Loss: 0.009355399757623672\n",
      "Iteration: 8235/10000, Loss: 0.01062723807990551\n",
      "Iteration: 8236/10000, Loss: 0.012521503493189812\n",
      "Iteration: 8237/10000, Loss: 0.008078964427113533\n",
      "Iteration: 8238/10000, Loss: 0.009429797530174255\n",
      "Iteration: 8239/10000, Loss: 0.008981971070170403\n",
      "Iteration: 8240/10000, Loss: 0.01147698424756527\n",
      "Iteration: 8241/10000, Loss: 0.013878504745662212\n",
      "Iteration: 8242/10000, Loss: 0.013352840207517147\n",
      "Iteration: 8243/10000, Loss: 0.010323741473257542\n",
      "Iteration: 8244/10000, Loss: 0.009956080466508865\n",
      "Iteration: 8245/10000, Loss: 0.0100584477186203\n",
      "Iteration: 8246/10000, Loss: 0.009410372003912926\n",
      "Iteration: 8247/10000, Loss: 0.007678018882870674\n",
      "Iteration: 8248/10000, Loss: 0.007056615315377712\n",
      "Iteration: 8249/10000, Loss: 0.009438919834792614\n",
      "Iteration: 8250/10000, Loss: 0.010157065466046333\n",
      "Iteration: 8251/10000, Loss: 0.007174154277890921\n",
      "Iteration: 8252/10000, Loss: 0.010835204273462296\n",
      "Iteration: 8253/10000, Loss: 0.008838905021548271\n",
      "Iteration: 8254/10000, Loss: 0.011659695766866207\n",
      "Iteration: 8255/10000, Loss: 0.004740516189485788\n",
      "Iteration: 8256/10000, Loss: 0.010707154870033264\n",
      "Iteration: 8257/10000, Loss: 0.007721381727606058\n",
      "Iteration: 8258/10000, Loss: 0.009865338914096355\n",
      "Iteration: 8259/10000, Loss: 0.008392363786697388\n",
      "Iteration: 8260/10000, Loss: 0.01007482223212719\n",
      "Iteration: 8261/10000, Loss: 0.01145295798778534\n",
      "Iteration: 8262/10000, Loss: 0.005551459733396769\n",
      "Iteration: 8263/10000, Loss: 0.009816288016736507\n",
      "Iteration: 8264/10000, Loss: 0.009374722838401794\n",
      "Iteration: 8265/10000, Loss: 0.009814566932618618\n",
      "Iteration: 8266/10000, Loss: 0.00790733378380537\n",
      "Iteration: 8267/10000, Loss: 0.007827525027096272\n",
      "Iteration: 8268/10000, Loss: 0.010415945202112198\n",
      "Iteration: 8269/10000, Loss: 0.007165216840803623\n",
      "Iteration: 8270/10000, Loss: 0.008348259143531322\n",
      "Iteration: 8271/10000, Loss: 0.009515229612588882\n",
      "Iteration: 8272/10000, Loss: 0.005971113685518503\n",
      "Iteration: 8273/10000, Loss: 0.01097025629132986\n",
      "Iteration: 8274/10000, Loss: 0.009127947501838207\n",
      "Iteration: 8275/10000, Loss: 0.005948888137936592\n",
      "Iteration: 8276/10000, Loss: 0.00959992129355669\n",
      "Iteration: 8277/10000, Loss: 0.009387305937707424\n",
      "Iteration: 8278/10000, Loss: 0.010596537962555885\n",
      "Iteration: 8279/10000, Loss: 0.012658483348786831\n",
      "Iteration: 8280/10000, Loss: 0.009665872901678085\n",
      "Iteration: 8281/10000, Loss: 0.006344703491777182\n",
      "Iteration: 8282/10000, Loss: 0.00917781051248312\n",
      "Iteration: 8283/10000, Loss: 0.010477558709681034\n",
      "Iteration: 8284/10000, Loss: 0.006587174255400896\n",
      "Iteration: 8285/10000, Loss: 0.00837449636310339\n",
      "Iteration: 8286/10000, Loss: 0.010555398650467396\n",
      "Iteration: 8287/10000, Loss: 0.008973389863967896\n",
      "Iteration: 8288/10000, Loss: 0.009869234636425972\n",
      "Iteration: 8289/10000, Loss: 0.008706764318048954\n",
      "Iteration: 8290/10000, Loss: 0.004811164923012257\n",
      "Iteration: 8291/10000, Loss: 0.01104743406176567\n",
      "Iteration: 8292/10000, Loss: 0.010238262824714184\n",
      "Iteration: 8293/10000, Loss: 0.01040436141192913\n",
      "Iteration: 8294/10000, Loss: 0.010825440287590027\n",
      "Iteration: 8295/10000, Loss: 0.007925520651042461\n",
      "Iteration: 8296/10000, Loss: 0.006500594317913055\n",
      "Iteration: 8297/10000, Loss: 0.009815770201385021\n",
      "Iteration: 8298/10000, Loss: 0.004819697700440884\n",
      "Iteration: 8299/10000, Loss: 0.010352049022912979\n",
      "Iteration: 8300/10000, Loss: 0.00912930816411972\n",
      "Average test loss:  0.0025\n",
      "Iteration: 8301/10000, Loss: 0.009488247334957123\n",
      "Iteration: 8302/10000, Loss: 0.008660094812512398\n",
      "Iteration: 8303/10000, Loss: 0.010859356261789799\n",
      "Iteration: 8304/10000, Loss: 0.010652582161128521\n",
      "Iteration: 8305/10000, Loss: 0.014442384243011475\n",
      "Iteration: 8306/10000, Loss: 0.0076079401187598705\n",
      "Iteration: 8307/10000, Loss: 0.01199796050786972\n",
      "Iteration: 8308/10000, Loss: 0.00967735331505537\n",
      "Iteration: 8309/10000, Loss: 0.013195302337408066\n",
      "Iteration: 8310/10000, Loss: 0.011220831423997879\n",
      "Iteration: 8311/10000, Loss: 0.007643747143447399\n",
      "Iteration: 8312/10000, Loss: 0.008192265406250954\n",
      "Iteration: 8313/10000, Loss: 0.009012077935039997\n",
      "Iteration: 8314/10000, Loss: 0.008300243876874447\n",
      "Iteration: 8315/10000, Loss: 0.012890410609543324\n",
      "Iteration: 8316/10000, Loss: 0.006180090364068747\n",
      "Iteration: 8317/10000, Loss: 0.00558102922514081\n",
      "Iteration: 8318/10000, Loss: 0.008469962514936924\n",
      "Iteration: 8319/10000, Loss: 0.010494117625057697\n",
      "Iteration: 8320/10000, Loss: 0.008033215999603271\n",
      "Iteration: 8321/10000, Loss: 0.014705242589116096\n",
      "Iteration: 8322/10000, Loss: 0.008199582807719707\n",
      "Iteration: 8323/10000, Loss: 0.011589370667934418\n",
      "Iteration: 8324/10000, Loss: 0.007378478534519672\n",
      "Iteration: 8325/10000, Loss: 0.009065037593245506\n",
      "Iteration: 8326/10000, Loss: 0.007367713842540979\n",
      "Iteration: 8327/10000, Loss: 0.008891087025403976\n",
      "Iteration: 8328/10000, Loss: 0.006376590114086866\n",
      "Iteration: 8329/10000, Loss: 0.00887223333120346\n",
      "Iteration: 8330/10000, Loss: 0.012840356677770615\n",
      "Iteration: 8331/10000, Loss: 0.007203137967735529\n",
      "Iteration: 8332/10000, Loss: 0.010534942150115967\n",
      "Iteration: 8333/10000, Loss: 0.010138499550521374\n",
      "Iteration: 8334/10000, Loss: 0.007741513662040234\n",
      "Iteration: 8335/10000, Loss: 0.00837505143135786\n",
      "Iteration: 8336/10000, Loss: 0.007706313859671354\n",
      "Iteration: 8337/10000, Loss: 0.011484646238386631\n",
      "Iteration: 8338/10000, Loss: 0.008214986883103848\n",
      "Iteration: 8339/10000, Loss: 0.007878396660089493\n",
      "Iteration: 8340/10000, Loss: 0.011291534639894962\n",
      "Iteration: 8341/10000, Loss: 0.010229863226413727\n",
      "Iteration: 8342/10000, Loss: 0.009318189695477486\n",
      "Iteration: 8343/10000, Loss: 0.01138395443558693\n",
      "Iteration: 8344/10000, Loss: 0.006825767457485199\n",
      "Iteration: 8345/10000, Loss: 0.008345349691808224\n",
      "Iteration: 8346/10000, Loss: 0.00846110749989748\n",
      "Iteration: 8347/10000, Loss: 0.008258790709078312\n",
      "Iteration: 8348/10000, Loss: 0.0061846282333135605\n",
      "Iteration: 8349/10000, Loss: 0.015748608857393265\n",
      "Iteration: 8350/10000, Loss: 0.011787908151745796\n",
      "Iteration: 8351/10000, Loss: 0.009902658872306347\n",
      "Iteration: 8352/10000, Loss: 0.010099508799612522\n",
      "Iteration: 8353/10000, Loss: 0.008129943162202835\n",
      "Iteration: 8354/10000, Loss: 0.005651924293488264\n",
      "Iteration: 8355/10000, Loss: 0.011613717302680016\n",
      "Iteration: 8356/10000, Loss: 0.015306217595934868\n",
      "Iteration: 8357/10000, Loss: 0.004675863776355982\n",
      "Iteration: 8358/10000, Loss: 0.007131215184926987\n",
      "Iteration: 8359/10000, Loss: 0.014259064570069313\n",
      "Iteration: 8360/10000, Loss: 0.009056375361979008\n",
      "Iteration: 8361/10000, Loss: 0.004292014054954052\n",
      "Iteration: 8362/10000, Loss: 0.010027110576629639\n",
      "Iteration: 8363/10000, Loss: 0.01246415264904499\n",
      "Iteration: 8364/10000, Loss: 0.009660358540713787\n",
      "Iteration: 8365/10000, Loss: 0.009375613182783127\n",
      "Iteration: 8366/10000, Loss: 0.009419015608727932\n",
      "Iteration: 8367/10000, Loss: 0.010672472417354584\n",
      "Iteration: 8368/10000, Loss: 0.006631296593695879\n",
      "Iteration: 8369/10000, Loss: 0.007231643423438072\n",
      "Iteration: 8370/10000, Loss: 0.008405771106481552\n",
      "Iteration: 8371/10000, Loss: 0.012515480630099773\n",
      "Iteration: 8372/10000, Loss: 0.008613660000264645\n",
      "Iteration: 8373/10000, Loss: 0.00609382800757885\n",
      "Iteration: 8374/10000, Loss: 0.00699082063511014\n",
      "Iteration: 8375/10000, Loss: 0.017169620841741562\n",
      "Iteration: 8376/10000, Loss: 0.01380874402821064\n",
      "Iteration: 8377/10000, Loss: 0.011985869146883488\n",
      "Iteration: 8378/10000, Loss: 0.007602853700518608\n",
      "Iteration: 8379/10000, Loss: 0.009012999013066292\n",
      "Iteration: 8380/10000, Loss: 0.009208964183926582\n",
      "Iteration: 8381/10000, Loss: 0.009931754320859909\n",
      "Iteration: 8382/10000, Loss: 0.010591905564069748\n",
      "Iteration: 8383/10000, Loss: 0.00696531543508172\n",
      "Iteration: 8384/10000, Loss: 0.007524410728365183\n",
      "Iteration: 8385/10000, Loss: 0.004680863581597805\n",
      "Iteration: 8386/10000, Loss: 0.008082284592092037\n",
      "Iteration: 8387/10000, Loss: 0.012322026304900646\n",
      "Iteration: 8388/10000, Loss: 0.007651946507394314\n",
      "Iteration: 8389/10000, Loss: 0.007819827646017075\n",
      "Iteration: 8390/10000, Loss: 0.007497960235923529\n",
      "Iteration: 8391/10000, Loss: 0.01289010513573885\n",
      "Iteration: 8392/10000, Loss: 0.007552025374025106\n",
      "Iteration: 8393/10000, Loss: 0.007430338300764561\n",
      "Iteration: 8394/10000, Loss: 0.008624996989965439\n",
      "Iteration: 8395/10000, Loss: 0.008994856849312782\n",
      "Iteration: 8396/10000, Loss: 0.007480556610971689\n",
      "Iteration: 8397/10000, Loss: 0.010325483046472073\n",
      "Iteration: 8398/10000, Loss: 0.009284000843763351\n",
      "Iteration: 8399/10000, Loss: 0.00875059887766838\n",
      "Iteration: 8400/10000, Loss: 0.006326592061668634\n",
      "Average test loss:  0.0033\n",
      "Iteration: 8401/10000, Loss: 0.01468641683459282\n",
      "Iteration: 8402/10000, Loss: 0.009840302169322968\n",
      "Iteration: 8403/10000, Loss: 0.008283167146146297\n",
      "Iteration: 8404/10000, Loss: 0.0116217490285635\n",
      "Iteration: 8405/10000, Loss: 0.015126161277294159\n",
      "Iteration: 8406/10000, Loss: 0.011120621114969254\n",
      "Iteration: 8407/10000, Loss: 0.009029433131217957\n",
      "Iteration: 8408/10000, Loss: 0.009048577398061752\n",
      "Iteration: 8409/10000, Loss: 0.0110049769282341\n",
      "Iteration: 8410/10000, Loss: 0.007047146558761597\n",
      "Iteration: 8411/10000, Loss: 0.0061850594356656075\n",
      "Iteration: 8412/10000, Loss: 0.011228177696466446\n",
      "Iteration: 8413/10000, Loss: 0.010262920521199703\n",
      "Iteration: 8414/10000, Loss: 0.007436695508658886\n",
      "Iteration: 8415/10000, Loss: 0.00834102276712656\n",
      "Iteration: 8416/10000, Loss: 0.009960105642676353\n",
      "Iteration: 8417/10000, Loss: 0.011174063198268414\n",
      "Iteration: 8418/10000, Loss: 0.00892131868749857\n",
      "Iteration: 8419/10000, Loss: 0.004978576209396124\n",
      "Iteration: 8420/10000, Loss: 0.013202974572777748\n",
      "Iteration: 8421/10000, Loss: 0.009436038322746754\n",
      "Iteration: 8422/10000, Loss: 0.009111370891332626\n",
      "Iteration: 8423/10000, Loss: 0.008417539298534393\n",
      "Iteration: 8424/10000, Loss: 0.008511136285960674\n",
      "Iteration: 8425/10000, Loss: 0.009280039928853512\n",
      "Iteration: 8426/10000, Loss: 0.008489013649523258\n",
      "Iteration: 8427/10000, Loss: 0.008909416384994984\n",
      "Iteration: 8428/10000, Loss: 0.01431914884597063\n",
      "Iteration: 8429/10000, Loss: 0.011257180944085121\n",
      "Iteration: 8430/10000, Loss: 0.010937119834125042\n",
      "Iteration: 8431/10000, Loss: 0.011660266667604446\n",
      "Iteration: 8432/10000, Loss: 0.00975846778601408\n",
      "Iteration: 8433/10000, Loss: 0.007385474629700184\n",
      "Iteration: 8434/10000, Loss: 0.009322979487478733\n",
      "Iteration: 8435/10000, Loss: 0.011426791548728943\n",
      "Iteration: 8436/10000, Loss: 0.009434763342142105\n",
      "Iteration: 8437/10000, Loss: 0.008666959591209888\n",
      "Iteration: 8438/10000, Loss: 0.010567759163677692\n",
      "Iteration: 8439/10000, Loss: 0.006721949204802513\n",
      "Iteration: 8440/10000, Loss: 0.01040471252053976\n",
      "Iteration: 8441/10000, Loss: 0.00735822506248951\n",
      "Iteration: 8442/10000, Loss: 0.010087423957884312\n",
      "Iteration: 8443/10000, Loss: 0.00700073828920722\n",
      "Iteration: 8444/10000, Loss: 0.011863979510962963\n",
      "Iteration: 8445/10000, Loss: 0.010195322334766388\n",
      "Iteration: 8446/10000, Loss: 0.011453293263912201\n",
      "Iteration: 8447/10000, Loss: 0.011073495261371136\n",
      "Iteration: 8448/10000, Loss: 0.009084222838282585\n",
      "Iteration: 8449/10000, Loss: 0.009883045218884945\n",
      "Iteration: 8450/10000, Loss: 0.011547887697815895\n",
      "Iteration: 8451/10000, Loss: 0.010121035389602184\n",
      "Iteration: 8452/10000, Loss: 0.009008771739900112\n",
      "Iteration: 8453/10000, Loss: 0.012109470553696156\n",
      "Iteration: 8454/10000, Loss: 0.008827345445752144\n",
      "Iteration: 8455/10000, Loss: 0.00849344115704298\n",
      "Iteration: 8456/10000, Loss: 0.01072362158447504\n",
      "Iteration: 8457/10000, Loss: 0.011501582339406013\n",
      "Iteration: 8458/10000, Loss: 0.010312722064554691\n",
      "Iteration: 8459/10000, Loss: 0.010413880459964275\n",
      "Iteration: 8460/10000, Loss: 0.005772972945123911\n",
      "Iteration: 8461/10000, Loss: 0.012542806565761566\n",
      "Iteration: 8462/10000, Loss: 0.007329254876822233\n",
      "Iteration: 8463/10000, Loss: 0.010052813217043877\n",
      "Iteration: 8464/10000, Loss: 0.011661109514534473\n",
      "Iteration: 8465/10000, Loss: 0.010615892708301544\n",
      "Iteration: 8466/10000, Loss: 0.00987289659678936\n",
      "Iteration: 8467/10000, Loss: 0.006377308629453182\n",
      "Iteration: 8468/10000, Loss: 0.010607290081679821\n",
      "Iteration: 8469/10000, Loss: 0.009296686388552189\n",
      "Iteration: 8470/10000, Loss: 0.00722816726192832\n",
      "Iteration: 8471/10000, Loss: 0.007808077149093151\n",
      "Iteration: 8472/10000, Loss: 0.009071458131074905\n",
      "Iteration: 8473/10000, Loss: 0.008263375610113144\n",
      "Iteration: 8474/10000, Loss: 0.01182999461889267\n",
      "Iteration: 8475/10000, Loss: 0.008291568607091904\n",
      "Iteration: 8476/10000, Loss: 0.00762541126459837\n",
      "Iteration: 8477/10000, Loss: 0.007444540970027447\n",
      "Iteration: 8478/10000, Loss: 0.008369640447199345\n",
      "Iteration: 8479/10000, Loss: 0.010456658899784088\n",
      "Iteration: 8480/10000, Loss: 0.012487336061894894\n",
      "Iteration: 8481/10000, Loss: 0.009922959841787815\n",
      "Iteration: 8482/10000, Loss: 0.006004647351801395\n",
      "Iteration: 8483/10000, Loss: 0.011976304464042187\n",
      "Iteration: 8484/10000, Loss: 0.0057305870577692986\n",
      "Iteration: 8485/10000, Loss: 0.01448200736194849\n",
      "Iteration: 8486/10000, Loss: 0.010656585916876793\n",
      "Iteration: 8487/10000, Loss: 0.007061381824314594\n",
      "Iteration: 8488/10000, Loss: 0.009679517708718777\n",
      "Iteration: 8489/10000, Loss: 0.007453941740095615\n",
      "Iteration: 8490/10000, Loss: 0.012102718465030193\n",
      "Iteration: 8491/10000, Loss: 0.012696840800344944\n",
      "Iteration: 8492/10000, Loss: 0.006165617145597935\n",
      "Iteration: 8493/10000, Loss: 0.007644222117960453\n",
      "Iteration: 8494/10000, Loss: 0.004856971558183432\n",
      "Iteration: 8495/10000, Loss: 0.005048047285526991\n",
      "Iteration: 8496/10000, Loss: 0.00904911756515503\n",
      "Iteration: 8497/10000, Loss: 0.004503380972892046\n",
      "Iteration: 8498/10000, Loss: 0.006067266687750816\n",
      "Iteration: 8499/10000, Loss: 0.008760293014347553\n",
      "Iteration: 8500/10000, Loss: 0.010833047330379486\n",
      "Average test loss:  0.0048\n",
      "Iteration: 8501/10000, Loss: 0.0071709961630403996\n",
      "Iteration: 8502/10000, Loss: 0.008955209515988827\n",
      "Iteration: 8503/10000, Loss: 0.01012467872351408\n",
      "Iteration: 8504/10000, Loss: 0.009091013111174107\n",
      "Iteration: 8505/10000, Loss: 0.011524111032485962\n",
      "Iteration: 8506/10000, Loss: 0.010303623043000698\n",
      "Iteration: 8507/10000, Loss: 0.008463076315820217\n",
      "Iteration: 8508/10000, Loss: 0.012947391718626022\n",
      "Iteration: 8509/10000, Loss: 0.008273115381598473\n",
      "Iteration: 8510/10000, Loss: 0.007879656739532948\n",
      "Iteration: 8511/10000, Loss: 0.010587293654680252\n",
      "Iteration: 8512/10000, Loss: 0.009069188497960567\n",
      "Iteration: 8513/10000, Loss: 0.006894916761666536\n",
      "Iteration: 8514/10000, Loss: 0.013305239379405975\n",
      "Iteration: 8515/10000, Loss: 0.007652448024600744\n",
      "Iteration: 8516/10000, Loss: 0.010677521117031574\n",
      "Iteration: 8517/10000, Loss: 0.006981660611927509\n",
      "Iteration: 8518/10000, Loss: 0.004570978693664074\n",
      "Iteration: 8519/10000, Loss: 0.01153603382408619\n",
      "Iteration: 8520/10000, Loss: 0.010285339318215847\n",
      "Iteration: 8521/10000, Loss: 0.009610882960259914\n",
      "Iteration: 8522/10000, Loss: 0.007611144799739122\n",
      "Iteration: 8523/10000, Loss: 0.012043573893606663\n",
      "Iteration: 8524/10000, Loss: 0.011171145364642143\n",
      "Iteration: 8525/10000, Loss: 0.008102212101221085\n",
      "Iteration: 8526/10000, Loss: 0.016059285029768944\n",
      "Iteration: 8527/10000, Loss: 0.007562230806797743\n",
      "Iteration: 8528/10000, Loss: 0.009935884736478329\n",
      "Iteration: 8529/10000, Loss: 0.00689581548795104\n",
      "Iteration: 8530/10000, Loss: 0.013278583995997906\n",
      "Iteration: 8531/10000, Loss: 0.018543478101491928\n",
      "Iteration: 8532/10000, Loss: 0.007486021611839533\n",
      "Iteration: 8533/10000, Loss: 0.010712684132158756\n",
      "Iteration: 8534/10000, Loss: 0.009930050000548363\n",
      "Iteration: 8535/10000, Loss: 0.016496144235134125\n",
      "Iteration: 8536/10000, Loss: 0.010450102388858795\n",
      "Iteration: 8537/10000, Loss: 0.009328512474894524\n",
      "Iteration: 8538/10000, Loss: 0.00777443777769804\n",
      "Iteration: 8539/10000, Loss: 0.007262764032930136\n",
      "Iteration: 8540/10000, Loss: 0.009542287327349186\n",
      "Iteration: 8541/10000, Loss: 0.009794062934815884\n",
      "Iteration: 8542/10000, Loss: 0.00864514708518982\n",
      "Iteration: 8543/10000, Loss: 0.011954331770539284\n",
      "Iteration: 8544/10000, Loss: 0.009532672353088856\n",
      "Iteration: 8545/10000, Loss: 0.005428237374871969\n",
      "Iteration: 8546/10000, Loss: 0.009841421619057655\n",
      "Iteration: 8547/10000, Loss: 0.011992708779871464\n",
      "Iteration: 8548/10000, Loss: 0.005705301649868488\n",
      "Iteration: 8549/10000, Loss: 0.008090316317975521\n",
      "Iteration: 8550/10000, Loss: 0.013050315901637077\n",
      "Iteration: 8551/10000, Loss: 0.005945485085248947\n",
      "Iteration: 8552/10000, Loss: 0.010075573809444904\n",
      "Iteration: 8553/10000, Loss: 0.010714047588407993\n",
      "Iteration: 8554/10000, Loss: 0.008647637441754341\n",
      "Iteration: 8555/10000, Loss: 0.0135141396895051\n",
      "Iteration: 8556/10000, Loss: 0.007475351449102163\n",
      "Iteration: 8557/10000, Loss: 0.006469956133514643\n",
      "Iteration: 8558/10000, Loss: 0.01183517836034298\n",
      "Iteration: 8559/10000, Loss: 0.011243432760238647\n",
      "Iteration: 8560/10000, Loss: 0.007419041357934475\n",
      "Iteration: 8561/10000, Loss: 0.008519325405359268\n",
      "Iteration: 8562/10000, Loss: 0.00851802434772253\n",
      "Iteration: 8563/10000, Loss: 0.005561779253184795\n",
      "Iteration: 8564/10000, Loss: 0.007232713047415018\n",
      "Iteration: 8565/10000, Loss: 0.012465134263038635\n",
      "Iteration: 8566/10000, Loss: 0.011206697672605515\n",
      "Iteration: 8567/10000, Loss: 0.0065007745288312435\n",
      "Iteration: 8568/10000, Loss: 0.01298883929848671\n",
      "Iteration: 8569/10000, Loss: 0.00832319539040327\n",
      "Iteration: 8570/10000, Loss: 0.0075911651365458965\n",
      "Iteration: 8571/10000, Loss: 0.006422801874577999\n",
      "Iteration: 8572/10000, Loss: 0.008931989781558514\n",
      "Iteration: 8573/10000, Loss: 0.009455992840230465\n",
      "Iteration: 8574/10000, Loss: 0.00979944784194231\n",
      "Iteration: 8575/10000, Loss: 0.011566833592951298\n",
      "Iteration: 8576/10000, Loss: 0.010439543053507805\n",
      "Iteration: 8577/10000, Loss: 0.00946734007447958\n",
      "Iteration: 8578/10000, Loss: 0.008038398809731007\n",
      "Iteration: 8579/10000, Loss: 0.007759789936244488\n",
      "Iteration: 8580/10000, Loss: 0.006784383673220873\n",
      "Iteration: 8581/10000, Loss: 0.007417791988700628\n",
      "Iteration: 8582/10000, Loss: 0.011421012692153454\n",
      "Iteration: 8583/10000, Loss: 0.009936830960214138\n",
      "Iteration: 8584/10000, Loss: 0.012078722007572651\n",
      "Iteration: 8585/10000, Loss: 0.01380583643913269\n",
      "Iteration: 8586/10000, Loss: 0.009629650972783566\n",
      "Iteration: 8587/10000, Loss: 0.009443921037018299\n",
      "Iteration: 8588/10000, Loss: 0.010750208981335163\n",
      "Iteration: 8589/10000, Loss: 0.009234318509697914\n",
      "Iteration: 8590/10000, Loss: 0.009013292379677296\n",
      "Iteration: 8591/10000, Loss: 0.006957583595067263\n",
      "Iteration: 8592/10000, Loss: 0.01099632028490305\n",
      "Iteration: 8593/10000, Loss: 0.008185242302715778\n",
      "Iteration: 8594/10000, Loss: 0.013682550750672817\n",
      "Iteration: 8595/10000, Loss: 0.008168008178472519\n",
      "Iteration: 8596/10000, Loss: 0.012190320529043674\n",
      "Iteration: 8597/10000, Loss: 0.01188324298709631\n",
      "Iteration: 8598/10000, Loss: 0.009889010339975357\n",
      "Iteration: 8599/10000, Loss: 0.007172176148742437\n",
      "Iteration: 8600/10000, Loss: 0.0123505974188447\n",
      "Average test loss:  0.0030\n",
      "Iteration: 8601/10000, Loss: 0.008934133686125278\n",
      "Iteration: 8602/10000, Loss: 0.012817718088626862\n",
      "Iteration: 8603/10000, Loss: 0.007769387681037188\n",
      "Iteration: 8604/10000, Loss: 0.00838338304311037\n",
      "Iteration: 8605/10000, Loss: 0.009771853685379028\n",
      "Iteration: 8606/10000, Loss: 0.006940384395420551\n",
      "Iteration: 8607/10000, Loss: 0.00912602711468935\n",
      "Iteration: 8608/10000, Loss: 0.011269904673099518\n",
      "Iteration: 8609/10000, Loss: 0.005493469070643187\n",
      "Iteration: 8610/10000, Loss: 0.009711600840091705\n",
      "Iteration: 8611/10000, Loss: 0.014810318127274513\n",
      "Iteration: 8612/10000, Loss: 0.011151526123285294\n",
      "Iteration: 8613/10000, Loss: 0.007126441225409508\n",
      "Iteration: 8614/10000, Loss: 0.007572670001536608\n",
      "Iteration: 8615/10000, Loss: 0.007611550390720367\n",
      "Iteration: 8616/10000, Loss: 0.007468922529369593\n",
      "Iteration: 8617/10000, Loss: 0.006145135965198278\n",
      "Iteration: 8618/10000, Loss: 0.006269535049796104\n",
      "Iteration: 8619/10000, Loss: 0.0067080059088766575\n",
      "Iteration: 8620/10000, Loss: 0.007089580874890089\n",
      "Iteration: 8621/10000, Loss: 0.009979188442230225\n",
      "Iteration: 8622/10000, Loss: 0.0071168686263263226\n",
      "Iteration: 8623/10000, Loss: 0.00723678944632411\n",
      "Iteration: 8624/10000, Loss: 0.009110543876886368\n",
      "Iteration: 8625/10000, Loss: 0.0076118940487504005\n",
      "Iteration: 8626/10000, Loss: 0.016348881646990776\n",
      "Iteration: 8627/10000, Loss: 0.010669423267245293\n",
      "Iteration: 8628/10000, Loss: 0.010089659132063389\n",
      "Iteration: 8629/10000, Loss: 0.009593833237886429\n",
      "Iteration: 8630/10000, Loss: 0.0074527268297970295\n",
      "Iteration: 8631/10000, Loss: 0.009456714615225792\n",
      "Iteration: 8632/10000, Loss: 0.006800801493227482\n",
      "Iteration: 8633/10000, Loss: 0.010748102329671383\n",
      "Iteration: 8634/10000, Loss: 0.004122199025005102\n",
      "Iteration: 8635/10000, Loss: 0.010920588858425617\n",
      "Iteration: 8636/10000, Loss: 0.013963836245238781\n",
      "Iteration: 8637/10000, Loss: 0.013180214911699295\n",
      "Iteration: 8638/10000, Loss: 0.009336109273135662\n",
      "Iteration: 8639/10000, Loss: 0.008617931045591831\n",
      "Iteration: 8640/10000, Loss: 0.008319155313074589\n",
      "Iteration: 8641/10000, Loss: 0.013888244517147541\n",
      "Iteration: 8642/10000, Loss: 0.011877927929162979\n",
      "Iteration: 8643/10000, Loss: 0.00791558250784874\n",
      "Iteration: 8644/10000, Loss: 0.0073030972853302956\n",
      "Iteration: 8645/10000, Loss: 0.010378136299550533\n",
      "Iteration: 8646/10000, Loss: 0.0048510245978832245\n",
      "Iteration: 8647/10000, Loss: 0.009377173148095608\n",
      "Iteration: 8648/10000, Loss: 0.00791215430945158\n",
      "Iteration: 8649/10000, Loss: 0.0090076494961977\n",
      "Iteration: 8650/10000, Loss: 0.009550366550683975\n",
      "Iteration: 8651/10000, Loss: 0.012511523440480232\n",
      "Iteration: 8652/10000, Loss: 0.007262285333126783\n",
      "Iteration: 8653/10000, Loss: 0.010736856609582901\n",
      "Iteration: 8654/10000, Loss: 0.011634496040642262\n",
      "Iteration: 8655/10000, Loss: 0.007326018530875444\n",
      "Iteration: 8656/10000, Loss: 0.009409068152308464\n",
      "Iteration: 8657/10000, Loss: 0.007604676298797131\n",
      "Iteration: 8658/10000, Loss: 0.010816679336130619\n",
      "Iteration: 8659/10000, Loss: 0.007730857934802771\n",
      "Iteration: 8660/10000, Loss: 0.010316159576177597\n",
      "Iteration: 8661/10000, Loss: 0.009602291509509087\n",
      "Iteration: 8662/10000, Loss: 0.009045026265084743\n",
      "Iteration: 8663/10000, Loss: 0.01053836103528738\n",
      "Iteration: 8664/10000, Loss: 0.009450072422623634\n",
      "Iteration: 8665/10000, Loss: 0.007302933372557163\n",
      "Iteration: 8666/10000, Loss: 0.008782768622040749\n",
      "Iteration: 8667/10000, Loss: 0.006188195198774338\n",
      "Iteration: 8668/10000, Loss: 0.0076898243278265\n",
      "Iteration: 8669/10000, Loss: 0.009592130780220032\n",
      "Iteration: 8670/10000, Loss: 0.009152981452643871\n",
      "Iteration: 8671/10000, Loss: 0.01588262803852558\n",
      "Iteration: 8672/10000, Loss: 0.012081672437489033\n",
      "Iteration: 8673/10000, Loss: 0.007996570318937302\n",
      "Iteration: 8674/10000, Loss: 0.010119364596903324\n",
      "Iteration: 8675/10000, Loss: 0.005400138441473246\n",
      "Iteration: 8676/10000, Loss: 0.007597459480166435\n",
      "Iteration: 8677/10000, Loss: 0.010816266760230064\n",
      "Iteration: 8678/10000, Loss: 0.008337303064763546\n",
      "Iteration: 8679/10000, Loss: 0.012493117712438107\n",
      "Iteration: 8680/10000, Loss: 0.0067695025354623795\n",
      "Iteration: 8681/10000, Loss: 0.008924063295125961\n",
      "Iteration: 8682/10000, Loss: 0.011680297553539276\n",
      "Iteration: 8683/10000, Loss: 0.006788245402276516\n",
      "Iteration: 8684/10000, Loss: 0.011288409121334553\n",
      "Iteration: 8685/10000, Loss: 0.008752831257879734\n",
      "Iteration: 8686/10000, Loss: 0.007715148385614157\n",
      "Iteration: 8687/10000, Loss: 0.009970670565962791\n",
      "Iteration: 8688/10000, Loss: 0.009003853425383568\n",
      "Iteration: 8689/10000, Loss: 0.01034204289317131\n",
      "Iteration: 8690/10000, Loss: 0.010800797492265701\n",
      "Iteration: 8691/10000, Loss: 0.009800887666642666\n",
      "Iteration: 8692/10000, Loss: 0.010579963214695454\n",
      "Iteration: 8693/10000, Loss: 0.011638196185231209\n",
      "Iteration: 8694/10000, Loss: 0.00770395016297698\n",
      "Iteration: 8695/10000, Loss: 0.007522864267230034\n",
      "Iteration: 8696/10000, Loss: 0.013939829543232918\n",
      "Iteration: 8697/10000, Loss: 0.009385778568685055\n",
      "Iteration: 8698/10000, Loss: 0.006995032541453838\n",
      "Iteration: 8699/10000, Loss: 0.007902083918452263\n",
      "Iteration: 8700/10000, Loss: 0.01515902578830719\n",
      "Average test loss:  0.0046\n",
      "Iteration: 8701/10000, Loss: 0.014619080349802971\n",
      "Iteration: 8702/10000, Loss: 0.006588637363165617\n",
      "Iteration: 8703/10000, Loss: 0.010750059969723225\n",
      "Iteration: 8704/10000, Loss: 0.009249180555343628\n",
      "Iteration: 8705/10000, Loss: 0.010007444769144058\n",
      "Iteration: 8706/10000, Loss: 0.004856771323829889\n",
      "Iteration: 8707/10000, Loss: 0.00676075741648674\n",
      "Iteration: 8708/10000, Loss: 0.006607216317206621\n",
      "Iteration: 8709/10000, Loss: 0.014270841144025326\n",
      "Iteration: 8710/10000, Loss: 0.012376721948385239\n",
      "Iteration: 8711/10000, Loss: 0.0076213679276406765\n",
      "Iteration: 8712/10000, Loss: 0.012625926174223423\n",
      "Iteration: 8713/10000, Loss: 0.010467358864843845\n",
      "Iteration: 8714/10000, Loss: 0.006800831761211157\n",
      "Iteration: 8715/10000, Loss: 0.011994710192084312\n",
      "Iteration: 8716/10000, Loss: 0.007449456490576267\n",
      "Iteration: 8717/10000, Loss: 0.01012936607003212\n",
      "Iteration: 8718/10000, Loss: 0.008614206686615944\n",
      "Iteration: 8719/10000, Loss: 0.00575354415923357\n",
      "Iteration: 8720/10000, Loss: 0.010754621587693691\n",
      "Iteration: 8721/10000, Loss: 0.008328378200531006\n",
      "Iteration: 8722/10000, Loss: 0.00637006526812911\n",
      "Iteration: 8723/10000, Loss: 0.010674240067601204\n",
      "Iteration: 8724/10000, Loss: 0.007826744578778744\n",
      "Iteration: 8725/10000, Loss: 0.010072884149849415\n",
      "Iteration: 8726/10000, Loss: 0.007306690327823162\n",
      "Iteration: 8727/10000, Loss: 0.008785259909927845\n",
      "Iteration: 8728/10000, Loss: 0.007194644305855036\n",
      "Iteration: 8729/10000, Loss: 0.005357127636671066\n",
      "Iteration: 8730/10000, Loss: 0.010650640353560448\n",
      "Iteration: 8731/10000, Loss: 0.013079733587801456\n",
      "Iteration: 8732/10000, Loss: 0.009316463023424149\n",
      "Iteration: 8733/10000, Loss: 0.01147281564772129\n",
      "Iteration: 8734/10000, Loss: 0.011520269326865673\n",
      "Iteration: 8735/10000, Loss: 0.008833653293550014\n",
      "Iteration: 8736/10000, Loss: 0.007114383392035961\n",
      "Iteration: 8737/10000, Loss: 0.010461450554430485\n",
      "Iteration: 8738/10000, Loss: 0.009465770795941353\n",
      "Iteration: 8739/10000, Loss: 0.009316912852227688\n",
      "Iteration: 8740/10000, Loss: 0.009178387001156807\n",
      "Iteration: 8741/10000, Loss: 0.009587697684764862\n",
      "Iteration: 8742/10000, Loss: 0.0076525090262293816\n",
      "Iteration: 8743/10000, Loss: 0.006939582992345095\n",
      "Iteration: 8744/10000, Loss: 0.011755427345633507\n",
      "Iteration: 8745/10000, Loss: 0.0056897434405982494\n",
      "Iteration: 8746/10000, Loss: 0.00829406175762415\n",
      "Iteration: 8747/10000, Loss: 0.009359821677207947\n",
      "Iteration: 8748/10000, Loss: 0.005132670048624277\n",
      "Iteration: 8749/10000, Loss: 0.009612654335796833\n",
      "Iteration: 8750/10000, Loss: 0.008453939110040665\n",
      "Iteration: 8751/10000, Loss: 0.007970742881298065\n",
      "Iteration: 8752/10000, Loss: 0.007986812852323055\n",
      "Iteration: 8753/10000, Loss: 0.005716605111956596\n",
      "Iteration: 8754/10000, Loss: 0.008353100158274174\n",
      "Iteration: 8755/10000, Loss: 0.00907468143850565\n",
      "Iteration: 8756/10000, Loss: 0.008792301639914513\n",
      "Iteration: 8757/10000, Loss: 0.010172712616622448\n",
      "Iteration: 8758/10000, Loss: 0.008482685312628746\n",
      "Iteration: 8759/10000, Loss: 0.010664603672921658\n",
      "Iteration: 8760/10000, Loss: 0.011051055043935776\n",
      "Iteration: 8761/10000, Loss: 0.00605679489672184\n",
      "Iteration: 8762/10000, Loss: 0.004891643300652504\n",
      "Iteration: 8763/10000, Loss: 0.008932135067880154\n",
      "Iteration: 8764/10000, Loss: 0.00832158699631691\n",
      "Iteration: 8765/10000, Loss: 0.009616103954613209\n",
      "Iteration: 8766/10000, Loss: 0.00416395952925086\n",
      "Iteration: 8767/10000, Loss: 0.009406904689967632\n",
      "Iteration: 8768/10000, Loss: 0.007708020508289337\n",
      "Iteration: 8769/10000, Loss: 0.011292141862213612\n",
      "Iteration: 8770/10000, Loss: 0.011671517044305801\n",
      "Iteration: 8771/10000, Loss: 0.007705403491854668\n",
      "Iteration: 8772/10000, Loss: 0.00963583867996931\n",
      "Iteration: 8773/10000, Loss: 0.007788222748786211\n",
      "Iteration: 8774/10000, Loss: 0.008723648265004158\n",
      "Iteration: 8775/10000, Loss: 0.008366231806576252\n",
      "Iteration: 8776/10000, Loss: 0.006180550903081894\n",
      "Iteration: 8777/10000, Loss: 0.008678577840328217\n",
      "Iteration: 8778/10000, Loss: 0.004876910243183374\n",
      "Iteration: 8779/10000, Loss: 0.007093549706041813\n",
      "Iteration: 8780/10000, Loss: 0.009309367276728153\n",
      "Iteration: 8781/10000, Loss: 0.011536143720149994\n",
      "Iteration: 8782/10000, Loss: 0.006313081830739975\n",
      "Iteration: 8783/10000, Loss: 0.004420480690896511\n",
      "Iteration: 8784/10000, Loss: 0.013572970405220985\n",
      "Iteration: 8785/10000, Loss: 0.008955721743404865\n",
      "Iteration: 8786/10000, Loss: 0.010651406832039356\n",
      "Iteration: 8787/10000, Loss: 0.013439786620438099\n",
      "Iteration: 8788/10000, Loss: 0.006579400505870581\n",
      "Iteration: 8789/10000, Loss: 0.009425253607332706\n",
      "Iteration: 8790/10000, Loss: 0.012347307987511158\n",
      "Iteration: 8791/10000, Loss: 0.012188352644443512\n",
      "Iteration: 8792/10000, Loss: 0.008764194324612617\n",
      "Iteration: 8793/10000, Loss: 0.0045439815148711205\n",
      "Iteration: 8794/10000, Loss: 0.007851150818169117\n",
      "Iteration: 8795/10000, Loss: 0.010315090417861938\n",
      "Iteration: 8796/10000, Loss: 0.011647850275039673\n",
      "Iteration: 8797/10000, Loss: 0.007049251347780228\n",
      "Iteration: 8798/10000, Loss: 0.007885399274528027\n",
      "Iteration: 8799/10000, Loss: 0.0070584919303655624\n",
      "Iteration: 8800/10000, Loss: 0.007389135658740997\n",
      "Average test loss:  0.0049\n",
      "Iteration: 8801/10000, Loss: 0.00920938141644001\n",
      "Iteration: 8802/10000, Loss: 0.006567433010786772\n",
      "Iteration: 8803/10000, Loss: 0.005591066554188728\n",
      "Iteration: 8804/10000, Loss: 0.0073729148134589195\n",
      "Iteration: 8805/10000, Loss: 0.00875951535999775\n",
      "Iteration: 8806/10000, Loss: 0.008464873768389225\n",
      "Iteration: 8807/10000, Loss: 0.010571062564849854\n",
      "Iteration: 8808/10000, Loss: 0.00885844323784113\n",
      "Iteration: 8809/10000, Loss: 0.0063712699338793755\n",
      "Iteration: 8810/10000, Loss: 0.011602966114878654\n",
      "Iteration: 8811/10000, Loss: 0.0089435875415802\n",
      "Iteration: 8812/10000, Loss: 0.009671139530837536\n",
      "Iteration: 8813/10000, Loss: 0.009442847222089767\n",
      "Iteration: 8814/10000, Loss: 0.00919811800122261\n",
      "Iteration: 8815/10000, Loss: 0.007806171663105488\n",
      "Iteration: 8816/10000, Loss: 0.010765458457171917\n",
      "Iteration: 8817/10000, Loss: 0.012567595578730106\n",
      "Iteration: 8818/10000, Loss: 0.008195782080292702\n",
      "Iteration: 8819/10000, Loss: 0.010592932812869549\n",
      "Iteration: 8820/10000, Loss: 0.007418956141918898\n",
      "Iteration: 8821/10000, Loss: 0.007608694024384022\n",
      "Iteration: 8822/10000, Loss: 0.0078104352578520775\n",
      "Iteration: 8823/10000, Loss: 0.00865199789404869\n",
      "Iteration: 8824/10000, Loss: 0.008752687834203243\n",
      "Iteration: 8825/10000, Loss: 0.0090117072686553\n",
      "Iteration: 8826/10000, Loss: 0.006152857095003128\n",
      "Iteration: 8827/10000, Loss: 0.007233847863972187\n",
      "Iteration: 8828/10000, Loss: 0.00751911848783493\n",
      "Iteration: 8829/10000, Loss: 0.012202635407447815\n",
      "Iteration: 8830/10000, Loss: 0.007685927674174309\n",
      "Iteration: 8831/10000, Loss: 0.012506645172834396\n",
      "Iteration: 8832/10000, Loss: 0.010664146393537521\n",
      "Iteration: 8833/10000, Loss: 0.0074234530329704285\n",
      "Iteration: 8834/10000, Loss: 0.009235289879143238\n",
      "Iteration: 8835/10000, Loss: 0.00863840151578188\n",
      "Iteration: 8836/10000, Loss: 0.009981744922697544\n",
      "Iteration: 8837/10000, Loss: 0.0055201430805027485\n",
      "Iteration: 8838/10000, Loss: 0.011591032147407532\n",
      "Iteration: 8839/10000, Loss: 0.009857377037405968\n",
      "Iteration: 8840/10000, Loss: 0.008844761177897453\n",
      "Iteration: 8841/10000, Loss: 0.0077984025701880455\n",
      "Iteration: 8842/10000, Loss: 0.007765516173094511\n",
      "Iteration: 8843/10000, Loss: 0.007455187849700451\n",
      "Iteration: 8844/10000, Loss: 0.01372282300144434\n",
      "Iteration: 8845/10000, Loss: 0.014324487186968327\n",
      "Iteration: 8846/10000, Loss: 0.006923206150531769\n",
      "Iteration: 8847/10000, Loss: 0.01193485502153635\n",
      "Iteration: 8848/10000, Loss: 0.006725540850311518\n",
      "Iteration: 8849/10000, Loss: 0.011915802024304867\n",
      "Iteration: 8850/10000, Loss: 0.01080047432333231\n",
      "Iteration: 8851/10000, Loss: 0.010611106641590595\n",
      "Iteration: 8852/10000, Loss: 0.00936166476458311\n",
      "Iteration: 8853/10000, Loss: 0.005487153306603432\n",
      "Iteration: 8854/10000, Loss: 0.014060452580451965\n",
      "Iteration: 8855/10000, Loss: 0.011413948610424995\n",
      "Iteration: 8856/10000, Loss: 0.010402955114841461\n",
      "Iteration: 8857/10000, Loss: 0.008119951002299786\n",
      "Iteration: 8858/10000, Loss: 0.009732075966894627\n",
      "Iteration: 8859/10000, Loss: 0.012301351875066757\n",
      "Iteration: 8860/10000, Loss: 0.009070808999240398\n",
      "Iteration: 8861/10000, Loss: 0.01051842700690031\n",
      "Iteration: 8862/10000, Loss: 0.007492062170058489\n",
      "Iteration: 8863/10000, Loss: 0.005252285394817591\n",
      "Iteration: 8864/10000, Loss: 0.009257396683096886\n",
      "Iteration: 8865/10000, Loss: 0.010496011935174465\n",
      "Iteration: 8866/10000, Loss: 0.009907269850373268\n",
      "Iteration: 8867/10000, Loss: 0.013311507180333138\n",
      "Iteration: 8868/10000, Loss: 0.010864950716495514\n",
      "Iteration: 8869/10000, Loss: 0.010335871018469334\n",
      "Iteration: 8870/10000, Loss: 0.008204094134271145\n",
      "Iteration: 8871/10000, Loss: 0.013646239414811134\n",
      "Iteration: 8872/10000, Loss: 0.010677131824195385\n",
      "Iteration: 8873/10000, Loss: 0.011617286130785942\n",
      "Iteration: 8874/10000, Loss: 0.005149338860064745\n",
      "Iteration: 8875/10000, Loss: 0.010611423291265965\n",
      "Iteration: 8876/10000, Loss: 0.011574637144804\n",
      "Iteration: 8877/10000, Loss: 0.008996272459626198\n",
      "Iteration: 8878/10000, Loss: 0.007479926571249962\n",
      "Iteration: 8879/10000, Loss: 0.010080970823764801\n",
      "Iteration: 8880/10000, Loss: 0.00649139191955328\n",
      "Iteration: 8881/10000, Loss: 0.012822776101529598\n",
      "Iteration: 8882/10000, Loss: 0.0062549361027777195\n",
      "Iteration: 8883/10000, Loss: 0.009995500557124615\n",
      "Iteration: 8884/10000, Loss: 0.0060577914118766785\n",
      "Iteration: 8885/10000, Loss: 0.010752173140645027\n",
      "Iteration: 8886/10000, Loss: 0.006046689581125975\n",
      "Iteration: 8887/10000, Loss: 0.010384134016931057\n",
      "Iteration: 8888/10000, Loss: 0.00834710244089365\n",
      "Iteration: 8889/10000, Loss: 0.011138321831822395\n",
      "Iteration: 8890/10000, Loss: 0.006819615140557289\n",
      "Iteration: 8891/10000, Loss: 0.013312515802681446\n",
      "Iteration: 8892/10000, Loss: 0.00824380200356245\n",
      "Iteration: 8893/10000, Loss: 0.008466674946248531\n",
      "Iteration: 8894/10000, Loss: 0.008736185729503632\n",
      "Iteration: 8895/10000, Loss: 0.015247316099703312\n",
      "Iteration: 8896/10000, Loss: 0.010177352465689182\n",
      "Iteration: 8897/10000, Loss: 0.013930551707744598\n",
      "Iteration: 8898/10000, Loss: 0.006911568809300661\n",
      "Iteration: 8899/10000, Loss: 0.00725440913811326\n",
      "Iteration: 8900/10000, Loss: 0.0064402250573039055\n",
      "Average test loss:  0.0025\n",
      "Iteration: 8901/10000, Loss: 0.009323978796601295\n",
      "Iteration: 8902/10000, Loss: 0.0073385946452617645\n",
      "Iteration: 8903/10000, Loss: 0.012045489624142647\n",
      "Iteration: 8904/10000, Loss: 0.0072135706432163715\n",
      "Iteration: 8905/10000, Loss: 0.008485746569931507\n",
      "Iteration: 8906/10000, Loss: 0.010140321217477322\n",
      "Iteration: 8907/10000, Loss: 0.016234394162893295\n",
      "Iteration: 8908/10000, Loss: 0.00791324395686388\n",
      "Iteration: 8909/10000, Loss: 0.010723058134317398\n",
      "Iteration: 8910/10000, Loss: 0.011407957412302494\n",
      "Iteration: 8911/10000, Loss: 0.010750440880656242\n",
      "Iteration: 8912/10000, Loss: 0.008107745088636875\n",
      "Iteration: 8913/10000, Loss: 0.006113392300903797\n",
      "Iteration: 8914/10000, Loss: 0.006240537390112877\n",
      "Iteration: 8915/10000, Loss: 0.00941516738384962\n",
      "Iteration: 8916/10000, Loss: 0.00952605064958334\n",
      "Iteration: 8917/10000, Loss: 0.010384075343608856\n",
      "Iteration: 8918/10000, Loss: 0.008664567023515701\n",
      "Iteration: 8919/10000, Loss: 0.00528761325404048\n",
      "Iteration: 8920/10000, Loss: 0.004943310748785734\n",
      "Iteration: 8921/10000, Loss: 0.013755489140748978\n",
      "Iteration: 8922/10000, Loss: 0.00872438307851553\n",
      "Iteration: 8923/10000, Loss: 0.007704050280153751\n",
      "Iteration: 8924/10000, Loss: 0.009763725101947784\n",
      "Iteration: 8925/10000, Loss: 0.008844058029353619\n",
      "Iteration: 8926/10000, Loss: 0.007423657923936844\n",
      "Iteration: 8927/10000, Loss: 0.008630067110061646\n",
      "Iteration: 8928/10000, Loss: 0.011029686778783798\n",
      "Iteration: 8929/10000, Loss: 0.009874630719423294\n",
      "Iteration: 8930/10000, Loss: 0.005488499999046326\n",
      "Iteration: 8931/10000, Loss: 0.011097483336925507\n",
      "Iteration: 8932/10000, Loss: 0.011634222231805325\n",
      "Iteration: 8933/10000, Loss: 0.00736969942227006\n",
      "Iteration: 8934/10000, Loss: 0.010026838630437851\n",
      "Iteration: 8935/10000, Loss: 0.008633804507553577\n",
      "Iteration: 8936/10000, Loss: 0.007213461212813854\n",
      "Iteration: 8937/10000, Loss: 0.010832637548446655\n",
      "Iteration: 8938/10000, Loss: 0.011692706495523453\n",
      "Iteration: 8939/10000, Loss: 0.00946713238954544\n",
      "Iteration: 8940/10000, Loss: 0.00879853405058384\n",
      "Iteration: 8941/10000, Loss: 0.010617622174322605\n",
      "Iteration: 8942/10000, Loss: 0.008671843446791172\n",
      "Iteration: 8943/10000, Loss: 0.0065059969201684\n",
      "Iteration: 8944/10000, Loss: 0.007509677205234766\n",
      "Iteration: 8945/10000, Loss: 0.004802849143743515\n",
      "Iteration: 8946/10000, Loss: 0.007305583916604519\n",
      "Iteration: 8947/10000, Loss: 0.007779449224472046\n",
      "Iteration: 8948/10000, Loss: 0.0073098610155284405\n",
      "Iteration: 8949/10000, Loss: 0.013641510158777237\n",
      "Iteration: 8950/10000, Loss: 0.006403631530702114\n",
      "Iteration: 8951/10000, Loss: 0.008789027109742165\n",
      "Iteration: 8952/10000, Loss: 0.009140611626207829\n",
      "Iteration: 8953/10000, Loss: 0.00832290668040514\n",
      "Iteration: 8954/10000, Loss: 0.006566505879163742\n",
      "Iteration: 8955/10000, Loss: 0.007655694615095854\n",
      "Iteration: 8956/10000, Loss: 0.0049691228196024895\n",
      "Iteration: 8957/10000, Loss: 0.010866603814065456\n",
      "Iteration: 8958/10000, Loss: 0.008968875743448734\n",
      "Iteration: 8959/10000, Loss: 0.006060861516743898\n",
      "Iteration: 8960/10000, Loss: 0.006349056027829647\n",
      "Iteration: 8961/10000, Loss: 0.008718067780137062\n",
      "Iteration: 8962/10000, Loss: 0.006795595865696669\n",
      "Iteration: 8963/10000, Loss: 0.008354603312909603\n",
      "Iteration: 8964/10000, Loss: 0.011292059905827045\n",
      "Iteration: 8965/10000, Loss: 0.007734055630862713\n",
      "Iteration: 8966/10000, Loss: 0.007403639145195484\n",
      "Iteration: 8967/10000, Loss: 0.0058915875852108\n",
      "Iteration: 8968/10000, Loss: 0.006467269267886877\n",
      "Iteration: 8969/10000, Loss: 0.0078669348731637\n",
      "Iteration: 8970/10000, Loss: 0.010608134791254997\n",
      "Iteration: 8971/10000, Loss: 0.009938078932464123\n",
      "Iteration: 8972/10000, Loss: 0.00791323184967041\n",
      "Iteration: 8973/10000, Loss: 0.00939053762704134\n",
      "Iteration: 8974/10000, Loss: 0.006506284233182669\n",
      "Iteration: 8975/10000, Loss: 0.006935089826583862\n",
      "Iteration: 8976/10000, Loss: 0.008908212184906006\n",
      "Iteration: 8977/10000, Loss: 0.006302637048065662\n",
      "Iteration: 8978/10000, Loss: 0.007425785530358553\n",
      "Iteration: 8979/10000, Loss: 0.00927735399454832\n",
      "Iteration: 8980/10000, Loss: 0.005362195894122124\n",
      "Iteration: 8981/10000, Loss: 0.009831788018345833\n",
      "Iteration: 8982/10000, Loss: 0.006856939755380154\n",
      "Iteration: 8983/10000, Loss: 0.006375313736498356\n",
      "Iteration: 8984/10000, Loss: 0.0071868873201310635\n",
      "Iteration: 8985/10000, Loss: 0.007267667446285486\n",
      "Iteration: 8986/10000, Loss: 0.006763881538063288\n",
      "Iteration: 8987/10000, Loss: 0.004810344893485308\n",
      "Iteration: 8988/10000, Loss: 0.009385200217366219\n",
      "Iteration: 8989/10000, Loss: 0.008346905931830406\n",
      "Iteration: 8990/10000, Loss: 0.011709802784025669\n",
      "Iteration: 8991/10000, Loss: 0.0109439417719841\n",
      "Iteration: 8992/10000, Loss: 0.0067932941019535065\n",
      "Iteration: 8993/10000, Loss: 0.005079691298305988\n",
      "Iteration: 8994/10000, Loss: 0.008681676350533962\n",
      "Iteration: 8995/10000, Loss: 0.008778775110840797\n",
      "Iteration: 8996/10000, Loss: 0.006338103674352169\n",
      "Iteration: 8997/10000, Loss: 0.011126571334898472\n",
      "Iteration: 8998/10000, Loss: 0.006497143767774105\n",
      "Iteration: 8999/10000, Loss: 0.007633916102349758\n",
      "Iteration: 9000/10000, Loss: 0.009405774064362049\n",
      "Average test loss:  0.0026\n",
      "Iteration: 9001/10000, Loss: 0.014379960484802723\n",
      "Iteration: 9002/10000, Loss: 0.0063599045388400555\n",
      "Iteration: 9003/10000, Loss: 0.00845255609601736\n",
      "Iteration: 9004/10000, Loss: 0.007092141546308994\n",
      "Iteration: 9005/10000, Loss: 0.011381128802895546\n",
      "Iteration: 9006/10000, Loss: 0.006852802820503712\n",
      "Iteration: 9007/10000, Loss: 0.006749577354639769\n",
      "Iteration: 9008/10000, Loss: 0.01134886872023344\n",
      "Iteration: 9009/10000, Loss: 0.009347577579319477\n",
      "Iteration: 9010/10000, Loss: 0.0069016870111227036\n",
      "Iteration: 9011/10000, Loss: 0.007779303472489119\n",
      "Iteration: 9012/10000, Loss: 0.0033625022042542696\n",
      "Iteration: 9013/10000, Loss: 0.009011223912239075\n",
      "Iteration: 9014/10000, Loss: 0.007698248606175184\n",
      "Iteration: 9015/10000, Loss: 0.012032910250127316\n",
      "Iteration: 9016/10000, Loss: 0.009810487739741802\n",
      "Iteration: 9017/10000, Loss: 0.00997923407703638\n",
      "Iteration: 9018/10000, Loss: 0.010550027713179588\n",
      "Iteration: 9019/10000, Loss: 0.01318725012242794\n",
      "Iteration: 9020/10000, Loss: 0.006776320282369852\n",
      "Iteration: 9021/10000, Loss: 0.010706241242587566\n",
      "Iteration: 9022/10000, Loss: 0.011211369186639786\n",
      "Iteration: 9023/10000, Loss: 0.011440454050898552\n",
      "Iteration: 9024/10000, Loss: 0.01215559896081686\n",
      "Iteration: 9025/10000, Loss: 0.008618312887847424\n",
      "Iteration: 9026/10000, Loss: 0.007071394007652998\n",
      "Iteration: 9027/10000, Loss: 0.005097811575978994\n",
      "Iteration: 9028/10000, Loss: 0.010811466723680496\n",
      "Iteration: 9029/10000, Loss: 0.011216218583285809\n",
      "Iteration: 9030/10000, Loss: 0.006052408367395401\n",
      "Iteration: 9031/10000, Loss: 0.01454258430749178\n",
      "Iteration: 9032/10000, Loss: 0.01129139494150877\n",
      "Iteration: 9033/10000, Loss: 0.0067881932482123375\n",
      "Iteration: 9034/10000, Loss: 0.007873798720538616\n",
      "Iteration: 9035/10000, Loss: 0.01024589128792286\n",
      "Iteration: 9036/10000, Loss: 0.008204887621104717\n",
      "Iteration: 9037/10000, Loss: 0.007712729275226593\n",
      "Iteration: 9038/10000, Loss: 0.007443867623806\n",
      "Iteration: 9039/10000, Loss: 0.007129964418709278\n",
      "Iteration: 9040/10000, Loss: 0.0108399773016572\n",
      "Iteration: 9041/10000, Loss: 0.010489354841411114\n",
      "Iteration: 9042/10000, Loss: 0.009742990136146545\n",
      "Iteration: 9043/10000, Loss: 0.0101470947265625\n",
      "Iteration: 9044/10000, Loss: 0.00818545650690794\n",
      "Iteration: 9045/10000, Loss: 0.006960217375308275\n",
      "Iteration: 9046/10000, Loss: 0.009572657756507397\n",
      "Iteration: 9047/10000, Loss: 0.013966837897896767\n",
      "Iteration: 9048/10000, Loss: 0.008032815530896187\n",
      "Iteration: 9049/10000, Loss: 0.0037313683424144983\n",
      "Iteration: 9050/10000, Loss: 0.012048453092575073\n",
      "Iteration: 9051/10000, Loss: 0.008517276495695114\n",
      "Iteration: 9052/10000, Loss: 0.008078631944954395\n",
      "Iteration: 9053/10000, Loss: 0.004652868025004864\n",
      "Iteration: 9054/10000, Loss: 0.006339269690215588\n",
      "Iteration: 9055/10000, Loss: 0.01341980043798685\n",
      "Iteration: 9056/10000, Loss: 0.01147865317761898\n",
      "Iteration: 9057/10000, Loss: 0.01016170997172594\n",
      "Iteration: 9058/10000, Loss: 0.006547108758240938\n",
      "Iteration: 9059/10000, Loss: 0.008391721174120903\n",
      "Iteration: 9060/10000, Loss: 0.009313262067735195\n",
      "Iteration: 9061/10000, Loss: 0.00744022848084569\n",
      "Iteration: 9062/10000, Loss: 0.007542336825281382\n",
      "Iteration: 9063/10000, Loss: 0.006748315878212452\n",
      "Iteration: 9064/10000, Loss: 0.008958323858678341\n",
      "Iteration: 9065/10000, Loss: 0.00778332119807601\n",
      "Iteration: 9066/10000, Loss: 0.010385535657405853\n",
      "Iteration: 9067/10000, Loss: 0.004596395883709192\n",
      "Iteration: 9068/10000, Loss: 0.008240047842264175\n",
      "Iteration: 9069/10000, Loss: 0.010022399015724659\n",
      "Iteration: 9070/10000, Loss: 0.010746333748102188\n",
      "Iteration: 9071/10000, Loss: 0.006289798300713301\n",
      "Iteration: 9072/10000, Loss: 0.007553381845355034\n",
      "Iteration: 9073/10000, Loss: 0.007954806089401245\n",
      "Iteration: 9074/10000, Loss: 0.007871363312005997\n",
      "Iteration: 9075/10000, Loss: 0.012571382336318493\n",
      "Iteration: 9076/10000, Loss: 0.005213725380599499\n",
      "Iteration: 9077/10000, Loss: 0.008971323259174824\n",
      "Iteration: 9078/10000, Loss: 0.008892894722521305\n",
      "Iteration: 9079/10000, Loss: 0.010850737802684307\n",
      "Iteration: 9080/10000, Loss: 0.007348252460360527\n",
      "Iteration: 9081/10000, Loss: 0.008855924010276794\n",
      "Iteration: 9082/10000, Loss: 0.011801322922110558\n",
      "Iteration: 9083/10000, Loss: 0.007583956234157085\n",
      "Iteration: 9084/10000, Loss: 0.015586791560053825\n",
      "Iteration: 9085/10000, Loss: 0.008209778927266598\n",
      "Iteration: 9086/10000, Loss: 0.010133751668035984\n",
      "Iteration: 9087/10000, Loss: 0.00608434434980154\n",
      "Iteration: 9088/10000, Loss: 0.013973718509078026\n",
      "Iteration: 9089/10000, Loss: 0.009237105026841164\n",
      "Iteration: 9090/10000, Loss: 0.007520277984440327\n",
      "Iteration: 9091/10000, Loss: 0.007482464425265789\n",
      "Iteration: 9092/10000, Loss: 0.014218401163816452\n",
      "Iteration: 9093/10000, Loss: 0.010199722833931446\n",
      "Iteration: 9094/10000, Loss: 0.007769093383103609\n",
      "Iteration: 9095/10000, Loss: 0.007696773856878281\n",
      "Iteration: 9096/10000, Loss: 0.01088428683578968\n",
      "Iteration: 9097/10000, Loss: 0.007170171942561865\n",
      "Iteration: 9098/10000, Loss: 0.008079680614173412\n",
      "Iteration: 9099/10000, Loss: 0.009357332251966\n",
      "Iteration: 9100/10000, Loss: 0.005736587103456259\n",
      "Average test loss:  0.0040\n",
      "Iteration: 9101/10000, Loss: 0.008562889881432056\n",
      "Iteration: 9102/10000, Loss: 0.0050798640586435795\n",
      "Iteration: 9103/10000, Loss: 0.007473001256585121\n",
      "Iteration: 9104/10000, Loss: 0.006200994830578566\n",
      "Iteration: 9105/10000, Loss: 0.007592458743602037\n",
      "Iteration: 9106/10000, Loss: 0.009499743580818176\n",
      "Iteration: 9107/10000, Loss: 0.008964377455413342\n",
      "Iteration: 9108/10000, Loss: 0.006297486834228039\n",
      "Iteration: 9109/10000, Loss: 0.010631361044943333\n",
      "Iteration: 9110/10000, Loss: 0.007279395125806332\n",
      "Iteration: 9111/10000, Loss: 0.008253995329141617\n",
      "Iteration: 9112/10000, Loss: 0.0070942239835858345\n",
      "Iteration: 9113/10000, Loss: 0.011648737825453281\n",
      "Iteration: 9114/10000, Loss: 0.011951928026974201\n",
      "Iteration: 9115/10000, Loss: 0.007468666881322861\n",
      "Iteration: 9116/10000, Loss: 0.008649605326354504\n",
      "Iteration: 9117/10000, Loss: 0.006872090045362711\n",
      "Iteration: 9118/10000, Loss: 0.007465946488082409\n",
      "Iteration: 9119/10000, Loss: 0.006504448596388102\n",
      "Iteration: 9120/10000, Loss: 0.008757181465625763\n",
      "Iteration: 9121/10000, Loss: 0.009830664843320847\n",
      "Iteration: 9122/10000, Loss: 0.010940690524876118\n",
      "Iteration: 9123/10000, Loss: 0.007904778234660625\n",
      "Iteration: 9124/10000, Loss: 0.007861465215682983\n",
      "Iteration: 9125/10000, Loss: 0.009911790490150452\n",
      "Iteration: 9126/10000, Loss: 0.014330319128930569\n",
      "Iteration: 9127/10000, Loss: 0.007215152960270643\n",
      "Iteration: 9128/10000, Loss: 0.008370970375835896\n",
      "Iteration: 9129/10000, Loss: 0.007286860607564449\n",
      "Iteration: 9130/10000, Loss: 0.010726358741521835\n",
      "Iteration: 9131/10000, Loss: 0.006790234707295895\n",
      "Iteration: 9132/10000, Loss: 0.00815797969698906\n",
      "Iteration: 9133/10000, Loss: 0.009291895665228367\n",
      "Iteration: 9134/10000, Loss: 0.011223307810723782\n",
      "Iteration: 9135/10000, Loss: 0.007617844268679619\n",
      "Iteration: 9136/10000, Loss: 0.00939417164772749\n",
      "Iteration: 9137/10000, Loss: 0.007871848531067371\n",
      "Iteration: 9138/10000, Loss: 0.010005542077124119\n",
      "Iteration: 9139/10000, Loss: 0.007189224008470774\n",
      "Iteration: 9140/10000, Loss: 0.012157045304775238\n",
      "Iteration: 9141/10000, Loss: 0.008386308327317238\n",
      "Iteration: 9142/10000, Loss: 0.006404449697583914\n",
      "Iteration: 9143/10000, Loss: 0.006591875106096268\n",
      "Iteration: 9144/10000, Loss: 0.005841988604515791\n",
      "Iteration: 9145/10000, Loss: 0.010591820813715458\n",
      "Iteration: 9146/10000, Loss: 0.007483081892132759\n",
      "Iteration: 9147/10000, Loss: 0.005862302612513304\n",
      "Iteration: 9148/10000, Loss: 0.008406824432313442\n",
      "Iteration: 9149/10000, Loss: 0.012909451499581337\n",
      "Iteration: 9150/10000, Loss: 0.007503558415919542\n",
      "Iteration: 9151/10000, Loss: 0.007752765901386738\n",
      "Iteration: 9152/10000, Loss: 0.005951607599854469\n",
      "Iteration: 9153/10000, Loss: 0.009182792156934738\n",
      "Iteration: 9154/10000, Loss: 0.006225125398486853\n",
      "Iteration: 9155/10000, Loss: 0.010946009308099747\n",
      "Iteration: 9156/10000, Loss: 0.006618372164666653\n",
      "Iteration: 9157/10000, Loss: 0.006369271315634251\n",
      "Iteration: 9158/10000, Loss: 0.007063961122184992\n",
      "Iteration: 9159/10000, Loss: 0.009387431666254997\n",
      "Iteration: 9160/10000, Loss: 0.01098653394728899\n",
      "Iteration: 9161/10000, Loss: 0.01048805471509695\n",
      "Iteration: 9162/10000, Loss: 0.0071293385699391365\n",
      "Iteration: 9163/10000, Loss: 0.006950658280402422\n",
      "Iteration: 9164/10000, Loss: 0.008698462508618832\n",
      "Iteration: 9165/10000, Loss: 0.009579379111528397\n",
      "Iteration: 9166/10000, Loss: 0.007643677294254303\n",
      "Iteration: 9167/10000, Loss: 0.005468813236802816\n",
      "Iteration: 9168/10000, Loss: 0.006837279070168734\n",
      "Iteration: 9169/10000, Loss: 0.011506523936986923\n",
      "Iteration: 9170/10000, Loss: 0.009178051725029945\n",
      "Iteration: 9171/10000, Loss: 0.007249386049807072\n",
      "Iteration: 9172/10000, Loss: 0.006886912509799004\n",
      "Iteration: 9173/10000, Loss: 0.010941784828901291\n",
      "Iteration: 9174/10000, Loss: 0.009324194863438606\n",
      "Iteration: 9175/10000, Loss: 0.008111156523227692\n",
      "Iteration: 9176/10000, Loss: 0.007023362442851067\n",
      "Iteration: 9177/10000, Loss: 0.010809991508722305\n",
      "Iteration: 9178/10000, Loss: 0.007824010215699673\n",
      "Iteration: 9179/10000, Loss: 0.009286639280617237\n",
      "Iteration: 9180/10000, Loss: 0.004563725087791681\n",
      "Iteration: 9181/10000, Loss: 0.006622815504670143\n",
      "Iteration: 9182/10000, Loss: 0.009062414057552814\n",
      "Iteration: 9183/10000, Loss: 0.008950388990342617\n",
      "Iteration: 9184/10000, Loss: 0.010768829844892025\n",
      "Iteration: 9185/10000, Loss: 0.01252153143286705\n",
      "Iteration: 9186/10000, Loss: 0.006990108639001846\n",
      "Iteration: 9187/10000, Loss: 0.009373423643410206\n",
      "Iteration: 9188/10000, Loss: 0.008700083941221237\n",
      "Iteration: 9189/10000, Loss: 0.00959663838148117\n",
      "Iteration: 9190/10000, Loss: 0.009139904752373695\n",
      "Iteration: 9191/10000, Loss: 0.011177750304341316\n",
      "Iteration: 9192/10000, Loss: 0.006124643608927727\n",
      "Iteration: 9193/10000, Loss: 0.00785871036350727\n",
      "Iteration: 9194/10000, Loss: 0.0063337585888803005\n",
      "Iteration: 9195/10000, Loss: 0.008705140091478825\n",
      "Iteration: 9196/10000, Loss: 0.008911232464015484\n",
      "Iteration: 9197/10000, Loss: 0.00546495895832777\n",
      "Iteration: 9198/10000, Loss: 0.013098961673676968\n",
      "Iteration: 9199/10000, Loss: 0.004657979588955641\n",
      "Iteration: 9200/10000, Loss: 0.008104810491204262\n",
      "Average test loss:  0.0040\n",
      "Iteration: 9201/10000, Loss: 0.009969244711101055\n",
      "Iteration: 9202/10000, Loss: 0.00920124351978302\n",
      "Iteration: 9203/10000, Loss: 0.007053375244140625\n",
      "Iteration: 9204/10000, Loss: 0.0060991751961410046\n",
      "Iteration: 9205/10000, Loss: 0.006574973464012146\n",
      "Iteration: 9206/10000, Loss: 0.011006164364516735\n",
      "Iteration: 9207/10000, Loss: 0.008501770906150341\n",
      "Iteration: 9208/10000, Loss: 0.007318069227039814\n",
      "Iteration: 9209/10000, Loss: 0.008927381597459316\n",
      "Iteration: 9210/10000, Loss: 0.006984167266637087\n",
      "Iteration: 9211/10000, Loss: 0.00904854666441679\n",
      "Iteration: 9212/10000, Loss: 0.00649640616029501\n",
      "Iteration: 9213/10000, Loss: 0.0049650720320641994\n",
      "Iteration: 9214/10000, Loss: 0.011831900104880333\n",
      "Iteration: 9215/10000, Loss: 0.006644671317189932\n",
      "Iteration: 9216/10000, Loss: 0.011139568872749805\n",
      "Iteration: 9217/10000, Loss: 0.010206959210336208\n",
      "Iteration: 9218/10000, Loss: 0.009648170322179794\n",
      "Iteration: 9219/10000, Loss: 0.009290334768593311\n",
      "Iteration: 9220/10000, Loss: 0.010549874976277351\n",
      "Iteration: 9221/10000, Loss: 0.010440594516694546\n",
      "Iteration: 9222/10000, Loss: 0.007681874558329582\n",
      "Iteration: 9223/10000, Loss: 0.005865901708602905\n",
      "Iteration: 9224/10000, Loss: 0.01029977761209011\n",
      "Iteration: 9225/10000, Loss: 0.005764038302004337\n",
      "Iteration: 9226/10000, Loss: 0.008254448883235455\n",
      "Iteration: 9227/10000, Loss: 0.0075423140078783035\n",
      "Iteration: 9228/10000, Loss: 0.006726340390741825\n",
      "Iteration: 9229/10000, Loss: 0.011389235034584999\n",
      "Iteration: 9230/10000, Loss: 0.006212323904037476\n",
      "Iteration: 9231/10000, Loss: 0.0077910469844937325\n",
      "Iteration: 9232/10000, Loss: 0.011538592167198658\n",
      "Iteration: 9233/10000, Loss: 0.008833336643874645\n",
      "Iteration: 9234/10000, Loss: 0.010631722398102283\n",
      "Iteration: 9235/10000, Loss: 0.01208343543112278\n",
      "Iteration: 9236/10000, Loss: 0.006418945733457804\n",
      "Iteration: 9237/10000, Loss: 0.008470077067613602\n",
      "Iteration: 9238/10000, Loss: 0.010492808185517788\n",
      "Iteration: 9239/10000, Loss: 0.008794990368187428\n",
      "Iteration: 9240/10000, Loss: 0.010144749656319618\n",
      "Iteration: 9241/10000, Loss: 0.007457915227860212\n",
      "Iteration: 9242/10000, Loss: 0.008066448383033276\n",
      "Iteration: 9243/10000, Loss: 0.01017534639686346\n",
      "Iteration: 9244/10000, Loss: 0.008519509807229042\n",
      "Iteration: 9245/10000, Loss: 0.008591988123953342\n",
      "Iteration: 9246/10000, Loss: 0.013363205827772617\n",
      "Iteration: 9247/10000, Loss: 0.007431450299918652\n",
      "Iteration: 9248/10000, Loss: 0.009310958907008171\n",
      "Iteration: 9249/10000, Loss: 0.007065488491207361\n",
      "Iteration: 9250/10000, Loss: 0.00919871311634779\n",
      "Iteration: 9251/10000, Loss: 0.010641816072165966\n",
      "Iteration: 9252/10000, Loss: 0.00962554756551981\n",
      "Iteration: 9253/10000, Loss: 0.009901370853185654\n",
      "Iteration: 9254/10000, Loss: 0.010199539363384247\n",
      "Iteration: 9255/10000, Loss: 0.00701992679387331\n",
      "Iteration: 9256/10000, Loss: 0.010181349702179432\n",
      "Iteration: 9257/10000, Loss: 0.01047520712018013\n",
      "Iteration: 9258/10000, Loss: 0.01190741453319788\n",
      "Iteration: 9259/10000, Loss: 0.007354238070547581\n",
      "Iteration: 9260/10000, Loss: 0.007203008513897657\n",
      "Iteration: 9261/10000, Loss: 0.007192716468125582\n",
      "Iteration: 9262/10000, Loss: 0.00916680134832859\n",
      "Iteration: 9263/10000, Loss: 0.0079489229246974\n",
      "Iteration: 9264/10000, Loss: 0.01001525018364191\n",
      "Iteration: 9265/10000, Loss: 0.006267504300922155\n",
      "Iteration: 9266/10000, Loss: 0.006571043282747269\n",
      "Iteration: 9267/10000, Loss: 0.007002399303019047\n",
      "Iteration: 9268/10000, Loss: 0.009144730865955353\n",
      "Iteration: 9269/10000, Loss: 0.00982585921883583\n",
      "Iteration: 9270/10000, Loss: 0.010013841092586517\n",
      "Iteration: 9271/10000, Loss: 0.009811332449316978\n",
      "Iteration: 9272/10000, Loss: 0.007329643703997135\n",
      "Iteration: 9273/10000, Loss: 0.006704132072627544\n",
      "Iteration: 9274/10000, Loss: 0.007655046880245209\n",
      "Iteration: 9275/10000, Loss: 0.008512930013239384\n",
      "Iteration: 9276/10000, Loss: 0.010831081308424473\n",
      "Iteration: 9277/10000, Loss: 0.009607288986444473\n",
      "Iteration: 9278/10000, Loss: 0.008831068873405457\n",
      "Iteration: 9279/10000, Loss: 0.006323299370706081\n",
      "Iteration: 9280/10000, Loss: 0.008696715347468853\n",
      "Iteration: 9281/10000, Loss: 0.009694247506558895\n",
      "Iteration: 9282/10000, Loss: 0.007058880291879177\n",
      "Iteration: 9283/10000, Loss: 0.009851724840700626\n",
      "Iteration: 9284/10000, Loss: 0.009383739903569221\n",
      "Iteration: 9285/10000, Loss: 0.013643644750118256\n",
      "Iteration: 9286/10000, Loss: 0.01131077203899622\n",
      "Iteration: 9287/10000, Loss: 0.008120689541101456\n",
      "Iteration: 9288/10000, Loss: 0.005846214480698109\n",
      "Iteration: 9289/10000, Loss: 0.007744712755084038\n",
      "Iteration: 9290/10000, Loss: 0.007685330230742693\n",
      "Iteration: 9291/10000, Loss: 0.01023455522954464\n",
      "Iteration: 9292/10000, Loss: 0.006348991300910711\n",
      "Iteration: 9293/10000, Loss: 0.013737604953348637\n",
      "Iteration: 9294/10000, Loss: 0.007000438868999481\n",
      "Iteration: 9295/10000, Loss: 0.013491636142134666\n",
      "Iteration: 9296/10000, Loss: 0.009288113564252853\n",
      "Iteration: 9297/10000, Loss: 0.007952215149998665\n",
      "Iteration: 9298/10000, Loss: 0.008734642527997494\n",
      "Iteration: 9299/10000, Loss: 0.010756084695458412\n",
      "Iteration: 9300/10000, Loss: 0.00876604113727808\n",
      "Average test loss:  0.0032\n",
      "Iteration: 9301/10000, Loss: 0.007313993759453297\n",
      "Iteration: 9302/10000, Loss: 0.006674143485724926\n",
      "Iteration: 9303/10000, Loss: 0.005894743371754885\n",
      "Iteration: 9304/10000, Loss: 0.010304161347448826\n",
      "Iteration: 9305/10000, Loss: 0.006584297399967909\n",
      "Iteration: 9306/10000, Loss: 0.00749091524630785\n",
      "Iteration: 9307/10000, Loss: 0.010465063154697418\n",
      "Iteration: 9308/10000, Loss: 0.009221629239618778\n",
      "Iteration: 9309/10000, Loss: 0.006332152057439089\n",
      "Iteration: 9310/10000, Loss: 0.010066342540085316\n",
      "Iteration: 9311/10000, Loss: 0.00954285915941\n",
      "Iteration: 9312/10000, Loss: 0.009585252031683922\n",
      "Iteration: 9313/10000, Loss: 0.006742227356880903\n",
      "Iteration: 9314/10000, Loss: 0.007607662584632635\n",
      "Iteration: 9315/10000, Loss: 0.006378497462719679\n",
      "Iteration: 9316/10000, Loss: 0.017047883942723274\n",
      "Iteration: 9317/10000, Loss: 0.0065893130376935005\n",
      "Iteration: 9318/10000, Loss: 0.005454957950860262\n",
      "Iteration: 9319/10000, Loss: 0.006997727323323488\n",
      "Iteration: 9320/10000, Loss: 0.008275349624454975\n",
      "Iteration: 9321/10000, Loss: 0.005913625471293926\n",
      "Iteration: 9322/10000, Loss: 0.011725327931344509\n",
      "Iteration: 9323/10000, Loss: 0.007429392542690039\n",
      "Iteration: 9324/10000, Loss: 0.007688963320106268\n",
      "Iteration: 9325/10000, Loss: 0.0064850300550460815\n",
      "Iteration: 9326/10000, Loss: 0.00719318026676774\n",
      "Iteration: 9327/10000, Loss: 0.00878480076789856\n",
      "Iteration: 9328/10000, Loss: 0.0047781760804355145\n",
      "Iteration: 9329/10000, Loss: 0.008523888885974884\n",
      "Iteration: 9330/10000, Loss: 0.004944415297359228\n",
      "Iteration: 9331/10000, Loss: 0.009090960025787354\n",
      "Iteration: 9332/10000, Loss: 0.009056253358721733\n",
      "Iteration: 9333/10000, Loss: 0.0057618701830506325\n",
      "Iteration: 9334/10000, Loss: 0.010556982830166817\n",
      "Iteration: 9335/10000, Loss: 0.008435945026576519\n",
      "Iteration: 9336/10000, Loss: 0.0115561718121171\n",
      "Iteration: 9337/10000, Loss: 0.011704303324222565\n",
      "Iteration: 9338/10000, Loss: 0.009360325522720814\n",
      "Iteration: 9339/10000, Loss: 0.007064020726829767\n",
      "Iteration: 9340/10000, Loss: 0.008358494378626347\n",
      "Iteration: 9341/10000, Loss: 0.007240503095090389\n",
      "Iteration: 9342/10000, Loss: 0.009091511368751526\n",
      "Iteration: 9343/10000, Loss: 0.005164916627109051\n",
      "Iteration: 9344/10000, Loss: 0.012036263011395931\n",
      "Iteration: 9345/10000, Loss: 0.009410705417394638\n",
      "Iteration: 9346/10000, Loss: 0.00992099940776825\n",
      "Iteration: 9347/10000, Loss: 0.009015449322760105\n",
      "Iteration: 9348/10000, Loss: 0.008035406470298767\n",
      "Iteration: 9349/10000, Loss: 0.010598181746900082\n",
      "Iteration: 9350/10000, Loss: 0.013039402663707733\n",
      "Iteration: 9351/10000, Loss: 0.007091819308698177\n",
      "Iteration: 9352/10000, Loss: 0.0046798610128462315\n",
      "Iteration: 9353/10000, Loss: 0.009899728931486607\n",
      "Iteration: 9354/10000, Loss: 0.008544721640646458\n",
      "Iteration: 9355/10000, Loss: 0.007430145516991615\n",
      "Iteration: 9356/10000, Loss: 0.007014410570263863\n",
      "Iteration: 9357/10000, Loss: 0.004771031439304352\n",
      "Iteration: 9358/10000, Loss: 0.01062169298529625\n",
      "Iteration: 9359/10000, Loss: 0.008767531253397465\n",
      "Iteration: 9360/10000, Loss: 0.010258305817842484\n",
      "Iteration: 9361/10000, Loss: 0.0055710026063025\n",
      "Iteration: 9362/10000, Loss: 0.009077672846615314\n",
      "Iteration: 9363/10000, Loss: 0.009565761312842369\n",
      "Iteration: 9364/10000, Loss: 0.007649260573089123\n",
      "Iteration: 9365/10000, Loss: 0.014423495158553123\n",
      "Iteration: 9366/10000, Loss: 0.00551041541621089\n",
      "Iteration: 9367/10000, Loss: 0.005512639880180359\n",
      "Iteration: 9368/10000, Loss: 0.009132708422839642\n",
      "Iteration: 9369/10000, Loss: 0.010987830348312855\n",
      "Iteration: 9370/10000, Loss: 0.009378157556056976\n",
      "Iteration: 9371/10000, Loss: 0.007690452039241791\n",
      "Iteration: 9372/10000, Loss: 0.009025225415825844\n",
      "Iteration: 9373/10000, Loss: 0.010718914680182934\n",
      "Iteration: 9374/10000, Loss: 0.01032180804759264\n",
      "Iteration: 9375/10000, Loss: 0.007586506195366383\n",
      "Iteration: 9376/10000, Loss: 0.006205849815160036\n",
      "Iteration: 9377/10000, Loss: 0.0059719267301261425\n",
      "Iteration: 9378/10000, Loss: 0.013045194558799267\n",
      "Iteration: 9379/10000, Loss: 0.009625672362744808\n",
      "Iteration: 9380/10000, Loss: 0.006446147337555885\n",
      "Iteration: 9381/10000, Loss: 0.006019881926476955\n",
      "Iteration: 9382/10000, Loss: 0.00670586246997118\n",
      "Iteration: 9383/10000, Loss: 0.005507177673280239\n",
      "Iteration: 9384/10000, Loss: 0.007831228896975517\n",
      "Iteration: 9385/10000, Loss: 0.00784926675260067\n",
      "Iteration: 9386/10000, Loss: 0.009629289619624615\n",
      "Iteration: 9387/10000, Loss: 0.009006309323012829\n",
      "Iteration: 9388/10000, Loss: 0.009678473696112633\n",
      "Iteration: 9389/10000, Loss: 0.00958419032394886\n",
      "Iteration: 9390/10000, Loss: 0.007443330250680447\n",
      "Iteration: 9391/10000, Loss: 0.0089660519734025\n",
      "Iteration: 9392/10000, Loss: 0.010567420162260532\n",
      "Iteration: 9393/10000, Loss: 0.008945290930569172\n",
      "Iteration: 9394/10000, Loss: 0.004657186567783356\n",
      "Iteration: 9395/10000, Loss: 0.010519234463572502\n",
      "Iteration: 9396/10000, Loss: 0.009877855889499187\n",
      "Iteration: 9397/10000, Loss: 0.005554914940148592\n",
      "Iteration: 9398/10000, Loss: 0.013961547054350376\n",
      "Iteration: 9399/10000, Loss: 0.005037124268710613\n",
      "Iteration: 9400/10000, Loss: 0.010831012390553951\n",
      "Average test loss:  0.0044\n",
      "Iteration: 9401/10000, Loss: 0.007624058518558741\n",
      "Iteration: 9402/10000, Loss: 0.00964758638292551\n",
      "Iteration: 9403/10000, Loss: 0.008209923282265663\n",
      "Iteration: 9404/10000, Loss: 0.009350658394396305\n",
      "Iteration: 9405/10000, Loss: 0.007902819663286209\n",
      "Iteration: 9406/10000, Loss: 0.0070017543621361256\n",
      "Iteration: 9407/10000, Loss: 0.009894409216940403\n",
      "Iteration: 9408/10000, Loss: 0.013010702095925808\n",
      "Iteration: 9409/10000, Loss: 0.0066708908416330814\n",
      "Iteration: 9410/10000, Loss: 0.011356259696185589\n",
      "Iteration: 9411/10000, Loss: 0.008644014596939087\n",
      "Iteration: 9412/10000, Loss: 0.00960337184369564\n",
      "Iteration: 9413/10000, Loss: 0.010924383997917175\n",
      "Iteration: 9414/10000, Loss: 0.009281215257942677\n",
      "Iteration: 9415/10000, Loss: 0.008146122097969055\n",
      "Iteration: 9416/10000, Loss: 0.007560131140053272\n",
      "Iteration: 9417/10000, Loss: 0.00587026821449399\n",
      "Iteration: 9418/10000, Loss: 0.006032617762684822\n",
      "Iteration: 9419/10000, Loss: 0.008565559051930904\n",
      "Iteration: 9420/10000, Loss: 0.009930537082254887\n",
      "Iteration: 9421/10000, Loss: 0.008822864852845669\n",
      "Iteration: 9422/10000, Loss: 0.0037278574891388416\n",
      "Iteration: 9423/10000, Loss: 0.005138285458087921\n",
      "Iteration: 9424/10000, Loss: 0.011040749028325081\n",
      "Iteration: 9425/10000, Loss: 0.008091636933386326\n",
      "Iteration: 9426/10000, Loss: 0.005553952418267727\n",
      "Iteration: 9427/10000, Loss: 0.009107543155550957\n",
      "Iteration: 9428/10000, Loss: 0.009288081899285316\n",
      "Iteration: 9429/10000, Loss: 0.007853609509766102\n",
      "Iteration: 9430/10000, Loss: 0.010156567208468914\n",
      "Iteration: 9431/10000, Loss: 0.008972934447228909\n",
      "Iteration: 9432/10000, Loss: 0.0059282211586833\n",
      "Iteration: 9433/10000, Loss: 0.005793028511106968\n",
      "Iteration: 9434/10000, Loss: 0.008324714377522469\n",
      "Iteration: 9435/10000, Loss: 0.01102677546441555\n",
      "Iteration: 9436/10000, Loss: 0.007286892272531986\n",
      "Iteration: 9437/10000, Loss: 0.007079621311277151\n",
      "Iteration: 9438/10000, Loss: 0.00553088029846549\n",
      "Iteration: 9439/10000, Loss: 0.005219083279371262\n",
      "Iteration: 9440/10000, Loss: 0.006690059322863817\n",
      "Iteration: 9441/10000, Loss: 0.007129299454391003\n",
      "Iteration: 9442/10000, Loss: 0.0060875751078128815\n",
      "Iteration: 9443/10000, Loss: 0.009238036349415779\n",
      "Iteration: 9444/10000, Loss: 0.005296735558658838\n",
      "Iteration: 9445/10000, Loss: 0.011725320480763912\n",
      "Iteration: 9446/10000, Loss: 0.010160952806472778\n",
      "Iteration: 9447/10000, Loss: 0.009899753145873547\n",
      "Iteration: 9448/10000, Loss: 0.00904807448387146\n",
      "Iteration: 9449/10000, Loss: 0.005337201524525881\n",
      "Iteration: 9450/10000, Loss: 0.011460217647254467\n",
      "Iteration: 9451/10000, Loss: 0.010044991038739681\n",
      "Iteration: 9452/10000, Loss: 0.007268104702234268\n",
      "Iteration: 9453/10000, Loss: 0.008330831304192543\n",
      "Iteration: 9454/10000, Loss: 0.008172993548214436\n",
      "Iteration: 9455/10000, Loss: 0.01037923526018858\n",
      "Iteration: 9456/10000, Loss: 0.005821863189339638\n",
      "Iteration: 9457/10000, Loss: 0.01105653028935194\n",
      "Iteration: 9458/10000, Loss: 0.010065142065286636\n",
      "Iteration: 9459/10000, Loss: 0.008257158100605011\n",
      "Iteration: 9460/10000, Loss: 0.008951626718044281\n",
      "Iteration: 9461/10000, Loss: 0.006610684096813202\n",
      "Iteration: 9462/10000, Loss: 0.0052010235376656055\n",
      "Iteration: 9463/10000, Loss: 0.006331491284072399\n",
      "Iteration: 9464/10000, Loss: 0.00832079816609621\n",
      "Iteration: 9465/10000, Loss: 0.005789098329842091\n",
      "Iteration: 9466/10000, Loss: 0.005494640674442053\n",
      "Iteration: 9467/10000, Loss: 0.0063210828229784966\n",
      "Iteration: 9468/10000, Loss: 0.005191511940211058\n",
      "Iteration: 9469/10000, Loss: 0.007429557386785746\n",
      "Iteration: 9470/10000, Loss: 0.00870056077837944\n",
      "Iteration: 9471/10000, Loss: 0.011068521998822689\n",
      "Iteration: 9472/10000, Loss: 0.009278426878154278\n",
      "Iteration: 9473/10000, Loss: 0.008836127817630768\n",
      "Iteration: 9474/10000, Loss: 0.012069611810147762\n",
      "Iteration: 9475/10000, Loss: 0.007880627177655697\n",
      "Iteration: 9476/10000, Loss: 0.008974539116024971\n",
      "Iteration: 9477/10000, Loss: 0.009049976244568825\n",
      "Iteration: 9478/10000, Loss: 0.009286618791520596\n",
      "Iteration: 9479/10000, Loss: 0.00981166772544384\n",
      "Iteration: 9480/10000, Loss: 0.008590050972998142\n",
      "Iteration: 9481/10000, Loss: 0.005321311764419079\n",
      "Iteration: 9482/10000, Loss: 0.00920813623815775\n",
      "Iteration: 9483/10000, Loss: 0.005825647618621588\n",
      "Iteration: 9484/10000, Loss: 0.012062275782227516\n",
      "Iteration: 9485/10000, Loss: 0.005413372069597244\n",
      "Iteration: 9486/10000, Loss: 0.007503268774598837\n",
      "Iteration: 9487/10000, Loss: 0.005450666882097721\n",
      "Iteration: 9488/10000, Loss: 0.0054061440750956535\n",
      "Iteration: 9489/10000, Loss: 0.009297557175159454\n",
      "Iteration: 9490/10000, Loss: 0.006238250527530909\n",
      "Iteration: 9491/10000, Loss: 0.005266091786324978\n",
      "Iteration: 9492/10000, Loss: 0.007185192313045263\n",
      "Iteration: 9493/10000, Loss: 0.00943735335022211\n",
      "Iteration: 9494/10000, Loss: 0.005683255847543478\n",
      "Iteration: 9495/10000, Loss: 0.009970296174287796\n",
      "Iteration: 9496/10000, Loss: 0.006622711196541786\n",
      "Iteration: 9497/10000, Loss: 0.011011457070708275\n",
      "Iteration: 9498/10000, Loss: 0.011400130577385426\n",
      "Iteration: 9499/10000, Loss: 0.006997737567871809\n",
      "Iteration: 9500/10000, Loss: 0.011234247125685215\n",
      "Average test loss:  0.0022\n",
      "Iteration: 9501/10000, Loss: 0.006196499336510897\n",
      "Iteration: 9502/10000, Loss: 0.009308994747698307\n",
      "Iteration: 9503/10000, Loss: 0.007291524671018124\n",
      "Iteration: 9504/10000, Loss: 0.006534725893288851\n",
      "Iteration: 9505/10000, Loss: 0.01220280583947897\n",
      "Iteration: 9506/10000, Loss: 0.008531485684216022\n",
      "Iteration: 9507/10000, Loss: 0.009087255224585533\n",
      "Iteration: 9508/10000, Loss: 0.006936247926205397\n",
      "Iteration: 9509/10000, Loss: 0.005537210963666439\n",
      "Iteration: 9510/10000, Loss: 0.007235066499561071\n",
      "Iteration: 9511/10000, Loss: 0.011291403323411942\n",
      "Iteration: 9512/10000, Loss: 0.008772844448685646\n",
      "Iteration: 9513/10000, Loss: 0.009314987808465958\n",
      "Iteration: 9514/10000, Loss: 0.0088009899482131\n",
      "Iteration: 9515/10000, Loss: 0.0069572413340210915\n",
      "Iteration: 9516/10000, Loss: 0.010071230120956898\n",
      "Iteration: 9517/10000, Loss: 0.011819452047348022\n",
      "Iteration: 9518/10000, Loss: 0.006172648165374994\n",
      "Iteration: 9519/10000, Loss: 0.005804950837045908\n",
      "Iteration: 9520/10000, Loss: 0.00900551863014698\n",
      "Iteration: 9521/10000, Loss: 0.004908061120659113\n",
      "Iteration: 9522/10000, Loss: 0.010465537197887897\n",
      "Iteration: 9523/10000, Loss: 0.006222917698323727\n",
      "Iteration: 9524/10000, Loss: 0.008807268925011158\n",
      "Iteration: 9525/10000, Loss: 0.009716427884995937\n",
      "Iteration: 9526/10000, Loss: 0.007414241787046194\n",
      "Iteration: 9527/10000, Loss: 0.00595428142696619\n",
      "Iteration: 9528/10000, Loss: 0.007693844381719828\n",
      "Iteration: 9529/10000, Loss: 0.00923074595630169\n",
      "Iteration: 9530/10000, Loss: 0.009658082388341427\n",
      "Iteration: 9531/10000, Loss: 0.012975862249732018\n",
      "Iteration: 9532/10000, Loss: 0.010467628948390484\n",
      "Iteration: 9533/10000, Loss: 0.0077154869213700294\n",
      "Iteration: 9534/10000, Loss: 0.01096130907535553\n",
      "Iteration: 9535/10000, Loss: 0.010192293673753738\n",
      "Iteration: 9536/10000, Loss: 0.01081082783639431\n",
      "Iteration: 9537/10000, Loss: 0.007429888937622309\n",
      "Iteration: 9538/10000, Loss: 0.007138564717024565\n",
      "Iteration: 9539/10000, Loss: 0.005955407861620188\n",
      "Iteration: 9540/10000, Loss: 0.006342057604342699\n",
      "Iteration: 9541/10000, Loss: 0.009674548171460629\n",
      "Iteration: 9542/10000, Loss: 0.012111500836908817\n",
      "Iteration: 9543/10000, Loss: 0.007923059165477753\n",
      "Iteration: 9544/10000, Loss: 0.008184473030269146\n",
      "Iteration: 9545/10000, Loss: 0.005422359798103571\n",
      "Iteration: 9546/10000, Loss: 0.010668905451893806\n",
      "Iteration: 9547/10000, Loss: 0.007675207685679197\n",
      "Iteration: 9548/10000, Loss: 0.0055379620753228664\n",
      "Iteration: 9549/10000, Loss: 0.005887252278625965\n",
      "Iteration: 9550/10000, Loss: 0.009070174768567085\n",
      "Iteration: 9551/10000, Loss: 0.007417493499815464\n",
      "Iteration: 9552/10000, Loss: 0.007210171315819025\n",
      "Iteration: 9553/10000, Loss: 0.004090463276952505\n",
      "Iteration: 9554/10000, Loss: 0.004920274950563908\n",
      "Iteration: 9555/10000, Loss: 0.007413714192807674\n",
      "Iteration: 9556/10000, Loss: 0.010207166895270348\n",
      "Iteration: 9557/10000, Loss: 0.005330854095518589\n",
      "Iteration: 9558/10000, Loss: 0.005871049594134092\n",
      "Iteration: 9559/10000, Loss: 0.008036199025809765\n",
      "Iteration: 9560/10000, Loss: 0.008410817012190819\n",
      "Iteration: 9561/10000, Loss: 0.008374577388167381\n",
      "Iteration: 9562/10000, Loss: 0.011488576419651508\n",
      "Iteration: 9563/10000, Loss: 0.014071658253669739\n",
      "Iteration: 9564/10000, Loss: 0.007015786599367857\n",
      "Iteration: 9565/10000, Loss: 0.00802676472812891\n",
      "Iteration: 9566/10000, Loss: 0.008626315742731094\n",
      "Iteration: 9567/10000, Loss: 0.009014880284667015\n",
      "Iteration: 9568/10000, Loss: 0.009786964394152164\n",
      "Iteration: 9569/10000, Loss: 0.010236181318759918\n",
      "Iteration: 9570/10000, Loss: 0.012616780586540699\n",
      "Iteration: 9571/10000, Loss: 0.01024507824331522\n",
      "Iteration: 9572/10000, Loss: 0.009635777212679386\n",
      "Iteration: 9573/10000, Loss: 0.008438547141849995\n",
      "Iteration: 9574/10000, Loss: 0.01179618388414383\n",
      "Iteration: 9575/10000, Loss: 0.006805143319070339\n",
      "Iteration: 9576/10000, Loss: 0.007424825336784124\n",
      "Iteration: 9577/10000, Loss: 0.011424180120229721\n",
      "Iteration: 9578/10000, Loss: 0.01180979236960411\n",
      "Iteration: 9579/10000, Loss: 0.010166308842599392\n",
      "Iteration: 9580/10000, Loss: 0.005321587435901165\n",
      "Iteration: 9581/10000, Loss: 0.008271080441772938\n",
      "Iteration: 9582/10000, Loss: 0.01075963769108057\n",
      "Iteration: 9583/10000, Loss: 0.006961887236684561\n",
      "Iteration: 9584/10000, Loss: 0.006189079489558935\n",
      "Iteration: 9585/10000, Loss: 0.006317734252661467\n",
      "Iteration: 9586/10000, Loss: 0.008774536661803722\n",
      "Iteration: 9587/10000, Loss: 0.01099027507007122\n",
      "Iteration: 9588/10000, Loss: 0.008954639546573162\n",
      "Iteration: 9589/10000, Loss: 0.00783290434628725\n",
      "Iteration: 9590/10000, Loss: 0.005921398755162954\n",
      "Iteration: 9591/10000, Loss: 0.010315882042050362\n",
      "Iteration: 9592/10000, Loss: 0.009247801266610622\n",
      "Iteration: 9593/10000, Loss: 0.008032810874283314\n",
      "Iteration: 9594/10000, Loss: 0.007123123854398727\n",
      "Iteration: 9595/10000, Loss: 0.00730455806478858\n",
      "Iteration: 9596/10000, Loss: 0.008056179620325565\n",
      "Iteration: 9597/10000, Loss: 0.009884020313620567\n",
      "Iteration: 9598/10000, Loss: 0.009461150504648685\n",
      "Iteration: 9599/10000, Loss: 0.009566214866936207\n",
      "Iteration: 9600/10000, Loss: 0.00911558698862791\n",
      "Average test loss:  0.0038\n",
      "Iteration: 9601/10000, Loss: 0.007240518927574158\n",
      "Iteration: 9602/10000, Loss: 0.012960541993379593\n",
      "Iteration: 9603/10000, Loss: 0.00992313027381897\n",
      "Iteration: 9604/10000, Loss: 0.007388125639408827\n",
      "Iteration: 9605/10000, Loss: 0.007091735024005175\n",
      "Iteration: 9606/10000, Loss: 0.009306398220360279\n",
      "Iteration: 9607/10000, Loss: 0.00699170958250761\n",
      "Iteration: 9608/10000, Loss: 0.009154514409601688\n",
      "Iteration: 9609/10000, Loss: 0.00950534176081419\n",
      "Iteration: 9610/10000, Loss: 0.008890272118151188\n",
      "Iteration: 9611/10000, Loss: 0.008470922708511353\n",
      "Iteration: 9612/10000, Loss: 0.008002424612641335\n",
      "Iteration: 9613/10000, Loss: 0.01026992779225111\n",
      "Iteration: 9614/10000, Loss: 0.007085478398948908\n",
      "Iteration: 9615/10000, Loss: 0.00618192832916975\n",
      "Iteration: 9616/10000, Loss: 0.008128381334245205\n",
      "Iteration: 9617/10000, Loss: 0.007814081385731697\n",
      "Iteration: 9618/10000, Loss: 0.011393385007977486\n",
      "Iteration: 9619/10000, Loss: 0.009222378022968769\n",
      "Iteration: 9620/10000, Loss: 0.006743797566741705\n",
      "Iteration: 9621/10000, Loss: 0.00797772966325283\n",
      "Iteration: 9622/10000, Loss: 0.011032056994736195\n",
      "Iteration: 9623/10000, Loss: 0.006622261367738247\n",
      "Iteration: 9624/10000, Loss: 0.007967187091708183\n",
      "Iteration: 9625/10000, Loss: 0.007787173148244619\n",
      "Iteration: 9626/10000, Loss: 0.010438967496156693\n",
      "Iteration: 9627/10000, Loss: 0.010457256808876991\n",
      "Iteration: 9628/10000, Loss: 0.009825780056416988\n",
      "Iteration: 9629/10000, Loss: 0.010980343446135521\n",
      "Iteration: 9630/10000, Loss: 0.00898744910955429\n",
      "Iteration: 9631/10000, Loss: 0.009573872201144695\n",
      "Iteration: 9632/10000, Loss: 0.011450188234448433\n",
      "Iteration: 9633/10000, Loss: 0.005281528457999229\n",
      "Iteration: 9634/10000, Loss: 0.012013458646833897\n",
      "Iteration: 9635/10000, Loss: 0.005152990110218525\n",
      "Iteration: 9636/10000, Loss: 0.007259759586304426\n",
      "Iteration: 9637/10000, Loss: 0.004918989259749651\n",
      "Iteration: 9638/10000, Loss: 0.014615092426538467\n",
      "Iteration: 9639/10000, Loss: 0.010167762637138367\n",
      "Iteration: 9640/10000, Loss: 0.011944375932216644\n",
      "Iteration: 9641/10000, Loss: 0.010438187047839165\n",
      "Iteration: 9642/10000, Loss: 0.009903567843139172\n",
      "Iteration: 9643/10000, Loss: 0.007334982976317406\n",
      "Iteration: 9644/10000, Loss: 0.008561390452086926\n",
      "Iteration: 9645/10000, Loss: 0.007847030647099018\n",
      "Iteration: 9646/10000, Loss: 0.007883531972765923\n",
      "Iteration: 9647/10000, Loss: 0.006468505132943392\n",
      "Iteration: 9648/10000, Loss: 0.005308378487825394\n",
      "Iteration: 9649/10000, Loss: 0.006843469105660915\n",
      "Iteration: 9650/10000, Loss: 0.009591791778802872\n",
      "Iteration: 9651/10000, Loss: 0.011694583110511303\n",
      "Iteration: 9652/10000, Loss: 0.008210884407162666\n",
      "Iteration: 9653/10000, Loss: 0.008360877633094788\n",
      "Iteration: 9654/10000, Loss: 0.013841351494193077\n",
      "Iteration: 9655/10000, Loss: 0.00839036051183939\n",
      "Iteration: 9656/10000, Loss: 0.008900766260921955\n",
      "Iteration: 9657/10000, Loss: 0.00925525464117527\n",
      "Iteration: 9658/10000, Loss: 0.008361130021512508\n",
      "Iteration: 9659/10000, Loss: 0.010005556046962738\n",
      "Iteration: 9660/10000, Loss: 0.009285512380301952\n",
      "Iteration: 9661/10000, Loss: 0.006034854333847761\n",
      "Iteration: 9662/10000, Loss: 0.009083522483706474\n",
      "Iteration: 9663/10000, Loss: 0.00792204774916172\n",
      "Iteration: 9664/10000, Loss: 0.008215030655264854\n",
      "Iteration: 9665/10000, Loss: 0.0074926381930708885\n",
      "Iteration: 9666/10000, Loss: 0.00560419075191021\n",
      "Iteration: 9667/10000, Loss: 0.008464433252811432\n",
      "Iteration: 9668/10000, Loss: 0.005734024103730917\n",
      "Iteration: 9669/10000, Loss: 0.013222257606685162\n",
      "Iteration: 9670/10000, Loss: 0.007566762622445822\n",
      "Iteration: 9671/10000, Loss: 0.011532817035913467\n",
      "Iteration: 9672/10000, Loss: 0.009049493819475174\n",
      "Iteration: 9673/10000, Loss: 0.009131206199526787\n",
      "Iteration: 9674/10000, Loss: 0.008679435588419437\n",
      "Iteration: 9675/10000, Loss: 0.006665060296654701\n",
      "Iteration: 9676/10000, Loss: 0.010690920054912567\n",
      "Iteration: 9677/10000, Loss: 0.010481796227395535\n",
      "Iteration: 9678/10000, Loss: 0.007665617391467094\n",
      "Iteration: 9679/10000, Loss: 0.008692242205142975\n",
      "Iteration: 9680/10000, Loss: 0.00618514372035861\n",
      "Iteration: 9681/10000, Loss: 0.010433432646095753\n",
      "Iteration: 9682/10000, Loss: 0.004058212041854858\n",
      "Iteration: 9683/10000, Loss: 0.007848838344216347\n",
      "Iteration: 9684/10000, Loss: 0.009432176128029823\n",
      "Iteration: 9685/10000, Loss: 0.008078292943537235\n",
      "Iteration: 9686/10000, Loss: 0.008779270574450493\n",
      "Iteration: 9687/10000, Loss: 0.007427793927490711\n",
      "Iteration: 9688/10000, Loss: 0.008882296271622181\n",
      "Iteration: 9689/10000, Loss: 0.00711215240880847\n",
      "Iteration: 9690/10000, Loss: 0.008102173916995525\n",
      "Iteration: 9691/10000, Loss: 0.007018879987299442\n",
      "Iteration: 9692/10000, Loss: 0.006750523112714291\n",
      "Iteration: 9693/10000, Loss: 0.006089138798415661\n",
      "Iteration: 9694/10000, Loss: 0.008299517445266247\n",
      "Iteration: 9695/10000, Loss: 0.0077828834764659405\n",
      "Iteration: 9696/10000, Loss: 0.007241018116474152\n",
      "Iteration: 9697/10000, Loss: 0.006117014680057764\n",
      "Iteration: 9698/10000, Loss: 0.011126951314508915\n",
      "Iteration: 9699/10000, Loss: 0.01019594632089138\n",
      "Iteration: 9700/10000, Loss: 0.008506585843861103\n",
      "Average test loss:  0.0025\n",
      "Iteration: 9701/10000, Loss: 0.005589768290519714\n",
      "Iteration: 9702/10000, Loss: 0.0072775171138346195\n",
      "Iteration: 9703/10000, Loss: 0.007322667632251978\n",
      "Iteration: 9704/10000, Loss: 0.007514238357543945\n",
      "Iteration: 9705/10000, Loss: 0.009740810841321945\n",
      "Iteration: 9706/10000, Loss: 0.009634456597268581\n",
      "Iteration: 9707/10000, Loss: 0.008725138381123543\n",
      "Iteration: 9708/10000, Loss: 0.008006924763321877\n",
      "Iteration: 9709/10000, Loss: 0.011484063230454922\n",
      "Iteration: 9710/10000, Loss: 0.007259642705321312\n",
      "Iteration: 9711/10000, Loss: 0.006804437842220068\n",
      "Iteration: 9712/10000, Loss: 0.005240366328507662\n",
      "Iteration: 9713/10000, Loss: 0.007904996164143085\n",
      "Iteration: 9714/10000, Loss: 0.012647443450987339\n",
      "Iteration: 9715/10000, Loss: 0.00907204020768404\n",
      "Iteration: 9716/10000, Loss: 0.007857101038098335\n",
      "Iteration: 9717/10000, Loss: 0.00819916557520628\n",
      "Iteration: 9718/10000, Loss: 0.007243757601827383\n",
      "Iteration: 9719/10000, Loss: 0.006549440324306488\n",
      "Iteration: 9720/10000, Loss: 0.007961113937199116\n",
      "Iteration: 9721/10000, Loss: 0.009408880956470966\n",
      "Iteration: 9722/10000, Loss: 0.007300877943634987\n",
      "Iteration: 9723/10000, Loss: 0.005696817301213741\n",
      "Iteration: 9724/10000, Loss: 0.007237568031996489\n",
      "Iteration: 9725/10000, Loss: 0.008487740531563759\n",
      "Iteration: 9726/10000, Loss: 0.005990086123347282\n",
      "Iteration: 9727/10000, Loss: 0.00933343917131424\n",
      "Iteration: 9728/10000, Loss: 0.007703894283622503\n",
      "Iteration: 9729/10000, Loss: 0.0069417147897183895\n",
      "Iteration: 9730/10000, Loss: 0.012136751785874367\n",
      "Iteration: 9731/10000, Loss: 0.009545285254716873\n",
      "Iteration: 9732/10000, Loss: 0.00869317539036274\n",
      "Iteration: 9733/10000, Loss: 0.007205898407846689\n",
      "Iteration: 9734/10000, Loss: 0.00901089794933796\n",
      "Iteration: 9735/10000, Loss: 0.008211927488446236\n",
      "Iteration: 9736/10000, Loss: 0.010871181264519691\n",
      "Iteration: 9737/10000, Loss: 0.010450542904436588\n",
      "Iteration: 9738/10000, Loss: 0.009485986083745956\n",
      "Iteration: 9739/10000, Loss: 0.007526325061917305\n",
      "Iteration: 9740/10000, Loss: 0.009508120827376842\n",
      "Iteration: 9741/10000, Loss: 0.0066770100966095924\n",
      "Iteration: 9742/10000, Loss: 0.008548744954168797\n",
      "Iteration: 9743/10000, Loss: 0.009956621564924717\n",
      "Iteration: 9744/10000, Loss: 0.007746469229459763\n",
      "Iteration: 9745/10000, Loss: 0.005657850299030542\n",
      "Iteration: 9746/10000, Loss: 0.008878897875547409\n",
      "Iteration: 9747/10000, Loss: 0.008584248833358288\n",
      "Iteration: 9748/10000, Loss: 0.007035460788756609\n",
      "Iteration: 9749/10000, Loss: 0.006514925509691238\n",
      "Iteration: 9750/10000, Loss: 0.00574897974729538\n",
      "Iteration: 9751/10000, Loss: 0.006994310300797224\n",
      "Iteration: 9752/10000, Loss: 0.00797923281788826\n",
      "Iteration: 9753/10000, Loss: 0.00830103363841772\n",
      "Iteration: 9754/10000, Loss: 0.012265320867300034\n",
      "Iteration: 9755/10000, Loss: 0.010252577252686024\n",
      "Iteration: 9756/10000, Loss: 0.004580121953040361\n",
      "Iteration: 9757/10000, Loss: 0.008820590563118458\n",
      "Iteration: 9758/10000, Loss: 0.01024388987571001\n",
      "Iteration: 9759/10000, Loss: 0.008811453357338905\n",
      "Iteration: 9760/10000, Loss: 0.009204267524182796\n",
      "Iteration: 9761/10000, Loss: 0.006019153166562319\n",
      "Iteration: 9762/10000, Loss: 0.011495738290250301\n",
      "Iteration: 9763/10000, Loss: 0.008725997991859913\n",
      "Iteration: 9764/10000, Loss: 0.01093375962227583\n",
      "Iteration: 9765/10000, Loss: 0.011522958986461163\n",
      "Iteration: 9766/10000, Loss: 0.008836270309984684\n",
      "Iteration: 9767/10000, Loss: 0.00866179820150137\n",
      "Iteration: 9768/10000, Loss: 0.012680704705417156\n",
      "Iteration: 9769/10000, Loss: 0.0045942263677716255\n",
      "Iteration: 9770/10000, Loss: 0.008084108121693134\n",
      "Iteration: 9771/10000, Loss: 0.008008137345314026\n",
      "Iteration: 9772/10000, Loss: 0.010188649408519268\n",
      "Iteration: 9773/10000, Loss: 0.009350001811981201\n",
      "Iteration: 9774/10000, Loss: 0.008009596727788448\n",
      "Iteration: 9775/10000, Loss: 0.005710133817046881\n",
      "Iteration: 9776/10000, Loss: 0.010135541670024395\n",
      "Iteration: 9777/10000, Loss: 0.006930741015821695\n",
      "Iteration: 9778/10000, Loss: 0.008367246948182583\n",
      "Iteration: 9779/10000, Loss: 0.007093593943864107\n",
      "Iteration: 9780/10000, Loss: 0.007529388181865215\n",
      "Iteration: 9781/10000, Loss: 0.007488047704100609\n",
      "Iteration: 9782/10000, Loss: 0.00801791250705719\n",
      "Iteration: 9783/10000, Loss: 0.006360270082950592\n",
      "Iteration: 9784/10000, Loss: 0.0067642806097865105\n",
      "Iteration: 9785/10000, Loss: 0.007677328307181597\n",
      "Iteration: 9786/10000, Loss: 0.005398535635322332\n",
      "Iteration: 9787/10000, Loss: 0.006159647833555937\n",
      "Iteration: 9788/10000, Loss: 0.009007876738905907\n",
      "Iteration: 9789/10000, Loss: 0.00738513795658946\n",
      "Iteration: 9790/10000, Loss: 0.0077376095578074455\n",
      "Iteration: 9791/10000, Loss: 0.006945224013179541\n",
      "Iteration: 9792/10000, Loss: 0.009187737479805946\n",
      "Iteration: 9793/10000, Loss: 0.0057961586862802505\n",
      "Iteration: 9794/10000, Loss: 0.005053606349974871\n",
      "Iteration: 9795/10000, Loss: 0.007151106838136911\n",
      "Iteration: 9796/10000, Loss: 0.006957280449569225\n",
      "Iteration: 9797/10000, Loss: 0.007296038791537285\n",
      "Iteration: 9798/10000, Loss: 0.006943078711628914\n",
      "Iteration: 9799/10000, Loss: 0.00765325129032135\n",
      "Iteration: 9800/10000, Loss: 0.008994619362056255\n",
      "Average test loss:  0.0078\n",
      "Iteration: 9801/10000, Loss: 0.006852957885712385\n",
      "Iteration: 9802/10000, Loss: 0.01127637829631567\n",
      "Iteration: 9803/10000, Loss: 0.007579556200653315\n",
      "Iteration: 9804/10000, Loss: 0.011179457418620586\n",
      "Iteration: 9805/10000, Loss: 0.006902338471263647\n",
      "Iteration: 9806/10000, Loss: 0.008286815136671066\n",
      "Iteration: 9807/10000, Loss: 0.0064406804740428925\n",
      "Iteration: 9808/10000, Loss: 0.011171722784638405\n",
      "Iteration: 9809/10000, Loss: 0.007185462862253189\n",
      "Iteration: 9810/10000, Loss: 0.00734705850481987\n",
      "Iteration: 9811/10000, Loss: 0.009989036247134209\n",
      "Iteration: 9812/10000, Loss: 0.008680267259478569\n",
      "Iteration: 9813/10000, Loss: 0.008989003486931324\n",
      "Iteration: 9814/10000, Loss: 0.008593155071139336\n",
      "Iteration: 9815/10000, Loss: 0.007051017135381699\n",
      "Iteration: 9816/10000, Loss: 0.007330621127039194\n",
      "Iteration: 9817/10000, Loss: 0.005020541604608297\n",
      "Iteration: 9818/10000, Loss: 0.010209059342741966\n",
      "Iteration: 9819/10000, Loss: 0.0075980923138558865\n",
      "Iteration: 9820/10000, Loss: 0.008672930300235748\n",
      "Iteration: 9821/10000, Loss: 0.007070084102451801\n",
      "Iteration: 9822/10000, Loss: 0.009631132706999779\n",
      "Iteration: 9823/10000, Loss: 0.0054717944003641605\n",
      "Iteration: 9824/10000, Loss: 0.006014640908688307\n",
      "Iteration: 9825/10000, Loss: 0.009271292947232723\n",
      "Iteration: 9826/10000, Loss: 0.00942200981080532\n",
      "Iteration: 9827/10000, Loss: 0.011849598027765751\n",
      "Iteration: 9828/10000, Loss: 0.00787616241723299\n",
      "Iteration: 9829/10000, Loss: 0.0075986990705132484\n",
      "Iteration: 9830/10000, Loss: 0.007947380654513836\n",
      "Iteration: 9831/10000, Loss: 0.008994655683636665\n",
      "Iteration: 9832/10000, Loss: 0.009164861403405666\n",
      "Iteration: 9833/10000, Loss: 0.007933348417282104\n",
      "Iteration: 9834/10000, Loss: 0.00826871208846569\n",
      "Iteration: 9835/10000, Loss: 0.01086980476975441\n",
      "Iteration: 9836/10000, Loss: 0.00443818885833025\n",
      "Iteration: 9837/10000, Loss: 0.004839919973164797\n",
      "Iteration: 9838/10000, Loss: 0.0073223961517214775\n",
      "Iteration: 9839/10000, Loss: 0.0043718647211790085\n",
      "Iteration: 9840/10000, Loss: 0.005352070089429617\n",
      "Iteration: 9841/10000, Loss: 0.009754614904522896\n",
      "Iteration: 9842/10000, Loss: 0.005092266481369734\n",
      "Iteration: 9843/10000, Loss: 0.008459711447358131\n",
      "Iteration: 9844/10000, Loss: 0.009204036556184292\n",
      "Iteration: 9845/10000, Loss: 0.009755308739840984\n",
      "Iteration: 9846/10000, Loss: 0.011124609969556332\n",
      "Iteration: 9847/10000, Loss: 0.006744664162397385\n",
      "Iteration: 9848/10000, Loss: 0.008237248286604881\n",
      "Iteration: 9849/10000, Loss: 0.007226227317005396\n",
      "Iteration: 9850/10000, Loss: 0.008815575391054153\n",
      "Iteration: 9851/10000, Loss: 0.010619132779538631\n",
      "Iteration: 9852/10000, Loss: 0.008582117035984993\n",
      "Iteration: 9853/10000, Loss: 0.008969184011220932\n",
      "Iteration: 9854/10000, Loss: 0.0059227896854281425\n",
      "Iteration: 9855/10000, Loss: 0.0050404248759150505\n",
      "Iteration: 9856/10000, Loss: 0.009615921415388584\n",
      "Iteration: 9857/10000, Loss: 0.005600349046289921\n",
      "Iteration: 9858/10000, Loss: 0.0056166579015553\n",
      "Iteration: 9859/10000, Loss: 0.00812129769474268\n",
      "Iteration: 9860/10000, Loss: 0.007475290913134813\n",
      "Iteration: 9861/10000, Loss: 0.011464017443358898\n",
      "Iteration: 9862/10000, Loss: 0.010357673279941082\n",
      "Iteration: 9863/10000, Loss: 0.005814298987388611\n",
      "Iteration: 9864/10000, Loss: 0.0052724615670740604\n",
      "Iteration: 9865/10000, Loss: 0.008687143214046955\n",
      "Iteration: 9866/10000, Loss: 0.009046814404428005\n",
      "Iteration: 9867/10000, Loss: 0.006656171288341284\n",
      "Iteration: 9868/10000, Loss: 0.008317542262375355\n",
      "Iteration: 9869/10000, Loss: 0.010277469642460346\n",
      "Iteration: 9870/10000, Loss: 0.007076720241457224\n",
      "Iteration: 9871/10000, Loss: 0.008476432412862778\n",
      "Iteration: 9872/10000, Loss: 0.005678876768797636\n",
      "Iteration: 9873/10000, Loss: 0.008311910554766655\n",
      "Iteration: 9874/10000, Loss: 0.006728603504598141\n",
      "Iteration: 9875/10000, Loss: 0.015494659543037415\n",
      "Iteration: 9876/10000, Loss: 0.00915366131812334\n",
      "Iteration: 9877/10000, Loss: 0.006786045618355274\n",
      "Iteration: 9878/10000, Loss: 0.009510944597423077\n",
      "Iteration: 9879/10000, Loss: 0.007245943881571293\n",
      "Iteration: 9880/10000, Loss: 0.010672304779291153\n",
      "Iteration: 9881/10000, Loss: 0.007836200296878815\n",
      "Iteration: 9882/10000, Loss: 0.007954026572406292\n",
      "Iteration: 9883/10000, Loss: 0.007696936372667551\n",
      "Iteration: 9884/10000, Loss: 0.009795399382710457\n",
      "Iteration: 9885/10000, Loss: 0.008465216495096684\n",
      "Iteration: 9886/10000, Loss: 0.009304406121373177\n",
      "Iteration: 9887/10000, Loss: 0.008817506022751331\n",
      "Iteration: 9888/10000, Loss: 0.006541441194713116\n",
      "Iteration: 9889/10000, Loss: 0.006532625760883093\n",
      "Iteration: 9890/10000, Loss: 0.009524330496788025\n",
      "Iteration: 9891/10000, Loss: 0.007832597941160202\n",
      "Iteration: 9892/10000, Loss: 0.008481064811348915\n",
      "Iteration: 9893/10000, Loss: 0.006985187530517578\n",
      "Iteration: 9894/10000, Loss: 0.008197762072086334\n",
      "Iteration: 9895/10000, Loss: 0.012696128338575363\n",
      "Iteration: 9896/10000, Loss: 0.005870259832590818\n",
      "Iteration: 9897/10000, Loss: 0.009156712330877781\n",
      "Iteration: 9898/10000, Loss: 0.01185328047722578\n",
      "Iteration: 9899/10000, Loss: 0.008383361622691154\n",
      "Iteration: 9900/10000, Loss: 0.006406852975487709\n",
      "Average test loss:  0.0046\n",
      "Iteration: 9901/10000, Loss: 0.006997410673648119\n",
      "Iteration: 9902/10000, Loss: 0.00637213746085763\n",
      "Iteration: 9903/10000, Loss: 0.007445445284247398\n",
      "Iteration: 9904/10000, Loss: 0.010015107691287994\n",
      "Iteration: 9905/10000, Loss: 0.005013071000576019\n",
      "Iteration: 9906/10000, Loss: 0.007648838683962822\n",
      "Iteration: 9907/10000, Loss: 0.011490993201732635\n",
      "Iteration: 9908/10000, Loss: 0.0062785460613667965\n",
      "Iteration: 9909/10000, Loss: 0.008805651217699051\n",
      "Iteration: 9910/10000, Loss: 0.008572491817176342\n",
      "Iteration: 9911/10000, Loss: 0.007077848073095083\n",
      "Iteration: 9912/10000, Loss: 0.00888015702366829\n",
      "Iteration: 9913/10000, Loss: 0.007855009287595749\n",
      "Iteration: 9914/10000, Loss: 0.0066513363271951675\n",
      "Iteration: 9915/10000, Loss: 0.009728030301630497\n",
      "Iteration: 9916/10000, Loss: 0.010879302397370338\n",
      "Iteration: 9917/10000, Loss: 0.005142753012478352\n",
      "Iteration: 9918/10000, Loss: 0.011285615153610706\n",
      "Iteration: 9919/10000, Loss: 0.008306735195219517\n",
      "Iteration: 9920/10000, Loss: 0.006210725754499435\n",
      "Iteration: 9921/10000, Loss: 0.00817245151847601\n",
      "Iteration: 9922/10000, Loss: 0.008192179724574089\n",
      "Iteration: 9923/10000, Loss: 0.009630120359361172\n",
      "Iteration: 9924/10000, Loss: 0.00843365490436554\n",
      "Iteration: 9925/10000, Loss: 0.008396395482122898\n",
      "Iteration: 9926/10000, Loss: 0.008899702690541744\n",
      "Iteration: 9927/10000, Loss: 0.008099468424916267\n",
      "Iteration: 9928/10000, Loss: 0.007268326357007027\n",
      "Iteration: 9929/10000, Loss: 0.008001605048775673\n",
      "Iteration: 9930/10000, Loss: 0.006632251664996147\n",
      "Iteration: 9931/10000, Loss: 0.008802344091236591\n",
      "Iteration: 9932/10000, Loss: 0.008358809165656567\n",
      "Iteration: 9933/10000, Loss: 0.012124060653150082\n",
      "Iteration: 9934/10000, Loss: 0.008850738406181335\n",
      "Iteration: 9935/10000, Loss: 0.011138305068016052\n",
      "Iteration: 9936/10000, Loss: 0.010691859759390354\n",
      "Iteration: 9937/10000, Loss: 0.007401377893984318\n",
      "Iteration: 9938/10000, Loss: 0.006963629741221666\n",
      "Iteration: 9939/10000, Loss: 0.014018243178725243\n",
      "Iteration: 9940/10000, Loss: 0.005183128174394369\n",
      "Iteration: 9941/10000, Loss: 0.006405448075383902\n",
      "Iteration: 9942/10000, Loss: 0.00574951758608222\n",
      "Iteration: 9943/10000, Loss: 0.008565302938222885\n",
      "Iteration: 9944/10000, Loss: 0.005577457137405872\n",
      "Iteration: 9945/10000, Loss: 0.0075775994919240475\n",
      "Iteration: 9946/10000, Loss: 0.007795921992510557\n",
      "Iteration: 9947/10000, Loss: 0.0069533768109977245\n",
      "Iteration: 9948/10000, Loss: 0.007061308715492487\n",
      "Iteration: 9949/10000, Loss: 0.004760111216455698\n",
      "Iteration: 9950/10000, Loss: 0.005123731214553118\n",
      "Iteration: 9951/10000, Loss: 0.006456503178924322\n",
      "Iteration: 9952/10000, Loss: 0.007875414565205574\n",
      "Iteration: 9953/10000, Loss: 0.00932395737618208\n",
      "Iteration: 9954/10000, Loss: 0.010650335811078548\n",
      "Iteration: 9955/10000, Loss: 0.006659785285592079\n",
      "Iteration: 9956/10000, Loss: 0.010226060636341572\n",
      "Iteration: 9957/10000, Loss: 0.009190394543111324\n",
      "Iteration: 9958/10000, Loss: 0.01259548868983984\n",
      "Iteration: 9959/10000, Loss: 0.006049822084605694\n",
      "Iteration: 9960/10000, Loss: 0.012103218585252762\n",
      "Iteration: 9961/10000, Loss: 0.005966678727418184\n",
      "Iteration: 9962/10000, Loss: 0.009511267766356468\n",
      "Iteration: 9963/10000, Loss: 0.004852364771068096\n",
      "Iteration: 9964/10000, Loss: 0.006256002467125654\n",
      "Iteration: 9965/10000, Loss: 0.010755840688943863\n",
      "Iteration: 9966/10000, Loss: 0.0068376497365534306\n",
      "Iteration: 9967/10000, Loss: 0.005451094824820757\n",
      "Iteration: 9968/10000, Loss: 0.006453117821365595\n",
      "Iteration: 9969/10000, Loss: 0.008609510958194733\n",
      "Iteration: 9970/10000, Loss: 0.009057930670678616\n",
      "Iteration: 9971/10000, Loss: 0.008246512152254581\n",
      "Iteration: 9972/10000, Loss: 0.00891279336065054\n",
      "Iteration: 9973/10000, Loss: 0.0075820209458470345\n",
      "Iteration: 9974/10000, Loss: 0.007959465496242046\n",
      "Iteration: 9975/10000, Loss: 0.006947506219148636\n",
      "Iteration: 9976/10000, Loss: 0.010264066979289055\n",
      "Iteration: 9977/10000, Loss: 0.010118084028363228\n",
      "Iteration: 9978/10000, Loss: 0.009384500794112682\n",
      "Iteration: 9979/10000, Loss: 0.00779834995046258\n",
      "Iteration: 9980/10000, Loss: 0.007103768642991781\n",
      "Iteration: 9981/10000, Loss: 0.009539796970784664\n",
      "Iteration: 9982/10000, Loss: 0.008800624869763851\n",
      "Iteration: 9983/10000, Loss: 0.010955826379358768\n",
      "Iteration: 9984/10000, Loss: 0.006219472736120224\n",
      "Iteration: 9985/10000, Loss: 0.006613932549953461\n",
      "Iteration: 9986/10000, Loss: 0.008549793623387814\n",
      "Iteration: 9987/10000, Loss: 0.008996226824820042\n",
      "Iteration: 9988/10000, Loss: 0.008643683977425098\n",
      "Iteration: 9989/10000, Loss: 0.00588093139231205\n",
      "Iteration: 9990/10000, Loss: 0.00946455355733633\n",
      "Iteration: 9991/10000, Loss: 0.007350636180490255\n",
      "Iteration: 9992/10000, Loss: 0.008275498636066914\n",
      "Iteration: 9993/10000, Loss: 0.008564873598515987\n",
      "Iteration: 9994/10000, Loss: 0.008160789497196674\n",
      "Iteration: 9995/10000, Loss: 0.008284279145300388\n",
      "Iteration: 9996/10000, Loss: 0.010296797379851341\n",
      "Iteration: 9997/10000, Loss: 0.007259031757712364\n",
      "Iteration: 9998/10000, Loss: 0.00829326268285513\n",
      "Iteration: 9999/10000, Loss: 0.00452561816200614\n",
      "Iteration: 10000/10000, Loss: 0.009573381394147873\n",
      "Average test loss:  0.0031\n",
      "Training took 244.578s in total.\n"
     ]
    }
   ],
   "source": [
    "# CUDA device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {0}'.format(device))\n",
    "\n",
    "# Build the model\n",
    "num_class = 4\n",
    "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
    "model = model.to(device)\n",
    "params = list(model.parameters())\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "# Segmentation loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Datasets\n",
    "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
    "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
    "\n",
    "# Train the model\n",
    "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
    "num_iter = 10000\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "start = time.time()\n",
    "for it in range(1, 1 + num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = train_set.get_random_batch(train_batch_size)\n",
    "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    logits = model(images)\n",
    "\n",
    "\n",
    "    # Perform optimisation and print out the training loss\n",
    "    ### Insert your code ###\n",
    "    optimizer.zero_grad()  # Clear the gradients\n",
    "    loss = criterion(logits, labels)  # Calculate the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update the model parameters\n",
    "\n",
    "    print(f'Iteration: {it}/{num_iter}, Loss: {loss.item()}')\n",
    "    ### End of your code ###\n",
    "\n",
    "    # Evaluate\n",
    "    if it % 100 == 0:\n",
    "        model.eval()\n",
    "        # Disabling gradient calculation during reference to reduce memory consumption\n",
    "        with torch.no_grad():\n",
    "            # Evaluate on a batch of test images and print out the test loss\n",
    "            ### Insert your code ###\n",
    "            total_loss = 0\n",
    "            input_images, real_labels = test_set.get_random_batch(eval_batch_size)\n",
    "            input_images, real_labels = torch.from_numpy(input_images), torch.from_numpy(real_labels)\n",
    "            input_images, real_labels = input_images.to(device, dtype=torch.float32), real_labels.to(device, dtype=torch.long)\n",
    "            outputs = model(input_images)\n",
    "            \n",
    "            loss = criterion(outputs, real_labels)\n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / eval_batch_size\n",
    "            \n",
    "            print(f\"Average test loss: {avg_loss: .4f}\")\n",
    "            \n",
    "            \n",
    "            ### End of your code ###\n",
    "\n",
    "    # Save the model\n",
    "    if it % 5000 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yjxjGyb6yT"
   },
   "source": [
    "## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
    "\n",
    "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wZeLE0qZjd2j"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "deploy_size = 4\n",
    "img_dim = (120, 120)\n",
    "\n",
    "model.eval()\n",
    "## Get a random set of 4 test images\n",
    "test_images, test_labels = test_set.get_random_batch(deploy_size)\n",
    "d_test_images = torch.from_numpy(test_images).to(device, dtype=torch.float32)\n",
    "\n",
    "## Perform inference on the test images\n",
    "outputs = model(d_test_images)\n",
    "predicted_labels = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "## Visualize the test images, automated segmentation, and ground truth segmentation\n",
    "fig, grid = plt.subplots(deploy_size, 3, figsize=(10, 10))\n",
    "\n",
    "## Add titles\n",
    "titles = [\"Test Image\", \"Auto Segmentation\", \"Ground Truth Segmentation\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(grid[0], titles)]\n",
    "\n",
    "for i in range(deploy_size):\n",
    "    grid[i, 0].imshow(test_images[i, 0], cmap=cmap_image)\n",
    "    grid[i, 0].axis('off')\n",
    "\n",
    "    grid[i, 1].imshow(predicted_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 1].axis('off')\n",
    "\n",
    "    grid[i, 2].imshow(test_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "\n",
    "### End of your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj3Qusin_s_r"
   },
   "source": [
    "## 6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Does your trained model work well?**\n",
    "To be able to comment on these there are few factors we need to consider. Big part that plays into this is the models performance, in terms of the average loss the model performs pretty well (0.0031) However, to comment on the full performance we should also bring in other metrics such as precision, recall and even evaluate the F1 score to get a better idea of the model.\n",
    "\n",
    "#### **How would you improve this model...**\n",
    "In terms of improvements, we can use a more complex or deeper convolutional neural network that can extract and 'learn' more information about the training data set and leverage that to be a better image segmentator. On top of this we can tune other hyperparameeters such as batch sizes or the number of convolutional steps (increase n to be more than 128 ...) .\n",
    "\n",
    "There can also be some data set improvements such as balancing our data set (not sure if this one is or not) but addressing a possible inbalanace will result in a more performant model. We should also  augment the data inputting into the modelby transforming the input data by: rotating, resizing, mirroring ... so the overall robustness of the model can be increased and it will perform better with real life data.\n",
    "\n",
    "Finally we can regularly test and evaluate the model so that we can make small adjustments or improvements to keep the model performant and robust.\n",
    "\n",
    "\n",
    "#### **...so it can deployed to a real clinic?**\n",
    "\n",
    "I think the most obvious first step would be to give some sort of meaning to this segmentation. Right now some colours are shown \n",
    "and whoever is interacting with this needs to be able to quickly understand what they are looking at. \n",
    "\n",
    "A really important second point is to have some sort of expert validation of these results beyond the testing of the model, so that we can be sure the model is aligning with what the medical professionals are expecting.\n",
    "\n",
    "Then, continuing on from the final point above, we need to be able to keep the model current. It cannot be trained then left alone as more data will become available over its lifespan and can be used to train and make the mdoel more robust.\n",
    "\n",
    "And finally, as any real system getting deployed it needs to have security measures and backups. Security is extra important as personal medical information is quite a sensitive piece of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
