{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "# Coursework 2: Image segmentation\n",
    "\n",
    "In this coursework you will develop and train a convolutional neural network for brain tumour image segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
    "\n",
    "```\n",
    "### Insert your code ###\n",
    "...\n",
    "### End of your code ###\n",
    "```\n",
    "\n",
    "## What to do?\n",
    "\n",
    "* Complete and run the code using `jupyter-lab` or `jupyter-notebook` to get the results.\n",
    "\n",
    "* Export (File | S'ave and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
    "\n",
    "* Instead of clicking the Export button, you can also run the following command instead: `jupyter nbconvert coursework.ipynb --to pdf`\n",
    "\n",
    "* If Jupyter complains about some problems in exporting, it is likely that pandoc (https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry.\n",
    "\n",
    "* If Jupyter-lab does not work for you at the end, you can use Google Colab to write the code and export the PDF file.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
    "`pip3 install [package_name]`\n",
    "\n",
    "## GPU resource\n",
    "\n",
    "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
    "\n",
    "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this tutorial.\n",
    "# However, if any other library is needed, please install by yourself.\n",
    "import tarfile\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## 1. Download and visualise the imaging dataset.\n",
    "\n",
    "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
    "\n",
    "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
    "\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mt93oQ8xZkE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 16:49:45--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6020:18::a27d:4012\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz [following]\n",
      "--2024-02-26 16:49:45--  https://www.dropbox.com/s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com/cd/0/inline/COCr5BGNvKeq-6JD4IpZZrqI7pDeb0Qmu-RKlNJKUeRnQFEaej4jyMAr1tmARrM8rpSfozbfrr9gVpznWWpM-Ed9leUeRVKZOAeKmR_V20oK-MUSvGFIcCayKpTw2mgJjiw/file# [following]\n",
      "--2024-02-26 16:49:46--  https://ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com/cd/0/inline/COCr5BGNvKeq-6JD4IpZZrqI7pDeb0Qmu-RKlNJKUeRnQFEaej4jyMAr1tmARrM8rpSfozbfrr9gVpznWWpM-Ed9leUeRVKZOAeKmR_V20oK-MUSvGFIcCayKpTw2mgJjiw/file\n",
      "Resolving ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com (ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n",
      "Connecting to ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com (ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/COC0QsUGXkOkXYyvBCOlleKjTV-JSrUvEWgPQPWQYlBhnGhR7jRU7RO3P-YXATlMELC5gb-fzJ9qP_iL7dTti-3yiBnBhQWfmIBwVcsdNmtUkWybpFSeX8T2qa1oTI5SA2BwCmfL7YHBcBSCvn5Z9f_SIni9TtL5AubRW54QOBewVMDfPoh3CmcZ7_jcJ2DSE4-z-YjJgpUiYEC573qdyTv5-3eAqlSFZ4lviQ_hTcqSkpvjlSgWQKX51zbb0yW3VMvtMvIchFT77G4E-ZWXdGv1Lng8pJ8YE1gSrJ4-u7g2ucS4sTZROzz_gg0NloY7sTmmOpoJZg_VT9RNczusKmD3Ry7KcKpK9aVVO7od9jxtiA/file [following]\n",
      "--2024-02-26 16:49:47--  https://ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com/cd/0/inline2/COC0QsUGXkOkXYyvBCOlleKjTV-JSrUvEWgPQPWQYlBhnGhR7jRU7RO3P-YXATlMELC5gb-fzJ9qP_iL7dTti-3yiBnBhQWfmIBwVcsdNmtUkWybpFSeX8T2qa1oTI5SA2BwCmfL7YHBcBSCvn5Z9f_SIni9TtL5AubRW54QOBewVMDfPoh3CmcZ7_jcJ2DSE4-z-YjJgpUiYEC573qdyTv5-3eAqlSFZ4lviQ_hTcqSkpvjlSgWQKX51zbb0yW3VMvtMvIchFT77G4E-ZWXdGv1Lng8pJ8YE1gSrJ4-u7g2ucS4sTZROzz_gg0NloY7sTmmOpoJZg_VT9RNczusKmD3Ry7KcKpK9aVVO7od9jxtiA/file\n",
      "Reusing existing connection to ucf85af04018d338be0c68a56a39.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9251149 (8.8M) [application/octet-stream]\n",
      "Saving to: ‘Task01_BrainTumour_2D.tar.gz.2’\n",
      "\n",
      "Task01_BrainTumour_ 100%[===================>]   8.82M  27.6MB/s    in 0.3s    \n",
      "\n",
      "2024-02-26 16:49:47 (27.6 MB/s) - ‘Task01_BrainTumour_2D.tar.gz.2’ saved [9251149/9251149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
    "\n",
    "# Unzip the '.tar.gz' file to the current directory\n",
    "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
    "datafile.extractall()\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu_BTL0x6o5a"
   },
   "source": [
    "## Visualise a random set of 4 training images along with their label maps.\n",
    "\n",
    "Suggested colour map for brain MR image:\n",
    "```\n",
    "cmap = 'gray'\n",
    "```\n",
    "\n",
    "Suggested colour map for segmentation map:\n",
    "```\n",
    "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3fgubCRC6m4k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16161/276553290.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(training_img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "cmap_image = \"gray\"\n",
    "cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "\n",
    "zs = [46, 62, 77, 93, 108, 124]\n",
    "IMAGES_FROM = 1\n",
    "IMAGES_TO = 483\n",
    "from random import randint\n",
    "from random import choice\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "\n",
    "# figure = plt.figure(figsize = (4, 2))\n",
    "# img_grid = ImageGrid(figure, 111, nrows_ncols = (4, 2), axes_pad =3)\n",
    "figure, img_grid = plt.subplots(nrows=4, ncols=2, figsize = (5, 10))\n",
    "\n",
    "titles = [\"Training Image\", \"Label\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(img_grid[0], titles)]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"./Task01_BrainTumour_2D/training_images/\", topdown = False):\n",
    "  chosen = []\n",
    "  for _ in range(4):\n",
    "    chosen.append(choice(files))\n",
    "\n",
    "path = \"Task01_BrainTumour_2D\"\n",
    "training_path = \"training_images\"\n",
    "label_path = \"training_labels\"\n",
    "\n",
    "for i, img_path in enumerate(chosen):\n",
    "  training_img_path = f\"{path}/{training_path}/{img_path}\"\n",
    "  label_img_path = f\"{path}/{label_path}/{img_path}\"\n",
    "  \n",
    "  ## Training Image\n",
    "  img = imageio.imread(training_img_path)\n",
    "  img_grid[i, 0].imshow(img, cmap = cmap_image)\n",
    "  img_grid[i, 0].axis(\"off\")\n",
    "  \n",
    "  ## Label Map\n",
    "  label_img= imageio.v3.imread(label_img_path)\n",
    "  \n",
    "  img_grid[i, 1].imshow(label_img, cmap = cmap_segmentation)\n",
    "  img_grid[i, 1].axis(\"off\")\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xWGT3KaML-D"
   },
   "source": [
    "## 2. Implement a dataset class.\n",
    "\n",
    "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6p6wFZ3na5z9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalise_intensity(image, thres_roi=1.0):\n",
    "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
    "    # ROI defines the image foreground\n",
    "    val_l = np.percentile(image, thres_roi)\n",
    "    roi = (image >= val_l)\n",
    "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
    "    eps = 1e-6\n",
    "    image2 = (image - mu) / (sigma + eps)\n",
    "    return image2\n",
    "\n",
    "\n",
    "class BrainImageSet(Dataset):\n",
    "    \"\"\" Brain image set \"\"\"\n",
    "    def __init__(self, image_path, label_path='', deploy=False):\n",
    "        self.image_path = image_path\n",
    "        self.deploy = deploy\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        image_names = sorted(os.listdir(image_path))\n",
    "        for image_name in image_names:\n",
    "            # Read the image\n",
    "            image = imageio.v3.imread(os.path.join(image_path, image_name))\n",
    "            self.images += [image]\n",
    "\n",
    "            # Read the label map\n",
    "            if not self.deploy:\n",
    "                label_name = os.path.join(label_path, image_name)\n",
    "                label = imageio.v3.imread(label_name)\n",
    "                self.labels += [label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get an image and perform intensity normalisation\n",
    "        # Dimension: XY\n",
    "        image = normalise_intensity(self.images[idx])\n",
    "\n",
    "        # Get its label map\n",
    "        # Dimension: XY\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_random_batch(self, batch_size):\n",
    "        # Get a batch of paired images and label maps\n",
    "        # Dimension of images: NCXY\n",
    "        # Dimension of labels: NXY\n",
    "        images, labels = [], []\n",
    "        \n",
    "        ### Insert your code ###\n",
    "        \n",
    "        # seed = np.random.default_rng().integers(low=0, high=2048) # arbitratry range can be changed\n",
    "        indices = np.random.randint(0, len(self), batch_size)\n",
    "        \n",
    "        for i in indices:\n",
    "          i, l = self[i]\n",
    "          images.append(i)\n",
    "          labels.append(l)\n",
    "        \n",
    "        \n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        ## add the greyscale colour channel so conv2d works correctly\n",
    "        images = np.reshape(images, (batch_size, 1, images.shape[1], images.shape[2])) \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "        ### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4ZpawDNmwu"
   },
   "source": [
    "## 3. Build a U-net architecture.\n",
    "\n",
    "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
    "\n",
    "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
    "\n",
    "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "IMPmBZVGb1aI"
   },
   "outputs": [],
   "source": [
    "\"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        ### Insert your code ###\n",
    "        n //= 2 # 64\n",
    "        self.upconv5 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 128 -> 64 ch (x2 dims)\n",
    "        self.conv5 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        n //= 2 # 32\n",
    "        self.upconv6 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2 ) # 64 -> 32 ch (x2 dims)\n",
    "        self.conv6 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        n //= 2 # 16\n",
    "        self.upconv7 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 32 -> 16 ch (x2 dims)\n",
    "        self.conv7 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2 , n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, output_channel, kernel_size=1) ## final 1x1 conv\n",
    "        )\n",
    "        ### End of your code ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the convolutional operators defined above to build the U-net\n",
    "        # The encoder part is already done for you.\n",
    "        # You need to complete the decoder part.\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        conv1_skip = x\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        conv2_skip = x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        conv3_skip = x\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Decoder\n",
    "        ### Insert your code ###\n",
    "        x = self.conv5(torch.cat([self.upconv5(x), conv3_skip], dim=1))\n",
    "        \n",
    "        x = self.conv6(torch.cat([self.upconv6(x), conv2_skip], dim=1))\n",
    "        \n",
    "        x = self.conv7(torch.cat([self.upconv7(x), conv1_skip], dim=1))\n",
    "        \n",
    "        ### End of your code ###\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcNWZS08d47P"
   },
   "source": [
    "## 4. Train the segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xaGGkKQndIaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Iteration: 1/10000, Loss: 1.2743040323257446\n",
      "Iteration: 2/10000, Loss: 1.210796594619751\n",
      "Iteration: 3/10000, Loss: 1.1650866270065308\n",
      "Iteration: 4/10000, Loss: 1.132899522781372\n",
      "Iteration: 5/10000, Loss: 1.1023021936416626\n",
      "Iteration: 6/10000, Loss: 1.0788320302963257\n",
      "Iteration: 7/10000, Loss: 1.0628032684326172\n",
      "Iteration: 8/10000, Loss: 1.039315104484558\n",
      "Iteration: 9/10000, Loss: 1.0210868120193481\n",
      "Iteration: 10/10000, Loss: 1.000687837600708\n",
      "Iteration: 11/10000, Loss: 0.9852638840675354\n",
      "Iteration: 12/10000, Loss: 0.9874458312988281\n",
      "Iteration: 13/10000, Loss: 0.9534912109375\n",
      "Iteration: 14/10000, Loss: 0.9517220258712769\n",
      "Iteration: 15/10000, Loss: 0.9274937510490417\n",
      "Iteration: 16/10000, Loss: 0.9112583994865417\n",
      "Iteration: 17/10000, Loss: 0.9110313057899475\n",
      "Iteration: 18/10000, Loss: 0.9127932190895081\n",
      "Iteration: 19/10000, Loss: 0.8892919421195984\n",
      "Iteration: 20/10000, Loss: 0.8679654002189636\n",
      "Iteration: 21/10000, Loss: 0.8734094500541687\n",
      "Iteration: 22/10000, Loss: 0.858411431312561\n",
      "Iteration: 23/10000, Loss: 0.8381189703941345\n",
      "Iteration: 24/10000, Loss: 0.8365164995193481\n",
      "Iteration: 25/10000, Loss: 0.8148864507675171\n",
      "Iteration: 26/10000, Loss: 0.8430848717689514\n",
      "Iteration: 27/10000, Loss: 0.8480170965194702\n",
      "Iteration: 28/10000, Loss: 0.8124983906745911\n",
      "Iteration: 29/10000, Loss: 0.8034261465072632\n",
      "Iteration: 30/10000, Loss: 0.8100683689117432\n",
      "Iteration: 31/10000, Loss: 0.8031808137893677\n",
      "Iteration: 32/10000, Loss: 0.7884664535522461\n",
      "Iteration: 33/10000, Loss: 0.7818186283111572\n",
      "Iteration: 34/10000, Loss: 0.7825853228569031\n",
      "Iteration: 35/10000, Loss: 0.7620874643325806\n",
      "Iteration: 36/10000, Loss: 0.7551073431968689\n",
      "Iteration: 37/10000, Loss: 0.7520285248756409\n",
      "Iteration: 38/10000, Loss: 0.7498886585235596\n",
      "Iteration: 39/10000, Loss: 0.7381588816642761\n",
      "Iteration: 40/10000, Loss: 0.7398214340209961\n",
      "Iteration: 41/10000, Loss: 0.7364550828933716\n",
      "Iteration: 42/10000, Loss: 0.7241328954696655\n",
      "Iteration: 43/10000, Loss: 0.7073807120323181\n",
      "Iteration: 44/10000, Loss: 0.7281168103218079\n",
      "Iteration: 45/10000, Loss: 0.7052101492881775\n",
      "Iteration: 46/10000, Loss: 0.6886699795722961\n",
      "Iteration: 47/10000, Loss: 0.6909261345863342\n",
      "Iteration: 48/10000, Loss: 0.6857137084007263\n",
      "Iteration: 49/10000, Loss: 0.6741491556167603\n",
      "Iteration: 50/10000, Loss: 0.6634408831596375\n",
      "Iteration: 51/10000, Loss: 0.6549241542816162\n",
      "Iteration: 52/10000, Loss: 0.6501219868659973\n",
      "Iteration: 53/10000, Loss: 0.6438536643981934\n",
      "Iteration: 54/10000, Loss: 0.639215350151062\n",
      "Iteration: 55/10000, Loss: 0.6300161480903625\n",
      "Iteration: 56/10000, Loss: 0.6257429718971252\n",
      "Iteration: 57/10000, Loss: 0.6167374849319458\n",
      "Iteration: 58/10000, Loss: 0.6125085353851318\n",
      "Iteration: 59/10000, Loss: 0.6132787466049194\n",
      "Iteration: 60/10000, Loss: 0.5943410992622375\n",
      "Iteration: 61/10000, Loss: 0.5984392762184143\n",
      "Iteration: 62/10000, Loss: 0.5906233787536621\n",
      "Iteration: 63/10000, Loss: 0.5795249342918396\n",
      "Iteration: 64/10000, Loss: 0.5753134489059448\n",
      "Iteration: 65/10000, Loss: 0.5667783617973328\n",
      "Iteration: 66/10000, Loss: 0.5637139678001404\n",
      "Iteration: 67/10000, Loss: 0.5505730509757996\n",
      "Iteration: 68/10000, Loss: 0.5553210973739624\n",
      "Iteration: 69/10000, Loss: 0.5471433997154236\n",
      "Iteration: 70/10000, Loss: 0.5456041097640991\n",
      "Iteration: 71/10000, Loss: 0.5349990725517273\n",
      "Iteration: 72/10000, Loss: 0.5330783128738403\n",
      "Iteration: 73/10000, Loss: 0.5241125226020813\n",
      "Iteration: 74/10000, Loss: 0.5098074078559875\n",
      "Iteration: 75/10000, Loss: 0.5044564604759216\n",
      "Iteration: 76/10000, Loss: 0.5040229558944702\n",
      "Iteration: 77/10000, Loss: 0.5011281967163086\n",
      "Iteration: 78/10000, Loss: 0.49449265003204346\n",
      "Iteration: 79/10000, Loss: 0.49963971972465515\n",
      "Iteration: 80/10000, Loss: 0.4781665802001953\n",
      "Iteration: 81/10000, Loss: 0.5010207295417786\n",
      "Iteration: 82/10000, Loss: 0.4754883348941803\n",
      "Iteration: 83/10000, Loss: 0.4763047695159912\n",
      "Iteration: 84/10000, Loss: 0.45957204699516296\n",
      "Iteration: 85/10000, Loss: 0.462024062871933\n",
      "Iteration: 86/10000, Loss: 0.4771302342414856\n",
      "Iteration: 87/10000, Loss: 0.4695897698402405\n",
      "Iteration: 88/10000, Loss: 0.45148417353630066\n",
      "Iteration: 89/10000, Loss: 0.45117849111557007\n",
      "Iteration: 90/10000, Loss: 0.44049859046936035\n",
      "Iteration: 91/10000, Loss: 0.43206074833869934\n",
      "Iteration: 92/10000, Loss: 0.4416728615760803\n",
      "Iteration: 93/10000, Loss: 0.42880794405937195\n",
      "Iteration: 94/10000, Loss: 0.4270356595516205\n",
      "Iteration: 95/10000, Loss: 0.4223989248275757\n",
      "Iteration: 96/10000, Loss: 0.41954994201660156\n",
      "Iteration: 97/10000, Loss: 0.41164037585258484\n",
      "Iteration: 98/10000, Loss: 0.41578689217567444\n",
      "Iteration: 99/10000, Loss: 0.3973425328731537\n",
      "Iteration: 100/10000, Loss: 0.3972027003765106\n",
      "Average test loss:  0.0273\n",
      "Iteration: 101/10000, Loss: 0.4076730012893677\n",
      "Iteration: 102/10000, Loss: 0.3977498710155487\n",
      "Iteration: 103/10000, Loss: 0.40203359723091125\n",
      "Iteration: 104/10000, Loss: 0.39606916904449463\n",
      "Iteration: 105/10000, Loss: 0.39321190118789673\n",
      "Iteration: 106/10000, Loss: 0.3788895010948181\n",
      "Iteration: 107/10000, Loss: 0.3779265880584717\n",
      "Iteration: 108/10000, Loss: 0.379891961812973\n",
      "Iteration: 109/10000, Loss: 0.3763354420661926\n",
      "Iteration: 110/10000, Loss: 0.3613893687725067\n",
      "Iteration: 111/10000, Loss: 0.3612649142742157\n",
      "Iteration: 112/10000, Loss: 0.35689207911491394\n",
      "Iteration: 113/10000, Loss: 0.36095094680786133\n",
      "Iteration: 114/10000, Loss: 0.3410342335700989\n",
      "Iteration: 115/10000, Loss: 0.3616495728492737\n",
      "Iteration: 116/10000, Loss: 0.34530484676361084\n",
      "Iteration: 117/10000, Loss: 0.32794493436813354\n",
      "Iteration: 118/10000, Loss: 0.34562036395072937\n",
      "Iteration: 119/10000, Loss: 0.3256000876426697\n",
      "Iteration: 120/10000, Loss: 0.3216208219528198\n",
      "Iteration: 121/10000, Loss: 0.3366495370864868\n",
      "Iteration: 122/10000, Loss: 0.3230535686016083\n",
      "Iteration: 123/10000, Loss: 0.33889278769493103\n",
      "Iteration: 124/10000, Loss: 0.35387223958969116\n",
      "Iteration: 125/10000, Loss: 0.32219406962394714\n",
      "Iteration: 126/10000, Loss: 0.31064215302467346\n",
      "Iteration: 127/10000, Loss: 0.30308467149734497\n",
      "Iteration: 128/10000, Loss: 0.30074551701545715\n",
      "Iteration: 129/10000, Loss: 0.30565470457077026\n",
      "Iteration: 130/10000, Loss: 0.321391224861145\n",
      "Iteration: 131/10000, Loss: 0.30752497911453247\n",
      "Iteration: 132/10000, Loss: 0.3056156635284424\n",
      "Iteration: 133/10000, Loss: 0.31618717312812805\n",
      "Iteration: 134/10000, Loss: 0.3011748492717743\n",
      "Iteration: 135/10000, Loss: 0.2938839793205261\n",
      "Iteration: 136/10000, Loss: 0.3056473731994629\n",
      "Iteration: 137/10000, Loss: 0.28209421038627625\n",
      "Iteration: 138/10000, Loss: 0.2945742607116699\n",
      "Iteration: 139/10000, Loss: 0.28969287872314453\n",
      "Iteration: 140/10000, Loss: 0.2896246016025543\n",
      "Iteration: 141/10000, Loss: 0.27243170142173767\n",
      "Iteration: 142/10000, Loss: 0.2793315052986145\n",
      "Iteration: 143/10000, Loss: 0.267994225025177\n",
      "Iteration: 144/10000, Loss: 0.28033900260925293\n",
      "Iteration: 145/10000, Loss: 0.2930460572242737\n",
      "Iteration: 146/10000, Loss: 0.27644598484039307\n",
      "Iteration: 147/10000, Loss: 0.28330758213996887\n",
      "Iteration: 148/10000, Loss: 0.26434341073036194\n",
      "Iteration: 149/10000, Loss: 0.25320565700531006\n",
      "Iteration: 150/10000, Loss: 0.2596457004547119\n",
      "Iteration: 151/10000, Loss: 0.2654920816421509\n",
      "Iteration: 152/10000, Loss: 0.24247930943965912\n",
      "Iteration: 153/10000, Loss: 0.2358766794204712\n",
      "Iteration: 154/10000, Loss: 0.2561996281147003\n",
      "Iteration: 155/10000, Loss: 0.23217584192752838\n",
      "Iteration: 156/10000, Loss: 0.23932676017284393\n",
      "Iteration: 157/10000, Loss: 0.24458961188793182\n",
      "Iteration: 158/10000, Loss: 0.2726593315601349\n",
      "Iteration: 159/10000, Loss: 0.2544573247432709\n",
      "Iteration: 160/10000, Loss: 0.23016121983528137\n",
      "Iteration: 161/10000, Loss: 0.22845301032066345\n",
      "Iteration: 162/10000, Loss: 0.22802723944187164\n",
      "Iteration: 163/10000, Loss: 0.24183669686317444\n",
      "Iteration: 164/10000, Loss: 0.22665956616401672\n",
      "Iteration: 165/10000, Loss: 0.22495806217193604\n",
      "Iteration: 166/10000, Loss: 0.21253153681755066\n",
      "Iteration: 167/10000, Loss: 0.2317199856042862\n",
      "Iteration: 168/10000, Loss: 0.22553125023841858\n",
      "Iteration: 169/10000, Loss: 0.22195976972579956\n",
      "Iteration: 170/10000, Loss: 0.22121760249137878\n",
      "Iteration: 171/10000, Loss: 0.21279311180114746\n",
      "Iteration: 172/10000, Loss: 0.20986616611480713\n",
      "Iteration: 173/10000, Loss: 0.21617820858955383\n",
      "Iteration: 174/10000, Loss: 0.22448410093784332\n",
      "Iteration: 175/10000, Loss: 0.195106640458107\n",
      "Iteration: 176/10000, Loss: 0.22703158855438232\n",
      "Iteration: 177/10000, Loss: 0.21275456249713898\n",
      "Iteration: 178/10000, Loss: 0.21746625006198883\n",
      "Iteration: 179/10000, Loss: 0.19762343168258667\n",
      "Iteration: 180/10000, Loss: 0.19955502450466156\n",
      "Iteration: 181/10000, Loss: 0.1863180696964264\n",
      "Iteration: 182/10000, Loss: 0.20910227298736572\n",
      "Iteration: 183/10000, Loss: 0.20718275010585785\n",
      "Iteration: 184/10000, Loss: 0.20423030853271484\n",
      "Iteration: 185/10000, Loss: 0.19833461940288544\n",
      "Iteration: 186/10000, Loss: 0.20476692914962769\n",
      "Iteration: 187/10000, Loss: 0.18642638623714447\n",
      "Iteration: 188/10000, Loss: 0.1881565898656845\n",
      "Iteration: 189/10000, Loss: 0.20352822542190552\n",
      "Iteration: 190/10000, Loss: 0.18223485350608826\n",
      "Iteration: 191/10000, Loss: 0.18230147659778595\n",
      "Iteration: 192/10000, Loss: 0.18589819967746735\n",
      "Iteration: 193/10000, Loss: 0.1877637356519699\n",
      "Iteration: 194/10000, Loss: 0.19187574088573456\n",
      "Iteration: 195/10000, Loss: 0.18115997314453125\n",
      "Iteration: 196/10000, Loss: 0.18392176926136017\n",
      "Iteration: 197/10000, Loss: 0.19442534446716309\n",
      "Iteration: 198/10000, Loss: 0.17501713335514069\n",
      "Iteration: 199/10000, Loss: 0.1841125190258026\n",
      "Iteration: 200/10000, Loss: 0.1759786605834961\n",
      "Average test loss:  0.0129\n",
      "Iteration: 201/10000, Loss: 0.19741086661815643\n",
      "Iteration: 202/10000, Loss: 0.21207846701145172\n",
      "Iteration: 203/10000, Loss: 0.16718797385692596\n",
      "Iteration: 204/10000, Loss: 0.17597554624080658\n",
      "Iteration: 205/10000, Loss: 0.15509994328022003\n",
      "Iteration: 206/10000, Loss: 0.18713992834091187\n",
      "Iteration: 207/10000, Loss: 0.17302842438220978\n",
      "Iteration: 208/10000, Loss: 0.16111455857753754\n",
      "Iteration: 209/10000, Loss: 0.15284718573093414\n",
      "Iteration: 210/10000, Loss: 0.15877765417099\n",
      "Iteration: 211/10000, Loss: 0.16742043197155\n",
      "Iteration: 212/10000, Loss: 0.16848473250865936\n",
      "Iteration: 213/10000, Loss: 0.1928829401731491\n",
      "Iteration: 214/10000, Loss: 0.16751520335674286\n",
      "Iteration: 215/10000, Loss: 0.15206752717494965\n",
      "Iteration: 216/10000, Loss: 0.17627497017383575\n",
      "Iteration: 217/10000, Loss: 0.15682698786258698\n",
      "Iteration: 218/10000, Loss: 0.14744174480438232\n",
      "Iteration: 219/10000, Loss: 0.17684045433998108\n",
      "Iteration: 220/10000, Loss: 0.15328386425971985\n",
      "Iteration: 221/10000, Loss: 0.1728837937116623\n",
      "Iteration: 222/10000, Loss: 0.16129624843597412\n",
      "Iteration: 223/10000, Loss: 0.1531064659357071\n",
      "Iteration: 224/10000, Loss: 0.17355336248874664\n",
      "Iteration: 225/10000, Loss: 0.16191327571868896\n",
      "Iteration: 226/10000, Loss: 0.147246852517128\n",
      "Iteration: 227/10000, Loss: 0.16279883682727814\n",
      "Iteration: 228/10000, Loss: 0.1501755714416504\n",
      "Iteration: 229/10000, Loss: 0.14257466793060303\n",
      "Iteration: 230/10000, Loss: 0.1348332315683365\n",
      "Iteration: 231/10000, Loss: 0.16855432093143463\n",
      "Iteration: 232/10000, Loss: 0.14534591138362885\n",
      "Iteration: 233/10000, Loss: 0.1447589099407196\n",
      "Iteration: 234/10000, Loss: 0.14051048457622528\n",
      "Iteration: 235/10000, Loss: 0.1489672213792801\n",
      "Iteration: 236/10000, Loss: 0.14740049839019775\n",
      "Iteration: 237/10000, Loss: 0.1603841632604599\n",
      "Iteration: 238/10000, Loss: 0.15105029940605164\n",
      "Iteration: 239/10000, Loss: 0.13278746604919434\n",
      "Iteration: 240/10000, Loss: 0.14837466180324554\n",
      "Iteration: 241/10000, Loss: 0.14078164100646973\n",
      "Iteration: 242/10000, Loss: 0.14893528819084167\n",
      "Iteration: 243/10000, Loss: 0.13946792483329773\n",
      "Iteration: 244/10000, Loss: 0.14463187754154205\n",
      "Iteration: 245/10000, Loss: 0.13761331140995026\n",
      "Iteration: 246/10000, Loss: 0.13839523494243622\n",
      "Iteration: 247/10000, Loss: 0.14176370203495026\n",
      "Iteration: 248/10000, Loss: 0.142757385969162\n",
      "Iteration: 249/10000, Loss: 0.1545400470495224\n",
      "Iteration: 250/10000, Loss: 0.12303832918405533\n",
      "Iteration: 251/10000, Loss: 0.13785980641841888\n",
      "Iteration: 252/10000, Loss: 0.11784926801919937\n",
      "Iteration: 253/10000, Loss: 0.14166322350502014\n",
      "Iteration: 254/10000, Loss: 0.15528017282485962\n",
      "Iteration: 255/10000, Loss: 0.11724448204040527\n",
      "Iteration: 256/10000, Loss: 0.12166314572095871\n",
      "Iteration: 257/10000, Loss: 0.14034315943717957\n",
      "Iteration: 258/10000, Loss: 0.12603352963924408\n",
      "Iteration: 259/10000, Loss: 0.1266973316669464\n",
      "Iteration: 260/10000, Loss: 0.1274283230304718\n",
      "Iteration: 261/10000, Loss: 0.13206546008586884\n",
      "Iteration: 262/10000, Loss: 0.14322026073932648\n",
      "Iteration: 263/10000, Loss: 0.1328050047159195\n",
      "Iteration: 264/10000, Loss: 0.11306779086589813\n",
      "Iteration: 265/10000, Loss: 0.1269676834344864\n",
      "Iteration: 266/10000, Loss: 0.13634397089481354\n",
      "Iteration: 267/10000, Loss: 0.1342921406030655\n",
      "Iteration: 268/10000, Loss: 0.13219331204891205\n",
      "Iteration: 269/10000, Loss: 0.11543673276901245\n",
      "Iteration: 270/10000, Loss: 0.1336679458618164\n",
      "Iteration: 271/10000, Loss: 0.12398677319288254\n",
      "Iteration: 272/10000, Loss: 0.14568300545215607\n",
      "Iteration: 273/10000, Loss: 0.1279451549053192\n",
      "Iteration: 274/10000, Loss: 0.12288107722997665\n",
      "Iteration: 275/10000, Loss: 0.11832360923290253\n",
      "Iteration: 276/10000, Loss: 0.09977049380540848\n",
      "Iteration: 277/10000, Loss: 0.14744235575199127\n",
      "Iteration: 278/10000, Loss: 0.13044904172420502\n",
      "Iteration: 279/10000, Loss: 0.11533809453248978\n",
      "Iteration: 280/10000, Loss: 0.12276002019643784\n",
      "Iteration: 281/10000, Loss: 0.13511168956756592\n",
      "Iteration: 282/10000, Loss: 0.13099142909049988\n",
      "Iteration: 283/10000, Loss: 0.1166405901312828\n",
      "Iteration: 284/10000, Loss: 0.11876728385686874\n",
      "Iteration: 285/10000, Loss: 0.12733598053455353\n",
      "Iteration: 286/10000, Loss: 0.115897998213768\n",
      "Iteration: 287/10000, Loss: 0.10620107501745224\n",
      "Iteration: 288/10000, Loss: 0.10840252041816711\n",
      "Iteration: 289/10000, Loss: 0.1389816403388977\n",
      "Iteration: 290/10000, Loss: 0.12262939661741257\n",
      "Iteration: 291/10000, Loss: 0.1284351646900177\n",
      "Iteration: 292/10000, Loss: 0.134567528963089\n",
      "Iteration: 293/10000, Loss: 0.11058127880096436\n",
      "Iteration: 294/10000, Loss: 0.11867580562829971\n",
      "Iteration: 295/10000, Loss: 0.12689697742462158\n",
      "Iteration: 296/10000, Loss: 0.13017450273036957\n",
      "Iteration: 297/10000, Loss: 0.10646222531795502\n",
      "Iteration: 298/10000, Loss: 0.1166187971830368\n",
      "Iteration: 299/10000, Loss: 0.12328199297189713\n",
      "Iteration: 300/10000, Loss: 0.09942018240690231\n",
      "Average test loss:  0.0104\n",
      "Iteration: 301/10000, Loss: 0.09438913315534592\n",
      "Iteration: 302/10000, Loss: 0.09886324405670166\n",
      "Iteration: 303/10000, Loss: 0.10151668637990952\n",
      "Iteration: 304/10000, Loss: 0.08230801671743393\n",
      "Iteration: 305/10000, Loss: 0.11633303016424179\n",
      "Iteration: 306/10000, Loss: 0.10467223823070526\n",
      "Iteration: 307/10000, Loss: 0.10381784290075302\n",
      "Iteration: 308/10000, Loss: 0.10590369999408722\n",
      "Iteration: 309/10000, Loss: 0.10357240587472916\n",
      "Iteration: 310/10000, Loss: 0.12390243262052536\n",
      "Iteration: 311/10000, Loss: 0.10457346588373184\n",
      "Iteration: 312/10000, Loss: 0.11604265123605728\n",
      "Iteration: 313/10000, Loss: 0.08824633806943893\n",
      "Iteration: 314/10000, Loss: 0.10219477862119675\n",
      "Iteration: 315/10000, Loss: 0.11272536963224411\n",
      "Iteration: 316/10000, Loss: 0.11244874447584152\n",
      "Iteration: 317/10000, Loss: 0.11294218897819519\n",
      "Iteration: 318/10000, Loss: 0.09912355989217758\n",
      "Iteration: 319/10000, Loss: 0.11821595579385757\n",
      "Iteration: 320/10000, Loss: 0.10136385262012482\n",
      "Iteration: 321/10000, Loss: 0.09892071783542633\n",
      "Iteration: 322/10000, Loss: 0.0763835534453392\n",
      "Iteration: 323/10000, Loss: 0.11115720868110657\n",
      "Iteration: 324/10000, Loss: 0.10035280138254166\n",
      "Iteration: 325/10000, Loss: 0.10671432316303253\n",
      "Iteration: 326/10000, Loss: 0.11228904873132706\n",
      "Iteration: 327/10000, Loss: 0.10261687636375427\n",
      "Iteration: 328/10000, Loss: 0.08334788680076599\n",
      "Iteration: 329/10000, Loss: 0.1007976159453392\n",
      "Iteration: 330/10000, Loss: 0.0984506830573082\n",
      "Iteration: 331/10000, Loss: 0.12441738694906235\n",
      "Iteration: 332/10000, Loss: 0.10250772535800934\n",
      "Iteration: 333/10000, Loss: 0.09568523615598679\n",
      "Iteration: 334/10000, Loss: 0.10253283381462097\n",
      "Iteration: 335/10000, Loss: 0.12450706213712692\n",
      "Iteration: 336/10000, Loss: 0.105884850025177\n",
      "Iteration: 337/10000, Loss: 0.10183495283126831\n",
      "Iteration: 338/10000, Loss: 0.10284597426652908\n",
      "Iteration: 339/10000, Loss: 0.11411505937576294\n",
      "Iteration: 340/10000, Loss: 0.09628745913505554\n",
      "Iteration: 341/10000, Loss: 0.09593856334686279\n",
      "Iteration: 342/10000, Loss: 0.0906745195388794\n",
      "Iteration: 343/10000, Loss: 0.09623580425977707\n",
      "Iteration: 344/10000, Loss: 0.10585315525531769\n",
      "Iteration: 345/10000, Loss: 0.09553008526563644\n",
      "Iteration: 346/10000, Loss: 0.08951164036989212\n",
      "Iteration: 347/10000, Loss: 0.10864977538585663\n",
      "Iteration: 348/10000, Loss: 0.07001528143882751\n",
      "Iteration: 349/10000, Loss: 0.12386691570281982\n",
      "Iteration: 350/10000, Loss: 0.07801220566034317\n",
      "Iteration: 351/10000, Loss: 0.10274043679237366\n",
      "Iteration: 352/10000, Loss: 0.12039875984191895\n",
      "Iteration: 353/10000, Loss: 0.0955536961555481\n",
      "Iteration: 354/10000, Loss: 0.08730553835630417\n",
      "Iteration: 355/10000, Loss: 0.10156549513339996\n",
      "Iteration: 356/10000, Loss: 0.07128030061721802\n",
      "Iteration: 357/10000, Loss: 0.09707092493772507\n",
      "Iteration: 358/10000, Loss: 0.11774490028619766\n",
      "Iteration: 359/10000, Loss: 0.0892842635512352\n",
      "Iteration: 360/10000, Loss: 0.07657496631145477\n",
      "Iteration: 361/10000, Loss: 0.07685669511556625\n",
      "Iteration: 362/10000, Loss: 0.07447332888841629\n",
      "Iteration: 363/10000, Loss: 0.09042778611183167\n",
      "Iteration: 364/10000, Loss: 0.06979142874479294\n",
      "Iteration: 365/10000, Loss: 0.10609178245067596\n",
      "Iteration: 366/10000, Loss: 0.0894046351313591\n",
      "Iteration: 367/10000, Loss: 0.09393510967493057\n",
      "Iteration: 368/10000, Loss: 0.06532152742147446\n",
      "Iteration: 369/10000, Loss: 0.08237597346305847\n",
      "Iteration: 370/10000, Loss: 0.09228108823299408\n",
      "Iteration: 371/10000, Loss: 0.10007055848836899\n",
      "Iteration: 372/10000, Loss: 0.07093539088964462\n",
      "Iteration: 373/10000, Loss: 0.0867750272154808\n",
      "Iteration: 374/10000, Loss: 0.0857342779636383\n",
      "Iteration: 375/10000, Loss: 0.08895701169967651\n",
      "Iteration: 376/10000, Loss: 0.09399165958166122\n",
      "Iteration: 377/10000, Loss: 0.09982682019472122\n",
      "Iteration: 378/10000, Loss: 0.09697447717189789\n",
      "Iteration: 379/10000, Loss: 0.08972522616386414\n",
      "Iteration: 380/10000, Loss: 0.0956467017531395\n",
      "Iteration: 381/10000, Loss: 0.090752013027668\n",
      "Iteration: 382/10000, Loss: 0.07548420876264572\n",
      "Iteration: 383/10000, Loss: 0.10323412716388702\n",
      "Iteration: 384/10000, Loss: 0.08630488067865372\n",
      "Iteration: 385/10000, Loss: 0.09012842178344727\n",
      "Iteration: 386/10000, Loss: 0.08833982795476913\n",
      "Iteration: 387/10000, Loss: 0.08379289507865906\n",
      "Iteration: 388/10000, Loss: 0.09169724583625793\n",
      "Iteration: 389/10000, Loss: 0.10353690385818481\n",
      "Iteration: 390/10000, Loss: 0.09845340251922607\n",
      "Iteration: 391/10000, Loss: 0.06618388742208481\n",
      "Iteration: 392/10000, Loss: 0.0934959352016449\n",
      "Iteration: 393/10000, Loss: 0.08149238675832748\n",
      "Iteration: 394/10000, Loss: 0.07408422976732254\n",
      "Iteration: 395/10000, Loss: 0.09583400189876556\n",
      "Iteration: 396/10000, Loss: 0.10266172140836716\n",
      "Iteration: 397/10000, Loss: 0.07847785204648972\n",
      "Iteration: 398/10000, Loss: 0.07042350620031357\n",
      "Iteration: 399/10000, Loss: 0.09197775274515152\n",
      "Iteration: 400/10000, Loss: 0.06013752147555351\n",
      "Average test loss:  0.0059\n",
      "Iteration: 401/10000, Loss: 0.08342616260051727\n",
      "Iteration: 402/10000, Loss: 0.07415185868740082\n",
      "Iteration: 403/10000, Loss: 0.09439817816019058\n",
      "Iteration: 404/10000, Loss: 0.0733596459031105\n",
      "Iteration: 405/10000, Loss: 0.1009654551744461\n",
      "Iteration: 406/10000, Loss: 0.09039513766765594\n",
      "Iteration: 407/10000, Loss: 0.08492028713226318\n",
      "Iteration: 408/10000, Loss: 0.07921027392148972\n",
      "Iteration: 409/10000, Loss: 0.07310373336076736\n",
      "Iteration: 410/10000, Loss: 0.07245631515979767\n",
      "Iteration: 411/10000, Loss: 0.09897658973932266\n",
      "Iteration: 412/10000, Loss: 0.08053102344274521\n",
      "Iteration: 413/10000, Loss: 0.0908077135682106\n",
      "Iteration: 414/10000, Loss: 0.09315591305494308\n",
      "Iteration: 415/10000, Loss: 0.08232312649488449\n",
      "Iteration: 416/10000, Loss: 0.09353675693273544\n",
      "Iteration: 417/10000, Loss: 0.07011667639017105\n",
      "Iteration: 418/10000, Loss: 0.07726667821407318\n",
      "Iteration: 419/10000, Loss: 0.09538416564464569\n",
      "Iteration: 420/10000, Loss: 0.09884314984083176\n",
      "Iteration: 421/10000, Loss: 0.07154598832130432\n",
      "Iteration: 422/10000, Loss: 0.08261434733867645\n",
      "Iteration: 423/10000, Loss: 0.07062356919050217\n",
      "Iteration: 424/10000, Loss: 0.08336654305458069\n",
      "Iteration: 425/10000, Loss: 0.09745058417320251\n",
      "Iteration: 426/10000, Loss: 0.09492725878953934\n",
      "Iteration: 427/10000, Loss: 0.05725857987999916\n",
      "Iteration: 428/10000, Loss: 0.08953610062599182\n",
      "Iteration: 429/10000, Loss: 0.06608623266220093\n",
      "Iteration: 430/10000, Loss: 0.07900260388851166\n",
      "Iteration: 431/10000, Loss: 0.0797850638628006\n",
      "Iteration: 432/10000, Loss: 0.10010159015655518\n",
      "Iteration: 433/10000, Loss: 0.0856526792049408\n",
      "Iteration: 434/10000, Loss: 0.08364854753017426\n",
      "Iteration: 435/10000, Loss: 0.08214564621448517\n",
      "Iteration: 436/10000, Loss: 0.07761397212743759\n",
      "Iteration: 437/10000, Loss: 0.0791437104344368\n",
      "Iteration: 438/10000, Loss: 0.07406198978424072\n",
      "Iteration: 439/10000, Loss: 0.06882992386817932\n",
      "Iteration: 440/10000, Loss: 0.07133070379495621\n",
      "Iteration: 441/10000, Loss: 0.06098100170493126\n",
      "Iteration: 442/10000, Loss: 0.09257769584655762\n",
      "Iteration: 443/10000, Loss: 0.07853725552558899\n",
      "Iteration: 444/10000, Loss: 0.0998980700969696\n",
      "Iteration: 445/10000, Loss: 0.06836260110139847\n",
      "Iteration: 446/10000, Loss: 0.08942575007677078\n",
      "Iteration: 447/10000, Loss: 0.05631331726908684\n",
      "Iteration: 448/10000, Loss: 0.07905473560094833\n",
      "Iteration: 449/10000, Loss: 0.0883047804236412\n",
      "Iteration: 450/10000, Loss: 0.07306450605392456\n",
      "Iteration: 451/10000, Loss: 0.08558641374111176\n",
      "Iteration: 452/10000, Loss: 0.06760401278734207\n",
      "Iteration: 453/10000, Loss: 0.07883524894714355\n",
      "Iteration: 454/10000, Loss: 0.08204434812068939\n",
      "Iteration: 455/10000, Loss: 0.09126127511262894\n",
      "Iteration: 456/10000, Loss: 0.08046609908342361\n",
      "Iteration: 457/10000, Loss: 0.06391675770282745\n",
      "Iteration: 458/10000, Loss: 0.06671953946352005\n",
      "Iteration: 459/10000, Loss: 0.08296490460634232\n",
      "Iteration: 460/10000, Loss: 0.09535183012485504\n",
      "Iteration: 461/10000, Loss: 0.07691982388496399\n",
      "Iteration: 462/10000, Loss: 0.07549425214529037\n",
      "Iteration: 463/10000, Loss: 0.056149765849113464\n",
      "Iteration: 464/10000, Loss: 0.050515737384557724\n",
      "Iteration: 465/10000, Loss: 0.0689234659075737\n",
      "Iteration: 466/10000, Loss: 0.060848817229270935\n",
      "Iteration: 467/10000, Loss: 0.10385194420814514\n",
      "Iteration: 468/10000, Loss: 0.08443346619606018\n",
      "Iteration: 469/10000, Loss: 0.08269917219877243\n",
      "Iteration: 470/10000, Loss: 0.07520993053913116\n",
      "Iteration: 471/10000, Loss: 0.05998752638697624\n",
      "Iteration: 472/10000, Loss: 0.09744790941476822\n",
      "Iteration: 473/10000, Loss: 0.07866203039884567\n",
      "Iteration: 474/10000, Loss: 0.10801316052675247\n",
      "Iteration: 475/10000, Loss: 0.07759959995746613\n",
      "Iteration: 476/10000, Loss: 0.08388227969408035\n",
      "Iteration: 477/10000, Loss: 0.07727321982383728\n",
      "Iteration: 478/10000, Loss: 0.08218532055616379\n",
      "Iteration: 479/10000, Loss: 0.049735646694898605\n",
      "Iteration: 480/10000, Loss: 0.07535474002361298\n",
      "Iteration: 481/10000, Loss: 0.06256212294101715\n",
      "Iteration: 482/10000, Loss: 0.07018617540597916\n",
      "Iteration: 483/10000, Loss: 0.07875794172286987\n",
      "Iteration: 484/10000, Loss: 0.061312831938266754\n",
      "Iteration: 485/10000, Loss: 0.08272550255060196\n",
      "Iteration: 486/10000, Loss: 0.07353384792804718\n",
      "Iteration: 487/10000, Loss: 0.05691167339682579\n",
      "Iteration: 488/10000, Loss: 0.08487068861722946\n",
      "Iteration: 489/10000, Loss: 0.07235132902860641\n",
      "Iteration: 490/10000, Loss: 0.09077085554599762\n",
      "Iteration: 491/10000, Loss: 0.06361181288957596\n",
      "Iteration: 492/10000, Loss: 0.07258673012256622\n",
      "Iteration: 493/10000, Loss: 0.06577184796333313\n",
      "Iteration: 494/10000, Loss: 0.06783977150917053\n",
      "Iteration: 495/10000, Loss: 0.05423930659890175\n",
      "Iteration: 496/10000, Loss: 0.05915768817067146\n",
      "Iteration: 497/10000, Loss: 0.0678478479385376\n",
      "Iteration: 498/10000, Loss: 0.06983012706041336\n",
      "Iteration: 499/10000, Loss: 0.0787581205368042\n",
      "Iteration: 500/10000, Loss: 0.06474173069000244\n",
      "Average test loss:  0.0051\n",
      "Iteration: 501/10000, Loss: 0.06870483607053757\n",
      "Iteration: 502/10000, Loss: 0.07623131573200226\n",
      "Iteration: 503/10000, Loss: 0.09201809018850327\n",
      "Iteration: 504/10000, Loss: 0.07158691436052322\n",
      "Iteration: 505/10000, Loss: 0.06119927763938904\n",
      "Iteration: 506/10000, Loss: 0.05691424757242203\n",
      "Iteration: 507/10000, Loss: 0.06935198605060577\n",
      "Iteration: 508/10000, Loss: 0.0603100061416626\n",
      "Iteration: 509/10000, Loss: 0.07693924754858017\n",
      "Iteration: 510/10000, Loss: 0.06907302141189575\n",
      "Iteration: 511/10000, Loss: 0.08124501258134842\n",
      "Iteration: 512/10000, Loss: 0.07500828057527542\n",
      "Iteration: 513/10000, Loss: 0.07443009316921234\n",
      "Iteration: 514/10000, Loss: 0.04670403525233269\n",
      "Iteration: 515/10000, Loss: 0.06306625157594681\n",
      "Iteration: 516/10000, Loss: 0.07079139351844788\n",
      "Iteration: 517/10000, Loss: 0.07354416698217392\n",
      "Iteration: 518/10000, Loss: 0.0626327246427536\n",
      "Iteration: 519/10000, Loss: 0.060400642454624176\n",
      "Iteration: 520/10000, Loss: 0.07207794487476349\n",
      "Iteration: 521/10000, Loss: 0.05396850407123566\n",
      "Iteration: 522/10000, Loss: 0.0693424791097641\n",
      "Iteration: 523/10000, Loss: 0.05304742604494095\n",
      "Iteration: 524/10000, Loss: 0.05167260393500328\n",
      "Iteration: 525/10000, Loss: 0.06241317838430405\n",
      "Iteration: 526/10000, Loss: 0.05224347487092018\n",
      "Iteration: 527/10000, Loss: 0.07580175250768661\n",
      "Iteration: 528/10000, Loss: 0.06448280811309814\n",
      "Iteration: 529/10000, Loss: 0.04948490485548973\n",
      "Iteration: 530/10000, Loss: 0.08088526129722595\n",
      "Iteration: 531/10000, Loss: 0.042648132890462875\n",
      "Iteration: 532/10000, Loss: 0.07264876365661621\n",
      "Iteration: 533/10000, Loss: 0.09129603952169418\n",
      "Iteration: 534/10000, Loss: 0.06171781197190285\n",
      "Iteration: 535/10000, Loss: 0.07177471369504929\n",
      "Iteration: 536/10000, Loss: 0.06741942465305328\n",
      "Iteration: 537/10000, Loss: 0.08241315186023712\n",
      "Iteration: 538/10000, Loss: 0.07981213927268982\n",
      "Iteration: 539/10000, Loss: 0.07402610033750534\n",
      "Iteration: 540/10000, Loss: 0.04986753687262535\n",
      "Iteration: 541/10000, Loss: 0.0719434842467308\n",
      "Iteration: 542/10000, Loss: 0.06602153182029724\n",
      "Iteration: 543/10000, Loss: 0.04533008486032486\n",
      "Iteration: 544/10000, Loss: 0.05304274335503578\n",
      "Iteration: 545/10000, Loss: 0.05186906456947327\n",
      "Iteration: 546/10000, Loss: 0.04806860536336899\n",
      "Iteration: 547/10000, Loss: 0.07441630959510803\n",
      "Iteration: 548/10000, Loss: 0.0474889799952507\n",
      "Iteration: 549/10000, Loss: 0.041780222207307816\n",
      "Iteration: 550/10000, Loss: 0.07126599550247192\n",
      "Iteration: 551/10000, Loss: 0.08501995354890823\n",
      "Iteration: 552/10000, Loss: 0.047148436307907104\n",
      "Iteration: 553/10000, Loss: 0.060397375375032425\n",
      "Iteration: 554/10000, Loss: 0.05427553132176399\n",
      "Iteration: 555/10000, Loss: 0.05002686753869057\n",
      "Iteration: 556/10000, Loss: 0.06062858924269676\n",
      "Iteration: 557/10000, Loss: 0.06602710485458374\n",
      "Iteration: 558/10000, Loss: 0.06776859611272812\n",
      "Iteration: 559/10000, Loss: 0.046905986964702606\n",
      "Iteration: 560/10000, Loss: 0.05606125295162201\n",
      "Iteration: 561/10000, Loss: 0.06982727348804474\n",
      "Iteration: 562/10000, Loss: 0.0339832566678524\n",
      "Iteration: 563/10000, Loss: 0.08362740278244019\n",
      "Iteration: 564/10000, Loss: 0.05748123675584793\n",
      "Iteration: 565/10000, Loss: 0.05710539221763611\n",
      "Iteration: 566/10000, Loss: 0.06126473471522331\n",
      "Iteration: 567/10000, Loss: 0.05379362404346466\n",
      "Iteration: 568/10000, Loss: 0.07211130857467651\n",
      "Iteration: 569/10000, Loss: 0.0789899155497551\n",
      "Iteration: 570/10000, Loss: 0.05845779925584793\n",
      "Iteration: 571/10000, Loss: 0.055727262049913406\n",
      "Iteration: 572/10000, Loss: 0.06998156011104584\n",
      "Iteration: 573/10000, Loss: 0.06494054943323135\n",
      "Iteration: 574/10000, Loss: 0.053860705345869064\n",
      "Iteration: 575/10000, Loss: 0.044812750071287155\n",
      "Iteration: 576/10000, Loss: 0.0486588329076767\n",
      "Iteration: 577/10000, Loss: 0.06695736199617386\n",
      "Iteration: 578/10000, Loss: 0.07886098325252533\n",
      "Iteration: 579/10000, Loss: 0.099166139960289\n",
      "Iteration: 580/10000, Loss: 0.06101461499929428\n",
      "Iteration: 581/10000, Loss: 0.0791051834821701\n",
      "Iteration: 582/10000, Loss: 0.07989565283060074\n",
      "Iteration: 583/10000, Loss: 0.04642726480960846\n",
      "Iteration: 584/10000, Loss: 0.05448831617832184\n",
      "Iteration: 585/10000, Loss: 0.08879905194044113\n",
      "Iteration: 586/10000, Loss: 0.06007169187068939\n",
      "Iteration: 587/10000, Loss: 0.07915494590997696\n",
      "Iteration: 588/10000, Loss: 0.07034150511026382\n",
      "Iteration: 589/10000, Loss: 0.05940176919102669\n",
      "Iteration: 590/10000, Loss: 0.06610693037509918\n",
      "Iteration: 591/10000, Loss: 0.04827817529439926\n",
      "Iteration: 592/10000, Loss: 0.05785052850842476\n",
      "Iteration: 593/10000, Loss: 0.08194673806428909\n",
      "Iteration: 594/10000, Loss: 0.05816008523106575\n",
      "Iteration: 595/10000, Loss: 0.07614371180534363\n",
      "Iteration: 596/10000, Loss: 0.044558774679899216\n",
      "Iteration: 597/10000, Loss: 0.05552542209625244\n",
      "Iteration: 598/10000, Loss: 0.06608300656080246\n",
      "Iteration: 599/10000, Loss: 0.061129435896873474\n",
      "Iteration: 600/10000, Loss: 0.05912427231669426\n",
      "Average test loss:  0.0037\n",
      "Iteration: 601/10000, Loss: 0.06398897618055344\n",
      "Iteration: 602/10000, Loss: 0.050337620079517365\n",
      "Iteration: 603/10000, Loss: 0.0580894760787487\n",
      "Iteration: 604/10000, Loss: 0.038075048476457596\n",
      "Iteration: 605/10000, Loss: 0.03896906226873398\n",
      "Iteration: 606/10000, Loss: 0.07506265491247177\n",
      "Iteration: 607/10000, Loss: 0.0653204470872879\n",
      "Iteration: 608/10000, Loss: 0.061759453266859055\n",
      "Iteration: 609/10000, Loss: 0.08163150399923325\n",
      "Iteration: 610/10000, Loss: 0.0727657750248909\n",
      "Iteration: 611/10000, Loss: 0.07111050933599472\n",
      "Iteration: 612/10000, Loss: 0.0664825513958931\n",
      "Iteration: 613/10000, Loss: 0.05561724677681923\n",
      "Iteration: 614/10000, Loss: 0.051019731909036636\n",
      "Iteration: 615/10000, Loss: 0.08035895228385925\n",
      "Iteration: 616/10000, Loss: 0.06704320013523102\n",
      "Iteration: 617/10000, Loss: 0.05636332556605339\n",
      "Iteration: 618/10000, Loss: 0.10232135653495789\n",
      "Iteration: 619/10000, Loss: 0.06103508546948433\n",
      "Iteration: 620/10000, Loss: 0.06322560459375381\n",
      "Iteration: 621/10000, Loss: 0.07324410229921341\n",
      "Iteration: 622/10000, Loss: 0.06481888145208359\n",
      "Iteration: 623/10000, Loss: 0.06209271401166916\n",
      "Iteration: 624/10000, Loss: 0.056155309081077576\n",
      "Iteration: 625/10000, Loss: 0.04675055667757988\n",
      "Iteration: 626/10000, Loss: 0.06384415179491043\n",
      "Iteration: 627/10000, Loss: 0.05550690367817879\n",
      "Iteration: 628/10000, Loss: 0.05942343920469284\n",
      "Iteration: 629/10000, Loss: 0.045092303305864334\n",
      "Iteration: 630/10000, Loss: 0.06329581141471863\n",
      "Iteration: 631/10000, Loss: 0.046403668820858\n",
      "Iteration: 632/10000, Loss: 0.057864248752593994\n",
      "Iteration: 633/10000, Loss: 0.06033763289451599\n",
      "Iteration: 634/10000, Loss: 0.049281973391771317\n",
      "Iteration: 635/10000, Loss: 0.041492730379104614\n",
      "Iteration: 636/10000, Loss: 0.03945440426468849\n",
      "Iteration: 637/10000, Loss: 0.055560510605573654\n",
      "Iteration: 638/10000, Loss: 0.07557468861341476\n",
      "Iteration: 639/10000, Loss: 0.05809587612748146\n",
      "Iteration: 640/10000, Loss: 0.050398629158735275\n",
      "Iteration: 641/10000, Loss: 0.07438556104898453\n",
      "Iteration: 642/10000, Loss: 0.07046134769916534\n",
      "Iteration: 643/10000, Loss: 0.05235598236322403\n",
      "Iteration: 644/10000, Loss: 0.04363090917468071\n",
      "Iteration: 645/10000, Loss: 0.06442572176456451\n",
      "Iteration: 646/10000, Loss: 0.04998768866062164\n",
      "Iteration: 647/10000, Loss: 0.05430147796869278\n",
      "Iteration: 648/10000, Loss: 0.09251479059457779\n",
      "Iteration: 649/10000, Loss: 0.05975364148616791\n",
      "Iteration: 650/10000, Loss: 0.06478793174028397\n",
      "Iteration: 651/10000, Loss: 0.06219353526830673\n",
      "Iteration: 652/10000, Loss: 0.03966927528381348\n",
      "Iteration: 653/10000, Loss: 0.057713255286216736\n",
      "Iteration: 654/10000, Loss: 0.05552181228995323\n",
      "Iteration: 655/10000, Loss: 0.045829445123672485\n",
      "Iteration: 656/10000, Loss: 0.07670154422521591\n",
      "Iteration: 657/10000, Loss: 0.06983551383018494\n",
      "Iteration: 658/10000, Loss: 0.04532640799880028\n",
      "Iteration: 659/10000, Loss: 0.08580630272626877\n",
      "Iteration: 660/10000, Loss: 0.062448229640722275\n",
      "Iteration: 661/10000, Loss: 0.048273567110300064\n",
      "Iteration: 662/10000, Loss: 0.08777268975973129\n",
      "Iteration: 663/10000, Loss: 0.05022960156202316\n",
      "Iteration: 664/10000, Loss: 0.07004427909851074\n",
      "Iteration: 665/10000, Loss: 0.049565389752388\n",
      "Iteration: 666/10000, Loss: 0.04819045215845108\n",
      "Iteration: 667/10000, Loss: 0.060727622359991074\n",
      "Iteration: 668/10000, Loss: 0.049684181809425354\n",
      "Iteration: 669/10000, Loss: 0.06317714601755142\n",
      "Iteration: 670/10000, Loss: 0.04814373329281807\n",
      "Iteration: 671/10000, Loss: 0.04431137442588806\n",
      "Iteration: 672/10000, Loss: 0.05523819848895073\n",
      "Iteration: 673/10000, Loss: 0.060975465923547745\n",
      "Iteration: 674/10000, Loss: 0.044970426708459854\n",
      "Iteration: 675/10000, Loss: 0.041314076632261276\n",
      "Iteration: 676/10000, Loss: 0.06929364055395126\n",
      "Iteration: 677/10000, Loss: 0.05201292410492897\n",
      "Iteration: 678/10000, Loss: 0.04786888137459755\n",
      "Iteration: 679/10000, Loss: 0.06763981282711029\n",
      "Iteration: 680/10000, Loss: 0.053868960589170456\n",
      "Iteration: 681/10000, Loss: 0.06449728459119797\n",
      "Iteration: 682/10000, Loss: 0.03499956801533699\n",
      "Iteration: 683/10000, Loss: 0.04839882627129555\n",
      "Iteration: 684/10000, Loss: 0.05072889104485512\n",
      "Iteration: 685/10000, Loss: 0.04802169278264046\n",
      "Iteration: 686/10000, Loss: 0.041903458535671234\n",
      "Iteration: 687/10000, Loss: 0.07586105167865753\n",
      "Iteration: 688/10000, Loss: 0.04724963754415512\n",
      "Iteration: 689/10000, Loss: 0.050878413021564484\n",
      "Iteration: 690/10000, Loss: 0.07021909207105637\n",
      "Iteration: 691/10000, Loss: 0.05611295625567436\n",
      "Iteration: 692/10000, Loss: 0.044272758066654205\n",
      "Iteration: 693/10000, Loss: 0.05056937411427498\n",
      "Iteration: 694/10000, Loss: 0.05081634595990181\n",
      "Iteration: 695/10000, Loss: 0.043062955141067505\n",
      "Iteration: 696/10000, Loss: 0.06223282963037491\n",
      "Iteration: 697/10000, Loss: 0.05457865446805954\n",
      "Iteration: 698/10000, Loss: 0.05790948495268822\n",
      "Iteration: 699/10000, Loss: 0.049754656851291656\n",
      "Iteration: 700/10000, Loss: 0.05480961874127388\n",
      "Average test loss:  0.0033\n",
      "Iteration: 701/10000, Loss: 0.05050330609083176\n",
      "Iteration: 702/10000, Loss: 0.06262341886758804\n",
      "Iteration: 703/10000, Loss: 0.049881260842084885\n",
      "Iteration: 704/10000, Loss: 0.043271034955978394\n",
      "Iteration: 705/10000, Loss: 0.057797499001026154\n",
      "Iteration: 706/10000, Loss: 0.06162305548787117\n",
      "Iteration: 707/10000, Loss: 0.04477730765938759\n",
      "Iteration: 708/10000, Loss: 0.07684706896543503\n",
      "Iteration: 709/10000, Loss: 0.055702511221170425\n",
      "Iteration: 710/10000, Loss: 0.041234880685806274\n",
      "Iteration: 711/10000, Loss: 0.05821707099676132\n",
      "Iteration: 712/10000, Loss: 0.03457159176468849\n",
      "Iteration: 713/10000, Loss: 0.04884137585759163\n",
      "Iteration: 714/10000, Loss: 0.0552251935005188\n",
      "Iteration: 715/10000, Loss: 0.04939558357000351\n",
      "Iteration: 716/10000, Loss: 0.040343694388866425\n",
      "Iteration: 717/10000, Loss: 0.07725170254707336\n",
      "Iteration: 718/10000, Loss: 0.04724825546145439\n",
      "Iteration: 719/10000, Loss: 0.042946673929691315\n",
      "Iteration: 720/10000, Loss: 0.058802954852581024\n",
      "Iteration: 721/10000, Loss: 0.08774035423994064\n",
      "Iteration: 722/10000, Loss: 0.051545191556215286\n",
      "Iteration: 723/10000, Loss: 0.05294063687324524\n",
      "Iteration: 724/10000, Loss: 0.04372214525938034\n",
      "Iteration: 725/10000, Loss: 0.06151531636714935\n",
      "Iteration: 726/10000, Loss: 0.05254223197698593\n",
      "Iteration: 727/10000, Loss: 0.06614171713590622\n",
      "Iteration: 728/10000, Loss: 0.07502622157335281\n",
      "Iteration: 729/10000, Loss: 0.0445452481508255\n",
      "Iteration: 730/10000, Loss: 0.05238408222794533\n",
      "Iteration: 731/10000, Loss: 0.050653498619794846\n",
      "Iteration: 732/10000, Loss: 0.052211977541446686\n",
      "Iteration: 733/10000, Loss: 0.05604705959558487\n",
      "Iteration: 734/10000, Loss: 0.07354443520307541\n",
      "Iteration: 735/10000, Loss: 0.04621903598308563\n",
      "Iteration: 736/10000, Loss: 0.038786087185144424\n",
      "Iteration: 737/10000, Loss: 0.05013217031955719\n",
      "Iteration: 738/10000, Loss: 0.0586247481405735\n",
      "Iteration: 739/10000, Loss: 0.051449839025735855\n",
      "Iteration: 740/10000, Loss: 0.05190092697739601\n",
      "Iteration: 741/10000, Loss: 0.039590656757354736\n",
      "Iteration: 742/10000, Loss: 0.051796410232782364\n",
      "Iteration: 743/10000, Loss: 0.03118649497628212\n",
      "Iteration: 744/10000, Loss: 0.04437738284468651\n",
      "Iteration: 745/10000, Loss: 0.045196592807769775\n",
      "Iteration: 746/10000, Loss: 0.0687815323472023\n",
      "Iteration: 747/10000, Loss: 0.05332592502236366\n",
      "Iteration: 748/10000, Loss: 0.048902224749326706\n",
      "Iteration: 749/10000, Loss: 0.04862247407436371\n",
      "Iteration: 750/10000, Loss: 0.062422044575214386\n",
      "Iteration: 751/10000, Loss: 0.058625198900699615\n",
      "Iteration: 752/10000, Loss: 0.046904467046260834\n",
      "Iteration: 753/10000, Loss: 0.04912254214286804\n",
      "Iteration: 754/10000, Loss: 0.05154251679778099\n",
      "Iteration: 755/10000, Loss: 0.04734838753938675\n",
      "Iteration: 756/10000, Loss: 0.05778595060110092\n",
      "Iteration: 757/10000, Loss: 0.03762783110141754\n",
      "Iteration: 758/10000, Loss: 0.049869854003190994\n",
      "Iteration: 759/10000, Loss: 0.057764824479818344\n",
      "Iteration: 760/10000, Loss: 0.07059766352176666\n",
      "Iteration: 761/10000, Loss: 0.05839676037430763\n",
      "Iteration: 762/10000, Loss: 0.04112335667014122\n",
      "Iteration: 763/10000, Loss: 0.037878651171922684\n",
      "Iteration: 764/10000, Loss: 0.04051695764064789\n",
      "Iteration: 765/10000, Loss: 0.056507743895053864\n",
      "Iteration: 766/10000, Loss: 0.04824962466955185\n",
      "Iteration: 767/10000, Loss: 0.06804173439741135\n",
      "Iteration: 768/10000, Loss: 0.06865278631448746\n",
      "Iteration: 769/10000, Loss: 0.050282444804906845\n",
      "Iteration: 770/10000, Loss: 0.048086896538734436\n",
      "Iteration: 771/10000, Loss: 0.060522884130477905\n",
      "Iteration: 772/10000, Loss: 0.05326750501990318\n",
      "Iteration: 773/10000, Loss: 0.051279693841934204\n",
      "Iteration: 774/10000, Loss: 0.052203621715307236\n",
      "Iteration: 775/10000, Loss: 0.061097241938114166\n",
      "Iteration: 776/10000, Loss: 0.0442260205745697\n",
      "Iteration: 777/10000, Loss: 0.06539251655340195\n",
      "Iteration: 778/10000, Loss: 0.044985197484493256\n",
      "Iteration: 779/10000, Loss: 0.05370995029807091\n",
      "Iteration: 780/10000, Loss: 0.05359821394085884\n",
      "Iteration: 781/10000, Loss: 0.046070121228694916\n",
      "Iteration: 782/10000, Loss: 0.051530491560697556\n",
      "Iteration: 783/10000, Loss: 0.051915690302848816\n",
      "Iteration: 784/10000, Loss: 0.046222083270549774\n",
      "Iteration: 785/10000, Loss: 0.04622562229633331\n",
      "Iteration: 786/10000, Loss: 0.04317908361554146\n",
      "Iteration: 787/10000, Loss: 0.05791713669896126\n",
      "Iteration: 788/10000, Loss: 0.0667659342288971\n",
      "Iteration: 789/10000, Loss: 0.04883545637130737\n",
      "Iteration: 790/10000, Loss: 0.056156158447265625\n",
      "Iteration: 791/10000, Loss: 0.046280357986688614\n",
      "Iteration: 792/10000, Loss: 0.049599792808294296\n",
      "Iteration: 793/10000, Loss: 0.042608410120010376\n",
      "Iteration: 794/10000, Loss: 0.05167035758495331\n",
      "Iteration: 795/10000, Loss: 0.042139604687690735\n",
      "Iteration: 796/10000, Loss: 0.048003409057855606\n",
      "Iteration: 797/10000, Loss: 0.04592587426304817\n",
      "Iteration: 798/10000, Loss: 0.05857592448592186\n",
      "Iteration: 799/10000, Loss: 0.06076889485120773\n",
      "Iteration: 800/10000, Loss: 0.043179549276828766\n",
      "Average test loss:  0.0036\n",
      "Iteration: 801/10000, Loss: 0.033162154257297516\n",
      "Iteration: 802/10000, Loss: 0.06323908269405365\n",
      "Iteration: 803/10000, Loss: 0.061843037605285645\n",
      "Iteration: 804/10000, Loss: 0.05126380920410156\n",
      "Iteration: 805/10000, Loss: 0.049461815506219864\n",
      "Iteration: 806/10000, Loss: 0.04879200458526611\n",
      "Iteration: 807/10000, Loss: 0.04810246825218201\n",
      "Iteration: 808/10000, Loss: 0.036969609558582306\n",
      "Iteration: 809/10000, Loss: 0.0362374372780323\n",
      "Iteration: 810/10000, Loss: 0.04799716919660568\n",
      "Iteration: 811/10000, Loss: 0.039299629628658295\n",
      "Iteration: 812/10000, Loss: 0.04275017976760864\n",
      "Iteration: 813/10000, Loss: 0.04723987728357315\n",
      "Iteration: 814/10000, Loss: 0.06194404140114784\n",
      "Iteration: 815/10000, Loss: 0.042021799832582474\n",
      "Iteration: 816/10000, Loss: 0.04210662841796875\n",
      "Iteration: 817/10000, Loss: 0.042442839592695236\n",
      "Iteration: 818/10000, Loss: 0.045589640736579895\n",
      "Iteration: 819/10000, Loss: 0.05871378630399704\n",
      "Iteration: 820/10000, Loss: 0.058486100286245346\n",
      "Iteration: 821/10000, Loss: 0.053145986050367355\n",
      "Iteration: 822/10000, Loss: 0.03821711614727974\n",
      "Iteration: 823/10000, Loss: 0.056311409920454025\n",
      "Iteration: 824/10000, Loss: 0.05058018118143082\n",
      "Iteration: 825/10000, Loss: 0.03621190786361694\n",
      "Iteration: 826/10000, Loss: 0.046238746494054794\n",
      "Iteration: 827/10000, Loss: 0.06404822319746017\n",
      "Iteration: 828/10000, Loss: 0.06799938529729843\n",
      "Iteration: 829/10000, Loss: 0.04641563817858696\n",
      "Iteration: 830/10000, Loss: 0.0472264364361763\n",
      "Iteration: 831/10000, Loss: 0.03775420039892197\n",
      "Iteration: 832/10000, Loss: 0.0411209911108017\n",
      "Iteration: 833/10000, Loss: 0.03484063968062401\n",
      "Iteration: 834/10000, Loss: 0.03929189592599869\n",
      "Iteration: 835/10000, Loss: 0.04495633766055107\n",
      "Iteration: 836/10000, Loss: 0.04866147041320801\n",
      "Iteration: 837/10000, Loss: 0.040927231311798096\n",
      "Iteration: 838/10000, Loss: 0.06485191732645035\n",
      "Iteration: 839/10000, Loss: 0.0741768479347229\n",
      "Iteration: 840/10000, Loss: 0.046213481575250626\n",
      "Iteration: 841/10000, Loss: 0.058374565094709396\n",
      "Iteration: 842/10000, Loss: 0.03879164904356003\n",
      "Iteration: 843/10000, Loss: 0.059271421283483505\n",
      "Iteration: 844/10000, Loss: 0.04417046159505844\n",
      "Iteration: 845/10000, Loss: 0.0403682142496109\n",
      "Iteration: 846/10000, Loss: 0.05299697816371918\n",
      "Iteration: 847/10000, Loss: 0.051002707332372665\n",
      "Iteration: 848/10000, Loss: 0.04114716500043869\n",
      "Iteration: 849/10000, Loss: 0.038458649069070816\n",
      "Iteration: 850/10000, Loss: 0.05189024657011032\n",
      "Iteration: 851/10000, Loss: 0.03963906317949295\n",
      "Iteration: 852/10000, Loss: 0.04559681937098503\n",
      "Iteration: 853/10000, Loss: 0.05809375271201134\n",
      "Iteration: 854/10000, Loss: 0.037847697734832764\n",
      "Iteration: 855/10000, Loss: 0.06205259636044502\n",
      "Iteration: 856/10000, Loss: 0.0435313805937767\n",
      "Iteration: 857/10000, Loss: 0.04546182602643967\n",
      "Iteration: 858/10000, Loss: 0.05182759463787079\n",
      "Iteration: 859/10000, Loss: 0.035023193806409836\n",
      "Iteration: 860/10000, Loss: 0.05793101713061333\n",
      "Iteration: 861/10000, Loss: 0.043745871633291245\n",
      "Iteration: 862/10000, Loss: 0.041631028056144714\n",
      "Iteration: 863/10000, Loss: 0.057317037135362625\n",
      "Iteration: 864/10000, Loss: 0.048061296343803406\n",
      "Iteration: 865/10000, Loss: 0.054065678268671036\n",
      "Iteration: 866/10000, Loss: 0.05389748886227608\n",
      "Iteration: 867/10000, Loss: 0.04952232912182808\n",
      "Iteration: 868/10000, Loss: 0.052308786660432816\n",
      "Iteration: 869/10000, Loss: 0.04457896202802658\n",
      "Iteration: 870/10000, Loss: 0.04681621119379997\n",
      "Iteration: 871/10000, Loss: 0.03935087472200394\n",
      "Iteration: 872/10000, Loss: 0.03871191665530205\n",
      "Iteration: 873/10000, Loss: 0.03844066709280014\n",
      "Iteration: 874/10000, Loss: 0.043453436344861984\n",
      "Iteration: 875/10000, Loss: 0.040400948375463486\n",
      "Iteration: 876/10000, Loss: 0.05350564420223236\n",
      "Iteration: 877/10000, Loss: 0.04267110675573349\n",
      "Iteration: 878/10000, Loss: 0.048542071133852005\n",
      "Iteration: 879/10000, Loss: 0.06086348742246628\n",
      "Iteration: 880/10000, Loss: 0.05402003228664398\n",
      "Iteration: 881/10000, Loss: 0.03733271732926369\n",
      "Iteration: 882/10000, Loss: 0.03707100823521614\n",
      "Iteration: 883/10000, Loss: 0.053630657494068146\n",
      "Iteration: 884/10000, Loss: 0.03834173083305359\n",
      "Iteration: 885/10000, Loss: 0.04373863711953163\n",
      "Iteration: 886/10000, Loss: 0.04767332598567009\n",
      "Iteration: 887/10000, Loss: 0.040775932371616364\n",
      "Iteration: 888/10000, Loss: 0.05930723249912262\n",
      "Iteration: 889/10000, Loss: 0.050088055431842804\n",
      "Iteration: 890/10000, Loss: 0.03540946543216705\n",
      "Iteration: 891/10000, Loss: 0.036093179136514664\n",
      "Iteration: 892/10000, Loss: 0.026695869863033295\n",
      "Iteration: 893/10000, Loss: 0.03595489636063576\n",
      "Iteration: 894/10000, Loss: 0.040278155356645584\n",
      "Iteration: 895/10000, Loss: 0.0710129588842392\n",
      "Iteration: 896/10000, Loss: 0.020062090829014778\n",
      "Iteration: 897/10000, Loss: 0.06599406898021698\n",
      "Iteration: 898/10000, Loss: 0.04997952654957771\n",
      "Iteration: 899/10000, Loss: 0.05657001957297325\n",
      "Iteration: 900/10000, Loss: 0.05367894470691681\n",
      "Average test loss:  0.0035\n",
      "Iteration: 901/10000, Loss: 0.03377677872776985\n",
      "Iteration: 902/10000, Loss: 0.041623834520578384\n",
      "Iteration: 903/10000, Loss: 0.0341479666531086\n",
      "Iteration: 904/10000, Loss: 0.02468561753630638\n",
      "Iteration: 905/10000, Loss: 0.03501443192362785\n",
      "Iteration: 906/10000, Loss: 0.057474978268146515\n",
      "Iteration: 907/10000, Loss: 0.037247877568006516\n",
      "Iteration: 908/10000, Loss: 0.05180473253130913\n",
      "Iteration: 909/10000, Loss: 0.04100460559129715\n",
      "Iteration: 910/10000, Loss: 0.03532211482524872\n",
      "Iteration: 911/10000, Loss: 0.050364524126052856\n",
      "Iteration: 912/10000, Loss: 0.08850733190774918\n",
      "Iteration: 913/10000, Loss: 0.02996712177991867\n",
      "Iteration: 914/10000, Loss: 0.04317742958664894\n",
      "Iteration: 915/10000, Loss: 0.026414917781949043\n",
      "Iteration: 916/10000, Loss: 0.04362168908119202\n",
      "Iteration: 917/10000, Loss: 0.031059568747878075\n",
      "Iteration: 918/10000, Loss: 0.026541491970419884\n",
      "Iteration: 919/10000, Loss: 0.05263552442193031\n",
      "Iteration: 920/10000, Loss: 0.03758038952946663\n",
      "Iteration: 921/10000, Loss: 0.04213588684797287\n",
      "Iteration: 922/10000, Loss: 0.04582192748785019\n",
      "Iteration: 923/10000, Loss: 0.04947381839156151\n",
      "Iteration: 924/10000, Loss: 0.04455883800983429\n",
      "Iteration: 925/10000, Loss: 0.03678774833679199\n",
      "Iteration: 926/10000, Loss: 0.03777641803026199\n",
      "Iteration: 927/10000, Loss: 0.04875026270747185\n",
      "Iteration: 928/10000, Loss: 0.04908522963523865\n",
      "Iteration: 929/10000, Loss: 0.04606455937027931\n",
      "Iteration: 930/10000, Loss: 0.04994559288024902\n",
      "Iteration: 931/10000, Loss: 0.056546278297901154\n",
      "Iteration: 932/10000, Loss: 0.04079728573560715\n",
      "Iteration: 933/10000, Loss: 0.05235210061073303\n",
      "Iteration: 934/10000, Loss: 0.03938291594386101\n",
      "Iteration: 935/10000, Loss: 0.053614381700754166\n",
      "Iteration: 936/10000, Loss: 0.04312965273857117\n",
      "Iteration: 937/10000, Loss: 0.05334783345460892\n",
      "Iteration: 938/10000, Loss: 0.056303318589925766\n",
      "Iteration: 939/10000, Loss: 0.06098920479416847\n",
      "Iteration: 940/10000, Loss: 0.05261479318141937\n",
      "Iteration: 941/10000, Loss: 0.046267345547676086\n",
      "Iteration: 942/10000, Loss: 0.06879379600286484\n",
      "Iteration: 943/10000, Loss: 0.03871987760066986\n",
      "Iteration: 944/10000, Loss: 0.04315466061234474\n",
      "Iteration: 945/10000, Loss: 0.056361813098192215\n",
      "Iteration: 946/10000, Loss: 0.04179016500711441\n",
      "Iteration: 947/10000, Loss: 0.04169818386435509\n",
      "Iteration: 948/10000, Loss: 0.036447398364543915\n",
      "Iteration: 949/10000, Loss: 0.04664101079106331\n",
      "Iteration: 950/10000, Loss: 0.038331303745508194\n",
      "Iteration: 951/10000, Loss: 0.03246669843792915\n",
      "Iteration: 952/10000, Loss: 0.03564781695604324\n",
      "Iteration: 953/10000, Loss: 0.03613930568099022\n",
      "Iteration: 954/10000, Loss: 0.04680449143052101\n",
      "Iteration: 955/10000, Loss: 0.04012274369597435\n",
      "Iteration: 956/10000, Loss: 0.054708246141672134\n",
      "Iteration: 957/10000, Loss: 0.07096270471811295\n",
      "Iteration: 958/10000, Loss: 0.029172899201512337\n",
      "Iteration: 959/10000, Loss: 0.04396508261561394\n",
      "Iteration: 960/10000, Loss: 0.05022229626774788\n",
      "Iteration: 961/10000, Loss: 0.05031846463680267\n",
      "Iteration: 962/10000, Loss: 0.032243967056274414\n",
      "Iteration: 963/10000, Loss: 0.040860455483198166\n",
      "Iteration: 964/10000, Loss: 0.03865060210227966\n",
      "Iteration: 965/10000, Loss: 0.05134954676032066\n",
      "Iteration: 966/10000, Loss: 0.046266812831163406\n",
      "Iteration: 967/10000, Loss: 0.08969490975141525\n",
      "Iteration: 968/10000, Loss: 0.05095292255282402\n",
      "Iteration: 969/10000, Loss: 0.03554286062717438\n",
      "Iteration: 970/10000, Loss: 0.04100608825683594\n",
      "Iteration: 971/10000, Loss: 0.03607336804270744\n",
      "Iteration: 972/10000, Loss: 0.05926448479294777\n",
      "Iteration: 973/10000, Loss: 0.04991508647799492\n",
      "Iteration: 974/10000, Loss: 0.04589797183871269\n",
      "Iteration: 975/10000, Loss: 0.053322382271289825\n",
      "Iteration: 976/10000, Loss: 0.04178822785615921\n",
      "Iteration: 977/10000, Loss: 0.028649797663092613\n",
      "Iteration: 978/10000, Loss: 0.05016201362013817\n",
      "Iteration: 979/10000, Loss: 0.05454196035861969\n",
      "Iteration: 980/10000, Loss: 0.02874881774187088\n",
      "Iteration: 981/10000, Loss: 0.040305037051439285\n",
      "Iteration: 982/10000, Loss: 0.05647215247154236\n",
      "Iteration: 983/10000, Loss: 0.050476133823394775\n",
      "Iteration: 984/10000, Loss: 0.036481138318777084\n",
      "Iteration: 985/10000, Loss: 0.029274873435497284\n",
      "Iteration: 986/10000, Loss: 0.03716132789850235\n",
      "Iteration: 987/10000, Loss: 0.055286724120378494\n",
      "Iteration: 988/10000, Loss: 0.054709360003471375\n",
      "Iteration: 989/10000, Loss: 0.04662151262164116\n",
      "Iteration: 990/10000, Loss: 0.045827656984329224\n",
      "Iteration: 991/10000, Loss: 0.04049740731716156\n",
      "Iteration: 992/10000, Loss: 0.03922394663095474\n",
      "Iteration: 993/10000, Loss: 0.03837446868419647\n",
      "Iteration: 994/10000, Loss: 0.04079105332493782\n",
      "Iteration: 995/10000, Loss: 0.047565754503011703\n",
      "Iteration: 996/10000, Loss: 0.05045279115438461\n",
      "Iteration: 997/10000, Loss: 0.062139421701431274\n",
      "Iteration: 998/10000, Loss: 0.032624371349811554\n",
      "Iteration: 999/10000, Loss: 0.054248176515102386\n",
      "Iteration: 1000/10000, Loss: 0.04271316155791283\n",
      "Average test loss:  0.0023\n",
      "Iteration: 1001/10000, Loss: 0.02982373908162117\n",
      "Iteration: 1002/10000, Loss: 0.047303516417741776\n",
      "Iteration: 1003/10000, Loss: 0.044197771698236465\n",
      "Iteration: 1004/10000, Loss: 0.05599895119667053\n",
      "Iteration: 1005/10000, Loss: 0.034276749938726425\n",
      "Iteration: 1006/10000, Loss: 0.036646198481321335\n",
      "Iteration: 1007/10000, Loss: 0.04677055776119232\n",
      "Iteration: 1008/10000, Loss: 0.035928916186094284\n",
      "Iteration: 1009/10000, Loss: 0.034551914781332016\n",
      "Iteration: 1010/10000, Loss: 0.04650940001010895\n",
      "Iteration: 1011/10000, Loss: 0.05795354023575783\n",
      "Iteration: 1012/10000, Loss: 0.039177145808935165\n",
      "Iteration: 1013/10000, Loss: 0.03503353148698807\n",
      "Iteration: 1014/10000, Loss: 0.04695652797818184\n",
      "Iteration: 1015/10000, Loss: 0.044196806848049164\n",
      "Iteration: 1016/10000, Loss: 0.06077125295996666\n",
      "Iteration: 1017/10000, Loss: 0.0661676749587059\n",
      "Iteration: 1018/10000, Loss: 0.03850425407290459\n",
      "Iteration: 1019/10000, Loss: 0.05474080890417099\n",
      "Iteration: 1020/10000, Loss: 0.046490948647260666\n",
      "Iteration: 1021/10000, Loss: 0.05253518372774124\n",
      "Iteration: 1022/10000, Loss: 0.05169486999511719\n",
      "Iteration: 1023/10000, Loss: 0.05300400033593178\n",
      "Iteration: 1024/10000, Loss: 0.04274921864271164\n",
      "Iteration: 1025/10000, Loss: 0.05038396641612053\n",
      "Iteration: 1026/10000, Loss: 0.052859555929899216\n",
      "Iteration: 1027/10000, Loss: 0.04460667818784714\n",
      "Iteration: 1028/10000, Loss: 0.03624137490987778\n",
      "Iteration: 1029/10000, Loss: 0.034779537469148636\n",
      "Iteration: 1030/10000, Loss: 0.039415355771780014\n",
      "Iteration: 1031/10000, Loss: 0.038148488849401474\n",
      "Iteration: 1032/10000, Loss: 0.037934087216854095\n",
      "Iteration: 1033/10000, Loss: 0.045211926102638245\n",
      "Iteration: 1034/10000, Loss: 0.046551529318094254\n",
      "Iteration: 1035/10000, Loss: 0.03644581139087677\n",
      "Iteration: 1036/10000, Loss: 0.0318073034286499\n",
      "Iteration: 1037/10000, Loss: 0.0281639713793993\n",
      "Iteration: 1038/10000, Loss: 0.04098360612988472\n",
      "Iteration: 1039/10000, Loss: 0.04509679228067398\n",
      "Iteration: 1040/10000, Loss: 0.039466068148612976\n",
      "Iteration: 1041/10000, Loss: 0.043448783457279205\n",
      "Iteration: 1042/10000, Loss: 0.06624547392129898\n",
      "Iteration: 1043/10000, Loss: 0.028184648603200912\n",
      "Iteration: 1044/10000, Loss: 0.03501531481742859\n",
      "Iteration: 1045/10000, Loss: 0.03878789767622948\n",
      "Iteration: 1046/10000, Loss: 0.04084860160946846\n",
      "Iteration: 1047/10000, Loss: 0.06760101020336151\n",
      "Iteration: 1048/10000, Loss: 0.05123687908053398\n",
      "Iteration: 1049/10000, Loss: 0.03876205533742905\n",
      "Iteration: 1050/10000, Loss: 0.06190221756696701\n",
      "Iteration: 1051/10000, Loss: 0.045670077204704285\n",
      "Iteration: 1052/10000, Loss: 0.04319930449128151\n",
      "Iteration: 1053/10000, Loss: 0.04187820479273796\n",
      "Iteration: 1054/10000, Loss: 0.04519663378596306\n",
      "Iteration: 1055/10000, Loss: 0.05747983977198601\n",
      "Iteration: 1056/10000, Loss: 0.043036602437496185\n",
      "Iteration: 1057/10000, Loss: 0.04237908497452736\n",
      "Iteration: 1058/10000, Loss: 0.03170100226998329\n",
      "Iteration: 1059/10000, Loss: 0.046088919043540955\n",
      "Iteration: 1060/10000, Loss: 0.05650026351213455\n",
      "Iteration: 1061/10000, Loss: 0.04332385212182999\n",
      "Iteration: 1062/10000, Loss: 0.04336721450090408\n",
      "Iteration: 1063/10000, Loss: 0.034601982682943344\n",
      "Iteration: 1064/10000, Loss: 0.04621857777237892\n",
      "Iteration: 1065/10000, Loss: 0.031796958297491074\n",
      "Iteration: 1066/10000, Loss: 0.028521757572889328\n",
      "Iteration: 1067/10000, Loss: 0.05257199704647064\n",
      "Iteration: 1068/10000, Loss: 0.04030619561672211\n",
      "Iteration: 1069/10000, Loss: 0.021758176386356354\n",
      "Iteration: 1070/10000, Loss: 0.04446129873394966\n",
      "Iteration: 1071/10000, Loss: 0.061091016978025436\n",
      "Iteration: 1072/10000, Loss: 0.04296218976378441\n",
      "Iteration: 1073/10000, Loss: 0.02913648635149002\n",
      "Iteration: 1074/10000, Loss: 0.04687390476465225\n",
      "Iteration: 1075/10000, Loss: 0.043248943984508514\n",
      "Iteration: 1076/10000, Loss: 0.03466897830367088\n",
      "Iteration: 1077/10000, Loss: 0.055488668382167816\n",
      "Iteration: 1078/10000, Loss: 0.03516661003232002\n",
      "Iteration: 1079/10000, Loss: 0.03432701155543327\n",
      "Iteration: 1080/10000, Loss: 0.028466347604990005\n",
      "Iteration: 1081/10000, Loss: 0.05814125016331673\n",
      "Iteration: 1082/10000, Loss: 0.06703785061836243\n",
      "Iteration: 1083/10000, Loss: 0.04257333278656006\n",
      "Iteration: 1084/10000, Loss: 0.02833343856036663\n",
      "Iteration: 1085/10000, Loss: 0.04295038431882858\n",
      "Iteration: 1086/10000, Loss: 0.034020137041807175\n",
      "Iteration: 1087/10000, Loss: 0.032169658690690994\n",
      "Iteration: 1088/10000, Loss: 0.037403639405965805\n",
      "Iteration: 1089/10000, Loss: 0.04001091793179512\n",
      "Iteration: 1090/10000, Loss: 0.047922294586896896\n",
      "Iteration: 1091/10000, Loss: 0.04450210556387901\n",
      "Iteration: 1092/10000, Loss: 0.04342677816748619\n",
      "Iteration: 1093/10000, Loss: 0.04655250906944275\n",
      "Iteration: 1094/10000, Loss: 0.04723992198705673\n",
      "Iteration: 1095/10000, Loss: 0.0406309999525547\n",
      "Iteration: 1096/10000, Loss: 0.03327552601695061\n",
      "Iteration: 1097/10000, Loss: 0.04164563864469528\n",
      "Iteration: 1098/10000, Loss: 0.03990881145000458\n",
      "Iteration: 1099/10000, Loss: 0.03426966071128845\n",
      "Iteration: 1100/10000, Loss: 0.041112568229436874\n",
      "Average test loss:  0.0039\n",
      "Iteration: 1101/10000, Loss: 0.057168204337358475\n",
      "Iteration: 1102/10000, Loss: 0.04311733692884445\n",
      "Iteration: 1103/10000, Loss: 0.040603164583444595\n",
      "Iteration: 1104/10000, Loss: 0.03477635979652405\n",
      "Iteration: 1105/10000, Loss: 0.040478337556123734\n",
      "Iteration: 1106/10000, Loss: 0.05113181099295616\n",
      "Iteration: 1107/10000, Loss: 0.03377777338027954\n",
      "Iteration: 1108/10000, Loss: 0.03234269842505455\n",
      "Iteration: 1109/10000, Loss: 0.0403183288872242\n",
      "Iteration: 1110/10000, Loss: 0.03571463003754616\n",
      "Iteration: 1111/10000, Loss: 0.039227958768606186\n",
      "Iteration: 1112/10000, Loss: 0.04980475455522537\n",
      "Iteration: 1113/10000, Loss: 0.03654983639717102\n",
      "Iteration: 1114/10000, Loss: 0.04640761762857437\n",
      "Iteration: 1115/10000, Loss: 0.035995662212371826\n",
      "Iteration: 1116/10000, Loss: 0.054939888417720795\n",
      "Iteration: 1117/10000, Loss: 0.0513770692050457\n",
      "Iteration: 1118/10000, Loss: 0.039593275636434555\n",
      "Iteration: 1119/10000, Loss: 0.03517919033765793\n",
      "Iteration: 1120/10000, Loss: 0.04222547262907028\n",
      "Iteration: 1121/10000, Loss: 0.037342965602874756\n",
      "Iteration: 1122/10000, Loss: 0.041643477976322174\n",
      "Iteration: 1123/10000, Loss: 0.036658160388469696\n",
      "Iteration: 1124/10000, Loss: 0.050666872411966324\n",
      "Iteration: 1125/10000, Loss: 0.05634894222021103\n",
      "Iteration: 1126/10000, Loss: 0.05312667787075043\n",
      "Iteration: 1127/10000, Loss: 0.051308199763298035\n",
      "Iteration: 1128/10000, Loss: 0.042286284267902374\n",
      "Iteration: 1129/10000, Loss: 0.05633406713604927\n",
      "Iteration: 1130/10000, Loss: 0.050066761672496796\n",
      "Iteration: 1131/10000, Loss: 0.04153934493660927\n",
      "Iteration: 1132/10000, Loss: 0.04549102857708931\n",
      "Iteration: 1133/10000, Loss: 0.04101984202861786\n",
      "Iteration: 1134/10000, Loss: 0.03587833046913147\n",
      "Iteration: 1135/10000, Loss: 0.04654676467180252\n",
      "Iteration: 1136/10000, Loss: 0.04519377648830414\n",
      "Iteration: 1137/10000, Loss: 0.03973093628883362\n",
      "Iteration: 1138/10000, Loss: 0.052547477185726166\n",
      "Iteration: 1139/10000, Loss: 0.033662524074316025\n",
      "Iteration: 1140/10000, Loss: 0.029033036902546883\n",
      "Iteration: 1141/10000, Loss: 0.04391215741634369\n",
      "Iteration: 1142/10000, Loss: 0.042891725897789\n",
      "Iteration: 1143/10000, Loss: 0.08019519597291946\n",
      "Iteration: 1144/10000, Loss: 0.037681251764297485\n",
      "Iteration: 1145/10000, Loss: 0.03906184062361717\n",
      "Iteration: 1146/10000, Loss: 0.03059413470327854\n",
      "Iteration: 1147/10000, Loss: 0.050734639167785645\n",
      "Iteration: 1148/10000, Loss: 0.03427507355809212\n",
      "Iteration: 1149/10000, Loss: 0.04240292310714722\n",
      "Iteration: 1150/10000, Loss: 0.04963233694434166\n",
      "Iteration: 1151/10000, Loss: 0.04433533549308777\n",
      "Iteration: 1152/10000, Loss: 0.04406708478927612\n",
      "Iteration: 1153/10000, Loss: 0.044531870633363724\n",
      "Iteration: 1154/10000, Loss: 0.04093705117702484\n",
      "Iteration: 1155/10000, Loss: 0.036020006984472275\n",
      "Iteration: 1156/10000, Loss: 0.028950832784175873\n",
      "Iteration: 1157/10000, Loss: 0.04560396820306778\n",
      "Iteration: 1158/10000, Loss: 0.048812385648489\n",
      "Iteration: 1159/10000, Loss: 0.04750443622469902\n",
      "Iteration: 1160/10000, Loss: 0.030407220125198364\n",
      "Iteration: 1161/10000, Loss: 0.043915074318647385\n",
      "Iteration: 1162/10000, Loss: 0.034181635826826096\n",
      "Iteration: 1163/10000, Loss: 0.04785023629665375\n",
      "Iteration: 1164/10000, Loss: 0.04869484901428223\n",
      "Iteration: 1165/10000, Loss: 0.04721507430076599\n",
      "Iteration: 1166/10000, Loss: 0.03616281598806381\n",
      "Iteration: 1167/10000, Loss: 0.039655279368162155\n",
      "Iteration: 1168/10000, Loss: 0.02803659997880459\n",
      "Iteration: 1169/10000, Loss: 0.053359925746917725\n",
      "Iteration: 1170/10000, Loss: 0.03952348977327347\n",
      "Iteration: 1171/10000, Loss: 0.04349992424249649\n",
      "Iteration: 1172/10000, Loss: 0.03086075931787491\n",
      "Iteration: 1173/10000, Loss: 0.03755874186754227\n",
      "Iteration: 1174/10000, Loss: 0.035141389816999435\n",
      "Iteration: 1175/10000, Loss: 0.03454308584332466\n",
      "Iteration: 1176/10000, Loss: 0.03765176609158516\n",
      "Iteration: 1177/10000, Loss: 0.03709562495350838\n",
      "Iteration: 1178/10000, Loss: 0.03423669561743736\n",
      "Iteration: 1179/10000, Loss: 0.03186799958348274\n",
      "Iteration: 1180/10000, Loss: 0.04116378352046013\n",
      "Iteration: 1181/10000, Loss: 0.03970801830291748\n",
      "Iteration: 1182/10000, Loss: 0.030646273866295815\n",
      "Iteration: 1183/10000, Loss: 0.04464254528284073\n",
      "Iteration: 1184/10000, Loss: 0.0287544634193182\n",
      "Iteration: 1185/10000, Loss: 0.03609419986605644\n",
      "Iteration: 1186/10000, Loss: 0.056173503398895264\n",
      "Iteration: 1187/10000, Loss: 0.03571568429470062\n",
      "Iteration: 1188/10000, Loss: 0.051447659730911255\n",
      "Iteration: 1189/10000, Loss: 0.03376815468072891\n",
      "Iteration: 1190/10000, Loss: 0.026157137006521225\n",
      "Iteration: 1191/10000, Loss: 0.03346913680434227\n",
      "Iteration: 1192/10000, Loss: 0.0299052856862545\n",
      "Iteration: 1193/10000, Loss: 0.042539771646261215\n",
      "Iteration: 1194/10000, Loss: 0.030206851661205292\n",
      "Iteration: 1195/10000, Loss: 0.04167231544852257\n",
      "Iteration: 1196/10000, Loss: 0.05375422537326813\n",
      "Iteration: 1197/10000, Loss: 0.027640778571367264\n",
      "Iteration: 1198/10000, Loss: 0.049737393856048584\n",
      "Iteration: 1199/10000, Loss: 0.03724005073308945\n",
      "Iteration: 1200/10000, Loss: 0.026834402233362198\n",
      "Average test loss:  0.0035\n",
      "Iteration: 1201/10000, Loss: 0.024282895028591156\n",
      "Iteration: 1202/10000, Loss: 0.043888431042432785\n",
      "Iteration: 1203/10000, Loss: 0.044292058795690536\n",
      "Iteration: 1204/10000, Loss: 0.05023162439465523\n",
      "Iteration: 1205/10000, Loss: 0.03234025835990906\n",
      "Iteration: 1206/10000, Loss: 0.039822135120630264\n",
      "Iteration: 1207/10000, Loss: 0.03685552626848221\n",
      "Iteration: 1208/10000, Loss: 0.05162131041288376\n",
      "Iteration: 1209/10000, Loss: 0.03334295004606247\n",
      "Iteration: 1210/10000, Loss: 0.03982486203312874\n",
      "Iteration: 1211/10000, Loss: 0.03434683755040169\n",
      "Iteration: 1212/10000, Loss: 0.039976052939891815\n",
      "Iteration: 1213/10000, Loss: 0.03453968092799187\n",
      "Iteration: 1214/10000, Loss: 0.034430909901857376\n",
      "Iteration: 1215/10000, Loss: 0.047350626438856125\n",
      "Iteration: 1216/10000, Loss: 0.047939594835042953\n",
      "Iteration: 1217/10000, Loss: 0.0454418919980526\n",
      "Iteration: 1218/10000, Loss: 0.025929955765604973\n",
      "Iteration: 1219/10000, Loss: 0.03381641209125519\n",
      "Iteration: 1220/10000, Loss: 0.028355248272418976\n",
      "Iteration: 1221/10000, Loss: 0.039998337626457214\n",
      "Iteration: 1222/10000, Loss: 0.03922770917415619\n",
      "Iteration: 1223/10000, Loss: 0.04239164665341377\n",
      "Iteration: 1224/10000, Loss: 0.02738223224878311\n",
      "Iteration: 1225/10000, Loss: 0.05499592795968056\n",
      "Iteration: 1226/10000, Loss: 0.04689059406518936\n",
      "Iteration: 1227/10000, Loss: 0.039492152631282806\n",
      "Iteration: 1228/10000, Loss: 0.04348988085985184\n",
      "Iteration: 1229/10000, Loss: 0.03693408519029617\n",
      "Iteration: 1230/10000, Loss: 0.025253383442759514\n",
      "Iteration: 1231/10000, Loss: 0.04306945949792862\n",
      "Iteration: 1232/10000, Loss: 0.027927130460739136\n",
      "Iteration: 1233/10000, Loss: 0.03179420530796051\n",
      "Iteration: 1234/10000, Loss: 0.027940979227423668\n",
      "Iteration: 1235/10000, Loss: 0.052115775644779205\n",
      "Iteration: 1236/10000, Loss: 0.029906516894698143\n",
      "Iteration: 1237/10000, Loss: 0.04590446874499321\n",
      "Iteration: 1238/10000, Loss: 0.03490953519940376\n",
      "Iteration: 1239/10000, Loss: 0.032463982701301575\n",
      "Iteration: 1240/10000, Loss: 0.03227471187710762\n",
      "Iteration: 1241/10000, Loss: 0.05539686232805252\n",
      "Iteration: 1242/10000, Loss: 0.033565446734428406\n",
      "Iteration: 1243/10000, Loss: 0.03268544375896454\n",
      "Iteration: 1244/10000, Loss: 0.039461322128772736\n",
      "Iteration: 1245/10000, Loss: 0.03887810558080673\n",
      "Iteration: 1246/10000, Loss: 0.037991780787706375\n",
      "Iteration: 1247/10000, Loss: 0.03593989834189415\n",
      "Iteration: 1248/10000, Loss: 0.03222019970417023\n",
      "Iteration: 1249/10000, Loss: 0.03680556267499924\n",
      "Iteration: 1250/10000, Loss: 0.04242425039410591\n",
      "Iteration: 1251/10000, Loss: 0.038344353437423706\n",
      "Iteration: 1252/10000, Loss: 0.024513596668839455\n",
      "Iteration: 1253/10000, Loss: 0.04546218737959862\n",
      "Iteration: 1254/10000, Loss: 0.039459630846977234\n",
      "Iteration: 1255/10000, Loss: 0.0371832475066185\n",
      "Iteration: 1256/10000, Loss: 0.026581743732094765\n",
      "Iteration: 1257/10000, Loss: 0.039321377873420715\n",
      "Iteration: 1258/10000, Loss: 0.04416105896234512\n",
      "Iteration: 1259/10000, Loss: 0.03934759646654129\n",
      "Iteration: 1260/10000, Loss: 0.035697389394044876\n",
      "Iteration: 1261/10000, Loss: 0.053449131548404694\n",
      "Iteration: 1262/10000, Loss: 0.03621172159910202\n",
      "Iteration: 1263/10000, Loss: 0.04029169678688049\n",
      "Iteration: 1264/10000, Loss: 0.050123777240514755\n",
      "Iteration: 1265/10000, Loss: 0.03979520499706268\n",
      "Iteration: 1266/10000, Loss: 0.03366142138838768\n",
      "Iteration: 1267/10000, Loss: 0.030047856271266937\n",
      "Iteration: 1268/10000, Loss: 0.04417847469449043\n",
      "Iteration: 1269/10000, Loss: 0.032527752220630646\n",
      "Iteration: 1270/10000, Loss: 0.025484735146164894\n",
      "Iteration: 1271/10000, Loss: 0.04209078103303909\n",
      "Iteration: 1272/10000, Loss: 0.03405164182186127\n",
      "Iteration: 1273/10000, Loss: 0.04493055120110512\n",
      "Iteration: 1274/10000, Loss: 0.026623643934726715\n",
      "Iteration: 1275/10000, Loss: 0.046543899923563004\n",
      "Iteration: 1276/10000, Loss: 0.03167416900396347\n",
      "Iteration: 1277/10000, Loss: 0.03452489897608757\n",
      "Iteration: 1278/10000, Loss: 0.02658168412744999\n",
      "Iteration: 1279/10000, Loss: 0.05068333074450493\n",
      "Iteration: 1280/10000, Loss: 0.03787378966808319\n",
      "Iteration: 1281/10000, Loss: 0.02338818646967411\n",
      "Iteration: 1282/10000, Loss: 0.04450583457946777\n",
      "Iteration: 1283/10000, Loss: 0.045825086534023285\n",
      "Iteration: 1284/10000, Loss: 0.03762934356927872\n",
      "Iteration: 1285/10000, Loss: 0.034534938633441925\n",
      "Iteration: 1286/10000, Loss: 0.03685884550213814\n",
      "Iteration: 1287/10000, Loss: 0.039451226592063904\n",
      "Iteration: 1288/10000, Loss: 0.03597000241279602\n",
      "Iteration: 1289/10000, Loss: 0.03251494839787483\n",
      "Iteration: 1290/10000, Loss: 0.03340129554271698\n",
      "Iteration: 1291/10000, Loss: 0.0354471318423748\n",
      "Iteration: 1292/10000, Loss: 0.04276256263256073\n",
      "Iteration: 1293/10000, Loss: 0.04759644344449043\n",
      "Iteration: 1294/10000, Loss: 0.04324006289243698\n",
      "Iteration: 1295/10000, Loss: 0.02533104456961155\n",
      "Iteration: 1296/10000, Loss: 0.03283758834004402\n",
      "Iteration: 1297/10000, Loss: 0.03014066256582737\n",
      "Iteration: 1298/10000, Loss: 0.03388936445116997\n",
      "Iteration: 1299/10000, Loss: 0.03303319960832596\n",
      "Iteration: 1300/10000, Loss: 0.03614829480648041\n",
      "Average test loss:  0.0038\n",
      "Iteration: 1301/10000, Loss: 0.06695964187383652\n",
      "Iteration: 1302/10000, Loss: 0.04014570266008377\n",
      "Iteration: 1303/10000, Loss: 0.05480020493268967\n",
      "Iteration: 1304/10000, Loss: 0.04546540603041649\n",
      "Iteration: 1305/10000, Loss: 0.041047677397727966\n",
      "Iteration: 1306/10000, Loss: 0.03509271517395973\n",
      "Iteration: 1307/10000, Loss: 0.05547533929347992\n",
      "Iteration: 1308/10000, Loss: 0.039356499910354614\n",
      "Iteration: 1309/10000, Loss: 0.03529415652155876\n",
      "Iteration: 1310/10000, Loss: 0.04026061296463013\n",
      "Iteration: 1311/10000, Loss: 0.042614053934812546\n",
      "Iteration: 1312/10000, Loss: 0.03247453644871712\n",
      "Iteration: 1313/10000, Loss: 0.037589337676763535\n",
      "Iteration: 1314/10000, Loss: 0.03740125149488449\n",
      "Iteration: 1315/10000, Loss: 0.037954892963171005\n",
      "Iteration: 1316/10000, Loss: 0.059066712856292725\n",
      "Iteration: 1317/10000, Loss: 0.05211940035223961\n",
      "Iteration: 1318/10000, Loss: 0.046436864882707596\n",
      "Iteration: 1319/10000, Loss: 0.027363309636712074\n",
      "Iteration: 1320/10000, Loss: 0.042606059461832047\n",
      "Iteration: 1321/10000, Loss: 0.03985019773244858\n",
      "Iteration: 1322/10000, Loss: 0.05679767578840256\n",
      "Iteration: 1323/10000, Loss: 0.04551774263381958\n",
      "Iteration: 1324/10000, Loss: 0.025928283110260963\n",
      "Iteration: 1325/10000, Loss: 0.03985176980495453\n",
      "Iteration: 1326/10000, Loss: 0.03615192323923111\n",
      "Iteration: 1327/10000, Loss: 0.027880335226655006\n",
      "Iteration: 1328/10000, Loss: 0.0300479494035244\n",
      "Iteration: 1329/10000, Loss: 0.031878046691417694\n",
      "Iteration: 1330/10000, Loss: 0.04937925934791565\n",
      "Iteration: 1331/10000, Loss: 0.04080624878406525\n",
      "Iteration: 1332/10000, Loss: 0.04140147566795349\n",
      "Iteration: 1333/10000, Loss: 0.051313214004039764\n",
      "Iteration: 1334/10000, Loss: 0.03455895557999611\n",
      "Iteration: 1335/10000, Loss: 0.04367973655462265\n",
      "Iteration: 1336/10000, Loss: 0.036620426923036575\n",
      "Iteration: 1337/10000, Loss: 0.060254551470279694\n",
      "Iteration: 1338/10000, Loss: 0.03148795664310455\n",
      "Iteration: 1339/10000, Loss: 0.03833235800266266\n",
      "Iteration: 1340/10000, Loss: 0.02527845837175846\n",
      "Iteration: 1341/10000, Loss: 0.03516903892159462\n",
      "Iteration: 1342/10000, Loss: 0.05012897029519081\n",
      "Iteration: 1343/10000, Loss: 0.04611121863126755\n",
      "Iteration: 1344/10000, Loss: 0.03701670840382576\n",
      "Iteration: 1345/10000, Loss: 0.028058141469955444\n",
      "Iteration: 1346/10000, Loss: 0.030000291764736176\n",
      "Iteration: 1347/10000, Loss: 0.02848275937139988\n",
      "Iteration: 1348/10000, Loss: 0.03347133472561836\n",
      "Iteration: 1349/10000, Loss: 0.03742367774248123\n",
      "Iteration: 1350/10000, Loss: 0.04833006113767624\n",
      "Iteration: 1351/10000, Loss: 0.017880789935588837\n",
      "Iteration: 1352/10000, Loss: 0.03543391451239586\n",
      "Iteration: 1353/10000, Loss: 0.03667126223444939\n",
      "Iteration: 1354/10000, Loss: 0.02790713496506214\n",
      "Iteration: 1355/10000, Loss: 0.02799295447766781\n",
      "Iteration: 1356/10000, Loss: 0.03347408398985863\n",
      "Iteration: 1357/10000, Loss: 0.04460926353931427\n",
      "Iteration: 1358/10000, Loss: 0.061785876750946045\n",
      "Iteration: 1359/10000, Loss: 0.03545558825135231\n",
      "Iteration: 1360/10000, Loss: 0.025817379355430603\n",
      "Iteration: 1361/10000, Loss: 0.03210162743926048\n",
      "Iteration: 1362/10000, Loss: 0.045541491359472275\n",
      "Iteration: 1363/10000, Loss: 0.061411984264850616\n",
      "Iteration: 1364/10000, Loss: 0.03366924822330475\n",
      "Iteration: 1365/10000, Loss: 0.04264269396662712\n",
      "Iteration: 1366/10000, Loss: 0.03102887235581875\n",
      "Iteration: 1367/10000, Loss: 0.03839558735489845\n",
      "Iteration: 1368/10000, Loss: 0.03981122002005577\n",
      "Iteration: 1369/10000, Loss: 0.04011714458465576\n",
      "Iteration: 1370/10000, Loss: 0.023376639932394028\n",
      "Iteration: 1371/10000, Loss: 0.0478380024433136\n",
      "Iteration: 1372/10000, Loss: 0.043349817395210266\n",
      "Iteration: 1373/10000, Loss: 0.03639700263738632\n",
      "Iteration: 1374/10000, Loss: 0.046461321413517\n",
      "Iteration: 1375/10000, Loss: 0.027289411053061485\n",
      "Iteration: 1376/10000, Loss: 0.028961729258298874\n",
      "Iteration: 1377/10000, Loss: 0.0518379881978035\n",
      "Iteration: 1378/10000, Loss: 0.03611840680241585\n",
      "Iteration: 1379/10000, Loss: 0.023360630497336388\n",
      "Iteration: 1380/10000, Loss: 0.03739286586642265\n",
      "Iteration: 1381/10000, Loss: 0.03102521412074566\n",
      "Iteration: 1382/10000, Loss: 0.040666364133358\n",
      "Iteration: 1383/10000, Loss: 0.03717511147260666\n",
      "Iteration: 1384/10000, Loss: 0.03845223784446716\n",
      "Iteration: 1385/10000, Loss: 0.05212699621915817\n",
      "Iteration: 1386/10000, Loss: 0.023348858579993248\n",
      "Iteration: 1387/10000, Loss: 0.03724266216158867\n",
      "Iteration: 1388/10000, Loss: 0.039445992559194565\n",
      "Iteration: 1389/10000, Loss: 0.03470283001661301\n",
      "Iteration: 1390/10000, Loss: 0.03227398917078972\n",
      "Iteration: 1391/10000, Loss: 0.03326039761304855\n",
      "Iteration: 1392/10000, Loss: 0.03619735315442085\n",
      "Iteration: 1393/10000, Loss: 0.03404829651117325\n",
      "Iteration: 1394/10000, Loss: 0.04971926286816597\n",
      "Iteration: 1395/10000, Loss: 0.025512930005788803\n",
      "Iteration: 1396/10000, Loss: 0.04351450502872467\n",
      "Iteration: 1397/10000, Loss: 0.030360255390405655\n",
      "Iteration: 1398/10000, Loss: 0.03385335952043533\n",
      "Iteration: 1399/10000, Loss: 0.033348117023706436\n",
      "Iteration: 1400/10000, Loss: 0.03497498109936714\n",
      "Average test loss:  0.0023\n",
      "Iteration: 1401/10000, Loss: 0.040769509971141815\n",
      "Iteration: 1402/10000, Loss: 0.029842786490917206\n",
      "Iteration: 1403/10000, Loss: 0.05413346365094185\n",
      "Iteration: 1404/10000, Loss: 0.03598209470510483\n",
      "Iteration: 1405/10000, Loss: 0.031680818647146225\n",
      "Iteration: 1406/10000, Loss: 0.03452140837907791\n",
      "Iteration: 1407/10000, Loss: 0.03712494298815727\n",
      "Iteration: 1408/10000, Loss: 0.03470857813954353\n",
      "Iteration: 1409/10000, Loss: 0.033532168716192245\n",
      "Iteration: 1410/10000, Loss: 0.040018752217292786\n",
      "Iteration: 1411/10000, Loss: 0.035742152482271194\n",
      "Iteration: 1412/10000, Loss: 0.030984923243522644\n",
      "Iteration: 1413/10000, Loss: 0.046808160841464996\n",
      "Iteration: 1414/10000, Loss: 0.028540201485157013\n",
      "Iteration: 1415/10000, Loss: 0.045568227767944336\n",
      "Iteration: 1416/10000, Loss: 0.03729719668626785\n",
      "Iteration: 1417/10000, Loss: 0.041568998247385025\n",
      "Iteration: 1418/10000, Loss: 0.046400249004364014\n",
      "Iteration: 1419/10000, Loss: 0.03566141799092293\n",
      "Iteration: 1420/10000, Loss: 0.035793695598840714\n",
      "Iteration: 1421/10000, Loss: 0.030942799523472786\n",
      "Iteration: 1422/10000, Loss: 0.03576979786157608\n",
      "Iteration: 1423/10000, Loss: 0.03764006122946739\n",
      "Iteration: 1424/10000, Loss: 0.03075719252228737\n",
      "Iteration: 1425/10000, Loss: 0.045524511486291885\n",
      "Iteration: 1426/10000, Loss: 0.04672490432858467\n",
      "Iteration: 1427/10000, Loss: 0.035577453672885895\n",
      "Iteration: 1428/10000, Loss: 0.04445771872997284\n",
      "Iteration: 1429/10000, Loss: 0.03645841032266617\n",
      "Iteration: 1430/10000, Loss: 0.04487478360533714\n",
      "Iteration: 1431/10000, Loss: 0.04199148342013359\n",
      "Iteration: 1432/10000, Loss: 0.04431567341089249\n",
      "Iteration: 1433/10000, Loss: 0.025544216856360435\n",
      "Iteration: 1434/10000, Loss: 0.03982344642281532\n",
      "Iteration: 1435/10000, Loss: 0.030862510204315186\n",
      "Iteration: 1436/10000, Loss: 0.04125220701098442\n",
      "Iteration: 1437/10000, Loss: 0.028801653534173965\n",
      "Iteration: 1438/10000, Loss: 0.02445470169186592\n",
      "Iteration: 1439/10000, Loss: 0.0357937328517437\n",
      "Iteration: 1440/10000, Loss: 0.04363034665584564\n",
      "Iteration: 1441/10000, Loss: 0.039792466908693314\n",
      "Iteration: 1442/10000, Loss: 0.030483828857541084\n",
      "Iteration: 1443/10000, Loss: 0.03970655798912048\n",
      "Iteration: 1444/10000, Loss: 0.027708634734153748\n",
      "Iteration: 1445/10000, Loss: 0.04374043270945549\n",
      "Iteration: 1446/10000, Loss: 0.038097478449344635\n",
      "Iteration: 1447/10000, Loss: 0.03670108690857887\n",
      "Iteration: 1448/10000, Loss: 0.031326550990343094\n",
      "Iteration: 1449/10000, Loss: 0.0409226268529892\n",
      "Iteration: 1450/10000, Loss: 0.048955969512462616\n",
      "Iteration: 1451/10000, Loss: 0.029692906886339188\n",
      "Iteration: 1452/10000, Loss: 0.050160475075244904\n",
      "Iteration: 1453/10000, Loss: 0.048799946904182434\n",
      "Iteration: 1454/10000, Loss: 0.034417569637298584\n",
      "Iteration: 1455/10000, Loss: 0.027049975469708443\n",
      "Iteration: 1456/10000, Loss: 0.049718938767910004\n",
      "Iteration: 1457/10000, Loss: 0.034803662449121475\n",
      "Iteration: 1458/10000, Loss: 0.029383860528469086\n",
      "Iteration: 1459/10000, Loss: 0.03536171838641167\n",
      "Iteration: 1460/10000, Loss: 0.025533482432365417\n",
      "Iteration: 1461/10000, Loss: 0.03202603757381439\n",
      "Iteration: 1462/10000, Loss: 0.03329646587371826\n",
      "Iteration: 1463/10000, Loss: 0.03716297075152397\n",
      "Iteration: 1464/10000, Loss: 0.0425817109644413\n",
      "Iteration: 1465/10000, Loss: 0.0381464883685112\n",
      "Iteration: 1466/10000, Loss: 0.03842888027429581\n",
      "Iteration: 1467/10000, Loss: 0.04276512935757637\n",
      "Iteration: 1468/10000, Loss: 0.02296849526464939\n",
      "Iteration: 1469/10000, Loss: 0.0419909805059433\n",
      "Iteration: 1470/10000, Loss: 0.03779727965593338\n",
      "Iteration: 1471/10000, Loss: 0.045490190386772156\n",
      "Iteration: 1472/10000, Loss: 0.03287826105952263\n",
      "Iteration: 1473/10000, Loss: 0.03279031068086624\n",
      "Iteration: 1474/10000, Loss: 0.03437136486172676\n",
      "Iteration: 1475/10000, Loss: 0.030775193125009537\n",
      "Iteration: 1476/10000, Loss: 0.034959256649017334\n",
      "Iteration: 1477/10000, Loss: 0.039912134408950806\n",
      "Iteration: 1478/10000, Loss: 0.034113749861717224\n",
      "Iteration: 1479/10000, Loss: 0.022908974438905716\n",
      "Iteration: 1480/10000, Loss: 0.03163151815533638\n",
      "Iteration: 1481/10000, Loss: 0.04350388050079346\n",
      "Iteration: 1482/10000, Loss: 0.02664153464138508\n",
      "Iteration: 1483/10000, Loss: 0.03195178881287575\n",
      "Iteration: 1484/10000, Loss: 0.05437786504626274\n",
      "Iteration: 1485/10000, Loss: 0.03728622570633888\n",
      "Iteration: 1486/10000, Loss: 0.03813637048006058\n",
      "Iteration: 1487/10000, Loss: 0.031160123646259308\n",
      "Iteration: 1488/10000, Loss: 0.03876420482993126\n",
      "Iteration: 1489/10000, Loss: 0.04165654629468918\n",
      "Iteration: 1490/10000, Loss: 0.04424131661653519\n",
      "Iteration: 1491/10000, Loss: 0.041349418461322784\n",
      "Iteration: 1492/10000, Loss: 0.03112165629863739\n",
      "Iteration: 1493/10000, Loss: 0.04315744340419769\n",
      "Iteration: 1494/10000, Loss: 0.03472692891955376\n",
      "Iteration: 1495/10000, Loss: 0.04476296156644821\n",
      "Iteration: 1496/10000, Loss: 0.03479795530438423\n",
      "Iteration: 1497/10000, Loss: 0.0394628643989563\n",
      "Iteration: 1498/10000, Loss: 0.05005984753370285\n",
      "Iteration: 1499/10000, Loss: 0.03167594224214554\n",
      "Iteration: 1500/10000, Loss: 0.0401231087744236\n",
      "Average test loss:  0.0031\n",
      "Iteration: 1501/10000, Loss: 0.02972065471112728\n",
      "Iteration: 1502/10000, Loss: 0.033448394387960434\n",
      "Iteration: 1503/10000, Loss: 0.027792874723672867\n",
      "Iteration: 1504/10000, Loss: 0.034690145403146744\n",
      "Iteration: 1505/10000, Loss: 0.0281534306704998\n",
      "Iteration: 1506/10000, Loss: 0.024656392633914948\n",
      "Iteration: 1507/10000, Loss: 0.033047594130039215\n",
      "Iteration: 1508/10000, Loss: 0.037699706852436066\n",
      "Iteration: 1509/10000, Loss: 0.022746410220861435\n",
      "Iteration: 1510/10000, Loss: 0.024818183854222298\n",
      "Iteration: 1511/10000, Loss: 0.03195129334926605\n",
      "Iteration: 1512/10000, Loss: 0.03473128378391266\n",
      "Iteration: 1513/10000, Loss: 0.04611678794026375\n",
      "Iteration: 1514/10000, Loss: 0.03188956901431084\n",
      "Iteration: 1515/10000, Loss: 0.01862236112356186\n",
      "Iteration: 1516/10000, Loss: 0.04456391558051109\n",
      "Iteration: 1517/10000, Loss: 0.030884360894560814\n",
      "Iteration: 1518/10000, Loss: 0.029067451134324074\n",
      "Iteration: 1519/10000, Loss: 0.041137468069791794\n",
      "Iteration: 1520/10000, Loss: 0.03923758491873741\n",
      "Iteration: 1521/10000, Loss: 0.02472398243844509\n",
      "Iteration: 1522/10000, Loss: 0.04009690880775452\n",
      "Iteration: 1523/10000, Loss: 0.03588205948472023\n",
      "Iteration: 1524/10000, Loss: 0.03204695135354996\n",
      "Iteration: 1525/10000, Loss: 0.03495028242468834\n",
      "Iteration: 1526/10000, Loss: 0.03039356879889965\n",
      "Iteration: 1527/10000, Loss: 0.04014456272125244\n",
      "Iteration: 1528/10000, Loss: 0.0373658612370491\n",
      "Iteration: 1529/10000, Loss: 0.04027935862541199\n",
      "Iteration: 1530/10000, Loss: 0.025444872677326202\n",
      "Iteration: 1531/10000, Loss: 0.035753034055233\n",
      "Iteration: 1532/10000, Loss: 0.03128356859087944\n",
      "Iteration: 1533/10000, Loss: 0.03216889873147011\n",
      "Iteration: 1534/10000, Loss: 0.03456588461995125\n",
      "Iteration: 1535/10000, Loss: 0.02791528031229973\n",
      "Iteration: 1536/10000, Loss: 0.032119084149599075\n",
      "Iteration: 1537/10000, Loss: 0.030233804136514664\n",
      "Iteration: 1538/10000, Loss: 0.025925640016794205\n",
      "Iteration: 1539/10000, Loss: 0.05497917905449867\n",
      "Iteration: 1540/10000, Loss: 0.033443205058574677\n",
      "Iteration: 1541/10000, Loss: 0.039530884474515915\n",
      "Iteration: 1542/10000, Loss: 0.03329206630587578\n",
      "Iteration: 1543/10000, Loss: 0.033675823360681534\n",
      "Iteration: 1544/10000, Loss: 0.028424669057130814\n",
      "Iteration: 1545/10000, Loss: 0.031177548691630363\n",
      "Iteration: 1546/10000, Loss: 0.021548066288232803\n",
      "Iteration: 1547/10000, Loss: 0.029414119198918343\n",
      "Iteration: 1548/10000, Loss: 0.026108689606189728\n",
      "Iteration: 1549/10000, Loss: 0.031166410073637962\n",
      "Iteration: 1550/10000, Loss: 0.028482181951403618\n",
      "Iteration: 1551/10000, Loss: 0.0409429557621479\n",
      "Iteration: 1552/10000, Loss: 0.05146310105919838\n",
      "Iteration: 1553/10000, Loss: 0.04437195509672165\n",
      "Iteration: 1554/10000, Loss: 0.052915059030056\n",
      "Iteration: 1555/10000, Loss: 0.04750021547079086\n",
      "Iteration: 1556/10000, Loss: 0.030540788546204567\n",
      "Iteration: 1557/10000, Loss: 0.036341592669487\n",
      "Iteration: 1558/10000, Loss: 0.028672166168689728\n",
      "Iteration: 1559/10000, Loss: 0.0378156453371048\n",
      "Iteration: 1560/10000, Loss: 0.04522128030657768\n",
      "Iteration: 1561/10000, Loss: 0.03145516663789749\n",
      "Iteration: 1562/10000, Loss: 0.024069618433713913\n",
      "Iteration: 1563/10000, Loss: 0.027463560923933983\n",
      "Iteration: 1564/10000, Loss: 0.03224175423383713\n",
      "Iteration: 1565/10000, Loss: 0.029493996873497963\n",
      "Iteration: 1566/10000, Loss: 0.03431445732712746\n",
      "Iteration: 1567/10000, Loss: 0.03364533558487892\n",
      "Iteration: 1568/10000, Loss: 0.03128507733345032\n",
      "Iteration: 1569/10000, Loss: 0.03572492301464081\n",
      "Iteration: 1570/10000, Loss: 0.040811844170093536\n",
      "Iteration: 1571/10000, Loss: 0.04840432479977608\n",
      "Iteration: 1572/10000, Loss: 0.029501164332032204\n",
      "Iteration: 1573/10000, Loss: 0.02758469060063362\n",
      "Iteration: 1574/10000, Loss: 0.029198504984378815\n",
      "Iteration: 1575/10000, Loss: 0.04194449633359909\n",
      "Iteration: 1576/10000, Loss: 0.025620875880122185\n",
      "Iteration: 1577/10000, Loss: 0.040330372750759125\n",
      "Iteration: 1578/10000, Loss: 0.03364003822207451\n",
      "Iteration: 1579/10000, Loss: 0.02887357957661152\n",
      "Iteration: 1580/10000, Loss: 0.03881165012717247\n",
      "Iteration: 1581/10000, Loss: 0.02662099339067936\n",
      "Iteration: 1582/10000, Loss: 0.04423226788640022\n",
      "Iteration: 1583/10000, Loss: 0.03490540757775307\n",
      "Iteration: 1584/10000, Loss: 0.027456779032945633\n",
      "Iteration: 1585/10000, Loss: 0.029425708577036858\n",
      "Iteration: 1586/10000, Loss: 0.03433528169989586\n",
      "Iteration: 1587/10000, Loss: 0.02888818457722664\n",
      "Iteration: 1588/10000, Loss: 0.021048862487077713\n",
      "Iteration: 1589/10000, Loss: 0.030406253412365913\n",
      "Iteration: 1590/10000, Loss: 0.03995197266340256\n",
      "Iteration: 1591/10000, Loss: 0.031102914363145828\n",
      "Iteration: 1592/10000, Loss: 0.03225327655673027\n",
      "Iteration: 1593/10000, Loss: 0.036486003547906876\n",
      "Iteration: 1594/10000, Loss: 0.023901507258415222\n",
      "Iteration: 1595/10000, Loss: 0.023501945659518242\n",
      "Iteration: 1596/10000, Loss: 0.04110247641801834\n",
      "Iteration: 1597/10000, Loss: 0.02779294177889824\n",
      "Iteration: 1598/10000, Loss: 0.042838092893362045\n",
      "Iteration: 1599/10000, Loss: 0.044061753898859024\n",
      "Iteration: 1600/10000, Loss: 0.035202689468860626\n",
      "Average test loss:  0.0025\n",
      "Iteration: 1601/10000, Loss: 0.03682251274585724\n",
      "Iteration: 1602/10000, Loss: 0.029559915885329247\n",
      "Iteration: 1603/10000, Loss: 0.03167674317955971\n",
      "Iteration: 1604/10000, Loss: 0.02516978420317173\n",
      "Iteration: 1605/10000, Loss: 0.03752373903989792\n",
      "Iteration: 1606/10000, Loss: 0.03177940100431442\n",
      "Iteration: 1607/10000, Loss: 0.03329247236251831\n",
      "Iteration: 1608/10000, Loss: 0.034984346479177475\n",
      "Iteration: 1609/10000, Loss: 0.038386933505535126\n",
      "Iteration: 1610/10000, Loss: 0.03599826991558075\n",
      "Iteration: 1611/10000, Loss: 0.03126341849565506\n",
      "Iteration: 1612/10000, Loss: 0.037592943757772446\n",
      "Iteration: 1613/10000, Loss: 0.024717411026358604\n",
      "Iteration: 1614/10000, Loss: 0.039883267134428024\n",
      "Iteration: 1615/10000, Loss: 0.03603829815983772\n",
      "Iteration: 1616/10000, Loss: 0.02959093265235424\n",
      "Iteration: 1617/10000, Loss: 0.030995890498161316\n",
      "Iteration: 1618/10000, Loss: 0.029538260772824287\n",
      "Iteration: 1619/10000, Loss: 0.017957691103219986\n",
      "Iteration: 1620/10000, Loss: 0.028937997296452522\n",
      "Iteration: 1621/10000, Loss: 0.043717361986637115\n",
      "Iteration: 1622/10000, Loss: 0.0385897234082222\n",
      "Iteration: 1623/10000, Loss: 0.030318861827254295\n",
      "Iteration: 1624/10000, Loss: 0.036091551184654236\n",
      "Iteration: 1625/10000, Loss: 0.03160536289215088\n",
      "Iteration: 1626/10000, Loss: 0.03523477911949158\n",
      "Iteration: 1627/10000, Loss: 0.03885292634367943\n",
      "Iteration: 1628/10000, Loss: 0.02760489657521248\n",
      "Iteration: 1629/10000, Loss: 0.04627414420247078\n",
      "Iteration: 1630/10000, Loss: 0.02458486333489418\n",
      "Iteration: 1631/10000, Loss: 0.03455403074622154\n",
      "Iteration: 1632/10000, Loss: 0.028825677931308746\n",
      "Iteration: 1633/10000, Loss: 0.03392385318875313\n",
      "Iteration: 1634/10000, Loss: 0.03365034982562065\n",
      "Iteration: 1635/10000, Loss: 0.031198276206851006\n",
      "Iteration: 1636/10000, Loss: 0.03528367355465889\n",
      "Iteration: 1637/10000, Loss: 0.05167597532272339\n",
      "Iteration: 1638/10000, Loss: 0.02774636819958687\n",
      "Iteration: 1639/10000, Loss: 0.026515686884522438\n",
      "Iteration: 1640/10000, Loss: 0.040008507668972015\n",
      "Iteration: 1641/10000, Loss: 0.03321819379925728\n",
      "Iteration: 1642/10000, Loss: 0.028519829735159874\n",
      "Iteration: 1643/10000, Loss: 0.03145818039774895\n",
      "Iteration: 1644/10000, Loss: 0.039422329515218735\n",
      "Iteration: 1645/10000, Loss: 0.0358201339840889\n",
      "Iteration: 1646/10000, Loss: 0.019172867760062218\n",
      "Iteration: 1647/10000, Loss: 0.03179941326379776\n",
      "Iteration: 1648/10000, Loss: 0.022286390885710716\n",
      "Iteration: 1649/10000, Loss: 0.03560502827167511\n",
      "Iteration: 1650/10000, Loss: 0.04545768350362778\n",
      "Iteration: 1651/10000, Loss: 0.027948422357439995\n",
      "Iteration: 1652/10000, Loss: 0.04518121853470802\n",
      "Iteration: 1653/10000, Loss: 0.038542021065950394\n",
      "Iteration: 1654/10000, Loss: 0.03422151878476143\n",
      "Iteration: 1655/10000, Loss: 0.03245154768228531\n",
      "Iteration: 1656/10000, Loss: 0.03169906139373779\n",
      "Iteration: 1657/10000, Loss: 0.040485117584466934\n",
      "Iteration: 1658/10000, Loss: 0.036898255348205566\n",
      "Iteration: 1659/10000, Loss: 0.03560994938015938\n",
      "Iteration: 1660/10000, Loss: 0.03432172164320946\n",
      "Iteration: 1661/10000, Loss: 0.02671392820775509\n",
      "Iteration: 1662/10000, Loss: 0.03629216179251671\n",
      "Iteration: 1663/10000, Loss: 0.02885824628174305\n",
      "Iteration: 1664/10000, Loss: 0.02478785254061222\n",
      "Iteration: 1665/10000, Loss: 0.03239751234650612\n",
      "Iteration: 1666/10000, Loss: 0.03810322284698486\n",
      "Iteration: 1667/10000, Loss: 0.03236643224954605\n",
      "Iteration: 1668/10000, Loss: 0.034120216965675354\n",
      "Iteration: 1669/10000, Loss: 0.0379175990819931\n",
      "Iteration: 1670/10000, Loss: 0.03052976168692112\n",
      "Iteration: 1671/10000, Loss: 0.04537404328584671\n",
      "Iteration: 1672/10000, Loss: 0.022405557334423065\n",
      "Iteration: 1673/10000, Loss: 0.04272036626935005\n",
      "Iteration: 1674/10000, Loss: 0.027388690039515495\n",
      "Iteration: 1675/10000, Loss: 0.03400983661413193\n",
      "Iteration: 1676/10000, Loss: 0.027504324913024902\n",
      "Iteration: 1677/10000, Loss: 0.024268945679068565\n",
      "Iteration: 1678/10000, Loss: 0.030261807143688202\n",
      "Iteration: 1679/10000, Loss: 0.03442508354783058\n",
      "Iteration: 1680/10000, Loss: 0.04197021201252937\n",
      "Iteration: 1681/10000, Loss: 0.049737125635147095\n",
      "Iteration: 1682/10000, Loss: 0.021663686260581017\n",
      "Iteration: 1683/10000, Loss: 0.027057938277721405\n",
      "Iteration: 1684/10000, Loss: 0.028443532064557076\n",
      "Iteration: 1685/10000, Loss: 0.036239996552467346\n",
      "Iteration: 1686/10000, Loss: 0.040969207882881165\n",
      "Iteration: 1687/10000, Loss: 0.04601740464568138\n",
      "Iteration: 1688/10000, Loss: 0.05725076422095299\n",
      "Iteration: 1689/10000, Loss: 0.03853478282690048\n",
      "Iteration: 1690/10000, Loss: 0.033221207559108734\n",
      "Iteration: 1691/10000, Loss: 0.04081377759575844\n",
      "Iteration: 1692/10000, Loss: 0.02692321315407753\n",
      "Iteration: 1693/10000, Loss: 0.028603076934814453\n",
      "Iteration: 1694/10000, Loss: 0.031185418367385864\n",
      "Iteration: 1695/10000, Loss: 0.029735492542386055\n",
      "Iteration: 1696/10000, Loss: 0.025098292157053947\n",
      "Iteration: 1697/10000, Loss: 0.03031940758228302\n",
      "Iteration: 1698/10000, Loss: 0.02433912083506584\n",
      "Iteration: 1699/10000, Loss: 0.03626107797026634\n",
      "Iteration: 1700/10000, Loss: 0.03152807801961899\n",
      "Average test loss:  0.0035\n",
      "Iteration: 1701/10000, Loss: 0.03509927913546562\n",
      "Iteration: 1702/10000, Loss: 0.037182148545980453\n",
      "Iteration: 1703/10000, Loss: 0.036471545696258545\n",
      "Iteration: 1704/10000, Loss: 0.033508818596601486\n",
      "Iteration: 1705/10000, Loss: 0.04011198505759239\n",
      "Iteration: 1706/10000, Loss: 0.02795211598277092\n",
      "Iteration: 1707/10000, Loss: 0.037341464310884476\n",
      "Iteration: 1708/10000, Loss: 0.027077216655015945\n",
      "Iteration: 1709/10000, Loss: 0.021506961435079575\n",
      "Iteration: 1710/10000, Loss: 0.020309219136834145\n",
      "Iteration: 1711/10000, Loss: 0.0266274306923151\n",
      "Iteration: 1712/10000, Loss: 0.027326159179210663\n",
      "Iteration: 1713/10000, Loss: 0.030822046101093292\n",
      "Iteration: 1714/10000, Loss: 0.028943538665771484\n",
      "Iteration: 1715/10000, Loss: 0.02616003528237343\n",
      "Iteration: 1716/10000, Loss: 0.023886946961283684\n",
      "Iteration: 1717/10000, Loss: 0.023650381714105606\n",
      "Iteration: 1718/10000, Loss: 0.04260821267962456\n",
      "Iteration: 1719/10000, Loss: 0.047619860619306564\n",
      "Iteration: 1720/10000, Loss: 0.039039600640535355\n",
      "Iteration: 1721/10000, Loss: 0.0400141105055809\n",
      "Iteration: 1722/10000, Loss: 0.029662400484085083\n",
      "Iteration: 1723/10000, Loss: 0.033979639410972595\n",
      "Iteration: 1724/10000, Loss: 0.022183112800121307\n",
      "Iteration: 1725/10000, Loss: 0.036771029233932495\n",
      "Iteration: 1726/10000, Loss: 0.024477019906044006\n",
      "Iteration: 1727/10000, Loss: 0.042591631412506104\n",
      "Iteration: 1728/10000, Loss: 0.02399766631424427\n",
      "Iteration: 1729/10000, Loss: 0.03310282528400421\n",
      "Iteration: 1730/10000, Loss: 0.0359405018389225\n",
      "Iteration: 1731/10000, Loss: 0.03234890475869179\n",
      "Iteration: 1732/10000, Loss: 0.0246917512267828\n",
      "Iteration: 1733/10000, Loss: 0.03483037278056145\n",
      "Iteration: 1734/10000, Loss: 0.02867371030151844\n",
      "Iteration: 1735/10000, Loss: 0.02716975100338459\n",
      "Iteration: 1736/10000, Loss: 0.03296344727277756\n",
      "Iteration: 1737/10000, Loss: 0.0333297960460186\n",
      "Iteration: 1738/10000, Loss: 0.02514529600739479\n",
      "Iteration: 1739/10000, Loss: 0.02988591603934765\n",
      "Iteration: 1740/10000, Loss: 0.03502139449119568\n",
      "Iteration: 1741/10000, Loss: 0.031059546396136284\n",
      "Iteration: 1742/10000, Loss: 0.03216830641031265\n",
      "Iteration: 1743/10000, Loss: 0.038913924247026443\n",
      "Iteration: 1744/10000, Loss: 0.028943786397576332\n",
      "Iteration: 1745/10000, Loss: 0.04634097218513489\n",
      "Iteration: 1746/10000, Loss: 0.024174505844712257\n",
      "Iteration: 1747/10000, Loss: 0.0383489653468132\n",
      "Iteration: 1748/10000, Loss: 0.05255173519253731\n",
      "Iteration: 1749/10000, Loss: 0.040727242827415466\n",
      "Iteration: 1750/10000, Loss: 0.031372830271720886\n",
      "Iteration: 1751/10000, Loss: 0.04003431275486946\n",
      "Iteration: 1752/10000, Loss: 0.02824440225958824\n",
      "Iteration: 1753/10000, Loss: 0.03131115064024925\n",
      "Iteration: 1754/10000, Loss: 0.033786628395318985\n",
      "Iteration: 1755/10000, Loss: 0.02394207939505577\n",
      "Iteration: 1756/10000, Loss: 0.023867059499025345\n",
      "Iteration: 1757/10000, Loss: 0.032733481377363205\n",
      "Iteration: 1758/10000, Loss: 0.030579932034015656\n",
      "Iteration: 1759/10000, Loss: 0.04977595806121826\n",
      "Iteration: 1760/10000, Loss: 0.03217938914895058\n",
      "Iteration: 1761/10000, Loss: 0.024979423731565475\n",
      "Iteration: 1762/10000, Loss: 0.031178569421172142\n",
      "Iteration: 1763/10000, Loss: 0.026532698422670364\n",
      "Iteration: 1764/10000, Loss: 0.03726310655474663\n",
      "Iteration: 1765/10000, Loss: 0.02925555594265461\n",
      "Iteration: 1766/10000, Loss: 0.027699099853634834\n",
      "Iteration: 1767/10000, Loss: 0.055369783192873\n",
      "Iteration: 1768/10000, Loss: 0.021645596250891685\n",
      "Iteration: 1769/10000, Loss: 0.03523685410618782\n",
      "Iteration: 1770/10000, Loss: 0.03134515881538391\n",
      "Iteration: 1771/10000, Loss: 0.03947066143155098\n",
      "Iteration: 1772/10000, Loss: 0.02505415864288807\n",
      "Iteration: 1773/10000, Loss: 0.02186974696815014\n",
      "Iteration: 1774/10000, Loss: 0.024650422856211662\n",
      "Iteration: 1775/10000, Loss: 0.033299412578344345\n",
      "Iteration: 1776/10000, Loss: 0.028844676911830902\n",
      "Iteration: 1777/10000, Loss: 0.029937172308564186\n",
      "Iteration: 1778/10000, Loss: 0.026235481724143028\n",
      "Iteration: 1779/10000, Loss: 0.037780970335006714\n",
      "Iteration: 1780/10000, Loss: 0.04036938026547432\n",
      "Iteration: 1781/10000, Loss: 0.044518060982227325\n",
      "Iteration: 1782/10000, Loss: 0.02238665334880352\n",
      "Iteration: 1783/10000, Loss: 0.026748953387141228\n",
      "Iteration: 1784/10000, Loss: 0.023693393915891647\n",
      "Iteration: 1785/10000, Loss: 0.035487107932567596\n",
      "Iteration: 1786/10000, Loss: 0.024759024381637573\n",
      "Iteration: 1787/10000, Loss: 0.031257230788469315\n",
      "Iteration: 1788/10000, Loss: 0.0419103279709816\n",
      "Iteration: 1789/10000, Loss: 0.031515996903181076\n",
      "Iteration: 1790/10000, Loss: 0.026231376454234123\n",
      "Iteration: 1791/10000, Loss: 0.043746475130319595\n",
      "Iteration: 1792/10000, Loss: 0.029449891299009323\n",
      "Iteration: 1793/10000, Loss: 0.029638832435011864\n",
      "Iteration: 1794/10000, Loss: 0.03169693797826767\n",
      "Iteration: 1795/10000, Loss: 0.0337979719042778\n",
      "Iteration: 1796/10000, Loss: 0.037247031927108765\n",
      "Iteration: 1797/10000, Loss: 0.03797426074743271\n",
      "Iteration: 1798/10000, Loss: 0.0396869033575058\n",
      "Iteration: 1799/10000, Loss: 0.026988686993718147\n",
      "Iteration: 1800/10000, Loss: 0.028604671359062195\n",
      "Average test loss:  0.0027\n",
      "Iteration: 1801/10000, Loss: 0.04052706062793732\n",
      "Iteration: 1802/10000, Loss: 0.03179006278514862\n",
      "Iteration: 1803/10000, Loss: 0.03060666099190712\n",
      "Iteration: 1804/10000, Loss: 0.036133404821157455\n",
      "Iteration: 1805/10000, Loss: 0.031810346990823746\n",
      "Iteration: 1806/10000, Loss: 0.02337554469704628\n",
      "Iteration: 1807/10000, Loss: 0.029972758144140244\n",
      "Iteration: 1808/10000, Loss: 0.04669569805264473\n",
      "Iteration: 1809/10000, Loss: 0.040331318974494934\n",
      "Iteration: 1810/10000, Loss: 0.02484334073960781\n",
      "Iteration: 1811/10000, Loss: 0.025808528065681458\n",
      "Iteration: 1812/10000, Loss: 0.03454335778951645\n",
      "Iteration: 1813/10000, Loss: 0.03756175562739372\n",
      "Iteration: 1814/10000, Loss: 0.02670860104262829\n",
      "Iteration: 1815/10000, Loss: 0.03419828042387962\n",
      "Iteration: 1816/10000, Loss: 0.029725903645157814\n",
      "Iteration: 1817/10000, Loss: 0.037813205271959305\n",
      "Iteration: 1818/10000, Loss: 0.03721153363585472\n",
      "Iteration: 1819/10000, Loss: 0.028449397534132004\n",
      "Iteration: 1820/10000, Loss: 0.02251012623310089\n",
      "Iteration: 1821/10000, Loss: 0.032676585018634796\n",
      "Iteration: 1822/10000, Loss: 0.04509248584508896\n",
      "Iteration: 1823/10000, Loss: 0.029177021235227585\n",
      "Iteration: 1824/10000, Loss: 0.03024078533053398\n",
      "Iteration: 1825/10000, Loss: 0.02808055840432644\n",
      "Iteration: 1826/10000, Loss: 0.026792515069246292\n",
      "Iteration: 1827/10000, Loss: 0.029817741364240646\n",
      "Iteration: 1828/10000, Loss: 0.03276291862130165\n",
      "Iteration: 1829/10000, Loss: 0.048452477902173996\n",
      "Iteration: 1830/10000, Loss: 0.024503696709871292\n",
      "Iteration: 1831/10000, Loss: 0.035396281629800797\n",
      "Iteration: 1832/10000, Loss: 0.028934089466929436\n",
      "Iteration: 1833/10000, Loss: 0.021947313100099564\n",
      "Iteration: 1834/10000, Loss: 0.03841732442378998\n",
      "Iteration: 1835/10000, Loss: 0.022969845682382584\n",
      "Iteration: 1836/10000, Loss: 0.03968726843595505\n",
      "Iteration: 1837/10000, Loss: 0.025105435401201248\n",
      "Iteration: 1838/10000, Loss: 0.023412104696035385\n",
      "Iteration: 1839/10000, Loss: 0.03647077828645706\n",
      "Iteration: 1840/10000, Loss: 0.019133510068058968\n",
      "Iteration: 1841/10000, Loss: 0.03592338040471077\n",
      "Iteration: 1842/10000, Loss: 0.03248222544789314\n",
      "Iteration: 1843/10000, Loss: 0.024579130113124847\n",
      "Iteration: 1844/10000, Loss: 0.040980223566293716\n",
      "Iteration: 1845/10000, Loss: 0.03480999171733856\n",
      "Iteration: 1846/10000, Loss: 0.037643034011125565\n",
      "Iteration: 1847/10000, Loss: 0.026011696085333824\n",
      "Iteration: 1848/10000, Loss: 0.020513640716671944\n",
      "Iteration: 1849/10000, Loss: 0.03373763710260391\n",
      "Iteration: 1850/10000, Loss: 0.04060101881623268\n",
      "Iteration: 1851/10000, Loss: 0.02618303894996643\n",
      "Iteration: 1852/10000, Loss: 0.0433817021548748\n",
      "Iteration: 1853/10000, Loss: 0.023066122084856033\n",
      "Iteration: 1854/10000, Loss: 0.03815798461437225\n",
      "Iteration: 1855/10000, Loss: 0.024561114609241486\n",
      "Iteration: 1856/10000, Loss: 0.028401870280504227\n",
      "Iteration: 1857/10000, Loss: 0.030773911625146866\n",
      "Iteration: 1858/10000, Loss: 0.02520664595067501\n",
      "Iteration: 1859/10000, Loss: 0.03634115681052208\n",
      "Iteration: 1860/10000, Loss: 0.033582400530576706\n",
      "Iteration: 1861/10000, Loss: 0.039110880345106125\n",
      "Iteration: 1862/10000, Loss: 0.02661326713860035\n",
      "Iteration: 1863/10000, Loss: 0.03297185152769089\n",
      "Iteration: 1864/10000, Loss: 0.03522581607103348\n",
      "Iteration: 1865/10000, Loss: 0.031198730692267418\n",
      "Iteration: 1866/10000, Loss: 0.039615485817193985\n",
      "Iteration: 1867/10000, Loss: 0.034277886152267456\n",
      "Iteration: 1868/10000, Loss: 0.03682848438620567\n",
      "Iteration: 1869/10000, Loss: 0.024868151172995567\n",
      "Iteration: 1870/10000, Loss: 0.028811423107981682\n",
      "Iteration: 1871/10000, Loss: 0.040939122438430786\n",
      "Iteration: 1872/10000, Loss: 0.02513263002038002\n",
      "Iteration: 1873/10000, Loss: 0.028515031561255455\n",
      "Iteration: 1874/10000, Loss: 0.02150874212384224\n",
      "Iteration: 1875/10000, Loss: 0.02239183895289898\n",
      "Iteration: 1876/10000, Loss: 0.02185232564806938\n",
      "Iteration: 1877/10000, Loss: 0.0295326616615057\n",
      "Iteration: 1878/10000, Loss: 0.021107468754053116\n",
      "Iteration: 1879/10000, Loss: 0.03347346559166908\n",
      "Iteration: 1880/10000, Loss: 0.03662567213177681\n",
      "Iteration: 1881/10000, Loss: 0.018893705680966377\n",
      "Iteration: 1882/10000, Loss: 0.03077416680753231\n",
      "Iteration: 1883/10000, Loss: 0.02302674949169159\n",
      "Iteration: 1884/10000, Loss: 0.02131127193570137\n",
      "Iteration: 1885/10000, Loss: 0.02990078367292881\n",
      "Iteration: 1886/10000, Loss: 0.03336713835597038\n",
      "Iteration: 1887/10000, Loss: 0.03068886697292328\n",
      "Iteration: 1888/10000, Loss: 0.02448596991598606\n",
      "Iteration: 1889/10000, Loss: 0.03298722207546234\n",
      "Iteration: 1890/10000, Loss: 0.026591859757900238\n",
      "Iteration: 1891/10000, Loss: 0.03148157522082329\n",
      "Iteration: 1892/10000, Loss: 0.02900412678718567\n",
      "Iteration: 1893/10000, Loss: 0.02524566277861595\n",
      "Iteration: 1894/10000, Loss: 0.028872769325971603\n",
      "Iteration: 1895/10000, Loss: 0.02861141599714756\n",
      "Iteration: 1896/10000, Loss: 0.026388609781861305\n",
      "Iteration: 1897/10000, Loss: 0.04593883454799652\n",
      "Iteration: 1898/10000, Loss: 0.030158482491970062\n",
      "Iteration: 1899/10000, Loss: 0.028668802231550217\n",
      "Iteration: 1900/10000, Loss: 0.021245505660772324\n",
      "Average test loss:  0.0034\n",
      "Iteration: 1901/10000, Loss: 0.022726260125637054\n",
      "Iteration: 1902/10000, Loss: 0.029028702527284622\n",
      "Iteration: 1903/10000, Loss: 0.035370148718357086\n",
      "Iteration: 1904/10000, Loss: 0.03935466334223747\n",
      "Iteration: 1905/10000, Loss: 0.034247856587171555\n",
      "Iteration: 1906/10000, Loss: 0.03672032803297043\n",
      "Iteration: 1907/10000, Loss: 0.02483580820262432\n",
      "Iteration: 1908/10000, Loss: 0.027088593691587448\n",
      "Iteration: 1909/10000, Loss: 0.037474289536476135\n",
      "Iteration: 1910/10000, Loss: 0.03238455578684807\n",
      "Iteration: 1911/10000, Loss: 0.03001517988741398\n",
      "Iteration: 1912/10000, Loss: 0.024522239342331886\n",
      "Iteration: 1913/10000, Loss: 0.02488214522600174\n",
      "Iteration: 1914/10000, Loss: 0.022890310734510422\n",
      "Iteration: 1915/10000, Loss: 0.029988525435328484\n",
      "Iteration: 1916/10000, Loss: 0.02367192879319191\n",
      "Iteration: 1917/10000, Loss: 0.026324784383177757\n",
      "Iteration: 1918/10000, Loss: 0.02773650735616684\n",
      "Iteration: 1919/10000, Loss: 0.03040030226111412\n",
      "Iteration: 1920/10000, Loss: 0.032602645456790924\n",
      "Iteration: 1921/10000, Loss: 0.024861816316843033\n",
      "Iteration: 1922/10000, Loss: 0.048258595168590546\n",
      "Iteration: 1923/10000, Loss: 0.020405586808919907\n",
      "Iteration: 1924/10000, Loss: 0.02952919341623783\n",
      "Iteration: 1925/10000, Loss: 0.022638998925685883\n",
      "Iteration: 1926/10000, Loss: 0.030095649883151054\n",
      "Iteration: 1927/10000, Loss: 0.03229394927620888\n",
      "Iteration: 1928/10000, Loss: 0.024031542241573334\n",
      "Iteration: 1929/10000, Loss: 0.03369425609707832\n",
      "Iteration: 1930/10000, Loss: 0.036678314208984375\n",
      "Iteration: 1931/10000, Loss: 0.03946831077337265\n",
      "Iteration: 1932/10000, Loss: 0.04203805327415466\n",
      "Iteration: 1933/10000, Loss: 0.029896514490246773\n",
      "Iteration: 1934/10000, Loss: 0.033013660460710526\n",
      "Iteration: 1935/10000, Loss: 0.033132947981357574\n",
      "Iteration: 1936/10000, Loss: 0.02397732250392437\n",
      "Iteration: 1937/10000, Loss: 0.03690864145755768\n",
      "Iteration: 1938/10000, Loss: 0.033673424273729324\n",
      "Iteration: 1939/10000, Loss: 0.02415412850677967\n",
      "Iteration: 1940/10000, Loss: 0.019059427082538605\n",
      "Iteration: 1941/10000, Loss: 0.02151709608733654\n",
      "Iteration: 1942/10000, Loss: 0.035623956471681595\n",
      "Iteration: 1943/10000, Loss: 0.032516684383153915\n",
      "Iteration: 1944/10000, Loss: 0.027411943301558495\n",
      "Iteration: 1945/10000, Loss: 0.01838478446006775\n",
      "Iteration: 1946/10000, Loss: 0.032356396317481995\n",
      "Iteration: 1947/10000, Loss: 0.02073291316628456\n",
      "Iteration: 1948/10000, Loss: 0.031841736286878586\n",
      "Iteration: 1949/10000, Loss: 0.01675330102443695\n",
      "Iteration: 1950/10000, Loss: 0.017378801479935646\n",
      "Iteration: 1951/10000, Loss: 0.015952490270137787\n",
      "Iteration: 1952/10000, Loss: 0.018967581912875175\n",
      "Iteration: 1953/10000, Loss: 0.024714050814509392\n",
      "Iteration: 1954/10000, Loss: 0.027443470433354378\n",
      "Iteration: 1955/10000, Loss: 0.02343575656414032\n",
      "Iteration: 1956/10000, Loss: 0.03735848143696785\n",
      "Iteration: 1957/10000, Loss: 0.03030581772327423\n",
      "Iteration: 1958/10000, Loss: 0.03380328044295311\n",
      "Iteration: 1959/10000, Loss: 0.017037320882081985\n",
      "Iteration: 1960/10000, Loss: 0.03220343962311745\n",
      "Iteration: 1961/10000, Loss: 0.023664843291044235\n",
      "Iteration: 1962/10000, Loss: 0.0288627240806818\n",
      "Iteration: 1963/10000, Loss: 0.023137656971812248\n",
      "Iteration: 1964/10000, Loss: 0.025135284289717674\n",
      "Iteration: 1965/10000, Loss: 0.031912773847579956\n",
      "Iteration: 1966/10000, Loss: 0.02924976497888565\n",
      "Iteration: 1967/10000, Loss: 0.021060368046164513\n",
      "Iteration: 1968/10000, Loss: 0.021523084491491318\n",
      "Iteration: 1969/10000, Loss: 0.03104059025645256\n",
      "Iteration: 1970/10000, Loss: 0.030992217361927032\n",
      "Iteration: 1971/10000, Loss: 0.04275759309530258\n",
      "Iteration: 1972/10000, Loss: 0.023716935887932777\n",
      "Iteration: 1973/10000, Loss: 0.02287881448864937\n",
      "Iteration: 1974/10000, Loss: 0.01852506771683693\n",
      "Iteration: 1975/10000, Loss: 0.041915394365787506\n",
      "Iteration: 1976/10000, Loss: 0.05443959683179855\n",
      "Iteration: 1977/10000, Loss: 0.024995850399136543\n",
      "Iteration: 1978/10000, Loss: 0.02229037694633007\n",
      "Iteration: 1979/10000, Loss: 0.034282419830560684\n",
      "Iteration: 1980/10000, Loss: 0.02967623434960842\n",
      "Iteration: 1981/10000, Loss: 0.0379391647875309\n",
      "Iteration: 1982/10000, Loss: 0.020520130172371864\n",
      "Iteration: 1983/10000, Loss: 0.018538838252425194\n",
      "Iteration: 1984/10000, Loss: 0.01592399738729\n",
      "Iteration: 1985/10000, Loss: 0.04307560250163078\n",
      "Iteration: 1986/10000, Loss: 0.02931104600429535\n",
      "Iteration: 1987/10000, Loss: 0.03215267136693001\n",
      "Iteration: 1988/10000, Loss: 0.0374324657022953\n",
      "Iteration: 1989/10000, Loss: 0.03037935309112072\n",
      "Iteration: 1990/10000, Loss: 0.02784116566181183\n",
      "Iteration: 1991/10000, Loss: 0.02917318418622017\n",
      "Iteration: 1992/10000, Loss: 0.03257042542099953\n",
      "Iteration: 1993/10000, Loss: 0.027874959632754326\n",
      "Iteration: 1994/10000, Loss: 0.04317599907517433\n",
      "Iteration: 1995/10000, Loss: 0.03163843974471092\n",
      "Iteration: 1996/10000, Loss: 0.031234165653586388\n",
      "Iteration: 1997/10000, Loss: 0.022099290043115616\n",
      "Iteration: 1998/10000, Loss: 0.04062946140766144\n",
      "Iteration: 1999/10000, Loss: 0.02903200313448906\n",
      "Iteration: 2000/10000, Loss: 0.028362885117530823\n",
      "Average test loss:  0.0016\n",
      "Iteration: 2001/10000, Loss: 0.020040711387991905\n",
      "Iteration: 2002/10000, Loss: 0.018886979669332504\n",
      "Iteration: 2003/10000, Loss: 0.023739518597722054\n",
      "Iteration: 2004/10000, Loss: 0.03733211010694504\n",
      "Iteration: 2005/10000, Loss: 0.04379819333553314\n",
      "Iteration: 2006/10000, Loss: 0.02312934398651123\n",
      "Iteration: 2007/10000, Loss: 0.019069824367761612\n",
      "Iteration: 2008/10000, Loss: 0.024303771555423737\n",
      "Iteration: 2009/10000, Loss: 0.03188991919159889\n",
      "Iteration: 2010/10000, Loss: 0.021403253078460693\n",
      "Iteration: 2011/10000, Loss: 0.02733972668647766\n",
      "Iteration: 2012/10000, Loss: 0.031038392335176468\n",
      "Iteration: 2013/10000, Loss: 0.02820996567606926\n",
      "Iteration: 2014/10000, Loss: 0.02297496423125267\n",
      "Iteration: 2015/10000, Loss: 0.025700997561216354\n",
      "Iteration: 2016/10000, Loss: 0.04322635382413864\n",
      "Iteration: 2017/10000, Loss: 0.025967035442590714\n",
      "Iteration: 2018/10000, Loss: 0.03420407325029373\n",
      "Iteration: 2019/10000, Loss: 0.01891534961760044\n",
      "Iteration: 2020/10000, Loss: 0.0234879981726408\n",
      "Iteration: 2021/10000, Loss: 0.021501654759049416\n",
      "Iteration: 2022/10000, Loss: 0.031220154836773872\n",
      "Iteration: 2023/10000, Loss: 0.0391446016728878\n",
      "Iteration: 2024/10000, Loss: 0.040869515389204025\n",
      "Iteration: 2025/10000, Loss: 0.029782699421048164\n",
      "Iteration: 2026/10000, Loss: 0.02409203164279461\n",
      "Iteration: 2027/10000, Loss: 0.019367501139640808\n",
      "Iteration: 2028/10000, Loss: 0.025666600093245506\n",
      "Iteration: 2029/10000, Loss: 0.025032442063093185\n",
      "Iteration: 2030/10000, Loss: 0.030970808118581772\n",
      "Iteration: 2031/10000, Loss: 0.021853914484381676\n",
      "Iteration: 2032/10000, Loss: 0.02103727124631405\n",
      "Iteration: 2033/10000, Loss: 0.02907443232834339\n",
      "Iteration: 2034/10000, Loss: 0.04076312482357025\n",
      "Iteration: 2035/10000, Loss: 0.034555431455373764\n",
      "Iteration: 2036/10000, Loss: 0.04647495970129967\n",
      "Iteration: 2037/10000, Loss: 0.024100612848997116\n",
      "Iteration: 2038/10000, Loss: 0.018013514578342438\n",
      "Iteration: 2039/10000, Loss: 0.03178916126489639\n",
      "Iteration: 2040/10000, Loss: 0.017688864842057228\n",
      "Iteration: 2041/10000, Loss: 0.021043410524725914\n",
      "Iteration: 2042/10000, Loss: 0.03225187212228775\n",
      "Iteration: 2043/10000, Loss: 0.02561516873538494\n",
      "Iteration: 2044/10000, Loss: 0.04426196217536926\n",
      "Iteration: 2045/10000, Loss: 0.021997248753905296\n",
      "Iteration: 2046/10000, Loss: 0.018210604786872864\n",
      "Iteration: 2047/10000, Loss: 0.03133425861597061\n",
      "Iteration: 2048/10000, Loss: 0.02442147023975849\n",
      "Iteration: 2049/10000, Loss: 0.024881910532712936\n",
      "Iteration: 2050/10000, Loss: 0.02784038335084915\n",
      "Iteration: 2051/10000, Loss: 0.04294474422931671\n",
      "Iteration: 2052/10000, Loss: 0.020896464586257935\n",
      "Iteration: 2053/10000, Loss: 0.044519856572151184\n",
      "Iteration: 2054/10000, Loss: 0.02798784337937832\n",
      "Iteration: 2055/10000, Loss: 0.026999037712812424\n",
      "Iteration: 2056/10000, Loss: 0.035146068781614304\n",
      "Iteration: 2057/10000, Loss: 0.02304774522781372\n",
      "Iteration: 2058/10000, Loss: 0.0253616813570261\n",
      "Iteration: 2059/10000, Loss: 0.030674930661916733\n",
      "Iteration: 2060/10000, Loss: 0.023777276277542114\n",
      "Iteration: 2061/10000, Loss: 0.031882334500551224\n",
      "Iteration: 2062/10000, Loss: 0.033253833651542664\n",
      "Iteration: 2063/10000, Loss: 0.023132389411330223\n",
      "Iteration: 2064/10000, Loss: 0.024461910128593445\n",
      "Iteration: 2065/10000, Loss: 0.01962369866669178\n",
      "Iteration: 2066/10000, Loss: 0.018609125167131424\n",
      "Iteration: 2067/10000, Loss: 0.028584850952029228\n",
      "Iteration: 2068/10000, Loss: 0.022580962628126144\n",
      "Iteration: 2069/10000, Loss: 0.02204418182373047\n",
      "Iteration: 2070/10000, Loss: 0.03021993674337864\n",
      "Iteration: 2071/10000, Loss: 0.017122415825724602\n",
      "Iteration: 2072/10000, Loss: 0.027631910517811775\n",
      "Iteration: 2073/10000, Loss: 0.028444606810808182\n",
      "Iteration: 2074/10000, Loss: 0.024009449407458305\n",
      "Iteration: 2075/10000, Loss: 0.033158574253320694\n",
      "Iteration: 2076/10000, Loss: 0.018345830962061882\n",
      "Iteration: 2077/10000, Loss: 0.020982759073376656\n",
      "Iteration: 2078/10000, Loss: 0.029023129492998123\n",
      "Iteration: 2079/10000, Loss: 0.025296563282608986\n",
      "Iteration: 2080/10000, Loss: 0.028612349182367325\n",
      "Iteration: 2081/10000, Loss: 0.03469586744904518\n",
      "Iteration: 2082/10000, Loss: 0.022996822372078896\n",
      "Iteration: 2083/10000, Loss: 0.046732839196920395\n",
      "Iteration: 2084/10000, Loss: 0.030314477160573006\n",
      "Iteration: 2085/10000, Loss: 0.028026308864355087\n",
      "Iteration: 2086/10000, Loss: 0.016174964606761932\n",
      "Iteration: 2087/10000, Loss: 0.023918114602565765\n",
      "Iteration: 2088/10000, Loss: 0.034259699285030365\n",
      "Iteration: 2089/10000, Loss: 0.0267964918166399\n",
      "Iteration: 2090/10000, Loss: 0.02243797667324543\n",
      "Iteration: 2091/10000, Loss: 0.028443535789847374\n",
      "Iteration: 2092/10000, Loss: 0.0284136775881052\n",
      "Iteration: 2093/10000, Loss: 0.014324056915938854\n",
      "Iteration: 2094/10000, Loss: 0.035503506660461426\n",
      "Iteration: 2095/10000, Loss: 0.022301197052001953\n",
      "Iteration: 2096/10000, Loss: 0.01783795654773712\n",
      "Iteration: 2097/10000, Loss: 0.03362743556499481\n",
      "Iteration: 2098/10000, Loss: 0.02052900195121765\n",
      "Iteration: 2099/10000, Loss: 0.04177587479352951\n",
      "Iteration: 2100/10000, Loss: 0.02715895138680935\n",
      "Average test loss:  0.0035\n",
      "Iteration: 2101/10000, Loss: 0.02704351767897606\n",
      "Iteration: 2102/10000, Loss: 0.02374458871781826\n",
      "Iteration: 2103/10000, Loss: 0.018465561792254448\n",
      "Iteration: 2104/10000, Loss: 0.02651142328977585\n",
      "Iteration: 2105/10000, Loss: 0.025699414312839508\n",
      "Iteration: 2106/10000, Loss: 0.03747027367353439\n",
      "Iteration: 2107/10000, Loss: 0.033817462623119354\n",
      "Iteration: 2108/10000, Loss: 0.023973777890205383\n",
      "Iteration: 2109/10000, Loss: 0.027377668768167496\n",
      "Iteration: 2110/10000, Loss: 0.029789889231324196\n",
      "Iteration: 2111/10000, Loss: 0.0316048189997673\n",
      "Iteration: 2112/10000, Loss: 0.03085373155772686\n",
      "Iteration: 2113/10000, Loss: 0.021313270553946495\n",
      "Iteration: 2114/10000, Loss: 0.04362780228257179\n",
      "Iteration: 2115/10000, Loss: 0.025500386953353882\n",
      "Iteration: 2116/10000, Loss: 0.020133337005972862\n",
      "Iteration: 2117/10000, Loss: 0.039900463074445724\n",
      "Iteration: 2118/10000, Loss: 0.025826819241046906\n",
      "Iteration: 2119/10000, Loss: 0.04361367225646973\n",
      "Iteration: 2120/10000, Loss: 0.03308961167931557\n",
      "Iteration: 2121/10000, Loss: 0.025450292974710464\n",
      "Iteration: 2122/10000, Loss: 0.025228286162018776\n",
      "Iteration: 2123/10000, Loss: 0.02700977772474289\n",
      "Iteration: 2124/10000, Loss: 0.024694202467799187\n",
      "Iteration: 2125/10000, Loss: 0.021037288010120392\n",
      "Iteration: 2126/10000, Loss: 0.03145178034901619\n",
      "Iteration: 2127/10000, Loss: 0.029477842152118683\n",
      "Iteration: 2128/10000, Loss: 0.03362167999148369\n",
      "Iteration: 2129/10000, Loss: 0.03771770000457764\n",
      "Iteration: 2130/10000, Loss: 0.022942891344428062\n",
      "Iteration: 2131/10000, Loss: 0.022485099732875824\n",
      "Iteration: 2132/10000, Loss: 0.028819633647799492\n",
      "Iteration: 2133/10000, Loss: 0.02558431401848793\n",
      "Iteration: 2134/10000, Loss: 0.045614343136548996\n",
      "Iteration: 2135/10000, Loss: 0.033661138266325\n",
      "Iteration: 2136/10000, Loss: 0.026583503931760788\n",
      "Iteration: 2137/10000, Loss: 0.02455557882785797\n",
      "Iteration: 2138/10000, Loss: 0.023962734267115593\n",
      "Iteration: 2139/10000, Loss: 0.03267490863800049\n",
      "Iteration: 2140/10000, Loss: 0.02332056313753128\n",
      "Iteration: 2141/10000, Loss: 0.029781661927700043\n",
      "Iteration: 2142/10000, Loss: 0.03728088364005089\n",
      "Iteration: 2143/10000, Loss: 0.03125946968793869\n",
      "Iteration: 2144/10000, Loss: 0.02617308683693409\n",
      "Iteration: 2145/10000, Loss: 0.018578246235847473\n",
      "Iteration: 2146/10000, Loss: 0.030040839686989784\n",
      "Iteration: 2147/10000, Loss: 0.0245115477591753\n",
      "Iteration: 2148/10000, Loss: 0.031041331589221954\n",
      "Iteration: 2149/10000, Loss: 0.02496524155139923\n",
      "Iteration: 2150/10000, Loss: 0.03220362588763237\n",
      "Iteration: 2151/10000, Loss: 0.02365589700639248\n",
      "Iteration: 2152/10000, Loss: 0.035530973225831985\n",
      "Iteration: 2153/10000, Loss: 0.019990224391222\n",
      "Iteration: 2154/10000, Loss: 0.03229055926203728\n",
      "Iteration: 2155/10000, Loss: 0.019741617143154144\n",
      "Iteration: 2156/10000, Loss: 0.015234100632369518\n",
      "Iteration: 2157/10000, Loss: 0.021540775895118713\n",
      "Iteration: 2158/10000, Loss: 0.016225028783082962\n",
      "Iteration: 2159/10000, Loss: 0.02170676551759243\n",
      "Iteration: 2160/10000, Loss: 0.025835124775767326\n",
      "Iteration: 2161/10000, Loss: 0.018330547958612442\n",
      "Iteration: 2162/10000, Loss: 0.02657608687877655\n",
      "Iteration: 2163/10000, Loss: 0.03066505864262581\n",
      "Iteration: 2164/10000, Loss: 0.02510521188378334\n",
      "Iteration: 2165/10000, Loss: 0.02208137698471546\n",
      "Iteration: 2166/10000, Loss: 0.02776223234832287\n",
      "Iteration: 2167/10000, Loss: 0.021086012944579124\n",
      "Iteration: 2168/10000, Loss: 0.028282886371016502\n",
      "Iteration: 2169/10000, Loss: 0.030711481347680092\n",
      "Iteration: 2170/10000, Loss: 0.025301670655608177\n",
      "Iteration: 2171/10000, Loss: 0.025287557393312454\n",
      "Iteration: 2172/10000, Loss: 0.020528126507997513\n",
      "Iteration: 2173/10000, Loss: 0.027369942516088486\n",
      "Iteration: 2174/10000, Loss: 0.02018413133919239\n",
      "Iteration: 2175/10000, Loss: 0.02475895546376705\n",
      "Iteration: 2176/10000, Loss: 0.01797722652554512\n",
      "Iteration: 2177/10000, Loss: 0.03936883807182312\n",
      "Iteration: 2178/10000, Loss: 0.042560040950775146\n",
      "Iteration: 2179/10000, Loss: 0.035538967698812485\n",
      "Iteration: 2180/10000, Loss: 0.030602023005485535\n",
      "Iteration: 2181/10000, Loss: 0.02872544340789318\n",
      "Iteration: 2182/10000, Loss: 0.029307221993803978\n",
      "Iteration: 2183/10000, Loss: 0.019072193652391434\n",
      "Iteration: 2184/10000, Loss: 0.03162616491317749\n",
      "Iteration: 2185/10000, Loss: 0.03238020837306976\n",
      "Iteration: 2186/10000, Loss: 0.025042874738574028\n",
      "Iteration: 2187/10000, Loss: 0.02692469209432602\n",
      "Iteration: 2188/10000, Loss: 0.024250272661447525\n",
      "Iteration: 2189/10000, Loss: 0.01604332961142063\n",
      "Iteration: 2190/10000, Loss: 0.03715995326638222\n",
      "Iteration: 2191/10000, Loss: 0.037474244832992554\n",
      "Iteration: 2192/10000, Loss: 0.029715003445744514\n",
      "Iteration: 2193/10000, Loss: 0.018037397414445877\n",
      "Iteration: 2194/10000, Loss: 0.03192734345793724\n",
      "Iteration: 2195/10000, Loss: 0.02943921647965908\n",
      "Iteration: 2196/10000, Loss: 0.03203914687037468\n",
      "Iteration: 2197/10000, Loss: 0.030473658815026283\n",
      "Iteration: 2198/10000, Loss: 0.022545473650097847\n",
      "Iteration: 2199/10000, Loss: 0.024197053164243698\n",
      "Iteration: 2200/10000, Loss: 0.024757780134677887\n",
      "Average test loss:  0.0016\n",
      "Iteration: 2201/10000, Loss: 0.028485652059316635\n",
      "Iteration: 2202/10000, Loss: 0.021284854039549828\n",
      "Iteration: 2203/10000, Loss: 0.02423507533967495\n",
      "Iteration: 2204/10000, Loss: 0.021740611642599106\n",
      "Iteration: 2205/10000, Loss: 0.025564108043909073\n",
      "Iteration: 2206/10000, Loss: 0.023416666314005852\n",
      "Iteration: 2207/10000, Loss: 0.02471071295440197\n",
      "Iteration: 2208/10000, Loss: 0.026516692712903023\n",
      "Iteration: 2209/10000, Loss: 0.025211239233613014\n",
      "Iteration: 2210/10000, Loss: 0.03702515363693237\n",
      "Iteration: 2211/10000, Loss: 0.023254819214344025\n",
      "Iteration: 2212/10000, Loss: 0.029351573437452316\n",
      "Iteration: 2213/10000, Loss: 0.036174751818180084\n",
      "Iteration: 2214/10000, Loss: 0.0378018356859684\n",
      "Iteration: 2215/10000, Loss: 0.022639086470007896\n",
      "Iteration: 2216/10000, Loss: 0.019450094550848007\n",
      "Iteration: 2217/10000, Loss: 0.035088635981082916\n",
      "Iteration: 2218/10000, Loss: 0.028832223266363144\n",
      "Iteration: 2219/10000, Loss: 0.020687269046902657\n",
      "Iteration: 2220/10000, Loss: 0.02889317274093628\n",
      "Iteration: 2221/10000, Loss: 0.03054650127887726\n",
      "Iteration: 2222/10000, Loss: 0.027757545933127403\n",
      "Iteration: 2223/10000, Loss: 0.025653313845396042\n",
      "Iteration: 2224/10000, Loss: 0.01778029277920723\n",
      "Iteration: 2225/10000, Loss: 0.0227169468998909\n",
      "Iteration: 2226/10000, Loss: 0.018329313024878502\n",
      "Iteration: 2227/10000, Loss: 0.02337816171348095\n",
      "Iteration: 2228/10000, Loss: 0.028015708550810814\n",
      "Iteration: 2229/10000, Loss: 0.027104485780000687\n",
      "Iteration: 2230/10000, Loss: 0.02260768972337246\n",
      "Iteration: 2231/10000, Loss: 0.030345531180500984\n",
      "Iteration: 2232/10000, Loss: 0.022048991173505783\n",
      "Iteration: 2233/10000, Loss: 0.02770180255174637\n",
      "Iteration: 2234/10000, Loss: 0.025157665833830833\n",
      "Iteration: 2235/10000, Loss: 0.03732927888631821\n",
      "Iteration: 2236/10000, Loss: 0.02160729095339775\n",
      "Iteration: 2237/10000, Loss: 0.02088879980146885\n",
      "Iteration: 2238/10000, Loss: 0.03257383033633232\n",
      "Iteration: 2239/10000, Loss: 0.03212125226855278\n",
      "Iteration: 2240/10000, Loss: 0.02978033572435379\n",
      "Iteration: 2241/10000, Loss: 0.04190029576420784\n",
      "Iteration: 2242/10000, Loss: 0.03500141203403473\n",
      "Iteration: 2243/10000, Loss: 0.03254667669534683\n",
      "Iteration: 2244/10000, Loss: 0.01844501681625843\n",
      "Iteration: 2245/10000, Loss: 0.03307931125164032\n",
      "Iteration: 2246/10000, Loss: 0.03463626280426979\n",
      "Iteration: 2247/10000, Loss: 0.02964596636593342\n",
      "Iteration: 2248/10000, Loss: 0.02936706691980362\n",
      "Iteration: 2249/10000, Loss: 0.02822040393948555\n",
      "Iteration: 2250/10000, Loss: 0.02694656141102314\n",
      "Iteration: 2251/10000, Loss: 0.023323755711317062\n",
      "Iteration: 2252/10000, Loss: 0.03299941122531891\n",
      "Iteration: 2253/10000, Loss: 0.022614290937781334\n",
      "Iteration: 2254/10000, Loss: 0.026969632133841515\n",
      "Iteration: 2255/10000, Loss: 0.021142503246665\n",
      "Iteration: 2256/10000, Loss: 0.021906204521656036\n",
      "Iteration: 2257/10000, Loss: 0.03485804796218872\n",
      "Iteration: 2258/10000, Loss: 0.027850905433297157\n",
      "Iteration: 2259/10000, Loss: 0.025642381981015205\n",
      "Iteration: 2260/10000, Loss: 0.02519877254962921\n",
      "Iteration: 2261/10000, Loss: 0.02992986887693405\n",
      "Iteration: 2262/10000, Loss: 0.028731612488627434\n",
      "Iteration: 2263/10000, Loss: 0.025138065218925476\n",
      "Iteration: 2264/10000, Loss: 0.028909984976053238\n",
      "Iteration: 2265/10000, Loss: 0.03153489530086517\n",
      "Iteration: 2266/10000, Loss: 0.027110014110803604\n",
      "Iteration: 2267/10000, Loss: 0.023209212347865105\n",
      "Iteration: 2268/10000, Loss: 0.024252519011497498\n",
      "Iteration: 2269/10000, Loss: 0.02105337753891945\n",
      "Iteration: 2270/10000, Loss: 0.02072666399180889\n",
      "Iteration: 2271/10000, Loss: 0.01995147578418255\n",
      "Iteration: 2272/10000, Loss: 0.022888582199811935\n",
      "Iteration: 2273/10000, Loss: 0.026767298579216003\n",
      "Iteration: 2274/10000, Loss: 0.02328094281256199\n",
      "Iteration: 2275/10000, Loss: 0.02247442677617073\n",
      "Iteration: 2276/10000, Loss: 0.016972709447145462\n",
      "Iteration: 2277/10000, Loss: 0.020864292979240417\n",
      "Iteration: 2278/10000, Loss: 0.023080332204699516\n",
      "Iteration: 2279/10000, Loss: 0.031688474118709564\n",
      "Iteration: 2280/10000, Loss: 0.024848656728863716\n",
      "Iteration: 2281/10000, Loss: 0.020411131903529167\n",
      "Iteration: 2282/10000, Loss: 0.03409542515873909\n",
      "Iteration: 2283/10000, Loss: 0.03410812467336655\n",
      "Iteration: 2284/10000, Loss: 0.01741670072078705\n",
      "Iteration: 2285/10000, Loss: 0.04002833738923073\n",
      "Iteration: 2286/10000, Loss: 0.017595762386918068\n",
      "Iteration: 2287/10000, Loss: 0.021046366542577744\n",
      "Iteration: 2288/10000, Loss: 0.03066256269812584\n",
      "Iteration: 2289/10000, Loss: 0.0259646438062191\n",
      "Iteration: 2290/10000, Loss: 0.028691265732049942\n",
      "Iteration: 2291/10000, Loss: 0.04211527109146118\n",
      "Iteration: 2292/10000, Loss: 0.020421132445335388\n",
      "Iteration: 2293/10000, Loss: 0.0322105772793293\n",
      "Iteration: 2294/10000, Loss: 0.02113615907728672\n",
      "Iteration: 2295/10000, Loss: 0.026725757867097855\n",
      "Iteration: 2296/10000, Loss: 0.024121560156345367\n",
      "Iteration: 2297/10000, Loss: 0.03146706521511078\n",
      "Iteration: 2298/10000, Loss: 0.02731834165751934\n",
      "Iteration: 2299/10000, Loss: 0.02073419652879238\n",
      "Iteration: 2300/10000, Loss: 0.015342038124799728\n",
      "Average test loss:  0.0029\n",
      "Iteration: 2301/10000, Loss: 0.020861728116869926\n",
      "Iteration: 2302/10000, Loss: 0.025224803015589714\n",
      "Iteration: 2303/10000, Loss: 0.03885149583220482\n",
      "Iteration: 2304/10000, Loss: 0.02728324383497238\n",
      "Iteration: 2305/10000, Loss: 0.01999557949602604\n",
      "Iteration: 2306/10000, Loss: 0.034845978021621704\n",
      "Iteration: 2307/10000, Loss: 0.030116666108369827\n",
      "Iteration: 2308/10000, Loss: 0.021683329716324806\n",
      "Iteration: 2309/10000, Loss: 0.02476651780307293\n",
      "Iteration: 2310/10000, Loss: 0.022150162607431412\n",
      "Iteration: 2311/10000, Loss: 0.024909721687436104\n",
      "Iteration: 2312/10000, Loss: 0.025057943537831306\n",
      "Iteration: 2313/10000, Loss: 0.021536407992243767\n",
      "Iteration: 2314/10000, Loss: 0.024587294086813927\n",
      "Iteration: 2315/10000, Loss: 0.01749652624130249\n",
      "Iteration: 2316/10000, Loss: 0.028920944780111313\n",
      "Iteration: 2317/10000, Loss: 0.03380800783634186\n",
      "Iteration: 2318/10000, Loss: 0.023403415456414223\n",
      "Iteration: 2319/10000, Loss: 0.025951914489269257\n",
      "Iteration: 2320/10000, Loss: 0.02329295501112938\n",
      "Iteration: 2321/10000, Loss: 0.024952786043286324\n",
      "Iteration: 2322/10000, Loss: 0.017837796360254288\n",
      "Iteration: 2323/10000, Loss: 0.029828360304236412\n",
      "Iteration: 2324/10000, Loss: 0.03164342790842056\n",
      "Iteration: 2325/10000, Loss: 0.025595413520932198\n",
      "Iteration: 2326/10000, Loss: 0.021072281524538994\n",
      "Iteration: 2327/10000, Loss: 0.03374837711453438\n",
      "Iteration: 2328/10000, Loss: 0.019025679677724838\n",
      "Iteration: 2329/10000, Loss: 0.019586961716413498\n",
      "Iteration: 2330/10000, Loss: 0.023236505687236786\n",
      "Iteration: 2331/10000, Loss: 0.018213093280792236\n",
      "Iteration: 2332/10000, Loss: 0.02344457060098648\n",
      "Iteration: 2333/10000, Loss: 0.020456463098526\n",
      "Iteration: 2334/10000, Loss: 0.0304257795214653\n",
      "Iteration: 2335/10000, Loss: 0.020302772521972656\n",
      "Iteration: 2336/10000, Loss: 0.03232985734939575\n",
      "Iteration: 2337/10000, Loss: 0.03024419955909252\n",
      "Iteration: 2338/10000, Loss: 0.0313371866941452\n",
      "Iteration: 2339/10000, Loss: 0.034523334354162216\n",
      "Iteration: 2340/10000, Loss: 0.027533162385225296\n",
      "Iteration: 2341/10000, Loss: 0.02542976289987564\n",
      "Iteration: 2342/10000, Loss: 0.03688209503889084\n",
      "Iteration: 2343/10000, Loss: 0.020892726257443428\n",
      "Iteration: 2344/10000, Loss: 0.03644855320453644\n",
      "Iteration: 2345/10000, Loss: 0.02137519046664238\n",
      "Iteration: 2346/10000, Loss: 0.025753403082489967\n",
      "Iteration: 2347/10000, Loss: 0.03776050731539726\n",
      "Iteration: 2348/10000, Loss: 0.021750932559370995\n",
      "Iteration: 2349/10000, Loss: 0.03271098807454109\n",
      "Iteration: 2350/10000, Loss: 0.033057987689971924\n",
      "Iteration: 2351/10000, Loss: 0.028882432729005814\n",
      "Iteration: 2352/10000, Loss: 0.017437392845749855\n",
      "Iteration: 2353/10000, Loss: 0.028409074991941452\n",
      "Iteration: 2354/10000, Loss: 0.02272898517549038\n",
      "Iteration: 2355/10000, Loss: 0.016416236758232117\n",
      "Iteration: 2356/10000, Loss: 0.024793019518256187\n",
      "Iteration: 2357/10000, Loss: 0.036280084401369095\n",
      "Iteration: 2358/10000, Loss: 0.027638792991638184\n",
      "Iteration: 2359/10000, Loss: 0.028513846918940544\n",
      "Iteration: 2360/10000, Loss: 0.031045470386743546\n",
      "Iteration: 2361/10000, Loss: 0.025575833395123482\n",
      "Iteration: 2362/10000, Loss: 0.021015778183937073\n",
      "Iteration: 2363/10000, Loss: 0.020219288766384125\n",
      "Iteration: 2364/10000, Loss: 0.0216081403195858\n",
      "Iteration: 2365/10000, Loss: 0.029429826885461807\n",
      "Iteration: 2366/10000, Loss: 0.029963871464133263\n",
      "Iteration: 2367/10000, Loss: 0.01875433884561062\n",
      "Iteration: 2368/10000, Loss: 0.029789138585329056\n",
      "Iteration: 2369/10000, Loss: 0.024069830775260925\n",
      "Iteration: 2370/10000, Loss: 0.032418228685855865\n",
      "Iteration: 2371/10000, Loss: 0.021584808826446533\n",
      "Iteration: 2372/10000, Loss: 0.021842170506715775\n",
      "Iteration: 2373/10000, Loss: 0.029187556356191635\n",
      "Iteration: 2374/10000, Loss: 0.023029077798128128\n",
      "Iteration: 2375/10000, Loss: 0.023982953280210495\n",
      "Iteration: 2376/10000, Loss: 0.027729636058211327\n",
      "Iteration: 2377/10000, Loss: 0.02947787381708622\n",
      "Iteration: 2378/10000, Loss: 0.02034844644367695\n",
      "Iteration: 2379/10000, Loss: 0.020985400304198265\n",
      "Iteration: 2380/10000, Loss: 0.02138173021376133\n",
      "Iteration: 2381/10000, Loss: 0.020153308287262917\n",
      "Iteration: 2382/10000, Loss: 0.04268184304237366\n",
      "Iteration: 2383/10000, Loss: 0.026227692142128944\n",
      "Iteration: 2384/10000, Loss: 0.021817496046423912\n",
      "Iteration: 2385/10000, Loss: 0.025042487308382988\n",
      "Iteration: 2386/10000, Loss: 0.023074960336089134\n",
      "Iteration: 2387/10000, Loss: 0.020697934553027153\n",
      "Iteration: 2388/10000, Loss: 0.02482825517654419\n",
      "Iteration: 2389/10000, Loss: 0.02284998632967472\n",
      "Iteration: 2390/10000, Loss: 0.026269294321537018\n",
      "Iteration: 2391/10000, Loss: 0.02126147225499153\n",
      "Iteration: 2392/10000, Loss: 0.020006636157631874\n",
      "Iteration: 2393/10000, Loss: 0.03466840460896492\n",
      "Iteration: 2394/10000, Loss: 0.02612035721540451\n",
      "Iteration: 2395/10000, Loss: 0.026594428345561028\n",
      "Iteration: 2396/10000, Loss: 0.01986648328602314\n",
      "Iteration: 2397/10000, Loss: 0.020874792709946632\n",
      "Iteration: 2398/10000, Loss: 0.026690255850553513\n",
      "Iteration: 2399/10000, Loss: 0.028260288760066032\n",
      "Iteration: 2400/10000, Loss: 0.021072378382086754\n",
      "Average test loss:  0.0020\n",
      "Iteration: 2401/10000, Loss: 0.02420518919825554\n",
      "Iteration: 2402/10000, Loss: 0.028984008356928825\n",
      "Iteration: 2403/10000, Loss: 0.030503612011671066\n",
      "Iteration: 2404/10000, Loss: 0.020352859050035477\n",
      "Iteration: 2405/10000, Loss: 0.017555413767695427\n",
      "Iteration: 2406/10000, Loss: 0.022027509286999702\n",
      "Iteration: 2407/10000, Loss: 0.022666608914732933\n",
      "Iteration: 2408/10000, Loss: 0.018233701586723328\n",
      "Iteration: 2409/10000, Loss: 0.02201317623257637\n",
      "Iteration: 2410/10000, Loss: 0.021555975079536438\n",
      "Iteration: 2411/10000, Loss: 0.02522542141377926\n",
      "Iteration: 2412/10000, Loss: 0.027016423642635345\n",
      "Iteration: 2413/10000, Loss: 0.02877591736614704\n",
      "Iteration: 2414/10000, Loss: 0.02505144104361534\n",
      "Iteration: 2415/10000, Loss: 0.02204088680446148\n",
      "Iteration: 2416/10000, Loss: 0.029687367379665375\n",
      "Iteration: 2417/10000, Loss: 0.01931828446686268\n",
      "Iteration: 2418/10000, Loss: 0.016888529062271118\n",
      "Iteration: 2419/10000, Loss: 0.022759700194001198\n",
      "Iteration: 2420/10000, Loss: 0.035791825503110886\n",
      "Iteration: 2421/10000, Loss: 0.019092639908194542\n",
      "Iteration: 2422/10000, Loss: 0.020090706646442413\n",
      "Iteration: 2423/10000, Loss: 0.02851743996143341\n",
      "Iteration: 2424/10000, Loss: 0.025847576558589935\n",
      "Iteration: 2425/10000, Loss: 0.01846044696867466\n",
      "Iteration: 2426/10000, Loss: 0.026785576716065407\n",
      "Iteration: 2427/10000, Loss: 0.02191082201898098\n",
      "Iteration: 2428/10000, Loss: 0.025147417560219765\n",
      "Iteration: 2429/10000, Loss: 0.0155173996463418\n",
      "Iteration: 2430/10000, Loss: 0.018220143392682076\n",
      "Iteration: 2431/10000, Loss: 0.025694364681839943\n",
      "Iteration: 2432/10000, Loss: 0.03212476894259453\n",
      "Iteration: 2433/10000, Loss: 0.03239952027797699\n",
      "Iteration: 2434/10000, Loss: 0.018528105691075325\n",
      "Iteration: 2435/10000, Loss: 0.027015697211027145\n",
      "Iteration: 2436/10000, Loss: 0.024021117016673088\n",
      "Iteration: 2437/10000, Loss: 0.022892557084560394\n",
      "Iteration: 2438/10000, Loss: 0.025919239968061447\n",
      "Iteration: 2439/10000, Loss: 0.017137203365564346\n",
      "Iteration: 2440/10000, Loss: 0.03304029256105423\n",
      "Iteration: 2441/10000, Loss: 0.027555901557207108\n",
      "Iteration: 2442/10000, Loss: 0.01608281210064888\n",
      "Iteration: 2443/10000, Loss: 0.02454186975955963\n",
      "Iteration: 2444/10000, Loss: 0.03204125910997391\n",
      "Iteration: 2445/10000, Loss: 0.02404583990573883\n",
      "Iteration: 2446/10000, Loss: 0.026745986193418503\n",
      "Iteration: 2447/10000, Loss: 0.028180813416838646\n",
      "Iteration: 2448/10000, Loss: 0.01899959333240986\n",
      "Iteration: 2449/10000, Loss: 0.021739235147833824\n",
      "Iteration: 2450/10000, Loss: 0.025583846494555473\n",
      "Iteration: 2451/10000, Loss: 0.02634001336991787\n",
      "Iteration: 2452/10000, Loss: 0.031834568828344345\n",
      "Iteration: 2453/10000, Loss: 0.02761342190206051\n",
      "Iteration: 2454/10000, Loss: 0.021747229620814323\n",
      "Iteration: 2455/10000, Loss: 0.025309650227427483\n",
      "Iteration: 2456/10000, Loss: 0.023428097367286682\n",
      "Iteration: 2457/10000, Loss: 0.01924031414091587\n",
      "Iteration: 2458/10000, Loss: 0.02515397220849991\n",
      "Iteration: 2459/10000, Loss: 0.024203820154070854\n",
      "Iteration: 2460/10000, Loss: 0.02304658107459545\n",
      "Iteration: 2461/10000, Loss: 0.022531289607286453\n",
      "Iteration: 2462/10000, Loss: 0.02420119382441044\n",
      "Iteration: 2463/10000, Loss: 0.031871337443590164\n",
      "Iteration: 2464/10000, Loss: 0.017214998602867126\n",
      "Iteration: 2465/10000, Loss: 0.024868696928024292\n",
      "Iteration: 2466/10000, Loss: 0.024257460609078407\n",
      "Iteration: 2467/10000, Loss: 0.02344418503344059\n",
      "Iteration: 2468/10000, Loss: 0.03218454122543335\n",
      "Iteration: 2469/10000, Loss: 0.029371831566095352\n",
      "Iteration: 2470/10000, Loss: 0.020961033180356026\n",
      "Iteration: 2471/10000, Loss: 0.0313444659113884\n",
      "Iteration: 2472/10000, Loss: 0.02474718913435936\n",
      "Iteration: 2473/10000, Loss: 0.022309044376015663\n",
      "Iteration: 2474/10000, Loss: 0.03718755394220352\n",
      "Iteration: 2475/10000, Loss: 0.03329240530729294\n",
      "Iteration: 2476/10000, Loss: 0.026903942227363586\n",
      "Iteration: 2477/10000, Loss: 0.021951548755168915\n",
      "Iteration: 2478/10000, Loss: 0.017450636252760887\n",
      "Iteration: 2479/10000, Loss: 0.017154930159449577\n",
      "Iteration: 2480/10000, Loss: 0.020820869132876396\n",
      "Iteration: 2481/10000, Loss: 0.03229686990380287\n",
      "Iteration: 2482/10000, Loss: 0.024625234305858612\n",
      "Iteration: 2483/10000, Loss: 0.029457705095410347\n",
      "Iteration: 2484/10000, Loss: 0.025305286049842834\n",
      "Iteration: 2485/10000, Loss: 0.0232784952968359\n",
      "Iteration: 2486/10000, Loss: 0.021693727001547813\n",
      "Iteration: 2487/10000, Loss: 0.01901945471763611\n",
      "Iteration: 2488/10000, Loss: 0.022937607020139694\n",
      "Iteration: 2489/10000, Loss: 0.027107534930109978\n",
      "Iteration: 2490/10000, Loss: 0.021750126034021378\n",
      "Iteration: 2491/10000, Loss: 0.02526850998401642\n",
      "Iteration: 2492/10000, Loss: 0.021297814324498177\n",
      "Iteration: 2493/10000, Loss: 0.02624415047466755\n",
      "Iteration: 2494/10000, Loss: 0.03267672285437584\n",
      "Iteration: 2495/10000, Loss: 0.029535003006458282\n",
      "Iteration: 2496/10000, Loss: 0.019138997420668602\n",
      "Iteration: 2497/10000, Loss: 0.04379860684275627\n",
      "Iteration: 2498/10000, Loss: 0.027904804795980453\n",
      "Iteration: 2499/10000, Loss: 0.026181677356362343\n",
      "Iteration: 2500/10000, Loss: 0.022792890667915344\n",
      "Average test loss:  0.0027\n",
      "Iteration: 2501/10000, Loss: 0.027812505140900612\n",
      "Iteration: 2502/10000, Loss: 0.025710290297865868\n",
      "Iteration: 2503/10000, Loss: 0.03186836838722229\n",
      "Iteration: 2504/10000, Loss: 0.0212729349732399\n",
      "Iteration: 2505/10000, Loss: 0.034666407853364944\n",
      "Iteration: 2506/10000, Loss: 0.0185068529099226\n",
      "Iteration: 2507/10000, Loss: 0.017381718382239342\n",
      "Iteration: 2508/10000, Loss: 0.02725181169807911\n",
      "Iteration: 2509/10000, Loss: 0.021233271807432175\n",
      "Iteration: 2510/10000, Loss: 0.03363469988107681\n",
      "Iteration: 2511/10000, Loss: 0.027281152084469795\n",
      "Iteration: 2512/10000, Loss: 0.02598682977259159\n",
      "Iteration: 2513/10000, Loss: 0.022043244913220406\n",
      "Iteration: 2514/10000, Loss: 0.02630663849413395\n",
      "Iteration: 2515/10000, Loss: 0.014949843287467957\n",
      "Iteration: 2516/10000, Loss: 0.03715589642524719\n",
      "Iteration: 2517/10000, Loss: 0.02151326835155487\n",
      "Iteration: 2518/10000, Loss: 0.02506301924586296\n",
      "Iteration: 2519/10000, Loss: 0.022686239331960678\n",
      "Iteration: 2520/10000, Loss: 0.022720742970705032\n",
      "Iteration: 2521/10000, Loss: 0.02757912687957287\n",
      "Iteration: 2522/10000, Loss: 0.023655060678720474\n",
      "Iteration: 2523/10000, Loss: 0.017944810912013054\n",
      "Iteration: 2524/10000, Loss: 0.019629931077361107\n",
      "Iteration: 2525/10000, Loss: 0.026363080367445946\n",
      "Iteration: 2526/10000, Loss: 0.016042960807681084\n",
      "Iteration: 2527/10000, Loss: 0.05612414330244064\n",
      "Iteration: 2528/10000, Loss: 0.029726367443799973\n",
      "Iteration: 2529/10000, Loss: 0.021954847499728203\n",
      "Iteration: 2530/10000, Loss: 0.018504153937101364\n",
      "Iteration: 2531/10000, Loss: 0.025897210463881493\n",
      "Iteration: 2532/10000, Loss: 0.023243922740221024\n",
      "Iteration: 2533/10000, Loss: 0.026957770809531212\n",
      "Iteration: 2534/10000, Loss: 0.023033382371068\n",
      "Iteration: 2535/10000, Loss: 0.03460276126861572\n",
      "Iteration: 2536/10000, Loss: 0.01757526956498623\n",
      "Iteration: 2537/10000, Loss: 0.021883558481931686\n",
      "Iteration: 2538/10000, Loss: 0.021098880097270012\n",
      "Iteration: 2539/10000, Loss: 0.01377098634839058\n",
      "Iteration: 2540/10000, Loss: 0.01998274400830269\n",
      "Iteration: 2541/10000, Loss: 0.014381807297468185\n",
      "Iteration: 2542/10000, Loss: 0.011683600023388863\n",
      "Iteration: 2543/10000, Loss: 0.03274060785770416\n",
      "Iteration: 2544/10000, Loss: 0.01733177900314331\n",
      "Iteration: 2545/10000, Loss: 0.023844048380851746\n",
      "Iteration: 2546/10000, Loss: 0.02396566793322563\n",
      "Iteration: 2547/10000, Loss: 0.026203298941254616\n",
      "Iteration: 2548/10000, Loss: 0.021890908479690552\n",
      "Iteration: 2549/10000, Loss: 0.02733330987393856\n",
      "Iteration: 2550/10000, Loss: 0.02114892564713955\n",
      "Iteration: 2551/10000, Loss: 0.03479060158133507\n",
      "Iteration: 2552/10000, Loss: 0.0295349583029747\n",
      "Iteration: 2553/10000, Loss: 0.024028919637203217\n",
      "Iteration: 2554/10000, Loss: 0.019139403477311134\n",
      "Iteration: 2555/10000, Loss: 0.02605704590678215\n",
      "Iteration: 2556/10000, Loss: 0.021765733137726784\n",
      "Iteration: 2557/10000, Loss: 0.021328765898942947\n",
      "Iteration: 2558/10000, Loss: 0.02181621827185154\n",
      "Iteration: 2559/10000, Loss: 0.02153264731168747\n",
      "Iteration: 2560/10000, Loss: 0.0355178564786911\n",
      "Iteration: 2561/10000, Loss: 0.021900886669754982\n",
      "Iteration: 2562/10000, Loss: 0.022169431671500206\n",
      "Iteration: 2563/10000, Loss: 0.029957924038171768\n",
      "Iteration: 2564/10000, Loss: 0.01827204041182995\n",
      "Iteration: 2565/10000, Loss: 0.013949484564363956\n",
      "Iteration: 2566/10000, Loss: 0.024099193513393402\n",
      "Iteration: 2567/10000, Loss: 0.023051094263792038\n",
      "Iteration: 2568/10000, Loss: 0.020288795232772827\n",
      "Iteration: 2569/10000, Loss: 0.021617058664560318\n",
      "Iteration: 2570/10000, Loss: 0.016025176271796227\n",
      "Iteration: 2571/10000, Loss: 0.01722642034292221\n",
      "Iteration: 2572/10000, Loss: 0.02133064903318882\n",
      "Iteration: 2573/10000, Loss: 0.022345760837197304\n",
      "Iteration: 2574/10000, Loss: 0.029382674023509026\n",
      "Iteration: 2575/10000, Loss: 0.016187604516744614\n",
      "Iteration: 2576/10000, Loss: 0.02025512605905533\n",
      "Iteration: 2577/10000, Loss: 0.018887661397457123\n",
      "Iteration: 2578/10000, Loss: 0.025327268987894058\n",
      "Iteration: 2579/10000, Loss: 0.02986917272210121\n",
      "Iteration: 2580/10000, Loss: 0.020203961059451103\n",
      "Iteration: 2581/10000, Loss: 0.02500496804714203\n",
      "Iteration: 2582/10000, Loss: 0.03053692914545536\n",
      "Iteration: 2583/10000, Loss: 0.01964874565601349\n",
      "Iteration: 2584/10000, Loss: 0.022486453875899315\n",
      "Iteration: 2585/10000, Loss: 0.017708180472254753\n",
      "Iteration: 2586/10000, Loss: 0.016699641942977905\n",
      "Iteration: 2587/10000, Loss: 0.02296478860080242\n",
      "Iteration: 2588/10000, Loss: 0.01593378186225891\n",
      "Iteration: 2589/10000, Loss: 0.02497909963130951\n",
      "Iteration: 2590/10000, Loss: 0.02885855920612812\n",
      "Iteration: 2591/10000, Loss: 0.03221592307090759\n",
      "Iteration: 2592/10000, Loss: 0.030682191252708435\n",
      "Iteration: 2593/10000, Loss: 0.017300700768828392\n",
      "Iteration: 2594/10000, Loss: 0.020692551508545876\n",
      "Iteration: 2595/10000, Loss: 0.027533909305930138\n",
      "Iteration: 2596/10000, Loss: 0.02501240000128746\n",
      "Iteration: 2597/10000, Loss: 0.020845500752329826\n",
      "Iteration: 2598/10000, Loss: 0.018235402181744576\n",
      "Iteration: 2599/10000, Loss: 0.02055438607931137\n",
      "Iteration: 2600/10000, Loss: 0.033515844494104385\n",
      "Average test loss:  0.0019\n",
      "Iteration: 2601/10000, Loss: 0.020544081926345825\n",
      "Iteration: 2602/10000, Loss: 0.033838901668787\n",
      "Iteration: 2603/10000, Loss: 0.028332993388175964\n",
      "Iteration: 2604/10000, Loss: 0.014621620997786522\n",
      "Iteration: 2605/10000, Loss: 0.02257518284022808\n",
      "Iteration: 2606/10000, Loss: 0.015333671122789383\n",
      "Iteration: 2607/10000, Loss: 0.02913956344127655\n",
      "Iteration: 2608/10000, Loss: 0.018168438225984573\n",
      "Iteration: 2609/10000, Loss: 0.022427456453442574\n",
      "Iteration: 2610/10000, Loss: 0.024124793708324432\n",
      "Iteration: 2611/10000, Loss: 0.022790435701608658\n",
      "Iteration: 2612/10000, Loss: 0.010894118808209896\n",
      "Iteration: 2613/10000, Loss: 0.025159802287817\n",
      "Iteration: 2614/10000, Loss: 0.021432990208268166\n",
      "Iteration: 2615/10000, Loss: 0.022887693718075752\n",
      "Iteration: 2616/10000, Loss: 0.01772579737007618\n",
      "Iteration: 2617/10000, Loss: 0.02046886272728443\n",
      "Iteration: 2618/10000, Loss: 0.021499913185834885\n",
      "Iteration: 2619/10000, Loss: 0.019103653728961945\n",
      "Iteration: 2620/10000, Loss: 0.016257349401712418\n",
      "Iteration: 2621/10000, Loss: 0.016956370323896408\n",
      "Iteration: 2622/10000, Loss: 0.023855092003941536\n",
      "Iteration: 2623/10000, Loss: 0.02064323052763939\n",
      "Iteration: 2624/10000, Loss: 0.031031914055347443\n",
      "Iteration: 2625/10000, Loss: 0.025324082002043724\n",
      "Iteration: 2626/10000, Loss: 0.020914165303111076\n",
      "Iteration: 2627/10000, Loss: 0.030498847365379333\n",
      "Iteration: 2628/10000, Loss: 0.019026784226298332\n",
      "Iteration: 2629/10000, Loss: 0.025723224505782127\n",
      "Iteration: 2630/10000, Loss: 0.023470381274819374\n",
      "Iteration: 2631/10000, Loss: 0.016385694965720177\n",
      "Iteration: 2632/10000, Loss: 0.019839651882648468\n",
      "Iteration: 2633/10000, Loss: 0.02859339863061905\n",
      "Iteration: 2634/10000, Loss: 0.024815354496240616\n",
      "Iteration: 2635/10000, Loss: 0.017500994727015495\n",
      "Iteration: 2636/10000, Loss: 0.0261684637516737\n",
      "Iteration: 2637/10000, Loss: 0.018241800367832184\n",
      "Iteration: 2638/10000, Loss: 0.03124275803565979\n",
      "Iteration: 2639/10000, Loss: 0.025243928655982018\n",
      "Iteration: 2640/10000, Loss: 0.032951176166534424\n",
      "Iteration: 2641/10000, Loss: 0.02857428602874279\n",
      "Iteration: 2642/10000, Loss: 0.019407866522669792\n",
      "Iteration: 2643/10000, Loss: 0.02157137729227543\n",
      "Iteration: 2644/10000, Loss: 0.02443462423980236\n",
      "Iteration: 2645/10000, Loss: 0.043841246515512466\n",
      "Iteration: 2646/10000, Loss: 0.023130981251597404\n",
      "Iteration: 2647/10000, Loss: 0.02190556190907955\n",
      "Iteration: 2648/10000, Loss: 0.026160290464758873\n",
      "Iteration: 2649/10000, Loss: 0.019807705655694008\n",
      "Iteration: 2650/10000, Loss: 0.028359508141875267\n",
      "Iteration: 2651/10000, Loss: 0.01178485993295908\n",
      "Iteration: 2652/10000, Loss: 0.030473073944449425\n",
      "Iteration: 2653/10000, Loss: 0.028538953512907028\n",
      "Iteration: 2654/10000, Loss: 0.03105626069009304\n",
      "Iteration: 2655/10000, Loss: 0.0289323627948761\n",
      "Iteration: 2656/10000, Loss: 0.017210014164447784\n",
      "Iteration: 2657/10000, Loss: 0.019468236714601517\n",
      "Iteration: 2658/10000, Loss: 0.024005597457289696\n",
      "Iteration: 2659/10000, Loss: 0.024082615971565247\n",
      "Iteration: 2660/10000, Loss: 0.01971624791622162\n",
      "Iteration: 2661/10000, Loss: 0.02510467730462551\n",
      "Iteration: 2662/10000, Loss: 0.025943811982870102\n",
      "Iteration: 2663/10000, Loss: 0.022191520780324936\n",
      "Iteration: 2664/10000, Loss: 0.03402876853942871\n",
      "Iteration: 2665/10000, Loss: 0.02276374027132988\n",
      "Iteration: 2666/10000, Loss: 0.019446155056357384\n",
      "Iteration: 2667/10000, Loss: 0.01840999163687229\n",
      "Iteration: 2668/10000, Loss: 0.026198089122772217\n",
      "Iteration: 2669/10000, Loss: 0.02322787046432495\n",
      "Iteration: 2670/10000, Loss: 0.027333710342645645\n",
      "Iteration: 2671/10000, Loss: 0.03339709714055061\n",
      "Iteration: 2672/10000, Loss: 0.024173244833946228\n",
      "Iteration: 2673/10000, Loss: 0.020542487502098083\n",
      "Iteration: 2674/10000, Loss: 0.01908258907496929\n",
      "Iteration: 2675/10000, Loss: 0.027827559038996696\n",
      "Iteration: 2676/10000, Loss: 0.018032947555184364\n",
      "Iteration: 2677/10000, Loss: 0.024700626730918884\n",
      "Iteration: 2678/10000, Loss: 0.021456442773342133\n",
      "Iteration: 2679/10000, Loss: 0.02222472056746483\n",
      "Iteration: 2680/10000, Loss: 0.017755473032593727\n",
      "Iteration: 2681/10000, Loss: 0.023980693891644478\n",
      "Iteration: 2682/10000, Loss: 0.02436947636306286\n",
      "Iteration: 2683/10000, Loss: 0.026826996356248856\n",
      "Iteration: 2684/10000, Loss: 0.02352030947804451\n",
      "Iteration: 2685/10000, Loss: 0.021296899765729904\n",
      "Iteration: 2686/10000, Loss: 0.028324870392680168\n",
      "Iteration: 2687/10000, Loss: 0.019957203418016434\n",
      "Iteration: 2688/10000, Loss: 0.02097061648964882\n",
      "Iteration: 2689/10000, Loss: 0.016677016392350197\n",
      "Iteration: 2690/10000, Loss: 0.01785159669816494\n",
      "Iteration: 2691/10000, Loss: 0.016634585335850716\n",
      "Iteration: 2692/10000, Loss: 0.02805948071181774\n",
      "Iteration: 2693/10000, Loss: 0.02047419175505638\n",
      "Iteration: 2694/10000, Loss: 0.0168458241969347\n",
      "Iteration: 2695/10000, Loss: 0.03314097970724106\n",
      "Iteration: 2696/10000, Loss: 0.017391357570886612\n",
      "Iteration: 2697/10000, Loss: 0.02792447991669178\n",
      "Iteration: 2698/10000, Loss: 0.023412248119711876\n",
      "Iteration: 2699/10000, Loss: 0.01726924441754818\n",
      "Iteration: 2700/10000, Loss: 0.021140901371836662\n",
      "Average test loss:  0.0012\n",
      "Iteration: 2701/10000, Loss: 0.027752887457609177\n",
      "Iteration: 2702/10000, Loss: 0.027694137766957283\n",
      "Iteration: 2703/10000, Loss: 0.01983322948217392\n",
      "Iteration: 2704/10000, Loss: 0.023654110729694366\n",
      "Iteration: 2705/10000, Loss: 0.031126664951443672\n",
      "Iteration: 2706/10000, Loss: 0.016345050185918808\n",
      "Iteration: 2707/10000, Loss: 0.013760413974523544\n",
      "Iteration: 2708/10000, Loss: 0.025909533724188805\n",
      "Iteration: 2709/10000, Loss: 0.032070424407720566\n",
      "Iteration: 2710/10000, Loss: 0.01357931736856699\n",
      "Iteration: 2711/10000, Loss: 0.023341728374361992\n",
      "Iteration: 2712/10000, Loss: 0.018001845106482506\n",
      "Iteration: 2713/10000, Loss: 0.018413927406072617\n",
      "Iteration: 2714/10000, Loss: 0.022602228447794914\n",
      "Iteration: 2715/10000, Loss: 0.018615249544382095\n",
      "Iteration: 2716/10000, Loss: 0.02041039988398552\n",
      "Iteration: 2717/10000, Loss: 0.02424461580812931\n",
      "Iteration: 2718/10000, Loss: 0.018965626135468483\n",
      "Iteration: 2719/10000, Loss: 0.026662977412343025\n",
      "Iteration: 2720/10000, Loss: 0.024730518460273743\n",
      "Iteration: 2721/10000, Loss: 0.03159148246049881\n",
      "Iteration: 2722/10000, Loss: 0.009910167194902897\n",
      "Iteration: 2723/10000, Loss: 0.01881473883986473\n",
      "Iteration: 2724/10000, Loss: 0.025942586362361908\n",
      "Iteration: 2725/10000, Loss: 0.023649711161851883\n",
      "Iteration: 2726/10000, Loss: 0.023122482001781464\n",
      "Iteration: 2727/10000, Loss: 0.016225088387727737\n",
      "Iteration: 2728/10000, Loss: 0.01738247089087963\n",
      "Iteration: 2729/10000, Loss: 0.01935793273150921\n",
      "Iteration: 2730/10000, Loss: 0.026380926370620728\n",
      "Iteration: 2731/10000, Loss: 0.014159278012812138\n",
      "Iteration: 2732/10000, Loss: 0.02317434549331665\n",
      "Iteration: 2733/10000, Loss: 0.021086446940898895\n",
      "Iteration: 2734/10000, Loss: 0.023361848667263985\n",
      "Iteration: 2735/10000, Loss: 0.024042997509241104\n",
      "Iteration: 2736/10000, Loss: 0.02439003437757492\n",
      "Iteration: 2737/10000, Loss: 0.018611960113048553\n",
      "Iteration: 2738/10000, Loss: 0.021323312073946\n",
      "Iteration: 2739/10000, Loss: 0.022282354533672333\n",
      "Iteration: 2740/10000, Loss: 0.01958891563117504\n",
      "Iteration: 2741/10000, Loss: 0.019211065024137497\n",
      "Iteration: 2742/10000, Loss: 0.015422316268086433\n",
      "Iteration: 2743/10000, Loss: 0.01578323356807232\n",
      "Iteration: 2744/10000, Loss: 0.02160208858549595\n",
      "Iteration: 2745/10000, Loss: 0.02466036193072796\n",
      "Iteration: 2746/10000, Loss: 0.019401922821998596\n",
      "Iteration: 2747/10000, Loss: 0.026154717430472374\n",
      "Iteration: 2748/10000, Loss: 0.021739041432738304\n",
      "Iteration: 2749/10000, Loss: 0.01906771771609783\n",
      "Iteration: 2750/10000, Loss: 0.016374513506889343\n",
      "Iteration: 2751/10000, Loss: 0.024778587743639946\n",
      "Iteration: 2752/10000, Loss: 0.02877652645111084\n",
      "Iteration: 2753/10000, Loss: 0.026045139878988266\n",
      "Iteration: 2754/10000, Loss: 0.0259998831897974\n",
      "Iteration: 2755/10000, Loss: 0.01776483841240406\n",
      "Iteration: 2756/10000, Loss: 0.019734732806682587\n",
      "Iteration: 2757/10000, Loss: 0.01410425640642643\n",
      "Iteration: 2758/10000, Loss: 0.01902354508638382\n",
      "Iteration: 2759/10000, Loss: 0.017956186085939407\n",
      "Iteration: 2760/10000, Loss: 0.03466099500656128\n",
      "Iteration: 2761/10000, Loss: 0.014283576980233192\n",
      "Iteration: 2762/10000, Loss: 0.018258152529597282\n",
      "Iteration: 2763/10000, Loss: 0.025490902364253998\n",
      "Iteration: 2764/10000, Loss: 0.025288762524724007\n",
      "Iteration: 2765/10000, Loss: 0.024025464430451393\n",
      "Iteration: 2766/10000, Loss: 0.023498818278312683\n",
      "Iteration: 2767/10000, Loss: 0.020725764334201813\n",
      "Iteration: 2768/10000, Loss: 0.017938001081347466\n",
      "Iteration: 2769/10000, Loss: 0.02165806293487549\n",
      "Iteration: 2770/10000, Loss: 0.01742030493915081\n",
      "Iteration: 2771/10000, Loss: 0.022863294929265976\n",
      "Iteration: 2772/10000, Loss: 0.02552701346576214\n",
      "Iteration: 2773/10000, Loss: 0.01710745319724083\n",
      "Iteration: 2774/10000, Loss: 0.018765050917863846\n",
      "Iteration: 2775/10000, Loss: 0.026031512767076492\n",
      "Iteration: 2776/10000, Loss: 0.034145697951316833\n",
      "Iteration: 2777/10000, Loss: 0.024810638278722763\n",
      "Iteration: 2778/10000, Loss: 0.018669836223125458\n",
      "Iteration: 2779/10000, Loss: 0.01835782639682293\n",
      "Iteration: 2780/10000, Loss: 0.015883680433034897\n",
      "Iteration: 2781/10000, Loss: 0.023259934037923813\n",
      "Iteration: 2782/10000, Loss: 0.02270517125725746\n",
      "Iteration: 2783/10000, Loss: 0.020253591239452362\n",
      "Iteration: 2784/10000, Loss: 0.02450679987668991\n",
      "Iteration: 2785/10000, Loss: 0.015408591367304325\n",
      "Iteration: 2786/10000, Loss: 0.01727527566254139\n",
      "Iteration: 2787/10000, Loss: 0.015298576094210148\n",
      "Iteration: 2788/10000, Loss: 0.025791997089982033\n",
      "Iteration: 2789/10000, Loss: 0.034423358738422394\n",
      "Iteration: 2790/10000, Loss: 0.02433166466653347\n",
      "Iteration: 2791/10000, Loss: 0.01440955139696598\n",
      "Iteration: 2792/10000, Loss: 0.025182293727993965\n",
      "Iteration: 2793/10000, Loss: 0.019608240574598312\n",
      "Iteration: 2794/10000, Loss: 0.024305686354637146\n",
      "Iteration: 2795/10000, Loss: 0.023140661418437958\n",
      "Iteration: 2796/10000, Loss: 0.01764681190252304\n",
      "Iteration: 2797/10000, Loss: 0.027815448120236397\n",
      "Iteration: 2798/10000, Loss: 0.015289976261556149\n",
      "Iteration: 2799/10000, Loss: 0.024746976792812347\n",
      "Iteration: 2800/10000, Loss: 0.02362838387489319\n",
      "Average test loss:  0.0009\n",
      "Iteration: 2801/10000, Loss: 0.022042976692318916\n",
      "Iteration: 2802/10000, Loss: 0.03383105993270874\n",
      "Iteration: 2803/10000, Loss: 0.02660500630736351\n",
      "Iteration: 2804/10000, Loss: 0.015504770912230015\n",
      "Iteration: 2805/10000, Loss: 0.022832157090306282\n",
      "Iteration: 2806/10000, Loss: 0.02030804380774498\n",
      "Iteration: 2807/10000, Loss: 0.024165675044059753\n",
      "Iteration: 2808/10000, Loss: 0.017151564359664917\n",
      "Iteration: 2809/10000, Loss: 0.020008917897939682\n",
      "Iteration: 2810/10000, Loss: 0.023354506120085716\n",
      "Iteration: 2811/10000, Loss: 0.01607934571802616\n",
      "Iteration: 2812/10000, Loss: 0.025742724537849426\n",
      "Iteration: 2813/10000, Loss: 0.028069866821169853\n",
      "Iteration: 2814/10000, Loss: 0.021469855681061745\n",
      "Iteration: 2815/10000, Loss: 0.01585964858531952\n",
      "Iteration: 2816/10000, Loss: 0.03830258548259735\n",
      "Iteration: 2817/10000, Loss: 0.019816646352410316\n",
      "Iteration: 2818/10000, Loss: 0.02786860056221485\n",
      "Iteration: 2819/10000, Loss: 0.022593030706048012\n",
      "Iteration: 2820/10000, Loss: 0.01870133727788925\n",
      "Iteration: 2821/10000, Loss: 0.019708730280399323\n",
      "Iteration: 2822/10000, Loss: 0.015599018894135952\n",
      "Iteration: 2823/10000, Loss: 0.023160316050052643\n",
      "Iteration: 2824/10000, Loss: 0.014277303591370583\n",
      "Iteration: 2825/10000, Loss: 0.018203502520918846\n",
      "Iteration: 2826/10000, Loss: 0.013476723805069923\n",
      "Iteration: 2827/10000, Loss: 0.020070096477866173\n",
      "Iteration: 2828/10000, Loss: 0.014078888110816479\n",
      "Iteration: 2829/10000, Loss: 0.0284687802195549\n",
      "Iteration: 2830/10000, Loss: 0.014814207330346107\n",
      "Iteration: 2831/10000, Loss: 0.016779428347945213\n",
      "Iteration: 2832/10000, Loss: 0.023920152336359024\n",
      "Iteration: 2833/10000, Loss: 0.0224758367985487\n",
      "Iteration: 2834/10000, Loss: 0.01796700991690159\n",
      "Iteration: 2835/10000, Loss: 0.02097649872303009\n",
      "Iteration: 2836/10000, Loss: 0.020129285752773285\n",
      "Iteration: 2837/10000, Loss: 0.020525479689240456\n",
      "Iteration: 2838/10000, Loss: 0.01810229755938053\n",
      "Iteration: 2839/10000, Loss: 0.027447417378425598\n",
      "Iteration: 2840/10000, Loss: 0.0185659509152174\n",
      "Iteration: 2841/10000, Loss: 0.02673190087080002\n",
      "Iteration: 2842/10000, Loss: 0.006660378072410822\n",
      "Iteration: 2843/10000, Loss: 0.029097838327288628\n",
      "Iteration: 2844/10000, Loss: 0.01688477024435997\n",
      "Iteration: 2845/10000, Loss: 0.03053697757422924\n",
      "Iteration: 2846/10000, Loss: 0.028544997796416283\n",
      "Iteration: 2847/10000, Loss: 0.01586226560175419\n",
      "Iteration: 2848/10000, Loss: 0.02193538099527359\n",
      "Iteration: 2849/10000, Loss: 0.02864838019013405\n",
      "Iteration: 2850/10000, Loss: 0.02525247633457184\n",
      "Iteration: 2851/10000, Loss: 0.02036302722990513\n",
      "Iteration: 2852/10000, Loss: 0.022331835702061653\n",
      "Iteration: 2853/10000, Loss: 0.016191264614462852\n",
      "Iteration: 2854/10000, Loss: 0.01728571392595768\n",
      "Iteration: 2855/10000, Loss: 0.022682778537273407\n",
      "Iteration: 2856/10000, Loss: 0.025979086756706238\n",
      "Iteration: 2857/10000, Loss: 0.020985368639230728\n",
      "Iteration: 2858/10000, Loss: 0.023363158106803894\n",
      "Iteration: 2859/10000, Loss: 0.025082619860768318\n",
      "Iteration: 2860/10000, Loss: 0.01833825185894966\n",
      "Iteration: 2861/10000, Loss: 0.016313202679157257\n",
      "Iteration: 2862/10000, Loss: 0.01581493765115738\n",
      "Iteration: 2863/10000, Loss: 0.018487459048628807\n",
      "Iteration: 2864/10000, Loss: 0.0279769878834486\n",
      "Iteration: 2865/10000, Loss: 0.02326699160039425\n",
      "Iteration: 2866/10000, Loss: 0.022100238129496574\n",
      "Iteration: 2867/10000, Loss: 0.02008628472685814\n",
      "Iteration: 2868/10000, Loss: 0.02685863897204399\n",
      "Iteration: 2869/10000, Loss: 0.020845165476202965\n",
      "Iteration: 2870/10000, Loss: 0.01723138615489006\n",
      "Iteration: 2871/10000, Loss: 0.015880396589636803\n",
      "Iteration: 2872/10000, Loss: 0.0270537156611681\n",
      "Iteration: 2873/10000, Loss: 0.017407750710844994\n",
      "Iteration: 2874/10000, Loss: 0.024170735850930214\n",
      "Iteration: 2875/10000, Loss: 0.020237628370523453\n",
      "Iteration: 2876/10000, Loss: 0.022614575922489166\n",
      "Iteration: 2877/10000, Loss: 0.024541303515434265\n",
      "Iteration: 2878/10000, Loss: 0.019459987059235573\n",
      "Iteration: 2879/10000, Loss: 0.0209210105240345\n",
      "Iteration: 2880/10000, Loss: 0.022208338603377342\n",
      "Iteration: 2881/10000, Loss: 0.015457484871149063\n",
      "Iteration: 2882/10000, Loss: 0.019353311508893967\n",
      "Iteration: 2883/10000, Loss: 0.009606652893126011\n",
      "Iteration: 2884/10000, Loss: 0.020192546769976616\n",
      "Iteration: 2885/10000, Loss: 0.01876915991306305\n",
      "Iteration: 2886/10000, Loss: 0.027953194454312325\n",
      "Iteration: 2887/10000, Loss: 0.02607238106429577\n",
      "Iteration: 2888/10000, Loss: 0.02050153911113739\n",
      "Iteration: 2889/10000, Loss: 0.01980038359761238\n",
      "Iteration: 2890/10000, Loss: 0.019335851073265076\n",
      "Iteration: 2891/10000, Loss: 0.022407900542020798\n",
      "Iteration: 2892/10000, Loss: 0.0174956526607275\n",
      "Iteration: 2893/10000, Loss: 0.021022966131567955\n",
      "Iteration: 2894/10000, Loss: 0.021047621965408325\n",
      "Iteration: 2895/10000, Loss: 0.017757082358002663\n",
      "Iteration: 2896/10000, Loss: 0.021716764196753502\n",
      "Iteration: 2897/10000, Loss: 0.032847702503204346\n",
      "Iteration: 2898/10000, Loss: 0.025286003947257996\n",
      "Iteration: 2899/10000, Loss: 0.02658873237669468\n",
      "Iteration: 2900/10000, Loss: 0.013409756124019623\n",
      "Average test loss:  0.0022\n",
      "Iteration: 2901/10000, Loss: 0.018147943541407585\n",
      "Iteration: 2902/10000, Loss: 0.024625511839985847\n",
      "Iteration: 2903/10000, Loss: 0.029048815369606018\n",
      "Iteration: 2904/10000, Loss: 0.016520678997039795\n",
      "Iteration: 2905/10000, Loss: 0.012580018490552902\n",
      "Iteration: 2906/10000, Loss: 0.018856894224882126\n",
      "Iteration: 2907/10000, Loss: 0.011031582951545715\n",
      "Iteration: 2908/10000, Loss: 0.01587444543838501\n",
      "Iteration: 2909/10000, Loss: 0.020273398607969284\n",
      "Iteration: 2910/10000, Loss: 0.0239145215600729\n",
      "Iteration: 2911/10000, Loss: 0.019068637862801552\n",
      "Iteration: 2912/10000, Loss: 0.01755252480506897\n",
      "Iteration: 2913/10000, Loss: 0.019150294363498688\n",
      "Iteration: 2914/10000, Loss: 0.020240694284439087\n",
      "Iteration: 2915/10000, Loss: 0.0188968013972044\n",
      "Iteration: 2916/10000, Loss: 0.02201635017991066\n",
      "Iteration: 2917/10000, Loss: 0.026485733687877655\n",
      "Iteration: 2918/10000, Loss: 0.02797432243824005\n",
      "Iteration: 2919/10000, Loss: 0.021625567227602005\n",
      "Iteration: 2920/10000, Loss: 0.022120246663689613\n",
      "Iteration: 2921/10000, Loss: 0.02487420104444027\n",
      "Iteration: 2922/10000, Loss: 0.021479863673448563\n",
      "Iteration: 2923/10000, Loss: 0.031182141974568367\n",
      "Iteration: 2924/10000, Loss: 0.02412225864827633\n",
      "Iteration: 2925/10000, Loss: 0.027465514838695526\n",
      "Iteration: 2926/10000, Loss: 0.025319211184978485\n",
      "Iteration: 2927/10000, Loss: 0.023428520187735558\n",
      "Iteration: 2928/10000, Loss: 0.019849911332130432\n",
      "Iteration: 2929/10000, Loss: 0.018748503178358078\n",
      "Iteration: 2930/10000, Loss: 0.02116706781089306\n",
      "Iteration: 2931/10000, Loss: 0.015312721021473408\n",
      "Iteration: 2932/10000, Loss: 0.014946794137358665\n",
      "Iteration: 2933/10000, Loss: 0.020366765558719635\n",
      "Iteration: 2934/10000, Loss: 0.018737131729722023\n",
      "Iteration: 2935/10000, Loss: 0.022860171273350716\n",
      "Iteration: 2936/10000, Loss: 0.023103268817067146\n",
      "Iteration: 2937/10000, Loss: 0.016799746081233025\n",
      "Iteration: 2938/10000, Loss: 0.02304363064467907\n",
      "Iteration: 2939/10000, Loss: 0.01788284443318844\n",
      "Iteration: 2940/10000, Loss: 0.01971198245882988\n",
      "Iteration: 2941/10000, Loss: 0.01745683327317238\n",
      "Iteration: 2942/10000, Loss: 0.016689358279109\n",
      "Iteration: 2943/10000, Loss: 0.018102603033185005\n",
      "Iteration: 2944/10000, Loss: 0.02452804334461689\n",
      "Iteration: 2945/10000, Loss: 0.022247472777962685\n",
      "Iteration: 2946/10000, Loss: 0.019327159970998764\n",
      "Iteration: 2947/10000, Loss: 0.023955920711159706\n",
      "Iteration: 2948/10000, Loss: 0.026455912739038467\n",
      "Iteration: 2949/10000, Loss: 0.03366312384605408\n",
      "Iteration: 2950/10000, Loss: 0.022854024544358253\n",
      "Iteration: 2951/10000, Loss: 0.02090301923453808\n",
      "Iteration: 2952/10000, Loss: 0.01814965531229973\n",
      "Iteration: 2953/10000, Loss: 0.017458012327551842\n",
      "Iteration: 2954/10000, Loss: 0.018140656873583794\n",
      "Iteration: 2955/10000, Loss: 0.0217081680893898\n",
      "Iteration: 2956/10000, Loss: 0.030068475753068924\n",
      "Iteration: 2957/10000, Loss: 0.02064717374742031\n",
      "Iteration: 2958/10000, Loss: 0.025553205981850624\n",
      "Iteration: 2959/10000, Loss: 0.021857816725969315\n",
      "Iteration: 2960/10000, Loss: 0.01527048647403717\n",
      "Iteration: 2961/10000, Loss: 0.022003525868058205\n",
      "Iteration: 2962/10000, Loss: 0.028816821053624153\n",
      "Iteration: 2963/10000, Loss: 0.015562531538307667\n",
      "Iteration: 2964/10000, Loss: 0.017063913866877556\n",
      "Iteration: 2965/10000, Loss: 0.023532960563898087\n",
      "Iteration: 2966/10000, Loss: 0.01601499132812023\n",
      "Iteration: 2967/10000, Loss: 0.01732901856303215\n",
      "Iteration: 2968/10000, Loss: 0.0162776131182909\n",
      "Iteration: 2969/10000, Loss: 0.015710528939962387\n",
      "Iteration: 2970/10000, Loss: 0.02300073206424713\n",
      "Iteration: 2971/10000, Loss: 0.01374038029462099\n",
      "Iteration: 2972/10000, Loss: 0.02002508006989956\n",
      "Iteration: 2973/10000, Loss: 0.02128194458782673\n",
      "Iteration: 2974/10000, Loss: 0.01876152493059635\n",
      "Iteration: 2975/10000, Loss: 0.02638850547373295\n",
      "Iteration: 2976/10000, Loss: 0.013816713355481625\n",
      "Iteration: 2977/10000, Loss: 0.018551431596279144\n",
      "Iteration: 2978/10000, Loss: 0.020442292094230652\n",
      "Iteration: 2979/10000, Loss: 0.021236060187220573\n",
      "Iteration: 2980/10000, Loss: 0.022446176037192345\n",
      "Iteration: 2981/10000, Loss: 0.025448214262723923\n",
      "Iteration: 2982/10000, Loss: 0.017367536202073097\n",
      "Iteration: 2983/10000, Loss: 0.021722005680203438\n",
      "Iteration: 2984/10000, Loss: 0.020151028409600258\n",
      "Iteration: 2985/10000, Loss: 0.02808639034628868\n",
      "Iteration: 2986/10000, Loss: 0.02551821805536747\n",
      "Iteration: 2987/10000, Loss: 0.01818004809319973\n",
      "Iteration: 2988/10000, Loss: 0.020291795954108238\n",
      "Iteration: 2989/10000, Loss: 0.024928156286478043\n",
      "Iteration: 2990/10000, Loss: 0.021412095054984093\n",
      "Iteration: 2991/10000, Loss: 0.023702265694737434\n",
      "Iteration: 2992/10000, Loss: 0.022132351994514465\n",
      "Iteration: 2993/10000, Loss: 0.01777653768658638\n",
      "Iteration: 2994/10000, Loss: 0.015994027256965637\n",
      "Iteration: 2995/10000, Loss: 0.025731507688760757\n",
      "Iteration: 2996/10000, Loss: 0.02212030068039894\n",
      "Iteration: 2997/10000, Loss: 0.013957194052636623\n",
      "Iteration: 2998/10000, Loss: 0.020588019862771034\n",
      "Iteration: 2999/10000, Loss: 0.018986890092492104\n",
      "Iteration: 3000/10000, Loss: 0.018478751182556152\n",
      "Average test loss:  0.0023\n",
      "Iteration: 3001/10000, Loss: 0.015047641471028328\n",
      "Iteration: 3002/10000, Loss: 0.02181796170771122\n",
      "Iteration: 3003/10000, Loss: 0.02147490903735161\n",
      "Iteration: 3004/10000, Loss: 0.016341783106327057\n",
      "Iteration: 3005/10000, Loss: 0.01931232586503029\n",
      "Iteration: 3006/10000, Loss: 0.022628042846918106\n",
      "Iteration: 3007/10000, Loss: 0.02287708967924118\n",
      "Iteration: 3008/10000, Loss: 0.016272328794002533\n",
      "Iteration: 3009/10000, Loss: 0.02442716434597969\n",
      "Iteration: 3010/10000, Loss: 0.016756463795900345\n",
      "Iteration: 3011/10000, Loss: 0.017123395577073097\n",
      "Iteration: 3012/10000, Loss: 0.026335692033171654\n",
      "Iteration: 3013/10000, Loss: 0.020075853914022446\n",
      "Iteration: 3014/10000, Loss: 0.02109132707118988\n",
      "Iteration: 3015/10000, Loss: 0.019526245072484016\n",
      "Iteration: 3016/10000, Loss: 0.022366836667060852\n",
      "Iteration: 3017/10000, Loss: 0.024013759568333626\n",
      "Iteration: 3018/10000, Loss: 0.018375122919678688\n",
      "Iteration: 3019/10000, Loss: 0.01135279517620802\n",
      "Iteration: 3020/10000, Loss: 0.013746829703450203\n",
      "Iteration: 3021/10000, Loss: 0.02078615315258503\n",
      "Iteration: 3022/10000, Loss: 0.02043849043548107\n",
      "Iteration: 3023/10000, Loss: 0.0229234267026186\n",
      "Iteration: 3024/10000, Loss: 0.016045982018113136\n",
      "Iteration: 3025/10000, Loss: 0.021742437034845352\n",
      "Iteration: 3026/10000, Loss: 0.020910387858748436\n",
      "Iteration: 3027/10000, Loss: 0.017725832760334015\n",
      "Iteration: 3028/10000, Loss: 0.015839708968997\n",
      "Iteration: 3029/10000, Loss: 0.018858112394809723\n",
      "Iteration: 3030/10000, Loss: 0.024785637855529785\n",
      "Iteration: 3031/10000, Loss: 0.020574821159243584\n",
      "Iteration: 3032/10000, Loss: 0.012368063442409039\n",
      "Iteration: 3033/10000, Loss: 0.019096141681075096\n",
      "Iteration: 3034/10000, Loss: 0.024115096777677536\n",
      "Iteration: 3035/10000, Loss: 0.025981416925787926\n",
      "Iteration: 3036/10000, Loss: 0.019449466839432716\n",
      "Iteration: 3037/10000, Loss: 0.024350091814994812\n",
      "Iteration: 3038/10000, Loss: 0.025689803063869476\n",
      "Iteration: 3039/10000, Loss: 0.015478935092687607\n",
      "Iteration: 3040/10000, Loss: 0.014607306569814682\n",
      "Iteration: 3041/10000, Loss: 0.022655466571450233\n",
      "Iteration: 3042/10000, Loss: 0.022262945771217346\n",
      "Iteration: 3043/10000, Loss: 0.017490467056632042\n",
      "Iteration: 3044/10000, Loss: 0.02294100448489189\n",
      "Iteration: 3045/10000, Loss: 0.022541766986250877\n",
      "Iteration: 3046/10000, Loss: 0.02519901841878891\n",
      "Iteration: 3047/10000, Loss: 0.018665652722120285\n",
      "Iteration: 3048/10000, Loss: 0.019224122166633606\n",
      "Iteration: 3049/10000, Loss: 0.024460073560476303\n",
      "Iteration: 3050/10000, Loss: 0.024033263325691223\n",
      "Iteration: 3051/10000, Loss: 0.011576315388083458\n",
      "Iteration: 3052/10000, Loss: 0.023745538666844368\n",
      "Iteration: 3053/10000, Loss: 0.029288578778505325\n",
      "Iteration: 3054/10000, Loss: 0.02155713364481926\n",
      "Iteration: 3055/10000, Loss: 0.01759825460612774\n",
      "Iteration: 3056/10000, Loss: 0.01680881343781948\n",
      "Iteration: 3057/10000, Loss: 0.025558676570653915\n",
      "Iteration: 3058/10000, Loss: 0.020141396671533585\n",
      "Iteration: 3059/10000, Loss: 0.022239824756979942\n",
      "Iteration: 3060/10000, Loss: 0.035280466079711914\n",
      "Iteration: 3061/10000, Loss: 0.014871973544359207\n",
      "Iteration: 3062/10000, Loss: 0.01891784369945526\n",
      "Iteration: 3063/10000, Loss: 0.023217597976326942\n",
      "Iteration: 3064/10000, Loss: 0.01067811157554388\n",
      "Iteration: 3065/10000, Loss: 0.015580529347062111\n",
      "Iteration: 3066/10000, Loss: 0.02006392739713192\n",
      "Iteration: 3067/10000, Loss: 0.022412139922380447\n",
      "Iteration: 3068/10000, Loss: 0.016642339527606964\n",
      "Iteration: 3069/10000, Loss: 0.02798263356089592\n",
      "Iteration: 3070/10000, Loss: 0.027410928159952164\n",
      "Iteration: 3071/10000, Loss: 0.013887669891119003\n",
      "Iteration: 3072/10000, Loss: 0.017892492935061455\n",
      "Iteration: 3073/10000, Loss: 0.018215728923678398\n",
      "Iteration: 3074/10000, Loss: 0.024079183116555214\n",
      "Iteration: 3075/10000, Loss: 0.020887792110443115\n",
      "Iteration: 3076/10000, Loss: 0.015204029157757759\n",
      "Iteration: 3077/10000, Loss: 0.024221526458859444\n",
      "Iteration: 3078/10000, Loss: 0.015855098143219948\n",
      "Iteration: 3079/10000, Loss: 0.024904483929276466\n",
      "Iteration: 3080/10000, Loss: 0.03609646111726761\n",
      "Iteration: 3081/10000, Loss: 0.024711165577173233\n",
      "Iteration: 3082/10000, Loss: 0.02716364525258541\n",
      "Iteration: 3083/10000, Loss: 0.012533005326986313\n",
      "Iteration: 3084/10000, Loss: 0.020520182326436043\n",
      "Iteration: 3085/10000, Loss: 0.011284621432423592\n",
      "Iteration: 3086/10000, Loss: 0.017189068719744682\n",
      "Iteration: 3087/10000, Loss: 0.015306168235838413\n",
      "Iteration: 3088/10000, Loss: 0.015351947396993637\n",
      "Iteration: 3089/10000, Loss: 0.014729498885571957\n",
      "Iteration: 3090/10000, Loss: 0.01927819848060608\n",
      "Iteration: 3091/10000, Loss: 0.02700837515294552\n",
      "Iteration: 3092/10000, Loss: 0.025779802352190018\n",
      "Iteration: 3093/10000, Loss: 0.02663915604352951\n",
      "Iteration: 3094/10000, Loss: 0.026449190452694893\n",
      "Iteration: 3095/10000, Loss: 0.019499681890010834\n",
      "Iteration: 3096/10000, Loss: 0.01946423202753067\n",
      "Iteration: 3097/10000, Loss: 0.021807903423905373\n",
      "Iteration: 3098/10000, Loss: 0.018804393708705902\n",
      "Iteration: 3099/10000, Loss: 0.017114918678998947\n",
      "Iteration: 3100/10000, Loss: 0.024907205253839493\n",
      "Average test loss:  0.0016\n",
      "Iteration: 3101/10000, Loss: 0.01181222777813673\n",
      "Iteration: 3102/10000, Loss: 0.014640574343502522\n",
      "Iteration: 3103/10000, Loss: 0.010605055838823318\n",
      "Iteration: 3104/10000, Loss: 0.025452367961406708\n",
      "Iteration: 3105/10000, Loss: 0.020913736894726753\n",
      "Iteration: 3106/10000, Loss: 0.02382316254079342\n",
      "Iteration: 3107/10000, Loss: 0.020081795752048492\n",
      "Iteration: 3108/10000, Loss: 0.02353178709745407\n",
      "Iteration: 3109/10000, Loss: 0.018695631995797157\n",
      "Iteration: 3110/10000, Loss: 0.014049309305846691\n",
      "Iteration: 3111/10000, Loss: 0.026346959173679352\n",
      "Iteration: 3112/10000, Loss: 0.02486337162554264\n",
      "Iteration: 3113/10000, Loss: 0.02234942466020584\n",
      "Iteration: 3114/10000, Loss: 0.02619515359401703\n",
      "Iteration: 3115/10000, Loss: 0.017090480774641037\n",
      "Iteration: 3116/10000, Loss: 0.019268354400992393\n",
      "Iteration: 3117/10000, Loss: 0.015561798587441444\n",
      "Iteration: 3118/10000, Loss: 0.01791994273662567\n",
      "Iteration: 3119/10000, Loss: 0.012857080437242985\n",
      "Iteration: 3120/10000, Loss: 0.010770474560558796\n",
      "Iteration: 3121/10000, Loss: 0.018044358119368553\n",
      "Iteration: 3122/10000, Loss: 0.019290532916784286\n",
      "Iteration: 3123/10000, Loss: 0.012826611287891865\n",
      "Iteration: 3124/10000, Loss: 0.015211351215839386\n",
      "Iteration: 3125/10000, Loss: 0.0235068891197443\n",
      "Iteration: 3126/10000, Loss: 0.013833214528858662\n",
      "Iteration: 3127/10000, Loss: 0.019516605883836746\n",
      "Iteration: 3128/10000, Loss: 0.028123684227466583\n",
      "Iteration: 3129/10000, Loss: 0.013986186124384403\n",
      "Iteration: 3130/10000, Loss: 0.015014264732599258\n",
      "Iteration: 3131/10000, Loss: 0.018285555765032768\n",
      "Iteration: 3132/10000, Loss: 0.03444294258952141\n",
      "Iteration: 3133/10000, Loss: 0.015169482678174973\n",
      "Iteration: 3134/10000, Loss: 0.02650812640786171\n",
      "Iteration: 3135/10000, Loss: 0.011533267796039581\n",
      "Iteration: 3136/10000, Loss: 0.01450170949101448\n",
      "Iteration: 3137/10000, Loss: 0.018884919583797455\n",
      "Iteration: 3138/10000, Loss: 0.019548337906599045\n",
      "Iteration: 3139/10000, Loss: 0.022989515215158463\n",
      "Iteration: 3140/10000, Loss: 0.02079707942903042\n",
      "Iteration: 3141/10000, Loss: 0.015985554084181786\n",
      "Iteration: 3142/10000, Loss: 0.01797633059322834\n",
      "Iteration: 3143/10000, Loss: 0.028731567785143852\n",
      "Iteration: 3144/10000, Loss: 0.01897386461496353\n",
      "Iteration: 3145/10000, Loss: 0.018648605793714523\n",
      "Iteration: 3146/10000, Loss: 0.030150672420859337\n",
      "Iteration: 3147/10000, Loss: 0.01483916211873293\n",
      "Iteration: 3148/10000, Loss: 0.024914707988500595\n",
      "Iteration: 3149/10000, Loss: 0.02090969868004322\n",
      "Iteration: 3150/10000, Loss: 0.016464048996567726\n",
      "Iteration: 3151/10000, Loss: 0.02729181945323944\n",
      "Iteration: 3152/10000, Loss: 0.015153740532696247\n",
      "Iteration: 3153/10000, Loss: 0.015950074419379234\n",
      "Iteration: 3154/10000, Loss: 0.028569066897034645\n",
      "Iteration: 3155/10000, Loss: 0.01814863830804825\n",
      "Iteration: 3156/10000, Loss: 0.019292613491415977\n",
      "Iteration: 3157/10000, Loss: 0.017324570566415787\n",
      "Iteration: 3158/10000, Loss: 0.016885194927453995\n",
      "Iteration: 3159/10000, Loss: 0.017734244465827942\n",
      "Iteration: 3160/10000, Loss: 0.023602550849318504\n",
      "Iteration: 3161/10000, Loss: 0.01959157921373844\n",
      "Iteration: 3162/10000, Loss: 0.020641285926103592\n",
      "Iteration: 3163/10000, Loss: 0.012131880037486553\n",
      "Iteration: 3164/10000, Loss: 0.016073305159807205\n",
      "Iteration: 3165/10000, Loss: 0.014458862133324146\n",
      "Iteration: 3166/10000, Loss: 0.017553899437189102\n",
      "Iteration: 3167/10000, Loss: 0.012466379441320896\n",
      "Iteration: 3168/10000, Loss: 0.015907365828752518\n",
      "Iteration: 3169/10000, Loss: 0.014147992245852947\n",
      "Iteration: 3170/10000, Loss: 0.023389479145407677\n",
      "Iteration: 3171/10000, Loss: 0.01767982356250286\n",
      "Iteration: 3172/10000, Loss: 0.01899539679288864\n",
      "Iteration: 3173/10000, Loss: 0.02708081714808941\n",
      "Iteration: 3174/10000, Loss: 0.01879652589559555\n",
      "Iteration: 3175/10000, Loss: 0.0166059248149395\n",
      "Iteration: 3176/10000, Loss: 0.023215029388666153\n",
      "Iteration: 3177/10000, Loss: 0.022526884451508522\n",
      "Iteration: 3178/10000, Loss: 0.015138072893023491\n",
      "Iteration: 3179/10000, Loss: 0.020857451483607292\n",
      "Iteration: 3180/10000, Loss: 0.018022798001766205\n",
      "Iteration: 3181/10000, Loss: 0.017105689272284508\n",
      "Iteration: 3182/10000, Loss: 0.022987933829426765\n",
      "Iteration: 3183/10000, Loss: 0.017489630728960037\n",
      "Iteration: 3184/10000, Loss: 0.020421793684363365\n",
      "Iteration: 3185/10000, Loss: 0.023453574627637863\n",
      "Iteration: 3186/10000, Loss: 0.020901083946228027\n",
      "Iteration: 3187/10000, Loss: 0.02322763204574585\n",
      "Iteration: 3188/10000, Loss: 0.0168105810880661\n",
      "Iteration: 3189/10000, Loss: 0.019825104624032974\n",
      "Iteration: 3190/10000, Loss: 0.02733915112912655\n",
      "Iteration: 3191/10000, Loss: 0.014878281392157078\n",
      "Iteration: 3192/10000, Loss: 0.025584906339645386\n",
      "Iteration: 3193/10000, Loss: 0.018067941069602966\n",
      "Iteration: 3194/10000, Loss: 0.022378094494342804\n",
      "Iteration: 3195/10000, Loss: 0.01667061634361744\n",
      "Iteration: 3196/10000, Loss: 0.00978958047926426\n",
      "Iteration: 3197/10000, Loss: 0.02130058966577053\n",
      "Iteration: 3198/10000, Loss: 0.017984140664339066\n",
      "Iteration: 3199/10000, Loss: 0.028277350589632988\n",
      "Iteration: 3200/10000, Loss: 0.02238159254193306\n",
      "Average test loss:  0.0021\n",
      "Iteration: 3201/10000, Loss: 0.023939352482557297\n",
      "Iteration: 3202/10000, Loss: 0.02644316293299198\n",
      "Iteration: 3203/10000, Loss: 0.018174417316913605\n",
      "Iteration: 3204/10000, Loss: 0.016534488648176193\n",
      "Iteration: 3205/10000, Loss: 0.02661646157503128\n",
      "Iteration: 3206/10000, Loss: 0.014609569683670998\n",
      "Iteration: 3207/10000, Loss: 0.01080322451889515\n",
      "Iteration: 3208/10000, Loss: 0.024531489238142967\n",
      "Iteration: 3209/10000, Loss: 0.015103952959179878\n",
      "Iteration: 3210/10000, Loss: 0.015804238617420197\n",
      "Iteration: 3211/10000, Loss: 0.02662748098373413\n",
      "Iteration: 3212/10000, Loss: 0.018283594399690628\n",
      "Iteration: 3213/10000, Loss: 0.018482880666851997\n",
      "Iteration: 3214/10000, Loss: 0.015510041266679764\n",
      "Iteration: 3215/10000, Loss: 0.02221781760454178\n",
      "Iteration: 3216/10000, Loss: 0.026900136843323708\n",
      "Iteration: 3217/10000, Loss: 0.010394581593573093\n",
      "Iteration: 3218/10000, Loss: 0.017037680372595787\n",
      "Iteration: 3219/10000, Loss: 0.022375553846359253\n",
      "Iteration: 3220/10000, Loss: 0.03015199489891529\n",
      "Iteration: 3221/10000, Loss: 0.017352312803268433\n",
      "Iteration: 3222/10000, Loss: 0.016406219452619553\n",
      "Iteration: 3223/10000, Loss: 0.014743010513484478\n",
      "Iteration: 3224/10000, Loss: 0.024586666375398636\n",
      "Iteration: 3225/10000, Loss: 0.017706623300909996\n",
      "Iteration: 3226/10000, Loss: 0.011139608919620514\n",
      "Iteration: 3227/10000, Loss: 0.01487591490149498\n",
      "Iteration: 3228/10000, Loss: 0.018153153359889984\n",
      "Iteration: 3229/10000, Loss: 0.016643349081277847\n",
      "Iteration: 3230/10000, Loss: 0.016017835587263107\n",
      "Iteration: 3231/10000, Loss: 0.015319841913878918\n",
      "Iteration: 3232/10000, Loss: 0.01732918620109558\n",
      "Iteration: 3233/10000, Loss: 0.019298385828733444\n",
      "Iteration: 3234/10000, Loss: 0.019006384536623955\n",
      "Iteration: 3235/10000, Loss: 0.01338256523013115\n",
      "Iteration: 3236/10000, Loss: 0.013655571267008781\n",
      "Iteration: 3237/10000, Loss: 0.020497256889939308\n",
      "Iteration: 3238/10000, Loss: 0.01912505552172661\n",
      "Iteration: 3239/10000, Loss: 0.020063119009137154\n",
      "Iteration: 3240/10000, Loss: 0.018078766763210297\n",
      "Iteration: 3241/10000, Loss: 0.029165679588913918\n",
      "Iteration: 3242/10000, Loss: 0.025800207629799843\n",
      "Iteration: 3243/10000, Loss: 0.024603024125099182\n",
      "Iteration: 3244/10000, Loss: 0.014215998351573944\n",
      "Iteration: 3245/10000, Loss: 0.01995031163096428\n",
      "Iteration: 3246/10000, Loss: 0.015415524132549763\n",
      "Iteration: 3247/10000, Loss: 0.02157769910991192\n",
      "Iteration: 3248/10000, Loss: 0.015935754403471947\n",
      "Iteration: 3249/10000, Loss: 0.020288024097681046\n",
      "Iteration: 3250/10000, Loss: 0.017409948632121086\n",
      "Iteration: 3251/10000, Loss: 0.024731438606977463\n",
      "Iteration: 3252/10000, Loss: 0.030795400962233543\n",
      "Iteration: 3253/10000, Loss: 0.02098463661968708\n",
      "Iteration: 3254/10000, Loss: 0.02013786882162094\n",
      "Iteration: 3255/10000, Loss: 0.019101884216070175\n",
      "Iteration: 3256/10000, Loss: 0.01988791488111019\n",
      "Iteration: 3257/10000, Loss: 0.018863728269934654\n",
      "Iteration: 3258/10000, Loss: 0.013193942606449127\n",
      "Iteration: 3259/10000, Loss: 0.01744730770587921\n",
      "Iteration: 3260/10000, Loss: 0.01913386583328247\n",
      "Iteration: 3261/10000, Loss: 0.024095917120575905\n",
      "Iteration: 3262/10000, Loss: 0.01966247521340847\n",
      "Iteration: 3263/10000, Loss: 0.017903553321957588\n",
      "Iteration: 3264/10000, Loss: 0.01996275782585144\n",
      "Iteration: 3265/10000, Loss: 0.01573173701763153\n",
      "Iteration: 3266/10000, Loss: 0.020727867260575294\n",
      "Iteration: 3267/10000, Loss: 0.018503518775105476\n",
      "Iteration: 3268/10000, Loss: 0.025525227189064026\n",
      "Iteration: 3269/10000, Loss: 0.019619835540652275\n",
      "Iteration: 3270/10000, Loss: 0.02704397216439247\n",
      "Iteration: 3271/10000, Loss: 0.018986236304044724\n",
      "Iteration: 3272/10000, Loss: 0.017799414694309235\n",
      "Iteration: 3273/10000, Loss: 0.021337611600756645\n",
      "Iteration: 3274/10000, Loss: 0.014375911094248295\n",
      "Iteration: 3275/10000, Loss: 0.023128744214773178\n",
      "Iteration: 3276/10000, Loss: 0.016029691323637962\n",
      "Iteration: 3277/10000, Loss: 0.016680819913744926\n",
      "Iteration: 3278/10000, Loss: 0.017352575436234474\n",
      "Iteration: 3279/10000, Loss: 0.015759382396936417\n",
      "Iteration: 3280/10000, Loss: 0.01671578735113144\n",
      "Iteration: 3281/10000, Loss: 0.019719017669558525\n",
      "Iteration: 3282/10000, Loss: 0.018309211358428\n",
      "Iteration: 3283/10000, Loss: 0.020574675872921944\n",
      "Iteration: 3284/10000, Loss: 0.026028791442513466\n",
      "Iteration: 3285/10000, Loss: 0.024977780878543854\n",
      "Iteration: 3286/10000, Loss: 0.012956341728568077\n",
      "Iteration: 3287/10000, Loss: 0.01434981171041727\n",
      "Iteration: 3288/10000, Loss: 0.028317349031567574\n",
      "Iteration: 3289/10000, Loss: 0.016860563308000565\n",
      "Iteration: 3290/10000, Loss: 0.019215766340494156\n",
      "Iteration: 3291/10000, Loss: 0.02148795872926712\n",
      "Iteration: 3292/10000, Loss: 0.020783886313438416\n",
      "Iteration: 3293/10000, Loss: 0.01500975526869297\n",
      "Iteration: 3294/10000, Loss: 0.014737477526068687\n",
      "Iteration: 3295/10000, Loss: 0.014964993111789227\n",
      "Iteration: 3296/10000, Loss: 0.015036074444651604\n",
      "Iteration: 3297/10000, Loss: 0.013766949996352196\n",
      "Iteration: 3298/10000, Loss: 0.021937696263194084\n",
      "Iteration: 3299/10000, Loss: 0.02298513986170292\n",
      "Iteration: 3300/10000, Loss: 0.016777563840150833\n",
      "Average test loss:  0.0022\n",
      "Iteration: 3301/10000, Loss: 0.011883191764354706\n",
      "Iteration: 3302/10000, Loss: 0.022293243557214737\n",
      "Iteration: 3303/10000, Loss: 0.019564300775527954\n",
      "Iteration: 3304/10000, Loss: 0.022937368601560593\n",
      "Iteration: 3305/10000, Loss: 0.01982591673731804\n",
      "Iteration: 3306/10000, Loss: 0.01808767020702362\n",
      "Iteration: 3307/10000, Loss: 0.017891325056552887\n",
      "Iteration: 3308/10000, Loss: 0.02040036953985691\n",
      "Iteration: 3309/10000, Loss: 0.015886632725596428\n",
      "Iteration: 3310/10000, Loss: 0.02055470086634159\n",
      "Iteration: 3311/10000, Loss: 0.0206263717263937\n",
      "Iteration: 3312/10000, Loss: 0.018657274544239044\n",
      "Iteration: 3313/10000, Loss: 0.015461985021829605\n",
      "Iteration: 3314/10000, Loss: 0.017867857590317726\n",
      "Iteration: 3315/10000, Loss: 0.013059273362159729\n",
      "Iteration: 3316/10000, Loss: 0.020505402237176895\n",
      "Iteration: 3317/10000, Loss: 0.018648000434041023\n",
      "Iteration: 3318/10000, Loss: 0.01622224599123001\n",
      "Iteration: 3319/10000, Loss: 0.019310181960463524\n",
      "Iteration: 3320/10000, Loss: 0.019745973870158195\n",
      "Iteration: 3321/10000, Loss: 0.0212490726262331\n",
      "Iteration: 3322/10000, Loss: 0.016901910305023193\n",
      "Iteration: 3323/10000, Loss: 0.017240598797798157\n",
      "Iteration: 3324/10000, Loss: 0.02482018992304802\n",
      "Iteration: 3325/10000, Loss: 0.018061311915516853\n",
      "Iteration: 3326/10000, Loss: 0.021201835945248604\n",
      "Iteration: 3327/10000, Loss: 0.02147398330271244\n",
      "Iteration: 3328/10000, Loss: 0.01118130050599575\n",
      "Iteration: 3329/10000, Loss: 0.023369360715150833\n",
      "Iteration: 3330/10000, Loss: 0.02915850654244423\n",
      "Iteration: 3331/10000, Loss: 0.023669520393013954\n",
      "Iteration: 3332/10000, Loss: 0.014043946750462055\n",
      "Iteration: 3333/10000, Loss: 0.029540229588747025\n",
      "Iteration: 3334/10000, Loss: 0.02004433609545231\n",
      "Iteration: 3335/10000, Loss: 0.018421001732349396\n",
      "Iteration: 3336/10000, Loss: 0.0264605600386858\n",
      "Iteration: 3337/10000, Loss: 0.022768596187233925\n",
      "Iteration: 3338/10000, Loss: 0.01381289679557085\n",
      "Iteration: 3339/10000, Loss: 0.01671074517071247\n",
      "Iteration: 3340/10000, Loss: 0.02577752247452736\n",
      "Iteration: 3341/10000, Loss: 0.01914096064865589\n",
      "Iteration: 3342/10000, Loss: 0.013091182336211205\n",
      "Iteration: 3343/10000, Loss: 0.018367165699601173\n",
      "Iteration: 3344/10000, Loss: 0.015936948359012604\n",
      "Iteration: 3345/10000, Loss: 0.020968955010175705\n",
      "Iteration: 3346/10000, Loss: 0.024616682901978493\n",
      "Iteration: 3347/10000, Loss: 0.011853371746838093\n",
      "Iteration: 3348/10000, Loss: 0.014841715805232525\n",
      "Iteration: 3349/10000, Loss: 0.01963168755173683\n",
      "Iteration: 3350/10000, Loss: 0.014869422651827335\n",
      "Iteration: 3351/10000, Loss: 0.014829844236373901\n",
      "Iteration: 3352/10000, Loss: 0.015198573470115662\n",
      "Iteration: 3353/10000, Loss: 0.020373497158288956\n",
      "Iteration: 3354/10000, Loss: 0.015082575380802155\n",
      "Iteration: 3355/10000, Loss: 0.021739816293120384\n",
      "Iteration: 3356/10000, Loss: 0.02740475721657276\n",
      "Iteration: 3357/10000, Loss: 0.013870824128389359\n",
      "Iteration: 3358/10000, Loss: 0.027144990861415863\n",
      "Iteration: 3359/10000, Loss: 0.022174900397658348\n",
      "Iteration: 3360/10000, Loss: 0.023295536637306213\n",
      "Iteration: 3361/10000, Loss: 0.014299138449132442\n",
      "Iteration: 3362/10000, Loss: 0.02341499552130699\n",
      "Iteration: 3363/10000, Loss: 0.015931224450469017\n",
      "Iteration: 3364/10000, Loss: 0.018851416185498238\n",
      "Iteration: 3365/10000, Loss: 0.016244323924183846\n",
      "Iteration: 3366/10000, Loss: 0.014117766171693802\n",
      "Iteration: 3367/10000, Loss: 0.012844550423324108\n",
      "Iteration: 3368/10000, Loss: 0.024579664692282677\n",
      "Iteration: 3369/10000, Loss: 0.032949965447187424\n",
      "Iteration: 3370/10000, Loss: 0.024266408756375313\n",
      "Iteration: 3371/10000, Loss: 0.016989735886454582\n",
      "Iteration: 3372/10000, Loss: 0.012744802050292492\n",
      "Iteration: 3373/10000, Loss: 0.016074931249022484\n",
      "Iteration: 3374/10000, Loss: 0.022257229313254356\n",
      "Iteration: 3375/10000, Loss: 0.02217313088476658\n",
      "Iteration: 3376/10000, Loss: 0.02167860046029091\n",
      "Iteration: 3377/10000, Loss: 0.013760491274297237\n",
      "Iteration: 3378/10000, Loss: 0.028403716161847115\n",
      "Iteration: 3379/10000, Loss: 0.026711534708738327\n",
      "Iteration: 3380/10000, Loss: 0.026289692148566246\n",
      "Iteration: 3381/10000, Loss: 0.014158240519464016\n",
      "Iteration: 3382/10000, Loss: 0.014188169501721859\n",
      "Iteration: 3383/10000, Loss: 0.01862293854355812\n",
      "Iteration: 3384/10000, Loss: 0.01848693937063217\n",
      "Iteration: 3385/10000, Loss: 0.023237871006131172\n",
      "Iteration: 3386/10000, Loss: 0.01683620549738407\n",
      "Iteration: 3387/10000, Loss: 0.016290217638015747\n",
      "Iteration: 3388/10000, Loss: 0.01728462055325508\n",
      "Iteration: 3389/10000, Loss: 0.01977585069835186\n",
      "Iteration: 3390/10000, Loss: 0.01734362170100212\n",
      "Iteration: 3391/10000, Loss: 0.024599215015769005\n",
      "Iteration: 3392/10000, Loss: 0.022060757502913475\n",
      "Iteration: 3393/10000, Loss: 0.021342355757951736\n",
      "Iteration: 3394/10000, Loss: 0.021794939413666725\n",
      "Iteration: 3395/10000, Loss: 0.02762307971715927\n",
      "Iteration: 3396/10000, Loss: 0.025402741506695747\n",
      "Iteration: 3397/10000, Loss: 0.018961723893880844\n",
      "Iteration: 3398/10000, Loss: 0.03175012022256851\n",
      "Iteration: 3399/10000, Loss: 0.01875024102628231\n",
      "Iteration: 3400/10000, Loss: 0.02677331678569317\n",
      "Average test loss:  0.0012\n",
      "Iteration: 3401/10000, Loss: 0.017378635704517365\n",
      "Iteration: 3402/10000, Loss: 0.018471958115696907\n",
      "Iteration: 3403/10000, Loss: 0.015186660923063755\n",
      "Iteration: 3404/10000, Loss: 0.02285202592611313\n",
      "Iteration: 3405/10000, Loss: 0.028936130926012993\n",
      "Iteration: 3406/10000, Loss: 0.01602889411151409\n",
      "Iteration: 3407/10000, Loss: 0.015446427278220654\n",
      "Iteration: 3408/10000, Loss: 0.019829247146844864\n",
      "Iteration: 3409/10000, Loss: 0.010594005696475506\n",
      "Iteration: 3410/10000, Loss: 0.019097240641713142\n",
      "Iteration: 3411/10000, Loss: 0.023509731516242027\n",
      "Iteration: 3412/10000, Loss: 0.023345082998275757\n",
      "Iteration: 3413/10000, Loss: 0.020118294283747673\n",
      "Iteration: 3414/10000, Loss: 0.013922309502959251\n",
      "Iteration: 3415/10000, Loss: 0.02423747256398201\n",
      "Iteration: 3416/10000, Loss: 0.02072763629257679\n",
      "Iteration: 3417/10000, Loss: 0.015322952531278133\n",
      "Iteration: 3418/10000, Loss: 0.015270095318555832\n",
      "Iteration: 3419/10000, Loss: 0.011203414760529995\n",
      "Iteration: 3420/10000, Loss: 0.010768983513116837\n",
      "Iteration: 3421/10000, Loss: 0.018603866919875145\n",
      "Iteration: 3422/10000, Loss: 0.01635776273906231\n",
      "Iteration: 3423/10000, Loss: 0.01656786911189556\n",
      "Iteration: 3424/10000, Loss: 0.027674240991473198\n",
      "Iteration: 3425/10000, Loss: 0.023783069103956223\n",
      "Iteration: 3426/10000, Loss: 0.014612222090363503\n",
      "Iteration: 3427/10000, Loss: 0.017504537478089333\n",
      "Iteration: 3428/10000, Loss: 0.019814204424619675\n",
      "Iteration: 3429/10000, Loss: 0.017521873116493225\n",
      "Iteration: 3430/10000, Loss: 0.016847621649503708\n",
      "Iteration: 3431/10000, Loss: 0.018702110275626183\n",
      "Iteration: 3432/10000, Loss: 0.018928831443190575\n",
      "Iteration: 3433/10000, Loss: 0.013195501640439034\n",
      "Iteration: 3434/10000, Loss: 0.02143249474465847\n",
      "Iteration: 3435/10000, Loss: 0.030265608802437782\n",
      "Iteration: 3436/10000, Loss: 0.010635007172822952\n",
      "Iteration: 3437/10000, Loss: 0.01852739416062832\n",
      "Iteration: 3438/10000, Loss: 0.015728214755654335\n",
      "Iteration: 3439/10000, Loss: 0.01796584017574787\n",
      "Iteration: 3440/10000, Loss: 0.023193279281258583\n",
      "Iteration: 3441/10000, Loss: 0.020962975919246674\n",
      "Iteration: 3442/10000, Loss: 0.013539197854697704\n",
      "Iteration: 3443/10000, Loss: 0.01515395287424326\n",
      "Iteration: 3444/10000, Loss: 0.014260212890803814\n",
      "Iteration: 3445/10000, Loss: 0.009480469860136509\n",
      "Iteration: 3446/10000, Loss: 0.01909363642334938\n",
      "Iteration: 3447/10000, Loss: 0.02282567135989666\n",
      "Iteration: 3448/10000, Loss: 0.020414084196090698\n",
      "Iteration: 3449/10000, Loss: 0.011157017201185226\n",
      "Iteration: 3450/10000, Loss: 0.013625466264784336\n",
      "Iteration: 3451/10000, Loss: 0.020387429744005203\n",
      "Iteration: 3452/10000, Loss: 0.016539644449949265\n",
      "Iteration: 3453/10000, Loss: 0.016070974990725517\n",
      "Iteration: 3454/10000, Loss: 0.017044564709067345\n",
      "Iteration: 3455/10000, Loss: 0.021780962124466896\n",
      "Iteration: 3456/10000, Loss: 0.022080043330788612\n",
      "Iteration: 3457/10000, Loss: 0.01896556094288826\n",
      "Iteration: 3458/10000, Loss: 0.022558705881237984\n",
      "Iteration: 3459/10000, Loss: 0.014021867886185646\n",
      "Iteration: 3460/10000, Loss: 0.018102195113897324\n",
      "Iteration: 3461/10000, Loss: 0.02060917392373085\n",
      "Iteration: 3462/10000, Loss: 0.025260042399168015\n",
      "Iteration: 3463/10000, Loss: 0.02316819317638874\n",
      "Iteration: 3464/10000, Loss: 0.0177770983427763\n",
      "Iteration: 3465/10000, Loss: 0.013118506409227848\n",
      "Iteration: 3466/10000, Loss: 0.01958237588405609\n",
      "Iteration: 3467/10000, Loss: 0.02162260003387928\n",
      "Iteration: 3468/10000, Loss: 0.016991540789604187\n",
      "Iteration: 3469/10000, Loss: 0.018730558454990387\n",
      "Iteration: 3470/10000, Loss: 0.01854655146598816\n",
      "Iteration: 3471/10000, Loss: 0.021549511700868607\n",
      "Iteration: 3472/10000, Loss: 0.013246310874819756\n",
      "Iteration: 3473/10000, Loss: 0.01531240064650774\n",
      "Iteration: 3474/10000, Loss: 0.02486076019704342\n",
      "Iteration: 3475/10000, Loss: 0.017569469287991524\n",
      "Iteration: 3476/10000, Loss: 0.014680486172437668\n",
      "Iteration: 3477/10000, Loss: 0.019965555518865585\n",
      "Iteration: 3478/10000, Loss: 0.017615020275115967\n",
      "Iteration: 3479/10000, Loss: 0.0162474624812603\n",
      "Iteration: 3480/10000, Loss: 0.020350255072116852\n",
      "Iteration: 3481/10000, Loss: 0.01578117348253727\n",
      "Iteration: 3482/10000, Loss: 0.01377059519290924\n",
      "Iteration: 3483/10000, Loss: 0.014408291317522526\n",
      "Iteration: 3484/10000, Loss: 0.015648113563656807\n",
      "Iteration: 3485/10000, Loss: 0.01736035943031311\n",
      "Iteration: 3486/10000, Loss: 0.02050919644534588\n",
      "Iteration: 3487/10000, Loss: 0.02256389893591404\n",
      "Iteration: 3488/10000, Loss: 0.01841629110276699\n",
      "Iteration: 3489/10000, Loss: 0.022537337616086006\n",
      "Iteration: 3490/10000, Loss: 0.014843934215605259\n",
      "Iteration: 3491/10000, Loss: 0.025313515216112137\n",
      "Iteration: 3492/10000, Loss: 0.025171559303998947\n",
      "Iteration: 3493/10000, Loss: 0.0154255460947752\n",
      "Iteration: 3494/10000, Loss: 0.017593810334801674\n",
      "Iteration: 3495/10000, Loss: 0.018815744668245316\n",
      "Iteration: 3496/10000, Loss: 0.020543711259961128\n",
      "Iteration: 3497/10000, Loss: 0.016825765371322632\n",
      "Iteration: 3498/10000, Loss: 0.01838865503668785\n",
      "Iteration: 3499/10000, Loss: 0.012204977683722973\n",
      "Iteration: 3500/10000, Loss: 0.018075956031680107\n",
      "Average test loss:  0.0023\n",
      "Iteration: 3501/10000, Loss: 0.013388271443545818\n",
      "Iteration: 3502/10000, Loss: 0.01656700298190117\n",
      "Iteration: 3503/10000, Loss: 0.014779122546315193\n",
      "Iteration: 3504/10000, Loss: 0.020874209702014923\n",
      "Iteration: 3505/10000, Loss: 0.013183278031647205\n",
      "Iteration: 3506/10000, Loss: 0.01653226837515831\n",
      "Iteration: 3507/10000, Loss: 0.011791549623012543\n",
      "Iteration: 3508/10000, Loss: 0.012063197791576385\n",
      "Iteration: 3509/10000, Loss: 0.02407967671751976\n",
      "Iteration: 3510/10000, Loss: 0.015056739561259747\n",
      "Iteration: 3511/10000, Loss: 0.01439337246119976\n",
      "Iteration: 3512/10000, Loss: 0.012852514162659645\n",
      "Iteration: 3513/10000, Loss: 0.013135958462953568\n",
      "Iteration: 3514/10000, Loss: 0.017612269148230553\n",
      "Iteration: 3515/10000, Loss: 0.023163819685578346\n",
      "Iteration: 3516/10000, Loss: 0.014310680329799652\n",
      "Iteration: 3517/10000, Loss: 0.011480557732284069\n",
      "Iteration: 3518/10000, Loss: 0.017286550253629684\n",
      "Iteration: 3519/10000, Loss: 0.013441057875752449\n",
      "Iteration: 3520/10000, Loss: 0.009505631402134895\n",
      "Iteration: 3521/10000, Loss: 0.023224962875247\n",
      "Iteration: 3522/10000, Loss: 0.019290663301944733\n",
      "Iteration: 3523/10000, Loss: 0.01151615846902132\n",
      "Iteration: 3524/10000, Loss: 0.03212856128811836\n",
      "Iteration: 3525/10000, Loss: 0.014206510968506336\n",
      "Iteration: 3526/10000, Loss: 0.023998349905014038\n",
      "Iteration: 3527/10000, Loss: 0.017920734360814095\n",
      "Iteration: 3528/10000, Loss: 0.021262088790535927\n",
      "Iteration: 3529/10000, Loss: 0.02467336319386959\n",
      "Iteration: 3530/10000, Loss: 0.018000954762101173\n",
      "Iteration: 3531/10000, Loss: 0.017100894823670387\n",
      "Iteration: 3532/10000, Loss: 0.016510730609297752\n",
      "Iteration: 3533/10000, Loss: 0.01602480560541153\n",
      "Iteration: 3534/10000, Loss: 0.011520822532474995\n",
      "Iteration: 3535/10000, Loss: 0.01624474674463272\n",
      "Iteration: 3536/10000, Loss: 0.010601837188005447\n",
      "Iteration: 3537/10000, Loss: 0.02092752233147621\n",
      "Iteration: 3538/10000, Loss: 0.01722315140068531\n",
      "Iteration: 3539/10000, Loss: 0.02223961427807808\n",
      "Iteration: 3540/10000, Loss: 0.018912289291620255\n",
      "Iteration: 3541/10000, Loss: 0.014954782091081142\n",
      "Iteration: 3542/10000, Loss: 0.01652301289141178\n",
      "Iteration: 3543/10000, Loss: 0.017235128208994865\n",
      "Iteration: 3544/10000, Loss: 0.016795815899968147\n",
      "Iteration: 3545/10000, Loss: 0.015756109729409218\n",
      "Iteration: 3546/10000, Loss: 0.016539454460144043\n",
      "Iteration: 3547/10000, Loss: 0.01747157983481884\n",
      "Iteration: 3548/10000, Loss: 0.014373112469911575\n",
      "Iteration: 3549/10000, Loss: 0.020553939044475555\n",
      "Iteration: 3550/10000, Loss: 0.017373597249388695\n",
      "Iteration: 3551/10000, Loss: 0.02504502236843109\n",
      "Iteration: 3552/10000, Loss: 0.02468181774020195\n",
      "Iteration: 3553/10000, Loss: 0.009599599987268448\n",
      "Iteration: 3554/10000, Loss: 0.01663302443921566\n",
      "Iteration: 3555/10000, Loss: 0.018374323844909668\n",
      "Iteration: 3556/10000, Loss: 0.019355354830622673\n",
      "Iteration: 3557/10000, Loss: 0.018505647778511047\n",
      "Iteration: 3558/10000, Loss: 0.012003577314317226\n",
      "Iteration: 3559/10000, Loss: 0.01593455858528614\n",
      "Iteration: 3560/10000, Loss: 0.016325337812304497\n",
      "Iteration: 3561/10000, Loss: 0.01566259190440178\n",
      "Iteration: 3562/10000, Loss: 0.01603921502828598\n",
      "Iteration: 3563/10000, Loss: 0.01250150054693222\n",
      "Iteration: 3564/10000, Loss: 0.0213581882417202\n",
      "Iteration: 3565/10000, Loss: 0.014376924373209476\n",
      "Iteration: 3566/10000, Loss: 0.020338285714387894\n",
      "Iteration: 3567/10000, Loss: 0.016117608174681664\n",
      "Iteration: 3568/10000, Loss: 0.020610880106687546\n",
      "Iteration: 3569/10000, Loss: 0.016731666401028633\n",
      "Iteration: 3570/10000, Loss: 0.016825921833515167\n",
      "Iteration: 3571/10000, Loss: 0.012414868921041489\n",
      "Iteration: 3572/10000, Loss: 0.01542819943279028\n",
      "Iteration: 3573/10000, Loss: 0.02625456266105175\n",
      "Iteration: 3574/10000, Loss: 0.013972952961921692\n",
      "Iteration: 3575/10000, Loss: 0.02352861873805523\n",
      "Iteration: 3576/10000, Loss: 0.012389698065817356\n",
      "Iteration: 3577/10000, Loss: 0.01208211574703455\n",
      "Iteration: 3578/10000, Loss: 0.019291061908006668\n",
      "Iteration: 3579/10000, Loss: 0.01843232661485672\n",
      "Iteration: 3580/10000, Loss: 0.012401926331222057\n",
      "Iteration: 3581/10000, Loss: 0.013655334711074829\n",
      "Iteration: 3582/10000, Loss: 0.011838200502097607\n",
      "Iteration: 3583/10000, Loss: 0.01859147846698761\n",
      "Iteration: 3584/10000, Loss: 0.01450846716761589\n",
      "Iteration: 3585/10000, Loss: 0.011666201055049896\n",
      "Iteration: 3586/10000, Loss: 0.013994462788105011\n",
      "Iteration: 3587/10000, Loss: 0.015949444845318794\n",
      "Iteration: 3588/10000, Loss: 0.009824609383940697\n",
      "Iteration: 3589/10000, Loss: 0.014387845993041992\n",
      "Iteration: 3590/10000, Loss: 0.023559315130114555\n",
      "Iteration: 3591/10000, Loss: 0.02312649041414261\n",
      "Iteration: 3592/10000, Loss: 0.02297613024711609\n",
      "Iteration: 3593/10000, Loss: 0.01665634848177433\n",
      "Iteration: 3594/10000, Loss: 0.013622093014419079\n",
      "Iteration: 3595/10000, Loss: 0.01746419258415699\n",
      "Iteration: 3596/10000, Loss: 0.024218827486038208\n",
      "Iteration: 3597/10000, Loss: 0.019053736701607704\n",
      "Iteration: 3598/10000, Loss: 0.01547841727733612\n",
      "Iteration: 3599/10000, Loss: 0.013323182240128517\n",
      "Iteration: 3600/10000, Loss: 0.011340861208736897\n",
      "Average test loss:  0.0038\n",
      "Iteration: 3601/10000, Loss: 0.011055540293455124\n",
      "Iteration: 3602/10000, Loss: 0.015673000365495682\n",
      "Iteration: 3603/10000, Loss: 0.016469847410917282\n",
      "Iteration: 3604/10000, Loss: 0.012538570910692215\n",
      "Iteration: 3605/10000, Loss: 0.021115846931934357\n",
      "Iteration: 3606/10000, Loss: 0.015008467249572277\n",
      "Iteration: 3607/10000, Loss: 0.019554955884814262\n",
      "Iteration: 3608/10000, Loss: 0.023002706468105316\n",
      "Iteration: 3609/10000, Loss: 0.008018593303859234\n",
      "Iteration: 3610/10000, Loss: 0.019256887957453728\n",
      "Iteration: 3611/10000, Loss: 0.017428863793611526\n",
      "Iteration: 3612/10000, Loss: 0.01421720813959837\n",
      "Iteration: 3613/10000, Loss: 0.018390191718935966\n",
      "Iteration: 3614/10000, Loss: 0.01720338873565197\n",
      "Iteration: 3615/10000, Loss: 0.020732508972287178\n",
      "Iteration: 3616/10000, Loss: 0.01961502991616726\n",
      "Iteration: 3617/10000, Loss: 0.017282284796237946\n",
      "Iteration: 3618/10000, Loss: 0.01565754972398281\n",
      "Iteration: 3619/10000, Loss: 0.02045278809964657\n",
      "Iteration: 3620/10000, Loss: 0.015054676681756973\n",
      "Iteration: 3621/10000, Loss: 0.014566300436854362\n",
      "Iteration: 3622/10000, Loss: 0.015767455101013184\n",
      "Iteration: 3623/10000, Loss: 0.01521515566855669\n",
      "Iteration: 3624/10000, Loss: 0.020081575959920883\n",
      "Iteration: 3625/10000, Loss: 0.010972877964377403\n",
      "Iteration: 3626/10000, Loss: 0.019554132595658302\n",
      "Iteration: 3627/10000, Loss: 0.016763413324952126\n",
      "Iteration: 3628/10000, Loss: 0.012357364408671856\n",
      "Iteration: 3629/10000, Loss: 0.015287656337022781\n",
      "Iteration: 3630/10000, Loss: 0.02001354657113552\n",
      "Iteration: 3631/10000, Loss: 0.018469346687197685\n",
      "Iteration: 3632/10000, Loss: 0.016479309648275375\n",
      "Iteration: 3633/10000, Loss: 0.012434852309525013\n",
      "Iteration: 3634/10000, Loss: 0.020210029557347298\n",
      "Iteration: 3635/10000, Loss: 0.025653298944234848\n",
      "Iteration: 3636/10000, Loss: 0.023640448227524757\n",
      "Iteration: 3637/10000, Loss: 0.020824560895562172\n",
      "Iteration: 3638/10000, Loss: 0.01687527820467949\n",
      "Iteration: 3639/10000, Loss: 0.02053002640604973\n",
      "Iteration: 3640/10000, Loss: 0.017628138884902\n",
      "Iteration: 3641/10000, Loss: 0.02359100989997387\n",
      "Iteration: 3642/10000, Loss: 0.013734085485339165\n",
      "Iteration: 3643/10000, Loss: 0.017996495589613914\n",
      "Iteration: 3644/10000, Loss: 0.012696833349764347\n",
      "Iteration: 3645/10000, Loss: 0.01838596723973751\n",
      "Iteration: 3646/10000, Loss: 0.017093991860747337\n",
      "Iteration: 3647/10000, Loss: 0.01144137792289257\n",
      "Iteration: 3648/10000, Loss: 0.024554219096899033\n",
      "Iteration: 3649/10000, Loss: 0.01603066548705101\n",
      "Iteration: 3650/10000, Loss: 0.017401063814759254\n",
      "Iteration: 3651/10000, Loss: 0.011945913545787334\n",
      "Iteration: 3652/10000, Loss: 0.020263012498617172\n",
      "Iteration: 3653/10000, Loss: 0.012208675034344196\n",
      "Iteration: 3654/10000, Loss: 0.009177771396934986\n",
      "Iteration: 3655/10000, Loss: 0.020074134692549706\n",
      "Iteration: 3656/10000, Loss: 0.01834270916879177\n",
      "Iteration: 3657/10000, Loss: 0.02106139063835144\n",
      "Iteration: 3658/10000, Loss: 0.015166684985160828\n",
      "Iteration: 3659/10000, Loss: 0.02038426697254181\n",
      "Iteration: 3660/10000, Loss: 0.020407725125551224\n",
      "Iteration: 3661/10000, Loss: 0.01731586828827858\n",
      "Iteration: 3662/10000, Loss: 0.017744524404406548\n",
      "Iteration: 3663/10000, Loss: 0.014750720001757145\n",
      "Iteration: 3664/10000, Loss: 0.01506526954472065\n",
      "Iteration: 3665/10000, Loss: 0.02101355604827404\n",
      "Iteration: 3666/10000, Loss: 0.012759757228195667\n",
      "Iteration: 3667/10000, Loss: 0.01304701343178749\n",
      "Iteration: 3668/10000, Loss: 0.026783455163240433\n",
      "Iteration: 3669/10000, Loss: 0.01600840501487255\n",
      "Iteration: 3670/10000, Loss: 0.02031467854976654\n",
      "Iteration: 3671/10000, Loss: 0.016873689368367195\n",
      "Iteration: 3672/10000, Loss: 0.01723082736134529\n",
      "Iteration: 3673/10000, Loss: 0.019050145521759987\n",
      "Iteration: 3674/10000, Loss: 0.01685505546629429\n",
      "Iteration: 3675/10000, Loss: 0.019959647208452225\n",
      "Iteration: 3676/10000, Loss: 0.014987142756581306\n",
      "Iteration: 3677/10000, Loss: 0.01127333752810955\n",
      "Iteration: 3678/10000, Loss: 0.019222041592001915\n",
      "Iteration: 3679/10000, Loss: 0.010806238278746605\n",
      "Iteration: 3680/10000, Loss: 0.036709628999233246\n",
      "Iteration: 3681/10000, Loss: 0.015386929735541344\n",
      "Iteration: 3682/10000, Loss: 0.017604798078536987\n",
      "Iteration: 3683/10000, Loss: 0.023073425516486168\n",
      "Iteration: 3684/10000, Loss: 0.017869453877210617\n",
      "Iteration: 3685/10000, Loss: 0.028997370973229408\n",
      "Iteration: 3686/10000, Loss: 0.015862414613366127\n",
      "Iteration: 3687/10000, Loss: 0.016826985403895378\n",
      "Iteration: 3688/10000, Loss: 0.01698858104646206\n",
      "Iteration: 3689/10000, Loss: 0.018192799761891365\n",
      "Iteration: 3690/10000, Loss: 0.012960003688931465\n",
      "Iteration: 3691/10000, Loss: 0.015501242130994797\n",
      "Iteration: 3692/10000, Loss: 0.019651256501674652\n",
      "Iteration: 3693/10000, Loss: 0.016144245862960815\n",
      "Iteration: 3694/10000, Loss: 0.02404489368200302\n",
      "Iteration: 3695/10000, Loss: 0.01405566930770874\n",
      "Iteration: 3696/10000, Loss: 0.011165820993483067\n",
      "Iteration: 3697/10000, Loss: 0.015476949512958527\n",
      "Iteration: 3698/10000, Loss: 0.016705183312296867\n",
      "Iteration: 3699/10000, Loss: 0.01614789478480816\n",
      "Iteration: 3700/10000, Loss: 0.015824509784579277\n",
      "Average test loss:  0.0019\n",
      "Iteration: 3701/10000, Loss: 0.01161264069378376\n",
      "Iteration: 3702/10000, Loss: 0.01961221732199192\n",
      "Iteration: 3703/10000, Loss: 0.021010352298617363\n",
      "Iteration: 3704/10000, Loss: 0.015888726338744164\n",
      "Iteration: 3705/10000, Loss: 0.023208027705550194\n",
      "Iteration: 3706/10000, Loss: 0.011997722089290619\n",
      "Iteration: 3707/10000, Loss: 0.019657077267766\n",
      "Iteration: 3708/10000, Loss: 0.02429823949933052\n",
      "Iteration: 3709/10000, Loss: 0.017372701317071915\n",
      "Iteration: 3710/10000, Loss: 0.015247097238898277\n",
      "Iteration: 3711/10000, Loss: 0.02380130998790264\n",
      "Iteration: 3712/10000, Loss: 0.012833654880523682\n",
      "Iteration: 3713/10000, Loss: 0.015676680952310562\n",
      "Iteration: 3714/10000, Loss: 0.01852993853390217\n",
      "Iteration: 3715/10000, Loss: 0.022588804364204407\n",
      "Iteration: 3716/10000, Loss: 0.01871844381093979\n",
      "Iteration: 3717/10000, Loss: 0.017837749794125557\n",
      "Iteration: 3718/10000, Loss: 0.018109487369656563\n",
      "Iteration: 3719/10000, Loss: 0.02187063731253147\n",
      "Iteration: 3720/10000, Loss: 0.02008739858865738\n",
      "Iteration: 3721/10000, Loss: 0.012279684655368328\n",
      "Iteration: 3722/10000, Loss: 0.008935349993407726\n",
      "Iteration: 3723/10000, Loss: 0.015785684809088707\n",
      "Iteration: 3724/10000, Loss: 0.016181664541363716\n",
      "Iteration: 3725/10000, Loss: 0.013250043615698814\n",
      "Iteration: 3726/10000, Loss: 0.023973733186721802\n",
      "Iteration: 3727/10000, Loss: 0.010647842660546303\n",
      "Iteration: 3728/10000, Loss: 0.022348590195178986\n",
      "Iteration: 3729/10000, Loss: 0.020547430962324142\n",
      "Iteration: 3730/10000, Loss: 0.02420816756784916\n",
      "Iteration: 3731/10000, Loss: 0.014490621164441109\n",
      "Iteration: 3732/10000, Loss: 0.016245096921920776\n",
      "Iteration: 3733/10000, Loss: 0.020107917487621307\n",
      "Iteration: 3734/10000, Loss: 0.017575567588210106\n",
      "Iteration: 3735/10000, Loss: 0.03001529350876808\n",
      "Iteration: 3736/10000, Loss: 0.02720104716718197\n",
      "Iteration: 3737/10000, Loss: 0.016218287870287895\n",
      "Iteration: 3738/10000, Loss: 0.01823621802031994\n",
      "Iteration: 3739/10000, Loss: 0.01737394370138645\n",
      "Iteration: 3740/10000, Loss: 0.02108755335211754\n",
      "Iteration: 3741/10000, Loss: 0.015312714502215385\n",
      "Iteration: 3742/10000, Loss: 0.01761600747704506\n",
      "Iteration: 3743/10000, Loss: 0.019116049632430077\n",
      "Iteration: 3744/10000, Loss: 0.01397668942809105\n",
      "Iteration: 3745/10000, Loss: 0.016123497858643532\n",
      "Iteration: 3746/10000, Loss: 0.012143559753894806\n",
      "Iteration: 3747/10000, Loss: 0.01568925566971302\n",
      "Iteration: 3748/10000, Loss: 0.020797794684767723\n",
      "Iteration: 3749/10000, Loss: 0.01648242026567459\n",
      "Iteration: 3750/10000, Loss: 0.01794508844614029\n",
      "Iteration: 3751/10000, Loss: 0.022178884595632553\n",
      "Iteration: 3752/10000, Loss: 0.019160933792591095\n",
      "Iteration: 3753/10000, Loss: 0.02279779501259327\n",
      "Iteration: 3754/10000, Loss: 0.013341899029910564\n",
      "Iteration: 3755/10000, Loss: 0.016908857971429825\n",
      "Iteration: 3756/10000, Loss: 0.01619122177362442\n",
      "Iteration: 3757/10000, Loss: 0.025125235319137573\n",
      "Iteration: 3758/10000, Loss: 0.013176262378692627\n",
      "Iteration: 3759/10000, Loss: 0.020667599514126778\n",
      "Iteration: 3760/10000, Loss: 0.020569220185279846\n",
      "Iteration: 3761/10000, Loss: 0.015202236361801624\n",
      "Iteration: 3762/10000, Loss: 0.017059916630387306\n",
      "Iteration: 3763/10000, Loss: 0.017966410145163536\n",
      "Iteration: 3764/10000, Loss: 0.021901128813624382\n",
      "Iteration: 3765/10000, Loss: 0.01376163586974144\n",
      "Iteration: 3766/10000, Loss: 0.017983224242925644\n",
      "Iteration: 3767/10000, Loss: 0.018799925222992897\n",
      "Iteration: 3768/10000, Loss: 0.010905075818300247\n",
      "Iteration: 3769/10000, Loss: 0.008792433887720108\n",
      "Iteration: 3770/10000, Loss: 0.02640458382666111\n",
      "Iteration: 3771/10000, Loss: 0.019195346161723137\n",
      "Iteration: 3772/10000, Loss: 0.021857086569070816\n",
      "Iteration: 3773/10000, Loss: 0.012194880284368992\n",
      "Iteration: 3774/10000, Loss: 0.021346231922507286\n",
      "Iteration: 3775/10000, Loss: 0.018949056044220924\n",
      "Iteration: 3776/10000, Loss: 0.017439857125282288\n",
      "Iteration: 3777/10000, Loss: 0.012320396490395069\n",
      "Iteration: 3778/10000, Loss: 0.01743214763700962\n",
      "Iteration: 3779/10000, Loss: 0.014304271899163723\n",
      "Iteration: 3780/10000, Loss: 0.018171492964029312\n",
      "Iteration: 3781/10000, Loss: 0.017540032044053078\n",
      "Iteration: 3782/10000, Loss: 0.010600773617625237\n",
      "Iteration: 3783/10000, Loss: 0.02894022688269615\n",
      "Iteration: 3784/10000, Loss: 0.016083216294646263\n",
      "Iteration: 3785/10000, Loss: 0.016023557633161545\n",
      "Iteration: 3786/10000, Loss: 0.01601170003414154\n",
      "Iteration: 3787/10000, Loss: 0.01634759083390236\n",
      "Iteration: 3788/10000, Loss: 0.013434110209345818\n",
      "Iteration: 3789/10000, Loss: 0.01744738034904003\n",
      "Iteration: 3790/10000, Loss: 0.01619630679488182\n",
      "Iteration: 3791/10000, Loss: 0.013628234155476093\n",
      "Iteration: 3792/10000, Loss: 0.017889490351080894\n",
      "Iteration: 3793/10000, Loss: 0.025103773921728134\n",
      "Iteration: 3794/10000, Loss: 0.016419755294919014\n",
      "Iteration: 3795/10000, Loss: 0.016752446070313454\n",
      "Iteration: 3796/10000, Loss: 0.025397146120667458\n",
      "Iteration: 3797/10000, Loss: 0.01361503079533577\n",
      "Iteration: 3798/10000, Loss: 0.02097300998866558\n",
      "Iteration: 3799/10000, Loss: 0.01517157070338726\n",
      "Iteration: 3800/10000, Loss: 0.016615519300103188\n",
      "Average test loss:  0.0017\n",
      "Iteration: 3801/10000, Loss: 0.013050084002315998\n",
      "Iteration: 3802/10000, Loss: 0.01767502725124359\n",
      "Iteration: 3803/10000, Loss: 0.016187261790037155\n",
      "Iteration: 3804/10000, Loss: 0.024469053372740746\n",
      "Iteration: 3805/10000, Loss: 0.019864190369844437\n",
      "Iteration: 3806/10000, Loss: 0.014432870782911777\n",
      "Iteration: 3807/10000, Loss: 0.02512442320585251\n",
      "Iteration: 3808/10000, Loss: 0.01685844361782074\n",
      "Iteration: 3809/10000, Loss: 0.016986912116408348\n",
      "Iteration: 3810/10000, Loss: 0.019464312121272087\n",
      "Iteration: 3811/10000, Loss: 0.013448171317577362\n",
      "Iteration: 3812/10000, Loss: 0.013101656921207905\n",
      "Iteration: 3813/10000, Loss: 0.01643124409019947\n",
      "Iteration: 3814/10000, Loss: 0.017025461420416832\n",
      "Iteration: 3815/10000, Loss: 0.017872115597128868\n",
      "Iteration: 3816/10000, Loss: 0.014265007339417934\n",
      "Iteration: 3817/10000, Loss: 0.016038108617067337\n",
      "Iteration: 3818/10000, Loss: 0.02046722173690796\n",
      "Iteration: 3819/10000, Loss: 0.012373954057693481\n",
      "Iteration: 3820/10000, Loss: 0.022661546245217323\n",
      "Iteration: 3821/10000, Loss: 0.012992213480174541\n",
      "Iteration: 3822/10000, Loss: 0.013110716827213764\n",
      "Iteration: 3823/10000, Loss: 0.011271325871348381\n",
      "Iteration: 3824/10000, Loss: 0.02139434963464737\n",
      "Iteration: 3825/10000, Loss: 0.02180039882659912\n",
      "Iteration: 3826/10000, Loss: 0.015153475105762482\n",
      "Iteration: 3827/10000, Loss: 0.01706189662218094\n",
      "Iteration: 3828/10000, Loss: 0.019953854382038116\n",
      "Iteration: 3829/10000, Loss: 0.016169171780347824\n",
      "Iteration: 3830/10000, Loss: 0.012721833772957325\n",
      "Iteration: 3831/10000, Loss: 0.01214086078107357\n",
      "Iteration: 3832/10000, Loss: 0.01901235803961754\n",
      "Iteration: 3833/10000, Loss: 0.01918131113052368\n",
      "Iteration: 3834/10000, Loss: 0.014605045318603516\n",
      "Iteration: 3835/10000, Loss: 0.016377203166484833\n",
      "Iteration: 3836/10000, Loss: 0.021212352439761162\n",
      "Iteration: 3837/10000, Loss: 0.020690759643912315\n",
      "Iteration: 3838/10000, Loss: 0.01644771359860897\n",
      "Iteration: 3839/10000, Loss: 0.015732401981949806\n",
      "Iteration: 3840/10000, Loss: 0.015702780336141586\n",
      "Iteration: 3841/10000, Loss: 0.02128581702709198\n",
      "Iteration: 3842/10000, Loss: 0.01496921293437481\n",
      "Iteration: 3843/10000, Loss: 0.009305741637945175\n",
      "Iteration: 3844/10000, Loss: 0.014509164728224277\n",
      "Iteration: 3845/10000, Loss: 0.010921858251094818\n",
      "Iteration: 3846/10000, Loss: 0.01721971109509468\n",
      "Iteration: 3847/10000, Loss: 0.017735032364726067\n",
      "Iteration: 3848/10000, Loss: 0.017990946769714355\n",
      "Iteration: 3849/10000, Loss: 0.009087711572647095\n",
      "Iteration: 3850/10000, Loss: 0.02196064405143261\n",
      "Iteration: 3851/10000, Loss: 0.01533796638250351\n",
      "Iteration: 3852/10000, Loss: 0.013108017854392529\n",
      "Iteration: 3853/10000, Loss: 0.013814473524689674\n",
      "Iteration: 3854/10000, Loss: 0.015210243873298168\n",
      "Iteration: 3855/10000, Loss: 0.019241543486714363\n",
      "Iteration: 3856/10000, Loss: 0.021057840436697006\n",
      "Iteration: 3857/10000, Loss: 0.014417148195207119\n",
      "Iteration: 3858/10000, Loss: 0.019705405458807945\n",
      "Iteration: 3859/10000, Loss: 0.012247372418642044\n",
      "Iteration: 3860/10000, Loss: 0.020104113966226578\n",
      "Iteration: 3861/10000, Loss: 0.012985520996153355\n",
      "Iteration: 3862/10000, Loss: 0.016994547098875046\n",
      "Iteration: 3863/10000, Loss: 0.014582881703972816\n",
      "Iteration: 3864/10000, Loss: 0.025539681315422058\n",
      "Iteration: 3865/10000, Loss: 0.02041901834309101\n",
      "Iteration: 3866/10000, Loss: 0.0175396166741848\n",
      "Iteration: 3867/10000, Loss: 0.016367986798286438\n",
      "Iteration: 3868/10000, Loss: 0.015503667294979095\n",
      "Iteration: 3869/10000, Loss: 0.012554499320685863\n",
      "Iteration: 3870/10000, Loss: 0.016985073685646057\n",
      "Iteration: 3871/10000, Loss: 0.010978988371789455\n",
      "Iteration: 3872/10000, Loss: 0.02303408272564411\n",
      "Iteration: 3873/10000, Loss: 0.017669441178441048\n",
      "Iteration: 3874/10000, Loss: 0.019882723689079285\n",
      "Iteration: 3875/10000, Loss: 0.021267415955662727\n",
      "Iteration: 3876/10000, Loss: 0.01098551508039236\n",
      "Iteration: 3877/10000, Loss: 0.011561308987438679\n",
      "Iteration: 3878/10000, Loss: 0.02309822104871273\n",
      "Iteration: 3879/10000, Loss: 0.01864011213183403\n",
      "Iteration: 3880/10000, Loss: 0.01750722900032997\n",
      "Iteration: 3881/10000, Loss: 0.019921820610761642\n",
      "Iteration: 3882/10000, Loss: 0.010322313755750656\n",
      "Iteration: 3883/10000, Loss: 0.014768007211387157\n",
      "Iteration: 3884/10000, Loss: 0.01512492261826992\n",
      "Iteration: 3885/10000, Loss: 0.02688978798687458\n",
      "Iteration: 3886/10000, Loss: 0.013481399044394493\n",
      "Iteration: 3887/10000, Loss: 0.014605870470404625\n",
      "Iteration: 3888/10000, Loss: 0.019478552043437958\n",
      "Iteration: 3889/10000, Loss: 0.012138388119637966\n",
      "Iteration: 3890/10000, Loss: 0.01998998410999775\n",
      "Iteration: 3891/10000, Loss: 0.01476574968546629\n",
      "Iteration: 3892/10000, Loss: 0.014796538278460503\n",
      "Iteration: 3893/10000, Loss: 0.021663764491677284\n",
      "Iteration: 3894/10000, Loss: 0.016605567187070847\n",
      "Iteration: 3895/10000, Loss: 0.020229434594511986\n",
      "Iteration: 3896/10000, Loss: 0.016513796523213387\n",
      "Iteration: 3897/10000, Loss: 0.015885213389992714\n",
      "Iteration: 3898/10000, Loss: 0.014105355367064476\n",
      "Iteration: 3899/10000, Loss: 0.011118896305561066\n",
      "Iteration: 3900/10000, Loss: 0.015432369895279408\n",
      "Average test loss:  0.0025\n",
      "Iteration: 3901/10000, Loss: 0.021633347496390343\n",
      "Iteration: 3902/10000, Loss: 0.01323841791599989\n",
      "Iteration: 3903/10000, Loss: 0.016187984496355057\n",
      "Iteration: 3904/10000, Loss: 0.013962361961603165\n",
      "Iteration: 3905/10000, Loss: 0.016771463677287102\n",
      "Iteration: 3906/10000, Loss: 0.013579146936535835\n",
      "Iteration: 3907/10000, Loss: 0.015688816085457802\n",
      "Iteration: 3908/10000, Loss: 0.012315314263105392\n",
      "Iteration: 3909/10000, Loss: 0.01412340346723795\n",
      "Iteration: 3910/10000, Loss: 0.011542622931301594\n",
      "Iteration: 3911/10000, Loss: 0.019651388749480247\n",
      "Iteration: 3912/10000, Loss: 0.014350822195410728\n",
      "Iteration: 3913/10000, Loss: 0.02852349355816841\n",
      "Iteration: 3914/10000, Loss: 0.014229736290872097\n",
      "Iteration: 3915/10000, Loss: 0.019211819395422935\n",
      "Iteration: 3916/10000, Loss: 0.011078459210693836\n",
      "Iteration: 3917/10000, Loss: 0.018204037100076675\n",
      "Iteration: 3918/10000, Loss: 0.010036846622824669\n",
      "Iteration: 3919/10000, Loss: 0.013948813080787659\n",
      "Iteration: 3920/10000, Loss: 0.017659854143857956\n",
      "Iteration: 3921/10000, Loss: 0.02164856344461441\n",
      "Iteration: 3922/10000, Loss: 0.01665080524981022\n",
      "Iteration: 3923/10000, Loss: 0.018828561529517174\n",
      "Iteration: 3924/10000, Loss: 0.02059401385486126\n",
      "Iteration: 3925/10000, Loss: 0.01589011400938034\n",
      "Iteration: 3926/10000, Loss: 0.017684414982795715\n",
      "Iteration: 3927/10000, Loss: 0.0132640665397048\n",
      "Iteration: 3928/10000, Loss: 0.019281422719359398\n",
      "Iteration: 3929/10000, Loss: 0.012270698323845863\n",
      "Iteration: 3930/10000, Loss: 0.016758417710661888\n",
      "Iteration: 3931/10000, Loss: 0.011881250888109207\n",
      "Iteration: 3932/10000, Loss: 0.020093630999326706\n",
      "Iteration: 3933/10000, Loss: 0.018676001578569412\n",
      "Iteration: 3934/10000, Loss: 0.01404940988868475\n",
      "Iteration: 3935/10000, Loss: 0.02183423936367035\n",
      "Iteration: 3936/10000, Loss: 0.01885288394987583\n",
      "Iteration: 3937/10000, Loss: 0.014424026012420654\n",
      "Iteration: 3938/10000, Loss: 0.015363568440079689\n",
      "Iteration: 3939/10000, Loss: 0.01572129689157009\n",
      "Iteration: 3940/10000, Loss: 0.015310943126678467\n",
      "Iteration: 3941/10000, Loss: 0.022891702130436897\n",
      "Iteration: 3942/10000, Loss: 0.009998220019042492\n",
      "Iteration: 3943/10000, Loss: 0.01742878369987011\n",
      "Iteration: 3944/10000, Loss: 0.028303731232881546\n",
      "Iteration: 3945/10000, Loss: 0.013170460239052773\n",
      "Iteration: 3946/10000, Loss: 0.013566778972744942\n",
      "Iteration: 3947/10000, Loss: 0.018477346748113632\n",
      "Iteration: 3948/10000, Loss: 0.010767967440187931\n",
      "Iteration: 3949/10000, Loss: 0.015264020301401615\n",
      "Iteration: 3950/10000, Loss: 0.021241528913378716\n",
      "Iteration: 3951/10000, Loss: 0.011908777989447117\n",
      "Iteration: 3952/10000, Loss: 0.016980022192001343\n",
      "Iteration: 3953/10000, Loss: 0.013208580203354359\n",
      "Iteration: 3954/10000, Loss: 0.014123000204563141\n",
      "Iteration: 3955/10000, Loss: 0.016694480553269386\n",
      "Iteration: 3956/10000, Loss: 0.014408126473426819\n",
      "Iteration: 3957/10000, Loss: 0.01899058371782303\n",
      "Iteration: 3958/10000, Loss: 0.01182048674672842\n",
      "Iteration: 3959/10000, Loss: 0.015702029690146446\n",
      "Iteration: 3960/10000, Loss: 0.01700209081172943\n",
      "Iteration: 3961/10000, Loss: 0.013606447726488113\n",
      "Iteration: 3962/10000, Loss: 0.01475058775395155\n",
      "Iteration: 3963/10000, Loss: 0.010493433102965355\n",
      "Iteration: 3964/10000, Loss: 0.021106883883476257\n",
      "Iteration: 3965/10000, Loss: 0.024387480691075325\n",
      "Iteration: 3966/10000, Loss: 0.012121353298425674\n",
      "Iteration: 3967/10000, Loss: 0.018781453371047974\n",
      "Iteration: 3968/10000, Loss: 0.019644955173134804\n",
      "Iteration: 3969/10000, Loss: 0.014063321985304356\n",
      "Iteration: 3970/10000, Loss: 0.012984678149223328\n",
      "Iteration: 3971/10000, Loss: 0.013670933432877064\n",
      "Iteration: 3972/10000, Loss: 0.017643632367253304\n",
      "Iteration: 3973/10000, Loss: 0.026725467294454575\n",
      "Iteration: 3974/10000, Loss: 0.00938483327627182\n",
      "Iteration: 3975/10000, Loss: 0.021721376106142998\n",
      "Iteration: 3976/10000, Loss: 0.016637668013572693\n",
      "Iteration: 3977/10000, Loss: 0.016910512000322342\n",
      "Iteration: 3978/10000, Loss: 0.024105427786707878\n",
      "Iteration: 3979/10000, Loss: 0.017066124826669693\n",
      "Iteration: 3980/10000, Loss: 0.017536895349621773\n",
      "Iteration: 3981/10000, Loss: 0.01576870121061802\n",
      "Iteration: 3982/10000, Loss: 0.013400120660662651\n",
      "Iteration: 3983/10000, Loss: 0.013616777025163174\n",
      "Iteration: 3984/10000, Loss: 0.015780063346028328\n",
      "Iteration: 3985/10000, Loss: 0.01587921567261219\n",
      "Iteration: 3986/10000, Loss: 0.017008377239108086\n",
      "Iteration: 3987/10000, Loss: 0.018121276050806046\n",
      "Iteration: 3988/10000, Loss: 0.01467004232108593\n",
      "Iteration: 3989/10000, Loss: 0.014615282416343689\n",
      "Iteration: 3990/10000, Loss: 0.01421546284109354\n",
      "Iteration: 3991/10000, Loss: 0.01831778697669506\n",
      "Iteration: 3992/10000, Loss: 0.014568433165550232\n",
      "Iteration: 3993/10000, Loss: 0.021891620010137558\n",
      "Iteration: 3994/10000, Loss: 0.017520733177661896\n",
      "Iteration: 3995/10000, Loss: 0.023562420159578323\n",
      "Iteration: 3996/10000, Loss: 0.01814453676342964\n",
      "Iteration: 3997/10000, Loss: 0.022679457440972328\n",
      "Iteration: 3998/10000, Loss: 0.008157312870025635\n",
      "Iteration: 3999/10000, Loss: 0.011469007469713688\n",
      "Iteration: 4000/10000, Loss: 0.016515159979462624\n",
      "Average test loss:  0.0024\n",
      "Iteration: 4001/10000, Loss: 0.013656395487487316\n",
      "Iteration: 4002/10000, Loss: 0.012437599711120129\n",
      "Iteration: 4003/10000, Loss: 0.023285256698727608\n",
      "Iteration: 4004/10000, Loss: 0.02513657510280609\n",
      "Iteration: 4005/10000, Loss: 0.01802227459847927\n",
      "Iteration: 4006/10000, Loss: 0.016804389655590057\n",
      "Iteration: 4007/10000, Loss: 0.016896937042474747\n",
      "Iteration: 4008/10000, Loss: 0.019321933388710022\n",
      "Iteration: 4009/10000, Loss: 0.015137439593672752\n",
      "Iteration: 4010/10000, Loss: 0.019742414355278015\n",
      "Iteration: 4011/10000, Loss: 0.013768503442406654\n",
      "Iteration: 4012/10000, Loss: 0.014527712017297745\n",
      "Iteration: 4013/10000, Loss: 0.021841077134013176\n",
      "Iteration: 4014/10000, Loss: 0.014929480850696564\n",
      "Iteration: 4015/10000, Loss: 0.017926711589097977\n",
      "Iteration: 4016/10000, Loss: 0.018823856487870216\n",
      "Iteration: 4017/10000, Loss: 0.01783120073378086\n",
      "Iteration: 4018/10000, Loss: 0.019046280533075333\n",
      "Iteration: 4019/10000, Loss: 0.013832422904670238\n",
      "Iteration: 4020/10000, Loss: 0.02103937417268753\n",
      "Iteration: 4021/10000, Loss: 0.012945635244250298\n",
      "Iteration: 4022/10000, Loss: 0.02185109630227089\n",
      "Iteration: 4023/10000, Loss: 0.021845782175660133\n",
      "Iteration: 4024/10000, Loss: 0.018329516053199768\n",
      "Iteration: 4025/10000, Loss: 0.01362616941332817\n",
      "Iteration: 4026/10000, Loss: 0.016497941687703133\n",
      "Iteration: 4027/10000, Loss: 0.018297133967280388\n",
      "Iteration: 4028/10000, Loss: 0.009919504635035992\n",
      "Iteration: 4029/10000, Loss: 0.017139501869678497\n",
      "Iteration: 4030/10000, Loss: 0.010881075635552406\n",
      "Iteration: 4031/10000, Loss: 0.01652832329273224\n",
      "Iteration: 4032/10000, Loss: 0.013957838527858257\n",
      "Iteration: 4033/10000, Loss: 0.014574594795703888\n",
      "Iteration: 4034/10000, Loss: 0.020877812057733536\n",
      "Iteration: 4035/10000, Loss: 0.01509027648717165\n",
      "Iteration: 4036/10000, Loss: 0.016573814675211906\n",
      "Iteration: 4037/10000, Loss: 0.014909766614437103\n",
      "Iteration: 4038/10000, Loss: 0.014745875261723995\n",
      "Iteration: 4039/10000, Loss: 0.011576785705983639\n",
      "Iteration: 4040/10000, Loss: 0.011389126069843769\n",
      "Iteration: 4041/10000, Loss: 0.015301242470741272\n",
      "Iteration: 4042/10000, Loss: 0.018063077703118324\n",
      "Iteration: 4043/10000, Loss: 0.017893671989440918\n",
      "Iteration: 4044/10000, Loss: 0.01745683327317238\n",
      "Iteration: 4045/10000, Loss: 0.01861395686864853\n",
      "Iteration: 4046/10000, Loss: 0.013042828068137169\n",
      "Iteration: 4047/10000, Loss: 0.019457658752799034\n",
      "Iteration: 4048/10000, Loss: 0.015481424517929554\n",
      "Iteration: 4049/10000, Loss: 0.01566220633685589\n",
      "Iteration: 4050/10000, Loss: 0.01915021426975727\n",
      "Iteration: 4051/10000, Loss: 0.014157643541693687\n",
      "Iteration: 4052/10000, Loss: 0.022676309570670128\n",
      "Iteration: 4053/10000, Loss: 0.016552036628127098\n",
      "Iteration: 4054/10000, Loss: 0.011394522152841091\n",
      "Iteration: 4055/10000, Loss: 0.023927031084895134\n",
      "Iteration: 4056/10000, Loss: 0.018226848915219307\n",
      "Iteration: 4057/10000, Loss: 0.01846533827483654\n",
      "Iteration: 4058/10000, Loss: 0.019922057166695595\n",
      "Iteration: 4059/10000, Loss: 0.020142385736107826\n",
      "Iteration: 4060/10000, Loss: 0.016444696113467216\n",
      "Iteration: 4061/10000, Loss: 0.01281555462628603\n",
      "Iteration: 4062/10000, Loss: 0.018536226823925972\n",
      "Iteration: 4063/10000, Loss: 0.021588489413261414\n",
      "Iteration: 4064/10000, Loss: 0.015033659525215626\n",
      "Iteration: 4065/10000, Loss: 0.019698498770594597\n",
      "Iteration: 4066/10000, Loss: 0.013594013638794422\n",
      "Iteration: 4067/10000, Loss: 0.016673659905791283\n",
      "Iteration: 4068/10000, Loss: 0.01792425848543644\n",
      "Iteration: 4069/10000, Loss: 0.020043006166815758\n",
      "Iteration: 4070/10000, Loss: 0.012724323198199272\n",
      "Iteration: 4071/10000, Loss: 0.011901257559657097\n",
      "Iteration: 4072/10000, Loss: 0.019072121009230614\n",
      "Iteration: 4073/10000, Loss: 0.01789923943579197\n",
      "Iteration: 4074/10000, Loss: 0.016687218099832535\n",
      "Iteration: 4075/10000, Loss: 0.02087656781077385\n",
      "Iteration: 4076/10000, Loss: 0.021997006610035896\n",
      "Iteration: 4077/10000, Loss: 0.01609971560537815\n",
      "Iteration: 4078/10000, Loss: 0.01609688065946102\n",
      "Iteration: 4079/10000, Loss: 0.011145075783133507\n",
      "Iteration: 4080/10000, Loss: 0.01397809199988842\n",
      "Iteration: 4081/10000, Loss: 0.013990411534905434\n",
      "Iteration: 4082/10000, Loss: 0.021753406152129173\n",
      "Iteration: 4083/10000, Loss: 0.01319111604243517\n",
      "Iteration: 4084/10000, Loss: 0.01015523448586464\n",
      "Iteration: 4085/10000, Loss: 0.011815149337053299\n",
      "Iteration: 4086/10000, Loss: 0.015607581473886967\n",
      "Iteration: 4087/10000, Loss: 0.010339745320379734\n",
      "Iteration: 4088/10000, Loss: 0.02009817399084568\n",
      "Iteration: 4089/10000, Loss: 0.015518106520175934\n",
      "Iteration: 4090/10000, Loss: 0.01579880155622959\n",
      "Iteration: 4091/10000, Loss: 0.017077848315238953\n",
      "Iteration: 4092/10000, Loss: 0.016723835840821266\n",
      "Iteration: 4093/10000, Loss: 0.013869396410882473\n",
      "Iteration: 4094/10000, Loss: 0.00782821886241436\n",
      "Iteration: 4095/10000, Loss: 0.017374316230416298\n",
      "Iteration: 4096/10000, Loss: 0.01071382500231266\n",
      "Iteration: 4097/10000, Loss: 0.005714881233870983\n",
      "Iteration: 4098/10000, Loss: 0.009612212888896465\n",
      "Iteration: 4099/10000, Loss: 0.02573580853641033\n",
      "Iteration: 4100/10000, Loss: 0.03243826702237129\n",
      "Average test loss:  0.0017\n",
      "Iteration: 4101/10000, Loss: 0.017725098878145218\n",
      "Iteration: 4102/10000, Loss: 0.01703483611345291\n",
      "Iteration: 4103/10000, Loss: 0.02178695797920227\n",
      "Iteration: 4104/10000, Loss: 0.024672428146004677\n",
      "Iteration: 4105/10000, Loss: 0.018748074769973755\n",
      "Iteration: 4106/10000, Loss: 0.014184961095452309\n",
      "Iteration: 4107/10000, Loss: 0.011850148439407349\n",
      "Iteration: 4108/10000, Loss: 0.01813606731593609\n",
      "Iteration: 4109/10000, Loss: 0.01695753075182438\n",
      "Iteration: 4110/10000, Loss: 0.016870012506842613\n",
      "Iteration: 4111/10000, Loss: 0.029399650171399117\n",
      "Iteration: 4112/10000, Loss: 0.01979192905128002\n",
      "Iteration: 4113/10000, Loss: 0.02162519097328186\n",
      "Iteration: 4114/10000, Loss: 0.01678210124373436\n",
      "Iteration: 4115/10000, Loss: 0.018361752852797508\n",
      "Iteration: 4116/10000, Loss: 0.009163234382867813\n",
      "Iteration: 4117/10000, Loss: 0.018041294068098068\n",
      "Iteration: 4118/10000, Loss: 0.017687998712062836\n",
      "Iteration: 4119/10000, Loss: 0.013693348504602909\n",
      "Iteration: 4120/10000, Loss: 0.024072272703051567\n",
      "Iteration: 4121/10000, Loss: 0.014614635147154331\n",
      "Iteration: 4122/10000, Loss: 0.014371284283697605\n",
      "Iteration: 4123/10000, Loss: 0.009587850421667099\n",
      "Iteration: 4124/10000, Loss: 0.012854658998548985\n",
      "Iteration: 4125/10000, Loss: 0.015179082751274109\n",
      "Iteration: 4126/10000, Loss: 0.015297328121960163\n",
      "Iteration: 4127/10000, Loss: 0.01431969553232193\n",
      "Iteration: 4128/10000, Loss: 0.02275514416396618\n",
      "Iteration: 4129/10000, Loss: 0.017069809138774872\n",
      "Iteration: 4130/10000, Loss: 0.015424806624650955\n",
      "Iteration: 4131/10000, Loss: 0.0207846537232399\n",
      "Iteration: 4132/10000, Loss: 0.01860998198390007\n",
      "Iteration: 4133/10000, Loss: 0.01667831279337406\n",
      "Iteration: 4134/10000, Loss: 0.015407299622893333\n",
      "Iteration: 4135/10000, Loss: 0.009546582587063313\n",
      "Iteration: 4136/10000, Loss: 0.016811024397611618\n",
      "Iteration: 4137/10000, Loss: 0.014287099242210388\n",
      "Iteration: 4138/10000, Loss: 0.015071677975356579\n",
      "Iteration: 4139/10000, Loss: 0.011655012145638466\n",
      "Iteration: 4140/10000, Loss: 0.022914351895451546\n",
      "Iteration: 4141/10000, Loss: 0.021483495831489563\n",
      "Iteration: 4142/10000, Loss: 0.0187901109457016\n",
      "Iteration: 4143/10000, Loss: 0.01633254438638687\n",
      "Iteration: 4144/10000, Loss: 0.014091219753026962\n",
      "Iteration: 4145/10000, Loss: 0.0174120981246233\n",
      "Iteration: 4146/10000, Loss: 0.02013637125492096\n",
      "Iteration: 4147/10000, Loss: 0.018609704449772835\n",
      "Iteration: 4148/10000, Loss: 0.014796148985624313\n",
      "Iteration: 4149/10000, Loss: 0.011796104721724987\n",
      "Iteration: 4150/10000, Loss: 0.018491115421056747\n",
      "Iteration: 4151/10000, Loss: 0.013871370814740658\n",
      "Iteration: 4152/10000, Loss: 0.012295874767005444\n",
      "Iteration: 4153/10000, Loss: 0.021297512575984\n",
      "Iteration: 4154/10000, Loss: 0.012715471908450127\n",
      "Iteration: 4155/10000, Loss: 0.0307730995118618\n",
      "Iteration: 4156/10000, Loss: 0.010227126069366932\n",
      "Iteration: 4157/10000, Loss: 0.008941168896853924\n",
      "Iteration: 4158/10000, Loss: 0.022869085893034935\n",
      "Iteration: 4159/10000, Loss: 0.011440451256930828\n",
      "Iteration: 4160/10000, Loss: 0.011342300102114677\n",
      "Iteration: 4161/10000, Loss: 0.014634426683187485\n",
      "Iteration: 4162/10000, Loss: 0.013299706391990185\n",
      "Iteration: 4163/10000, Loss: 0.016175301745533943\n",
      "Iteration: 4164/10000, Loss: 0.019671590998768806\n",
      "Iteration: 4165/10000, Loss: 0.015859877690672874\n",
      "Iteration: 4166/10000, Loss: 0.020409448072314262\n",
      "Iteration: 4167/10000, Loss: 0.017263516783714294\n",
      "Iteration: 4168/10000, Loss: 0.0187913179397583\n",
      "Iteration: 4169/10000, Loss: 0.013805989176034927\n",
      "Iteration: 4170/10000, Loss: 0.0123812360689044\n",
      "Iteration: 4171/10000, Loss: 0.01411987654864788\n",
      "Iteration: 4172/10000, Loss: 0.014578391797840595\n",
      "Iteration: 4173/10000, Loss: 0.012693925760686398\n",
      "Iteration: 4174/10000, Loss: 0.017882494255900383\n",
      "Iteration: 4175/10000, Loss: 0.009865201078355312\n",
      "Iteration: 4176/10000, Loss: 0.01522107981145382\n",
      "Iteration: 4177/10000, Loss: 0.02461233176290989\n",
      "Iteration: 4178/10000, Loss: 0.014749621972441673\n",
      "Iteration: 4179/10000, Loss: 0.012220228090882301\n",
      "Iteration: 4180/10000, Loss: 0.020683305338025093\n",
      "Iteration: 4181/10000, Loss: 0.02252315729856491\n",
      "Iteration: 4182/10000, Loss: 0.015872769057750702\n",
      "Iteration: 4183/10000, Loss: 0.022608961910009384\n",
      "Iteration: 4184/10000, Loss: 0.014145715162158012\n",
      "Iteration: 4185/10000, Loss: 0.0156727097928524\n",
      "Iteration: 4186/10000, Loss: 0.0069039203226566315\n",
      "Iteration: 4187/10000, Loss: 0.02466174215078354\n",
      "Iteration: 4188/10000, Loss: 0.010989487171173096\n",
      "Iteration: 4189/10000, Loss: 0.02082926034927368\n",
      "Iteration: 4190/10000, Loss: 0.020854724571108818\n",
      "Iteration: 4191/10000, Loss: 0.017000507563352585\n",
      "Iteration: 4192/10000, Loss: 0.0199285838752985\n",
      "Iteration: 4193/10000, Loss: 0.018590323626995087\n",
      "Iteration: 4194/10000, Loss: 0.020800286903977394\n",
      "Iteration: 4195/10000, Loss: 0.014863838441669941\n",
      "Iteration: 4196/10000, Loss: 0.013728247955441475\n",
      "Iteration: 4197/10000, Loss: 0.012778718955814838\n",
      "Iteration: 4198/10000, Loss: 0.018735716119408607\n",
      "Iteration: 4199/10000, Loss: 0.009561952203512192\n",
      "Iteration: 4200/10000, Loss: 0.010334857739508152\n",
      "Average test loss:  0.0022\n",
      "Iteration: 4201/10000, Loss: 0.01743689551949501\n",
      "Iteration: 4202/10000, Loss: 0.020150935277342796\n",
      "Iteration: 4203/10000, Loss: 0.01934516243636608\n",
      "Iteration: 4204/10000, Loss: 0.011875857599079609\n",
      "Iteration: 4205/10000, Loss: 0.009827434085309505\n",
      "Iteration: 4206/10000, Loss: 0.012607629410922527\n",
      "Iteration: 4207/10000, Loss: 0.011553850956261158\n",
      "Iteration: 4208/10000, Loss: 0.009750405326485634\n",
      "Iteration: 4209/10000, Loss: 0.0146021144464612\n",
      "Iteration: 4210/10000, Loss: 0.012906312011182308\n",
      "Iteration: 4211/10000, Loss: 0.012812434695661068\n",
      "Iteration: 4212/10000, Loss: 0.023837700486183167\n",
      "Iteration: 4213/10000, Loss: 0.012713815085589886\n",
      "Iteration: 4214/10000, Loss: 0.02255895361304283\n",
      "Iteration: 4215/10000, Loss: 0.01227349042892456\n",
      "Iteration: 4216/10000, Loss: 0.01657913438975811\n",
      "Iteration: 4217/10000, Loss: 0.019217774271965027\n",
      "Iteration: 4218/10000, Loss: 0.017257627099752426\n",
      "Iteration: 4219/10000, Loss: 0.013937427662312984\n",
      "Iteration: 4220/10000, Loss: 0.016477057710289955\n",
      "Iteration: 4221/10000, Loss: 0.017717871814966202\n",
      "Iteration: 4222/10000, Loss: 0.01718245819211006\n",
      "Iteration: 4223/10000, Loss: 0.013997664675116539\n",
      "Iteration: 4224/10000, Loss: 0.017168542370200157\n",
      "Iteration: 4225/10000, Loss: 0.011485490016639233\n",
      "Iteration: 4226/10000, Loss: 0.023568935692310333\n",
      "Iteration: 4227/10000, Loss: 0.013925623148679733\n",
      "Iteration: 4228/10000, Loss: 0.015857871621847153\n",
      "Iteration: 4229/10000, Loss: 0.00988179724663496\n",
      "Iteration: 4230/10000, Loss: 0.014470480382442474\n",
      "Iteration: 4231/10000, Loss: 0.0235335323959589\n",
      "Iteration: 4232/10000, Loss: 0.015778381377458572\n",
      "Iteration: 4233/10000, Loss: 0.015699846670031548\n",
      "Iteration: 4234/10000, Loss: 0.010279117152094841\n",
      "Iteration: 4235/10000, Loss: 0.018420059233903885\n",
      "Iteration: 4236/10000, Loss: 0.024490952491760254\n",
      "Iteration: 4237/10000, Loss: 0.020838001742959023\n",
      "Iteration: 4238/10000, Loss: 0.0227231252938509\n",
      "Iteration: 4239/10000, Loss: 0.014497656375169754\n",
      "Iteration: 4240/10000, Loss: 0.014309621416032314\n",
      "Iteration: 4241/10000, Loss: 0.015242845751345158\n",
      "Iteration: 4242/10000, Loss: 0.016247374936938286\n",
      "Iteration: 4243/10000, Loss: 0.012301222421228886\n",
      "Iteration: 4244/10000, Loss: 0.009438698180019855\n",
      "Iteration: 4245/10000, Loss: 0.013032197020947933\n",
      "Iteration: 4246/10000, Loss: 0.013359349220991135\n",
      "Iteration: 4247/10000, Loss: 0.016069408506155014\n",
      "Iteration: 4248/10000, Loss: 0.01191036868840456\n",
      "Iteration: 4249/10000, Loss: 0.015596846118569374\n",
      "Iteration: 4250/10000, Loss: 0.007307075895369053\n",
      "Iteration: 4251/10000, Loss: 0.014367958530783653\n",
      "Iteration: 4252/10000, Loss: 0.012224451638758183\n",
      "Iteration: 4253/10000, Loss: 0.0167244803160429\n",
      "Iteration: 4254/10000, Loss: 0.009491292759776115\n",
      "Iteration: 4255/10000, Loss: 0.011945408768951893\n",
      "Iteration: 4256/10000, Loss: 0.0090684425085783\n",
      "Iteration: 4257/10000, Loss: 0.014657029882073402\n",
      "Iteration: 4258/10000, Loss: 0.015402812510728836\n",
      "Iteration: 4259/10000, Loss: 0.012670422904193401\n",
      "Iteration: 4260/10000, Loss: 0.014890576712787151\n",
      "Iteration: 4261/10000, Loss: 0.012070461176335812\n",
      "Iteration: 4262/10000, Loss: 0.013353616930544376\n",
      "Iteration: 4263/10000, Loss: 0.009777102619409561\n",
      "Iteration: 4264/10000, Loss: 0.015703249722719193\n",
      "Iteration: 4265/10000, Loss: 0.02024981752038002\n",
      "Iteration: 4266/10000, Loss: 0.014864950440824032\n",
      "Iteration: 4267/10000, Loss: 0.016960838809609413\n",
      "Iteration: 4268/10000, Loss: 0.012703755870461464\n",
      "Iteration: 4269/10000, Loss: 0.006891459692269564\n",
      "Iteration: 4270/10000, Loss: 0.018506266176700592\n",
      "Iteration: 4271/10000, Loss: 0.020504025742411613\n",
      "Iteration: 4272/10000, Loss: 0.016072699800133705\n",
      "Iteration: 4273/10000, Loss: 0.014820126816630363\n",
      "Iteration: 4274/10000, Loss: 0.016548529267311096\n",
      "Iteration: 4275/10000, Loss: 0.016325047239661217\n",
      "Iteration: 4276/10000, Loss: 0.013740912079811096\n",
      "Iteration: 4277/10000, Loss: 0.013307134620845318\n",
      "Iteration: 4278/10000, Loss: 0.018778914585709572\n",
      "Iteration: 4279/10000, Loss: 0.020122574642300606\n",
      "Iteration: 4280/10000, Loss: 0.013225533999502659\n",
      "Iteration: 4281/10000, Loss: 0.010273061692714691\n",
      "Iteration: 4282/10000, Loss: 0.016796262934803963\n",
      "Iteration: 4283/10000, Loss: 0.015399545431137085\n",
      "Iteration: 4284/10000, Loss: 0.016671374440193176\n",
      "Iteration: 4285/10000, Loss: 0.012477877549827099\n",
      "Iteration: 4286/10000, Loss: 0.020337948575615883\n",
      "Iteration: 4287/10000, Loss: 0.020565595477819443\n",
      "Iteration: 4288/10000, Loss: 0.01265898160636425\n",
      "Iteration: 4289/10000, Loss: 0.014379101805388927\n",
      "Iteration: 4290/10000, Loss: 0.015312423929572105\n",
      "Iteration: 4291/10000, Loss: 0.02255997620522976\n",
      "Iteration: 4292/10000, Loss: 0.01712144911289215\n",
      "Iteration: 4293/10000, Loss: 0.014074936509132385\n",
      "Iteration: 4294/10000, Loss: 0.013541389256715775\n",
      "Iteration: 4295/10000, Loss: 0.017026109620928764\n",
      "Iteration: 4296/10000, Loss: 0.018486017361283302\n",
      "Iteration: 4297/10000, Loss: 0.01713603176176548\n",
      "Iteration: 4298/10000, Loss: 0.01041078008711338\n",
      "Iteration: 4299/10000, Loss: 0.007612967398017645\n",
      "Iteration: 4300/10000, Loss: 0.01308563444763422\n",
      "Average test loss:  0.0018\n",
      "Iteration: 4301/10000, Loss: 0.018284127116203308\n",
      "Iteration: 4302/10000, Loss: 0.02139098569750786\n",
      "Iteration: 4303/10000, Loss: 0.013786828145384789\n",
      "Iteration: 4304/10000, Loss: 0.01140195969492197\n",
      "Iteration: 4305/10000, Loss: 0.020170532166957855\n",
      "Iteration: 4306/10000, Loss: 0.02242293395102024\n",
      "Iteration: 4307/10000, Loss: 0.010297989472746849\n",
      "Iteration: 4308/10000, Loss: 0.016265902668237686\n",
      "Iteration: 4309/10000, Loss: 0.016053082421422005\n",
      "Iteration: 4310/10000, Loss: 0.013103003613650799\n",
      "Iteration: 4311/10000, Loss: 0.010609894059598446\n",
      "Iteration: 4312/10000, Loss: 0.014936008490622044\n",
      "Iteration: 4313/10000, Loss: 0.012440765276551247\n",
      "Iteration: 4314/10000, Loss: 0.02105603739619255\n",
      "Iteration: 4315/10000, Loss: 0.011187002994120121\n",
      "Iteration: 4316/10000, Loss: 0.016954364255070686\n",
      "Iteration: 4317/10000, Loss: 0.01696065440773964\n",
      "Iteration: 4318/10000, Loss: 0.02142985723912716\n",
      "Iteration: 4319/10000, Loss: 0.018967917189002037\n",
      "Iteration: 4320/10000, Loss: 0.01886521466076374\n",
      "Iteration: 4321/10000, Loss: 0.018028780817985535\n",
      "Iteration: 4322/10000, Loss: 0.020152168348431587\n",
      "Iteration: 4323/10000, Loss: 0.015182005241513252\n",
      "Iteration: 4324/10000, Loss: 0.018803652375936508\n",
      "Iteration: 4325/10000, Loss: 0.021282361820340157\n",
      "Iteration: 4326/10000, Loss: 0.014823269098997116\n",
      "Iteration: 4327/10000, Loss: 0.012324061244726181\n",
      "Iteration: 4328/10000, Loss: 0.010354992933571339\n",
      "Iteration: 4329/10000, Loss: 0.016970600932836533\n",
      "Iteration: 4330/10000, Loss: 0.0187910795211792\n",
      "Iteration: 4331/10000, Loss: 0.013835850171744823\n",
      "Iteration: 4332/10000, Loss: 0.011596701107919216\n",
      "Iteration: 4333/10000, Loss: 0.014441397041082382\n",
      "Iteration: 4334/10000, Loss: 0.01982412114739418\n",
      "Iteration: 4335/10000, Loss: 0.01680835522711277\n",
      "Iteration: 4336/10000, Loss: 0.008687441237270832\n",
      "Iteration: 4337/10000, Loss: 0.022221548482775688\n",
      "Iteration: 4338/10000, Loss: 0.006607792805880308\n",
      "Iteration: 4339/10000, Loss: 0.012714900076389313\n",
      "Iteration: 4340/10000, Loss: 0.011526821181178093\n",
      "Iteration: 4341/10000, Loss: 0.013586100190877914\n",
      "Iteration: 4342/10000, Loss: 0.018687188625335693\n",
      "Iteration: 4343/10000, Loss: 0.017390022054314613\n",
      "Iteration: 4344/10000, Loss: 0.01617460697889328\n",
      "Iteration: 4345/10000, Loss: 0.019804291427135468\n",
      "Iteration: 4346/10000, Loss: 0.01522806379944086\n",
      "Iteration: 4347/10000, Loss: 0.014979117549955845\n",
      "Iteration: 4348/10000, Loss: 0.013028813526034355\n",
      "Iteration: 4349/10000, Loss: 0.010570384562015533\n",
      "Iteration: 4350/10000, Loss: 0.012454102747142315\n",
      "Iteration: 4351/10000, Loss: 0.011653263121843338\n",
      "Iteration: 4352/10000, Loss: 0.019629064947366714\n",
      "Iteration: 4353/10000, Loss: 0.0192424189299345\n",
      "Iteration: 4354/10000, Loss: 0.014672592282295227\n",
      "Iteration: 4355/10000, Loss: 0.017398914322257042\n",
      "Iteration: 4356/10000, Loss: 0.020761331543326378\n",
      "Iteration: 4357/10000, Loss: 0.01518357452005148\n",
      "Iteration: 4358/10000, Loss: 0.014121792279183865\n",
      "Iteration: 4359/10000, Loss: 0.013435570523142815\n",
      "Iteration: 4360/10000, Loss: 0.022252298891544342\n",
      "Iteration: 4361/10000, Loss: 0.02050967700779438\n",
      "Iteration: 4362/10000, Loss: 0.0143395084887743\n",
      "Iteration: 4363/10000, Loss: 0.020310241729021072\n",
      "Iteration: 4364/10000, Loss: 0.01501102652400732\n",
      "Iteration: 4365/10000, Loss: 0.016641680151224136\n",
      "Iteration: 4366/10000, Loss: 0.02399175986647606\n",
      "Iteration: 4367/10000, Loss: 0.011468098498880863\n",
      "Iteration: 4368/10000, Loss: 0.016648905351758003\n",
      "Iteration: 4369/10000, Loss: 0.010245407931506634\n",
      "Iteration: 4370/10000, Loss: 0.020174555480480194\n",
      "Iteration: 4371/10000, Loss: 0.014597942121326923\n",
      "Iteration: 4372/10000, Loss: 0.015108440071344376\n",
      "Iteration: 4373/10000, Loss: 0.017705537378787994\n",
      "Iteration: 4374/10000, Loss: 0.022030595690011978\n",
      "Iteration: 4375/10000, Loss: 0.016927052289247513\n",
      "Iteration: 4376/10000, Loss: 0.016870001330971718\n",
      "Iteration: 4377/10000, Loss: 0.014063521288335323\n",
      "Iteration: 4378/10000, Loss: 0.013302979990839958\n",
      "Iteration: 4379/10000, Loss: 0.020659849047660828\n",
      "Iteration: 4380/10000, Loss: 0.02134985662996769\n",
      "Iteration: 4381/10000, Loss: 0.01928175799548626\n",
      "Iteration: 4382/10000, Loss: 0.017327656969428062\n",
      "Iteration: 4383/10000, Loss: 0.021683337166905403\n",
      "Iteration: 4384/10000, Loss: 0.016660843044519424\n",
      "Iteration: 4385/10000, Loss: 0.0207835603505373\n",
      "Iteration: 4386/10000, Loss: 0.013453144580125809\n",
      "Iteration: 4387/10000, Loss: 0.012098604813218117\n",
      "Iteration: 4388/10000, Loss: 0.02033337764441967\n",
      "Iteration: 4389/10000, Loss: 0.01956186257302761\n",
      "Iteration: 4390/10000, Loss: 0.011762557551264763\n",
      "Iteration: 4391/10000, Loss: 0.018643466755747795\n",
      "Iteration: 4392/10000, Loss: 0.01588861271739006\n",
      "Iteration: 4393/10000, Loss: 0.0156782865524292\n",
      "Iteration: 4394/10000, Loss: 0.016784792765975\n",
      "Iteration: 4395/10000, Loss: 0.012213199399411678\n",
      "Iteration: 4396/10000, Loss: 0.017070217058062553\n",
      "Iteration: 4397/10000, Loss: 0.016941996291279793\n",
      "Iteration: 4398/10000, Loss: 0.015709588304162025\n",
      "Iteration: 4399/10000, Loss: 0.013110125437378883\n",
      "Iteration: 4400/10000, Loss: 0.012277333065867424\n",
      "Average test loss:  0.0037\n",
      "Iteration: 4401/10000, Loss: 0.014646646566689014\n",
      "Iteration: 4402/10000, Loss: 0.014126860536634922\n",
      "Iteration: 4403/10000, Loss: 0.01754506677389145\n",
      "Iteration: 4404/10000, Loss: 0.016563471406698227\n",
      "Iteration: 4405/10000, Loss: 0.01589207910001278\n",
      "Iteration: 4406/10000, Loss: 0.017469821497797966\n",
      "Iteration: 4407/10000, Loss: 0.017218749970197678\n",
      "Iteration: 4408/10000, Loss: 0.016647618263959885\n",
      "Iteration: 4409/10000, Loss: 0.0070649501867592335\n",
      "Iteration: 4410/10000, Loss: 0.011778686195611954\n",
      "Iteration: 4411/10000, Loss: 0.014947613701224327\n",
      "Iteration: 4412/10000, Loss: 0.010446962900459766\n",
      "Iteration: 4413/10000, Loss: 0.014845785684883595\n",
      "Iteration: 4414/10000, Loss: 0.011284583248198032\n",
      "Iteration: 4415/10000, Loss: 0.019721215590834618\n",
      "Iteration: 4416/10000, Loss: 0.012573622167110443\n",
      "Iteration: 4417/10000, Loss: 0.019217565655708313\n",
      "Iteration: 4418/10000, Loss: 0.018141265958547592\n",
      "Iteration: 4419/10000, Loss: 0.017310338094830513\n",
      "Iteration: 4420/10000, Loss: 0.015986870974302292\n",
      "Iteration: 4421/10000, Loss: 0.01460838969796896\n",
      "Iteration: 4422/10000, Loss: 0.019685758277773857\n",
      "Iteration: 4423/10000, Loss: 0.010745988227427006\n",
      "Iteration: 4424/10000, Loss: 0.02126964181661606\n",
      "Iteration: 4425/10000, Loss: 0.0158587247133255\n",
      "Iteration: 4426/10000, Loss: 0.008505637757480145\n",
      "Iteration: 4427/10000, Loss: 0.011013349518179893\n",
      "Iteration: 4428/10000, Loss: 0.01866866461932659\n",
      "Iteration: 4429/10000, Loss: 0.01148253958672285\n",
      "Iteration: 4430/10000, Loss: 0.008154122158885002\n",
      "Iteration: 4431/10000, Loss: 0.013670976273715496\n",
      "Iteration: 4432/10000, Loss: 0.013269524089992046\n",
      "Iteration: 4433/10000, Loss: 0.01592748984694481\n",
      "Iteration: 4434/10000, Loss: 0.013207057490944862\n",
      "Iteration: 4435/10000, Loss: 0.010518688708543777\n",
      "Iteration: 4436/10000, Loss: 0.02116747573018074\n",
      "Iteration: 4437/10000, Loss: 0.016541454941034317\n",
      "Iteration: 4438/10000, Loss: 0.024062685668468475\n",
      "Iteration: 4439/10000, Loss: 0.0165545754134655\n",
      "Iteration: 4440/10000, Loss: 0.015253438614308834\n",
      "Iteration: 4441/10000, Loss: 0.014574815519154072\n",
      "Iteration: 4442/10000, Loss: 0.01903769187629223\n",
      "Iteration: 4443/10000, Loss: 0.020853612571954727\n",
      "Iteration: 4444/10000, Loss: 0.016347413882613182\n",
      "Iteration: 4445/10000, Loss: 0.01622861810028553\n",
      "Iteration: 4446/10000, Loss: 0.013963291421532631\n",
      "Iteration: 4447/10000, Loss: 0.015519298613071442\n",
      "Iteration: 4448/10000, Loss: 0.01678077131509781\n",
      "Iteration: 4449/10000, Loss: 0.014085990376770496\n",
      "Iteration: 4450/10000, Loss: 0.018505960702896118\n",
      "Iteration: 4451/10000, Loss: 0.011113317683339119\n",
      "Iteration: 4452/10000, Loss: 0.01352128479629755\n",
      "Iteration: 4453/10000, Loss: 0.013437350280582905\n",
      "Iteration: 4454/10000, Loss: 0.008414563722908497\n",
      "Iteration: 4455/10000, Loss: 0.012416621670126915\n",
      "Iteration: 4456/10000, Loss: 0.01520034484565258\n",
      "Iteration: 4457/10000, Loss: 0.010385256260633469\n",
      "Iteration: 4458/10000, Loss: 0.014466256834566593\n",
      "Iteration: 4459/10000, Loss: 0.013088708743453026\n",
      "Iteration: 4460/10000, Loss: 0.019363930448889732\n",
      "Iteration: 4461/10000, Loss: 0.015131426975131035\n",
      "Iteration: 4462/10000, Loss: 0.021265512332320213\n",
      "Iteration: 4463/10000, Loss: 0.014726524241268635\n",
      "Iteration: 4464/10000, Loss: 0.017641810700297356\n",
      "Iteration: 4465/10000, Loss: 0.016992084681987762\n",
      "Iteration: 4466/10000, Loss: 0.012522709555923939\n",
      "Iteration: 4467/10000, Loss: 0.01603332906961441\n",
      "Iteration: 4468/10000, Loss: 0.017334748059511185\n",
      "Iteration: 4469/10000, Loss: 0.018702803179621696\n",
      "Iteration: 4470/10000, Loss: 0.011422180570662022\n",
      "Iteration: 4471/10000, Loss: 0.011190198361873627\n",
      "Iteration: 4472/10000, Loss: 0.01408959086984396\n",
      "Iteration: 4473/10000, Loss: 0.007756478618830442\n",
      "Iteration: 4474/10000, Loss: 0.01985759288072586\n",
      "Iteration: 4475/10000, Loss: 0.020079534500837326\n",
      "Iteration: 4476/10000, Loss: 0.015527474693953991\n",
      "Iteration: 4477/10000, Loss: 0.014621291309595108\n",
      "Iteration: 4478/10000, Loss: 0.014350620098412037\n",
      "Iteration: 4479/10000, Loss: 0.013675997965037823\n",
      "Iteration: 4480/10000, Loss: 0.014885124750435352\n",
      "Iteration: 4481/10000, Loss: 0.016774719581007957\n",
      "Iteration: 4482/10000, Loss: 0.011985424906015396\n",
      "Iteration: 4483/10000, Loss: 0.01885637268424034\n",
      "Iteration: 4484/10000, Loss: 0.013659716583788395\n",
      "Iteration: 4485/10000, Loss: 0.016196854412555695\n",
      "Iteration: 4486/10000, Loss: 0.007147299591451883\n",
      "Iteration: 4487/10000, Loss: 0.012093444354832172\n",
      "Iteration: 4488/10000, Loss: 0.019676238298416138\n",
      "Iteration: 4489/10000, Loss: 0.009573650546371937\n",
      "Iteration: 4490/10000, Loss: 0.013493015430867672\n",
      "Iteration: 4491/10000, Loss: 0.010609460063278675\n",
      "Iteration: 4492/10000, Loss: 0.017162779346108437\n",
      "Iteration: 4493/10000, Loss: 0.012093815952539444\n",
      "Iteration: 4494/10000, Loss: 0.010327136144042015\n",
      "Iteration: 4495/10000, Loss: 0.015033413656055927\n",
      "Iteration: 4496/10000, Loss: 0.016939252614974976\n",
      "Iteration: 4497/10000, Loss: 0.010697535239160061\n",
      "Iteration: 4498/10000, Loss: 0.012027011252939701\n",
      "Iteration: 4499/10000, Loss: 0.013107131235301495\n",
      "Iteration: 4500/10000, Loss: 0.017086751759052277\n",
      "Average test loss:  0.0032\n",
      "Iteration: 4501/10000, Loss: 0.011380326002836227\n",
      "Iteration: 4502/10000, Loss: 0.019674019888043404\n",
      "Iteration: 4503/10000, Loss: 0.015106230042874813\n",
      "Iteration: 4504/10000, Loss: 0.017338989302515984\n",
      "Iteration: 4505/10000, Loss: 0.019414560869336128\n",
      "Iteration: 4506/10000, Loss: 0.012186652049422264\n",
      "Iteration: 4507/10000, Loss: 0.017917800694704056\n",
      "Iteration: 4508/10000, Loss: 0.013489185832440853\n",
      "Iteration: 4509/10000, Loss: 0.020645489916205406\n",
      "Iteration: 4510/10000, Loss: 0.013370019383728504\n",
      "Iteration: 4511/10000, Loss: 0.014268327504396439\n",
      "Iteration: 4512/10000, Loss: 0.011249848641455173\n",
      "Iteration: 4513/10000, Loss: 0.018482254818081856\n",
      "Iteration: 4514/10000, Loss: 0.015403365716338158\n",
      "Iteration: 4515/10000, Loss: 0.009480674751102924\n",
      "Iteration: 4516/10000, Loss: 0.016775960102677345\n",
      "Iteration: 4517/10000, Loss: 0.013647261075675488\n",
      "Iteration: 4518/10000, Loss: 0.010647076182067394\n",
      "Iteration: 4519/10000, Loss: 0.011398055590689182\n",
      "Iteration: 4520/10000, Loss: 0.016261940822005272\n",
      "Iteration: 4521/10000, Loss: 0.02000746689736843\n",
      "Iteration: 4522/10000, Loss: 0.011962019838392735\n",
      "Iteration: 4523/10000, Loss: 0.013192007318139076\n",
      "Iteration: 4524/10000, Loss: 0.013615017756819725\n",
      "Iteration: 4525/10000, Loss: 0.016920244321227074\n",
      "Iteration: 4526/10000, Loss: 0.012561999261379242\n",
      "Iteration: 4527/10000, Loss: 0.01412440650165081\n",
      "Iteration: 4528/10000, Loss: 0.014594065956771374\n",
      "Iteration: 4529/10000, Loss: 0.013307209126651287\n",
      "Iteration: 4530/10000, Loss: 0.017337340861558914\n",
      "Iteration: 4531/10000, Loss: 0.01724419556558132\n",
      "Iteration: 4532/10000, Loss: 0.020851321518421173\n",
      "Iteration: 4533/10000, Loss: 0.014551474712789059\n",
      "Iteration: 4534/10000, Loss: 0.014895155094563961\n",
      "Iteration: 4535/10000, Loss: 0.014663850888609886\n",
      "Iteration: 4536/10000, Loss: 0.01359755638986826\n",
      "Iteration: 4537/10000, Loss: 0.011583192273974419\n",
      "Iteration: 4538/10000, Loss: 0.01619674824178219\n",
      "Iteration: 4539/10000, Loss: 0.020945845171809196\n",
      "Iteration: 4540/10000, Loss: 0.01194810587912798\n",
      "Iteration: 4541/10000, Loss: 0.014249029569327831\n",
      "Iteration: 4542/10000, Loss: 0.01578914187848568\n",
      "Iteration: 4543/10000, Loss: 0.014256917871534824\n",
      "Iteration: 4544/10000, Loss: 0.011499021202325821\n",
      "Iteration: 4545/10000, Loss: 0.0184201467782259\n",
      "Iteration: 4546/10000, Loss: 0.01979316584765911\n",
      "Iteration: 4547/10000, Loss: 0.014302872121334076\n",
      "Iteration: 4548/10000, Loss: 0.014632441103458405\n",
      "Iteration: 4549/10000, Loss: 0.014097154140472412\n",
      "Iteration: 4550/10000, Loss: 0.013362131081521511\n",
      "Iteration: 4551/10000, Loss: 0.018331117928028107\n",
      "Iteration: 4552/10000, Loss: 0.015669265761971474\n",
      "Iteration: 4553/10000, Loss: 0.02258547767996788\n",
      "Iteration: 4554/10000, Loss: 0.013706071302294731\n",
      "Iteration: 4555/10000, Loss: 0.01864067278802395\n",
      "Iteration: 4556/10000, Loss: 0.012293698266148567\n",
      "Iteration: 4557/10000, Loss: 0.016521258279681206\n",
      "Iteration: 4558/10000, Loss: 0.01576361432671547\n",
      "Iteration: 4559/10000, Loss: 0.014966243878006935\n",
      "Iteration: 4560/10000, Loss: 0.0133534399792552\n",
      "Iteration: 4561/10000, Loss: 0.02515985630452633\n",
      "Iteration: 4562/10000, Loss: 0.016435246914625168\n",
      "Iteration: 4563/10000, Loss: 0.011294811964035034\n",
      "Iteration: 4564/10000, Loss: 0.023094434291124344\n",
      "Iteration: 4565/10000, Loss: 0.01063899602741003\n",
      "Iteration: 4566/10000, Loss: 0.014585616067051888\n",
      "Iteration: 4567/10000, Loss: 0.018759069964289665\n",
      "Iteration: 4568/10000, Loss: 0.0168574508279562\n",
      "Iteration: 4569/10000, Loss: 0.01567840948700905\n",
      "Iteration: 4570/10000, Loss: 0.015729745849967003\n",
      "Iteration: 4571/10000, Loss: 0.01216164045035839\n",
      "Iteration: 4572/10000, Loss: 0.014040268957614899\n",
      "Iteration: 4573/10000, Loss: 0.010145067237317562\n",
      "Iteration: 4574/10000, Loss: 0.007245272863656282\n",
      "Iteration: 4575/10000, Loss: 0.02172163687646389\n",
      "Iteration: 4576/10000, Loss: 0.017458811402320862\n",
      "Iteration: 4577/10000, Loss: 0.01297811046242714\n",
      "Iteration: 4578/10000, Loss: 0.01324143074452877\n",
      "Iteration: 4579/10000, Loss: 0.011049040593206882\n",
      "Iteration: 4580/10000, Loss: 0.011761070229113102\n",
      "Iteration: 4581/10000, Loss: 0.010614141821861267\n",
      "Iteration: 4582/10000, Loss: 0.00886416994035244\n",
      "Iteration: 4583/10000, Loss: 0.018439892679452896\n",
      "Iteration: 4584/10000, Loss: 0.015052425675094128\n",
      "Iteration: 4585/10000, Loss: 0.01696261391043663\n",
      "Iteration: 4586/10000, Loss: 0.02026227116584778\n",
      "Iteration: 4587/10000, Loss: 0.012297025881707668\n",
      "Iteration: 4588/10000, Loss: 0.013254129327833652\n",
      "Iteration: 4589/10000, Loss: 0.007666300516575575\n",
      "Iteration: 4590/10000, Loss: 0.01829022355377674\n",
      "Iteration: 4591/10000, Loss: 0.019373513758182526\n",
      "Iteration: 4592/10000, Loss: 0.009748012758791447\n",
      "Iteration: 4593/10000, Loss: 0.013301800936460495\n",
      "Iteration: 4594/10000, Loss: 0.017965905368328094\n",
      "Iteration: 4595/10000, Loss: 0.01597624644637108\n",
      "Iteration: 4596/10000, Loss: 0.020183654502034187\n",
      "Iteration: 4597/10000, Loss: 0.017994651570916176\n",
      "Iteration: 4598/10000, Loss: 0.01967492140829563\n",
      "Iteration: 4599/10000, Loss: 0.011931919492781162\n",
      "Iteration: 4600/10000, Loss: 0.013553189113736153\n",
      "Average test loss:  0.0027\n",
      "Iteration: 4601/10000, Loss: 0.020896203815937042\n",
      "Iteration: 4602/10000, Loss: 0.01835613325238228\n",
      "Iteration: 4603/10000, Loss: 0.016249768435955048\n",
      "Iteration: 4604/10000, Loss: 0.013018791563808918\n",
      "Iteration: 4605/10000, Loss: 0.017029067501425743\n",
      "Iteration: 4606/10000, Loss: 0.01569228619337082\n",
      "Iteration: 4607/10000, Loss: 0.01570879854261875\n",
      "Iteration: 4608/10000, Loss: 0.026422148570418358\n",
      "Iteration: 4609/10000, Loss: 0.014434924349188805\n",
      "Iteration: 4610/10000, Loss: 0.01581001654267311\n",
      "Iteration: 4611/10000, Loss: 0.013284810818731785\n",
      "Iteration: 4612/10000, Loss: 0.015149984508752823\n",
      "Iteration: 4613/10000, Loss: 0.013032379560172558\n",
      "Iteration: 4614/10000, Loss: 0.01449480652809143\n",
      "Iteration: 4615/10000, Loss: 0.01056932657957077\n",
      "Iteration: 4616/10000, Loss: 0.018586844205856323\n",
      "Iteration: 4617/10000, Loss: 0.013751751743257046\n",
      "Iteration: 4618/10000, Loss: 0.014604516327381134\n",
      "Iteration: 4619/10000, Loss: 0.014339536428451538\n",
      "Iteration: 4620/10000, Loss: 0.012501224875450134\n",
      "Iteration: 4621/10000, Loss: 0.019154353067278862\n",
      "Iteration: 4622/10000, Loss: 0.012251614592969418\n",
      "Iteration: 4623/10000, Loss: 0.006809334270656109\n",
      "Iteration: 4624/10000, Loss: 0.010730955749750137\n",
      "Iteration: 4625/10000, Loss: 0.015368408523499966\n",
      "Iteration: 4626/10000, Loss: 0.013441014103591442\n",
      "Iteration: 4627/10000, Loss: 0.016045723110437393\n",
      "Iteration: 4628/10000, Loss: 0.01133657805621624\n",
      "Iteration: 4629/10000, Loss: 0.009300106205046177\n",
      "Iteration: 4630/10000, Loss: 0.012005777098238468\n",
      "Iteration: 4631/10000, Loss: 0.01022148597985506\n",
      "Iteration: 4632/10000, Loss: 0.020301146432757378\n",
      "Iteration: 4633/10000, Loss: 0.013023554347455502\n",
      "Iteration: 4634/10000, Loss: 0.01333299558609724\n",
      "Iteration: 4635/10000, Loss: 0.006784269120544195\n",
      "Iteration: 4636/10000, Loss: 0.016737325116991997\n",
      "Iteration: 4637/10000, Loss: 0.021018533036112785\n",
      "Iteration: 4638/10000, Loss: 0.014924752525985241\n",
      "Iteration: 4639/10000, Loss: 0.01561544556170702\n",
      "Iteration: 4640/10000, Loss: 0.017854416742920876\n",
      "Iteration: 4641/10000, Loss: 0.016166046261787415\n",
      "Iteration: 4642/10000, Loss: 0.015992222353816032\n",
      "Iteration: 4643/10000, Loss: 0.0157889723777771\n",
      "Iteration: 4644/10000, Loss: 0.0086243636906147\n",
      "Iteration: 4645/10000, Loss: 0.013637585565447807\n",
      "Iteration: 4646/10000, Loss: 0.018463976681232452\n",
      "Iteration: 4647/10000, Loss: 0.018160806968808174\n",
      "Iteration: 4648/10000, Loss: 0.014718118123710155\n",
      "Iteration: 4649/10000, Loss: 0.015335319563746452\n",
      "Iteration: 4650/10000, Loss: 0.010614627040922642\n",
      "Iteration: 4651/10000, Loss: 0.011274727061390877\n",
      "Iteration: 4652/10000, Loss: 0.011122386902570724\n",
      "Iteration: 4653/10000, Loss: 0.013439931906759739\n",
      "Iteration: 4654/10000, Loss: 0.011966356076300144\n",
      "Iteration: 4655/10000, Loss: 0.014630568213760853\n",
      "Iteration: 4656/10000, Loss: 0.015441915951669216\n",
      "Iteration: 4657/10000, Loss: 0.011072230525314808\n",
      "Iteration: 4658/10000, Loss: 0.013109087012708187\n",
      "Iteration: 4659/10000, Loss: 0.015459191054105759\n",
      "Iteration: 4660/10000, Loss: 0.012765494175255299\n",
      "Iteration: 4661/10000, Loss: 0.0135509567335248\n",
      "Iteration: 4662/10000, Loss: 0.017179686576128006\n",
      "Iteration: 4663/10000, Loss: 0.01562686637043953\n",
      "Iteration: 4664/10000, Loss: 0.016063451766967773\n",
      "Iteration: 4665/10000, Loss: 0.01439101155847311\n",
      "Iteration: 4666/10000, Loss: 0.01050149742513895\n",
      "Iteration: 4667/10000, Loss: 0.018728869035840034\n",
      "Iteration: 4668/10000, Loss: 0.021510543301701546\n",
      "Iteration: 4669/10000, Loss: 0.012112105265259743\n",
      "Iteration: 4670/10000, Loss: 0.010812735185027122\n",
      "Iteration: 4671/10000, Loss: 0.009508264251053333\n",
      "Iteration: 4672/10000, Loss: 0.01539292000234127\n",
      "Iteration: 4673/10000, Loss: 0.010009286925196648\n",
      "Iteration: 4674/10000, Loss: 0.01394630316644907\n",
      "Iteration: 4675/10000, Loss: 0.011386091820895672\n",
      "Iteration: 4676/10000, Loss: 0.014316138811409473\n",
      "Iteration: 4677/10000, Loss: 0.019866162911057472\n",
      "Iteration: 4678/10000, Loss: 0.015841279178857803\n",
      "Iteration: 4679/10000, Loss: 0.007307250984013081\n",
      "Iteration: 4680/10000, Loss: 0.012969550676643848\n",
      "Iteration: 4681/10000, Loss: 0.013093631714582443\n",
      "Iteration: 4682/10000, Loss: 0.01543099619448185\n",
      "Iteration: 4683/10000, Loss: 0.012693325988948345\n",
      "Iteration: 4684/10000, Loss: 0.01769646629691124\n",
      "Iteration: 4685/10000, Loss: 0.012943561188876629\n",
      "Iteration: 4686/10000, Loss: 0.010407686233520508\n",
      "Iteration: 4687/10000, Loss: 0.0113269854336977\n",
      "Iteration: 4688/10000, Loss: 0.020684007555246353\n",
      "Iteration: 4689/10000, Loss: 0.012753929942846298\n",
      "Iteration: 4690/10000, Loss: 0.013637639582157135\n",
      "Iteration: 4691/10000, Loss: 0.010292312130331993\n",
      "Iteration: 4692/10000, Loss: 0.0124711524695158\n",
      "Iteration: 4693/10000, Loss: 0.012726176530122757\n",
      "Iteration: 4694/10000, Loss: 0.020121993497014046\n",
      "Iteration: 4695/10000, Loss: 0.01252678968012333\n",
      "Iteration: 4696/10000, Loss: 0.00850953720510006\n",
      "Iteration: 4697/10000, Loss: 0.018578726798295975\n",
      "Iteration: 4698/10000, Loss: 0.011537601239979267\n",
      "Iteration: 4699/10000, Loss: 0.014356820844113827\n",
      "Iteration: 4700/10000, Loss: 0.010146855376660824\n",
      "Average test loss:  0.0014\n",
      "Iteration: 4701/10000, Loss: 0.01344056986272335\n",
      "Iteration: 4702/10000, Loss: 0.014173959381878376\n",
      "Iteration: 4703/10000, Loss: 0.014819839969277382\n",
      "Iteration: 4704/10000, Loss: 0.017812972888350487\n",
      "Iteration: 4705/10000, Loss: 0.01164267212152481\n",
      "Iteration: 4706/10000, Loss: 0.020635878667235374\n",
      "Iteration: 4707/10000, Loss: 0.016105495393276215\n",
      "Iteration: 4708/10000, Loss: 0.013491523452103138\n",
      "Iteration: 4709/10000, Loss: 0.011538946069777012\n",
      "Iteration: 4710/10000, Loss: 0.015722138807177544\n",
      "Iteration: 4711/10000, Loss: 0.0120617114007473\n",
      "Iteration: 4712/10000, Loss: 0.01341901533305645\n",
      "Iteration: 4713/10000, Loss: 0.017104053869843483\n",
      "Iteration: 4714/10000, Loss: 0.015071791596710682\n",
      "Iteration: 4715/10000, Loss: 0.013517655432224274\n",
      "Iteration: 4716/10000, Loss: 0.013767099007964134\n",
      "Iteration: 4717/10000, Loss: 0.023143194615840912\n",
      "Iteration: 4718/10000, Loss: 0.019181814044713974\n",
      "Iteration: 4719/10000, Loss: 0.012186168693006039\n",
      "Iteration: 4720/10000, Loss: 0.014133460819721222\n",
      "Iteration: 4721/10000, Loss: 0.01065164152532816\n",
      "Iteration: 4722/10000, Loss: 0.015259209088981152\n",
      "Iteration: 4723/10000, Loss: 0.02011628821492195\n",
      "Iteration: 4724/10000, Loss: 0.009685016237199306\n",
      "Iteration: 4725/10000, Loss: 0.018916135653853416\n",
      "Iteration: 4726/10000, Loss: 0.012037370353937149\n",
      "Iteration: 4727/10000, Loss: 0.012519095093011856\n",
      "Iteration: 4728/10000, Loss: 0.016472890973091125\n",
      "Iteration: 4729/10000, Loss: 0.021190591156482697\n",
      "Iteration: 4730/10000, Loss: 0.01011341717094183\n",
      "Iteration: 4731/10000, Loss: 0.012937281280755997\n",
      "Iteration: 4732/10000, Loss: 0.014948023483157158\n",
      "Iteration: 4733/10000, Loss: 0.017754800617694855\n",
      "Iteration: 4734/10000, Loss: 0.014269650913774967\n",
      "Iteration: 4735/10000, Loss: 0.012497348710894585\n",
      "Iteration: 4736/10000, Loss: 0.014628556556999683\n",
      "Iteration: 4737/10000, Loss: 0.02219773828983307\n",
      "Iteration: 4738/10000, Loss: 0.013364889658987522\n",
      "Iteration: 4739/10000, Loss: 0.01046881265938282\n",
      "Iteration: 4740/10000, Loss: 0.011813003569841385\n",
      "Iteration: 4741/10000, Loss: 0.020695911720395088\n",
      "Iteration: 4742/10000, Loss: 0.014918112196028233\n",
      "Iteration: 4743/10000, Loss: 0.01674085482954979\n",
      "Iteration: 4744/10000, Loss: 0.01786121353507042\n",
      "Iteration: 4745/10000, Loss: 0.014639993198215961\n",
      "Iteration: 4746/10000, Loss: 0.009138190187513828\n",
      "Iteration: 4747/10000, Loss: 0.01847691461443901\n",
      "Iteration: 4748/10000, Loss: 0.01326669380068779\n",
      "Iteration: 4749/10000, Loss: 0.014335633255541325\n",
      "Iteration: 4750/10000, Loss: 0.014683740213513374\n",
      "Iteration: 4751/10000, Loss: 0.014311762526631355\n",
      "Iteration: 4752/10000, Loss: 0.01182381808757782\n",
      "Iteration: 4753/10000, Loss: 0.01500648818910122\n",
      "Iteration: 4754/10000, Loss: 0.01053523551672697\n",
      "Iteration: 4755/10000, Loss: 0.018405407667160034\n",
      "Iteration: 4756/10000, Loss: 0.01597227342426777\n",
      "Iteration: 4757/10000, Loss: 0.015112538821995258\n",
      "Iteration: 4758/10000, Loss: 0.013637766242027283\n",
      "Iteration: 4759/10000, Loss: 0.012717574834823608\n",
      "Iteration: 4760/10000, Loss: 0.01353631541132927\n",
      "Iteration: 4761/10000, Loss: 0.008773024193942547\n",
      "Iteration: 4762/10000, Loss: 0.014451239258050919\n",
      "Iteration: 4763/10000, Loss: 0.013816026039421558\n",
      "Iteration: 4764/10000, Loss: 0.015419582836329937\n",
      "Iteration: 4765/10000, Loss: 0.010948083363473415\n",
      "Iteration: 4766/10000, Loss: 0.007913786917924881\n",
      "Iteration: 4767/10000, Loss: 0.015173545107245445\n",
      "Iteration: 4768/10000, Loss: 0.013485409319400787\n",
      "Iteration: 4769/10000, Loss: 0.00994402077049017\n",
      "Iteration: 4770/10000, Loss: 0.015412108041346073\n",
      "Iteration: 4771/10000, Loss: 0.011963100172579288\n",
      "Iteration: 4772/10000, Loss: 0.00973602756857872\n",
      "Iteration: 4773/10000, Loss: 0.009109480306506157\n",
      "Iteration: 4774/10000, Loss: 0.014564383774995804\n",
      "Iteration: 4775/10000, Loss: 0.010579646565020084\n",
      "Iteration: 4776/10000, Loss: 0.011724325828254223\n",
      "Iteration: 4777/10000, Loss: 0.0175327155739069\n",
      "Iteration: 4778/10000, Loss: 0.01258227601647377\n",
      "Iteration: 4779/10000, Loss: 0.010921414010226727\n",
      "Iteration: 4780/10000, Loss: 0.011532246135175228\n",
      "Iteration: 4781/10000, Loss: 0.017493657767772675\n",
      "Iteration: 4782/10000, Loss: 0.012373936362564564\n",
      "Iteration: 4783/10000, Loss: 0.01730392314493656\n",
      "Iteration: 4784/10000, Loss: 0.011300519108772278\n",
      "Iteration: 4785/10000, Loss: 0.013680482283234596\n",
      "Iteration: 4786/10000, Loss: 0.009961886331439018\n",
      "Iteration: 4787/10000, Loss: 0.012284285388886929\n",
      "Iteration: 4788/10000, Loss: 0.015669245272874832\n",
      "Iteration: 4789/10000, Loss: 0.009729120880365372\n",
      "Iteration: 4790/10000, Loss: 0.013772129081189632\n",
      "Iteration: 4791/10000, Loss: 0.01844487152993679\n",
      "Iteration: 4792/10000, Loss: 0.019252102822065353\n",
      "Iteration: 4793/10000, Loss: 0.01962128095328808\n",
      "Iteration: 4794/10000, Loss: 0.01577017270028591\n",
      "Iteration: 4795/10000, Loss: 0.013181676156818867\n",
      "Iteration: 4796/10000, Loss: 0.015180977992713451\n",
      "Iteration: 4797/10000, Loss: 0.017040563747286797\n",
      "Iteration: 4798/10000, Loss: 0.016331644728779793\n",
      "Iteration: 4799/10000, Loss: 0.011463380418717861\n",
      "Iteration: 4800/10000, Loss: 0.013531864620745182\n",
      "Average test loss:  0.0018\n",
      "Iteration: 4801/10000, Loss: 0.011678481474518776\n",
      "Iteration: 4802/10000, Loss: 0.015198872424662113\n",
      "Iteration: 4803/10000, Loss: 0.022618446499109268\n",
      "Iteration: 4804/10000, Loss: 0.017591282725334167\n",
      "Iteration: 4805/10000, Loss: 0.015103827230632305\n",
      "Iteration: 4806/10000, Loss: 0.01344230305403471\n",
      "Iteration: 4807/10000, Loss: 0.014184568077325821\n",
      "Iteration: 4808/10000, Loss: 0.014185544103384018\n",
      "Iteration: 4809/10000, Loss: 0.016079504042863846\n",
      "Iteration: 4810/10000, Loss: 0.014796119183301926\n",
      "Iteration: 4811/10000, Loss: 0.019487161189317703\n",
      "Iteration: 4812/10000, Loss: 0.014747489243745804\n",
      "Iteration: 4813/10000, Loss: 0.015317699871957302\n",
      "Iteration: 4814/10000, Loss: 0.011638140305876732\n",
      "Iteration: 4815/10000, Loss: 0.01674359291791916\n",
      "Iteration: 4816/10000, Loss: 0.011131138540804386\n",
      "Iteration: 4817/10000, Loss: 0.020277084782719612\n",
      "Iteration: 4818/10000, Loss: 0.012896155938506126\n",
      "Iteration: 4819/10000, Loss: 0.014299892820417881\n",
      "Iteration: 4820/10000, Loss: 0.01627376116812229\n",
      "Iteration: 4821/10000, Loss: 0.011354164220392704\n",
      "Iteration: 4822/10000, Loss: 0.017669135704636574\n",
      "Iteration: 4823/10000, Loss: 0.016762573271989822\n",
      "Iteration: 4824/10000, Loss: 0.008107482455670834\n",
      "Iteration: 4825/10000, Loss: 0.01781049743294716\n",
      "Iteration: 4826/10000, Loss: 0.01790580525994301\n",
      "Iteration: 4827/10000, Loss: 0.017135629430413246\n",
      "Iteration: 4828/10000, Loss: 0.02275186777114868\n",
      "Iteration: 4829/10000, Loss: 0.012705017812550068\n",
      "Iteration: 4830/10000, Loss: 0.020339706912636757\n",
      "Iteration: 4831/10000, Loss: 0.01281210407614708\n",
      "Iteration: 4832/10000, Loss: 0.016219284385442734\n",
      "Iteration: 4833/10000, Loss: 0.009989471174776554\n",
      "Iteration: 4834/10000, Loss: 0.014449111185967922\n",
      "Iteration: 4835/10000, Loss: 0.00876171886920929\n",
      "Iteration: 4836/10000, Loss: 0.0171031691133976\n",
      "Iteration: 4837/10000, Loss: 0.012242548167705536\n",
      "Iteration: 4838/10000, Loss: 0.016939980909228325\n",
      "Iteration: 4839/10000, Loss: 0.017936980351805687\n",
      "Iteration: 4840/10000, Loss: 0.00982591975480318\n",
      "Iteration: 4841/10000, Loss: 0.016446692869067192\n",
      "Iteration: 4842/10000, Loss: 0.011280018836259842\n",
      "Iteration: 4843/10000, Loss: 0.012981302104890347\n",
      "Iteration: 4844/10000, Loss: 0.013671716675162315\n",
      "Iteration: 4845/10000, Loss: 0.017889151349663734\n",
      "Iteration: 4846/10000, Loss: 0.014564634300768375\n",
      "Iteration: 4847/10000, Loss: 0.01677975244820118\n",
      "Iteration: 4848/10000, Loss: 0.014730066061019897\n",
      "Iteration: 4849/10000, Loss: 0.012995327822864056\n",
      "Iteration: 4850/10000, Loss: 0.013842661865055561\n",
      "Iteration: 4851/10000, Loss: 0.016217190772294998\n",
      "Iteration: 4852/10000, Loss: 0.013478745706379414\n",
      "Iteration: 4853/10000, Loss: 0.015276813879609108\n",
      "Iteration: 4854/10000, Loss: 0.013126712292432785\n",
      "Iteration: 4855/10000, Loss: 0.016846517100930214\n",
      "Iteration: 4856/10000, Loss: 0.01360913272947073\n",
      "Iteration: 4857/10000, Loss: 0.008717773482203484\n",
      "Iteration: 4858/10000, Loss: 0.012307791970670223\n",
      "Iteration: 4859/10000, Loss: 0.0224603321403265\n",
      "Iteration: 4860/10000, Loss: 0.014051263220608234\n",
      "Iteration: 4861/10000, Loss: 0.012519756332039833\n",
      "Iteration: 4862/10000, Loss: 0.012572120875120163\n",
      "Iteration: 4863/10000, Loss: 0.016997046768665314\n",
      "Iteration: 4864/10000, Loss: 0.014754701405763626\n",
      "Iteration: 4865/10000, Loss: 0.01585957407951355\n",
      "Iteration: 4866/10000, Loss: 0.012821799144148827\n",
      "Iteration: 4867/10000, Loss: 0.012069008313119411\n",
      "Iteration: 4868/10000, Loss: 0.017802612856030464\n",
      "Iteration: 4869/10000, Loss: 0.011746370233595371\n",
      "Iteration: 4870/10000, Loss: 0.011638572439551353\n",
      "Iteration: 4871/10000, Loss: 0.016223067417740822\n",
      "Iteration: 4872/10000, Loss: 0.01624520681798458\n",
      "Iteration: 4873/10000, Loss: 0.017851820215582848\n",
      "Iteration: 4874/10000, Loss: 0.014855601824820042\n",
      "Iteration: 4875/10000, Loss: 0.018018456175923347\n",
      "Iteration: 4876/10000, Loss: 0.01041864138096571\n",
      "Iteration: 4877/10000, Loss: 0.012329363264143467\n",
      "Iteration: 4878/10000, Loss: 0.007959901355206966\n",
      "Iteration: 4879/10000, Loss: 0.017893623560667038\n",
      "Iteration: 4880/10000, Loss: 0.010114499367773533\n",
      "Iteration: 4881/10000, Loss: 0.01107477955520153\n",
      "Iteration: 4882/10000, Loss: 0.015046913176774979\n",
      "Iteration: 4883/10000, Loss: 0.016320696100592613\n",
      "Iteration: 4884/10000, Loss: 0.015081433579325676\n",
      "Iteration: 4885/10000, Loss: 0.011399331502616405\n",
      "Iteration: 4886/10000, Loss: 0.01307462714612484\n",
      "Iteration: 4887/10000, Loss: 0.013936321251094341\n",
      "Iteration: 4888/10000, Loss: 0.01915452815592289\n",
      "Iteration: 4889/10000, Loss: 0.013466735370457172\n",
      "Iteration: 4890/10000, Loss: 0.020119931548833847\n",
      "Iteration: 4891/10000, Loss: 0.01380282174795866\n",
      "Iteration: 4892/10000, Loss: 0.015565146692097187\n",
      "Iteration: 4893/10000, Loss: 0.014201276935636997\n",
      "Iteration: 4894/10000, Loss: 0.010938026942312717\n",
      "Iteration: 4895/10000, Loss: 0.01314197201281786\n",
      "Iteration: 4896/10000, Loss: 0.016825011000037193\n",
      "Iteration: 4897/10000, Loss: 0.01334052812308073\n",
      "Iteration: 4898/10000, Loss: 0.01240664441138506\n",
      "Iteration: 4899/10000, Loss: 0.014107422903180122\n",
      "Iteration: 4900/10000, Loss: 0.01522903423756361\n",
      "Average test loss:  0.0026\n",
      "Iteration: 4901/10000, Loss: 0.017295893281698227\n",
      "Iteration: 4902/10000, Loss: 0.007166262716054916\n",
      "Iteration: 4903/10000, Loss: 0.008316058665513992\n",
      "Iteration: 4904/10000, Loss: 0.008519290015101433\n",
      "Iteration: 4905/10000, Loss: 0.014432813972234726\n",
      "Iteration: 4906/10000, Loss: 0.017802365124225616\n",
      "Iteration: 4907/10000, Loss: 0.011943255551159382\n",
      "Iteration: 4908/10000, Loss: 0.01526467315852642\n",
      "Iteration: 4909/10000, Loss: 0.011031870730221272\n",
      "Iteration: 4910/10000, Loss: 0.015262086875736713\n",
      "Iteration: 4911/10000, Loss: 0.01527133397758007\n",
      "Iteration: 4912/10000, Loss: 0.010562391951680183\n",
      "Iteration: 4913/10000, Loss: 0.020812487229704857\n",
      "Iteration: 4914/10000, Loss: 0.011626592837274075\n",
      "Iteration: 4915/10000, Loss: 0.016689227893948555\n",
      "Iteration: 4916/10000, Loss: 0.014089198783040047\n",
      "Iteration: 4917/10000, Loss: 0.012263687327504158\n",
      "Iteration: 4918/10000, Loss: 0.012699577957391739\n",
      "Iteration: 4919/10000, Loss: 0.01169499196112156\n",
      "Iteration: 4920/10000, Loss: 0.014114564284682274\n",
      "Iteration: 4921/10000, Loss: 0.012031464837491512\n",
      "Iteration: 4922/10000, Loss: 0.015904966741800308\n",
      "Iteration: 4923/10000, Loss: 0.011464371345937252\n",
      "Iteration: 4924/10000, Loss: 0.00932591874152422\n",
      "Iteration: 4925/10000, Loss: 0.01021196972578764\n",
      "Iteration: 4926/10000, Loss: 0.022971687838435173\n",
      "Iteration: 4927/10000, Loss: 0.017713868990540504\n",
      "Iteration: 4928/10000, Loss: 0.010548737831413746\n",
      "Iteration: 4929/10000, Loss: 0.014133250340819359\n",
      "Iteration: 4930/10000, Loss: 0.019453782588243484\n",
      "Iteration: 4931/10000, Loss: 0.011464396491646767\n",
      "Iteration: 4932/10000, Loss: 0.015819832682609558\n",
      "Iteration: 4933/10000, Loss: 0.014385406859219074\n",
      "Iteration: 4934/10000, Loss: 0.010755619034171104\n",
      "Iteration: 4935/10000, Loss: 0.02195439673960209\n",
      "Iteration: 4936/10000, Loss: 0.009513854049146175\n",
      "Iteration: 4937/10000, Loss: 0.012938976287841797\n",
      "Iteration: 4938/10000, Loss: 0.009600217454135418\n",
      "Iteration: 4939/10000, Loss: 0.012529210187494755\n",
      "Iteration: 4940/10000, Loss: 0.01303339283913374\n",
      "Iteration: 4941/10000, Loss: 0.017894942313432693\n",
      "Iteration: 4942/10000, Loss: 0.014236043207347393\n",
      "Iteration: 4943/10000, Loss: 0.011851013638079166\n",
      "Iteration: 4944/10000, Loss: 0.02364785596728325\n",
      "Iteration: 4945/10000, Loss: 0.00973645318299532\n",
      "Iteration: 4946/10000, Loss: 0.012144286185503006\n",
      "Iteration: 4947/10000, Loss: 0.013066352345049381\n",
      "Iteration: 4948/10000, Loss: 0.011722384952008724\n",
      "Iteration: 4949/10000, Loss: 0.015820328146219254\n",
      "Iteration: 4950/10000, Loss: 0.00978981051594019\n",
      "Iteration: 4951/10000, Loss: 0.011052923277020454\n",
      "Iteration: 4952/10000, Loss: 0.01743617095053196\n",
      "Iteration: 4953/10000, Loss: 0.008480465039610863\n",
      "Iteration: 4954/10000, Loss: 0.01946124993264675\n",
      "Iteration: 4955/10000, Loss: 0.014651513658463955\n",
      "Iteration: 4956/10000, Loss: 0.019153760746121407\n",
      "Iteration: 4957/10000, Loss: 0.010338096879422665\n",
      "Iteration: 4958/10000, Loss: 0.013378310948610306\n",
      "Iteration: 4959/10000, Loss: 0.011060751974582672\n",
      "Iteration: 4960/10000, Loss: 0.009752340614795685\n",
      "Iteration: 4961/10000, Loss: 0.01116651576012373\n",
      "Iteration: 4962/10000, Loss: 0.019764302298426628\n",
      "Iteration: 4963/10000, Loss: 0.009818422608077526\n",
      "Iteration: 4964/10000, Loss: 0.009088383987545967\n",
      "Iteration: 4965/10000, Loss: 0.02037532813847065\n",
      "Iteration: 4966/10000, Loss: 0.010055774822831154\n",
      "Iteration: 4967/10000, Loss: 0.01987585239112377\n",
      "Iteration: 4968/10000, Loss: 0.013010479509830475\n",
      "Iteration: 4969/10000, Loss: 0.02176983281970024\n",
      "Iteration: 4970/10000, Loss: 0.013861311599612236\n",
      "Iteration: 4971/10000, Loss: 0.015386495739221573\n",
      "Iteration: 4972/10000, Loss: 0.014333638362586498\n",
      "Iteration: 4973/10000, Loss: 0.026281721889972687\n",
      "Iteration: 4974/10000, Loss: 0.01110612228512764\n",
      "Iteration: 4975/10000, Loss: 0.014062363654375076\n",
      "Iteration: 4976/10000, Loss: 0.013012923300266266\n",
      "Iteration: 4977/10000, Loss: 0.017020605504512787\n",
      "Iteration: 4978/10000, Loss: 0.01803198829293251\n",
      "Iteration: 4979/10000, Loss: 0.02570241689682007\n",
      "Iteration: 4980/10000, Loss: 0.015577430836856365\n",
      "Iteration: 4981/10000, Loss: 0.014586826786398888\n",
      "Iteration: 4982/10000, Loss: 0.012409619987010956\n",
      "Iteration: 4983/10000, Loss: 0.014337732456624508\n",
      "Iteration: 4984/10000, Loss: 0.01561715081334114\n",
      "Iteration: 4985/10000, Loss: 0.014030162245035172\n",
      "Iteration: 4986/10000, Loss: 0.01163762528449297\n",
      "Iteration: 4987/10000, Loss: 0.01739589497447014\n",
      "Iteration: 4988/10000, Loss: 0.017217328771948814\n",
      "Iteration: 4989/10000, Loss: 0.01518348790705204\n",
      "Iteration: 4990/10000, Loss: 0.017904117703437805\n",
      "Iteration: 4991/10000, Loss: 0.013098469004034996\n",
      "Iteration: 4992/10000, Loss: 0.016015177592635155\n",
      "Iteration: 4993/10000, Loss: 0.013441286981105804\n",
      "Iteration: 4994/10000, Loss: 0.01023614127188921\n",
      "Iteration: 4995/10000, Loss: 0.014844742603600025\n",
      "Iteration: 4996/10000, Loss: 0.018096260726451874\n",
      "Iteration: 4997/10000, Loss: 0.01352387573570013\n",
      "Iteration: 4998/10000, Loss: 0.008567257784307003\n",
      "Iteration: 4999/10000, Loss: 0.015273017808794975\n",
      "Iteration: 5000/10000, Loss: 0.015417329967021942\n",
      "Average test loss:  0.0030\n",
      "Iteration: 5001/10000, Loss: 0.01662835292518139\n",
      "Iteration: 5002/10000, Loss: 0.009370303712785244\n",
      "Iteration: 5003/10000, Loss: 0.012879656627774239\n",
      "Iteration: 5004/10000, Loss: 0.007908853702247143\n",
      "Iteration: 5005/10000, Loss: 0.008953182026743889\n",
      "Iteration: 5006/10000, Loss: 0.013457018882036209\n",
      "Iteration: 5007/10000, Loss: 0.012552156113088131\n",
      "Iteration: 5008/10000, Loss: 0.02055869996547699\n",
      "Iteration: 5009/10000, Loss: 0.010949365794658661\n",
      "Iteration: 5010/10000, Loss: 0.010940766893327236\n",
      "Iteration: 5011/10000, Loss: 0.013430018909275532\n",
      "Iteration: 5012/10000, Loss: 0.014639046974480152\n",
      "Iteration: 5013/10000, Loss: 0.010784626938402653\n",
      "Iteration: 5014/10000, Loss: 0.018172407522797585\n",
      "Iteration: 5015/10000, Loss: 0.013712195679545403\n",
      "Iteration: 5016/10000, Loss: 0.009895606897771358\n",
      "Iteration: 5017/10000, Loss: 0.014736685901880264\n",
      "Iteration: 5018/10000, Loss: 0.011092446744441986\n",
      "Iteration: 5019/10000, Loss: 0.017634479328989983\n",
      "Iteration: 5020/10000, Loss: 0.018255867063999176\n",
      "Iteration: 5021/10000, Loss: 0.017389409244060516\n",
      "Iteration: 5022/10000, Loss: 0.010949934832751751\n",
      "Iteration: 5023/10000, Loss: 0.01869402639567852\n",
      "Iteration: 5024/10000, Loss: 0.015132606960833073\n",
      "Iteration: 5025/10000, Loss: 0.011447897180914879\n",
      "Iteration: 5026/10000, Loss: 0.014239951968193054\n",
      "Iteration: 5027/10000, Loss: 0.015212802216410637\n",
      "Iteration: 5028/10000, Loss: 0.011067704297602177\n",
      "Iteration: 5029/10000, Loss: 0.016679704189300537\n",
      "Iteration: 5030/10000, Loss: 0.007706306409090757\n",
      "Iteration: 5031/10000, Loss: 0.009440528228878975\n",
      "Iteration: 5032/10000, Loss: 0.023479165509343147\n",
      "Iteration: 5033/10000, Loss: 0.009164589457213879\n",
      "Iteration: 5034/10000, Loss: 0.013297573663294315\n",
      "Iteration: 5035/10000, Loss: 0.011564155109226704\n",
      "Iteration: 5036/10000, Loss: 0.010749565437436104\n",
      "Iteration: 5037/10000, Loss: 0.01162368431687355\n",
      "Iteration: 5038/10000, Loss: 0.01363320555537939\n",
      "Iteration: 5039/10000, Loss: 0.015840472653508186\n",
      "Iteration: 5040/10000, Loss: 0.017140638083219528\n",
      "Iteration: 5041/10000, Loss: 0.01816331222653389\n",
      "Iteration: 5042/10000, Loss: 0.013390026055276394\n",
      "Iteration: 5043/10000, Loss: 0.009250547736883163\n",
      "Iteration: 5044/10000, Loss: 0.017864122986793518\n",
      "Iteration: 5045/10000, Loss: 0.007814018055796623\n",
      "Iteration: 5046/10000, Loss: 0.013997982256114483\n",
      "Iteration: 5047/10000, Loss: 0.011449255049228668\n",
      "Iteration: 5048/10000, Loss: 0.02206282876431942\n",
      "Iteration: 5049/10000, Loss: 0.015324990265071392\n",
      "Iteration: 5050/10000, Loss: 0.013808303512632847\n",
      "Iteration: 5051/10000, Loss: 0.012909675016999245\n",
      "Iteration: 5052/10000, Loss: 0.020786209031939507\n",
      "Iteration: 5053/10000, Loss: 0.011694792658090591\n",
      "Iteration: 5054/10000, Loss: 0.02227879874408245\n",
      "Iteration: 5055/10000, Loss: 0.016181251034140587\n",
      "Iteration: 5056/10000, Loss: 0.013791322708129883\n",
      "Iteration: 5057/10000, Loss: 0.014088974334299564\n",
      "Iteration: 5058/10000, Loss: 0.014253480359911919\n",
      "Iteration: 5059/10000, Loss: 0.015351838432252407\n",
      "Iteration: 5060/10000, Loss: 0.01085665449500084\n",
      "Iteration: 5061/10000, Loss: 0.018628960475325584\n",
      "Iteration: 5062/10000, Loss: 0.010384932160377502\n",
      "Iteration: 5063/10000, Loss: 0.0106354346498847\n",
      "Iteration: 5064/10000, Loss: 0.011627590283751488\n",
      "Iteration: 5065/10000, Loss: 0.017343007028102875\n",
      "Iteration: 5066/10000, Loss: 0.010746262967586517\n",
      "Iteration: 5067/10000, Loss: 0.009533965960144997\n",
      "Iteration: 5068/10000, Loss: 0.014768993481993675\n",
      "Iteration: 5069/10000, Loss: 0.01858128421008587\n",
      "Iteration: 5070/10000, Loss: 0.008646066300570965\n",
      "Iteration: 5071/10000, Loss: 0.02194141410291195\n",
      "Iteration: 5072/10000, Loss: 0.009202519431710243\n",
      "Iteration: 5073/10000, Loss: 0.011749926954507828\n",
      "Iteration: 5074/10000, Loss: 0.013659597374498844\n",
      "Iteration: 5075/10000, Loss: 0.01359537336975336\n",
      "Iteration: 5076/10000, Loss: 0.01371394656598568\n",
      "Iteration: 5077/10000, Loss: 0.01804197020828724\n",
      "Iteration: 5078/10000, Loss: 0.01351701095700264\n",
      "Iteration: 5079/10000, Loss: 0.011323852464556694\n",
      "Iteration: 5080/10000, Loss: 0.012646228075027466\n",
      "Iteration: 5081/10000, Loss: 0.01609211415052414\n",
      "Iteration: 5082/10000, Loss: 0.023063691332936287\n",
      "Iteration: 5083/10000, Loss: 0.0126720005646348\n",
      "Iteration: 5084/10000, Loss: 0.01945408433675766\n",
      "Iteration: 5085/10000, Loss: 0.012871181592345238\n",
      "Iteration: 5086/10000, Loss: 0.009493506513535976\n",
      "Iteration: 5087/10000, Loss: 0.009225692600011826\n",
      "Iteration: 5088/10000, Loss: 0.015206610783934593\n",
      "Iteration: 5089/10000, Loss: 0.021677330136299133\n",
      "Iteration: 5090/10000, Loss: 0.015126682817935944\n",
      "Iteration: 5091/10000, Loss: 0.0100516676902771\n",
      "Iteration: 5092/10000, Loss: 0.012131664901971817\n",
      "Iteration: 5093/10000, Loss: 0.015869200229644775\n",
      "Iteration: 5094/10000, Loss: 0.01689772680401802\n",
      "Iteration: 5095/10000, Loss: 0.01518633309751749\n",
      "Iteration: 5096/10000, Loss: 0.011342917568981647\n",
      "Iteration: 5097/10000, Loss: 0.014098028652369976\n",
      "Iteration: 5098/10000, Loss: 0.013011648319661617\n",
      "Iteration: 5099/10000, Loss: 0.01649104617536068\n",
      "Iteration: 5100/10000, Loss: 0.01628141850233078\n",
      "Average test loss:  0.0017\n",
      "Iteration: 5101/10000, Loss: 0.013371401466429234\n",
      "Iteration: 5102/10000, Loss: 0.014288803562521935\n",
      "Iteration: 5103/10000, Loss: 0.009394140914082527\n",
      "Iteration: 5104/10000, Loss: 0.014792372472584248\n",
      "Iteration: 5105/10000, Loss: 0.013712265528738499\n",
      "Iteration: 5106/10000, Loss: 0.01570749282836914\n",
      "Iteration: 5107/10000, Loss: 0.017575593665242195\n",
      "Iteration: 5108/10000, Loss: 0.011600833386182785\n",
      "Iteration: 5109/10000, Loss: 0.015455223619937897\n",
      "Iteration: 5110/10000, Loss: 0.0129978246986866\n",
      "Iteration: 5111/10000, Loss: 0.014589310623705387\n",
      "Iteration: 5112/10000, Loss: 0.01207189355045557\n",
      "Iteration: 5113/10000, Loss: 0.015248189680278301\n",
      "Iteration: 5114/10000, Loss: 0.015976829454302788\n",
      "Iteration: 5115/10000, Loss: 0.015275624580681324\n",
      "Iteration: 5116/10000, Loss: 0.009830323979258537\n",
      "Iteration: 5117/10000, Loss: 0.011145253665745258\n",
      "Iteration: 5118/10000, Loss: 0.01673303171992302\n",
      "Iteration: 5119/10000, Loss: 0.013549396768212318\n",
      "Iteration: 5120/10000, Loss: 0.016112446784973145\n",
      "Iteration: 5121/10000, Loss: 0.014790458604693413\n",
      "Iteration: 5122/10000, Loss: 0.010350029915571213\n",
      "Iteration: 5123/10000, Loss: 0.01615448296070099\n",
      "Iteration: 5124/10000, Loss: 0.01259682048112154\n",
      "Iteration: 5125/10000, Loss: 0.010149704292416573\n",
      "Iteration: 5126/10000, Loss: 0.014489144086837769\n",
      "Iteration: 5127/10000, Loss: 0.014609875157475471\n",
      "Iteration: 5128/10000, Loss: 0.013625354506075382\n",
      "Iteration: 5129/10000, Loss: 0.011870104819536209\n",
      "Iteration: 5130/10000, Loss: 0.012089777737855911\n",
      "Iteration: 5131/10000, Loss: 0.012098859064280987\n",
      "Iteration: 5132/10000, Loss: 0.014630201272666454\n",
      "Iteration: 5133/10000, Loss: 0.008186384104192257\n",
      "Iteration: 5134/10000, Loss: 0.01795630156993866\n",
      "Iteration: 5135/10000, Loss: 0.013487626798450947\n",
      "Iteration: 5136/10000, Loss: 0.014614274725317955\n",
      "Iteration: 5137/10000, Loss: 0.006354696583002806\n",
      "Iteration: 5138/10000, Loss: 0.01534772478044033\n",
      "Iteration: 5139/10000, Loss: 0.014042249880731106\n",
      "Iteration: 5140/10000, Loss: 0.014143736101686954\n",
      "Iteration: 5141/10000, Loss: 0.01130050141364336\n",
      "Iteration: 5142/10000, Loss: 0.007780174259096384\n",
      "Iteration: 5143/10000, Loss: 0.010954402387142181\n",
      "Iteration: 5144/10000, Loss: 0.011295347474515438\n",
      "Iteration: 5145/10000, Loss: 0.012898223474621773\n",
      "Iteration: 5146/10000, Loss: 0.027278002351522446\n",
      "Iteration: 5147/10000, Loss: 0.01588757149875164\n",
      "Iteration: 5148/10000, Loss: 0.013275579549372196\n",
      "Iteration: 5149/10000, Loss: 0.00935130100697279\n",
      "Iteration: 5150/10000, Loss: 0.012251422740519047\n",
      "Iteration: 5151/10000, Loss: 0.01221079658716917\n",
      "Iteration: 5152/10000, Loss: 0.012890448793768883\n",
      "Iteration: 5153/10000, Loss: 0.013575451448559761\n",
      "Iteration: 5154/10000, Loss: 0.011300872080028057\n",
      "Iteration: 5155/10000, Loss: 0.010877269320189953\n",
      "Iteration: 5156/10000, Loss: 0.012130112387239933\n",
      "Iteration: 5157/10000, Loss: 0.011428284458816051\n",
      "Iteration: 5158/10000, Loss: 0.018937446177005768\n",
      "Iteration: 5159/10000, Loss: 0.012896067462861538\n",
      "Iteration: 5160/10000, Loss: 0.015087753534317017\n",
      "Iteration: 5161/10000, Loss: 0.013627439737319946\n",
      "Iteration: 5162/10000, Loss: 0.01495430339127779\n",
      "Iteration: 5163/10000, Loss: 0.015787478536367416\n",
      "Iteration: 5164/10000, Loss: 0.010265868157148361\n",
      "Iteration: 5165/10000, Loss: 0.012697826139628887\n",
      "Iteration: 5166/10000, Loss: 0.009460159577429295\n",
      "Iteration: 5167/10000, Loss: 0.007543127052485943\n",
      "Iteration: 5168/10000, Loss: 0.013498305343091488\n",
      "Iteration: 5169/10000, Loss: 0.01641550473868847\n",
      "Iteration: 5170/10000, Loss: 0.01440479513257742\n",
      "Iteration: 5171/10000, Loss: 0.012596276588737965\n",
      "Iteration: 5172/10000, Loss: 0.014522646553814411\n",
      "Iteration: 5173/10000, Loss: 0.019491620361804962\n",
      "Iteration: 5174/10000, Loss: 0.01299210824072361\n",
      "Iteration: 5175/10000, Loss: 0.017995258793234825\n",
      "Iteration: 5176/10000, Loss: 0.013803783804178238\n",
      "Iteration: 5177/10000, Loss: 0.012339566834270954\n",
      "Iteration: 5178/10000, Loss: 0.014246881008148193\n",
      "Iteration: 5179/10000, Loss: 0.011552699841558933\n",
      "Iteration: 5180/10000, Loss: 0.012943665497004986\n",
      "Iteration: 5181/10000, Loss: 0.01046858448535204\n",
      "Iteration: 5182/10000, Loss: 0.011977688409388065\n",
      "Iteration: 5183/10000, Loss: 0.01397549919784069\n",
      "Iteration: 5184/10000, Loss: 0.009394773282110691\n",
      "Iteration: 5185/10000, Loss: 0.011701906099915504\n",
      "Iteration: 5186/10000, Loss: 0.012718579731881618\n",
      "Iteration: 5187/10000, Loss: 0.008984529413282871\n",
      "Iteration: 5188/10000, Loss: 0.010105008259415627\n",
      "Iteration: 5189/10000, Loss: 0.016071191057562828\n",
      "Iteration: 5190/10000, Loss: 0.013448171317577362\n",
      "Iteration: 5191/10000, Loss: 0.012203692458570004\n",
      "Iteration: 5192/10000, Loss: 0.018115131184458733\n",
      "Iteration: 5193/10000, Loss: 0.008866201154887676\n",
      "Iteration: 5194/10000, Loss: 0.011517099104821682\n",
      "Iteration: 5195/10000, Loss: 0.01540041621774435\n",
      "Iteration: 5196/10000, Loss: 0.013027088716626167\n",
      "Iteration: 5197/10000, Loss: 0.010872945189476013\n",
      "Iteration: 5198/10000, Loss: 0.014198246411979198\n",
      "Iteration: 5199/10000, Loss: 0.011626417748630047\n",
      "Iteration: 5200/10000, Loss: 0.016136938706040382\n",
      "Average test loss:  0.0024\n",
      "Iteration: 5201/10000, Loss: 0.015306992456316948\n",
      "Iteration: 5202/10000, Loss: 0.013692825101315975\n",
      "Iteration: 5203/10000, Loss: 0.013644995167851448\n",
      "Iteration: 5204/10000, Loss: 0.01561408955603838\n",
      "Iteration: 5205/10000, Loss: 0.014912907034158707\n",
      "Iteration: 5206/10000, Loss: 0.014422697946429253\n",
      "Iteration: 5207/10000, Loss: 0.008808981627225876\n",
      "Iteration: 5208/10000, Loss: 0.013423179276287556\n",
      "Iteration: 5209/10000, Loss: 0.011114266701042652\n",
      "Iteration: 5210/10000, Loss: 0.01537781860679388\n",
      "Iteration: 5211/10000, Loss: 0.010015202686190605\n",
      "Iteration: 5212/10000, Loss: 0.008391797542572021\n",
      "Iteration: 5213/10000, Loss: 0.012078924104571342\n",
      "Iteration: 5214/10000, Loss: 0.01232462003827095\n",
      "Iteration: 5215/10000, Loss: 0.013536699116230011\n",
      "Iteration: 5216/10000, Loss: 0.015226250514388084\n",
      "Iteration: 5217/10000, Loss: 0.013043119572103024\n",
      "Iteration: 5218/10000, Loss: 0.01055466290563345\n",
      "Iteration: 5219/10000, Loss: 0.010800197720527649\n",
      "Iteration: 5220/10000, Loss: 0.01221991516649723\n",
      "Iteration: 5221/10000, Loss: 0.02168913558125496\n",
      "Iteration: 5222/10000, Loss: 0.010824925266206264\n",
      "Iteration: 5223/10000, Loss: 0.016214435920119286\n",
      "Iteration: 5224/10000, Loss: 0.011133822612464428\n",
      "Iteration: 5225/10000, Loss: 0.013381189666688442\n",
      "Iteration: 5226/10000, Loss: 0.014430287294089794\n",
      "Iteration: 5227/10000, Loss: 0.012727869674563408\n",
      "Iteration: 5228/10000, Loss: 0.012132820673286915\n",
      "Iteration: 5229/10000, Loss: 0.009435647167265415\n",
      "Iteration: 5230/10000, Loss: 0.01682782731950283\n",
      "Iteration: 5231/10000, Loss: 0.012662528082728386\n",
      "Iteration: 5232/10000, Loss: 0.013206392526626587\n",
      "Iteration: 5233/10000, Loss: 0.008857966400682926\n",
      "Iteration: 5234/10000, Loss: 0.017146455124020576\n",
      "Iteration: 5235/10000, Loss: 0.011498871259391308\n",
      "Iteration: 5236/10000, Loss: 0.010661987587809563\n",
      "Iteration: 5237/10000, Loss: 0.009054578840732574\n",
      "Iteration: 5238/10000, Loss: 0.011723763309419155\n",
      "Iteration: 5239/10000, Loss: 0.016957683488726616\n",
      "Iteration: 5240/10000, Loss: 0.015109882690012455\n",
      "Iteration: 5241/10000, Loss: 0.011099538765847683\n",
      "Iteration: 5242/10000, Loss: 0.015727156773209572\n",
      "Iteration: 5243/10000, Loss: 0.015983721241354942\n",
      "Iteration: 5244/10000, Loss: 0.018638042733073235\n",
      "Iteration: 5245/10000, Loss: 0.012285768985748291\n",
      "Iteration: 5246/10000, Loss: 0.014816629700362682\n",
      "Iteration: 5247/10000, Loss: 0.012983362190425396\n",
      "Iteration: 5248/10000, Loss: 0.014525791630148888\n",
      "Iteration: 5249/10000, Loss: 0.012473409064114094\n",
      "Iteration: 5250/10000, Loss: 0.015367867425084114\n",
      "Iteration: 5251/10000, Loss: 0.01165391318500042\n",
      "Iteration: 5252/10000, Loss: 0.015476604923605919\n",
      "Iteration: 5253/10000, Loss: 0.014329769648611546\n",
      "Iteration: 5254/10000, Loss: 0.013002236373722553\n",
      "Iteration: 5255/10000, Loss: 0.014080509543418884\n",
      "Iteration: 5256/10000, Loss: 0.010389949195086956\n",
      "Iteration: 5257/10000, Loss: 0.013711437582969666\n",
      "Iteration: 5258/10000, Loss: 0.014575382694602013\n",
      "Iteration: 5259/10000, Loss: 0.016155729070305824\n",
      "Iteration: 5260/10000, Loss: 0.010386677458882332\n",
      "Iteration: 5261/10000, Loss: 0.018327223137021065\n",
      "Iteration: 5262/10000, Loss: 0.01155775599181652\n",
      "Iteration: 5263/10000, Loss: 0.017843211069703102\n",
      "Iteration: 5264/10000, Loss: 0.013102753087878227\n",
      "Iteration: 5265/10000, Loss: 0.016499506309628487\n",
      "Iteration: 5266/10000, Loss: 0.009417269378900528\n",
      "Iteration: 5267/10000, Loss: 0.009138953872025013\n",
      "Iteration: 5268/10000, Loss: 0.01301155611872673\n",
      "Iteration: 5269/10000, Loss: 0.02192058227956295\n",
      "Iteration: 5270/10000, Loss: 0.016573484987020493\n",
      "Iteration: 5271/10000, Loss: 0.009483621455729008\n",
      "Iteration: 5272/10000, Loss: 0.011792005971074104\n",
      "Iteration: 5273/10000, Loss: 0.01314906869083643\n",
      "Iteration: 5274/10000, Loss: 0.019542720168828964\n",
      "Iteration: 5275/10000, Loss: 0.015051300637423992\n",
      "Iteration: 5276/10000, Loss: 0.011231478303670883\n",
      "Iteration: 5277/10000, Loss: 0.013628534972667694\n",
      "Iteration: 5278/10000, Loss: 0.013467004522681236\n",
      "Iteration: 5279/10000, Loss: 0.016777310520410538\n",
      "Iteration: 5280/10000, Loss: 0.012640348635613918\n",
      "Iteration: 5281/10000, Loss: 0.013261869549751282\n",
      "Iteration: 5282/10000, Loss: 0.013574094511568546\n",
      "Iteration: 5283/10000, Loss: 0.017989009618759155\n",
      "Iteration: 5284/10000, Loss: 0.009714792482554913\n",
      "Iteration: 5285/10000, Loss: 0.00757179269567132\n",
      "Iteration: 5286/10000, Loss: 0.0123381232842803\n",
      "Iteration: 5287/10000, Loss: 0.018556607887148857\n",
      "Iteration: 5288/10000, Loss: 0.023363938555121422\n",
      "Iteration: 5289/10000, Loss: 0.011999445967376232\n",
      "Iteration: 5290/10000, Loss: 0.010742726735770702\n",
      "Iteration: 5291/10000, Loss: 0.00919291004538536\n",
      "Iteration: 5292/10000, Loss: 0.01524774357676506\n",
      "Iteration: 5293/10000, Loss: 0.014411596581339836\n",
      "Iteration: 5294/10000, Loss: 0.01569361425936222\n",
      "Iteration: 5295/10000, Loss: 0.009385645389556885\n",
      "Iteration: 5296/10000, Loss: 0.011528239585459232\n",
      "Iteration: 5297/10000, Loss: 0.015846140682697296\n",
      "Iteration: 5298/10000, Loss: 0.014346239157021046\n",
      "Iteration: 5299/10000, Loss: 0.01728770323097706\n",
      "Iteration: 5300/10000, Loss: 0.019029837101697922\n",
      "Average test loss:  0.0023\n",
      "Iteration: 5301/10000, Loss: 0.011894469149410725\n",
      "Iteration: 5302/10000, Loss: 0.018456248566508293\n",
      "Iteration: 5303/10000, Loss: 0.014445769600570202\n",
      "Iteration: 5304/10000, Loss: 0.010993369854986668\n",
      "Iteration: 5305/10000, Loss: 0.015366225503385067\n",
      "Iteration: 5306/10000, Loss: 0.009335801936686039\n",
      "Iteration: 5307/10000, Loss: 0.019884373992681503\n",
      "Iteration: 5308/10000, Loss: 0.01750815473496914\n",
      "Iteration: 5309/10000, Loss: 0.011053605936467648\n",
      "Iteration: 5310/10000, Loss: 0.014822380617260933\n",
      "Iteration: 5311/10000, Loss: 0.007561482489109039\n",
      "Iteration: 5312/10000, Loss: 0.008656577207148075\n",
      "Iteration: 5313/10000, Loss: 0.013388553634285927\n",
      "Iteration: 5314/10000, Loss: 0.014325201511383057\n",
      "Iteration: 5315/10000, Loss: 0.014926689676940441\n",
      "Iteration: 5316/10000, Loss: 0.012837215326726437\n",
      "Iteration: 5317/10000, Loss: 0.012539028190076351\n",
      "Iteration: 5318/10000, Loss: 0.01626637578010559\n",
      "Iteration: 5319/10000, Loss: 0.012119755148887634\n",
      "Iteration: 5320/10000, Loss: 0.012614908628165722\n",
      "Iteration: 5321/10000, Loss: 0.009767246432602406\n",
      "Iteration: 5322/10000, Loss: 0.010353258810937405\n",
      "Iteration: 5323/10000, Loss: 0.010154519230127335\n",
      "Iteration: 5324/10000, Loss: 0.013375061564147472\n",
      "Iteration: 5325/10000, Loss: 0.010389848612248898\n",
      "Iteration: 5326/10000, Loss: 0.010835694149136543\n",
      "Iteration: 5327/10000, Loss: 0.012742914259433746\n",
      "Iteration: 5328/10000, Loss: 0.011782300658524036\n",
      "Iteration: 5329/10000, Loss: 0.007406772579997778\n",
      "Iteration: 5330/10000, Loss: 0.017298299819231033\n",
      "Iteration: 5331/10000, Loss: 0.018124135211110115\n",
      "Iteration: 5332/10000, Loss: 0.013678778894245625\n",
      "Iteration: 5333/10000, Loss: 0.016817810013890266\n",
      "Iteration: 5334/10000, Loss: 0.017194345593452454\n",
      "Iteration: 5335/10000, Loss: 0.011366091668605804\n",
      "Iteration: 5336/10000, Loss: 0.011315702460706234\n",
      "Iteration: 5337/10000, Loss: 0.015983833000063896\n",
      "Iteration: 5338/10000, Loss: 0.014159872196614742\n",
      "Iteration: 5339/10000, Loss: 0.006854533683508635\n",
      "Iteration: 5340/10000, Loss: 0.014880742877721786\n",
      "Iteration: 5341/10000, Loss: 0.012267383746802807\n",
      "Iteration: 5342/10000, Loss: 0.011738838627934456\n",
      "Iteration: 5343/10000, Loss: 0.014406335540115833\n",
      "Iteration: 5344/10000, Loss: 0.010292191058397293\n",
      "Iteration: 5345/10000, Loss: 0.020269379019737244\n",
      "Iteration: 5346/10000, Loss: 0.011999654583632946\n",
      "Iteration: 5347/10000, Loss: 0.016507983207702637\n",
      "Iteration: 5348/10000, Loss: 0.015197821892797947\n",
      "Iteration: 5349/10000, Loss: 0.013406769372522831\n",
      "Iteration: 5350/10000, Loss: 0.007320161443203688\n",
      "Iteration: 5351/10000, Loss: 0.018858298659324646\n",
      "Iteration: 5352/10000, Loss: 0.013573301956057549\n",
      "Iteration: 5353/10000, Loss: 0.016447219997644424\n",
      "Iteration: 5354/10000, Loss: 0.018921926617622375\n",
      "Iteration: 5355/10000, Loss: 0.015219868160784245\n",
      "Iteration: 5356/10000, Loss: 0.01037693116813898\n",
      "Iteration: 5357/10000, Loss: 0.01750386506319046\n",
      "Iteration: 5358/10000, Loss: 0.011078334413468838\n",
      "Iteration: 5359/10000, Loss: 0.015382700599730015\n",
      "Iteration: 5360/10000, Loss: 0.01340462826192379\n",
      "Iteration: 5361/10000, Loss: 0.009951627813279629\n",
      "Iteration: 5362/10000, Loss: 0.009554142132401466\n",
      "Iteration: 5363/10000, Loss: 0.012852945365011692\n",
      "Iteration: 5364/10000, Loss: 0.01593911275267601\n",
      "Iteration: 5365/10000, Loss: 0.011426346376538277\n",
      "Iteration: 5366/10000, Loss: 0.013095764443278313\n",
      "Iteration: 5367/10000, Loss: 0.012439696118235588\n",
      "Iteration: 5368/10000, Loss: 0.010759294964373112\n",
      "Iteration: 5369/10000, Loss: 0.01278538815677166\n",
      "Iteration: 5370/10000, Loss: 0.012707573361694813\n",
      "Iteration: 5371/10000, Loss: 0.01032929215580225\n",
      "Iteration: 5372/10000, Loss: 0.017597587779164314\n",
      "Iteration: 5373/10000, Loss: 0.0130924042314291\n",
      "Iteration: 5374/10000, Loss: 0.018150286749005318\n",
      "Iteration: 5375/10000, Loss: 0.011759364046156406\n",
      "Iteration: 5376/10000, Loss: 0.012018082663416862\n",
      "Iteration: 5377/10000, Loss: 0.014025089330971241\n",
      "Iteration: 5378/10000, Loss: 0.013119082897901535\n",
      "Iteration: 5379/10000, Loss: 0.009319034405052662\n",
      "Iteration: 5380/10000, Loss: 0.012775706127285957\n",
      "Iteration: 5381/10000, Loss: 0.023129360750317574\n",
      "Iteration: 5382/10000, Loss: 0.013750326819717884\n",
      "Iteration: 5383/10000, Loss: 0.015229427255690098\n",
      "Iteration: 5384/10000, Loss: 0.011948232538998127\n",
      "Iteration: 5385/10000, Loss: 0.012208739295601845\n",
      "Iteration: 5386/10000, Loss: 0.009569529443979263\n",
      "Iteration: 5387/10000, Loss: 0.009165185503661633\n",
      "Iteration: 5388/10000, Loss: 0.016732990741729736\n",
      "Iteration: 5389/10000, Loss: 0.01408788189291954\n",
      "Iteration: 5390/10000, Loss: 0.018953466787934303\n",
      "Iteration: 5391/10000, Loss: 0.012158717960119247\n",
      "Iteration: 5392/10000, Loss: 0.01402194146066904\n",
      "Iteration: 5393/10000, Loss: 0.016741963103413582\n",
      "Iteration: 5394/10000, Loss: 0.013451890088617802\n",
      "Iteration: 5395/10000, Loss: 0.014307019300758839\n",
      "Iteration: 5396/10000, Loss: 0.0131178954616189\n",
      "Iteration: 5397/10000, Loss: 0.009946903213858604\n",
      "Iteration: 5398/10000, Loss: 0.013650286942720413\n",
      "Iteration: 5399/10000, Loss: 0.009909411892294884\n",
      "Iteration: 5400/10000, Loss: 0.01577773131430149\n",
      "Average test loss:  0.0046\n",
      "Iteration: 5401/10000, Loss: 0.010813296772539616\n",
      "Iteration: 5402/10000, Loss: 0.018468739464879036\n",
      "Iteration: 5403/10000, Loss: 0.013876546174287796\n",
      "Iteration: 5404/10000, Loss: 0.010795152746140957\n",
      "Iteration: 5405/10000, Loss: 0.013965039514005184\n",
      "Iteration: 5406/10000, Loss: 0.015996737405657768\n",
      "Iteration: 5407/10000, Loss: 0.01672198437154293\n",
      "Iteration: 5408/10000, Loss: 0.01365436427295208\n",
      "Iteration: 5409/10000, Loss: 0.013128496706485748\n",
      "Iteration: 5410/10000, Loss: 0.01409957930445671\n",
      "Iteration: 5411/10000, Loss: 0.011874428018927574\n",
      "Iteration: 5412/10000, Loss: 0.010448805056512356\n",
      "Iteration: 5413/10000, Loss: 0.006426686886698008\n",
      "Iteration: 5414/10000, Loss: 0.008479882963001728\n",
      "Iteration: 5415/10000, Loss: 0.011491436511278152\n",
      "Iteration: 5416/10000, Loss: 0.01595832221210003\n",
      "Iteration: 5417/10000, Loss: 0.00651951227337122\n",
      "Iteration: 5418/10000, Loss: 0.0171461533755064\n",
      "Iteration: 5419/10000, Loss: 0.018543876707553864\n",
      "Iteration: 5420/10000, Loss: 0.014262187294661999\n",
      "Iteration: 5421/10000, Loss: 0.01238135527819395\n",
      "Iteration: 5422/10000, Loss: 0.01558816246688366\n",
      "Iteration: 5423/10000, Loss: 0.012137620709836483\n",
      "Iteration: 5424/10000, Loss: 0.014891891740262508\n",
      "Iteration: 5425/10000, Loss: 0.013914017006754875\n",
      "Iteration: 5426/10000, Loss: 0.011935582384467125\n",
      "Iteration: 5427/10000, Loss: 0.011577168479561806\n",
      "Iteration: 5428/10000, Loss: 0.02108006924390793\n",
      "Iteration: 5429/10000, Loss: 0.018210487440228462\n",
      "Iteration: 5430/10000, Loss: 0.00898673664778471\n",
      "Iteration: 5431/10000, Loss: 0.017938781529664993\n",
      "Iteration: 5432/10000, Loss: 0.012989065609872341\n",
      "Iteration: 5433/10000, Loss: 0.007882827892899513\n",
      "Iteration: 5434/10000, Loss: 0.016038116067647934\n",
      "Iteration: 5435/10000, Loss: 0.009804412722587585\n",
      "Iteration: 5436/10000, Loss: 0.01768035627901554\n",
      "Iteration: 5437/10000, Loss: 0.0204378142952919\n",
      "Iteration: 5438/10000, Loss: 0.012875903397798538\n",
      "Iteration: 5439/10000, Loss: 0.012296810746192932\n",
      "Iteration: 5440/10000, Loss: 0.013870779424905777\n",
      "Iteration: 5441/10000, Loss: 0.01670803874731064\n",
      "Iteration: 5442/10000, Loss: 0.012824066914618015\n",
      "Iteration: 5443/10000, Loss: 0.015518056228756905\n",
      "Iteration: 5444/10000, Loss: 0.015992585569620132\n",
      "Iteration: 5445/10000, Loss: 0.013754863291978836\n",
      "Iteration: 5446/10000, Loss: 0.011844052001833916\n",
      "Iteration: 5447/10000, Loss: 0.012190211564302444\n",
      "Iteration: 5448/10000, Loss: 0.013038193807005882\n",
      "Iteration: 5449/10000, Loss: 0.016295678913593292\n",
      "Iteration: 5450/10000, Loss: 0.013336778618395329\n",
      "Iteration: 5451/10000, Loss: 0.01413242518901825\n",
      "Iteration: 5452/10000, Loss: 0.011120018549263477\n",
      "Iteration: 5453/10000, Loss: 0.016556991264224052\n",
      "Iteration: 5454/10000, Loss: 0.011335523799061775\n",
      "Iteration: 5455/10000, Loss: 0.018505433574318886\n",
      "Iteration: 5456/10000, Loss: 0.010050407610833645\n",
      "Iteration: 5457/10000, Loss: 0.007323172874748707\n",
      "Iteration: 5458/10000, Loss: 0.008279108442366123\n",
      "Iteration: 5459/10000, Loss: 0.012667978182435036\n",
      "Iteration: 5460/10000, Loss: 0.019808324053883553\n",
      "Iteration: 5461/10000, Loss: 0.011186584830284119\n",
      "Iteration: 5462/10000, Loss: 0.009645814076066017\n",
      "Iteration: 5463/10000, Loss: 0.013070470653474331\n",
      "Iteration: 5464/10000, Loss: 0.010125416330993176\n",
      "Iteration: 5465/10000, Loss: 0.011735601350665092\n",
      "Iteration: 5466/10000, Loss: 0.009753376245498657\n",
      "Iteration: 5467/10000, Loss: 0.016192307695746422\n",
      "Iteration: 5468/10000, Loss: 0.010096282698214054\n",
      "Iteration: 5469/10000, Loss: 0.009683370590209961\n",
      "Iteration: 5470/10000, Loss: 0.011221561580896378\n",
      "Iteration: 5471/10000, Loss: 0.016053855419158936\n",
      "Iteration: 5472/10000, Loss: 0.011873527429997921\n",
      "Iteration: 5473/10000, Loss: 0.01754988729953766\n",
      "Iteration: 5474/10000, Loss: 0.010583693161606789\n",
      "Iteration: 5475/10000, Loss: 0.008723692037165165\n",
      "Iteration: 5476/10000, Loss: 0.014823186211287975\n",
      "Iteration: 5477/10000, Loss: 0.011216823011636734\n",
      "Iteration: 5478/10000, Loss: 0.014869933016598225\n",
      "Iteration: 5479/10000, Loss: 0.013804621994495392\n",
      "Iteration: 5480/10000, Loss: 0.013649665750563145\n",
      "Iteration: 5481/10000, Loss: 0.013885214924812317\n",
      "Iteration: 5482/10000, Loss: 0.01751042529940605\n",
      "Iteration: 5483/10000, Loss: 0.015215082094073296\n",
      "Iteration: 5484/10000, Loss: 0.012618079781532288\n",
      "Iteration: 5485/10000, Loss: 0.01092793233692646\n",
      "Iteration: 5486/10000, Loss: 0.010913679376244545\n",
      "Iteration: 5487/10000, Loss: 0.016261551529169083\n",
      "Iteration: 5488/10000, Loss: 0.008109399117529392\n",
      "Iteration: 5489/10000, Loss: 0.011273903772234917\n",
      "Iteration: 5490/10000, Loss: 0.010042582638561726\n",
      "Iteration: 5491/10000, Loss: 0.010882033966481686\n",
      "Iteration: 5492/10000, Loss: 0.011256474070250988\n",
      "Iteration: 5493/10000, Loss: 0.016212454065680504\n",
      "Iteration: 5494/10000, Loss: 0.013268578797578812\n",
      "Iteration: 5495/10000, Loss: 0.010179010219871998\n",
      "Iteration: 5496/10000, Loss: 0.011388000100851059\n",
      "Iteration: 5497/10000, Loss: 0.015431564301252365\n",
      "Iteration: 5498/10000, Loss: 0.012415868230164051\n",
      "Iteration: 5499/10000, Loss: 0.009402107447385788\n",
      "Iteration: 5500/10000, Loss: 0.013898774981498718\n",
      "Average test loss:  0.0027\n",
      "Iteration: 5501/10000, Loss: 0.009089413098990917\n",
      "Iteration: 5502/10000, Loss: 0.01600380428135395\n",
      "Iteration: 5503/10000, Loss: 0.01676076278090477\n",
      "Iteration: 5504/10000, Loss: 0.011304379440844059\n",
      "Iteration: 5505/10000, Loss: 0.011358620598912239\n",
      "Iteration: 5506/10000, Loss: 0.013627637177705765\n",
      "Iteration: 5507/10000, Loss: 0.013981744647026062\n",
      "Iteration: 5508/10000, Loss: 0.013722984120249748\n",
      "Iteration: 5509/10000, Loss: 0.013505229726433754\n",
      "Iteration: 5510/10000, Loss: 0.011343353427946568\n",
      "Iteration: 5511/10000, Loss: 0.01994340494275093\n",
      "Iteration: 5512/10000, Loss: 0.012017150409519672\n",
      "Iteration: 5513/10000, Loss: 0.008086695335805416\n",
      "Iteration: 5514/10000, Loss: 0.01492760144174099\n",
      "Iteration: 5515/10000, Loss: 0.018654117360711098\n",
      "Iteration: 5516/10000, Loss: 0.020185651257634163\n",
      "Iteration: 5517/10000, Loss: 0.011922718025743961\n",
      "Iteration: 5518/10000, Loss: 0.01663685217499733\n",
      "Iteration: 5519/10000, Loss: 0.015083268284797668\n",
      "Iteration: 5520/10000, Loss: 0.012446836568415165\n",
      "Iteration: 5521/10000, Loss: 0.013979661278426647\n",
      "Iteration: 5522/10000, Loss: 0.013201316818594933\n",
      "Iteration: 5523/10000, Loss: 0.008453131653368473\n",
      "Iteration: 5524/10000, Loss: 0.01248243823647499\n",
      "Iteration: 5525/10000, Loss: 0.01170827355235815\n",
      "Iteration: 5526/10000, Loss: 0.0074743228033185005\n",
      "Iteration: 5527/10000, Loss: 0.007693956606090069\n",
      "Iteration: 5528/10000, Loss: 0.016672145575284958\n",
      "Iteration: 5529/10000, Loss: 0.013960952870547771\n",
      "Iteration: 5530/10000, Loss: 0.011645868420600891\n",
      "Iteration: 5531/10000, Loss: 0.02128806710243225\n",
      "Iteration: 5532/10000, Loss: 0.016889257356524467\n",
      "Iteration: 5533/10000, Loss: 0.015505000948905945\n",
      "Iteration: 5534/10000, Loss: 0.014945052564144135\n",
      "Iteration: 5535/10000, Loss: 0.013129856437444687\n",
      "Iteration: 5536/10000, Loss: 0.012081226333975792\n",
      "Iteration: 5537/10000, Loss: 0.011535362340509892\n",
      "Iteration: 5538/10000, Loss: 0.015559963881969452\n",
      "Iteration: 5539/10000, Loss: 0.009843649342656136\n",
      "Iteration: 5540/10000, Loss: 0.010983360931277275\n",
      "Iteration: 5541/10000, Loss: 0.0180827509611845\n",
      "Iteration: 5542/10000, Loss: 0.01030939631164074\n",
      "Iteration: 5543/10000, Loss: 0.010820988565683365\n",
      "Iteration: 5544/10000, Loss: 0.013692284002900124\n",
      "Iteration: 5545/10000, Loss: 0.015242653898894787\n",
      "Iteration: 5546/10000, Loss: 0.011009279638528824\n",
      "Iteration: 5547/10000, Loss: 0.012819105759263039\n",
      "Iteration: 5548/10000, Loss: 0.011958365328609943\n",
      "Iteration: 5549/10000, Loss: 0.01356312446296215\n",
      "Iteration: 5550/10000, Loss: 0.010489827021956444\n",
      "Iteration: 5551/10000, Loss: 0.01632242649793625\n",
      "Iteration: 5552/10000, Loss: 0.012935392558574677\n",
      "Iteration: 5553/10000, Loss: 0.01476290263235569\n",
      "Iteration: 5554/10000, Loss: 0.019856654107570648\n",
      "Iteration: 5555/10000, Loss: 0.014405664056539536\n",
      "Iteration: 5556/10000, Loss: 0.013619109988212585\n",
      "Iteration: 5557/10000, Loss: 0.010181116871535778\n",
      "Iteration: 5558/10000, Loss: 0.01409059762954712\n",
      "Iteration: 5559/10000, Loss: 0.014415395446121693\n",
      "Iteration: 5560/10000, Loss: 0.013567108660936356\n",
      "Iteration: 5561/10000, Loss: 0.014879055321216583\n",
      "Iteration: 5562/10000, Loss: 0.018624259158968925\n",
      "Iteration: 5563/10000, Loss: 0.01574471965432167\n",
      "Iteration: 5564/10000, Loss: 0.016504725441336632\n",
      "Iteration: 5565/10000, Loss: 0.010218813084065914\n",
      "Iteration: 5566/10000, Loss: 0.011316508054733276\n",
      "Iteration: 5567/10000, Loss: 0.007713048718869686\n",
      "Iteration: 5568/10000, Loss: 0.01034414954483509\n",
      "Iteration: 5569/10000, Loss: 0.00793636403977871\n",
      "Iteration: 5570/10000, Loss: 0.01145173329859972\n",
      "Iteration: 5571/10000, Loss: 0.012982559390366077\n",
      "Iteration: 5572/10000, Loss: 0.015080491080880165\n",
      "Iteration: 5573/10000, Loss: 0.015221045352518559\n",
      "Iteration: 5574/10000, Loss: 0.011002161540091038\n",
      "Iteration: 5575/10000, Loss: 0.013372237794101238\n",
      "Iteration: 5576/10000, Loss: 0.014575456269085407\n",
      "Iteration: 5577/10000, Loss: 0.013411791995167732\n",
      "Iteration: 5578/10000, Loss: 0.01517409086227417\n",
      "Iteration: 5579/10000, Loss: 0.014837364666163921\n",
      "Iteration: 5580/10000, Loss: 0.013067263178527355\n",
      "Iteration: 5581/10000, Loss: 0.015572171658277512\n",
      "Iteration: 5582/10000, Loss: 0.02129123918712139\n",
      "Iteration: 5583/10000, Loss: 0.010236825793981552\n",
      "Iteration: 5584/10000, Loss: 0.010628466494381428\n",
      "Iteration: 5585/10000, Loss: 0.012547382153570652\n",
      "Iteration: 5586/10000, Loss: 0.010282970033586025\n",
      "Iteration: 5587/10000, Loss: 0.010846146382391453\n",
      "Iteration: 5588/10000, Loss: 0.016989771276712418\n",
      "Iteration: 5589/10000, Loss: 0.016589151695370674\n",
      "Iteration: 5590/10000, Loss: 0.014263351447880268\n",
      "Iteration: 5591/10000, Loss: 0.013810589909553528\n",
      "Iteration: 5592/10000, Loss: 0.01663609780371189\n",
      "Iteration: 5593/10000, Loss: 0.009663829579949379\n",
      "Iteration: 5594/10000, Loss: 0.015944909304380417\n",
      "Iteration: 5595/10000, Loss: 0.007363666780292988\n",
      "Iteration: 5596/10000, Loss: 0.01614920236170292\n",
      "Iteration: 5597/10000, Loss: 0.016143830493092537\n",
      "Iteration: 5598/10000, Loss: 0.011747497133910656\n",
      "Iteration: 5599/10000, Loss: 0.009569908492267132\n",
      "Iteration: 5600/10000, Loss: 0.014108291827142239\n",
      "Average test loss:  0.0015\n",
      "Iteration: 5601/10000, Loss: 0.01474540214985609\n",
      "Iteration: 5602/10000, Loss: 0.01121086161583662\n",
      "Iteration: 5603/10000, Loss: 0.014722210355103016\n",
      "Iteration: 5604/10000, Loss: 0.021599091589450836\n",
      "Iteration: 5605/10000, Loss: 0.014067403972148895\n",
      "Iteration: 5606/10000, Loss: 0.01453618984669447\n",
      "Iteration: 5607/10000, Loss: 0.009105472825467587\n",
      "Iteration: 5608/10000, Loss: 0.01515829935669899\n",
      "Iteration: 5609/10000, Loss: 0.018292374908924103\n",
      "Iteration: 5610/10000, Loss: 0.010674002580344677\n",
      "Iteration: 5611/10000, Loss: 0.01370429527014494\n",
      "Iteration: 5612/10000, Loss: 0.017057711258530617\n",
      "Iteration: 5613/10000, Loss: 0.021431850269436836\n",
      "Iteration: 5614/10000, Loss: 0.01608712039887905\n",
      "Iteration: 5615/10000, Loss: 0.006180431228131056\n",
      "Iteration: 5616/10000, Loss: 0.01398721057921648\n",
      "Iteration: 5617/10000, Loss: 0.012212269008159637\n",
      "Iteration: 5618/10000, Loss: 0.011692636646330357\n",
      "Iteration: 5619/10000, Loss: 0.013733777217566967\n",
      "Iteration: 5620/10000, Loss: 0.011117720045149326\n",
      "Iteration: 5621/10000, Loss: 0.015310756862163544\n",
      "Iteration: 5622/10000, Loss: 0.019150814041495323\n",
      "Iteration: 5623/10000, Loss: 0.010646172799170017\n",
      "Iteration: 5624/10000, Loss: 0.008114625699818134\n",
      "Iteration: 5625/10000, Loss: 0.015174406580626965\n",
      "Iteration: 5626/10000, Loss: 0.011203954927623272\n",
      "Iteration: 5627/10000, Loss: 0.014626617543399334\n",
      "Iteration: 5628/10000, Loss: 0.012987267225980759\n",
      "Iteration: 5629/10000, Loss: 0.012164353393018246\n",
      "Iteration: 5630/10000, Loss: 0.012996341101825237\n",
      "Iteration: 5631/10000, Loss: 0.013478897511959076\n",
      "Iteration: 5632/10000, Loss: 0.01489207148551941\n",
      "Iteration: 5633/10000, Loss: 0.016331765800714493\n",
      "Iteration: 5634/10000, Loss: 0.013992147520184517\n",
      "Iteration: 5635/10000, Loss: 0.007040914613753557\n",
      "Iteration: 5636/10000, Loss: 0.01093191746622324\n",
      "Iteration: 5637/10000, Loss: 0.008942464366555214\n",
      "Iteration: 5638/10000, Loss: 0.012274020351469517\n",
      "Iteration: 5639/10000, Loss: 0.019185662269592285\n",
      "Iteration: 5640/10000, Loss: 0.014024365693330765\n",
      "Iteration: 5641/10000, Loss: 0.01740041933953762\n",
      "Iteration: 5642/10000, Loss: 0.013680914416909218\n",
      "Iteration: 5643/10000, Loss: 0.013068284839391708\n",
      "Iteration: 5644/10000, Loss: 0.012827771715819836\n",
      "Iteration: 5645/10000, Loss: 0.0091633265838027\n",
      "Iteration: 5646/10000, Loss: 0.019743718206882477\n",
      "Iteration: 5647/10000, Loss: 0.011421183124184608\n",
      "Iteration: 5648/10000, Loss: 0.010580076836049557\n",
      "Iteration: 5649/10000, Loss: 0.01299024373292923\n",
      "Iteration: 5650/10000, Loss: 0.012361142784357071\n",
      "Iteration: 5651/10000, Loss: 0.016464630141854286\n",
      "Iteration: 5652/10000, Loss: 0.013110269792377949\n",
      "Iteration: 5653/10000, Loss: 0.009802840650081635\n",
      "Iteration: 5654/10000, Loss: 0.012275329791009426\n",
      "Iteration: 5655/10000, Loss: 0.016405995935201645\n",
      "Iteration: 5656/10000, Loss: 0.01221790723502636\n",
      "Iteration: 5657/10000, Loss: 0.012598233297467232\n",
      "Iteration: 5658/10000, Loss: 0.019196724519133568\n",
      "Iteration: 5659/10000, Loss: 0.012437215074896812\n",
      "Iteration: 5660/10000, Loss: 0.013331161811947823\n",
      "Iteration: 5661/10000, Loss: 0.012200224213302135\n",
      "Iteration: 5662/10000, Loss: 0.007835553027689457\n",
      "Iteration: 5663/10000, Loss: 0.010427627712488174\n",
      "Iteration: 5664/10000, Loss: 0.014063839800655842\n",
      "Iteration: 5665/10000, Loss: 0.011312835849821568\n",
      "Iteration: 5666/10000, Loss: 0.0153902443125844\n",
      "Iteration: 5667/10000, Loss: 0.011322748847305775\n",
      "Iteration: 5668/10000, Loss: 0.01563965529203415\n",
      "Iteration: 5669/10000, Loss: 0.012103102169930935\n",
      "Iteration: 5670/10000, Loss: 0.008656480349600315\n",
      "Iteration: 5671/10000, Loss: 0.016731932759284973\n",
      "Iteration: 5672/10000, Loss: 0.013212954625487328\n",
      "Iteration: 5673/10000, Loss: 0.010540002025663853\n",
      "Iteration: 5674/10000, Loss: 0.01675238087773323\n",
      "Iteration: 5675/10000, Loss: 0.014077595435082912\n",
      "Iteration: 5676/10000, Loss: 0.00971729215234518\n",
      "Iteration: 5677/10000, Loss: 0.0112860556691885\n",
      "Iteration: 5678/10000, Loss: 0.016183508560061455\n",
      "Iteration: 5679/10000, Loss: 0.018916727975010872\n",
      "Iteration: 5680/10000, Loss: 0.017933689057826996\n",
      "Iteration: 5681/10000, Loss: 0.0145513154566288\n",
      "Iteration: 5682/10000, Loss: 0.007155201397836208\n",
      "Iteration: 5683/10000, Loss: 0.016134504228830338\n",
      "Iteration: 5684/10000, Loss: 0.013479547575116158\n",
      "Iteration: 5685/10000, Loss: 0.009864816442131996\n",
      "Iteration: 5686/10000, Loss: 0.01574126072227955\n",
      "Iteration: 5687/10000, Loss: 0.010306373238563538\n",
      "Iteration: 5688/10000, Loss: 0.008404605090618134\n",
      "Iteration: 5689/10000, Loss: 0.014881297014653683\n",
      "Iteration: 5690/10000, Loss: 0.006338251754641533\n",
      "Iteration: 5691/10000, Loss: 0.008695924654603004\n",
      "Iteration: 5692/10000, Loss: 0.01485633198171854\n",
      "Iteration: 5693/10000, Loss: 0.017075687646865845\n",
      "Iteration: 5694/10000, Loss: 0.011674209497869015\n",
      "Iteration: 5695/10000, Loss: 0.011840389110147953\n",
      "Iteration: 5696/10000, Loss: 0.008243974298238754\n",
      "Iteration: 5697/10000, Loss: 0.017374519258737564\n",
      "Iteration: 5698/10000, Loss: 0.012667099945247173\n",
      "Iteration: 5699/10000, Loss: 0.008859350346028805\n",
      "Iteration: 5700/10000, Loss: 0.011014675721526146\n",
      "Average test loss:  0.0034\n",
      "Iteration: 5701/10000, Loss: 0.012916642241179943\n",
      "Iteration: 5702/10000, Loss: 0.014506307430565357\n",
      "Iteration: 5703/10000, Loss: 0.012375655584037304\n",
      "Iteration: 5704/10000, Loss: 0.012025111354887486\n",
      "Iteration: 5705/10000, Loss: 0.01150216069072485\n",
      "Iteration: 5706/10000, Loss: 0.010755540803074837\n",
      "Iteration: 5707/10000, Loss: 0.0073333983309566975\n",
      "Iteration: 5708/10000, Loss: 0.010429812595248222\n",
      "Iteration: 5709/10000, Loss: 0.011262672953307629\n",
      "Iteration: 5710/10000, Loss: 0.011297865770757198\n",
      "Iteration: 5711/10000, Loss: 0.009517003782093525\n",
      "Iteration: 5712/10000, Loss: 0.014278232119977474\n",
      "Iteration: 5713/10000, Loss: 0.009884021244943142\n",
      "Iteration: 5714/10000, Loss: 0.01650836691260338\n",
      "Iteration: 5715/10000, Loss: 0.01166888140141964\n",
      "Iteration: 5716/10000, Loss: 0.008463828824460506\n",
      "Iteration: 5717/10000, Loss: 0.009013048373162746\n",
      "Iteration: 5718/10000, Loss: 0.010522428900003433\n",
      "Iteration: 5719/10000, Loss: 0.017691927030682564\n",
      "Iteration: 5720/10000, Loss: 0.00835191085934639\n",
      "Iteration: 5721/10000, Loss: 0.012869755737483501\n",
      "Iteration: 5722/10000, Loss: 0.01115361787378788\n",
      "Iteration: 5723/10000, Loss: 0.01633256860077381\n",
      "Iteration: 5724/10000, Loss: 0.012335529550909996\n",
      "Iteration: 5725/10000, Loss: 0.013157889246940613\n",
      "Iteration: 5726/10000, Loss: 0.011994587257504463\n",
      "Iteration: 5727/10000, Loss: 0.016371505334973335\n",
      "Iteration: 5728/10000, Loss: 0.01015346311032772\n",
      "Iteration: 5729/10000, Loss: 0.0096674095839262\n",
      "Iteration: 5730/10000, Loss: 0.009910264983773232\n",
      "Iteration: 5731/10000, Loss: 0.006509888917207718\n",
      "Iteration: 5732/10000, Loss: 0.009888109751045704\n",
      "Iteration: 5733/10000, Loss: 0.014017967507243156\n",
      "Iteration: 5734/10000, Loss: 0.008029446937143803\n",
      "Iteration: 5735/10000, Loss: 0.014207354746758938\n",
      "Iteration: 5736/10000, Loss: 0.014798336662352085\n",
      "Iteration: 5737/10000, Loss: 0.01260460540652275\n",
      "Iteration: 5738/10000, Loss: 0.012875131331384182\n",
      "Iteration: 5739/10000, Loss: 0.010444801300764084\n",
      "Iteration: 5740/10000, Loss: 0.009540174156427383\n",
      "Iteration: 5741/10000, Loss: 0.015047560445964336\n",
      "Iteration: 5742/10000, Loss: 0.012786716222763062\n",
      "Iteration: 5743/10000, Loss: 0.015251798555254936\n",
      "Iteration: 5744/10000, Loss: 0.014629230834543705\n",
      "Iteration: 5745/10000, Loss: 0.01098768413066864\n",
      "Iteration: 5746/10000, Loss: 0.010289427824318409\n",
      "Iteration: 5747/10000, Loss: 0.015610679052770138\n",
      "Iteration: 5748/10000, Loss: 0.013744210824370384\n",
      "Iteration: 5749/10000, Loss: 0.008193030953407288\n",
      "Iteration: 5750/10000, Loss: 0.016483290120959282\n",
      "Iteration: 5751/10000, Loss: 0.007038104813545942\n",
      "Iteration: 5752/10000, Loss: 0.0055489311926066875\n",
      "Iteration: 5753/10000, Loss: 0.013479750603437424\n",
      "Iteration: 5754/10000, Loss: 0.009666875936090946\n",
      "Iteration: 5755/10000, Loss: 0.006255295127630234\n",
      "Iteration: 5756/10000, Loss: 0.008133798837661743\n",
      "Iteration: 5757/10000, Loss: 0.00946100614964962\n",
      "Iteration: 5758/10000, Loss: 0.0175522118806839\n",
      "Iteration: 5759/10000, Loss: 0.017064834013581276\n",
      "Iteration: 5760/10000, Loss: 0.011435767635703087\n",
      "Iteration: 5761/10000, Loss: 0.013374880887567997\n",
      "Iteration: 5762/10000, Loss: 0.015847222879529\n",
      "Iteration: 5763/10000, Loss: 0.014641652815043926\n",
      "Iteration: 5764/10000, Loss: 0.015382882207632065\n",
      "Iteration: 5765/10000, Loss: 0.008066263049840927\n",
      "Iteration: 5766/10000, Loss: 0.01095365546643734\n",
      "Iteration: 5767/10000, Loss: 0.015923039987683296\n",
      "Iteration: 5768/10000, Loss: 0.011340536177158356\n",
      "Iteration: 5769/10000, Loss: 0.006866238545626402\n",
      "Iteration: 5770/10000, Loss: 0.007205044385045767\n",
      "Iteration: 5771/10000, Loss: 0.017234183847904205\n",
      "Iteration: 5772/10000, Loss: 0.01478311512619257\n",
      "Iteration: 5773/10000, Loss: 0.014928284101188183\n",
      "Iteration: 5774/10000, Loss: 0.0100344717502594\n",
      "Iteration: 5775/10000, Loss: 0.010723513551056385\n",
      "Iteration: 5776/10000, Loss: 0.008685185573995113\n",
      "Iteration: 5777/10000, Loss: 0.016624068841338158\n",
      "Iteration: 5778/10000, Loss: 0.009435312822461128\n",
      "Iteration: 5779/10000, Loss: 0.012571891769766808\n",
      "Iteration: 5780/10000, Loss: 0.015132983215153217\n",
      "Iteration: 5781/10000, Loss: 0.009215986356139183\n",
      "Iteration: 5782/10000, Loss: 0.009119274094700813\n",
      "Iteration: 5783/10000, Loss: 0.009455728344619274\n",
      "Iteration: 5784/10000, Loss: 0.012288806028664112\n",
      "Iteration: 5785/10000, Loss: 0.011850301176309586\n",
      "Iteration: 5786/10000, Loss: 0.01624440588057041\n",
      "Iteration: 5787/10000, Loss: 0.011528684757649899\n",
      "Iteration: 5788/10000, Loss: 0.009879994206130505\n",
      "Iteration: 5789/10000, Loss: 0.006757866125553846\n",
      "Iteration: 5790/10000, Loss: 0.012747270986437798\n",
      "Iteration: 5791/10000, Loss: 0.009809941984713078\n",
      "Iteration: 5792/10000, Loss: 0.011153904721140862\n",
      "Iteration: 5793/10000, Loss: 0.010707713663578033\n",
      "Iteration: 5794/10000, Loss: 0.01142613310366869\n",
      "Iteration: 5795/10000, Loss: 0.011244547553360462\n",
      "Iteration: 5796/10000, Loss: 0.007283599115908146\n",
      "Iteration: 5797/10000, Loss: 0.012610948644578457\n",
      "Iteration: 5798/10000, Loss: 0.012600873596966267\n",
      "Iteration: 5799/10000, Loss: 0.010972652584314346\n",
      "Iteration: 5800/10000, Loss: 0.006136679090559483\n",
      "Average test loss:  0.0032\n",
      "Iteration: 5801/10000, Loss: 0.012527653016149998\n",
      "Iteration: 5802/10000, Loss: 0.015946179628372192\n",
      "Iteration: 5803/10000, Loss: 0.009856810793280602\n",
      "Iteration: 5804/10000, Loss: 0.014418384060263634\n",
      "Iteration: 5805/10000, Loss: 0.008105670101940632\n",
      "Iteration: 5806/10000, Loss: 0.010127943940460682\n",
      "Iteration: 5807/10000, Loss: 0.00931857991963625\n",
      "Iteration: 5808/10000, Loss: 0.008385157212615013\n",
      "Iteration: 5809/10000, Loss: 0.017377978190779686\n",
      "Iteration: 5810/10000, Loss: 0.015432505868375301\n",
      "Iteration: 5811/10000, Loss: 0.012925742194056511\n",
      "Iteration: 5812/10000, Loss: 0.009369885548949242\n",
      "Iteration: 5813/10000, Loss: 0.012550538405776024\n",
      "Iteration: 5814/10000, Loss: 0.014435471035540104\n",
      "Iteration: 5815/10000, Loss: 0.005554187577217817\n",
      "Iteration: 5816/10000, Loss: 0.012419525533914566\n",
      "Iteration: 5817/10000, Loss: 0.013390032574534416\n",
      "Iteration: 5818/10000, Loss: 0.01267747487872839\n",
      "Iteration: 5819/10000, Loss: 0.012293527834117413\n",
      "Iteration: 5820/10000, Loss: 0.012044152244925499\n",
      "Iteration: 5821/10000, Loss: 0.01086951233446598\n",
      "Iteration: 5822/10000, Loss: 0.020295696333050728\n",
      "Iteration: 5823/10000, Loss: 0.0077321091666817665\n",
      "Iteration: 5824/10000, Loss: 0.013545475900173187\n",
      "Iteration: 5825/10000, Loss: 0.007925093173980713\n",
      "Iteration: 5826/10000, Loss: 0.007741021458059549\n",
      "Iteration: 5827/10000, Loss: 0.011474180035293102\n",
      "Iteration: 5828/10000, Loss: 0.013845613226294518\n",
      "Iteration: 5829/10000, Loss: 0.012078255414962769\n",
      "Iteration: 5830/10000, Loss: 0.010209844447672367\n",
      "Iteration: 5831/10000, Loss: 0.013042702339589596\n",
      "Iteration: 5832/10000, Loss: 0.01136686559766531\n",
      "Iteration: 5833/10000, Loss: 0.01109060924500227\n",
      "Iteration: 5834/10000, Loss: 0.012217860668897629\n",
      "Iteration: 5835/10000, Loss: 0.012478725984692574\n",
      "Iteration: 5836/10000, Loss: 0.008787454105913639\n",
      "Iteration: 5837/10000, Loss: 0.01381797157227993\n",
      "Iteration: 5838/10000, Loss: 0.009542029350996017\n",
      "Iteration: 5839/10000, Loss: 0.012632125057280064\n",
      "Iteration: 5840/10000, Loss: 0.018725380301475525\n",
      "Iteration: 5841/10000, Loss: 0.013127770274877548\n",
      "Iteration: 5842/10000, Loss: 0.013013537041842937\n",
      "Iteration: 5843/10000, Loss: 0.01505008339881897\n",
      "Iteration: 5844/10000, Loss: 0.016239386051893234\n",
      "Iteration: 5845/10000, Loss: 0.017054041847586632\n",
      "Iteration: 5846/10000, Loss: 0.00932722445577383\n",
      "Iteration: 5847/10000, Loss: 0.015821386128664017\n",
      "Iteration: 5848/10000, Loss: 0.010469973087310791\n",
      "Iteration: 5849/10000, Loss: 0.009180857799947262\n",
      "Iteration: 5850/10000, Loss: 0.00804869644343853\n",
      "Iteration: 5851/10000, Loss: 0.012792157009243965\n",
      "Iteration: 5852/10000, Loss: 0.010586148127913475\n",
      "Iteration: 5853/10000, Loss: 0.011507746763527393\n",
      "Iteration: 5854/10000, Loss: 0.012240666896104813\n",
      "Iteration: 5855/10000, Loss: 0.012970929965376854\n",
      "Iteration: 5856/10000, Loss: 0.015700068324804306\n",
      "Iteration: 5857/10000, Loss: 0.014547201804816723\n",
      "Iteration: 5858/10000, Loss: 0.008397437632083893\n",
      "Iteration: 5859/10000, Loss: 0.013498754240572453\n",
      "Iteration: 5860/10000, Loss: 0.008248511701822281\n",
      "Iteration: 5861/10000, Loss: 0.013693380169570446\n",
      "Iteration: 5862/10000, Loss: 0.017246756702661514\n",
      "Iteration: 5863/10000, Loss: 0.007775761652737856\n",
      "Iteration: 5864/10000, Loss: 0.014976207166910172\n",
      "Iteration: 5865/10000, Loss: 0.010831286199390888\n",
      "Iteration: 5866/10000, Loss: 0.009052017703652382\n",
      "Iteration: 5867/10000, Loss: 0.010813429951667786\n",
      "Iteration: 5868/10000, Loss: 0.013639397919178009\n",
      "Iteration: 5869/10000, Loss: 0.01554489228874445\n",
      "Iteration: 5870/10000, Loss: 0.012669876217842102\n",
      "Iteration: 5871/10000, Loss: 0.01076802983880043\n",
      "Iteration: 5872/10000, Loss: 0.014570015482604504\n",
      "Iteration: 5873/10000, Loss: 0.013612846843898296\n",
      "Iteration: 5874/10000, Loss: 0.008387344889342785\n",
      "Iteration: 5875/10000, Loss: 0.017361732199788094\n",
      "Iteration: 5876/10000, Loss: 0.010445920750498772\n",
      "Iteration: 5877/10000, Loss: 0.005869117099791765\n",
      "Iteration: 5878/10000, Loss: 0.01697617769241333\n",
      "Iteration: 5879/10000, Loss: 0.007878763601183891\n",
      "Iteration: 5880/10000, Loss: 0.00693703955039382\n",
      "Iteration: 5881/10000, Loss: 0.010392074473202229\n",
      "Iteration: 5882/10000, Loss: 0.006411768030375242\n",
      "Iteration: 5883/10000, Loss: 0.011615760624408722\n",
      "Iteration: 5884/10000, Loss: 0.01041433122009039\n",
      "Iteration: 5885/10000, Loss: 0.012684328481554985\n",
      "Iteration: 5886/10000, Loss: 0.011139248497784138\n",
      "Iteration: 5887/10000, Loss: 0.010665079578757286\n",
      "Iteration: 5888/10000, Loss: 0.010442035272717476\n",
      "Iteration: 5889/10000, Loss: 0.01287405751645565\n",
      "Iteration: 5890/10000, Loss: 0.011791286058723927\n",
      "Iteration: 5891/10000, Loss: 0.016945242881774902\n",
      "Iteration: 5892/10000, Loss: 0.008225401863455772\n",
      "Iteration: 5893/10000, Loss: 0.013075217604637146\n",
      "Iteration: 5894/10000, Loss: 0.011772440746426582\n",
      "Iteration: 5895/10000, Loss: 0.014203974045813084\n",
      "Iteration: 5896/10000, Loss: 0.010485252365469933\n",
      "Iteration: 5897/10000, Loss: 0.007662145886570215\n",
      "Iteration: 5898/10000, Loss: 0.008283785544335842\n",
      "Iteration: 5899/10000, Loss: 0.009154578670859337\n",
      "Iteration: 5900/10000, Loss: 0.007233398966491222\n",
      "Average test loss:  0.0020\n",
      "Iteration: 5901/10000, Loss: 0.0077741798013448715\n",
      "Iteration: 5902/10000, Loss: 0.014607660472393036\n",
      "Iteration: 5903/10000, Loss: 0.014699572697281837\n",
      "Iteration: 5904/10000, Loss: 0.020908061414957047\n",
      "Iteration: 5905/10000, Loss: 0.014972777105867863\n",
      "Iteration: 5906/10000, Loss: 0.012260827235877514\n",
      "Iteration: 5907/10000, Loss: 0.013681631535291672\n",
      "Iteration: 5908/10000, Loss: 0.009264500811696053\n",
      "Iteration: 5909/10000, Loss: 0.013621145859360695\n",
      "Iteration: 5910/10000, Loss: 0.010316104628145695\n",
      "Iteration: 5911/10000, Loss: 0.011849955655634403\n",
      "Iteration: 5912/10000, Loss: 0.012777221389114857\n",
      "Iteration: 5913/10000, Loss: 0.013095403090119362\n",
      "Iteration: 5914/10000, Loss: 0.01305283885449171\n",
      "Iteration: 5915/10000, Loss: 0.011573879048228264\n",
      "Iteration: 5916/10000, Loss: 0.009285921230912209\n",
      "Iteration: 5917/10000, Loss: 0.003912671469151974\n",
      "Iteration: 5918/10000, Loss: 0.010437867604196072\n",
      "Iteration: 5919/10000, Loss: 0.009180556051433086\n",
      "Iteration: 5920/10000, Loss: 0.00798611156642437\n",
      "Iteration: 5921/10000, Loss: 0.014090292155742645\n",
      "Iteration: 5922/10000, Loss: 0.010846206918358803\n",
      "Iteration: 5923/10000, Loss: 0.010388463735580444\n",
      "Iteration: 5924/10000, Loss: 0.012042916379868984\n",
      "Iteration: 5925/10000, Loss: 0.014625037088990211\n",
      "Iteration: 5926/10000, Loss: 0.007640712894499302\n",
      "Iteration: 5927/10000, Loss: 0.013594013638794422\n",
      "Iteration: 5928/10000, Loss: 0.01147744245827198\n",
      "Iteration: 5929/10000, Loss: 0.017691615968942642\n",
      "Iteration: 5930/10000, Loss: 0.010819927789270878\n",
      "Iteration: 5931/10000, Loss: 0.010778948664665222\n",
      "Iteration: 5932/10000, Loss: 0.010501278564333916\n",
      "Iteration: 5933/10000, Loss: 0.017039451748132706\n",
      "Iteration: 5934/10000, Loss: 0.009564743377268314\n",
      "Iteration: 5935/10000, Loss: 0.004776485729962587\n",
      "Iteration: 5936/10000, Loss: 0.012658348307013512\n",
      "Iteration: 5937/10000, Loss: 0.01446559838950634\n",
      "Iteration: 5938/10000, Loss: 0.008134475909173489\n",
      "Iteration: 5939/10000, Loss: 0.009231985546648502\n",
      "Iteration: 5940/10000, Loss: 0.00839766301214695\n",
      "Iteration: 5941/10000, Loss: 0.01296933926641941\n",
      "Iteration: 5942/10000, Loss: 0.013970811851322651\n",
      "Iteration: 5943/10000, Loss: 0.006706545129418373\n",
      "Iteration: 5944/10000, Loss: 0.012938047759234905\n",
      "Iteration: 5945/10000, Loss: 0.006666334345936775\n",
      "Iteration: 5946/10000, Loss: 0.010124200023710728\n",
      "Iteration: 5947/10000, Loss: 0.008892710320651531\n",
      "Iteration: 5948/10000, Loss: 0.010525129735469818\n",
      "Iteration: 5949/10000, Loss: 0.011210002936422825\n",
      "Iteration: 5950/10000, Loss: 0.011912439949810505\n",
      "Iteration: 5951/10000, Loss: 0.011528647504746914\n",
      "Iteration: 5952/10000, Loss: 0.010621079243719578\n",
      "Iteration: 5953/10000, Loss: 0.008868427947163582\n",
      "Iteration: 5954/10000, Loss: 0.01234996598213911\n",
      "Iteration: 5955/10000, Loss: 0.01241599302738905\n",
      "Iteration: 5956/10000, Loss: 0.01375170424580574\n",
      "Iteration: 5957/10000, Loss: 0.010775573551654816\n",
      "Iteration: 5958/10000, Loss: 0.014976268634200096\n",
      "Iteration: 5959/10000, Loss: 0.017486553639173508\n",
      "Iteration: 5960/10000, Loss: 0.010663817636668682\n",
      "Iteration: 5961/10000, Loss: 0.013294543139636517\n",
      "Iteration: 5962/10000, Loss: 0.012231172993779182\n",
      "Iteration: 5963/10000, Loss: 0.010321203619241714\n",
      "Iteration: 5964/10000, Loss: 0.014683644287288189\n",
      "Iteration: 5965/10000, Loss: 0.013575916178524494\n",
      "Iteration: 5966/10000, Loss: 0.01789243333041668\n",
      "Iteration: 5967/10000, Loss: 0.011051373556256294\n",
      "Iteration: 5968/10000, Loss: 0.014943920075893402\n",
      "Iteration: 5969/10000, Loss: 0.015175983309745789\n",
      "Iteration: 5970/10000, Loss: 0.009400692768394947\n",
      "Iteration: 5971/10000, Loss: 0.013794374652206898\n",
      "Iteration: 5972/10000, Loss: 0.012852301821112633\n",
      "Iteration: 5973/10000, Loss: 0.010245163924992085\n",
      "Iteration: 5974/10000, Loss: 0.015475175343453884\n",
      "Iteration: 5975/10000, Loss: 0.015330689027905464\n",
      "Iteration: 5976/10000, Loss: 0.01442630123347044\n",
      "Iteration: 5977/10000, Loss: 0.011295618489384651\n",
      "Iteration: 5978/10000, Loss: 0.010490015149116516\n",
      "Iteration: 5979/10000, Loss: 0.013355342671275139\n",
      "Iteration: 5980/10000, Loss: 0.012204262427985668\n",
      "Iteration: 5981/10000, Loss: 0.015567620284855366\n",
      "Iteration: 5982/10000, Loss: 0.008081755600869656\n",
      "Iteration: 5983/10000, Loss: 0.010895960964262486\n",
      "Iteration: 5984/10000, Loss: 0.01622137799859047\n",
      "Iteration: 5985/10000, Loss: 0.013898727484047413\n",
      "Iteration: 5986/10000, Loss: 0.011577276512980461\n",
      "Iteration: 5987/10000, Loss: 0.010257753543555737\n",
      "Iteration: 5988/10000, Loss: 0.009030194021761417\n",
      "Iteration: 5989/10000, Loss: 0.012147657573223114\n",
      "Iteration: 5990/10000, Loss: 0.009492411278188229\n",
      "Iteration: 5991/10000, Loss: 0.009661613963544369\n",
      "Iteration: 5992/10000, Loss: 0.01409450825303793\n",
      "Iteration: 5993/10000, Loss: 0.00945226103067398\n",
      "Iteration: 5994/10000, Loss: 0.008588719181716442\n",
      "Iteration: 5995/10000, Loss: 0.010630059987306595\n",
      "Iteration: 5996/10000, Loss: 0.008005423471331596\n",
      "Iteration: 5997/10000, Loss: 0.011210665106773376\n",
      "Iteration: 5998/10000, Loss: 0.022587083280086517\n",
      "Iteration: 5999/10000, Loss: 0.012391814030706882\n",
      "Iteration: 6000/10000, Loss: 0.01650492288172245\n",
      "Average test loss:  0.0024\n",
      "Iteration: 6001/10000, Loss: 0.016782671213150024\n",
      "Iteration: 6002/10000, Loss: 0.008745063096284866\n",
      "Iteration: 6003/10000, Loss: 0.014361520297825336\n",
      "Iteration: 6004/10000, Loss: 0.009405250661075115\n",
      "Iteration: 6005/10000, Loss: 0.014220823533833027\n",
      "Iteration: 6006/10000, Loss: 0.02026093378663063\n",
      "Iteration: 6007/10000, Loss: 0.014808773063123226\n",
      "Iteration: 6008/10000, Loss: 0.009927556850016117\n",
      "Iteration: 6009/10000, Loss: 0.007245482411235571\n",
      "Iteration: 6010/10000, Loss: 0.012719755992293358\n",
      "Iteration: 6011/10000, Loss: 0.010927984490990639\n",
      "Iteration: 6012/10000, Loss: 0.012491024099290371\n",
      "Iteration: 6013/10000, Loss: 0.012804284691810608\n",
      "Iteration: 6014/10000, Loss: 0.007902253419160843\n",
      "Iteration: 6015/10000, Loss: 0.014449229463934898\n",
      "Iteration: 6016/10000, Loss: 0.007639821153134108\n",
      "Iteration: 6017/10000, Loss: 0.007698424160480499\n",
      "Iteration: 6018/10000, Loss: 0.01896531693637371\n",
      "Iteration: 6019/10000, Loss: 0.010048484429717064\n",
      "Iteration: 6020/10000, Loss: 0.010814260691404343\n",
      "Iteration: 6021/10000, Loss: 0.007532614283263683\n",
      "Iteration: 6022/10000, Loss: 0.013404695317149162\n",
      "Iteration: 6023/10000, Loss: 0.013127925805747509\n",
      "Iteration: 6024/10000, Loss: 0.008765025064349174\n",
      "Iteration: 6025/10000, Loss: 0.014003111980855465\n",
      "Iteration: 6026/10000, Loss: 0.0064642359502613544\n",
      "Iteration: 6027/10000, Loss: 0.011550738476216793\n",
      "Iteration: 6028/10000, Loss: 0.01643986441195011\n",
      "Iteration: 6029/10000, Loss: 0.008851648308336735\n",
      "Iteration: 6030/10000, Loss: 0.017853233963251114\n",
      "Iteration: 6031/10000, Loss: 0.013561827130615711\n",
      "Iteration: 6032/10000, Loss: 0.012890972197055817\n",
      "Iteration: 6033/10000, Loss: 0.010594019666314125\n",
      "Iteration: 6034/10000, Loss: 0.01219729520380497\n",
      "Iteration: 6035/10000, Loss: 0.014875257387757301\n",
      "Iteration: 6036/10000, Loss: 0.0130887720733881\n",
      "Iteration: 6037/10000, Loss: 0.013431131839752197\n",
      "Iteration: 6038/10000, Loss: 0.01366381999105215\n",
      "Iteration: 6039/10000, Loss: 0.013758262619376183\n",
      "Iteration: 6040/10000, Loss: 0.015823030844330788\n",
      "Iteration: 6041/10000, Loss: 0.012002931907773018\n",
      "Iteration: 6042/10000, Loss: 0.009151536971330643\n",
      "Iteration: 6043/10000, Loss: 0.011685599572956562\n",
      "Iteration: 6044/10000, Loss: 0.012404643930494785\n",
      "Iteration: 6045/10000, Loss: 0.013325599953532219\n",
      "Iteration: 6046/10000, Loss: 0.012060794979333878\n",
      "Iteration: 6047/10000, Loss: 0.009107165969908237\n",
      "Iteration: 6048/10000, Loss: 0.008920395746827126\n",
      "Iteration: 6049/10000, Loss: 0.013491190969944\n",
      "Iteration: 6050/10000, Loss: 0.009839106351137161\n",
      "Iteration: 6051/10000, Loss: 0.011377322487533092\n",
      "Iteration: 6052/10000, Loss: 0.005866025108844042\n",
      "Iteration: 6053/10000, Loss: 0.009842882864177227\n",
      "Iteration: 6054/10000, Loss: 0.010550864972174168\n",
      "Iteration: 6055/10000, Loss: 0.012933950871229172\n",
      "Iteration: 6056/10000, Loss: 0.007851406000554562\n",
      "Iteration: 6057/10000, Loss: 0.011383753269910812\n",
      "Iteration: 6058/10000, Loss: 0.011255926452577114\n",
      "Iteration: 6059/10000, Loss: 0.006595739629119635\n",
      "Iteration: 6060/10000, Loss: 0.009798495098948479\n",
      "Iteration: 6061/10000, Loss: 0.01237561460584402\n",
      "Iteration: 6062/10000, Loss: 0.01755453459918499\n",
      "Iteration: 6063/10000, Loss: 0.012671755626797676\n",
      "Iteration: 6064/10000, Loss: 0.010503177531063557\n",
      "Iteration: 6065/10000, Loss: 0.010461906902492046\n",
      "Iteration: 6066/10000, Loss: 0.009289640001952648\n",
      "Iteration: 6067/10000, Loss: 0.014478805474936962\n",
      "Iteration: 6068/10000, Loss: 0.010687261819839478\n",
      "Iteration: 6069/10000, Loss: 0.008035368286073208\n",
      "Iteration: 6070/10000, Loss: 0.01171416137367487\n",
      "Iteration: 6071/10000, Loss: 0.014867084100842476\n",
      "Iteration: 6072/10000, Loss: 0.010401709005236626\n",
      "Iteration: 6073/10000, Loss: 0.009343931451439857\n",
      "Iteration: 6074/10000, Loss: 0.011214793659746647\n",
      "Iteration: 6075/10000, Loss: 0.015402339398860931\n",
      "Iteration: 6076/10000, Loss: 0.013704463839530945\n",
      "Iteration: 6077/10000, Loss: 0.006240453105419874\n",
      "Iteration: 6078/10000, Loss: 0.013998160138726234\n",
      "Iteration: 6079/10000, Loss: 0.007408375386148691\n",
      "Iteration: 6080/10000, Loss: 0.012432797811925411\n",
      "Iteration: 6081/10000, Loss: 0.010440513491630554\n",
      "Iteration: 6082/10000, Loss: 0.013093452900648117\n",
      "Iteration: 6083/10000, Loss: 0.013635125011205673\n",
      "Iteration: 6084/10000, Loss: 0.019266318529844284\n",
      "Iteration: 6085/10000, Loss: 0.015066355466842651\n",
      "Iteration: 6086/10000, Loss: 0.009475833736360073\n",
      "Iteration: 6087/10000, Loss: 0.012346161529421806\n",
      "Iteration: 6088/10000, Loss: 0.011883542872965336\n",
      "Iteration: 6089/10000, Loss: 0.011532018892467022\n",
      "Iteration: 6090/10000, Loss: 0.01378880999982357\n",
      "Iteration: 6091/10000, Loss: 0.01853127032518387\n",
      "Iteration: 6092/10000, Loss: 0.011443193070590496\n",
      "Iteration: 6093/10000, Loss: 0.011946968734264374\n",
      "Iteration: 6094/10000, Loss: 0.01107622031122446\n",
      "Iteration: 6095/10000, Loss: 0.014877289533615112\n",
      "Iteration: 6096/10000, Loss: 0.012876918539404869\n",
      "Iteration: 6097/10000, Loss: 0.0092973243445158\n",
      "Iteration: 6098/10000, Loss: 0.008937601931393147\n",
      "Iteration: 6099/10000, Loss: 0.01032322458922863\n",
      "Iteration: 6100/10000, Loss: 0.013022948987782001\n",
      "Average test loss:  0.0050\n",
      "Iteration: 6101/10000, Loss: 0.013808916322886944\n",
      "Iteration: 6102/10000, Loss: 0.009779746644198895\n",
      "Iteration: 6103/10000, Loss: 0.00867189560085535\n",
      "Iteration: 6104/10000, Loss: 0.019238431006669998\n",
      "Iteration: 6105/10000, Loss: 0.010555172339081764\n",
      "Iteration: 6106/10000, Loss: 0.009352482855319977\n",
      "Iteration: 6107/10000, Loss: 0.012062578462064266\n",
      "Iteration: 6108/10000, Loss: 0.009750515222549438\n",
      "Iteration: 6109/10000, Loss: 0.006102397106587887\n",
      "Iteration: 6110/10000, Loss: 0.0116685526445508\n",
      "Iteration: 6111/10000, Loss: 0.012649319134652615\n",
      "Iteration: 6112/10000, Loss: 0.015304535627365112\n",
      "Iteration: 6113/10000, Loss: 0.015480033122003078\n",
      "Iteration: 6114/10000, Loss: 0.011627059429883957\n",
      "Iteration: 6115/10000, Loss: 0.012631339952349663\n",
      "Iteration: 6116/10000, Loss: 0.014757376164197922\n",
      "Iteration: 6117/10000, Loss: 0.013795286417007446\n",
      "Iteration: 6118/10000, Loss: 0.016340311616659164\n",
      "Iteration: 6119/10000, Loss: 0.016162976622581482\n",
      "Iteration: 6120/10000, Loss: 0.010406002402305603\n",
      "Iteration: 6121/10000, Loss: 0.011511335149407387\n",
      "Iteration: 6122/10000, Loss: 0.0068436795845627785\n",
      "Iteration: 6123/10000, Loss: 0.013278370723128319\n",
      "Iteration: 6124/10000, Loss: 0.013660871423780918\n",
      "Iteration: 6125/10000, Loss: 0.007565505802631378\n",
      "Iteration: 6126/10000, Loss: 0.01537466049194336\n",
      "Iteration: 6127/10000, Loss: 0.012367980554699898\n",
      "Iteration: 6128/10000, Loss: 0.007680996786803007\n",
      "Iteration: 6129/10000, Loss: 0.013371937908232212\n",
      "Iteration: 6130/10000, Loss: 0.010367641225457191\n",
      "Iteration: 6131/10000, Loss: 0.0087219113484025\n",
      "Iteration: 6132/10000, Loss: 0.007151083089411259\n",
      "Iteration: 6133/10000, Loss: 0.011839745566248894\n",
      "Iteration: 6134/10000, Loss: 0.013653888367116451\n",
      "Iteration: 6135/10000, Loss: 0.009245696477591991\n",
      "Iteration: 6136/10000, Loss: 0.013219725340604782\n",
      "Iteration: 6137/10000, Loss: 0.01659742370247841\n",
      "Iteration: 6138/10000, Loss: 0.015572022646665573\n",
      "Iteration: 6139/10000, Loss: 0.0093529699370265\n",
      "Iteration: 6140/10000, Loss: 0.01360106747597456\n",
      "Iteration: 6141/10000, Loss: 0.012356887571513653\n",
      "Iteration: 6142/10000, Loss: 0.013498945161700249\n",
      "Iteration: 6143/10000, Loss: 0.007456587627530098\n",
      "Iteration: 6144/10000, Loss: 0.01932315155863762\n",
      "Iteration: 6145/10000, Loss: 0.008669792674481869\n",
      "Iteration: 6146/10000, Loss: 0.011760990135371685\n",
      "Iteration: 6147/10000, Loss: 0.01268082857131958\n",
      "Iteration: 6148/10000, Loss: 0.011621787212789059\n",
      "Iteration: 6149/10000, Loss: 0.009391941130161285\n",
      "Iteration: 6150/10000, Loss: 0.013488063588738441\n",
      "Iteration: 6151/10000, Loss: 0.00819898396730423\n",
      "Iteration: 6152/10000, Loss: 0.01091545820236206\n",
      "Iteration: 6153/10000, Loss: 0.01089028362184763\n",
      "Iteration: 6154/10000, Loss: 0.016557298600673676\n",
      "Iteration: 6155/10000, Loss: 0.009388506412506104\n",
      "Iteration: 6156/10000, Loss: 0.00816521979868412\n",
      "Iteration: 6157/10000, Loss: 0.011388412676751614\n",
      "Iteration: 6158/10000, Loss: 0.011153100058436394\n",
      "Iteration: 6159/10000, Loss: 0.01064880657941103\n",
      "Iteration: 6160/10000, Loss: 0.018815746530890465\n",
      "Iteration: 6161/10000, Loss: 0.012904074043035507\n",
      "Iteration: 6162/10000, Loss: 0.007697402033954859\n",
      "Iteration: 6163/10000, Loss: 0.011065973900258541\n",
      "Iteration: 6164/10000, Loss: 0.012687447480857372\n",
      "Iteration: 6165/10000, Loss: 0.012207125313580036\n",
      "Iteration: 6166/10000, Loss: 0.009692535735666752\n",
      "Iteration: 6167/10000, Loss: 0.01678767055273056\n",
      "Iteration: 6168/10000, Loss: 0.010148249566555023\n",
      "Iteration: 6169/10000, Loss: 0.01123683899641037\n",
      "Iteration: 6170/10000, Loss: 0.01784910075366497\n",
      "Iteration: 6171/10000, Loss: 0.01646813005208969\n",
      "Iteration: 6172/10000, Loss: 0.016102096065878868\n",
      "Iteration: 6173/10000, Loss: 0.007531533017754555\n",
      "Iteration: 6174/10000, Loss: 0.009534151293337345\n",
      "Iteration: 6175/10000, Loss: 0.015115796588361263\n",
      "Iteration: 6176/10000, Loss: 0.013164684176445007\n",
      "Iteration: 6177/10000, Loss: 0.011881809681653976\n",
      "Iteration: 6178/10000, Loss: 0.013786932453513145\n",
      "Iteration: 6179/10000, Loss: 0.011620654724538326\n",
      "Iteration: 6180/10000, Loss: 0.00798093993216753\n",
      "Iteration: 6181/10000, Loss: 0.010472814552485943\n",
      "Iteration: 6182/10000, Loss: 0.012235265225172043\n",
      "Iteration: 6183/10000, Loss: 0.009512998163700104\n",
      "Iteration: 6184/10000, Loss: 0.023311955854296684\n",
      "Iteration: 6185/10000, Loss: 0.01798168756067753\n",
      "Iteration: 6186/10000, Loss: 0.012285523116588593\n",
      "Iteration: 6187/10000, Loss: 0.01790408417582512\n",
      "Iteration: 6188/10000, Loss: 0.013015041127800941\n",
      "Iteration: 6189/10000, Loss: 0.008961810730397701\n",
      "Iteration: 6190/10000, Loss: 0.011843152344226837\n",
      "Iteration: 6191/10000, Loss: 0.013827653601765633\n",
      "Iteration: 6192/10000, Loss: 0.011811062693595886\n",
      "Iteration: 6193/10000, Loss: 0.017778316512703896\n",
      "Iteration: 6194/10000, Loss: 0.02479637786746025\n",
      "Iteration: 6195/10000, Loss: 0.011597748845815659\n",
      "Iteration: 6196/10000, Loss: 0.008934197016060352\n",
      "Iteration: 6197/10000, Loss: 0.017323918640613556\n",
      "Iteration: 6198/10000, Loss: 0.02102024294435978\n",
      "Iteration: 6199/10000, Loss: 0.010706732980906963\n",
      "Iteration: 6200/10000, Loss: 0.012973898090422153\n",
      "Average test loss:  0.0043\n",
      "Iteration: 6201/10000, Loss: 0.01969187706708908\n",
      "Iteration: 6202/10000, Loss: 0.016258785501122475\n",
      "Iteration: 6203/10000, Loss: 0.013121671043336391\n",
      "Iteration: 6204/10000, Loss: 0.014510173350572586\n",
      "Iteration: 6205/10000, Loss: 0.011117374524474144\n",
      "Iteration: 6206/10000, Loss: 0.010735297575592995\n",
      "Iteration: 6207/10000, Loss: 0.01287663821130991\n",
      "Iteration: 6208/10000, Loss: 0.010944969020783901\n",
      "Iteration: 6209/10000, Loss: 0.007918098010122776\n",
      "Iteration: 6210/10000, Loss: 0.015581678599119186\n",
      "Iteration: 6211/10000, Loss: 0.0072707743383944035\n",
      "Iteration: 6212/10000, Loss: 0.016585491597652435\n",
      "Iteration: 6213/10000, Loss: 0.011793818324804306\n",
      "Iteration: 6214/10000, Loss: 0.014391184784471989\n",
      "Iteration: 6215/10000, Loss: 0.014341069385409355\n",
      "Iteration: 6216/10000, Loss: 0.01473823469132185\n",
      "Iteration: 6217/10000, Loss: 0.013773998245596886\n",
      "Iteration: 6218/10000, Loss: 0.015486360527575016\n",
      "Iteration: 6219/10000, Loss: 0.017444951459765434\n",
      "Iteration: 6220/10000, Loss: 0.007489384151995182\n",
      "Iteration: 6221/10000, Loss: 0.009574891068041325\n",
      "Iteration: 6222/10000, Loss: 0.012983664870262146\n",
      "Iteration: 6223/10000, Loss: 0.016833877190947533\n",
      "Iteration: 6224/10000, Loss: 0.014318341389298439\n",
      "Iteration: 6225/10000, Loss: 0.016078921034932137\n",
      "Iteration: 6226/10000, Loss: 0.011453128419816494\n",
      "Iteration: 6227/10000, Loss: 0.013031567446887493\n",
      "Iteration: 6228/10000, Loss: 0.013072388246655464\n",
      "Iteration: 6229/10000, Loss: 0.010791509412229061\n",
      "Iteration: 6230/10000, Loss: 0.01091665681451559\n",
      "Iteration: 6231/10000, Loss: 0.018698690459132195\n",
      "Iteration: 6232/10000, Loss: 0.010185608640313148\n",
      "Iteration: 6233/10000, Loss: 0.014136199839413166\n",
      "Iteration: 6234/10000, Loss: 0.013021416962146759\n",
      "Iteration: 6235/10000, Loss: 0.01374631654471159\n",
      "Iteration: 6236/10000, Loss: 0.011012621223926544\n",
      "Iteration: 6237/10000, Loss: 0.012791331857442856\n",
      "Iteration: 6238/10000, Loss: 0.010782339610159397\n",
      "Iteration: 6239/10000, Loss: 0.012397073209285736\n",
      "Iteration: 6240/10000, Loss: 0.010436909273266792\n",
      "Iteration: 6241/10000, Loss: 0.008830888196825981\n",
      "Iteration: 6242/10000, Loss: 0.01368460152298212\n",
      "Iteration: 6243/10000, Loss: 0.011184749193489552\n",
      "Iteration: 6244/10000, Loss: 0.011328672058880329\n",
      "Iteration: 6245/10000, Loss: 0.011245260015130043\n",
      "Iteration: 6246/10000, Loss: 0.018954019993543625\n",
      "Iteration: 6247/10000, Loss: 0.012005357071757317\n",
      "Iteration: 6248/10000, Loss: 0.01728731021285057\n",
      "Iteration: 6249/10000, Loss: 0.009146359749138355\n",
      "Iteration: 6250/10000, Loss: 0.00883038341999054\n",
      "Iteration: 6251/10000, Loss: 0.018955634906888008\n",
      "Iteration: 6252/10000, Loss: 0.011443767696619034\n",
      "Iteration: 6253/10000, Loss: 0.00860626995563507\n",
      "Iteration: 6254/10000, Loss: 0.014859752729535103\n",
      "Iteration: 6255/10000, Loss: 0.015120413154363632\n",
      "Iteration: 6256/10000, Loss: 0.009030341170728207\n",
      "Iteration: 6257/10000, Loss: 0.010731777176260948\n",
      "Iteration: 6258/10000, Loss: 0.01630565896630287\n",
      "Iteration: 6259/10000, Loss: 0.010476112365722656\n",
      "Iteration: 6260/10000, Loss: 0.011010367423295975\n",
      "Iteration: 6261/10000, Loss: 0.0135831693187356\n",
      "Iteration: 6262/10000, Loss: 0.010730035603046417\n",
      "Iteration: 6263/10000, Loss: 0.018114671111106873\n",
      "Iteration: 6264/10000, Loss: 0.013614808209240437\n",
      "Iteration: 6265/10000, Loss: 0.014787837862968445\n",
      "Iteration: 6266/10000, Loss: 0.01484024990350008\n",
      "Iteration: 6267/10000, Loss: 0.011262700892984867\n",
      "Iteration: 6268/10000, Loss: 0.012869826517999172\n",
      "Iteration: 6269/10000, Loss: 0.014985733665525913\n",
      "Iteration: 6270/10000, Loss: 0.012045737355947495\n",
      "Iteration: 6271/10000, Loss: 0.015665682032704353\n",
      "Iteration: 6272/10000, Loss: 0.014195241034030914\n",
      "Iteration: 6273/10000, Loss: 0.010351574048399925\n",
      "Iteration: 6274/10000, Loss: 0.013030950911343098\n",
      "Iteration: 6275/10000, Loss: 0.01387599017471075\n",
      "Iteration: 6276/10000, Loss: 0.012080909684300423\n",
      "Iteration: 6277/10000, Loss: 0.015217993408441544\n",
      "Iteration: 6278/10000, Loss: 0.011024441570043564\n",
      "Iteration: 6279/10000, Loss: 0.010540955699980259\n",
      "Iteration: 6280/10000, Loss: 0.006486956495791674\n",
      "Iteration: 6281/10000, Loss: 0.011114628054201603\n",
      "Iteration: 6282/10000, Loss: 0.007810923736542463\n",
      "Iteration: 6283/10000, Loss: 0.006347570102661848\n",
      "Iteration: 6284/10000, Loss: 0.012378524988889694\n",
      "Iteration: 6285/10000, Loss: 0.020601827651262283\n",
      "Iteration: 6286/10000, Loss: 0.009437224827706814\n",
      "Iteration: 6287/10000, Loss: 0.016919583082199097\n",
      "Iteration: 6288/10000, Loss: 0.011196413077414036\n",
      "Iteration: 6289/10000, Loss: 0.008897047489881516\n",
      "Iteration: 6290/10000, Loss: 0.012830575928092003\n",
      "Iteration: 6291/10000, Loss: 0.010549824684858322\n",
      "Iteration: 6292/10000, Loss: 0.01453440636396408\n",
      "Iteration: 6293/10000, Loss: 0.01810322515666485\n",
      "Iteration: 6294/10000, Loss: 0.009808546863496304\n",
      "Iteration: 6295/10000, Loss: 0.013079553842544556\n",
      "Iteration: 6296/10000, Loss: 0.009554523974657059\n",
      "Iteration: 6297/10000, Loss: 0.01622491329908371\n",
      "Iteration: 6298/10000, Loss: 0.012317951768636703\n",
      "Iteration: 6299/10000, Loss: 0.008996465243399143\n",
      "Iteration: 6300/10000, Loss: 0.011649449355900288\n",
      "Average test loss:  0.0022\n",
      "Iteration: 6301/10000, Loss: 0.014720577746629715\n",
      "Iteration: 6302/10000, Loss: 0.008549148216843605\n",
      "Iteration: 6303/10000, Loss: 0.010152877308428288\n",
      "Iteration: 6304/10000, Loss: 0.01232853066176176\n",
      "Iteration: 6305/10000, Loss: 0.01433818694204092\n",
      "Iteration: 6306/10000, Loss: 0.010951651260256767\n",
      "Iteration: 6307/10000, Loss: 0.010815228335559368\n",
      "Iteration: 6308/10000, Loss: 0.012182487174868584\n",
      "Iteration: 6309/10000, Loss: 0.013689570128917694\n",
      "Iteration: 6310/10000, Loss: 0.01082723867148161\n",
      "Iteration: 6311/10000, Loss: 0.01219368539750576\n",
      "Iteration: 6312/10000, Loss: 0.016028529033064842\n",
      "Iteration: 6313/10000, Loss: 0.012173591181635857\n",
      "Iteration: 6314/10000, Loss: 0.012652386911213398\n",
      "Iteration: 6315/10000, Loss: 0.013445110991597176\n",
      "Iteration: 6316/10000, Loss: 0.010529608465731144\n",
      "Iteration: 6317/10000, Loss: 0.016109930351376534\n",
      "Iteration: 6318/10000, Loss: 0.006926847621798515\n",
      "Iteration: 6319/10000, Loss: 0.01349021214991808\n",
      "Iteration: 6320/10000, Loss: 0.017678694799542427\n",
      "Iteration: 6321/10000, Loss: 0.011157436296343803\n",
      "Iteration: 6322/10000, Loss: 0.010501425713300705\n",
      "Iteration: 6323/10000, Loss: 0.012695543467998505\n",
      "Iteration: 6324/10000, Loss: 0.00674325879663229\n",
      "Iteration: 6325/10000, Loss: 0.010380249470472336\n",
      "Iteration: 6326/10000, Loss: 0.013427839614450932\n",
      "Iteration: 6327/10000, Loss: 0.01557045429944992\n",
      "Iteration: 6328/10000, Loss: 0.013820817694067955\n",
      "Iteration: 6329/10000, Loss: 0.010468922555446625\n",
      "Iteration: 6330/10000, Loss: 0.01625274308025837\n",
      "Iteration: 6331/10000, Loss: 0.011423246935009956\n",
      "Iteration: 6332/10000, Loss: 0.013293796218931675\n",
      "Iteration: 6333/10000, Loss: 0.013929769396781921\n",
      "Iteration: 6334/10000, Loss: 0.0117998868227005\n",
      "Iteration: 6335/10000, Loss: 0.014160355553030968\n",
      "Iteration: 6336/10000, Loss: 0.007932723499834538\n",
      "Iteration: 6337/10000, Loss: 0.004833473823964596\n",
      "Iteration: 6338/10000, Loss: 0.006432974711060524\n",
      "Iteration: 6339/10000, Loss: 0.01863085851073265\n",
      "Iteration: 6340/10000, Loss: 0.010371874086558819\n",
      "Iteration: 6341/10000, Loss: 0.01091527845710516\n",
      "Iteration: 6342/10000, Loss: 0.011912601999938488\n",
      "Iteration: 6343/10000, Loss: 0.01014511939138174\n",
      "Iteration: 6344/10000, Loss: 0.011617178097367287\n",
      "Iteration: 6345/10000, Loss: 0.011772365309298038\n",
      "Iteration: 6346/10000, Loss: 0.007903396151959896\n",
      "Iteration: 6347/10000, Loss: 0.006370539776980877\n",
      "Iteration: 6348/10000, Loss: 0.015346333384513855\n",
      "Iteration: 6349/10000, Loss: 0.013030698522925377\n",
      "Iteration: 6350/10000, Loss: 0.011820115149021149\n",
      "Iteration: 6351/10000, Loss: 0.00972691085189581\n",
      "Iteration: 6352/10000, Loss: 0.01164302323013544\n",
      "Iteration: 6353/10000, Loss: 0.01167548168450594\n",
      "Iteration: 6354/10000, Loss: 0.009870782494544983\n",
      "Iteration: 6355/10000, Loss: 0.010724615305662155\n",
      "Iteration: 6356/10000, Loss: 0.006328066345304251\n",
      "Iteration: 6357/10000, Loss: 0.017029087990522385\n",
      "Iteration: 6358/10000, Loss: 0.006496873218566179\n",
      "Iteration: 6359/10000, Loss: 0.010970738716423512\n",
      "Iteration: 6360/10000, Loss: 0.013595152646303177\n",
      "Iteration: 6361/10000, Loss: 0.014886341989040375\n",
      "Iteration: 6362/10000, Loss: 0.009337835013866425\n",
      "Iteration: 6363/10000, Loss: 0.010428654961287975\n",
      "Iteration: 6364/10000, Loss: 0.011959658935666084\n",
      "Iteration: 6365/10000, Loss: 0.01239820197224617\n",
      "Iteration: 6366/10000, Loss: 0.013702331110835075\n",
      "Iteration: 6367/10000, Loss: 0.011757242493331432\n",
      "Iteration: 6368/10000, Loss: 0.008921359665691853\n",
      "Iteration: 6369/10000, Loss: 0.013439279049634933\n",
      "Iteration: 6370/10000, Loss: 0.012904299423098564\n",
      "Iteration: 6371/10000, Loss: 0.011189489625394344\n",
      "Iteration: 6372/10000, Loss: 0.014148049987852573\n",
      "Iteration: 6373/10000, Loss: 0.013855990022420883\n",
      "Iteration: 6374/10000, Loss: 0.016838038340210915\n",
      "Iteration: 6375/10000, Loss: 0.012385163456201553\n",
      "Iteration: 6376/10000, Loss: 0.006708238273859024\n",
      "Iteration: 6377/10000, Loss: 0.010236386209726334\n",
      "Iteration: 6378/10000, Loss: 0.008124311454594135\n",
      "Iteration: 6379/10000, Loss: 0.011919097043573856\n",
      "Iteration: 6380/10000, Loss: 0.017333436757326126\n",
      "Iteration: 6381/10000, Loss: 0.0051457230001688\n",
      "Iteration: 6382/10000, Loss: 0.008555257692933083\n",
      "Iteration: 6383/10000, Loss: 0.008592542260885239\n",
      "Iteration: 6384/10000, Loss: 0.012735211290419102\n",
      "Iteration: 6385/10000, Loss: 0.009770386852324009\n",
      "Iteration: 6386/10000, Loss: 0.01288878545165062\n",
      "Iteration: 6387/10000, Loss: 0.01031891256570816\n",
      "Iteration: 6388/10000, Loss: 0.00768759660422802\n",
      "Iteration: 6389/10000, Loss: 0.01296025700867176\n",
      "Iteration: 6390/10000, Loss: 0.010768542997539043\n",
      "Iteration: 6391/10000, Loss: 0.014441195875406265\n",
      "Iteration: 6392/10000, Loss: 0.010523883625864983\n",
      "Iteration: 6393/10000, Loss: 0.01043117418885231\n",
      "Iteration: 6394/10000, Loss: 0.0195743590593338\n",
      "Iteration: 6395/10000, Loss: 0.014468161389231682\n",
      "Iteration: 6396/10000, Loss: 0.00844542495906353\n",
      "Iteration: 6397/10000, Loss: 0.014286249876022339\n",
      "Iteration: 6398/10000, Loss: 0.015387370251119137\n",
      "Iteration: 6399/10000, Loss: 0.01385064609348774\n",
      "Iteration: 6400/10000, Loss: 0.010261202231049538\n",
      "Average test loss:  0.0016\n",
      "Iteration: 6401/10000, Loss: 0.009663164615631104\n",
      "Iteration: 6402/10000, Loss: 0.013957595452666283\n",
      "Iteration: 6403/10000, Loss: 0.007014475762844086\n",
      "Iteration: 6404/10000, Loss: 0.011751314625144005\n",
      "Iteration: 6405/10000, Loss: 0.012987337075173855\n",
      "Iteration: 6406/10000, Loss: 0.011567757464945316\n",
      "Iteration: 6407/10000, Loss: 0.009122081100940704\n",
      "Iteration: 6408/10000, Loss: 0.010677430778741837\n",
      "Iteration: 6409/10000, Loss: 0.00865219533443451\n",
      "Iteration: 6410/10000, Loss: 0.005695979110896587\n",
      "Iteration: 6411/10000, Loss: 0.011233444325625896\n",
      "Iteration: 6412/10000, Loss: 0.008888782002031803\n",
      "Iteration: 6413/10000, Loss: 0.01215436588972807\n",
      "Iteration: 6414/10000, Loss: 0.009615995921194553\n",
      "Iteration: 6415/10000, Loss: 0.01070092711597681\n",
      "Iteration: 6416/10000, Loss: 0.011230731382966042\n",
      "Iteration: 6417/10000, Loss: 0.0129892872646451\n",
      "Iteration: 6418/10000, Loss: 0.011599654331803322\n",
      "Iteration: 6419/10000, Loss: 0.01025931816548109\n",
      "Iteration: 6420/10000, Loss: 0.014988313429057598\n",
      "Iteration: 6421/10000, Loss: 0.006444632541388273\n",
      "Iteration: 6422/10000, Loss: 0.014656808227300644\n",
      "Iteration: 6423/10000, Loss: 0.01326221227645874\n",
      "Iteration: 6424/10000, Loss: 0.010767444036900997\n",
      "Iteration: 6425/10000, Loss: 0.011878974735736847\n",
      "Iteration: 6426/10000, Loss: 0.015490085817873478\n",
      "Iteration: 6427/10000, Loss: 0.011539521627128124\n",
      "Iteration: 6428/10000, Loss: 0.01330309547483921\n",
      "Iteration: 6429/10000, Loss: 0.010066568851470947\n",
      "Iteration: 6430/10000, Loss: 0.010265104472637177\n",
      "Iteration: 6431/10000, Loss: 0.0077033694833517075\n",
      "Iteration: 6432/10000, Loss: 0.013876992277801037\n",
      "Iteration: 6433/10000, Loss: 0.01097148284316063\n",
      "Iteration: 6434/10000, Loss: 0.010501984506845474\n",
      "Iteration: 6435/10000, Loss: 0.01956077292561531\n",
      "Iteration: 6436/10000, Loss: 0.00940367765724659\n",
      "Iteration: 6437/10000, Loss: 0.013194224797189236\n",
      "Iteration: 6438/10000, Loss: 0.008192353881895542\n",
      "Iteration: 6439/10000, Loss: 0.010241253301501274\n",
      "Iteration: 6440/10000, Loss: 0.008553012274205685\n",
      "Iteration: 6441/10000, Loss: 0.013837712816894054\n",
      "Iteration: 6442/10000, Loss: 0.01064589899033308\n",
      "Iteration: 6443/10000, Loss: 0.011121941730380058\n",
      "Iteration: 6444/10000, Loss: 0.01033773459494114\n",
      "Iteration: 6445/10000, Loss: 0.010485864244401455\n",
      "Iteration: 6446/10000, Loss: 0.006035839673131704\n",
      "Iteration: 6447/10000, Loss: 0.011991971172392368\n",
      "Iteration: 6448/10000, Loss: 0.010592392645776272\n",
      "Iteration: 6449/10000, Loss: 0.012815337628126144\n",
      "Iteration: 6450/10000, Loss: 0.013391303829848766\n",
      "Iteration: 6451/10000, Loss: 0.015075861476361752\n",
      "Iteration: 6452/10000, Loss: 0.013160490430891514\n",
      "Iteration: 6453/10000, Loss: 0.012846352532505989\n",
      "Iteration: 6454/10000, Loss: 0.015736842527985573\n",
      "Iteration: 6455/10000, Loss: 0.011425847187638283\n",
      "Iteration: 6456/10000, Loss: 0.011291194707155228\n",
      "Iteration: 6457/10000, Loss: 0.01024357508867979\n",
      "Iteration: 6458/10000, Loss: 0.010597207583487034\n",
      "Iteration: 6459/10000, Loss: 0.008676020428538322\n",
      "Iteration: 6460/10000, Loss: 0.013786997646093369\n",
      "Iteration: 6461/10000, Loss: 0.013998054899275303\n",
      "Iteration: 6462/10000, Loss: 0.00920352153480053\n",
      "Iteration: 6463/10000, Loss: 0.01008240133523941\n",
      "Iteration: 6464/10000, Loss: 0.011196721345186234\n",
      "Iteration: 6465/10000, Loss: 0.0076441229321062565\n",
      "Iteration: 6466/10000, Loss: 0.01829240843653679\n",
      "Iteration: 6467/10000, Loss: 0.012849264778196812\n",
      "Iteration: 6468/10000, Loss: 0.013769827783107758\n",
      "Iteration: 6469/10000, Loss: 0.011325926519930363\n",
      "Iteration: 6470/10000, Loss: 0.0128543172031641\n",
      "Iteration: 6471/10000, Loss: 0.015179532580077648\n",
      "Iteration: 6472/10000, Loss: 0.008523368276655674\n",
      "Iteration: 6473/10000, Loss: 0.01337919570505619\n",
      "Iteration: 6474/10000, Loss: 0.013076530769467354\n",
      "Iteration: 6475/10000, Loss: 0.01552251074463129\n",
      "Iteration: 6476/10000, Loss: 0.00901002250611782\n",
      "Iteration: 6477/10000, Loss: 0.009672963060438633\n",
      "Iteration: 6478/10000, Loss: 0.010165442712605\n",
      "Iteration: 6479/10000, Loss: 0.010280377231538296\n",
      "Iteration: 6480/10000, Loss: 0.017700547352433205\n",
      "Iteration: 6481/10000, Loss: 0.017650431022047997\n",
      "Iteration: 6482/10000, Loss: 0.011742524802684784\n",
      "Iteration: 6483/10000, Loss: 0.014187311753630638\n",
      "Iteration: 6484/10000, Loss: 0.011199704371392727\n",
      "Iteration: 6485/10000, Loss: 0.013539495877921581\n",
      "Iteration: 6486/10000, Loss: 0.012221419252455235\n",
      "Iteration: 6487/10000, Loss: 0.011228702962398529\n",
      "Iteration: 6488/10000, Loss: 0.008574770763516426\n",
      "Iteration: 6489/10000, Loss: 0.010488924570381641\n",
      "Iteration: 6490/10000, Loss: 0.012189093977212906\n",
      "Iteration: 6491/10000, Loss: 0.007531501352787018\n",
      "Iteration: 6492/10000, Loss: 0.008288359269499779\n",
      "Iteration: 6493/10000, Loss: 0.01990428753197193\n",
      "Iteration: 6494/10000, Loss: 0.016564616933465004\n",
      "Iteration: 6495/10000, Loss: 0.009579138830304146\n",
      "Iteration: 6496/10000, Loss: 0.011523034423589706\n",
      "Iteration: 6497/10000, Loss: 0.012991880066692829\n",
      "Iteration: 6498/10000, Loss: 0.013646726496517658\n",
      "Iteration: 6499/10000, Loss: 0.008668660186231136\n",
      "Iteration: 6500/10000, Loss: 0.010752500966191292\n",
      "Average test loss:  0.0022\n",
      "Iteration: 6501/10000, Loss: 0.008270694874227047\n",
      "Iteration: 6502/10000, Loss: 0.012965264730155468\n",
      "Iteration: 6503/10000, Loss: 0.01147005707025528\n",
      "Iteration: 6504/10000, Loss: 0.006654846016317606\n",
      "Iteration: 6505/10000, Loss: 0.014688446186482906\n",
      "Iteration: 6506/10000, Loss: 0.010497798211872578\n",
      "Iteration: 6507/10000, Loss: 0.012324663810431957\n",
      "Iteration: 6508/10000, Loss: 0.018762962892651558\n",
      "Iteration: 6509/10000, Loss: 0.008259703405201435\n",
      "Iteration: 6510/10000, Loss: 0.003384921234101057\n",
      "Iteration: 6511/10000, Loss: 0.009570527821779251\n",
      "Iteration: 6512/10000, Loss: 0.009442123584449291\n",
      "Iteration: 6513/10000, Loss: 0.010774390771985054\n",
      "Iteration: 6514/10000, Loss: 0.012421107850968838\n",
      "Iteration: 6515/10000, Loss: 0.018139390274882317\n",
      "Iteration: 6516/10000, Loss: 0.009448792785406113\n",
      "Iteration: 6517/10000, Loss: 0.01259325910359621\n",
      "Iteration: 6518/10000, Loss: 0.01231984794139862\n",
      "Iteration: 6519/10000, Loss: 0.006133283954113722\n",
      "Iteration: 6520/10000, Loss: 0.013107710517942905\n",
      "Iteration: 6521/10000, Loss: 0.00883011519908905\n",
      "Iteration: 6522/10000, Loss: 0.00856610108166933\n",
      "Iteration: 6523/10000, Loss: 0.019245317205786705\n",
      "Iteration: 6524/10000, Loss: 0.010861978866159916\n",
      "Iteration: 6525/10000, Loss: 0.01473128329962492\n",
      "Iteration: 6526/10000, Loss: 0.012508981861174107\n",
      "Iteration: 6527/10000, Loss: 0.01153973676264286\n",
      "Iteration: 6528/10000, Loss: 0.013053545728325844\n",
      "Iteration: 6529/10000, Loss: 0.009460093453526497\n",
      "Iteration: 6530/10000, Loss: 0.018452901393175125\n",
      "Iteration: 6531/10000, Loss: 0.011757295578718185\n",
      "Iteration: 6532/10000, Loss: 0.012443228624761105\n",
      "Iteration: 6533/10000, Loss: 0.012444589287042618\n",
      "Iteration: 6534/10000, Loss: 0.012006462551653385\n",
      "Iteration: 6535/10000, Loss: 0.010500432923436165\n",
      "Iteration: 6536/10000, Loss: 0.010711239650845528\n",
      "Iteration: 6537/10000, Loss: 0.012058136984705925\n",
      "Iteration: 6538/10000, Loss: 0.009189772419631481\n",
      "Iteration: 6539/10000, Loss: 0.007100559305399656\n",
      "Iteration: 6540/10000, Loss: 0.01231920812278986\n",
      "Iteration: 6541/10000, Loss: 0.006064338609576225\n",
      "Iteration: 6542/10000, Loss: 0.01352611929178238\n",
      "Iteration: 6543/10000, Loss: 0.00962568074464798\n",
      "Iteration: 6544/10000, Loss: 0.012305213138461113\n",
      "Iteration: 6545/10000, Loss: 0.007191813085228205\n",
      "Iteration: 6546/10000, Loss: 0.011489061638712883\n",
      "Iteration: 6547/10000, Loss: 0.014494210481643677\n",
      "Iteration: 6548/10000, Loss: 0.013180253095924854\n",
      "Iteration: 6549/10000, Loss: 0.013189835473895073\n",
      "Iteration: 6550/10000, Loss: 0.016000917181372643\n",
      "Iteration: 6551/10000, Loss: 0.006291096098721027\n",
      "Iteration: 6552/10000, Loss: 0.010093344375491142\n",
      "Iteration: 6553/10000, Loss: 0.012966143898665905\n",
      "Iteration: 6554/10000, Loss: 0.010716677643358707\n",
      "Iteration: 6555/10000, Loss: 0.008742552250623703\n",
      "Iteration: 6556/10000, Loss: 0.01925480365753174\n",
      "Iteration: 6557/10000, Loss: 0.015550750307738781\n",
      "Iteration: 6558/10000, Loss: 0.013160708360373974\n",
      "Iteration: 6559/10000, Loss: 0.010774355381727219\n",
      "Iteration: 6560/10000, Loss: 0.01074848510324955\n",
      "Iteration: 6561/10000, Loss: 0.014784658327698708\n",
      "Iteration: 6562/10000, Loss: 0.012899314053356647\n",
      "Iteration: 6563/10000, Loss: 0.007282630540430546\n",
      "Iteration: 6564/10000, Loss: 0.009643145836889744\n",
      "Iteration: 6565/10000, Loss: 0.01149868406355381\n",
      "Iteration: 6566/10000, Loss: 0.01332419365644455\n",
      "Iteration: 6567/10000, Loss: 0.012568492442369461\n",
      "Iteration: 6568/10000, Loss: 0.01619029976427555\n",
      "Iteration: 6569/10000, Loss: 0.01164586003869772\n",
      "Iteration: 6570/10000, Loss: 0.009794113226234913\n",
      "Iteration: 6571/10000, Loss: 0.008748335763812065\n",
      "Iteration: 6572/10000, Loss: 0.011972115375101566\n",
      "Iteration: 6573/10000, Loss: 0.0071437475271523\n",
      "Iteration: 6574/10000, Loss: 0.00975808221846819\n",
      "Iteration: 6575/10000, Loss: 0.016278622671961784\n",
      "Iteration: 6576/10000, Loss: 0.011915798299014568\n",
      "Iteration: 6577/10000, Loss: 0.011919138953089714\n",
      "Iteration: 6578/10000, Loss: 0.011188885197043419\n",
      "Iteration: 6579/10000, Loss: 0.0077299694530665874\n",
      "Iteration: 6580/10000, Loss: 0.010638084262609482\n",
      "Iteration: 6581/10000, Loss: 0.012127627618610859\n",
      "Iteration: 6582/10000, Loss: 0.014842137694358826\n",
      "Iteration: 6583/10000, Loss: 0.009660866111516953\n",
      "Iteration: 6584/10000, Loss: 0.01463349349796772\n",
      "Iteration: 6585/10000, Loss: 0.007720737252384424\n",
      "Iteration: 6586/10000, Loss: 0.0099412240087986\n",
      "Iteration: 6587/10000, Loss: 0.014889257028698921\n",
      "Iteration: 6588/10000, Loss: 0.016339462250471115\n",
      "Iteration: 6589/10000, Loss: 0.00751461461186409\n",
      "Iteration: 6590/10000, Loss: 0.00910397432744503\n",
      "Iteration: 6591/10000, Loss: 0.01471521332859993\n",
      "Iteration: 6592/10000, Loss: 0.015247444622218609\n",
      "Iteration: 6593/10000, Loss: 0.00855987798422575\n",
      "Iteration: 6594/10000, Loss: 0.010245904326438904\n",
      "Iteration: 6595/10000, Loss: 0.008257229812443256\n",
      "Iteration: 6596/10000, Loss: 0.009881758131086826\n",
      "Iteration: 6597/10000, Loss: 0.008231522515416145\n",
      "Iteration: 6598/10000, Loss: 0.014656703919172287\n",
      "Iteration: 6599/10000, Loss: 0.007145415060222149\n",
      "Iteration: 6600/10000, Loss: 0.012466330081224442\n",
      "Average test loss:  0.0039\n",
      "Iteration: 6601/10000, Loss: 0.01335984654724598\n",
      "Iteration: 6602/10000, Loss: 0.013404026627540588\n",
      "Iteration: 6603/10000, Loss: 0.007810307200998068\n",
      "Iteration: 6604/10000, Loss: 0.007031208835542202\n",
      "Iteration: 6605/10000, Loss: 0.008027695119380951\n",
      "Iteration: 6606/10000, Loss: 0.015752000734210014\n",
      "Iteration: 6607/10000, Loss: 0.014032633043825626\n",
      "Iteration: 6608/10000, Loss: 0.013395815156400204\n",
      "Iteration: 6609/10000, Loss: 0.008294463157653809\n",
      "Iteration: 6610/10000, Loss: 0.007532644085586071\n",
      "Iteration: 6611/10000, Loss: 0.00680732075124979\n",
      "Iteration: 6612/10000, Loss: 0.019078094512224197\n",
      "Iteration: 6613/10000, Loss: 0.017989400774240494\n",
      "Iteration: 6614/10000, Loss: 0.013096692971885204\n",
      "Iteration: 6615/10000, Loss: 0.01426539197564125\n",
      "Iteration: 6616/10000, Loss: 0.015182103961706161\n",
      "Iteration: 6617/10000, Loss: 0.008343945257365704\n",
      "Iteration: 6618/10000, Loss: 0.014321217313408852\n",
      "Iteration: 6619/10000, Loss: 0.006378773134201765\n",
      "Iteration: 6620/10000, Loss: 0.009709249250590801\n",
      "Iteration: 6621/10000, Loss: 0.011057406663894653\n",
      "Iteration: 6622/10000, Loss: 0.01101657934486866\n",
      "Iteration: 6623/10000, Loss: 0.011408207006752491\n",
      "Iteration: 6624/10000, Loss: 0.007453836966305971\n",
      "Iteration: 6625/10000, Loss: 0.011266824789345264\n",
      "Iteration: 6626/10000, Loss: 0.012402159161865711\n",
      "Iteration: 6627/10000, Loss: 0.011353633366525173\n",
      "Iteration: 6628/10000, Loss: 0.008861551992595196\n",
      "Iteration: 6629/10000, Loss: 0.010612000711262226\n",
      "Iteration: 6630/10000, Loss: 0.016587691381573677\n",
      "Iteration: 6631/10000, Loss: 0.011542891152203083\n",
      "Iteration: 6632/10000, Loss: 0.018080871552228928\n",
      "Iteration: 6633/10000, Loss: 0.01034403033554554\n",
      "Iteration: 6634/10000, Loss: 0.006240614224225283\n",
      "Iteration: 6635/10000, Loss: 0.006163671612739563\n",
      "Iteration: 6636/10000, Loss: 0.009833923541009426\n",
      "Iteration: 6637/10000, Loss: 0.013061261735856533\n",
      "Iteration: 6638/10000, Loss: 0.010321508161723614\n",
      "Iteration: 6639/10000, Loss: 0.008138889446854591\n",
      "Iteration: 6640/10000, Loss: 0.012093997560441494\n",
      "Iteration: 6641/10000, Loss: 0.007033749483525753\n",
      "Iteration: 6642/10000, Loss: 0.014664881862699986\n",
      "Iteration: 6643/10000, Loss: 0.010750915855169296\n",
      "Iteration: 6644/10000, Loss: 0.009799809195101261\n",
      "Iteration: 6645/10000, Loss: 0.012586708180606365\n",
      "Iteration: 6646/10000, Loss: 0.009824168868362904\n",
      "Iteration: 6647/10000, Loss: 0.014889465644955635\n",
      "Iteration: 6648/10000, Loss: 0.013019240461289883\n",
      "Iteration: 6649/10000, Loss: 0.011267623864114285\n",
      "Iteration: 6650/10000, Loss: 0.013873083516955376\n",
      "Iteration: 6651/10000, Loss: 0.0076051256619393826\n",
      "Iteration: 6652/10000, Loss: 0.009688968770205975\n",
      "Iteration: 6653/10000, Loss: 0.012981708161532879\n",
      "Iteration: 6654/10000, Loss: 0.011475755833089352\n",
      "Iteration: 6655/10000, Loss: 0.013387957587838173\n",
      "Iteration: 6656/10000, Loss: 0.013492218218743801\n",
      "Iteration: 6657/10000, Loss: 0.012921024113893509\n",
      "Iteration: 6658/10000, Loss: 0.012558134272694588\n",
      "Iteration: 6659/10000, Loss: 0.012046766467392445\n",
      "Iteration: 6660/10000, Loss: 0.009822809137403965\n",
      "Iteration: 6661/10000, Loss: 0.007856758311390877\n",
      "Iteration: 6662/10000, Loss: 0.011260895058512688\n",
      "Iteration: 6663/10000, Loss: 0.00845901109278202\n",
      "Iteration: 6664/10000, Loss: 0.009441330097615719\n",
      "Iteration: 6665/10000, Loss: 0.0117674320936203\n",
      "Iteration: 6666/10000, Loss: 0.013285797089338303\n",
      "Iteration: 6667/10000, Loss: 0.007686858531087637\n",
      "Iteration: 6668/10000, Loss: 0.0075520919635891914\n",
      "Iteration: 6669/10000, Loss: 0.01610805280506611\n",
      "Iteration: 6670/10000, Loss: 0.009543024934828281\n",
      "Iteration: 6671/10000, Loss: 0.013500562869012356\n",
      "Iteration: 6672/10000, Loss: 0.012971613556146622\n",
      "Iteration: 6673/10000, Loss: 0.013726741075515747\n",
      "Iteration: 6674/10000, Loss: 0.01725955307483673\n",
      "Iteration: 6675/10000, Loss: 0.007718576118350029\n",
      "Iteration: 6676/10000, Loss: 0.012591114267706871\n",
      "Iteration: 6677/10000, Loss: 0.008801424875855446\n",
      "Iteration: 6678/10000, Loss: 0.00976600032299757\n",
      "Iteration: 6679/10000, Loss: 0.009953496977686882\n",
      "Iteration: 6680/10000, Loss: 0.012493469752371311\n",
      "Iteration: 6681/10000, Loss: 0.011100835166871548\n",
      "Iteration: 6682/10000, Loss: 0.014955115504562855\n",
      "Iteration: 6683/10000, Loss: 0.0088392598554492\n",
      "Iteration: 6684/10000, Loss: 0.01278943195939064\n",
      "Iteration: 6685/10000, Loss: 0.006347362417727709\n",
      "Iteration: 6686/10000, Loss: 0.013179842382669449\n",
      "Iteration: 6687/10000, Loss: 0.014467732980847359\n",
      "Iteration: 6688/10000, Loss: 0.0115253496915102\n",
      "Iteration: 6689/10000, Loss: 0.00916384719312191\n",
      "Iteration: 6690/10000, Loss: 0.013388402760028839\n",
      "Iteration: 6691/10000, Loss: 0.015557937324047089\n",
      "Iteration: 6692/10000, Loss: 0.005932834930717945\n",
      "Iteration: 6693/10000, Loss: 0.012056219391524792\n",
      "Iteration: 6694/10000, Loss: 0.011416483670473099\n",
      "Iteration: 6695/10000, Loss: 0.015862414613366127\n",
      "Iteration: 6696/10000, Loss: 0.007238204125314951\n",
      "Iteration: 6697/10000, Loss: 0.013588405214250088\n",
      "Iteration: 6698/10000, Loss: 0.012487557716667652\n",
      "Iteration: 6699/10000, Loss: 0.016208549961447716\n",
      "Iteration: 6700/10000, Loss: 0.007708081975579262\n",
      "Average test loss:  0.0018\n",
      "Iteration: 6701/10000, Loss: 0.010959726758301258\n",
      "Iteration: 6702/10000, Loss: 0.01487932913005352\n",
      "Iteration: 6703/10000, Loss: 0.010966606438159943\n",
      "Iteration: 6704/10000, Loss: 0.01269440446048975\n",
      "Iteration: 6705/10000, Loss: 0.01176927424967289\n",
      "Iteration: 6706/10000, Loss: 0.012125753797590733\n",
      "Iteration: 6707/10000, Loss: 0.010287005454301834\n",
      "Iteration: 6708/10000, Loss: 0.00904154870659113\n",
      "Iteration: 6709/10000, Loss: 0.010277318768203259\n",
      "Iteration: 6710/10000, Loss: 0.01169480662792921\n",
      "Iteration: 6711/10000, Loss: 0.008429416455328465\n",
      "Iteration: 6712/10000, Loss: 0.006766096223145723\n",
      "Iteration: 6713/10000, Loss: 0.011651533655822277\n",
      "Iteration: 6714/10000, Loss: 0.008101329207420349\n",
      "Iteration: 6715/10000, Loss: 0.009056823328137398\n",
      "Iteration: 6716/10000, Loss: 0.009209265001118183\n",
      "Iteration: 6717/10000, Loss: 0.009052095003426075\n",
      "Iteration: 6718/10000, Loss: 0.009768164716660976\n",
      "Iteration: 6719/10000, Loss: 0.014378638938069344\n",
      "Iteration: 6720/10000, Loss: 0.008440348319709301\n",
      "Iteration: 6721/10000, Loss: 0.012487848289310932\n",
      "Iteration: 6722/10000, Loss: 0.009711001999676228\n",
      "Iteration: 6723/10000, Loss: 0.010870294645428658\n",
      "Iteration: 6724/10000, Loss: 0.014114982448518276\n",
      "Iteration: 6725/10000, Loss: 0.01132435817271471\n",
      "Iteration: 6726/10000, Loss: 0.00917180348187685\n",
      "Iteration: 6727/10000, Loss: 0.012174566276371479\n",
      "Iteration: 6728/10000, Loss: 0.007404472213238478\n",
      "Iteration: 6729/10000, Loss: 0.010465227998793125\n",
      "Iteration: 6730/10000, Loss: 0.013630754314363003\n",
      "Iteration: 6731/10000, Loss: 0.010890062898397446\n",
      "Iteration: 6732/10000, Loss: 0.010214642621576786\n",
      "Iteration: 6733/10000, Loss: 0.008883415721356869\n",
      "Iteration: 6734/10000, Loss: 0.010695237666368484\n",
      "Iteration: 6735/10000, Loss: 0.009697211906313896\n",
      "Iteration: 6736/10000, Loss: 0.010752782225608826\n",
      "Iteration: 6737/10000, Loss: 0.014119960367679596\n",
      "Iteration: 6738/10000, Loss: 0.008402693085372448\n",
      "Iteration: 6739/10000, Loss: 0.010486834682524204\n",
      "Iteration: 6740/10000, Loss: 0.012364433147013187\n",
      "Iteration: 6741/10000, Loss: 0.01053776778280735\n",
      "Iteration: 6742/10000, Loss: 0.01074672769755125\n",
      "Iteration: 6743/10000, Loss: 0.007832434959709644\n",
      "Iteration: 6744/10000, Loss: 0.01579020544886589\n",
      "Iteration: 6745/10000, Loss: 0.010839125141501427\n",
      "Iteration: 6746/10000, Loss: 0.011751154437661171\n",
      "Iteration: 6747/10000, Loss: 0.008840811438858509\n",
      "Iteration: 6748/10000, Loss: 0.010618837550282478\n",
      "Iteration: 6749/10000, Loss: 0.009653562679886818\n",
      "Iteration: 6750/10000, Loss: 0.013978484086692333\n",
      "Iteration: 6751/10000, Loss: 0.016763530671596527\n",
      "Iteration: 6752/10000, Loss: 0.01211981475353241\n",
      "Iteration: 6753/10000, Loss: 0.010212852619588375\n",
      "Iteration: 6754/10000, Loss: 0.015583841130137444\n",
      "Iteration: 6755/10000, Loss: 0.010833143256604671\n",
      "Iteration: 6756/10000, Loss: 0.006066245026886463\n",
      "Iteration: 6757/10000, Loss: 0.009943644516170025\n",
      "Iteration: 6758/10000, Loss: 0.012833189219236374\n",
      "Iteration: 6759/10000, Loss: 0.011579330079257488\n",
      "Iteration: 6760/10000, Loss: 0.0130676981061697\n",
      "Iteration: 6761/10000, Loss: 0.01184706762433052\n",
      "Iteration: 6762/10000, Loss: 0.007323072757571936\n",
      "Iteration: 6763/10000, Loss: 0.014534151181578636\n",
      "Iteration: 6764/10000, Loss: 0.010176584124565125\n",
      "Iteration: 6765/10000, Loss: 0.01193490345031023\n",
      "Iteration: 6766/10000, Loss: 0.008560790680348873\n",
      "Iteration: 6767/10000, Loss: 0.009906202554702759\n",
      "Iteration: 6768/10000, Loss: 0.011924444697797298\n",
      "Iteration: 6769/10000, Loss: 0.011271752417087555\n",
      "Iteration: 6770/10000, Loss: 0.00511964363977313\n",
      "Iteration: 6771/10000, Loss: 0.012320363894104958\n",
      "Iteration: 6772/10000, Loss: 0.01394455786794424\n",
      "Iteration: 6773/10000, Loss: 0.006069711409509182\n",
      "Iteration: 6774/10000, Loss: 0.011111898347735405\n",
      "Iteration: 6775/10000, Loss: 0.014289295300841331\n",
      "Iteration: 6776/10000, Loss: 0.012213529087603092\n",
      "Iteration: 6777/10000, Loss: 0.017039630562067032\n",
      "Iteration: 6778/10000, Loss: 0.015491269528865814\n",
      "Iteration: 6779/10000, Loss: 0.008648182265460491\n",
      "Iteration: 6780/10000, Loss: 0.009986829943954945\n",
      "Iteration: 6781/10000, Loss: 0.0081402026116848\n",
      "Iteration: 6782/10000, Loss: 0.013376138173043728\n",
      "Iteration: 6783/10000, Loss: 0.01604371704161167\n",
      "Iteration: 6784/10000, Loss: 0.009857715107500553\n",
      "Iteration: 6785/10000, Loss: 0.013188603334128857\n",
      "Iteration: 6786/10000, Loss: 0.011690660379827023\n",
      "Iteration: 6787/10000, Loss: 0.012446455657482147\n",
      "Iteration: 6788/10000, Loss: 0.008925765752792358\n",
      "Iteration: 6789/10000, Loss: 0.005712731275707483\n",
      "Iteration: 6790/10000, Loss: 0.015508132055401802\n",
      "Iteration: 6791/10000, Loss: 0.01378177385777235\n",
      "Iteration: 6792/10000, Loss: 0.01222812570631504\n",
      "Iteration: 6793/10000, Loss: 0.01249336451292038\n",
      "Iteration: 6794/10000, Loss: 0.015192108228802681\n",
      "Iteration: 6795/10000, Loss: 0.007941787131130695\n",
      "Iteration: 6796/10000, Loss: 0.010268736630678177\n",
      "Iteration: 6797/10000, Loss: 0.006225156597793102\n",
      "Iteration: 6798/10000, Loss: 0.007116698194295168\n",
      "Iteration: 6799/10000, Loss: 0.012641692534089088\n",
      "Iteration: 6800/10000, Loss: 0.01014086976647377\n",
      "Average test loss:  0.0033\n",
      "Iteration: 6801/10000, Loss: 0.00886349193751812\n",
      "Iteration: 6802/10000, Loss: 0.007651208899915218\n",
      "Iteration: 6803/10000, Loss: 0.005898021161556244\n",
      "Iteration: 6804/10000, Loss: 0.01170092448592186\n",
      "Iteration: 6805/10000, Loss: 0.011538058519363403\n",
      "Iteration: 6806/10000, Loss: 0.005837840493768454\n",
      "Iteration: 6807/10000, Loss: 0.009386839345097542\n",
      "Iteration: 6808/10000, Loss: 0.008386283181607723\n",
      "Iteration: 6809/10000, Loss: 0.007826226763427258\n",
      "Iteration: 6810/10000, Loss: 0.01922515034675598\n",
      "Iteration: 6811/10000, Loss: 0.013015654869377613\n",
      "Iteration: 6812/10000, Loss: 0.006274764891713858\n",
      "Iteration: 6813/10000, Loss: 0.014059741981327534\n",
      "Iteration: 6814/10000, Loss: 0.01329906564205885\n",
      "Iteration: 6815/10000, Loss: 0.011980051174759865\n",
      "Iteration: 6816/10000, Loss: 0.00578152434900403\n",
      "Iteration: 6817/10000, Loss: 0.00817591417580843\n",
      "Iteration: 6818/10000, Loss: 0.00930006429553032\n",
      "Iteration: 6819/10000, Loss: 0.010789543390274048\n",
      "Iteration: 6820/10000, Loss: 0.012199314311146736\n",
      "Iteration: 6821/10000, Loss: 0.016682177782058716\n",
      "Iteration: 6822/10000, Loss: 0.0217009074985981\n",
      "Iteration: 6823/10000, Loss: 0.007815059274435043\n",
      "Iteration: 6824/10000, Loss: 0.009709775447845459\n",
      "Iteration: 6825/10000, Loss: 0.010716037824749947\n",
      "Iteration: 6826/10000, Loss: 0.017192741855978966\n",
      "Iteration: 6827/10000, Loss: 0.013461382128298283\n",
      "Iteration: 6828/10000, Loss: 0.013074098154902458\n",
      "Iteration: 6829/10000, Loss: 0.013172819279134274\n",
      "Iteration: 6830/10000, Loss: 0.009565887041389942\n",
      "Iteration: 6831/10000, Loss: 0.011190732009708881\n",
      "Iteration: 6832/10000, Loss: 0.015721937641501427\n",
      "Iteration: 6833/10000, Loss: 0.005973595194518566\n",
      "Iteration: 6834/10000, Loss: 0.017619896680116653\n",
      "Iteration: 6835/10000, Loss: 0.007399966474622488\n",
      "Iteration: 6836/10000, Loss: 0.012599761597812176\n",
      "Iteration: 6837/10000, Loss: 0.009462928399443626\n",
      "Iteration: 6838/10000, Loss: 0.011018922552466393\n",
      "Iteration: 6839/10000, Loss: 0.007464696653187275\n",
      "Iteration: 6840/10000, Loss: 0.013394481502473354\n",
      "Iteration: 6841/10000, Loss: 0.007606078404933214\n",
      "Iteration: 6842/10000, Loss: 0.013654578477144241\n",
      "Iteration: 6843/10000, Loss: 0.01540439110249281\n",
      "Iteration: 6844/10000, Loss: 0.008999079465866089\n",
      "Iteration: 6845/10000, Loss: 0.014891093596816063\n",
      "Iteration: 6846/10000, Loss: 0.009597406722605228\n",
      "Iteration: 6847/10000, Loss: 0.013394530862569809\n",
      "Iteration: 6848/10000, Loss: 0.012959555722773075\n",
      "Iteration: 6849/10000, Loss: 0.008870670571923256\n",
      "Iteration: 6850/10000, Loss: 0.01058829203248024\n",
      "Iteration: 6851/10000, Loss: 0.010316086001694202\n",
      "Iteration: 6852/10000, Loss: 0.013825397938489914\n",
      "Iteration: 6853/10000, Loss: 0.012082652188837528\n",
      "Iteration: 6854/10000, Loss: 0.013037100434303284\n",
      "Iteration: 6855/10000, Loss: 0.009011059999465942\n",
      "Iteration: 6856/10000, Loss: 0.01028907485306263\n",
      "Iteration: 6857/10000, Loss: 0.007937261834740639\n",
      "Iteration: 6858/10000, Loss: 0.01127463486045599\n",
      "Iteration: 6859/10000, Loss: 0.010688869282603264\n",
      "Iteration: 6860/10000, Loss: 0.010917180217802525\n",
      "Iteration: 6861/10000, Loss: 0.009270947426557541\n",
      "Iteration: 6862/10000, Loss: 0.00976717658340931\n",
      "Iteration: 6863/10000, Loss: 0.010046866722404957\n",
      "Iteration: 6864/10000, Loss: 0.012552429921925068\n",
      "Iteration: 6865/10000, Loss: 0.017159219831228256\n",
      "Iteration: 6866/10000, Loss: 0.010678100399672985\n",
      "Iteration: 6867/10000, Loss: 0.008021311834454536\n",
      "Iteration: 6868/10000, Loss: 0.009630081243813038\n",
      "Iteration: 6869/10000, Loss: 0.01405923068523407\n",
      "Iteration: 6870/10000, Loss: 0.01158633828163147\n",
      "Iteration: 6871/10000, Loss: 0.011100223287940025\n",
      "Iteration: 6872/10000, Loss: 0.00935291312634945\n",
      "Iteration: 6873/10000, Loss: 0.00915427878499031\n",
      "Iteration: 6874/10000, Loss: 0.00794875156134367\n",
      "Iteration: 6875/10000, Loss: 0.013681616634130478\n",
      "Iteration: 6876/10000, Loss: 0.010944249108433723\n",
      "Iteration: 6877/10000, Loss: 0.015580089762806892\n",
      "Iteration: 6878/10000, Loss: 0.011930354870855808\n",
      "Iteration: 6879/10000, Loss: 0.0081919115036726\n",
      "Iteration: 6880/10000, Loss: 0.01590959168970585\n",
      "Iteration: 6881/10000, Loss: 0.011888181790709496\n",
      "Iteration: 6882/10000, Loss: 0.007640562020242214\n",
      "Iteration: 6883/10000, Loss: 0.009332825429737568\n",
      "Iteration: 6884/10000, Loss: 0.012600782327353954\n",
      "Iteration: 6885/10000, Loss: 0.008473852649331093\n",
      "Iteration: 6886/10000, Loss: 0.014615993946790695\n",
      "Iteration: 6887/10000, Loss: 0.009451533667743206\n",
      "Iteration: 6888/10000, Loss: 0.010067569091916084\n",
      "Iteration: 6889/10000, Loss: 0.010448629967868328\n",
      "Iteration: 6890/10000, Loss: 0.011035389266908169\n",
      "Iteration: 6891/10000, Loss: 0.01194668561220169\n",
      "Iteration: 6892/10000, Loss: 0.010160708799958229\n",
      "Iteration: 6893/10000, Loss: 0.013490138575434685\n",
      "Iteration: 6894/10000, Loss: 0.0074751791544258595\n",
      "Iteration: 6895/10000, Loss: 0.011904426850378513\n",
      "Iteration: 6896/10000, Loss: 0.007921526208519936\n",
      "Iteration: 6897/10000, Loss: 0.015296200290322304\n",
      "Iteration: 6898/10000, Loss: 0.01009348127990961\n",
      "Iteration: 6899/10000, Loss: 0.011341364122927189\n",
      "Iteration: 6900/10000, Loss: 0.010705024935305119\n",
      "Average test loss:  0.0029\n",
      "Iteration: 6901/10000, Loss: 0.007033866364508867\n",
      "Iteration: 6902/10000, Loss: 0.012903569266200066\n",
      "Iteration: 6903/10000, Loss: 0.01620062068104744\n",
      "Iteration: 6904/10000, Loss: 0.007728281430900097\n",
      "Iteration: 6905/10000, Loss: 0.00966858584433794\n",
      "Iteration: 6906/10000, Loss: 0.010355249978601933\n",
      "Iteration: 6907/10000, Loss: 0.010758851654827595\n",
      "Iteration: 6908/10000, Loss: 0.010956572368741035\n",
      "Iteration: 6909/10000, Loss: 0.007335207425057888\n",
      "Iteration: 6910/10000, Loss: 0.015040391124784946\n",
      "Iteration: 6911/10000, Loss: 0.010093271732330322\n",
      "Iteration: 6912/10000, Loss: 0.006842100992798805\n",
      "Iteration: 6913/10000, Loss: 0.005556568503379822\n",
      "Iteration: 6914/10000, Loss: 0.007597372401505709\n",
      "Iteration: 6915/10000, Loss: 0.011538025923073292\n",
      "Iteration: 6916/10000, Loss: 0.009994740597903728\n",
      "Iteration: 6917/10000, Loss: 0.008761241100728512\n",
      "Iteration: 6918/10000, Loss: 0.0064657400362193584\n",
      "Iteration: 6919/10000, Loss: 0.01280790101736784\n",
      "Iteration: 6920/10000, Loss: 0.013285091146826744\n",
      "Iteration: 6921/10000, Loss: 0.008599568158388138\n",
      "Iteration: 6922/10000, Loss: 0.016283279284834862\n",
      "Iteration: 6923/10000, Loss: 0.013597297482192516\n",
      "Iteration: 6924/10000, Loss: 0.017265189439058304\n",
      "Iteration: 6925/10000, Loss: 0.011407041922211647\n",
      "Iteration: 6926/10000, Loss: 0.011580460704863071\n",
      "Iteration: 6927/10000, Loss: 0.013167982921004295\n",
      "Iteration: 6928/10000, Loss: 0.007510533556342125\n",
      "Iteration: 6929/10000, Loss: 0.011374182067811489\n",
      "Iteration: 6930/10000, Loss: 0.010101959109306335\n",
      "Iteration: 6931/10000, Loss: 0.016559556126594543\n",
      "Iteration: 6932/10000, Loss: 0.00856739841401577\n",
      "Iteration: 6933/10000, Loss: 0.007800378371030092\n",
      "Iteration: 6934/10000, Loss: 0.009295380674302578\n",
      "Iteration: 6935/10000, Loss: 0.009122958406805992\n",
      "Iteration: 6936/10000, Loss: 0.010417005978524685\n",
      "Iteration: 6937/10000, Loss: 0.012391953729093075\n",
      "Iteration: 6938/10000, Loss: 0.013046136125922203\n",
      "Iteration: 6939/10000, Loss: 0.01157165877521038\n",
      "Iteration: 6940/10000, Loss: 0.016089677810668945\n",
      "Iteration: 6941/10000, Loss: 0.008577902801334858\n",
      "Iteration: 6942/10000, Loss: 0.01207707915455103\n",
      "Iteration: 6943/10000, Loss: 0.01114326249808073\n",
      "Iteration: 6944/10000, Loss: 0.011786759831011295\n",
      "Iteration: 6945/10000, Loss: 0.009041430428624153\n",
      "Iteration: 6946/10000, Loss: 0.010861379094421864\n",
      "Iteration: 6947/10000, Loss: 0.011712703853845596\n",
      "Iteration: 6948/10000, Loss: 0.012148348614573479\n",
      "Iteration: 6949/10000, Loss: 0.010274370200932026\n",
      "Iteration: 6950/10000, Loss: 0.013578448444604874\n",
      "Iteration: 6951/10000, Loss: 0.008394247852265835\n",
      "Iteration: 6952/10000, Loss: 0.007895172573626041\n",
      "Iteration: 6953/10000, Loss: 0.0072181494906544685\n",
      "Iteration: 6954/10000, Loss: 0.008185869082808495\n",
      "Iteration: 6955/10000, Loss: 0.005070967599749565\n",
      "Iteration: 6956/10000, Loss: 0.010556628927588463\n",
      "Iteration: 6957/10000, Loss: 0.008046896196901798\n",
      "Iteration: 6958/10000, Loss: 0.006774818990379572\n",
      "Iteration: 6959/10000, Loss: 0.00849838089197874\n",
      "Iteration: 6960/10000, Loss: 0.012323499657213688\n",
      "Iteration: 6961/10000, Loss: 0.008732975460588932\n",
      "Iteration: 6962/10000, Loss: 0.00913940742611885\n",
      "Iteration: 6963/10000, Loss: 0.0070983003824949265\n",
      "Iteration: 6964/10000, Loss: 0.016254523769021034\n",
      "Iteration: 6965/10000, Loss: 0.00762925622984767\n",
      "Iteration: 6966/10000, Loss: 0.010421836748719215\n",
      "Iteration: 6967/10000, Loss: 0.015687337145209312\n",
      "Iteration: 6968/10000, Loss: 0.011277192272245884\n",
      "Iteration: 6969/10000, Loss: 0.015182889997959137\n",
      "Iteration: 6970/10000, Loss: 0.008502449840307236\n",
      "Iteration: 6971/10000, Loss: 0.012270655483007431\n",
      "Iteration: 6972/10000, Loss: 0.012809199281036854\n",
      "Iteration: 6973/10000, Loss: 0.011854362674057484\n",
      "Iteration: 6974/10000, Loss: 0.012298939749598503\n",
      "Iteration: 6975/10000, Loss: 0.013550599105656147\n",
      "Iteration: 6976/10000, Loss: 0.008257217705249786\n",
      "Iteration: 6977/10000, Loss: 0.011182093992829323\n",
      "Iteration: 6978/10000, Loss: 0.012824204750359058\n",
      "Iteration: 6979/10000, Loss: 0.012907737866044044\n",
      "Iteration: 6980/10000, Loss: 0.011136547662317753\n",
      "Iteration: 6981/10000, Loss: 0.011664722114801407\n",
      "Iteration: 6982/10000, Loss: 0.008026140742003918\n",
      "Iteration: 6983/10000, Loss: 0.012147004716098309\n",
      "Iteration: 6984/10000, Loss: 0.01682909205555916\n",
      "Iteration: 6985/10000, Loss: 0.014196110889315605\n",
      "Iteration: 6986/10000, Loss: 0.014062674716114998\n",
      "Iteration: 6987/10000, Loss: 0.012466786429286003\n",
      "Iteration: 6988/10000, Loss: 0.014052153564989567\n",
      "Iteration: 6989/10000, Loss: 0.011720270849764347\n",
      "Iteration: 6990/10000, Loss: 0.013367613777518272\n",
      "Iteration: 6991/10000, Loss: 0.012448004446923733\n",
      "Iteration: 6992/10000, Loss: 0.011126670055091381\n",
      "Iteration: 6993/10000, Loss: 0.007431556936353445\n",
      "Iteration: 6994/10000, Loss: 0.009079904295504093\n",
      "Iteration: 6995/10000, Loss: 0.011558911763131618\n",
      "Iteration: 6996/10000, Loss: 0.01241289358586073\n",
      "Iteration: 6997/10000, Loss: 0.006891489028930664\n",
      "Iteration: 6998/10000, Loss: 0.008730839006602764\n",
      "Iteration: 6999/10000, Loss: 0.009508302435278893\n",
      "Iteration: 7000/10000, Loss: 0.01688777469098568\n",
      "Average test loss:  0.0028\n",
      "Iteration: 7001/10000, Loss: 0.010833978652954102\n",
      "Iteration: 7002/10000, Loss: 0.014153175055980682\n",
      "Iteration: 7003/10000, Loss: 0.008794663473963737\n",
      "Iteration: 7004/10000, Loss: 0.009041135199368\n",
      "Iteration: 7005/10000, Loss: 0.00859309546649456\n",
      "Iteration: 7006/10000, Loss: 0.008490826934576035\n",
      "Iteration: 7007/10000, Loss: 0.011090847663581371\n",
      "Iteration: 7008/10000, Loss: 0.00835674349218607\n",
      "Iteration: 7009/10000, Loss: 0.011003863997757435\n",
      "Iteration: 7010/10000, Loss: 0.014008870348334312\n",
      "Iteration: 7011/10000, Loss: 0.009109018370509148\n",
      "Iteration: 7012/10000, Loss: 0.009639634750783443\n",
      "Iteration: 7013/10000, Loss: 0.01161016896367073\n",
      "Iteration: 7014/10000, Loss: 0.0075048161670565605\n",
      "Iteration: 7015/10000, Loss: 0.009036332368850708\n",
      "Iteration: 7016/10000, Loss: 0.011060298420488834\n",
      "Iteration: 7017/10000, Loss: 0.009723173454403877\n",
      "Iteration: 7018/10000, Loss: 0.0065477630123496056\n",
      "Iteration: 7019/10000, Loss: 0.012806291691958904\n",
      "Iteration: 7020/10000, Loss: 0.00794397946447134\n",
      "Iteration: 7021/10000, Loss: 0.01591276377439499\n",
      "Iteration: 7022/10000, Loss: 0.007362760603427887\n",
      "Iteration: 7023/10000, Loss: 0.010069076903164387\n",
      "Iteration: 7024/10000, Loss: 0.007326425984501839\n",
      "Iteration: 7025/10000, Loss: 0.0120684914290905\n",
      "Iteration: 7026/10000, Loss: 0.011227905750274658\n",
      "Iteration: 7027/10000, Loss: 0.013836107216775417\n",
      "Iteration: 7028/10000, Loss: 0.01087169162929058\n",
      "Iteration: 7029/10000, Loss: 0.016428805887699127\n",
      "Iteration: 7030/10000, Loss: 0.01205302495509386\n",
      "Iteration: 7031/10000, Loss: 0.012746434658765793\n",
      "Iteration: 7032/10000, Loss: 0.011508596129715443\n",
      "Iteration: 7033/10000, Loss: 0.009629834443330765\n",
      "Iteration: 7034/10000, Loss: 0.020969485864043236\n",
      "Iteration: 7035/10000, Loss: 0.008398493751883507\n",
      "Iteration: 7036/10000, Loss: 0.008712267503142357\n",
      "Iteration: 7037/10000, Loss: 0.005720460321754217\n",
      "Iteration: 7038/10000, Loss: 0.012588085606694221\n",
      "Iteration: 7039/10000, Loss: 0.013232245109975338\n",
      "Iteration: 7040/10000, Loss: 0.010580701753497124\n",
      "Iteration: 7041/10000, Loss: 0.007515515200793743\n",
      "Iteration: 7042/10000, Loss: 0.009247440844774246\n",
      "Iteration: 7043/10000, Loss: 0.009565101005136967\n",
      "Iteration: 7044/10000, Loss: 0.016703933477401733\n",
      "Iteration: 7045/10000, Loss: 0.011100118048489094\n",
      "Iteration: 7046/10000, Loss: 0.008769822306931019\n",
      "Iteration: 7047/10000, Loss: 0.01477613765746355\n",
      "Iteration: 7048/10000, Loss: 0.01172692608088255\n",
      "Iteration: 7049/10000, Loss: 0.013211950659751892\n",
      "Iteration: 7050/10000, Loss: 0.00970647856593132\n",
      "Iteration: 7051/10000, Loss: 0.006862623617053032\n",
      "Iteration: 7052/10000, Loss: 0.013875486329197884\n",
      "Iteration: 7053/10000, Loss: 0.010060979053378105\n",
      "Iteration: 7054/10000, Loss: 0.004646431189030409\n",
      "Iteration: 7055/10000, Loss: 0.010509807616472244\n",
      "Iteration: 7056/10000, Loss: 0.015313354320824146\n",
      "Iteration: 7057/10000, Loss: 0.009987376630306244\n",
      "Iteration: 7058/10000, Loss: 0.010439996607601643\n",
      "Iteration: 7059/10000, Loss: 0.010295930318534374\n",
      "Iteration: 7060/10000, Loss: 0.013438929803669453\n",
      "Iteration: 7061/10000, Loss: 0.009782264940440655\n",
      "Iteration: 7062/10000, Loss: 0.013349445536732674\n",
      "Iteration: 7063/10000, Loss: 0.011048469692468643\n",
      "Iteration: 7064/10000, Loss: 0.012609928846359253\n",
      "Iteration: 7065/10000, Loss: 0.009846220724284649\n",
      "Iteration: 7066/10000, Loss: 0.014099495485424995\n",
      "Iteration: 7067/10000, Loss: 0.011781479232013226\n",
      "Iteration: 7068/10000, Loss: 0.015909811481833458\n",
      "Iteration: 7069/10000, Loss: 0.009227357804775238\n",
      "Iteration: 7070/10000, Loss: 0.009100654162466526\n",
      "Iteration: 7071/10000, Loss: 0.011514623649418354\n",
      "Iteration: 7072/10000, Loss: 0.012645984999835491\n",
      "Iteration: 7073/10000, Loss: 0.0139344846829772\n",
      "Iteration: 7074/10000, Loss: 0.016915244981646538\n",
      "Iteration: 7075/10000, Loss: 0.01167343184351921\n",
      "Iteration: 7076/10000, Loss: 0.010271620936691761\n",
      "Iteration: 7077/10000, Loss: 0.012764425948262215\n",
      "Iteration: 7078/10000, Loss: 0.009493902325630188\n",
      "Iteration: 7079/10000, Loss: 0.011235532350838184\n",
      "Iteration: 7080/10000, Loss: 0.008726120926439762\n",
      "Iteration: 7081/10000, Loss: 0.013310976326465607\n",
      "Iteration: 7082/10000, Loss: 0.01605989970266819\n",
      "Iteration: 7083/10000, Loss: 0.007360450923442841\n",
      "Iteration: 7084/10000, Loss: 0.013183074072003365\n",
      "Iteration: 7085/10000, Loss: 0.010483723133802414\n",
      "Iteration: 7086/10000, Loss: 0.013107484206557274\n",
      "Iteration: 7087/10000, Loss: 0.007855793461203575\n",
      "Iteration: 7088/10000, Loss: 0.011228094808757305\n",
      "Iteration: 7089/10000, Loss: 0.014939581975340843\n",
      "Iteration: 7090/10000, Loss: 0.007957668974995613\n",
      "Iteration: 7091/10000, Loss: 0.010983307845890522\n",
      "Iteration: 7092/10000, Loss: 0.012490418739616871\n",
      "Iteration: 7093/10000, Loss: 0.007762478664517403\n",
      "Iteration: 7094/10000, Loss: 0.007233805023133755\n",
      "Iteration: 7095/10000, Loss: 0.01568516157567501\n",
      "Iteration: 7096/10000, Loss: 0.011819940060377121\n",
      "Iteration: 7097/10000, Loss: 0.010521819815039635\n",
      "Iteration: 7098/10000, Loss: 0.012848670594394207\n",
      "Iteration: 7099/10000, Loss: 0.0065137711353600025\n",
      "Iteration: 7100/10000, Loss: 0.009594996459782124\n",
      "Average test loss:  0.0016\n",
      "Iteration: 7101/10000, Loss: 0.014066711999475956\n",
      "Iteration: 7102/10000, Loss: 0.00791967287659645\n",
      "Iteration: 7103/10000, Loss: 0.00842407625168562\n",
      "Iteration: 7104/10000, Loss: 0.015110370703041553\n",
      "Iteration: 7105/10000, Loss: 0.01151459664106369\n",
      "Iteration: 7106/10000, Loss: 0.013053088448941708\n",
      "Iteration: 7107/10000, Loss: 0.008651403710246086\n",
      "Iteration: 7108/10000, Loss: 0.0080613624304533\n",
      "Iteration: 7109/10000, Loss: 0.01054276991635561\n",
      "Iteration: 7110/10000, Loss: 0.011239536106586456\n",
      "Iteration: 7111/10000, Loss: 0.008844546973705292\n",
      "Iteration: 7112/10000, Loss: 0.012925050221383572\n",
      "Iteration: 7113/10000, Loss: 0.010533425956964493\n",
      "Iteration: 7114/10000, Loss: 0.013682673685252666\n",
      "Iteration: 7115/10000, Loss: 0.01018521748483181\n",
      "Iteration: 7116/10000, Loss: 0.011710619553923607\n",
      "Iteration: 7117/10000, Loss: 0.010129249654710293\n",
      "Iteration: 7118/10000, Loss: 0.010147578082978725\n",
      "Iteration: 7119/10000, Loss: 0.015757586807012558\n",
      "Iteration: 7120/10000, Loss: 0.01008669100701809\n",
      "Iteration: 7121/10000, Loss: 0.009645449928939342\n",
      "Iteration: 7122/10000, Loss: 0.009354432113468647\n",
      "Iteration: 7123/10000, Loss: 0.012614510022103786\n",
      "Iteration: 7124/10000, Loss: 0.013666654005646706\n",
      "Iteration: 7125/10000, Loss: 0.010599710047245026\n",
      "Iteration: 7126/10000, Loss: 0.005721214227378368\n",
      "Iteration: 7127/10000, Loss: 0.0062734163366258144\n",
      "Iteration: 7128/10000, Loss: 0.014126554131507874\n",
      "Iteration: 7129/10000, Loss: 0.013414542190730572\n",
      "Iteration: 7130/10000, Loss: 0.006740647833794355\n",
      "Iteration: 7131/10000, Loss: 0.009932490065693855\n",
      "Iteration: 7132/10000, Loss: 0.008745449595153332\n",
      "Iteration: 7133/10000, Loss: 0.009336050599813461\n",
      "Iteration: 7134/10000, Loss: 0.013262131251394749\n",
      "Iteration: 7135/10000, Loss: 0.00971192866563797\n",
      "Iteration: 7136/10000, Loss: 0.005734447855502367\n",
      "Iteration: 7137/10000, Loss: 0.008974995464086533\n",
      "Iteration: 7138/10000, Loss: 0.01068994402885437\n",
      "Iteration: 7139/10000, Loss: 0.008054832927882671\n",
      "Iteration: 7140/10000, Loss: 0.014911815524101257\n",
      "Iteration: 7141/10000, Loss: 0.007814615033566952\n",
      "Iteration: 7142/10000, Loss: 0.0075321439653635025\n",
      "Iteration: 7143/10000, Loss: 0.010104616172611713\n",
      "Iteration: 7144/10000, Loss: 0.008790409192442894\n",
      "Iteration: 7145/10000, Loss: 0.009997421875596046\n",
      "Iteration: 7146/10000, Loss: 0.013454729691147804\n",
      "Iteration: 7147/10000, Loss: 0.011578920297324657\n",
      "Iteration: 7148/10000, Loss: 0.011034591123461723\n",
      "Iteration: 7149/10000, Loss: 0.011515019461512566\n",
      "Iteration: 7150/10000, Loss: 0.011713902465999126\n",
      "Iteration: 7151/10000, Loss: 0.010664477944374084\n",
      "Iteration: 7152/10000, Loss: 0.01254994422197342\n",
      "Iteration: 7153/10000, Loss: 0.012614487670361996\n",
      "Iteration: 7154/10000, Loss: 0.015558861196041107\n",
      "Iteration: 7155/10000, Loss: 0.009315427392721176\n",
      "Iteration: 7156/10000, Loss: 0.010960180312395096\n",
      "Iteration: 7157/10000, Loss: 0.009239721111953259\n",
      "Iteration: 7158/10000, Loss: 0.01596403494477272\n",
      "Iteration: 7159/10000, Loss: 0.008720687590539455\n",
      "Iteration: 7160/10000, Loss: 0.017100268974900246\n",
      "Iteration: 7161/10000, Loss: 0.01185939833521843\n",
      "Iteration: 7162/10000, Loss: 0.010654771700501442\n",
      "Iteration: 7163/10000, Loss: 0.011080821044743061\n",
      "Iteration: 7164/10000, Loss: 0.015371812507510185\n",
      "Iteration: 7165/10000, Loss: 0.009964695200324059\n",
      "Iteration: 7166/10000, Loss: 0.009446791373193264\n",
      "Iteration: 7167/10000, Loss: 0.008400926366448402\n",
      "Iteration: 7168/10000, Loss: 0.0050552464090287685\n",
      "Iteration: 7169/10000, Loss: 0.007096677552908659\n",
      "Iteration: 7170/10000, Loss: 0.009697015397250652\n",
      "Iteration: 7171/10000, Loss: 0.009416011162102222\n",
      "Iteration: 7172/10000, Loss: 0.0060050212778151035\n",
      "Iteration: 7173/10000, Loss: 0.009862871840596199\n",
      "Iteration: 7174/10000, Loss: 0.011361603625118732\n",
      "Iteration: 7175/10000, Loss: 0.007162400986999273\n",
      "Iteration: 7176/10000, Loss: 0.013252236880362034\n",
      "Iteration: 7177/10000, Loss: 0.008547188714146614\n",
      "Iteration: 7178/10000, Loss: 0.013936951756477356\n",
      "Iteration: 7179/10000, Loss: 0.010474403388798237\n",
      "Iteration: 7180/10000, Loss: 0.006268208846449852\n",
      "Iteration: 7181/10000, Loss: 0.013046513311564922\n",
      "Iteration: 7182/10000, Loss: 0.008136114105582237\n",
      "Iteration: 7183/10000, Loss: 0.007512588519603014\n",
      "Iteration: 7184/10000, Loss: 0.014194757677614689\n",
      "Iteration: 7185/10000, Loss: 0.008106155321002007\n",
      "Iteration: 7186/10000, Loss: 0.011891048401594162\n",
      "Iteration: 7187/10000, Loss: 0.01219967845827341\n",
      "Iteration: 7188/10000, Loss: 0.008102268911898136\n",
      "Iteration: 7189/10000, Loss: 0.010231737978756428\n",
      "Iteration: 7190/10000, Loss: 0.01090514287352562\n",
      "Iteration: 7191/10000, Loss: 0.014103374443948269\n",
      "Iteration: 7192/10000, Loss: 0.015180562622845173\n",
      "Iteration: 7193/10000, Loss: 0.008744381368160248\n",
      "Iteration: 7194/10000, Loss: 0.008172045461833477\n",
      "Iteration: 7195/10000, Loss: 0.015468809753656387\n",
      "Iteration: 7196/10000, Loss: 0.011083672754466534\n",
      "Iteration: 7197/10000, Loss: 0.010796086862683296\n",
      "Iteration: 7198/10000, Loss: 0.0109004657715559\n",
      "Iteration: 7199/10000, Loss: 0.013188041746616364\n",
      "Iteration: 7200/10000, Loss: 0.015504566952586174\n",
      "Average test loss:  0.0030\n",
      "Iteration: 7201/10000, Loss: 0.011904663406312466\n",
      "Iteration: 7202/10000, Loss: 0.006583858747035265\n",
      "Iteration: 7203/10000, Loss: 0.012987486086785793\n",
      "Iteration: 7204/10000, Loss: 0.010629505850374699\n",
      "Iteration: 7205/10000, Loss: 0.0107374656945467\n",
      "Iteration: 7206/10000, Loss: 0.01403058972209692\n",
      "Iteration: 7207/10000, Loss: 0.009702896699309349\n",
      "Iteration: 7208/10000, Loss: 0.01202121376991272\n",
      "Iteration: 7209/10000, Loss: 0.00953766517341137\n",
      "Iteration: 7210/10000, Loss: 0.009690561331808567\n",
      "Iteration: 7211/10000, Loss: 0.008155398070812225\n",
      "Iteration: 7212/10000, Loss: 0.015963509678840637\n",
      "Iteration: 7213/10000, Loss: 0.00824224017560482\n",
      "Iteration: 7214/10000, Loss: 0.007600025273859501\n",
      "Iteration: 7215/10000, Loss: 0.010563690215349197\n",
      "Iteration: 7216/10000, Loss: 0.008880882523953915\n",
      "Iteration: 7217/10000, Loss: 0.015797702595591545\n",
      "Iteration: 7218/10000, Loss: 0.004201318137347698\n",
      "Iteration: 7219/10000, Loss: 0.012268919497728348\n",
      "Iteration: 7220/10000, Loss: 0.01416337676346302\n",
      "Iteration: 7221/10000, Loss: 0.008748441934585571\n",
      "Iteration: 7222/10000, Loss: 0.009592656046152115\n",
      "Iteration: 7223/10000, Loss: 0.013985192403197289\n",
      "Iteration: 7224/10000, Loss: 0.011556820943951607\n",
      "Iteration: 7225/10000, Loss: 0.009683577343821526\n",
      "Iteration: 7226/10000, Loss: 0.00937692727893591\n",
      "Iteration: 7227/10000, Loss: 0.007805394008755684\n",
      "Iteration: 7228/10000, Loss: 0.00671741645783186\n",
      "Iteration: 7229/10000, Loss: 0.009872488677501678\n",
      "Iteration: 7230/10000, Loss: 0.010363169945776463\n",
      "Iteration: 7231/10000, Loss: 0.003840523073449731\n",
      "Iteration: 7232/10000, Loss: 0.006641513668000698\n",
      "Iteration: 7233/10000, Loss: 0.007563588675111532\n",
      "Iteration: 7234/10000, Loss: 0.013240751810371876\n",
      "Iteration: 7235/10000, Loss: 0.007812866941094398\n",
      "Iteration: 7236/10000, Loss: 0.012729018926620483\n",
      "Iteration: 7237/10000, Loss: 0.010435117408633232\n",
      "Iteration: 7238/10000, Loss: 0.006151218432933092\n",
      "Iteration: 7239/10000, Loss: 0.01040319912135601\n",
      "Iteration: 7240/10000, Loss: 0.012781566008925438\n",
      "Iteration: 7241/10000, Loss: 0.012900006026029587\n",
      "Iteration: 7242/10000, Loss: 0.005041666328907013\n",
      "Iteration: 7243/10000, Loss: 0.0073433080688118935\n",
      "Iteration: 7244/10000, Loss: 0.0100398613139987\n",
      "Iteration: 7245/10000, Loss: 0.01508147269487381\n",
      "Iteration: 7246/10000, Loss: 0.010668652132153511\n",
      "Iteration: 7247/10000, Loss: 0.010254736989736557\n",
      "Iteration: 7248/10000, Loss: 0.008552998304367065\n",
      "Iteration: 7249/10000, Loss: 0.010209606029093266\n",
      "Iteration: 7250/10000, Loss: 0.015016469173133373\n",
      "Iteration: 7251/10000, Loss: 0.005544337909668684\n",
      "Iteration: 7252/10000, Loss: 0.007779274135828018\n",
      "Iteration: 7253/10000, Loss: 0.013221503235399723\n",
      "Iteration: 7254/10000, Loss: 0.010320696979761124\n",
      "Iteration: 7255/10000, Loss: 0.014165034517645836\n",
      "Iteration: 7256/10000, Loss: 0.010324818082153797\n",
      "Iteration: 7257/10000, Loss: 0.013502723537385464\n",
      "Iteration: 7258/10000, Loss: 0.01234062947332859\n",
      "Iteration: 7259/10000, Loss: 0.014286958612501621\n",
      "Iteration: 7260/10000, Loss: 0.010676532052457333\n",
      "Iteration: 7261/10000, Loss: 0.010076535865664482\n",
      "Iteration: 7262/10000, Loss: 0.008610746823251247\n",
      "Iteration: 7263/10000, Loss: 0.012488003820180893\n",
      "Iteration: 7264/10000, Loss: 0.0108890850096941\n",
      "Iteration: 7265/10000, Loss: 0.015754137188196182\n",
      "Iteration: 7266/10000, Loss: 0.01433496456593275\n",
      "Iteration: 7267/10000, Loss: 0.012710334733128548\n",
      "Iteration: 7268/10000, Loss: 0.016956305131316185\n",
      "Iteration: 7269/10000, Loss: 0.01001664623618126\n",
      "Iteration: 7270/10000, Loss: 0.010437949560582638\n",
      "Iteration: 7271/10000, Loss: 0.01858578808605671\n",
      "Iteration: 7272/10000, Loss: 0.008826972916722298\n",
      "Iteration: 7273/10000, Loss: 0.012454242445528507\n",
      "Iteration: 7274/10000, Loss: 0.0066969869658350945\n",
      "Iteration: 7275/10000, Loss: 0.011168522760272026\n",
      "Iteration: 7276/10000, Loss: 0.007101763039827347\n",
      "Iteration: 7277/10000, Loss: 0.012404810637235641\n",
      "Iteration: 7278/10000, Loss: 0.017993256449699402\n",
      "Iteration: 7279/10000, Loss: 0.01293738279491663\n",
      "Iteration: 7280/10000, Loss: 0.007487680297344923\n",
      "Iteration: 7281/10000, Loss: 0.010668234899640083\n",
      "Iteration: 7282/10000, Loss: 0.014122311025857925\n",
      "Iteration: 7283/10000, Loss: 0.01352264266461134\n",
      "Iteration: 7284/10000, Loss: 0.013075574301183224\n",
      "Iteration: 7285/10000, Loss: 0.0069890739396214485\n",
      "Iteration: 7286/10000, Loss: 0.007027727086097002\n",
      "Iteration: 7287/10000, Loss: 0.009837625548243523\n",
      "Iteration: 7288/10000, Loss: 0.01792476885020733\n",
      "Iteration: 7289/10000, Loss: 0.015638289973139763\n",
      "Iteration: 7290/10000, Loss: 0.01224543433636427\n",
      "Iteration: 7291/10000, Loss: 0.010809565894305706\n",
      "Iteration: 7292/10000, Loss: 0.018557008355855942\n",
      "Iteration: 7293/10000, Loss: 0.013979678973555565\n",
      "Iteration: 7294/10000, Loss: 0.009563981555402279\n",
      "Iteration: 7295/10000, Loss: 0.010281707160174847\n",
      "Iteration: 7296/10000, Loss: 0.011372050270438194\n",
      "Iteration: 7297/10000, Loss: 0.011971481144428253\n",
      "Iteration: 7298/10000, Loss: 0.011517193168401718\n",
      "Iteration: 7299/10000, Loss: 0.009180999360978603\n",
      "Iteration: 7300/10000, Loss: 0.010975413955748081\n",
      "Average test loss:  0.0018\n",
      "Iteration: 7301/10000, Loss: 0.005865347106009722\n",
      "Iteration: 7302/10000, Loss: 0.009394883178174496\n",
      "Iteration: 7303/10000, Loss: 0.01164200808852911\n",
      "Iteration: 7304/10000, Loss: 0.011950436979532242\n",
      "Iteration: 7305/10000, Loss: 0.009364750236272812\n",
      "Iteration: 7306/10000, Loss: 0.009431211277842522\n",
      "Iteration: 7307/10000, Loss: 0.016703641042113304\n",
      "Iteration: 7308/10000, Loss: 0.0139558594673872\n",
      "Iteration: 7309/10000, Loss: 0.01175807323306799\n",
      "Iteration: 7310/10000, Loss: 0.014546304941177368\n",
      "Iteration: 7311/10000, Loss: 0.013831175863742828\n",
      "Iteration: 7312/10000, Loss: 0.007855161093175411\n",
      "Iteration: 7313/10000, Loss: 0.011210013180971146\n",
      "Iteration: 7314/10000, Loss: 0.013174940831959248\n",
      "Iteration: 7315/10000, Loss: 0.011097203008830547\n",
      "Iteration: 7316/10000, Loss: 0.00858138594776392\n",
      "Iteration: 7317/10000, Loss: 0.014137761667370796\n",
      "Iteration: 7318/10000, Loss: 0.00864132959395647\n",
      "Iteration: 7319/10000, Loss: 0.008359414525330067\n",
      "Iteration: 7320/10000, Loss: 0.012403208762407303\n",
      "Iteration: 7321/10000, Loss: 0.008026025258004665\n",
      "Iteration: 7322/10000, Loss: 0.015026156790554523\n",
      "Iteration: 7323/10000, Loss: 0.0072779348120093346\n",
      "Iteration: 7324/10000, Loss: 0.012294596992433071\n",
      "Iteration: 7325/10000, Loss: 0.016219528391957283\n",
      "Iteration: 7326/10000, Loss: 0.01347566582262516\n",
      "Iteration: 7327/10000, Loss: 0.009252799674868584\n",
      "Iteration: 7328/10000, Loss: 0.011555846780538559\n",
      "Iteration: 7329/10000, Loss: 0.01222862210124731\n",
      "Iteration: 7330/10000, Loss: 0.010560588911175728\n",
      "Iteration: 7331/10000, Loss: 0.009508971124887466\n",
      "Iteration: 7332/10000, Loss: 0.015317624434828758\n",
      "Iteration: 7333/10000, Loss: 0.010753456503152847\n",
      "Iteration: 7334/10000, Loss: 0.013156157918274403\n",
      "Iteration: 7335/10000, Loss: 0.009557584300637245\n",
      "Iteration: 7336/10000, Loss: 0.011110682040452957\n",
      "Iteration: 7337/10000, Loss: 0.007398598361760378\n",
      "Iteration: 7338/10000, Loss: 0.009849623776972294\n",
      "Iteration: 7339/10000, Loss: 0.00965903326869011\n",
      "Iteration: 7340/10000, Loss: 0.009687472134828568\n",
      "Iteration: 7341/10000, Loss: 0.009590128436684608\n",
      "Iteration: 7342/10000, Loss: 0.009429492987692356\n",
      "Iteration: 7343/10000, Loss: 0.009382938966155052\n",
      "Iteration: 7344/10000, Loss: 0.009230196475982666\n",
      "Iteration: 7345/10000, Loss: 0.013003921136260033\n",
      "Iteration: 7346/10000, Loss: 0.013241661712527275\n",
      "Iteration: 7347/10000, Loss: 0.011620789766311646\n",
      "Iteration: 7348/10000, Loss: 0.008958852849900723\n",
      "Iteration: 7349/10000, Loss: 0.011241567321121693\n",
      "Iteration: 7350/10000, Loss: 0.0073074051178991795\n",
      "Iteration: 7351/10000, Loss: 0.012023327872157097\n",
      "Iteration: 7352/10000, Loss: 0.013323763385415077\n",
      "Iteration: 7353/10000, Loss: 0.014382311142981052\n",
      "Iteration: 7354/10000, Loss: 0.01179896853864193\n",
      "Iteration: 7355/10000, Loss: 0.007458932232111692\n",
      "Iteration: 7356/10000, Loss: 0.014605924487113953\n",
      "Iteration: 7357/10000, Loss: 0.006128637585788965\n",
      "Iteration: 7358/10000, Loss: 0.008768714964389801\n",
      "Iteration: 7359/10000, Loss: 0.0113510238006711\n",
      "Iteration: 7360/10000, Loss: 0.009203946217894554\n",
      "Iteration: 7361/10000, Loss: 0.008696191944181919\n",
      "Iteration: 7362/10000, Loss: 0.011264018714427948\n",
      "Iteration: 7363/10000, Loss: 0.009113322012126446\n",
      "Iteration: 7364/10000, Loss: 0.012599315494298935\n",
      "Iteration: 7365/10000, Loss: 0.014007006771862507\n",
      "Iteration: 7366/10000, Loss: 0.012488963082432747\n",
      "Iteration: 7367/10000, Loss: 0.014152838848531246\n",
      "Iteration: 7368/10000, Loss: 0.012217766605317593\n",
      "Iteration: 7369/10000, Loss: 0.012727223336696625\n",
      "Iteration: 7370/10000, Loss: 0.008545966818928719\n",
      "Iteration: 7371/10000, Loss: 0.011454764753580093\n",
      "Iteration: 7372/10000, Loss: 0.008826830424368382\n",
      "Iteration: 7373/10000, Loss: 0.011529181152582169\n",
      "Iteration: 7374/10000, Loss: 0.00818087812513113\n",
      "Iteration: 7375/10000, Loss: 0.009506423957645893\n",
      "Iteration: 7376/10000, Loss: 0.010016115382313728\n",
      "Iteration: 7377/10000, Loss: 0.012809178791940212\n",
      "Iteration: 7378/10000, Loss: 0.010007552802562714\n",
      "Iteration: 7379/10000, Loss: 0.011290475726127625\n",
      "Iteration: 7380/10000, Loss: 0.010760425589978695\n",
      "Iteration: 7381/10000, Loss: 0.009246312081813812\n",
      "Iteration: 7382/10000, Loss: 0.008142641745507717\n",
      "Iteration: 7383/10000, Loss: 0.013238846324384212\n",
      "Iteration: 7384/10000, Loss: 0.011460796929895878\n",
      "Iteration: 7385/10000, Loss: 0.008745087310671806\n",
      "Iteration: 7386/10000, Loss: 0.011331855319440365\n",
      "Iteration: 7387/10000, Loss: 0.008508581668138504\n",
      "Iteration: 7388/10000, Loss: 0.01168153341859579\n",
      "Iteration: 7389/10000, Loss: 0.009247973561286926\n",
      "Iteration: 7390/10000, Loss: 0.010312812402844429\n",
      "Iteration: 7391/10000, Loss: 0.0121476324275136\n",
      "Iteration: 7392/10000, Loss: 0.010256504639983177\n",
      "Iteration: 7393/10000, Loss: 0.01033932063728571\n",
      "Iteration: 7394/10000, Loss: 0.008609125390648842\n",
      "Iteration: 7395/10000, Loss: 0.010540091432631016\n",
      "Iteration: 7396/10000, Loss: 0.007985941134393215\n",
      "Iteration: 7397/10000, Loss: 0.010307388380169868\n",
      "Iteration: 7398/10000, Loss: 0.014690481126308441\n",
      "Iteration: 7399/10000, Loss: 0.010452941060066223\n",
      "Iteration: 7400/10000, Loss: 0.012028314173221588\n",
      "Average test loss:  0.0036\n",
      "Iteration: 7401/10000, Loss: 0.015161334536969662\n",
      "Iteration: 7402/10000, Loss: 0.008978735655546188\n",
      "Iteration: 7403/10000, Loss: 0.010271606035530567\n",
      "Iteration: 7404/10000, Loss: 0.00793252419680357\n",
      "Iteration: 7405/10000, Loss: 0.013453331775963306\n",
      "Iteration: 7406/10000, Loss: 0.011516004800796509\n",
      "Iteration: 7407/10000, Loss: 0.01386608649045229\n",
      "Iteration: 7408/10000, Loss: 0.007588802371174097\n",
      "Iteration: 7409/10000, Loss: 0.00845335517078638\n",
      "Iteration: 7410/10000, Loss: 0.010487709194421768\n",
      "Iteration: 7411/10000, Loss: 0.012129750102758408\n",
      "Iteration: 7412/10000, Loss: 0.010835581459105015\n",
      "Iteration: 7413/10000, Loss: 0.009450498037040234\n",
      "Iteration: 7414/10000, Loss: 0.00989389419555664\n",
      "Iteration: 7415/10000, Loss: 0.011046827770769596\n",
      "Iteration: 7416/10000, Loss: 0.008376996032893658\n",
      "Iteration: 7417/10000, Loss: 0.010576669126749039\n",
      "Iteration: 7418/10000, Loss: 0.011881153099238873\n",
      "Iteration: 7419/10000, Loss: 0.01013221126049757\n",
      "Iteration: 7420/10000, Loss: 0.006980679929256439\n",
      "Iteration: 7421/10000, Loss: 0.008876360952854156\n",
      "Iteration: 7422/10000, Loss: 0.008348650299012661\n",
      "Iteration: 7423/10000, Loss: 0.0052377087995409966\n",
      "Iteration: 7424/10000, Loss: 0.014807521365582943\n",
      "Iteration: 7425/10000, Loss: 0.007050665561109781\n",
      "Iteration: 7426/10000, Loss: 0.01353188045322895\n",
      "Iteration: 7427/10000, Loss: 0.00810974556952715\n",
      "Iteration: 7428/10000, Loss: 0.010566120967268944\n",
      "Iteration: 7429/10000, Loss: 0.009385823272168636\n",
      "Iteration: 7430/10000, Loss: 0.009648160077631474\n",
      "Iteration: 7431/10000, Loss: 0.0062058474868535995\n",
      "Iteration: 7432/10000, Loss: 0.010270457714796066\n",
      "Iteration: 7433/10000, Loss: 0.01577681675553322\n",
      "Iteration: 7434/10000, Loss: 0.012535437941551208\n",
      "Iteration: 7435/10000, Loss: 0.013091154396533966\n",
      "Iteration: 7436/10000, Loss: 0.011566209606826305\n",
      "Iteration: 7437/10000, Loss: 0.01232903078198433\n",
      "Iteration: 7438/10000, Loss: 0.010792650282382965\n",
      "Iteration: 7439/10000, Loss: 0.01396883837878704\n",
      "Iteration: 7440/10000, Loss: 0.01037669274955988\n",
      "Iteration: 7441/10000, Loss: 0.010092808865010738\n",
      "Iteration: 7442/10000, Loss: 0.012351751327514648\n",
      "Iteration: 7443/10000, Loss: 0.008678657002747059\n",
      "Iteration: 7444/10000, Loss: 0.014872416853904724\n",
      "Iteration: 7445/10000, Loss: 0.009572887793183327\n",
      "Iteration: 7446/10000, Loss: 0.018117094412446022\n",
      "Iteration: 7447/10000, Loss: 0.012562337331473827\n",
      "Iteration: 7448/10000, Loss: 0.013976647518575191\n",
      "Iteration: 7449/10000, Loss: 0.0067809587344527245\n",
      "Iteration: 7450/10000, Loss: 0.01099913939833641\n",
      "Iteration: 7451/10000, Loss: 0.010119716636836529\n",
      "Iteration: 7452/10000, Loss: 0.00975109077990055\n",
      "Iteration: 7453/10000, Loss: 0.013996431604027748\n",
      "Iteration: 7454/10000, Loss: 0.011528916656970978\n",
      "Iteration: 7455/10000, Loss: 0.006379549391567707\n",
      "Iteration: 7456/10000, Loss: 0.013316544704139233\n",
      "Iteration: 7457/10000, Loss: 0.007360597141087055\n",
      "Iteration: 7458/10000, Loss: 0.005339763592928648\n",
      "Iteration: 7459/10000, Loss: 0.013550430536270142\n",
      "Iteration: 7460/10000, Loss: 0.016058675944805145\n",
      "Iteration: 7461/10000, Loss: 0.01576557755470276\n",
      "Iteration: 7462/10000, Loss: 0.009595401585102081\n",
      "Iteration: 7463/10000, Loss: 0.009938672184944153\n",
      "Iteration: 7464/10000, Loss: 0.009681358933448792\n",
      "Iteration: 7465/10000, Loss: 0.008538469672203064\n",
      "Iteration: 7466/10000, Loss: 0.01594173163175583\n",
      "Iteration: 7467/10000, Loss: 0.014043521136045456\n",
      "Iteration: 7468/10000, Loss: 0.01272531971335411\n",
      "Iteration: 7469/10000, Loss: 0.010594177059829235\n",
      "Iteration: 7470/10000, Loss: 0.012709248811006546\n",
      "Iteration: 7471/10000, Loss: 0.010673451237380505\n",
      "Iteration: 7472/10000, Loss: 0.01223041769117117\n",
      "Iteration: 7473/10000, Loss: 0.009948714636266232\n",
      "Iteration: 7474/10000, Loss: 0.00780469598248601\n",
      "Iteration: 7475/10000, Loss: 0.006319853942841291\n",
      "Iteration: 7476/10000, Loss: 0.008956295438110828\n",
      "Iteration: 7477/10000, Loss: 0.007156031206250191\n",
      "Iteration: 7478/10000, Loss: 0.007829327136278152\n",
      "Iteration: 7479/10000, Loss: 0.007854449562728405\n",
      "Iteration: 7480/10000, Loss: 0.012236535549163818\n",
      "Iteration: 7481/10000, Loss: 0.010436502285301685\n",
      "Iteration: 7482/10000, Loss: 0.008953448385000229\n",
      "Iteration: 7483/10000, Loss: 0.007220120634883642\n",
      "Iteration: 7484/10000, Loss: 0.010236687958240509\n",
      "Iteration: 7485/10000, Loss: 0.014892898499965668\n",
      "Iteration: 7486/10000, Loss: 0.010593260638415813\n",
      "Iteration: 7487/10000, Loss: 0.012446047738194466\n",
      "Iteration: 7488/10000, Loss: 0.007366504520177841\n",
      "Iteration: 7489/10000, Loss: 0.009841365739703178\n",
      "Iteration: 7490/10000, Loss: 0.010443870909512043\n",
      "Iteration: 7491/10000, Loss: 0.008434989489614964\n",
      "Iteration: 7492/10000, Loss: 0.007010868284851313\n",
      "Iteration: 7493/10000, Loss: 0.011190773919224739\n",
      "Iteration: 7494/10000, Loss: 0.010074482299387455\n",
      "Iteration: 7495/10000, Loss: 0.009211812168359756\n",
      "Iteration: 7496/10000, Loss: 0.009430616162717342\n",
      "Iteration: 7497/10000, Loss: 0.009898355230689049\n",
      "Iteration: 7498/10000, Loss: 0.01081523485481739\n",
      "Iteration: 7499/10000, Loss: 0.005283167120069265\n",
      "Iteration: 7500/10000, Loss: 0.014041169546544552\n",
      "Average test loss:  0.0022\n",
      "Iteration: 7501/10000, Loss: 0.011386865749955177\n",
      "Iteration: 7502/10000, Loss: 0.008458265103399754\n",
      "Iteration: 7503/10000, Loss: 0.009428075514733791\n",
      "Iteration: 7504/10000, Loss: 0.006268453784286976\n",
      "Iteration: 7505/10000, Loss: 0.010780183598399162\n",
      "Iteration: 7506/10000, Loss: 0.013210682198405266\n",
      "Iteration: 7507/10000, Loss: 0.008935212157666683\n",
      "Iteration: 7508/10000, Loss: 0.01147907879203558\n",
      "Iteration: 7509/10000, Loss: 0.008327770046889782\n",
      "Iteration: 7510/10000, Loss: 0.010182689875364304\n",
      "Iteration: 7511/10000, Loss: 0.007238040678203106\n",
      "Iteration: 7512/10000, Loss: 0.012036900967359543\n",
      "Iteration: 7513/10000, Loss: 0.011803676374256611\n",
      "Iteration: 7514/10000, Loss: 0.015458190813660622\n",
      "Iteration: 7515/10000, Loss: 0.010728267021477222\n",
      "Iteration: 7516/10000, Loss: 0.007925163023173809\n",
      "Iteration: 7517/10000, Loss: 0.012781444005668163\n",
      "Iteration: 7518/10000, Loss: 0.012211548164486885\n",
      "Iteration: 7519/10000, Loss: 0.011111847124993801\n",
      "Iteration: 7520/10000, Loss: 0.011738679371774197\n",
      "Iteration: 7521/10000, Loss: 0.011987452395260334\n",
      "Iteration: 7522/10000, Loss: 0.008705529384315014\n",
      "Iteration: 7523/10000, Loss: 0.012459652498364449\n",
      "Iteration: 7524/10000, Loss: 0.008479908108711243\n",
      "Iteration: 7525/10000, Loss: 0.005682132672518492\n",
      "Iteration: 7526/10000, Loss: 0.013925135135650635\n",
      "Iteration: 7527/10000, Loss: 0.009816299192607403\n",
      "Iteration: 7528/10000, Loss: 0.012070068158209324\n",
      "Iteration: 7529/10000, Loss: 0.0074068475514650345\n",
      "Iteration: 7530/10000, Loss: 0.010985275730490685\n",
      "Iteration: 7531/10000, Loss: 0.012194649316370487\n",
      "Iteration: 7532/10000, Loss: 0.008938243612647057\n",
      "Iteration: 7533/10000, Loss: 0.01027768850326538\n",
      "Iteration: 7534/10000, Loss: 0.01020037941634655\n",
      "Iteration: 7535/10000, Loss: 0.008583564311265945\n",
      "Iteration: 7536/10000, Loss: 0.015422145836055279\n",
      "Iteration: 7537/10000, Loss: 0.009782114997506142\n",
      "Iteration: 7538/10000, Loss: 0.006410172209143639\n",
      "Iteration: 7539/10000, Loss: 0.009146962314844131\n",
      "Iteration: 7540/10000, Loss: 0.009729570709168911\n",
      "Iteration: 7541/10000, Loss: 0.009304836392402649\n",
      "Iteration: 7542/10000, Loss: 0.0075107356533408165\n",
      "Iteration: 7543/10000, Loss: 0.010691278614103794\n",
      "Iteration: 7544/10000, Loss: 0.01643693633377552\n",
      "Iteration: 7545/10000, Loss: 0.007650335785001516\n",
      "Iteration: 7546/10000, Loss: 0.0069127511233091354\n",
      "Iteration: 7547/10000, Loss: 0.008124236948788166\n",
      "Iteration: 7548/10000, Loss: 0.008835099637508392\n",
      "Iteration: 7549/10000, Loss: 0.012158707715570927\n",
      "Iteration: 7550/10000, Loss: 0.01550754439085722\n",
      "Iteration: 7551/10000, Loss: 0.010077454149723053\n",
      "Iteration: 7552/10000, Loss: 0.011846679262816906\n",
      "Iteration: 7553/10000, Loss: 0.013237928971648216\n",
      "Iteration: 7554/10000, Loss: 0.01243512611836195\n",
      "Iteration: 7555/10000, Loss: 0.009944548830389977\n",
      "Iteration: 7556/10000, Loss: 0.005500062834471464\n",
      "Iteration: 7557/10000, Loss: 0.006396820303052664\n",
      "Iteration: 7558/10000, Loss: 0.007288568653166294\n",
      "Iteration: 7559/10000, Loss: 0.012854250147938728\n",
      "Iteration: 7560/10000, Loss: 0.007934968918561935\n",
      "Iteration: 7561/10000, Loss: 0.010424098931252956\n",
      "Iteration: 7562/10000, Loss: 0.0077518862672150135\n",
      "Iteration: 7563/10000, Loss: 0.013357957825064659\n",
      "Iteration: 7564/10000, Loss: 0.007104312069714069\n",
      "Iteration: 7565/10000, Loss: 0.012469306588172913\n",
      "Iteration: 7566/10000, Loss: 0.011914193630218506\n",
      "Iteration: 7567/10000, Loss: 0.007553516421467066\n",
      "Iteration: 7568/10000, Loss: 0.007952935993671417\n",
      "Iteration: 7569/10000, Loss: 0.008607625029981136\n",
      "Iteration: 7570/10000, Loss: 0.0062780617736279964\n",
      "Iteration: 7571/10000, Loss: 0.010631807148456573\n",
      "Iteration: 7572/10000, Loss: 0.00901734922081232\n",
      "Iteration: 7573/10000, Loss: 0.00888522993773222\n",
      "Iteration: 7574/10000, Loss: 0.017118187621235847\n",
      "Iteration: 7575/10000, Loss: 0.009250681847333908\n",
      "Iteration: 7576/10000, Loss: 0.009226025082170963\n",
      "Iteration: 7577/10000, Loss: 0.008758114650845528\n",
      "Iteration: 7578/10000, Loss: 0.014339619316160679\n",
      "Iteration: 7579/10000, Loss: 0.009825773537158966\n",
      "Iteration: 7580/10000, Loss: 0.007321761455386877\n",
      "Iteration: 7581/10000, Loss: 0.007614761125296354\n",
      "Iteration: 7582/10000, Loss: 0.009172854013741016\n",
      "Iteration: 7583/10000, Loss: 0.008103707805275917\n",
      "Iteration: 7584/10000, Loss: 0.010996682569384575\n",
      "Iteration: 7585/10000, Loss: 0.003957713488489389\n",
      "Iteration: 7586/10000, Loss: 0.00999481976032257\n",
      "Iteration: 7587/10000, Loss: 0.009887189604341984\n",
      "Iteration: 7588/10000, Loss: 0.006561343092471361\n",
      "Iteration: 7589/10000, Loss: 0.011734643951058388\n",
      "Iteration: 7590/10000, Loss: 0.005852750036865473\n",
      "Iteration: 7591/10000, Loss: 0.00638345442712307\n",
      "Iteration: 7592/10000, Loss: 0.005999268498271704\n",
      "Iteration: 7593/10000, Loss: 0.01088691782206297\n",
      "Iteration: 7594/10000, Loss: 0.01159919984638691\n",
      "Iteration: 7595/10000, Loss: 0.010614924132823944\n",
      "Iteration: 7596/10000, Loss: 0.00861663743853569\n",
      "Iteration: 7597/10000, Loss: 0.008573517203330994\n",
      "Iteration: 7598/10000, Loss: 0.01649416983127594\n",
      "Iteration: 7599/10000, Loss: 0.011789754033088684\n",
      "Iteration: 7600/10000, Loss: 0.01196689810603857\n",
      "Average test loss:  0.0030\n",
      "Iteration: 7601/10000, Loss: 0.014944023452699184\n",
      "Iteration: 7602/10000, Loss: 0.011414495296776295\n",
      "Iteration: 7603/10000, Loss: 0.007976672612130642\n",
      "Iteration: 7604/10000, Loss: 0.015159006230533123\n",
      "Iteration: 7605/10000, Loss: 0.010878222994506359\n",
      "Iteration: 7606/10000, Loss: 0.010327554307878017\n",
      "Iteration: 7607/10000, Loss: 0.005555309355258942\n",
      "Iteration: 7608/10000, Loss: 0.010550007224082947\n",
      "Iteration: 7609/10000, Loss: 0.006929905153810978\n",
      "Iteration: 7610/10000, Loss: 0.011866630986332893\n",
      "Iteration: 7611/10000, Loss: 0.008913608267903328\n",
      "Iteration: 7612/10000, Loss: 0.012737306766211987\n",
      "Iteration: 7613/10000, Loss: 0.011462301015853882\n",
      "Iteration: 7614/10000, Loss: 0.009367143735289574\n",
      "Iteration: 7615/10000, Loss: 0.01317903958261013\n",
      "Iteration: 7616/10000, Loss: 0.011279811151325703\n",
      "Iteration: 7617/10000, Loss: 0.009505017660558224\n",
      "Iteration: 7618/10000, Loss: 0.010359156876802444\n",
      "Iteration: 7619/10000, Loss: 0.013229172676801682\n",
      "Iteration: 7620/10000, Loss: 0.015527434647083282\n",
      "Iteration: 7621/10000, Loss: 0.008292934857308865\n",
      "Iteration: 7622/10000, Loss: 0.01432789582759142\n",
      "Iteration: 7623/10000, Loss: 0.009160677902400494\n",
      "Iteration: 7624/10000, Loss: 0.007726164069026709\n",
      "Iteration: 7625/10000, Loss: 0.010261692106723785\n",
      "Iteration: 7626/10000, Loss: 0.013304530642926693\n",
      "Iteration: 7627/10000, Loss: 0.0071655516512691975\n",
      "Iteration: 7628/10000, Loss: 0.007585978135466576\n",
      "Iteration: 7629/10000, Loss: 0.007178695872426033\n",
      "Iteration: 7630/10000, Loss: 0.012623462826013565\n",
      "Iteration: 7631/10000, Loss: 0.008237095549702644\n",
      "Iteration: 7632/10000, Loss: 0.011203055270016193\n",
      "Iteration: 7633/10000, Loss: 0.010226757265627384\n",
      "Iteration: 7634/10000, Loss: 0.008269869722425938\n",
      "Iteration: 7635/10000, Loss: 0.010009241290390491\n",
      "Iteration: 7636/10000, Loss: 0.011790703982114792\n",
      "Iteration: 7637/10000, Loss: 0.012891961261630058\n",
      "Iteration: 7638/10000, Loss: 0.013828430324792862\n",
      "Iteration: 7639/10000, Loss: 0.010327508673071861\n",
      "Iteration: 7640/10000, Loss: 0.010474048554897308\n",
      "Iteration: 7641/10000, Loss: 0.01294717751443386\n",
      "Iteration: 7642/10000, Loss: 0.011901581659913063\n",
      "Iteration: 7643/10000, Loss: 0.012556067667901516\n",
      "Iteration: 7644/10000, Loss: 0.008472148329019547\n",
      "Iteration: 7645/10000, Loss: 0.010962973348796368\n",
      "Iteration: 7646/10000, Loss: 0.0093718022108078\n",
      "Iteration: 7647/10000, Loss: 0.008109500631690025\n",
      "Iteration: 7648/10000, Loss: 0.010146554559469223\n",
      "Iteration: 7649/10000, Loss: 0.008565021678805351\n",
      "Iteration: 7650/10000, Loss: 0.010821218602359295\n",
      "Iteration: 7651/10000, Loss: 0.00787632167339325\n",
      "Iteration: 7652/10000, Loss: 0.007209742907434702\n",
      "Iteration: 7653/10000, Loss: 0.008504199795424938\n",
      "Iteration: 7654/10000, Loss: 0.016060521826148033\n",
      "Iteration: 7655/10000, Loss: 0.018241284415125847\n",
      "Iteration: 7656/10000, Loss: 0.010964724235236645\n",
      "Iteration: 7657/10000, Loss: 0.00978906825184822\n",
      "Iteration: 7658/10000, Loss: 0.009104212746024132\n",
      "Iteration: 7659/10000, Loss: 0.009677592664957047\n",
      "Iteration: 7660/10000, Loss: 0.006554271560162306\n",
      "Iteration: 7661/10000, Loss: 0.01246495358645916\n",
      "Iteration: 7662/10000, Loss: 0.011877820827066898\n",
      "Iteration: 7663/10000, Loss: 0.013755429536104202\n",
      "Iteration: 7664/10000, Loss: 0.009342487901449203\n",
      "Iteration: 7665/10000, Loss: 0.012151804752647877\n",
      "Iteration: 7666/10000, Loss: 0.010173482820391655\n",
      "Iteration: 7667/10000, Loss: 0.01221474539488554\n",
      "Iteration: 7668/10000, Loss: 0.009329613298177719\n",
      "Iteration: 7669/10000, Loss: 0.012925378046929836\n",
      "Iteration: 7670/10000, Loss: 0.009956480003893375\n",
      "Iteration: 7671/10000, Loss: 0.0038911448791623116\n",
      "Iteration: 7672/10000, Loss: 0.013402121141552925\n",
      "Iteration: 7673/10000, Loss: 0.00764013547450304\n",
      "Iteration: 7674/10000, Loss: 0.007016065064817667\n",
      "Iteration: 7675/10000, Loss: 0.0044255503453314304\n",
      "Iteration: 7676/10000, Loss: 0.007900687865912914\n",
      "Iteration: 7677/10000, Loss: 0.009225022979080677\n",
      "Iteration: 7678/10000, Loss: 0.013231624849140644\n",
      "Iteration: 7679/10000, Loss: 0.009347832761704922\n",
      "Iteration: 7680/10000, Loss: 0.014980174601078033\n",
      "Iteration: 7681/10000, Loss: 0.010807998478412628\n",
      "Iteration: 7682/10000, Loss: 0.012488843873143196\n",
      "Iteration: 7683/10000, Loss: 0.008658530190587044\n",
      "Iteration: 7684/10000, Loss: 0.010762650519609451\n",
      "Iteration: 7685/10000, Loss: 0.014207839034497738\n",
      "Iteration: 7686/10000, Loss: 0.010344171896576881\n",
      "Iteration: 7687/10000, Loss: 0.007736889645457268\n",
      "Iteration: 7688/10000, Loss: 0.010329836048185825\n",
      "Iteration: 7689/10000, Loss: 0.014769266359508038\n",
      "Iteration: 7690/10000, Loss: 0.009578322991728783\n",
      "Iteration: 7691/10000, Loss: 0.013470818288624287\n",
      "Iteration: 7692/10000, Loss: 0.01154977735131979\n",
      "Iteration: 7693/10000, Loss: 0.00996373686939478\n",
      "Iteration: 7694/10000, Loss: 0.015605226159095764\n",
      "Iteration: 7695/10000, Loss: 0.007756742183119059\n",
      "Iteration: 7696/10000, Loss: 0.009377800859510899\n",
      "Iteration: 7697/10000, Loss: 0.007813102565705776\n",
      "Iteration: 7698/10000, Loss: 0.010911356657743454\n",
      "Iteration: 7699/10000, Loss: 0.011776191182434559\n",
      "Iteration: 7700/10000, Loss: 0.009100334718823433\n",
      "Average test loss:  0.0021\n",
      "Iteration: 7701/10000, Loss: 0.010945474728941917\n",
      "Iteration: 7702/10000, Loss: 0.008011698722839355\n",
      "Iteration: 7703/10000, Loss: 0.008337772451341152\n",
      "Iteration: 7704/10000, Loss: 0.011744789779186249\n",
      "Iteration: 7705/10000, Loss: 0.012024736031889915\n",
      "Iteration: 7706/10000, Loss: 0.007766345515847206\n",
      "Iteration: 7707/10000, Loss: 0.00952290277928114\n",
      "Iteration: 7708/10000, Loss: 0.011026403866708279\n",
      "Iteration: 7709/10000, Loss: 0.010506813414394855\n",
      "Iteration: 7710/10000, Loss: 0.011182638816535473\n",
      "Iteration: 7711/10000, Loss: 0.013078110292553902\n",
      "Iteration: 7712/10000, Loss: 0.006041911896318197\n",
      "Iteration: 7713/10000, Loss: 0.008335239253938198\n",
      "Iteration: 7714/10000, Loss: 0.008270027115941048\n",
      "Iteration: 7715/10000, Loss: 0.012683275155723095\n",
      "Iteration: 7716/10000, Loss: 0.010402561165392399\n",
      "Iteration: 7717/10000, Loss: 0.011848454363644123\n",
      "Iteration: 7718/10000, Loss: 0.009682804346084595\n",
      "Iteration: 7719/10000, Loss: 0.011309467256069183\n",
      "Iteration: 7720/10000, Loss: 0.012197475880384445\n",
      "Iteration: 7721/10000, Loss: 0.0063077122904360294\n",
      "Iteration: 7722/10000, Loss: 0.008551868610084057\n",
      "Iteration: 7723/10000, Loss: 0.011915414594113827\n",
      "Iteration: 7724/10000, Loss: 0.00914677418768406\n",
      "Iteration: 7725/10000, Loss: 0.010822881013154984\n",
      "Iteration: 7726/10000, Loss: 0.012951495125889778\n",
      "Iteration: 7727/10000, Loss: 0.013140548020601273\n",
      "Iteration: 7728/10000, Loss: 0.00805130135267973\n",
      "Iteration: 7729/10000, Loss: 0.00741912703961134\n",
      "Iteration: 7730/10000, Loss: 0.007253209128975868\n",
      "Iteration: 7731/10000, Loss: 0.011464724317193031\n",
      "Iteration: 7732/10000, Loss: 0.013075861148536205\n",
      "Iteration: 7733/10000, Loss: 0.015014547854661942\n",
      "Iteration: 7734/10000, Loss: 0.009461233392357826\n",
      "Iteration: 7735/10000, Loss: 0.010513543151319027\n",
      "Iteration: 7736/10000, Loss: 0.010023019276559353\n",
      "Iteration: 7737/10000, Loss: 0.0063080876134335995\n",
      "Iteration: 7738/10000, Loss: 0.01052241399884224\n",
      "Iteration: 7739/10000, Loss: 0.011711616069078445\n",
      "Iteration: 7740/10000, Loss: 0.011323395185172558\n",
      "Iteration: 7741/10000, Loss: 0.0081535829231143\n",
      "Iteration: 7742/10000, Loss: 0.007660816889256239\n",
      "Iteration: 7743/10000, Loss: 0.010224086232483387\n",
      "Iteration: 7744/10000, Loss: 0.0067848991602659225\n",
      "Iteration: 7745/10000, Loss: 0.010375308804214\n",
      "Iteration: 7746/10000, Loss: 0.0065666125155985355\n",
      "Iteration: 7747/10000, Loss: 0.00976132694631815\n",
      "Iteration: 7748/10000, Loss: 0.010164705105125904\n",
      "Iteration: 7749/10000, Loss: 0.009420272894203663\n",
      "Iteration: 7750/10000, Loss: 0.015325337648391724\n",
      "Iteration: 7751/10000, Loss: 0.015092003159224987\n",
      "Iteration: 7752/10000, Loss: 0.011088008992373943\n",
      "Iteration: 7753/10000, Loss: 0.01217715535312891\n",
      "Iteration: 7754/10000, Loss: 0.009020347148180008\n",
      "Iteration: 7755/10000, Loss: 0.009214907884597778\n",
      "Iteration: 7756/10000, Loss: 0.01545453630387783\n",
      "Iteration: 7757/10000, Loss: 0.012424850836396217\n",
      "Iteration: 7758/10000, Loss: 0.011810853146016598\n",
      "Iteration: 7759/10000, Loss: 0.011517731472849846\n",
      "Iteration: 7760/10000, Loss: 0.012559786438941956\n",
      "Iteration: 7761/10000, Loss: 0.0066887387074530125\n",
      "Iteration: 7762/10000, Loss: 0.006064694840461016\n",
      "Iteration: 7763/10000, Loss: 0.013552412390708923\n",
      "Iteration: 7764/10000, Loss: 0.019022392109036446\n",
      "Iteration: 7765/10000, Loss: 0.011110535822808743\n",
      "Iteration: 7766/10000, Loss: 0.008515659719705582\n",
      "Iteration: 7767/10000, Loss: 0.013618793338537216\n",
      "Iteration: 7768/10000, Loss: 0.008537905290722847\n",
      "Iteration: 7769/10000, Loss: 0.010781371034681797\n",
      "Iteration: 7770/10000, Loss: 0.012329595163464546\n",
      "Iteration: 7771/10000, Loss: 0.013217881321907043\n",
      "Iteration: 7772/10000, Loss: 0.009174286387860775\n",
      "Iteration: 7773/10000, Loss: 0.004852541256695986\n",
      "Iteration: 7774/10000, Loss: 0.017523029819130898\n",
      "Iteration: 7775/10000, Loss: 0.008452613838016987\n",
      "Iteration: 7776/10000, Loss: 0.009816035628318787\n",
      "Iteration: 7777/10000, Loss: 0.008113674819469452\n",
      "Iteration: 7778/10000, Loss: 0.011086964048445225\n",
      "Iteration: 7779/10000, Loss: 0.012142674997448921\n",
      "Iteration: 7780/10000, Loss: 0.008209831081330776\n",
      "Iteration: 7781/10000, Loss: 0.007698218338191509\n",
      "Iteration: 7782/10000, Loss: 0.010097667574882507\n",
      "Iteration: 7783/10000, Loss: 0.016064539551734924\n",
      "Iteration: 7784/10000, Loss: 0.01333555020391941\n",
      "Iteration: 7785/10000, Loss: 0.01480571087449789\n",
      "Iteration: 7786/10000, Loss: 0.0073888846673071384\n",
      "Iteration: 7787/10000, Loss: 0.008787322789430618\n",
      "Iteration: 7788/10000, Loss: 0.01726544462144375\n",
      "Iteration: 7789/10000, Loss: 0.010495771653950214\n",
      "Iteration: 7790/10000, Loss: 0.00522004347294569\n",
      "Iteration: 7791/10000, Loss: 0.008380092680454254\n",
      "Iteration: 7792/10000, Loss: 0.008827175945043564\n",
      "Iteration: 7793/10000, Loss: 0.009334707632660866\n",
      "Iteration: 7794/10000, Loss: 0.012809122912585735\n",
      "Iteration: 7795/10000, Loss: 0.011550936847925186\n",
      "Iteration: 7796/10000, Loss: 0.009480183944106102\n",
      "Iteration: 7797/10000, Loss: 0.011778280138969421\n",
      "Iteration: 7798/10000, Loss: 0.00981965847313404\n",
      "Iteration: 7799/10000, Loss: 0.009862855076789856\n",
      "Iteration: 7800/10000, Loss: 0.007699080742895603\n",
      "Average test loss:  0.0016\n",
      "Iteration: 7801/10000, Loss: 0.0061364565044641495\n",
      "Iteration: 7802/10000, Loss: 0.008015218190848827\n",
      "Iteration: 7803/10000, Loss: 0.006690213456749916\n",
      "Iteration: 7804/10000, Loss: 0.0069085052236914635\n",
      "Iteration: 7805/10000, Loss: 0.006938581820577383\n",
      "Iteration: 7806/10000, Loss: 0.010140342637896538\n",
      "Iteration: 7807/10000, Loss: 0.0071835885755717754\n",
      "Iteration: 7808/10000, Loss: 0.00504950201138854\n",
      "Iteration: 7809/10000, Loss: 0.01347267534583807\n",
      "Iteration: 7810/10000, Loss: 0.009514203295111656\n",
      "Iteration: 7811/10000, Loss: 0.012287021614611149\n",
      "Iteration: 7812/10000, Loss: 0.010208490304648876\n",
      "Iteration: 7813/10000, Loss: 0.005598016083240509\n",
      "Iteration: 7814/10000, Loss: 0.010970198549330235\n",
      "Iteration: 7815/10000, Loss: 0.011893944814801216\n",
      "Iteration: 7816/10000, Loss: 0.01268242858350277\n",
      "Iteration: 7817/10000, Loss: 0.011241867206990719\n",
      "Iteration: 7818/10000, Loss: 0.005138531792908907\n",
      "Iteration: 7819/10000, Loss: 0.011469303630292416\n",
      "Iteration: 7820/10000, Loss: 0.008295009844005108\n",
      "Iteration: 7821/10000, Loss: 0.008364729583263397\n",
      "Iteration: 7822/10000, Loss: 0.011008167639374733\n",
      "Iteration: 7823/10000, Loss: 0.014595892280340195\n",
      "Iteration: 7824/10000, Loss: 0.008772546425461769\n",
      "Iteration: 7825/10000, Loss: 0.005653919652104378\n",
      "Iteration: 7826/10000, Loss: 0.008427330292761326\n",
      "Iteration: 7827/10000, Loss: 0.010865183547139168\n",
      "Iteration: 7828/10000, Loss: 0.015089333988726139\n",
      "Iteration: 7829/10000, Loss: 0.00539487274363637\n",
      "Iteration: 7830/10000, Loss: 0.012681912630796432\n",
      "Iteration: 7831/10000, Loss: 0.010274164378643036\n",
      "Iteration: 7832/10000, Loss: 0.009199348278343678\n",
      "Iteration: 7833/10000, Loss: 0.005972426850348711\n",
      "Iteration: 7834/10000, Loss: 0.010321796871721745\n",
      "Iteration: 7835/10000, Loss: 0.013141604140400887\n",
      "Iteration: 7836/10000, Loss: 0.011709397658705711\n",
      "Iteration: 7837/10000, Loss: 0.011311151087284088\n",
      "Iteration: 7838/10000, Loss: 0.007645116187632084\n",
      "Iteration: 7839/10000, Loss: 0.011871909722685814\n",
      "Iteration: 7840/10000, Loss: 0.01026980858296156\n",
      "Iteration: 7841/10000, Loss: 0.00806313194334507\n",
      "Iteration: 7842/10000, Loss: 0.005558609962463379\n",
      "Iteration: 7843/10000, Loss: 0.009334133937954903\n",
      "Iteration: 7844/10000, Loss: 0.007976295426487923\n",
      "Iteration: 7845/10000, Loss: 0.013006315566599369\n",
      "Iteration: 7846/10000, Loss: 0.009037399664521217\n",
      "Iteration: 7847/10000, Loss: 0.011890608817338943\n",
      "Iteration: 7848/10000, Loss: 0.013074174523353577\n",
      "Iteration: 7849/10000, Loss: 0.009549803100526333\n",
      "Iteration: 7850/10000, Loss: 0.011383108794689178\n",
      "Iteration: 7851/10000, Loss: 0.006353524513542652\n",
      "Iteration: 7852/10000, Loss: 0.00829192716628313\n",
      "Iteration: 7853/10000, Loss: 0.008269526064395905\n",
      "Iteration: 7854/10000, Loss: 0.009217841550707817\n",
      "Iteration: 7855/10000, Loss: 0.0058958400040864944\n",
      "Iteration: 7856/10000, Loss: 0.008229599334299564\n",
      "Iteration: 7857/10000, Loss: 0.011158079840242863\n",
      "Iteration: 7858/10000, Loss: 0.012739601545035839\n",
      "Iteration: 7859/10000, Loss: 0.007435595151036978\n",
      "Iteration: 7860/10000, Loss: 0.0114904148504138\n",
      "Iteration: 7861/10000, Loss: 0.010766888037323952\n",
      "Iteration: 7862/10000, Loss: 0.009542710147798061\n",
      "Iteration: 7863/10000, Loss: 0.00993443839251995\n",
      "Iteration: 7864/10000, Loss: 0.012593797408044338\n",
      "Iteration: 7865/10000, Loss: 0.011325495317578316\n",
      "Iteration: 7866/10000, Loss: 0.012908619828522205\n",
      "Iteration: 7867/10000, Loss: 0.011771412566304207\n",
      "Iteration: 7868/10000, Loss: 0.012990274466574192\n",
      "Iteration: 7869/10000, Loss: 0.00825713574886322\n",
      "Iteration: 7870/10000, Loss: 0.009657646529376507\n",
      "Iteration: 7871/10000, Loss: 0.013121021911501884\n",
      "Iteration: 7872/10000, Loss: 0.009489038027822971\n",
      "Iteration: 7873/10000, Loss: 0.009358546696603298\n",
      "Iteration: 7874/10000, Loss: 0.011242077685892582\n",
      "Iteration: 7875/10000, Loss: 0.009832627139985561\n",
      "Iteration: 7876/10000, Loss: 0.008398742415010929\n",
      "Iteration: 7877/10000, Loss: 0.013166924938559532\n",
      "Iteration: 7878/10000, Loss: 0.011256184428930283\n",
      "Iteration: 7879/10000, Loss: 0.010175049304962158\n",
      "Iteration: 7880/10000, Loss: 0.005512872710824013\n",
      "Iteration: 7881/10000, Loss: 0.011820845305919647\n",
      "Iteration: 7882/10000, Loss: 0.011244646273553371\n",
      "Iteration: 7883/10000, Loss: 0.009797624312341213\n",
      "Iteration: 7884/10000, Loss: 0.007732991594821215\n",
      "Iteration: 7885/10000, Loss: 0.010663587599992752\n",
      "Iteration: 7886/10000, Loss: 0.005311811808496714\n",
      "Iteration: 7887/10000, Loss: 0.01302848570048809\n",
      "Iteration: 7888/10000, Loss: 0.014257211238145828\n",
      "Iteration: 7889/10000, Loss: 0.010049737989902496\n",
      "Iteration: 7890/10000, Loss: 0.011439099907875061\n",
      "Iteration: 7891/10000, Loss: 0.015265069901943207\n",
      "Iteration: 7892/10000, Loss: 0.008097522892057896\n",
      "Iteration: 7893/10000, Loss: 0.01085375715047121\n",
      "Iteration: 7894/10000, Loss: 0.013422342948615551\n",
      "Iteration: 7895/10000, Loss: 0.0070108980871737\n",
      "Iteration: 7896/10000, Loss: 0.01623690500855446\n",
      "Iteration: 7897/10000, Loss: 0.007371095009148121\n",
      "Iteration: 7898/10000, Loss: 0.010103882290422916\n",
      "Iteration: 7899/10000, Loss: 0.007515349425375462\n",
      "Iteration: 7900/10000, Loss: 0.011133724823594093\n",
      "Average test loss:  0.0014\n",
      "Iteration: 7901/10000, Loss: 0.007404634729027748\n",
      "Iteration: 7902/10000, Loss: 0.007982439361512661\n",
      "Iteration: 7903/10000, Loss: 0.007915615104138851\n",
      "Iteration: 7904/10000, Loss: 0.010410617105662823\n",
      "Iteration: 7905/10000, Loss: 0.013869916088879108\n",
      "Iteration: 7906/10000, Loss: 0.007849879562854767\n",
      "Iteration: 7907/10000, Loss: 0.008788317441940308\n",
      "Iteration: 7908/10000, Loss: 0.009658482857048512\n",
      "Iteration: 7909/10000, Loss: 0.01125409733504057\n",
      "Iteration: 7910/10000, Loss: 0.010088811628520489\n",
      "Iteration: 7911/10000, Loss: 0.009958089329302311\n",
      "Iteration: 7912/10000, Loss: 0.008031878620386124\n",
      "Iteration: 7913/10000, Loss: 0.01205424778163433\n",
      "Iteration: 7914/10000, Loss: 0.005437015555799007\n",
      "Iteration: 7915/10000, Loss: 0.009964480996131897\n",
      "Iteration: 7916/10000, Loss: 0.01447782851755619\n",
      "Iteration: 7917/10000, Loss: 0.015286468900740147\n",
      "Iteration: 7918/10000, Loss: 0.007727506570518017\n",
      "Iteration: 7919/10000, Loss: 0.0077377003617584705\n",
      "Iteration: 7920/10000, Loss: 0.010577723383903503\n",
      "Iteration: 7921/10000, Loss: 0.010249183513224125\n",
      "Iteration: 7922/10000, Loss: 0.008677328005433083\n",
      "Iteration: 7923/10000, Loss: 0.010205768048763275\n",
      "Iteration: 7924/10000, Loss: 0.010254358872771263\n",
      "Iteration: 7925/10000, Loss: 0.008861181326210499\n",
      "Iteration: 7926/10000, Loss: 0.014310810714960098\n",
      "Iteration: 7927/10000, Loss: 0.011039718054234982\n",
      "Iteration: 7928/10000, Loss: 0.011337162926793098\n",
      "Iteration: 7929/10000, Loss: 0.010085869580507278\n",
      "Iteration: 7930/10000, Loss: 0.008780357427895069\n",
      "Iteration: 7931/10000, Loss: 0.007215283811092377\n",
      "Iteration: 7932/10000, Loss: 0.012674340046942234\n",
      "Iteration: 7933/10000, Loss: 0.008790487423539162\n",
      "Iteration: 7934/10000, Loss: 0.009763606823980808\n",
      "Iteration: 7935/10000, Loss: 0.008108082227408886\n",
      "Iteration: 7936/10000, Loss: 0.01519585307687521\n",
      "Iteration: 7937/10000, Loss: 0.004755687899887562\n",
      "Iteration: 7938/10000, Loss: 0.01295390259474516\n",
      "Iteration: 7939/10000, Loss: 0.0073461574502289295\n",
      "Iteration: 7940/10000, Loss: 0.010585369542241096\n",
      "Iteration: 7941/10000, Loss: 0.010841602459549904\n",
      "Iteration: 7942/10000, Loss: 0.01174304448068142\n",
      "Iteration: 7943/10000, Loss: 0.010944798588752747\n",
      "Iteration: 7944/10000, Loss: 0.00898832082748413\n",
      "Iteration: 7945/10000, Loss: 0.020873209461569786\n",
      "Iteration: 7946/10000, Loss: 0.007907393388450146\n",
      "Iteration: 7947/10000, Loss: 0.009574443101882935\n",
      "Iteration: 7948/10000, Loss: 0.008385119959712029\n",
      "Iteration: 7949/10000, Loss: 0.0120700653642416\n",
      "Iteration: 7950/10000, Loss: 0.015184786170721054\n",
      "Iteration: 7951/10000, Loss: 0.0061569297686219215\n",
      "Iteration: 7952/10000, Loss: 0.012530467472970486\n",
      "Iteration: 7953/10000, Loss: 0.016884300857782364\n",
      "Iteration: 7954/10000, Loss: 0.013789402320981026\n",
      "Iteration: 7955/10000, Loss: 0.007673400919884443\n",
      "Iteration: 7956/10000, Loss: 0.012542184442281723\n",
      "Iteration: 7957/10000, Loss: 0.010472433641552925\n",
      "Iteration: 7958/10000, Loss: 0.010460052639245987\n",
      "Iteration: 7959/10000, Loss: 0.013665498234331608\n",
      "Iteration: 7960/10000, Loss: 0.01201009750366211\n",
      "Iteration: 7961/10000, Loss: 0.009153096936643124\n",
      "Iteration: 7962/10000, Loss: 0.007312281988561153\n",
      "Iteration: 7963/10000, Loss: 0.011711458675563335\n",
      "Iteration: 7964/10000, Loss: 0.013608666136860847\n",
      "Iteration: 7965/10000, Loss: 0.008295033127069473\n",
      "Iteration: 7966/10000, Loss: 0.010288377292454243\n",
      "Iteration: 7967/10000, Loss: 0.015109888277947903\n",
      "Iteration: 7968/10000, Loss: 0.014283972792327404\n",
      "Iteration: 7969/10000, Loss: 0.008011897094547749\n",
      "Iteration: 7970/10000, Loss: 0.013349759392440319\n",
      "Iteration: 7971/10000, Loss: 0.010900281369686127\n",
      "Iteration: 7972/10000, Loss: 0.01026296429336071\n",
      "Iteration: 7973/10000, Loss: 0.011267617344856262\n",
      "Iteration: 7974/10000, Loss: 0.008703785017132759\n",
      "Iteration: 7975/10000, Loss: 0.010607210919260979\n",
      "Iteration: 7976/10000, Loss: 0.006149590946733952\n",
      "Iteration: 7977/10000, Loss: 0.012698068283498287\n",
      "Iteration: 7978/10000, Loss: 0.01033883634954691\n",
      "Iteration: 7979/10000, Loss: 0.013069219887256622\n",
      "Iteration: 7980/10000, Loss: 0.014616710133850574\n",
      "Iteration: 7981/10000, Loss: 0.012783478014171124\n",
      "Iteration: 7982/10000, Loss: 0.01166325993835926\n",
      "Iteration: 7983/10000, Loss: 0.01160316914319992\n",
      "Iteration: 7984/10000, Loss: 0.012920651584863663\n",
      "Iteration: 7985/10000, Loss: 0.010612118989229202\n",
      "Iteration: 7986/10000, Loss: 0.008982417173683643\n",
      "Iteration: 7987/10000, Loss: 0.00999174453318119\n",
      "Iteration: 7988/10000, Loss: 0.010979562997817993\n",
      "Iteration: 7989/10000, Loss: 0.00618516281247139\n",
      "Iteration: 7990/10000, Loss: 0.015476866625249386\n",
      "Iteration: 7991/10000, Loss: 0.007311671506613493\n",
      "Iteration: 7992/10000, Loss: 0.008587166666984558\n",
      "Iteration: 7993/10000, Loss: 0.004584621172398329\n",
      "Iteration: 7994/10000, Loss: 0.008870909921824932\n",
      "Iteration: 7995/10000, Loss: 0.01322443038225174\n",
      "Iteration: 7996/10000, Loss: 0.012916600331664085\n",
      "Iteration: 7997/10000, Loss: 0.006938588339835405\n",
      "Iteration: 7998/10000, Loss: 0.010563947260379791\n",
      "Iteration: 7999/10000, Loss: 0.008799846284091473\n",
      "Iteration: 8000/10000, Loss: 0.011499548330903053\n",
      "Average test loss:  0.0032\n",
      "Iteration: 8001/10000, Loss: 0.010228317230939865\n",
      "Iteration: 8002/10000, Loss: 0.007917235605418682\n",
      "Iteration: 8003/10000, Loss: 0.006999209523200989\n",
      "Iteration: 8004/10000, Loss: 0.014089088886976242\n",
      "Iteration: 8005/10000, Loss: 0.01130262017250061\n",
      "Iteration: 8006/10000, Loss: 0.00853799469769001\n",
      "Iteration: 8007/10000, Loss: 0.01378969382494688\n",
      "Iteration: 8008/10000, Loss: 0.011700248345732689\n",
      "Iteration: 8009/10000, Loss: 0.01640055887401104\n",
      "Iteration: 8010/10000, Loss: 0.007833445444703102\n",
      "Iteration: 8011/10000, Loss: 0.010843347758054733\n",
      "Iteration: 8012/10000, Loss: 0.009785226546227932\n",
      "Iteration: 8013/10000, Loss: 0.011303884908556938\n",
      "Iteration: 8014/10000, Loss: 0.00931890681385994\n",
      "Iteration: 8015/10000, Loss: 0.011413521133363247\n",
      "Iteration: 8016/10000, Loss: 0.01588183268904686\n",
      "Iteration: 8017/10000, Loss: 0.012791228480637074\n",
      "Iteration: 8018/10000, Loss: 0.006126655265688896\n",
      "Iteration: 8019/10000, Loss: 0.011419381946325302\n",
      "Iteration: 8020/10000, Loss: 0.007567380089312792\n",
      "Iteration: 8021/10000, Loss: 0.008081603795289993\n",
      "Iteration: 8022/10000, Loss: 0.010731907561421394\n",
      "Iteration: 8023/10000, Loss: 0.012255960144102573\n",
      "Iteration: 8024/10000, Loss: 0.008335539139807224\n",
      "Iteration: 8025/10000, Loss: 0.010119298473000526\n",
      "Iteration: 8026/10000, Loss: 0.006378865335136652\n",
      "Iteration: 8027/10000, Loss: 0.006004583090543747\n",
      "Iteration: 8028/10000, Loss: 0.01287651713937521\n",
      "Iteration: 8029/10000, Loss: 0.01465223915874958\n",
      "Iteration: 8030/10000, Loss: 0.011691700667142868\n",
      "Iteration: 8031/10000, Loss: 0.012343105860054493\n",
      "Iteration: 8032/10000, Loss: 0.014470918104052544\n",
      "Iteration: 8033/10000, Loss: 0.009319349192082882\n",
      "Iteration: 8034/10000, Loss: 0.009361045435070992\n",
      "Iteration: 8035/10000, Loss: 0.011442135088145733\n",
      "Iteration: 8036/10000, Loss: 0.013104207813739777\n",
      "Iteration: 8037/10000, Loss: 0.01006261259317398\n",
      "Iteration: 8038/10000, Loss: 0.014047596603631973\n",
      "Iteration: 8039/10000, Loss: 0.01115234475582838\n",
      "Iteration: 8040/10000, Loss: 0.009238618426024914\n",
      "Iteration: 8041/10000, Loss: 0.012849153950810432\n",
      "Iteration: 8042/10000, Loss: 0.008557386696338654\n",
      "Iteration: 8043/10000, Loss: 0.0074218278750777245\n",
      "Iteration: 8044/10000, Loss: 0.014775621704757214\n",
      "Iteration: 8045/10000, Loss: 0.010785462334752083\n",
      "Iteration: 8046/10000, Loss: 0.008520173840224743\n",
      "Iteration: 8047/10000, Loss: 0.010438412427902222\n",
      "Iteration: 8048/10000, Loss: 0.009318347088992596\n",
      "Iteration: 8049/10000, Loss: 0.011749619618058205\n",
      "Iteration: 8050/10000, Loss: 0.009152567014098167\n",
      "Iteration: 8051/10000, Loss: 0.007242363411933184\n",
      "Iteration: 8052/10000, Loss: 0.010327286086976528\n",
      "Iteration: 8053/10000, Loss: 0.012077594175934792\n",
      "Iteration: 8054/10000, Loss: 0.013031918555498123\n",
      "Iteration: 8055/10000, Loss: 0.008233241736888885\n",
      "Iteration: 8056/10000, Loss: 0.011984643526375294\n",
      "Iteration: 8057/10000, Loss: 0.012182071805000305\n",
      "Iteration: 8058/10000, Loss: 0.009158923290669918\n",
      "Iteration: 8059/10000, Loss: 0.008831050246953964\n",
      "Iteration: 8060/10000, Loss: 0.011734417639672756\n",
      "Iteration: 8061/10000, Loss: 0.00917227566242218\n",
      "Iteration: 8062/10000, Loss: 0.008836216293275356\n",
      "Iteration: 8063/10000, Loss: 0.009833000600337982\n",
      "Iteration: 8064/10000, Loss: 0.012358137406408787\n",
      "Iteration: 8065/10000, Loss: 0.008017552085220814\n",
      "Iteration: 8066/10000, Loss: 0.008099356666207314\n",
      "Iteration: 8067/10000, Loss: 0.013162796385586262\n",
      "Iteration: 8068/10000, Loss: 0.012445833534002304\n",
      "Iteration: 8069/10000, Loss: 0.00894967932254076\n",
      "Iteration: 8070/10000, Loss: 0.01120459008961916\n",
      "Iteration: 8071/10000, Loss: 0.009123372845351696\n",
      "Iteration: 8072/10000, Loss: 0.008460728451609612\n",
      "Iteration: 8073/10000, Loss: 0.01591535657644272\n",
      "Iteration: 8074/10000, Loss: 0.010420961305499077\n",
      "Iteration: 8075/10000, Loss: 0.007887846790254116\n",
      "Iteration: 8076/10000, Loss: 0.007805028930306435\n",
      "Iteration: 8077/10000, Loss: 0.008973604068160057\n",
      "Iteration: 8078/10000, Loss: 0.014544162899255753\n",
      "Iteration: 8079/10000, Loss: 0.013322696089744568\n",
      "Iteration: 8080/10000, Loss: 0.012519133277237415\n",
      "Iteration: 8081/10000, Loss: 0.010009139776229858\n",
      "Iteration: 8082/10000, Loss: 0.008638482540845871\n",
      "Iteration: 8083/10000, Loss: 0.010905112139880657\n",
      "Iteration: 8084/10000, Loss: 0.005921994335949421\n",
      "Iteration: 8085/10000, Loss: 0.009404519572854042\n",
      "Iteration: 8086/10000, Loss: 0.008706294000148773\n",
      "Iteration: 8087/10000, Loss: 0.01059029158204794\n",
      "Iteration: 8088/10000, Loss: 0.011559846810996532\n",
      "Iteration: 8089/10000, Loss: 0.011486565694212914\n",
      "Iteration: 8090/10000, Loss: 0.010511504486203194\n",
      "Iteration: 8091/10000, Loss: 0.004867729265242815\n",
      "Iteration: 8092/10000, Loss: 0.011734806932508945\n",
      "Iteration: 8093/10000, Loss: 0.01052984967827797\n",
      "Iteration: 8094/10000, Loss: 0.00863192230463028\n",
      "Iteration: 8095/10000, Loss: 0.006433756556361914\n",
      "Iteration: 8096/10000, Loss: 0.00918940082192421\n",
      "Iteration: 8097/10000, Loss: 0.012539827264845371\n",
      "Iteration: 8098/10000, Loss: 0.011995661072432995\n",
      "Iteration: 8099/10000, Loss: 0.010565978474915028\n",
      "Iteration: 8100/10000, Loss: 0.012562977150082588\n",
      "Average test loss:  0.0039\n",
      "Iteration: 8101/10000, Loss: 0.01221748348325491\n",
      "Iteration: 8102/10000, Loss: 0.008022855035960674\n",
      "Iteration: 8103/10000, Loss: 0.015351049602031708\n",
      "Iteration: 8104/10000, Loss: 0.011623146012425423\n",
      "Iteration: 8105/10000, Loss: 0.01356099359691143\n",
      "Iteration: 8106/10000, Loss: 0.009459299966692924\n",
      "Iteration: 8107/10000, Loss: 0.011287136003375053\n",
      "Iteration: 8108/10000, Loss: 0.008820655755698681\n",
      "Iteration: 8109/10000, Loss: 0.010756599716842175\n",
      "Iteration: 8110/10000, Loss: 0.01310045551508665\n",
      "Iteration: 8111/10000, Loss: 0.006815369240939617\n",
      "Iteration: 8112/10000, Loss: 0.009207232855260372\n",
      "Iteration: 8113/10000, Loss: 0.010296754539012909\n",
      "Iteration: 8114/10000, Loss: 0.014940153807401657\n",
      "Iteration: 8115/10000, Loss: 0.011229118332266808\n",
      "Iteration: 8116/10000, Loss: 0.0106998011469841\n",
      "Iteration: 8117/10000, Loss: 0.010803730227053165\n",
      "Iteration: 8118/10000, Loss: 0.009450063109397888\n",
      "Iteration: 8119/10000, Loss: 0.014833686873316765\n",
      "Iteration: 8120/10000, Loss: 0.01094898022711277\n",
      "Iteration: 8121/10000, Loss: 0.012349575757980347\n",
      "Iteration: 8122/10000, Loss: 0.009654260240495205\n",
      "Iteration: 8123/10000, Loss: 0.00704254861921072\n",
      "Iteration: 8124/10000, Loss: 0.007924678735435009\n",
      "Iteration: 8125/10000, Loss: 0.009327979758381844\n",
      "Iteration: 8126/10000, Loss: 0.012424527667462826\n",
      "Iteration: 8127/10000, Loss: 0.007615556940436363\n",
      "Iteration: 8128/10000, Loss: 0.0170203298330307\n",
      "Iteration: 8129/10000, Loss: 0.013081020675599575\n",
      "Iteration: 8130/10000, Loss: 0.008255157619714737\n",
      "Iteration: 8131/10000, Loss: 0.006343124900013208\n",
      "Iteration: 8132/10000, Loss: 0.007467059884220362\n",
      "Iteration: 8133/10000, Loss: 0.009887917898595333\n",
      "Iteration: 8134/10000, Loss: 0.01084892451763153\n",
      "Iteration: 8135/10000, Loss: 0.011965210549533367\n",
      "Iteration: 8136/10000, Loss: 0.014915978536009789\n",
      "Iteration: 8137/10000, Loss: 0.012450517155230045\n",
      "Iteration: 8138/10000, Loss: 0.007009824272245169\n",
      "Iteration: 8139/10000, Loss: 0.009309014305472374\n",
      "Iteration: 8140/10000, Loss: 0.008557351306080818\n",
      "Iteration: 8141/10000, Loss: 0.007965058088302612\n",
      "Iteration: 8142/10000, Loss: 0.011505942791700363\n",
      "Iteration: 8143/10000, Loss: 0.006244567222893238\n",
      "Iteration: 8144/10000, Loss: 0.01190865971148014\n",
      "Iteration: 8145/10000, Loss: 0.011462002992630005\n",
      "Iteration: 8146/10000, Loss: 0.007774509489536285\n",
      "Iteration: 8147/10000, Loss: 0.011554836295545101\n",
      "Iteration: 8148/10000, Loss: 0.009610111825168133\n",
      "Iteration: 8149/10000, Loss: 0.010140475817024708\n",
      "Iteration: 8150/10000, Loss: 0.006900768261402845\n",
      "Iteration: 8151/10000, Loss: 0.0097957793623209\n",
      "Iteration: 8152/10000, Loss: 0.01047667395323515\n",
      "Iteration: 8153/10000, Loss: 0.009294899180531502\n",
      "Iteration: 8154/10000, Loss: 0.006892416160553694\n",
      "Iteration: 8155/10000, Loss: 0.007681610528379679\n",
      "Iteration: 8156/10000, Loss: 0.011373503133654594\n",
      "Iteration: 8157/10000, Loss: 0.009433001279830933\n",
      "Iteration: 8158/10000, Loss: 0.008089612238109112\n",
      "Iteration: 8159/10000, Loss: 0.005517235957086086\n",
      "Iteration: 8160/10000, Loss: 0.01155831664800644\n",
      "Iteration: 8161/10000, Loss: 0.010871359147131443\n",
      "Iteration: 8162/10000, Loss: 0.007221207022666931\n",
      "Iteration: 8163/10000, Loss: 0.012168960645794868\n",
      "Iteration: 8164/10000, Loss: 0.008873566053807735\n",
      "Iteration: 8165/10000, Loss: 0.008019755594432354\n",
      "Iteration: 8166/10000, Loss: 0.010787042789161205\n",
      "Iteration: 8167/10000, Loss: 0.008532064966857433\n",
      "Iteration: 8168/10000, Loss: 0.01013907603919506\n",
      "Iteration: 8169/10000, Loss: 0.011112688109278679\n",
      "Iteration: 8170/10000, Loss: 0.012314709834754467\n",
      "Iteration: 8171/10000, Loss: 0.011582976207137108\n",
      "Iteration: 8172/10000, Loss: 0.014312800951302052\n",
      "Iteration: 8173/10000, Loss: 0.009189173579216003\n",
      "Iteration: 8174/10000, Loss: 0.008280063048005104\n",
      "Iteration: 8175/10000, Loss: 0.008120906539261341\n",
      "Iteration: 8176/10000, Loss: 0.009098694659769535\n",
      "Iteration: 8177/10000, Loss: 0.01057349145412445\n",
      "Iteration: 8178/10000, Loss: 0.009079703129827976\n",
      "Iteration: 8179/10000, Loss: 0.011124230921268463\n",
      "Iteration: 8180/10000, Loss: 0.008520878851413727\n",
      "Iteration: 8181/10000, Loss: 0.008768688887357712\n",
      "Iteration: 8182/10000, Loss: 0.011115392670035362\n",
      "Iteration: 8183/10000, Loss: 0.006014598533511162\n",
      "Iteration: 8184/10000, Loss: 0.01073404960334301\n",
      "Iteration: 8185/10000, Loss: 0.009777246043086052\n",
      "Iteration: 8186/10000, Loss: 0.008301139809191227\n",
      "Iteration: 8187/10000, Loss: 0.005986868403851986\n",
      "Iteration: 8188/10000, Loss: 0.014777681790292263\n",
      "Iteration: 8189/10000, Loss: 0.006860961206257343\n",
      "Iteration: 8190/10000, Loss: 0.006819489877671003\n",
      "Iteration: 8191/10000, Loss: 0.009225582703948021\n",
      "Iteration: 8192/10000, Loss: 0.01187778078019619\n",
      "Iteration: 8193/10000, Loss: 0.011359996162354946\n",
      "Iteration: 8194/10000, Loss: 0.005895376671105623\n",
      "Iteration: 8195/10000, Loss: 0.010333900339901447\n",
      "Iteration: 8196/10000, Loss: 0.013950697146356106\n",
      "Iteration: 8197/10000, Loss: 0.013008049689233303\n",
      "Iteration: 8198/10000, Loss: 0.009755292907357216\n",
      "Iteration: 8199/10000, Loss: 0.006540043279528618\n",
      "Iteration: 8200/10000, Loss: 0.012556253932416439\n",
      "Average test loss:  0.0024\n",
      "Iteration: 8201/10000, Loss: 0.008142226375639439\n",
      "Iteration: 8202/10000, Loss: 0.012086381204426289\n",
      "Iteration: 8203/10000, Loss: 0.01104083564132452\n",
      "Iteration: 8204/10000, Loss: 0.007662953808903694\n",
      "Iteration: 8205/10000, Loss: 0.012667194940149784\n",
      "Iteration: 8206/10000, Loss: 0.008712930604815483\n",
      "Iteration: 8207/10000, Loss: 0.0071009485982358456\n",
      "Iteration: 8208/10000, Loss: 0.014155290089547634\n",
      "Iteration: 8209/10000, Loss: 0.011071642860770226\n",
      "Iteration: 8210/10000, Loss: 0.004928160924464464\n",
      "Iteration: 8211/10000, Loss: 0.0068971854634583\n",
      "Iteration: 8212/10000, Loss: 0.0064646038226783276\n",
      "Iteration: 8213/10000, Loss: 0.014112112112343311\n",
      "Iteration: 8214/10000, Loss: 0.008635326288640499\n",
      "Iteration: 8215/10000, Loss: 0.009134544059634209\n",
      "Iteration: 8216/10000, Loss: 0.0125808110460639\n",
      "Iteration: 8217/10000, Loss: 0.009848891757428646\n",
      "Iteration: 8218/10000, Loss: 0.011049633845686913\n",
      "Iteration: 8219/10000, Loss: 0.011329839937388897\n",
      "Iteration: 8220/10000, Loss: 0.011860916391015053\n",
      "Iteration: 8221/10000, Loss: 0.006798960268497467\n",
      "Iteration: 8222/10000, Loss: 0.00793459638953209\n",
      "Iteration: 8223/10000, Loss: 0.01072878297418356\n",
      "Iteration: 8224/10000, Loss: 0.013119448907673359\n",
      "Iteration: 8225/10000, Loss: 0.012688282877206802\n",
      "Iteration: 8226/10000, Loss: 0.009105421602725983\n",
      "Iteration: 8227/10000, Loss: 0.0080103212967515\n",
      "Iteration: 8228/10000, Loss: 0.010646766982972622\n",
      "Iteration: 8229/10000, Loss: 0.009941021911799908\n",
      "Iteration: 8230/10000, Loss: 0.007812083698809147\n",
      "Iteration: 8231/10000, Loss: 0.006589884404093027\n",
      "Iteration: 8232/10000, Loss: 0.01081649400293827\n",
      "Iteration: 8233/10000, Loss: 0.007102800067514181\n",
      "Iteration: 8234/10000, Loss: 0.013225107453763485\n",
      "Iteration: 8235/10000, Loss: 0.007928089238703251\n",
      "Iteration: 8236/10000, Loss: 0.013202877715229988\n",
      "Iteration: 8237/10000, Loss: 0.010456048883497715\n",
      "Iteration: 8238/10000, Loss: 0.011127796955406666\n",
      "Iteration: 8239/10000, Loss: 0.010666929185390472\n",
      "Iteration: 8240/10000, Loss: 0.009312947280704975\n",
      "Iteration: 8241/10000, Loss: 0.011688102036714554\n",
      "Iteration: 8242/10000, Loss: 0.012733780778944492\n",
      "Iteration: 8243/10000, Loss: 0.013140168972313404\n",
      "Iteration: 8244/10000, Loss: 0.01070593111217022\n",
      "Iteration: 8245/10000, Loss: 0.011516531929373741\n",
      "Iteration: 8246/10000, Loss: 0.009830226190388203\n",
      "Iteration: 8247/10000, Loss: 0.013593212701380253\n",
      "Iteration: 8248/10000, Loss: 0.013432763516902924\n",
      "Iteration: 8249/10000, Loss: 0.016708023846149445\n",
      "Iteration: 8250/10000, Loss: 0.010845323093235493\n",
      "Iteration: 8251/10000, Loss: 0.013072761707007885\n",
      "Iteration: 8252/10000, Loss: 0.00559476763010025\n",
      "Iteration: 8253/10000, Loss: 0.016136612743139267\n",
      "Iteration: 8254/10000, Loss: 0.011345050297677517\n",
      "Iteration: 8255/10000, Loss: 0.0069738649763166904\n",
      "Iteration: 8256/10000, Loss: 0.007718201726675034\n",
      "Iteration: 8257/10000, Loss: 0.009174276143312454\n",
      "Iteration: 8258/10000, Loss: 0.013042228296399117\n",
      "Iteration: 8259/10000, Loss: 0.005836823023855686\n",
      "Iteration: 8260/10000, Loss: 0.0068770661018788815\n",
      "Iteration: 8261/10000, Loss: 0.010985861532390118\n",
      "Iteration: 8262/10000, Loss: 0.013109274208545685\n",
      "Iteration: 8263/10000, Loss: 0.0055677685886621475\n",
      "Iteration: 8264/10000, Loss: 0.00974238570779562\n",
      "Iteration: 8265/10000, Loss: 0.008694886229932308\n",
      "Iteration: 8266/10000, Loss: 0.014170533046126366\n",
      "Iteration: 8267/10000, Loss: 0.011813458055257797\n",
      "Iteration: 8268/10000, Loss: 0.011977463029325008\n",
      "Iteration: 8269/10000, Loss: 0.009856855496764183\n",
      "Iteration: 8270/10000, Loss: 0.011088234372437\n",
      "Iteration: 8271/10000, Loss: 0.01067813765257597\n",
      "Iteration: 8272/10000, Loss: 0.005987765733152628\n",
      "Iteration: 8273/10000, Loss: 0.01360025443136692\n",
      "Iteration: 8274/10000, Loss: 0.008210675790905952\n",
      "Iteration: 8275/10000, Loss: 0.008445164188742638\n",
      "Iteration: 8276/10000, Loss: 0.011678778566420078\n",
      "Iteration: 8277/10000, Loss: 0.009525726549327374\n",
      "Iteration: 8278/10000, Loss: 0.005685076583176851\n",
      "Iteration: 8279/10000, Loss: 0.010429652407765388\n",
      "Iteration: 8280/10000, Loss: 0.012906273826956749\n",
      "Iteration: 8281/10000, Loss: 0.010859880596399307\n",
      "Iteration: 8282/10000, Loss: 0.006242169998586178\n",
      "Iteration: 8283/10000, Loss: 0.009774944745004177\n",
      "Iteration: 8284/10000, Loss: 0.005978862755000591\n",
      "Iteration: 8285/10000, Loss: 0.008742661215364933\n",
      "Iteration: 8286/10000, Loss: 0.00936531089246273\n",
      "Iteration: 8287/10000, Loss: 0.011315451003611088\n",
      "Iteration: 8288/10000, Loss: 0.006697834003716707\n",
      "Iteration: 8289/10000, Loss: 0.007488288450986147\n",
      "Iteration: 8290/10000, Loss: 0.01135584618896246\n",
      "Iteration: 8291/10000, Loss: 0.012651665136218071\n",
      "Iteration: 8292/10000, Loss: 0.009518962353467941\n",
      "Iteration: 8293/10000, Loss: 0.00904618576169014\n",
      "Iteration: 8294/10000, Loss: 0.010328237898647785\n",
      "Iteration: 8295/10000, Loss: 0.01273655891418457\n",
      "Iteration: 8296/10000, Loss: 0.011504678055644035\n",
      "Iteration: 8297/10000, Loss: 0.008880105800926685\n",
      "Iteration: 8298/10000, Loss: 0.011577406898140907\n",
      "Iteration: 8299/10000, Loss: 0.007223428227007389\n",
      "Iteration: 8300/10000, Loss: 0.0069740829057991505\n",
      "Average test loss:  0.0021\n",
      "Iteration: 8301/10000, Loss: 0.009936422109603882\n",
      "Iteration: 8302/10000, Loss: 0.007044892758131027\n",
      "Iteration: 8303/10000, Loss: 0.006548012141138315\n",
      "Iteration: 8304/10000, Loss: 0.012747175060212612\n",
      "Iteration: 8305/10000, Loss: 0.006252017337828875\n",
      "Iteration: 8306/10000, Loss: 0.010435263626277447\n",
      "Iteration: 8307/10000, Loss: 0.005110154859721661\n",
      "Iteration: 8308/10000, Loss: 0.012873374857008457\n",
      "Iteration: 8309/10000, Loss: 0.006669777911156416\n",
      "Iteration: 8310/10000, Loss: 0.01311278622597456\n",
      "Iteration: 8311/10000, Loss: 0.006072946824133396\n",
      "Iteration: 8312/10000, Loss: 0.01036421861499548\n",
      "Iteration: 8313/10000, Loss: 0.011573752388358116\n",
      "Iteration: 8314/10000, Loss: 0.007341241929680109\n",
      "Iteration: 8315/10000, Loss: 0.006209811195731163\n",
      "Iteration: 8316/10000, Loss: 0.011317839846014977\n",
      "Iteration: 8317/10000, Loss: 0.011815179139375687\n",
      "Iteration: 8318/10000, Loss: 0.007672194391489029\n",
      "Iteration: 8319/10000, Loss: 0.006822098512202501\n",
      "Iteration: 8320/10000, Loss: 0.007801994681358337\n",
      "Iteration: 8321/10000, Loss: 0.01282766554504633\n",
      "Iteration: 8322/10000, Loss: 0.007229158189147711\n",
      "Iteration: 8323/10000, Loss: 0.00883591640740633\n",
      "Iteration: 8324/10000, Loss: 0.01283187698572874\n",
      "Iteration: 8325/10000, Loss: 0.006185832899063826\n",
      "Iteration: 8326/10000, Loss: 0.010124736465513706\n",
      "Iteration: 8327/10000, Loss: 0.006962706334888935\n",
      "Iteration: 8328/10000, Loss: 0.012234373949468136\n",
      "Iteration: 8329/10000, Loss: 0.012857390567660332\n",
      "Iteration: 8330/10000, Loss: 0.015468284487724304\n",
      "Iteration: 8331/10000, Loss: 0.008125526830554008\n",
      "Iteration: 8332/10000, Loss: 0.010444256477057934\n",
      "Iteration: 8333/10000, Loss: 0.006889770273119211\n",
      "Iteration: 8334/10000, Loss: 0.008993403986096382\n",
      "Iteration: 8335/10000, Loss: 0.011547952890396118\n",
      "Iteration: 8336/10000, Loss: 0.00841557141393423\n",
      "Iteration: 8337/10000, Loss: 0.009068312123417854\n",
      "Iteration: 8338/10000, Loss: 0.007116128224879503\n",
      "Iteration: 8339/10000, Loss: 0.008418681100010872\n",
      "Iteration: 8340/10000, Loss: 0.0063554043881595135\n",
      "Iteration: 8341/10000, Loss: 0.008112959563732147\n",
      "Iteration: 8342/10000, Loss: 0.009401383809745312\n",
      "Iteration: 8343/10000, Loss: 0.00759492302313447\n",
      "Iteration: 8344/10000, Loss: 0.008889059536159039\n",
      "Iteration: 8345/10000, Loss: 0.012047385796904564\n",
      "Iteration: 8346/10000, Loss: 0.009729066863656044\n",
      "Iteration: 8347/10000, Loss: 0.0060770828276872635\n",
      "Iteration: 8348/10000, Loss: 0.008481938391923904\n",
      "Iteration: 8349/10000, Loss: 0.013034282252192497\n",
      "Iteration: 8350/10000, Loss: 0.008206653408706188\n",
      "Iteration: 8351/10000, Loss: 0.01144659984856844\n",
      "Iteration: 8352/10000, Loss: 0.009495191276073456\n",
      "Iteration: 8353/10000, Loss: 0.008201285265386105\n",
      "Iteration: 8354/10000, Loss: 0.010574053972959518\n",
      "Iteration: 8355/10000, Loss: 0.004431180655956268\n",
      "Iteration: 8356/10000, Loss: 0.01106432918459177\n",
      "Iteration: 8357/10000, Loss: 0.005609281826764345\n",
      "Iteration: 8358/10000, Loss: 0.004812772385776043\n",
      "Iteration: 8359/10000, Loss: 0.008897306397557259\n",
      "Iteration: 8360/10000, Loss: 0.008121063001453876\n",
      "Iteration: 8361/10000, Loss: 0.009571005590260029\n",
      "Iteration: 8362/10000, Loss: 0.013318824581801891\n",
      "Iteration: 8363/10000, Loss: 0.010494492948055267\n",
      "Iteration: 8364/10000, Loss: 0.011191030964255333\n",
      "Iteration: 8365/10000, Loss: 0.007368812337517738\n",
      "Iteration: 8366/10000, Loss: 0.007035099435597658\n",
      "Iteration: 8367/10000, Loss: 0.012607638724148273\n",
      "Iteration: 8368/10000, Loss: 0.011753491126000881\n",
      "Iteration: 8369/10000, Loss: 0.00878097303211689\n",
      "Iteration: 8370/10000, Loss: 0.009562725201249123\n",
      "Iteration: 8371/10000, Loss: 0.0037000325974076986\n",
      "Iteration: 8372/10000, Loss: 0.009677593596279621\n",
      "Iteration: 8373/10000, Loss: 0.007550310343503952\n",
      "Iteration: 8374/10000, Loss: 0.00841444917023182\n",
      "Iteration: 8375/10000, Loss: 0.01014524232596159\n",
      "Iteration: 8376/10000, Loss: 0.015779953449964523\n",
      "Iteration: 8377/10000, Loss: 0.009844078682363033\n",
      "Iteration: 8378/10000, Loss: 0.009452329017221928\n",
      "Iteration: 8379/10000, Loss: 0.0068033840507268906\n",
      "Iteration: 8380/10000, Loss: 0.010008221492171288\n",
      "Iteration: 8381/10000, Loss: 0.012383692897856236\n",
      "Iteration: 8382/10000, Loss: 0.006353316828608513\n",
      "Iteration: 8383/10000, Loss: 0.009058255702257156\n",
      "Iteration: 8384/10000, Loss: 0.006471342872828245\n",
      "Iteration: 8385/10000, Loss: 0.014884641394019127\n",
      "Iteration: 8386/10000, Loss: 0.013683052733540535\n",
      "Iteration: 8387/10000, Loss: 0.0053854952566325665\n",
      "Iteration: 8388/10000, Loss: 0.007948962971568108\n",
      "Iteration: 8389/10000, Loss: 0.007748714182525873\n",
      "Iteration: 8390/10000, Loss: 0.008615241385996342\n",
      "Iteration: 8391/10000, Loss: 0.010412255302071571\n",
      "Iteration: 8392/10000, Loss: 0.009455329738557339\n",
      "Iteration: 8393/10000, Loss: 0.010105902329087257\n",
      "Iteration: 8394/10000, Loss: 0.0103150000795722\n",
      "Iteration: 8395/10000, Loss: 0.010490382090210915\n",
      "Iteration: 8396/10000, Loss: 0.008616998791694641\n",
      "Iteration: 8397/10000, Loss: 0.012055170722305775\n",
      "Iteration: 8398/10000, Loss: 0.008825904689729214\n",
      "Iteration: 8399/10000, Loss: 0.013356821611523628\n",
      "Iteration: 8400/10000, Loss: 0.0076387920416891575\n",
      "Average test loss:  0.0027\n",
      "Iteration: 8401/10000, Loss: 0.01201364304870367\n",
      "Iteration: 8402/10000, Loss: 0.009687092155218124\n",
      "Iteration: 8403/10000, Loss: 0.007813142612576485\n",
      "Iteration: 8404/10000, Loss: 0.008028963580727577\n",
      "Iteration: 8405/10000, Loss: 0.014284246601164341\n",
      "Iteration: 8406/10000, Loss: 0.007208198308944702\n",
      "Iteration: 8407/10000, Loss: 0.0037539645563811064\n",
      "Iteration: 8408/10000, Loss: 0.008270049467682838\n",
      "Iteration: 8409/10000, Loss: 0.008176270872354507\n",
      "Iteration: 8410/10000, Loss: 0.008535545319318771\n",
      "Iteration: 8411/10000, Loss: 0.011294743046164513\n",
      "Iteration: 8412/10000, Loss: 0.010325373150408268\n",
      "Iteration: 8413/10000, Loss: 0.012815030291676521\n",
      "Iteration: 8414/10000, Loss: 0.006541133858263493\n",
      "Iteration: 8415/10000, Loss: 0.011105057783424854\n",
      "Iteration: 8416/10000, Loss: 0.015264901332557201\n",
      "Iteration: 8417/10000, Loss: 0.007653673645108938\n",
      "Iteration: 8418/10000, Loss: 0.007937569171190262\n",
      "Iteration: 8419/10000, Loss: 0.011194288730621338\n",
      "Iteration: 8420/10000, Loss: 0.005669453181326389\n",
      "Iteration: 8421/10000, Loss: 0.009198016487061977\n",
      "Iteration: 8422/10000, Loss: 0.0073387036100029945\n",
      "Iteration: 8423/10000, Loss: 0.011802640743553638\n",
      "Iteration: 8424/10000, Loss: 0.006751824636012316\n",
      "Iteration: 8425/10000, Loss: 0.013678092509508133\n",
      "Iteration: 8426/10000, Loss: 0.010339710861444473\n",
      "Iteration: 8427/10000, Loss: 0.009747752919793129\n",
      "Iteration: 8428/10000, Loss: 0.012835443951189518\n",
      "Iteration: 8429/10000, Loss: 0.007860744372010231\n",
      "Iteration: 8430/10000, Loss: 0.010981552302837372\n",
      "Iteration: 8431/10000, Loss: 0.007714941632002592\n",
      "Iteration: 8432/10000, Loss: 0.008888574317097664\n",
      "Iteration: 8433/10000, Loss: 0.010094605386257172\n",
      "Iteration: 8434/10000, Loss: 0.00525545421987772\n",
      "Iteration: 8435/10000, Loss: 0.009255045093595982\n",
      "Iteration: 8436/10000, Loss: 0.008947783149778843\n",
      "Iteration: 8437/10000, Loss: 0.016169091686606407\n",
      "Iteration: 8438/10000, Loss: 0.008677983656525612\n",
      "Iteration: 8439/10000, Loss: 0.010230635292828083\n",
      "Iteration: 8440/10000, Loss: 0.010017845779657364\n",
      "Iteration: 8441/10000, Loss: 0.01483512856066227\n",
      "Iteration: 8442/10000, Loss: 0.012604149989783764\n",
      "Iteration: 8443/10000, Loss: 0.008367436937987804\n",
      "Iteration: 8444/10000, Loss: 0.012942461296916008\n",
      "Iteration: 8445/10000, Loss: 0.009900280274450779\n",
      "Iteration: 8446/10000, Loss: 0.012136050499975681\n",
      "Iteration: 8447/10000, Loss: 0.010031421668827534\n",
      "Iteration: 8448/10000, Loss: 0.010840748436748981\n",
      "Iteration: 8449/10000, Loss: 0.009835517965257168\n",
      "Iteration: 8450/10000, Loss: 0.01035904698073864\n",
      "Iteration: 8451/10000, Loss: 0.008701969869434834\n",
      "Iteration: 8452/10000, Loss: 0.009624067693948746\n",
      "Iteration: 8453/10000, Loss: 0.017847971990704536\n",
      "Iteration: 8454/10000, Loss: 0.009960990399122238\n",
      "Iteration: 8455/10000, Loss: 0.014737250283360481\n",
      "Iteration: 8456/10000, Loss: 0.007694136817008257\n",
      "Iteration: 8457/10000, Loss: 0.007993767969310284\n",
      "Iteration: 8458/10000, Loss: 0.0069101122207939625\n",
      "Iteration: 8459/10000, Loss: 0.01398572325706482\n",
      "Iteration: 8460/10000, Loss: 0.018943248316645622\n",
      "Iteration: 8461/10000, Loss: 0.011335963383316994\n",
      "Iteration: 8462/10000, Loss: 0.008239305578172207\n",
      "Iteration: 8463/10000, Loss: 0.012243766337633133\n",
      "Iteration: 8464/10000, Loss: 0.010490242391824722\n",
      "Iteration: 8465/10000, Loss: 0.008834532462060452\n",
      "Iteration: 8466/10000, Loss: 0.009480100125074387\n",
      "Iteration: 8467/10000, Loss: 0.011185795068740845\n",
      "Iteration: 8468/10000, Loss: 0.010682151652872562\n",
      "Iteration: 8469/10000, Loss: 0.011265466921031475\n",
      "Iteration: 8470/10000, Loss: 0.009240166284143925\n",
      "Iteration: 8471/10000, Loss: 0.009747517295181751\n",
      "Iteration: 8472/10000, Loss: 0.010216793045401573\n",
      "Iteration: 8473/10000, Loss: 0.0060003227554261684\n",
      "Iteration: 8474/10000, Loss: 0.009908285923302174\n",
      "Iteration: 8475/10000, Loss: 0.012262771837413311\n",
      "Iteration: 8476/10000, Loss: 0.00996382161974907\n",
      "Iteration: 8477/10000, Loss: 0.007253849413245916\n",
      "Iteration: 8478/10000, Loss: 0.011060168966650963\n",
      "Iteration: 8479/10000, Loss: 0.010120031423866749\n",
      "Iteration: 8480/10000, Loss: 0.006118436809629202\n",
      "Iteration: 8481/10000, Loss: 0.014348290860652924\n",
      "Iteration: 8482/10000, Loss: 0.010195229202508926\n",
      "Iteration: 8483/10000, Loss: 0.012022102251648903\n",
      "Iteration: 8484/10000, Loss: 0.008897983469069004\n",
      "Iteration: 8485/10000, Loss: 0.00682230805978179\n",
      "Iteration: 8486/10000, Loss: 0.009023968130350113\n",
      "Iteration: 8487/10000, Loss: 0.013006281107664108\n",
      "Iteration: 8488/10000, Loss: 0.008906380273401737\n",
      "Iteration: 8489/10000, Loss: 0.006283520720899105\n",
      "Iteration: 8490/10000, Loss: 0.013705221936106682\n",
      "Iteration: 8491/10000, Loss: 0.016150422394275665\n",
      "Iteration: 8492/10000, Loss: 0.008078761398792267\n",
      "Iteration: 8493/10000, Loss: 0.00859545823186636\n",
      "Iteration: 8494/10000, Loss: 0.010717901401221752\n",
      "Iteration: 8495/10000, Loss: 0.012011527083814144\n",
      "Iteration: 8496/10000, Loss: 0.010688231326639652\n",
      "Iteration: 8497/10000, Loss: 0.007961110211908817\n",
      "Iteration: 8498/10000, Loss: 0.010538063012063503\n",
      "Iteration: 8499/10000, Loss: 0.011734074912965298\n",
      "Iteration: 8500/10000, Loss: 0.005619242787361145\n",
      "Average test loss:  0.0027\n",
      "Iteration: 8501/10000, Loss: 0.011108755134046078\n",
      "Iteration: 8502/10000, Loss: 0.007592123933136463\n",
      "Iteration: 8503/10000, Loss: 0.008528032340109348\n",
      "Iteration: 8504/10000, Loss: 0.011714373715221882\n",
      "Iteration: 8505/10000, Loss: 0.010749689303338528\n",
      "Iteration: 8506/10000, Loss: 0.01084437407553196\n",
      "Iteration: 8507/10000, Loss: 0.008328454568982124\n",
      "Iteration: 8508/10000, Loss: 0.009324843063950539\n",
      "Iteration: 8509/10000, Loss: 0.009496001526713371\n",
      "Iteration: 8510/10000, Loss: 0.009654991328716278\n",
      "Iteration: 8511/10000, Loss: 0.00831841304898262\n",
      "Iteration: 8512/10000, Loss: 0.008773555047810078\n",
      "Iteration: 8513/10000, Loss: 0.009436085820198059\n",
      "Iteration: 8514/10000, Loss: 0.008014054968953133\n",
      "Iteration: 8515/10000, Loss: 0.008193135261535645\n",
      "Iteration: 8516/10000, Loss: 0.006556226871907711\n",
      "Iteration: 8517/10000, Loss: 0.008285724557936192\n",
      "Iteration: 8518/10000, Loss: 0.007710748352110386\n",
      "Iteration: 8519/10000, Loss: 0.013035119511187077\n",
      "Iteration: 8520/10000, Loss: 0.010913632810115814\n",
      "Iteration: 8521/10000, Loss: 0.008530065417289734\n",
      "Iteration: 8522/10000, Loss: 0.009610281325876713\n",
      "Iteration: 8523/10000, Loss: 0.012012644670903683\n",
      "Iteration: 8524/10000, Loss: 0.01002737507224083\n",
      "Iteration: 8525/10000, Loss: 0.01176263764500618\n",
      "Iteration: 8526/10000, Loss: 0.014366816729307175\n",
      "Iteration: 8527/10000, Loss: 0.006818005815148354\n",
      "Iteration: 8528/10000, Loss: 0.009532539173960686\n",
      "Iteration: 8529/10000, Loss: 0.009903063997626305\n",
      "Iteration: 8530/10000, Loss: 0.011450806632637978\n",
      "Iteration: 8531/10000, Loss: 0.009225200861692429\n",
      "Iteration: 8532/10000, Loss: 0.012427171692252159\n",
      "Iteration: 8533/10000, Loss: 0.010234891436994076\n",
      "Iteration: 8534/10000, Loss: 0.009486461989581585\n",
      "Iteration: 8535/10000, Loss: 0.013394249603152275\n",
      "Iteration: 8536/10000, Loss: 0.011142129078507423\n",
      "Iteration: 8537/10000, Loss: 0.009080203250050545\n",
      "Iteration: 8538/10000, Loss: 0.0061613102443516254\n",
      "Iteration: 8539/10000, Loss: 0.008519511669874191\n",
      "Iteration: 8540/10000, Loss: 0.015075837261974812\n",
      "Iteration: 8541/10000, Loss: 0.01062318030744791\n",
      "Iteration: 8542/10000, Loss: 0.01193978637456894\n",
      "Iteration: 8543/10000, Loss: 0.010029501281678677\n",
      "Iteration: 8544/10000, Loss: 0.011382739059627056\n",
      "Iteration: 8545/10000, Loss: 0.010455884039402008\n",
      "Iteration: 8546/10000, Loss: 0.010357586666941643\n",
      "Iteration: 8547/10000, Loss: 0.00631756940856576\n",
      "Iteration: 8548/10000, Loss: 0.010294634848833084\n",
      "Iteration: 8549/10000, Loss: 0.00819270871579647\n",
      "Iteration: 8550/10000, Loss: 0.014667264185845852\n",
      "Iteration: 8551/10000, Loss: 0.005119511857628822\n",
      "Iteration: 8552/10000, Loss: 0.009567773900926113\n",
      "Iteration: 8553/10000, Loss: 0.006252814084291458\n",
      "Iteration: 8554/10000, Loss: 0.014365587383508682\n",
      "Iteration: 8555/10000, Loss: 0.007267306558787823\n",
      "Iteration: 8556/10000, Loss: 0.01085332129150629\n",
      "Iteration: 8557/10000, Loss: 0.008596920408308506\n",
      "Iteration: 8558/10000, Loss: 0.009430055506527424\n",
      "Iteration: 8559/10000, Loss: 0.010422158055007458\n",
      "Iteration: 8560/10000, Loss: 0.008681234903633595\n",
      "Iteration: 8561/10000, Loss: 0.010258962400257587\n",
      "Iteration: 8562/10000, Loss: 0.008397815749049187\n",
      "Iteration: 8563/10000, Loss: 0.010781457647681236\n",
      "Iteration: 8564/10000, Loss: 0.015657082200050354\n",
      "Iteration: 8565/10000, Loss: 0.006771310698240995\n",
      "Iteration: 8566/10000, Loss: 0.008723810315132141\n",
      "Iteration: 8567/10000, Loss: 0.01190121192485094\n",
      "Iteration: 8568/10000, Loss: 0.010028872638940811\n",
      "Iteration: 8569/10000, Loss: 0.011807198636233807\n",
      "Iteration: 8570/10000, Loss: 0.008243213407695293\n",
      "Iteration: 8571/10000, Loss: 0.010450152680277824\n",
      "Iteration: 8572/10000, Loss: 0.010552619583904743\n",
      "Iteration: 8573/10000, Loss: 0.01095759216696024\n",
      "Iteration: 8574/10000, Loss: 0.008897802792489529\n",
      "Iteration: 8575/10000, Loss: 0.011765831150114536\n",
      "Iteration: 8576/10000, Loss: 0.009070913307368755\n",
      "Iteration: 8577/10000, Loss: 0.008140451274812222\n",
      "Iteration: 8578/10000, Loss: 0.007457213941961527\n",
      "Iteration: 8579/10000, Loss: 0.009445787407457829\n",
      "Iteration: 8580/10000, Loss: 0.007382683455944061\n",
      "Iteration: 8581/10000, Loss: 0.006354966666549444\n",
      "Iteration: 8582/10000, Loss: 0.009319111704826355\n",
      "Iteration: 8583/10000, Loss: 0.009031428024172783\n",
      "Iteration: 8584/10000, Loss: 0.007943347096443176\n",
      "Iteration: 8585/10000, Loss: 0.00870166439563036\n",
      "Iteration: 8586/10000, Loss: 0.011471671983599663\n",
      "Iteration: 8587/10000, Loss: 0.008065665140748024\n",
      "Iteration: 8588/10000, Loss: 0.009082531556487083\n",
      "Iteration: 8589/10000, Loss: 0.010011959820985794\n",
      "Iteration: 8590/10000, Loss: 0.00782365258783102\n",
      "Iteration: 8591/10000, Loss: 0.008493879809975624\n",
      "Iteration: 8592/10000, Loss: 0.008515742607414722\n",
      "Iteration: 8593/10000, Loss: 0.009039811789989471\n",
      "Iteration: 8594/10000, Loss: 0.007674402557313442\n",
      "Iteration: 8595/10000, Loss: 0.009599130600690842\n",
      "Iteration: 8596/10000, Loss: 0.010388652794063091\n",
      "Iteration: 8597/10000, Loss: 0.007380222901701927\n",
      "Iteration: 8598/10000, Loss: 0.006015649531036615\n",
      "Iteration: 8599/10000, Loss: 0.009049876593053341\n",
      "Iteration: 8600/10000, Loss: 0.006983887404203415\n",
      "Average test loss:  0.0021\n",
      "Iteration: 8601/10000, Loss: 0.007974939420819283\n",
      "Iteration: 8602/10000, Loss: 0.010652986355125904\n",
      "Iteration: 8603/10000, Loss: 0.010563976131379604\n",
      "Iteration: 8604/10000, Loss: 0.00836368277668953\n",
      "Iteration: 8605/10000, Loss: 0.012935435399413109\n",
      "Iteration: 8606/10000, Loss: 0.0069755068980157375\n",
      "Iteration: 8607/10000, Loss: 0.007110163569450378\n",
      "Iteration: 8608/10000, Loss: 0.00531647726893425\n",
      "Iteration: 8609/10000, Loss: 0.010972789488732815\n",
      "Iteration: 8610/10000, Loss: 0.008423998020589352\n",
      "Iteration: 8611/10000, Loss: 0.00537676177918911\n",
      "Iteration: 8612/10000, Loss: 0.009942429140210152\n",
      "Iteration: 8613/10000, Loss: 0.011471818201243877\n",
      "Iteration: 8614/10000, Loss: 0.010071410797536373\n",
      "Iteration: 8615/10000, Loss: 0.010286394506692886\n",
      "Iteration: 8616/10000, Loss: 0.009106152690947056\n",
      "Iteration: 8617/10000, Loss: 0.011038451455533504\n",
      "Iteration: 8618/10000, Loss: 0.006046149414032698\n",
      "Iteration: 8619/10000, Loss: 0.00930431392043829\n",
      "Iteration: 8620/10000, Loss: 0.009081226773560047\n",
      "Iteration: 8621/10000, Loss: 0.008967616595327854\n",
      "Iteration: 8622/10000, Loss: 0.011018667370080948\n",
      "Iteration: 8623/10000, Loss: 0.004598385654389858\n",
      "Iteration: 8624/10000, Loss: 0.010146046057343483\n",
      "Iteration: 8625/10000, Loss: 0.006784306839108467\n",
      "Iteration: 8626/10000, Loss: 0.005995732732117176\n",
      "Iteration: 8627/10000, Loss: 0.011087779887020588\n",
      "Iteration: 8628/10000, Loss: 0.01046337466686964\n",
      "Iteration: 8629/10000, Loss: 0.011272198520600796\n",
      "Iteration: 8630/10000, Loss: 0.008343799039721489\n",
      "Iteration: 8631/10000, Loss: 0.014691773802042007\n",
      "Iteration: 8632/10000, Loss: 0.007414355408400297\n",
      "Iteration: 8633/10000, Loss: 0.010048778727650642\n",
      "Iteration: 8634/10000, Loss: 0.009198511950671673\n",
      "Iteration: 8635/10000, Loss: 0.006308136973530054\n",
      "Iteration: 8636/10000, Loss: 0.009703688323497772\n",
      "Iteration: 8637/10000, Loss: 0.008581770583987236\n",
      "Iteration: 8638/10000, Loss: 0.01018415205180645\n",
      "Iteration: 8639/10000, Loss: 0.00804138369858265\n",
      "Iteration: 8640/10000, Loss: 0.015999125316739082\n",
      "Iteration: 8641/10000, Loss: 0.005563609302043915\n",
      "Iteration: 8642/10000, Loss: 0.01077867578715086\n",
      "Iteration: 8643/10000, Loss: 0.008524397388100624\n",
      "Iteration: 8644/10000, Loss: 0.00938478484749794\n",
      "Iteration: 8645/10000, Loss: 0.007045696023851633\n",
      "Iteration: 8646/10000, Loss: 0.007830782793462276\n",
      "Iteration: 8647/10000, Loss: 0.011395338922739029\n",
      "Iteration: 8648/10000, Loss: 0.006715231575071812\n",
      "Iteration: 8649/10000, Loss: 0.008489223197102547\n",
      "Iteration: 8650/10000, Loss: 0.007866855710744858\n",
      "Iteration: 8651/10000, Loss: 0.013662328943610191\n",
      "Iteration: 8652/10000, Loss: 0.01255347952246666\n",
      "Iteration: 8653/10000, Loss: 0.01348533108830452\n",
      "Iteration: 8654/10000, Loss: 0.009165708906948566\n",
      "Iteration: 8655/10000, Loss: 0.009835224598646164\n",
      "Iteration: 8656/10000, Loss: 0.00776860024780035\n",
      "Iteration: 8657/10000, Loss: 0.01085454598069191\n",
      "Iteration: 8658/10000, Loss: 0.009262679144740105\n",
      "Iteration: 8659/10000, Loss: 0.01133306510746479\n",
      "Iteration: 8660/10000, Loss: 0.008440118283033371\n",
      "Iteration: 8661/10000, Loss: 0.017020707949995995\n",
      "Iteration: 8662/10000, Loss: 0.009645546786487103\n",
      "Iteration: 8663/10000, Loss: 0.007680120412260294\n",
      "Iteration: 8664/10000, Loss: 0.010585591197013855\n",
      "Iteration: 8665/10000, Loss: 0.006737125106155872\n",
      "Iteration: 8666/10000, Loss: 0.010351297445595264\n",
      "Iteration: 8667/10000, Loss: 0.01146096270531416\n",
      "Iteration: 8668/10000, Loss: 0.008266082964837551\n",
      "Iteration: 8669/10000, Loss: 0.012201406992971897\n",
      "Iteration: 8670/10000, Loss: 0.004656648728996515\n",
      "Iteration: 8671/10000, Loss: 0.013766475021839142\n",
      "Iteration: 8672/10000, Loss: 0.0076692053116858006\n",
      "Iteration: 8673/10000, Loss: 0.006744769401848316\n",
      "Iteration: 8674/10000, Loss: 0.008661064319312572\n",
      "Iteration: 8675/10000, Loss: 0.00937231257557869\n",
      "Iteration: 8676/10000, Loss: 0.006238084752112627\n",
      "Iteration: 8677/10000, Loss: 0.007203694432973862\n",
      "Iteration: 8678/10000, Loss: 0.011396382004022598\n",
      "Iteration: 8679/10000, Loss: 0.010629953816533089\n",
      "Iteration: 8680/10000, Loss: 0.006058953236788511\n",
      "Iteration: 8681/10000, Loss: 0.010347992181777954\n",
      "Iteration: 8682/10000, Loss: 0.006606768816709518\n",
      "Iteration: 8683/10000, Loss: 0.009017779491841793\n",
      "Iteration: 8684/10000, Loss: 0.010541833005845547\n",
      "Iteration: 8685/10000, Loss: 0.009279279969632626\n",
      "Iteration: 8686/10000, Loss: 0.0119400005787611\n",
      "Iteration: 8687/10000, Loss: 0.012267204001545906\n",
      "Iteration: 8688/10000, Loss: 0.009590811096131802\n",
      "Iteration: 8689/10000, Loss: 0.011367499828338623\n",
      "Iteration: 8690/10000, Loss: 0.009072097018361092\n",
      "Iteration: 8691/10000, Loss: 0.008024843409657478\n",
      "Iteration: 8692/10000, Loss: 0.009397934190928936\n",
      "Iteration: 8693/10000, Loss: 0.007545877248048782\n",
      "Iteration: 8694/10000, Loss: 0.01179775781929493\n",
      "Iteration: 8695/10000, Loss: 0.013616422191262245\n",
      "Iteration: 8696/10000, Loss: 0.008202282711863518\n",
      "Iteration: 8697/10000, Loss: 0.006375604309141636\n",
      "Iteration: 8698/10000, Loss: 0.00982620008289814\n",
      "Iteration: 8699/10000, Loss: 0.007163926959037781\n",
      "Iteration: 8700/10000, Loss: 0.010478486306965351\n",
      "Average test loss:  0.0025\n",
      "Iteration: 8701/10000, Loss: 0.006761686410754919\n",
      "Iteration: 8702/10000, Loss: 0.005802978295832872\n",
      "Iteration: 8703/10000, Loss: 0.008010218851268291\n",
      "Iteration: 8704/10000, Loss: 0.007112407591193914\n",
      "Iteration: 8705/10000, Loss: 0.0072301472537219524\n",
      "Iteration: 8706/10000, Loss: 0.008067070506513119\n",
      "Iteration: 8707/10000, Loss: 0.010089896619319916\n",
      "Iteration: 8708/10000, Loss: 0.010697241872549057\n",
      "Iteration: 8709/10000, Loss: 0.0071256207302212715\n",
      "Iteration: 8710/10000, Loss: 0.010250993072986603\n",
      "Iteration: 8711/10000, Loss: 0.009409114718437195\n",
      "Iteration: 8712/10000, Loss: 0.012780794873833656\n",
      "Iteration: 8713/10000, Loss: 0.007896065711975098\n",
      "Iteration: 8714/10000, Loss: 0.006805381737649441\n",
      "Iteration: 8715/10000, Loss: 0.010808374732732773\n",
      "Iteration: 8716/10000, Loss: 0.005911299958825111\n",
      "Iteration: 8717/10000, Loss: 0.009240458719432354\n",
      "Iteration: 8718/10000, Loss: 0.011476671323180199\n",
      "Iteration: 8719/10000, Loss: 0.009423311799764633\n",
      "Iteration: 8720/10000, Loss: 0.008320644497871399\n",
      "Iteration: 8721/10000, Loss: 0.009497463703155518\n",
      "Iteration: 8722/10000, Loss: 0.011834688484668732\n",
      "Iteration: 8723/10000, Loss: 0.00815099012106657\n",
      "Iteration: 8724/10000, Loss: 0.010815133340656757\n",
      "Iteration: 8725/10000, Loss: 0.006444468162953854\n",
      "Iteration: 8726/10000, Loss: 0.009477120824158192\n",
      "Iteration: 8727/10000, Loss: 0.009908805601298809\n",
      "Iteration: 8728/10000, Loss: 0.005896042566746473\n",
      "Iteration: 8729/10000, Loss: 0.008962848223745823\n",
      "Iteration: 8730/10000, Loss: 0.015110325068235397\n",
      "Iteration: 8731/10000, Loss: 0.010586905293166637\n",
      "Iteration: 8732/10000, Loss: 0.012845124118030071\n",
      "Iteration: 8733/10000, Loss: 0.005785116460174322\n",
      "Iteration: 8734/10000, Loss: 0.014057948254048824\n",
      "Iteration: 8735/10000, Loss: 0.007915818132460117\n",
      "Iteration: 8736/10000, Loss: 0.010241003707051277\n",
      "Iteration: 8737/10000, Loss: 0.005510061513632536\n",
      "Iteration: 8738/10000, Loss: 0.010322160087525845\n",
      "Iteration: 8739/10000, Loss: 0.012384431436657906\n",
      "Iteration: 8740/10000, Loss: 0.009963166899979115\n",
      "Iteration: 8741/10000, Loss: 0.00912337377667427\n",
      "Iteration: 8742/10000, Loss: 0.006043774075806141\n",
      "Iteration: 8743/10000, Loss: 0.008158301003277302\n",
      "Iteration: 8744/10000, Loss: 0.009390149265527725\n",
      "Iteration: 8745/10000, Loss: 0.009482083842158318\n",
      "Iteration: 8746/10000, Loss: 0.011079268530011177\n",
      "Iteration: 8747/10000, Loss: 0.005218559876084328\n",
      "Iteration: 8748/10000, Loss: 0.009932849556207657\n",
      "Iteration: 8749/10000, Loss: 0.010222844779491425\n",
      "Iteration: 8750/10000, Loss: 0.011619971133768559\n",
      "Iteration: 8751/10000, Loss: 0.007176514714956284\n",
      "Iteration: 8752/10000, Loss: 0.008680765517055988\n",
      "Iteration: 8753/10000, Loss: 0.014639238826930523\n",
      "Iteration: 8754/10000, Loss: 0.008959291502833366\n",
      "Iteration: 8755/10000, Loss: 0.010053534992039204\n",
      "Iteration: 8756/10000, Loss: 0.008832845836877823\n",
      "Iteration: 8757/10000, Loss: 0.010433497838675976\n",
      "Iteration: 8758/10000, Loss: 0.006785079836845398\n",
      "Iteration: 8759/10000, Loss: 0.00888036284595728\n",
      "Iteration: 8760/10000, Loss: 0.009263552725315094\n",
      "Iteration: 8761/10000, Loss: 0.007867105305194855\n",
      "Iteration: 8762/10000, Loss: 0.013081190176308155\n",
      "Iteration: 8763/10000, Loss: 0.004375262185931206\n",
      "Iteration: 8764/10000, Loss: 0.011861292645335197\n",
      "Iteration: 8765/10000, Loss: 0.006234016735106707\n",
      "Iteration: 8766/10000, Loss: 0.007135727442800999\n",
      "Iteration: 8767/10000, Loss: 0.004725079983472824\n",
      "Iteration: 8768/10000, Loss: 0.004996724426746368\n",
      "Iteration: 8769/10000, Loss: 0.013801274821162224\n",
      "Iteration: 8770/10000, Loss: 0.010930223390460014\n",
      "Iteration: 8771/10000, Loss: 0.007191227283328772\n",
      "Iteration: 8772/10000, Loss: 0.008181475102901459\n",
      "Iteration: 8773/10000, Loss: 0.007827166467905045\n",
      "Iteration: 8774/10000, Loss: 0.006664100103080273\n",
      "Iteration: 8775/10000, Loss: 0.00999621581286192\n",
      "Iteration: 8776/10000, Loss: 0.0058581046760082245\n",
      "Iteration: 8777/10000, Loss: 0.005868024192750454\n",
      "Iteration: 8778/10000, Loss: 0.01028685737401247\n",
      "Iteration: 8779/10000, Loss: 0.007823570631444454\n",
      "Iteration: 8780/10000, Loss: 0.010381472297012806\n",
      "Iteration: 8781/10000, Loss: 0.010888086631894112\n",
      "Iteration: 8782/10000, Loss: 0.007098534144461155\n",
      "Iteration: 8783/10000, Loss: 0.007318524178117514\n",
      "Iteration: 8784/10000, Loss: 0.008993750438094139\n",
      "Iteration: 8785/10000, Loss: 0.011402282863855362\n",
      "Iteration: 8786/10000, Loss: 0.006017443723976612\n",
      "Iteration: 8787/10000, Loss: 0.008192156441509724\n",
      "Iteration: 8788/10000, Loss: 0.007793999742716551\n",
      "Iteration: 8789/10000, Loss: 0.006236818619072437\n",
      "Iteration: 8790/10000, Loss: 0.010282560251653194\n",
      "Iteration: 8791/10000, Loss: 0.006724036764353514\n",
      "Iteration: 8792/10000, Loss: 0.009464588016271591\n",
      "Iteration: 8793/10000, Loss: 0.005684224423021078\n",
      "Iteration: 8794/10000, Loss: 0.010282648727297783\n",
      "Iteration: 8795/10000, Loss: 0.013203985057771206\n",
      "Iteration: 8796/10000, Loss: 0.008034177124500275\n",
      "Iteration: 8797/10000, Loss: 0.008726692758500576\n",
      "Iteration: 8798/10000, Loss: 0.007865050807595253\n",
      "Iteration: 8799/10000, Loss: 0.011084946803748608\n",
      "Iteration: 8800/10000, Loss: 0.017034612596035004\n",
      "Average test loss:  0.0031\n",
      "Iteration: 8801/10000, Loss: 0.012772566638886929\n",
      "Iteration: 8802/10000, Loss: 0.010623708367347717\n",
      "Iteration: 8803/10000, Loss: 0.011335880495607853\n",
      "Iteration: 8804/10000, Loss: 0.008460836485028267\n",
      "Iteration: 8805/10000, Loss: 0.0050017633475363255\n",
      "Iteration: 8806/10000, Loss: 0.009316659532487392\n",
      "Iteration: 8807/10000, Loss: 0.009804915636777878\n",
      "Iteration: 8808/10000, Loss: 0.008364452049136162\n",
      "Iteration: 8809/10000, Loss: 0.009181205183267593\n",
      "Iteration: 8810/10000, Loss: 0.009438063949346542\n",
      "Iteration: 8811/10000, Loss: 0.008666126057505608\n",
      "Iteration: 8812/10000, Loss: 0.01282601710408926\n",
      "Iteration: 8813/10000, Loss: 0.009308159351348877\n",
      "Iteration: 8814/10000, Loss: 0.0079488605260849\n",
      "Iteration: 8815/10000, Loss: 0.010955298319458961\n",
      "Iteration: 8816/10000, Loss: 0.010196903720498085\n",
      "Iteration: 8817/10000, Loss: 0.005544684361666441\n",
      "Iteration: 8818/10000, Loss: 0.01030998956412077\n",
      "Iteration: 8819/10000, Loss: 0.00794132798910141\n",
      "Iteration: 8820/10000, Loss: 0.011490030214190483\n",
      "Iteration: 8821/10000, Loss: 0.007468524854630232\n",
      "Iteration: 8822/10000, Loss: 0.008107137866318226\n",
      "Iteration: 8823/10000, Loss: 0.0054901824332773685\n",
      "Iteration: 8824/10000, Loss: 0.011807885020971298\n",
      "Iteration: 8825/10000, Loss: 0.016415266320109367\n",
      "Iteration: 8826/10000, Loss: 0.00982701126486063\n",
      "Iteration: 8827/10000, Loss: 0.00908544659614563\n",
      "Iteration: 8828/10000, Loss: 0.007230066694319248\n",
      "Iteration: 8829/10000, Loss: 0.008029465563595295\n",
      "Iteration: 8830/10000, Loss: 0.005302763544023037\n",
      "Iteration: 8831/10000, Loss: 0.009532625786960125\n",
      "Iteration: 8832/10000, Loss: 0.01012172270566225\n",
      "Iteration: 8833/10000, Loss: 0.01172139123082161\n",
      "Iteration: 8834/10000, Loss: 0.011058533564209938\n",
      "Iteration: 8835/10000, Loss: 0.006702918093651533\n",
      "Iteration: 8836/10000, Loss: 0.004715472925454378\n",
      "Iteration: 8837/10000, Loss: 0.011577856726944447\n",
      "Iteration: 8838/10000, Loss: 0.011853976175189018\n",
      "Iteration: 8839/10000, Loss: 0.007801946718245745\n",
      "Iteration: 8840/10000, Loss: 0.011203681118786335\n",
      "Iteration: 8841/10000, Loss: 0.01437909435480833\n",
      "Iteration: 8842/10000, Loss: 0.008289776742458344\n",
      "Iteration: 8843/10000, Loss: 0.016095571219921112\n",
      "Iteration: 8844/10000, Loss: 0.010672970674932003\n",
      "Iteration: 8845/10000, Loss: 0.009373215958476067\n",
      "Iteration: 8846/10000, Loss: 0.008070796728134155\n",
      "Iteration: 8847/10000, Loss: 0.009998505003750324\n",
      "Iteration: 8848/10000, Loss: 0.007924268022179604\n",
      "Iteration: 8849/10000, Loss: 0.0059289284981787205\n",
      "Iteration: 8850/10000, Loss: 0.008753206580877304\n",
      "Iteration: 8851/10000, Loss: 0.008656012825667858\n",
      "Iteration: 8852/10000, Loss: 0.0028865381609648466\n",
      "Iteration: 8853/10000, Loss: 0.007517488673329353\n",
      "Iteration: 8854/10000, Loss: 0.007670376915484667\n",
      "Iteration: 8855/10000, Loss: 0.005124514456838369\n",
      "Iteration: 8856/10000, Loss: 0.007048215717077255\n",
      "Iteration: 8857/10000, Loss: 0.0069822585210204124\n",
      "Iteration: 8858/10000, Loss: 0.008818536065518856\n",
      "Iteration: 8859/10000, Loss: 0.008496291004121304\n",
      "Iteration: 8860/10000, Loss: 0.011026200838387012\n",
      "Iteration: 8861/10000, Loss: 0.006156476680189371\n",
      "Iteration: 8862/10000, Loss: 0.009700299240648746\n",
      "Iteration: 8863/10000, Loss: 0.008801758289337158\n",
      "Iteration: 8864/10000, Loss: 0.008499471470713615\n",
      "Iteration: 8865/10000, Loss: 0.008775897324085236\n",
      "Iteration: 8866/10000, Loss: 0.006605085916817188\n",
      "Iteration: 8867/10000, Loss: 0.009480238892138004\n",
      "Iteration: 8868/10000, Loss: 0.009335219860076904\n",
      "Iteration: 8869/10000, Loss: 0.006919952109456062\n",
      "Iteration: 8870/10000, Loss: 0.006430629175156355\n",
      "Iteration: 8871/10000, Loss: 0.01235119253396988\n",
      "Iteration: 8872/10000, Loss: 0.008827936835587025\n",
      "Iteration: 8873/10000, Loss: 0.00845253188163042\n",
      "Iteration: 8874/10000, Loss: 0.011912484653294086\n",
      "Iteration: 8875/10000, Loss: 0.010210766457021236\n",
      "Iteration: 8876/10000, Loss: 0.01061719749122858\n",
      "Iteration: 8877/10000, Loss: 0.012359900400042534\n",
      "Iteration: 8878/10000, Loss: 0.010028084740042686\n",
      "Iteration: 8879/10000, Loss: 0.010489249601960182\n",
      "Iteration: 8880/10000, Loss: 0.005042369943112135\n",
      "Iteration: 8881/10000, Loss: 0.007219232153147459\n",
      "Iteration: 8882/10000, Loss: 0.014051167294383049\n",
      "Iteration: 8883/10000, Loss: 0.00948201771825552\n",
      "Iteration: 8884/10000, Loss: 0.00949157401919365\n",
      "Iteration: 8885/10000, Loss: 0.008285040967166424\n",
      "Iteration: 8886/10000, Loss: 0.009832019917666912\n",
      "Iteration: 8887/10000, Loss: 0.009470179677009583\n",
      "Iteration: 8888/10000, Loss: 0.007873025722801685\n",
      "Iteration: 8889/10000, Loss: 0.012515022419393063\n",
      "Iteration: 8890/10000, Loss: 0.007788047660142183\n",
      "Iteration: 8891/10000, Loss: 0.006839514710009098\n",
      "Iteration: 8892/10000, Loss: 0.008812225423753262\n",
      "Iteration: 8893/10000, Loss: 0.00976920872926712\n",
      "Iteration: 8894/10000, Loss: 0.006105518434196711\n",
      "Iteration: 8895/10000, Loss: 0.008128798566758633\n",
      "Iteration: 8896/10000, Loss: 0.00810896698385477\n",
      "Iteration: 8897/10000, Loss: 0.011671305634081364\n",
      "Iteration: 8898/10000, Loss: 0.005389920435845852\n",
      "Iteration: 8899/10000, Loss: 0.00791163556277752\n",
      "Iteration: 8900/10000, Loss: 0.00794550497084856\n",
      "Average test loss:  0.0017\n",
      "Iteration: 8901/10000, Loss: 0.011957071721553802\n",
      "Iteration: 8902/10000, Loss: 0.010881246998906136\n",
      "Iteration: 8903/10000, Loss: 0.008297055959701538\n",
      "Iteration: 8904/10000, Loss: 0.008009189739823341\n",
      "Iteration: 8905/10000, Loss: 0.007613473571836948\n",
      "Iteration: 8906/10000, Loss: 0.008231236599385738\n",
      "Iteration: 8907/10000, Loss: 0.0085508543998003\n",
      "Iteration: 8908/10000, Loss: 0.014143245294690132\n",
      "Iteration: 8909/10000, Loss: 0.006605224683880806\n",
      "Iteration: 8910/10000, Loss: 0.013600636273622513\n",
      "Iteration: 8911/10000, Loss: 0.007278821896761656\n",
      "Iteration: 8912/10000, Loss: 0.009688753634691238\n",
      "Iteration: 8913/10000, Loss: 0.0064729247242212296\n",
      "Iteration: 8914/10000, Loss: 0.009274606592953205\n",
      "Iteration: 8915/10000, Loss: 0.009702854789793491\n",
      "Iteration: 8916/10000, Loss: 0.009862064383924007\n",
      "Iteration: 8917/10000, Loss: 0.009258534759283066\n",
      "Iteration: 8918/10000, Loss: 0.010780083015561104\n",
      "Iteration: 8919/10000, Loss: 0.010863244533538818\n",
      "Iteration: 8920/10000, Loss: 0.00833849236369133\n",
      "Iteration: 8921/10000, Loss: 0.01024450920522213\n",
      "Iteration: 8922/10000, Loss: 0.010851383209228516\n",
      "Iteration: 8923/10000, Loss: 0.012417539022862911\n",
      "Iteration: 8924/10000, Loss: 0.00896946620196104\n",
      "Iteration: 8925/10000, Loss: 0.007298087235540152\n",
      "Iteration: 8926/10000, Loss: 0.012560123577713966\n",
      "Iteration: 8927/10000, Loss: 0.00944426842033863\n",
      "Iteration: 8928/10000, Loss: 0.006127768196165562\n",
      "Iteration: 8929/10000, Loss: 0.0078642088919878\n",
      "Iteration: 8930/10000, Loss: 0.0068932147696614265\n",
      "Iteration: 8931/10000, Loss: 0.009294592775404453\n",
      "Iteration: 8932/10000, Loss: 0.01059100590646267\n",
      "Iteration: 8933/10000, Loss: 0.007264420390129089\n",
      "Iteration: 8934/10000, Loss: 0.007430072408169508\n",
      "Iteration: 8935/10000, Loss: 0.006373506039381027\n",
      "Iteration: 8936/10000, Loss: 0.006915932055562735\n",
      "Iteration: 8937/10000, Loss: 0.006823539733886719\n",
      "Iteration: 8938/10000, Loss: 0.01265779510140419\n",
      "Iteration: 8939/10000, Loss: 0.006649498827755451\n",
      "Iteration: 8940/10000, Loss: 0.006803710013628006\n",
      "Iteration: 8941/10000, Loss: 0.009134667925536633\n",
      "Iteration: 8942/10000, Loss: 0.007758524734526873\n",
      "Iteration: 8943/10000, Loss: 0.007312409579753876\n",
      "Iteration: 8944/10000, Loss: 0.006259055342525244\n",
      "Iteration: 8945/10000, Loss: 0.006705187726765871\n",
      "Iteration: 8946/10000, Loss: 0.009810836985707283\n",
      "Iteration: 8947/10000, Loss: 0.010873453691601753\n",
      "Iteration: 8948/10000, Loss: 0.008403805084526539\n",
      "Iteration: 8949/10000, Loss: 0.00843814481049776\n",
      "Iteration: 8950/10000, Loss: 0.009187408722937107\n",
      "Iteration: 8951/10000, Loss: 0.010166718624532223\n",
      "Iteration: 8952/10000, Loss: 0.012583683244884014\n",
      "Iteration: 8953/10000, Loss: 0.013151378370821476\n",
      "Iteration: 8954/10000, Loss: 0.008691172115504742\n",
      "Iteration: 8955/10000, Loss: 0.0059491354040801525\n",
      "Iteration: 8956/10000, Loss: 0.004334187135100365\n",
      "Iteration: 8957/10000, Loss: 0.010606220923364162\n",
      "Iteration: 8958/10000, Loss: 0.009337200783193111\n",
      "Iteration: 8959/10000, Loss: 0.007639259099960327\n",
      "Iteration: 8960/10000, Loss: 0.009522625245153904\n",
      "Iteration: 8961/10000, Loss: 0.0074022929184138775\n",
      "Iteration: 8962/10000, Loss: 0.008718711324036121\n",
      "Iteration: 8963/10000, Loss: 0.008984320797026157\n",
      "Iteration: 8964/10000, Loss: 0.007648707367479801\n",
      "Iteration: 8965/10000, Loss: 0.012475650757551193\n",
      "Iteration: 8966/10000, Loss: 0.0029889345169067383\n",
      "Iteration: 8967/10000, Loss: 0.006256219930946827\n",
      "Iteration: 8968/10000, Loss: 0.0052979993633925915\n",
      "Iteration: 8969/10000, Loss: 0.011751769110560417\n",
      "Iteration: 8970/10000, Loss: 0.006815404165536165\n",
      "Iteration: 8971/10000, Loss: 0.01055388618260622\n",
      "Iteration: 8972/10000, Loss: 0.007269709836691618\n",
      "Iteration: 8973/10000, Loss: 0.00996621698141098\n",
      "Iteration: 8974/10000, Loss: 0.0074735418893396854\n",
      "Iteration: 8975/10000, Loss: 0.00950302742421627\n",
      "Iteration: 8976/10000, Loss: 0.008398893289268017\n",
      "Iteration: 8977/10000, Loss: 0.009910517372190952\n",
      "Iteration: 8978/10000, Loss: 0.009080433286726475\n",
      "Iteration: 8979/10000, Loss: 0.01005365140736103\n",
      "Iteration: 8980/10000, Loss: 0.007002111058682203\n",
      "Iteration: 8981/10000, Loss: 0.007907664403319359\n",
      "Iteration: 8982/10000, Loss: 0.00814494676887989\n",
      "Iteration: 8983/10000, Loss: 0.00966324470937252\n",
      "Iteration: 8984/10000, Loss: 0.005994200706481934\n",
      "Iteration: 8985/10000, Loss: 0.00883213710039854\n",
      "Iteration: 8986/10000, Loss: 0.010647798888385296\n",
      "Iteration: 8987/10000, Loss: 0.008786098100244999\n",
      "Iteration: 8988/10000, Loss: 0.009941218420863152\n",
      "Iteration: 8989/10000, Loss: 0.0048940288834273815\n",
      "Iteration: 8990/10000, Loss: 0.007920309901237488\n",
      "Iteration: 8991/10000, Loss: 0.006139699835330248\n",
      "Iteration: 8992/10000, Loss: 0.01138247363269329\n",
      "Iteration: 8993/10000, Loss: 0.008636560291051865\n",
      "Iteration: 8994/10000, Loss: 0.011300248093903065\n",
      "Iteration: 8995/10000, Loss: 0.011102658696472645\n",
      "Iteration: 8996/10000, Loss: 0.013374683447182178\n",
      "Iteration: 8997/10000, Loss: 0.010435668751597404\n",
      "Iteration: 8998/10000, Loss: 0.007183247711509466\n",
      "Iteration: 8999/10000, Loss: 0.012018673121929169\n",
      "Iteration: 9000/10000, Loss: 0.013259617611765862\n",
      "Average test loss:  0.0017\n",
      "Iteration: 9001/10000, Loss: 0.010486997663974762\n",
      "Iteration: 9002/10000, Loss: 0.00903511792421341\n",
      "Iteration: 9003/10000, Loss: 0.010765721090137959\n",
      "Iteration: 9004/10000, Loss: 0.0073025724850595\n",
      "Iteration: 9005/10000, Loss: 0.009188645519316196\n",
      "Iteration: 9006/10000, Loss: 0.007968410849571228\n",
      "Iteration: 9007/10000, Loss: 0.007904931902885437\n",
      "Iteration: 9008/10000, Loss: 0.009236880578100681\n",
      "Iteration: 9009/10000, Loss: 0.011054299771785736\n",
      "Iteration: 9010/10000, Loss: 0.008325512520968914\n",
      "Iteration: 9011/10000, Loss: 0.006777954287827015\n",
      "Iteration: 9012/10000, Loss: 0.008108806796371937\n",
      "Iteration: 9013/10000, Loss: 0.007701480761170387\n",
      "Iteration: 9014/10000, Loss: 0.007126407232135534\n",
      "Iteration: 9015/10000, Loss: 0.009553354233503342\n",
      "Iteration: 9016/10000, Loss: 0.011732488870620728\n",
      "Iteration: 9017/10000, Loss: 0.008281615562736988\n",
      "Iteration: 9018/10000, Loss: 0.006870421115309\n",
      "Iteration: 9019/10000, Loss: 0.01217333972454071\n",
      "Iteration: 9020/10000, Loss: 0.006551466882228851\n",
      "Iteration: 9021/10000, Loss: 0.008760778233408928\n",
      "Iteration: 9022/10000, Loss: 0.008767948485910892\n",
      "Iteration: 9023/10000, Loss: 0.010855413042008877\n",
      "Iteration: 9024/10000, Loss: 0.008093051612377167\n",
      "Iteration: 9025/10000, Loss: 0.012417885474860668\n",
      "Iteration: 9026/10000, Loss: 0.012236494570970535\n",
      "Iteration: 9027/10000, Loss: 0.007153184153139591\n",
      "Iteration: 9028/10000, Loss: 0.00514164287596941\n",
      "Iteration: 9029/10000, Loss: 0.013236179016530514\n",
      "Iteration: 9030/10000, Loss: 0.008798083290457726\n",
      "Iteration: 9031/10000, Loss: 0.006813826505094767\n",
      "Iteration: 9032/10000, Loss: 0.0038382422644644976\n",
      "Iteration: 9033/10000, Loss: 0.01570473238825798\n",
      "Iteration: 9034/10000, Loss: 0.008146580308675766\n",
      "Iteration: 9035/10000, Loss: 0.0056115612387657166\n",
      "Iteration: 9036/10000, Loss: 0.007845970802009106\n",
      "Iteration: 9037/10000, Loss: 0.014197207987308502\n",
      "Iteration: 9038/10000, Loss: 0.010355665348470211\n",
      "Iteration: 9039/10000, Loss: 0.012924612499773502\n",
      "Iteration: 9040/10000, Loss: 0.011997283436357975\n",
      "Iteration: 9041/10000, Loss: 0.009732892736792564\n",
      "Iteration: 9042/10000, Loss: 0.01203034445643425\n",
      "Iteration: 9043/10000, Loss: 0.008749756962060928\n",
      "Iteration: 9044/10000, Loss: 0.00972448568791151\n",
      "Iteration: 9045/10000, Loss: 0.008440893143415451\n",
      "Iteration: 9046/10000, Loss: 0.010121944360435009\n",
      "Iteration: 9047/10000, Loss: 0.007093905936926603\n",
      "Iteration: 9048/10000, Loss: 0.003923887386918068\n",
      "Iteration: 9049/10000, Loss: 0.008629434742033482\n",
      "Iteration: 9050/10000, Loss: 0.008880222216248512\n",
      "Iteration: 9051/10000, Loss: 0.008079365827143192\n",
      "Iteration: 9052/10000, Loss: 0.009538860060274601\n",
      "Iteration: 9053/10000, Loss: 0.0030607355292886496\n",
      "Iteration: 9054/10000, Loss: 0.007922874763607979\n",
      "Iteration: 9055/10000, Loss: 0.012182261794805527\n",
      "Iteration: 9056/10000, Loss: 0.01251970324665308\n",
      "Iteration: 9057/10000, Loss: 0.010384151712059975\n",
      "Iteration: 9058/10000, Loss: 0.011625823564827442\n",
      "Iteration: 9059/10000, Loss: 0.005274744238704443\n",
      "Iteration: 9060/10000, Loss: 0.007074232213199139\n",
      "Iteration: 9061/10000, Loss: 0.011084808968007565\n",
      "Iteration: 9062/10000, Loss: 0.011671359650790691\n",
      "Iteration: 9063/10000, Loss: 0.009145062416791916\n",
      "Iteration: 9064/10000, Loss: 0.011141562834382057\n",
      "Iteration: 9065/10000, Loss: 0.012516739778220654\n",
      "Iteration: 9066/10000, Loss: 0.006248003803193569\n",
      "Iteration: 9067/10000, Loss: 0.009193344973027706\n",
      "Iteration: 9068/10000, Loss: 0.01035753171890974\n",
      "Iteration: 9069/10000, Loss: 0.008373776450753212\n",
      "Iteration: 9070/10000, Loss: 0.008997263386845589\n",
      "Iteration: 9071/10000, Loss: 0.010423967614769936\n",
      "Iteration: 9072/10000, Loss: 0.009994292631745338\n",
      "Iteration: 9073/10000, Loss: 0.01050998829305172\n",
      "Iteration: 9074/10000, Loss: 0.008638964034616947\n",
      "Iteration: 9075/10000, Loss: 0.007305022329092026\n",
      "Iteration: 9076/10000, Loss: 0.005134140141308308\n",
      "Iteration: 9077/10000, Loss: 0.00987760629504919\n",
      "Iteration: 9078/10000, Loss: 0.012511702254414558\n",
      "Iteration: 9079/10000, Loss: 0.01540942583233118\n",
      "Iteration: 9080/10000, Loss: 0.009916839189827442\n",
      "Iteration: 9081/10000, Loss: 0.011368779465556145\n",
      "Iteration: 9082/10000, Loss: 0.009745731018483639\n",
      "Iteration: 9083/10000, Loss: 0.007772920187562704\n",
      "Iteration: 9084/10000, Loss: 0.008468948304653168\n",
      "Iteration: 9085/10000, Loss: 0.007014378905296326\n",
      "Iteration: 9086/10000, Loss: 0.008321885019540787\n",
      "Iteration: 9087/10000, Loss: 0.008684982545673847\n",
      "Iteration: 9088/10000, Loss: 0.005630558356642723\n",
      "Iteration: 9089/10000, Loss: 0.009730357676744461\n",
      "Iteration: 9090/10000, Loss: 0.007181545253843069\n",
      "Iteration: 9091/10000, Loss: 0.004533866420388222\n",
      "Iteration: 9092/10000, Loss: 0.010643035173416138\n",
      "Iteration: 9093/10000, Loss: 0.00559875275939703\n",
      "Iteration: 9094/10000, Loss: 0.009439184330403805\n",
      "Iteration: 9095/10000, Loss: 0.008554723113775253\n",
      "Iteration: 9096/10000, Loss: 0.00805222149938345\n",
      "Iteration: 9097/10000, Loss: 0.01012852881103754\n",
      "Iteration: 9098/10000, Loss: 0.008821551688015461\n",
      "Iteration: 9099/10000, Loss: 0.004814923275262117\n",
      "Iteration: 9100/10000, Loss: 0.009856926277279854\n",
      "Average test loss:  0.0026\n",
      "Iteration: 9101/10000, Loss: 0.012979847379028797\n",
      "Iteration: 9102/10000, Loss: 0.01054127886891365\n",
      "Iteration: 9103/10000, Loss: 0.010244887322187424\n",
      "Iteration: 9104/10000, Loss: 0.012075399048626423\n",
      "Iteration: 9105/10000, Loss: 0.00669489149004221\n",
      "Iteration: 9106/10000, Loss: 0.009162785485386848\n",
      "Iteration: 9107/10000, Loss: 0.005331795662641525\n",
      "Iteration: 9108/10000, Loss: 0.010585454292595387\n",
      "Iteration: 9109/10000, Loss: 0.004779256414622068\n",
      "Iteration: 9110/10000, Loss: 0.014901946298778057\n",
      "Iteration: 9111/10000, Loss: 0.007874440401792526\n",
      "Iteration: 9112/10000, Loss: 0.007615798152983189\n",
      "Iteration: 9113/10000, Loss: 0.009130728431046009\n",
      "Iteration: 9114/10000, Loss: 0.011881811544299126\n",
      "Iteration: 9115/10000, Loss: 0.010495323687791824\n",
      "Iteration: 9116/10000, Loss: 0.009137699380517006\n",
      "Iteration: 9117/10000, Loss: 0.006686684209853411\n",
      "Iteration: 9118/10000, Loss: 0.00727096339687705\n",
      "Iteration: 9119/10000, Loss: 0.011618564836680889\n",
      "Iteration: 9120/10000, Loss: 0.012085643596947193\n",
      "Iteration: 9121/10000, Loss: 0.011044291779398918\n",
      "Iteration: 9122/10000, Loss: 0.010534018278121948\n",
      "Iteration: 9123/10000, Loss: 0.00840672105550766\n",
      "Iteration: 9124/10000, Loss: 0.00924790557473898\n",
      "Iteration: 9125/10000, Loss: 0.009428274817764759\n",
      "Iteration: 9126/10000, Loss: 0.00909431278705597\n",
      "Iteration: 9127/10000, Loss: 0.0044885980896651745\n",
      "Iteration: 9128/10000, Loss: 0.007168964482843876\n",
      "Iteration: 9129/10000, Loss: 0.008738062344491482\n",
      "Iteration: 9130/10000, Loss: 0.011965783312916756\n",
      "Iteration: 9131/10000, Loss: 0.006948994006961584\n",
      "Iteration: 9132/10000, Loss: 0.008778032846748829\n",
      "Iteration: 9133/10000, Loss: 0.00594090111553669\n",
      "Iteration: 9134/10000, Loss: 0.0060071395710110664\n",
      "Iteration: 9135/10000, Loss: 0.0065202354453504086\n",
      "Iteration: 9136/10000, Loss: 0.008452098816633224\n",
      "Iteration: 9137/10000, Loss: 0.00808926671743393\n",
      "Iteration: 9138/10000, Loss: 0.011744070798158646\n",
      "Iteration: 9139/10000, Loss: 0.009208307601511478\n",
      "Iteration: 9140/10000, Loss: 0.010372772812843323\n",
      "Iteration: 9141/10000, Loss: 0.010311608202755451\n",
      "Iteration: 9142/10000, Loss: 0.009248895570635796\n",
      "Iteration: 9143/10000, Loss: 0.010441703721880913\n",
      "Iteration: 9144/10000, Loss: 0.011488959193229675\n",
      "Iteration: 9145/10000, Loss: 0.012280825525522232\n",
      "Iteration: 9146/10000, Loss: 0.006492938380688429\n",
      "Iteration: 9147/10000, Loss: 0.007509717717766762\n",
      "Iteration: 9148/10000, Loss: 0.012434782460331917\n",
      "Iteration: 9149/10000, Loss: 0.005407638847827911\n",
      "Iteration: 9150/10000, Loss: 0.009556034579873085\n",
      "Iteration: 9151/10000, Loss: 0.013599379919469357\n",
      "Iteration: 9152/10000, Loss: 0.013409389182925224\n",
      "Iteration: 9153/10000, Loss: 0.008384312503039837\n",
      "Iteration: 9154/10000, Loss: 0.0077646649442613125\n",
      "Iteration: 9155/10000, Loss: 0.010070610791444778\n",
      "Iteration: 9156/10000, Loss: 0.0072056595236063\n",
      "Iteration: 9157/10000, Loss: 0.008019426837563515\n",
      "Iteration: 9158/10000, Loss: 0.00995322410017252\n",
      "Iteration: 9159/10000, Loss: 0.01099071279168129\n",
      "Iteration: 9160/10000, Loss: 0.004016546998172998\n",
      "Iteration: 9161/10000, Loss: 0.009826541878283024\n",
      "Iteration: 9162/10000, Loss: 0.006637257523834705\n",
      "Iteration: 9163/10000, Loss: 0.008210853673517704\n",
      "Iteration: 9164/10000, Loss: 0.005606313236057758\n",
      "Iteration: 9165/10000, Loss: 0.009169384837150574\n",
      "Iteration: 9166/10000, Loss: 0.007291038986295462\n",
      "Iteration: 9167/10000, Loss: 0.005822603590786457\n",
      "Iteration: 9168/10000, Loss: 0.004815113730728626\n",
      "Iteration: 9169/10000, Loss: 0.009217420592904091\n",
      "Iteration: 9170/10000, Loss: 0.0082602109760046\n",
      "Iteration: 9171/10000, Loss: 0.01703501120209694\n",
      "Iteration: 9172/10000, Loss: 0.006798384245485067\n",
      "Iteration: 9173/10000, Loss: 0.008055854588747025\n",
      "Iteration: 9174/10000, Loss: 0.00907983910292387\n",
      "Iteration: 9175/10000, Loss: 0.009608566761016846\n",
      "Iteration: 9176/10000, Loss: 0.004768126178532839\n",
      "Iteration: 9177/10000, Loss: 0.008182669058442116\n",
      "Iteration: 9178/10000, Loss: 0.009961920790374279\n",
      "Iteration: 9179/10000, Loss: 0.01580885425209999\n",
      "Iteration: 9180/10000, Loss: 0.011890017427504063\n",
      "Iteration: 9181/10000, Loss: 0.006835706532001495\n",
      "Iteration: 9182/10000, Loss: 0.008533678017556667\n",
      "Iteration: 9183/10000, Loss: 0.011218134313821793\n",
      "Iteration: 9184/10000, Loss: 0.007399065885692835\n",
      "Iteration: 9185/10000, Loss: 0.014322109520435333\n",
      "Iteration: 9186/10000, Loss: 0.010259267874062061\n",
      "Iteration: 9187/10000, Loss: 0.010109956376254559\n",
      "Iteration: 9188/10000, Loss: 0.012311166152358055\n",
      "Iteration: 9189/10000, Loss: 0.013475853949785233\n",
      "Iteration: 9190/10000, Loss: 0.006050158757716417\n",
      "Iteration: 9191/10000, Loss: 0.010365795344114304\n",
      "Iteration: 9192/10000, Loss: 0.01040746457874775\n",
      "Iteration: 9193/10000, Loss: 0.00867069698870182\n",
      "Iteration: 9194/10000, Loss: 0.00770251639187336\n",
      "Iteration: 9195/10000, Loss: 0.00892662350088358\n",
      "Iteration: 9196/10000, Loss: 0.01147373579442501\n",
      "Iteration: 9197/10000, Loss: 0.005706597585231066\n",
      "Iteration: 9198/10000, Loss: 0.008747506886720657\n",
      "Iteration: 9199/10000, Loss: 0.005951988976448774\n",
      "Iteration: 9200/10000, Loss: 0.007178738247603178\n",
      "Average test loss:  0.0031\n",
      "Iteration: 9201/10000, Loss: 0.010020426474511623\n",
      "Iteration: 9202/10000, Loss: 0.010937739163637161\n",
      "Iteration: 9203/10000, Loss: 0.011656166054308414\n",
      "Iteration: 9204/10000, Loss: 0.0088272076100111\n",
      "Iteration: 9205/10000, Loss: 0.005495831370353699\n",
      "Iteration: 9206/10000, Loss: 0.00886298343539238\n",
      "Iteration: 9207/10000, Loss: 0.00986406859010458\n",
      "Iteration: 9208/10000, Loss: 0.01009482890367508\n",
      "Iteration: 9209/10000, Loss: 0.01016854215413332\n",
      "Iteration: 9210/10000, Loss: 0.006812299136072397\n",
      "Iteration: 9211/10000, Loss: 0.00794601533561945\n",
      "Iteration: 9212/10000, Loss: 0.00802797544747591\n",
      "Iteration: 9213/10000, Loss: 0.010684666223824024\n",
      "Iteration: 9214/10000, Loss: 0.009625275619328022\n",
      "Iteration: 9215/10000, Loss: 0.010346007533371449\n",
      "Iteration: 9216/10000, Loss: 0.00920033734291792\n",
      "Iteration: 9217/10000, Loss: 0.008181130513548851\n",
      "Iteration: 9218/10000, Loss: 0.011498406529426575\n",
      "Iteration: 9219/10000, Loss: 0.006968763191252947\n",
      "Iteration: 9220/10000, Loss: 0.010883812792599201\n",
      "Iteration: 9221/10000, Loss: 0.005327580962330103\n",
      "Iteration: 9222/10000, Loss: 0.007060044910758734\n",
      "Iteration: 9223/10000, Loss: 0.009440581314265728\n",
      "Iteration: 9224/10000, Loss: 0.0098878750577569\n",
      "Iteration: 9225/10000, Loss: 0.00747636565938592\n",
      "Iteration: 9226/10000, Loss: 0.006291842553764582\n",
      "Iteration: 9227/10000, Loss: 0.007984635420143604\n",
      "Iteration: 9228/10000, Loss: 0.008149778470396996\n",
      "Iteration: 9229/10000, Loss: 0.008673328906297684\n",
      "Iteration: 9230/10000, Loss: 0.008865613490343094\n",
      "Iteration: 9231/10000, Loss: 0.01027794647961855\n",
      "Iteration: 9232/10000, Loss: 0.008030294440686703\n",
      "Iteration: 9233/10000, Loss: 0.007922893390059471\n",
      "Iteration: 9234/10000, Loss: 0.010570673272013664\n",
      "Iteration: 9235/10000, Loss: 0.010733587667346\n",
      "Iteration: 9236/10000, Loss: 0.006247535813599825\n",
      "Iteration: 9237/10000, Loss: 0.011598004959523678\n",
      "Iteration: 9238/10000, Loss: 0.013212894089519978\n",
      "Iteration: 9239/10000, Loss: 0.010245044715702534\n",
      "Iteration: 9240/10000, Loss: 0.007733440492302179\n",
      "Iteration: 9241/10000, Loss: 0.007495872676372528\n",
      "Iteration: 9242/10000, Loss: 0.010041210800409317\n",
      "Iteration: 9243/10000, Loss: 0.009084808640182018\n",
      "Iteration: 9244/10000, Loss: 0.006892247125506401\n",
      "Iteration: 9245/10000, Loss: 0.006744826212525368\n",
      "Iteration: 9246/10000, Loss: 0.008396120741963387\n",
      "Iteration: 9247/10000, Loss: 0.00869448110461235\n",
      "Iteration: 9248/10000, Loss: 0.007516640238463879\n",
      "Iteration: 9249/10000, Loss: 0.006631474010646343\n",
      "Iteration: 9250/10000, Loss: 0.009080094285309315\n",
      "Iteration: 9251/10000, Loss: 0.00782144907861948\n",
      "Iteration: 9252/10000, Loss: 0.010872285813093185\n",
      "Iteration: 9253/10000, Loss: 0.008761603385210037\n",
      "Iteration: 9254/10000, Loss: 0.004930353257805109\n",
      "Iteration: 9255/10000, Loss: 0.006153465714305639\n",
      "Iteration: 9256/10000, Loss: 0.008756295777857304\n",
      "Iteration: 9257/10000, Loss: 0.011853054165840149\n",
      "Iteration: 9258/10000, Loss: 0.010183089412748814\n",
      "Iteration: 9259/10000, Loss: 0.006579052656888962\n",
      "Iteration: 9260/10000, Loss: 0.00977384764701128\n",
      "Iteration: 9261/10000, Loss: 0.00481620104983449\n",
      "Iteration: 9262/10000, Loss: 0.007404117379337549\n",
      "Iteration: 9263/10000, Loss: 0.010015110485255718\n",
      "Iteration: 9264/10000, Loss: 0.005385975819081068\n",
      "Iteration: 9265/10000, Loss: 0.01097629964351654\n",
      "Iteration: 9266/10000, Loss: 0.006696644704788923\n",
      "Iteration: 9267/10000, Loss: 0.0114231426268816\n",
      "Iteration: 9268/10000, Loss: 0.007357312366366386\n",
      "Iteration: 9269/10000, Loss: 0.01261095143854618\n",
      "Iteration: 9270/10000, Loss: 0.005641653202474117\n",
      "Iteration: 9271/10000, Loss: 0.007445566356182098\n",
      "Iteration: 9272/10000, Loss: 0.008778365328907967\n",
      "Iteration: 9273/10000, Loss: 0.008350539952516556\n",
      "Iteration: 9274/10000, Loss: 0.012762879021465778\n",
      "Iteration: 9275/10000, Loss: 0.005336924456059933\n",
      "Iteration: 9276/10000, Loss: 0.007982495240867138\n",
      "Iteration: 9277/10000, Loss: 0.005210329312831163\n",
      "Iteration: 9278/10000, Loss: 0.006672014482319355\n",
      "Iteration: 9279/10000, Loss: 0.009139384143054485\n",
      "Iteration: 9280/10000, Loss: 0.007161435671150684\n",
      "Iteration: 9281/10000, Loss: 0.010780462995171547\n",
      "Iteration: 9282/10000, Loss: 0.0076110465452075005\n",
      "Iteration: 9283/10000, Loss: 0.008032314479351044\n",
      "Iteration: 9284/10000, Loss: 0.01557043194770813\n",
      "Iteration: 9285/10000, Loss: 0.009232992306351662\n",
      "Iteration: 9286/10000, Loss: 0.00903824158012867\n",
      "Iteration: 9287/10000, Loss: 0.007397409528493881\n",
      "Iteration: 9288/10000, Loss: 0.007985035888850689\n",
      "Iteration: 9289/10000, Loss: 0.012367438524961472\n",
      "Iteration: 9290/10000, Loss: 0.0061142705380916595\n",
      "Iteration: 9291/10000, Loss: 0.008630300872027874\n",
      "Iteration: 9292/10000, Loss: 0.01189417764544487\n",
      "Iteration: 9293/10000, Loss: 0.007346033584326506\n",
      "Iteration: 9294/10000, Loss: 0.0064978208392858505\n",
      "Iteration: 9295/10000, Loss: 0.006009525619447231\n",
      "Iteration: 9296/10000, Loss: 0.009685172699391842\n",
      "Iteration: 9297/10000, Loss: 0.007772968616336584\n",
      "Iteration: 9298/10000, Loss: 0.009161561727523804\n",
      "Iteration: 9299/10000, Loss: 0.007764467038214207\n",
      "Iteration: 9300/10000, Loss: 0.011639618314802647\n",
      "Average test loss:  0.0022\n",
      "Iteration: 9301/10000, Loss: 0.01117707323282957\n",
      "Iteration: 9302/10000, Loss: 0.007664787117391825\n",
      "Iteration: 9303/10000, Loss: 0.010746023617684841\n",
      "Iteration: 9304/10000, Loss: 0.008207926526665688\n",
      "Iteration: 9305/10000, Loss: 0.010348028503358364\n",
      "Iteration: 9306/10000, Loss: 0.012388444505631924\n",
      "Iteration: 9307/10000, Loss: 0.007715444080531597\n",
      "Iteration: 9308/10000, Loss: 0.007154748309403658\n",
      "Iteration: 9309/10000, Loss: 0.011204701848328114\n",
      "Iteration: 9310/10000, Loss: 0.01116126123815775\n",
      "Iteration: 9311/10000, Loss: 0.00922310259193182\n",
      "Iteration: 9312/10000, Loss: 0.003353123553097248\n",
      "Iteration: 9313/10000, Loss: 0.008519098162651062\n",
      "Iteration: 9314/10000, Loss: 0.006761001888662577\n",
      "Iteration: 9315/10000, Loss: 0.01063049491494894\n",
      "Iteration: 9316/10000, Loss: 0.00783510785549879\n",
      "Iteration: 9317/10000, Loss: 0.006736927665770054\n",
      "Iteration: 9318/10000, Loss: 0.006483782548457384\n",
      "Iteration: 9319/10000, Loss: 0.007278943434357643\n",
      "Iteration: 9320/10000, Loss: 0.010088919661939144\n",
      "Iteration: 9321/10000, Loss: 0.0062874723225831985\n",
      "Iteration: 9322/10000, Loss: 0.006140440236777067\n",
      "Iteration: 9323/10000, Loss: 0.00348523142747581\n",
      "Iteration: 9324/10000, Loss: 0.0066687422804534435\n",
      "Iteration: 9325/10000, Loss: 0.006731308996677399\n",
      "Iteration: 9326/10000, Loss: 0.01131974346935749\n",
      "Iteration: 9327/10000, Loss: 0.0073376307263970375\n",
      "Iteration: 9328/10000, Loss: 0.0041040037758648396\n",
      "Iteration: 9329/10000, Loss: 0.01033660490065813\n",
      "Iteration: 9330/10000, Loss: 0.012484186328947544\n",
      "Iteration: 9331/10000, Loss: 0.009543118067085743\n",
      "Iteration: 9332/10000, Loss: 0.006680219434201717\n",
      "Iteration: 9333/10000, Loss: 0.016008129343390465\n",
      "Iteration: 9334/10000, Loss: 0.008459304459393024\n",
      "Iteration: 9335/10000, Loss: 0.006347724702209234\n",
      "Iteration: 9336/10000, Loss: 0.0096849724650383\n",
      "Iteration: 9337/10000, Loss: 0.00862424448132515\n",
      "Iteration: 9338/10000, Loss: 0.01075073517858982\n",
      "Iteration: 9339/10000, Loss: 0.009458941407501698\n",
      "Iteration: 9340/10000, Loss: 0.007614871021360159\n",
      "Iteration: 9341/10000, Loss: 0.011041657067835331\n",
      "Iteration: 9342/10000, Loss: 0.007169813383370638\n",
      "Iteration: 9343/10000, Loss: 0.009250217117369175\n",
      "Iteration: 9344/10000, Loss: 0.008399604819715023\n",
      "Iteration: 9345/10000, Loss: 0.009237021207809448\n",
      "Iteration: 9346/10000, Loss: 0.008886919356882572\n",
      "Iteration: 9347/10000, Loss: 0.010725106112658978\n",
      "Iteration: 9348/10000, Loss: 0.008093200623989105\n",
      "Iteration: 9349/10000, Loss: 0.010494924150407314\n",
      "Iteration: 9350/10000, Loss: 0.01158993411809206\n",
      "Iteration: 9351/10000, Loss: 0.007385067641735077\n",
      "Iteration: 9352/10000, Loss: 0.008293885737657547\n",
      "Iteration: 9353/10000, Loss: 0.007481406908482313\n",
      "Iteration: 9354/10000, Loss: 0.005267617292702198\n",
      "Iteration: 9355/10000, Loss: 0.011344017460942268\n",
      "Iteration: 9356/10000, Loss: 0.007542795035988092\n",
      "Iteration: 9357/10000, Loss: 0.006991291884332895\n",
      "Iteration: 9358/10000, Loss: 0.010063565336167812\n",
      "Iteration: 9359/10000, Loss: 0.00933885294944048\n",
      "Iteration: 9360/10000, Loss: 0.008315777406096458\n",
      "Iteration: 9361/10000, Loss: 0.010512673296034336\n",
      "Iteration: 9362/10000, Loss: 0.007323377765715122\n",
      "Iteration: 9363/10000, Loss: 0.009255421347916126\n",
      "Iteration: 9364/10000, Loss: 0.00960706826299429\n",
      "Iteration: 9365/10000, Loss: 0.008800225332379341\n",
      "Iteration: 9366/10000, Loss: 0.01123573537915945\n",
      "Iteration: 9367/10000, Loss: 0.014827004633843899\n",
      "Iteration: 9368/10000, Loss: 0.011274709366261959\n",
      "Iteration: 9369/10000, Loss: 0.011659382842481136\n",
      "Iteration: 9370/10000, Loss: 0.011326651088893414\n",
      "Iteration: 9371/10000, Loss: 0.009921910241246223\n",
      "Iteration: 9372/10000, Loss: 0.007478600833564997\n",
      "Iteration: 9373/10000, Loss: 0.008278940804302692\n",
      "Iteration: 9374/10000, Loss: 0.009059255011379719\n",
      "Iteration: 9375/10000, Loss: 0.0123129952698946\n",
      "Iteration: 9376/10000, Loss: 0.009241566993296146\n",
      "Iteration: 9377/10000, Loss: 0.012854373082518578\n",
      "Iteration: 9378/10000, Loss: 0.013380443677306175\n",
      "Iteration: 9379/10000, Loss: 0.007516672369092703\n",
      "Iteration: 9380/10000, Loss: 0.008308316580951214\n",
      "Iteration: 9381/10000, Loss: 0.008545520715415478\n",
      "Iteration: 9382/10000, Loss: 0.009271964430809021\n",
      "Iteration: 9383/10000, Loss: 0.008608922362327576\n",
      "Iteration: 9384/10000, Loss: 0.008763907477259636\n",
      "Iteration: 9385/10000, Loss: 0.006309237331151962\n",
      "Iteration: 9386/10000, Loss: 0.009891519322991371\n",
      "Iteration: 9387/10000, Loss: 0.009539470076560974\n",
      "Iteration: 9388/10000, Loss: 0.006319853011518717\n",
      "Iteration: 9389/10000, Loss: 0.009818504564464092\n",
      "Iteration: 9390/10000, Loss: 0.013687940314412117\n",
      "Iteration: 9391/10000, Loss: 0.009255021810531616\n",
      "Iteration: 9392/10000, Loss: 0.011204141192138195\n",
      "Iteration: 9393/10000, Loss: 0.011628065258264542\n",
      "Iteration: 9394/10000, Loss: 0.011928091756999493\n",
      "Iteration: 9395/10000, Loss: 0.008239164017140865\n",
      "Iteration: 9396/10000, Loss: 0.012406369671225548\n",
      "Iteration: 9397/10000, Loss: 0.011058928444981575\n",
      "Iteration: 9398/10000, Loss: 0.009443235583603382\n",
      "Iteration: 9399/10000, Loss: 0.008386644534766674\n",
      "Iteration: 9400/10000, Loss: 0.00987675879150629\n",
      "Average test loss:  0.0025\n",
      "Iteration: 9401/10000, Loss: 0.011309601366519928\n",
      "Iteration: 9402/10000, Loss: 0.008785787969827652\n",
      "Iteration: 9403/10000, Loss: 0.008403528481721878\n",
      "Iteration: 9404/10000, Loss: 0.008540059439837933\n",
      "Iteration: 9405/10000, Loss: 0.010017943568527699\n",
      "Iteration: 9406/10000, Loss: 0.008798818103969097\n",
      "Iteration: 9407/10000, Loss: 0.010062403045594692\n",
      "Iteration: 9408/10000, Loss: 0.005322294309735298\n",
      "Iteration: 9409/10000, Loss: 0.009751084260642529\n",
      "Iteration: 9410/10000, Loss: 0.012191926129162312\n",
      "Iteration: 9411/10000, Loss: 0.010051775723695755\n",
      "Iteration: 9412/10000, Loss: 0.011378654278814793\n",
      "Iteration: 9413/10000, Loss: 0.00907493568956852\n",
      "Iteration: 9414/10000, Loss: 0.009449014440178871\n",
      "Iteration: 9415/10000, Loss: 0.010515577159821987\n",
      "Iteration: 9416/10000, Loss: 0.011129764840006828\n",
      "Iteration: 9417/10000, Loss: 0.009206525981426239\n",
      "Iteration: 9418/10000, Loss: 0.013860096223652363\n",
      "Iteration: 9419/10000, Loss: 0.010635828599333763\n",
      "Iteration: 9420/10000, Loss: 0.012642860412597656\n",
      "Iteration: 9421/10000, Loss: 0.013449713587760925\n",
      "Iteration: 9422/10000, Loss: 0.006972312927246094\n",
      "Iteration: 9423/10000, Loss: 0.009218321181833744\n",
      "Iteration: 9424/10000, Loss: 0.007476789876818657\n",
      "Iteration: 9425/10000, Loss: 0.008737882599234581\n",
      "Iteration: 9426/10000, Loss: 0.00617595948278904\n",
      "Iteration: 9427/10000, Loss: 0.006601919420063496\n",
      "Iteration: 9428/10000, Loss: 0.007502611260861158\n",
      "Iteration: 9429/10000, Loss: 0.008175086230039597\n",
      "Iteration: 9430/10000, Loss: 0.008216354995965958\n",
      "Iteration: 9431/10000, Loss: 0.007337420247495174\n",
      "Iteration: 9432/10000, Loss: 0.008818743750452995\n",
      "Iteration: 9433/10000, Loss: 0.007587182801216841\n",
      "Iteration: 9434/10000, Loss: 0.010133967734873295\n",
      "Iteration: 9435/10000, Loss: 0.011308133602142334\n",
      "Iteration: 9436/10000, Loss: 0.00463767908513546\n",
      "Iteration: 9437/10000, Loss: 0.01130366325378418\n",
      "Iteration: 9438/10000, Loss: 0.01249825768172741\n",
      "Iteration: 9439/10000, Loss: 0.012028531171381474\n",
      "Iteration: 9440/10000, Loss: 0.005665144417434931\n",
      "Iteration: 9441/10000, Loss: 0.008255179971456528\n",
      "Iteration: 9442/10000, Loss: 0.008199081756174564\n",
      "Iteration: 9443/10000, Loss: 0.008243878372013569\n",
      "Iteration: 9444/10000, Loss: 0.00869456585496664\n",
      "Iteration: 9445/10000, Loss: 0.00991074275225401\n",
      "Iteration: 9446/10000, Loss: 0.00494870962575078\n",
      "Iteration: 9447/10000, Loss: 0.010614805854856968\n",
      "Iteration: 9448/10000, Loss: 0.013067365624010563\n",
      "Iteration: 9449/10000, Loss: 0.010696898214519024\n",
      "Iteration: 9450/10000, Loss: 0.012017612345516682\n",
      "Iteration: 9451/10000, Loss: 0.008916634134948254\n",
      "Iteration: 9452/10000, Loss: 0.004517341498285532\n",
      "Iteration: 9453/10000, Loss: 0.010446139611303806\n",
      "Iteration: 9454/10000, Loss: 0.008030278608202934\n",
      "Iteration: 9455/10000, Loss: 0.015489757992327213\n",
      "Iteration: 9456/10000, Loss: 0.010658163577318192\n",
      "Iteration: 9457/10000, Loss: 0.009969975799322128\n",
      "Iteration: 9458/10000, Loss: 0.010186702944338322\n",
      "Iteration: 9459/10000, Loss: 0.010763167403638363\n",
      "Iteration: 9460/10000, Loss: 0.008703020401299\n",
      "Iteration: 9461/10000, Loss: 0.0071387398056685925\n",
      "Iteration: 9462/10000, Loss: 0.007123054005205631\n",
      "Iteration: 9463/10000, Loss: 0.010126370005309582\n",
      "Iteration: 9464/10000, Loss: 0.009731127880513668\n",
      "Iteration: 9465/10000, Loss: 0.011703898198902607\n",
      "Iteration: 9466/10000, Loss: 0.011629889719188213\n",
      "Iteration: 9467/10000, Loss: 0.0121300732716918\n",
      "Iteration: 9468/10000, Loss: 0.006584907416254282\n",
      "Iteration: 9469/10000, Loss: 0.009374476969242096\n",
      "Iteration: 9470/10000, Loss: 0.0077598439529538155\n",
      "Iteration: 9471/10000, Loss: 0.00975897815078497\n",
      "Iteration: 9472/10000, Loss: 0.011533601209521294\n",
      "Iteration: 9473/10000, Loss: 0.01187724620103836\n",
      "Iteration: 9474/10000, Loss: 0.007710686884820461\n",
      "Iteration: 9475/10000, Loss: 0.011070714332163334\n",
      "Iteration: 9476/10000, Loss: 0.008151383139193058\n",
      "Iteration: 9477/10000, Loss: 0.008674905635416508\n",
      "Iteration: 9478/10000, Loss: 0.011576605029404163\n",
      "Iteration: 9479/10000, Loss: 0.008288159035146236\n",
      "Iteration: 9480/10000, Loss: 0.009821481071412563\n",
      "Iteration: 9481/10000, Loss: 0.011828535236418247\n",
      "Iteration: 9482/10000, Loss: 0.006712895352393389\n",
      "Iteration: 9483/10000, Loss: 0.008549503982067108\n",
      "Iteration: 9484/10000, Loss: 0.012685930356383324\n",
      "Iteration: 9485/10000, Loss: 0.009872913360595703\n",
      "Iteration: 9486/10000, Loss: 0.008106499910354614\n",
      "Iteration: 9487/10000, Loss: 0.011809355579316616\n",
      "Iteration: 9488/10000, Loss: 0.0059132142923772335\n",
      "Iteration: 9489/10000, Loss: 0.012671778909862041\n",
      "Iteration: 9490/10000, Loss: 0.007511577568948269\n",
      "Iteration: 9491/10000, Loss: 0.009604902006685734\n",
      "Iteration: 9492/10000, Loss: 0.00650548143312335\n",
      "Iteration: 9493/10000, Loss: 0.008867488242685795\n",
      "Iteration: 9494/10000, Loss: 0.010405708104372025\n",
      "Iteration: 9495/10000, Loss: 0.00953145045787096\n",
      "Iteration: 9496/10000, Loss: 0.009594499133527279\n",
      "Iteration: 9497/10000, Loss: 0.006039449945092201\n",
      "Iteration: 9498/10000, Loss: 0.010158560238778591\n",
      "Iteration: 9499/10000, Loss: 0.011179319582879543\n",
      "Iteration: 9500/10000, Loss: 0.008316891267895699\n",
      "Average test loss:  0.0035\n",
      "Iteration: 9501/10000, Loss: 0.010578285902738571\n",
      "Iteration: 9502/10000, Loss: 0.008309753611683846\n",
      "Iteration: 9503/10000, Loss: 0.010992123745381832\n",
      "Iteration: 9504/10000, Loss: 0.007087104022502899\n",
      "Iteration: 9505/10000, Loss: 0.008949626237154007\n",
      "Iteration: 9506/10000, Loss: 0.008613805286586285\n",
      "Iteration: 9507/10000, Loss: 0.010559274815022945\n",
      "Iteration: 9508/10000, Loss: 0.008635543286800385\n",
      "Iteration: 9509/10000, Loss: 0.008563998155295849\n",
      "Iteration: 9510/10000, Loss: 0.007719063200056553\n",
      "Iteration: 9511/10000, Loss: 0.010584802366793156\n",
      "Iteration: 9512/10000, Loss: 0.00988731998950243\n",
      "Iteration: 9513/10000, Loss: 0.01078101247549057\n",
      "Iteration: 9514/10000, Loss: 0.012053409591317177\n",
      "Iteration: 9515/10000, Loss: 0.006238820496946573\n",
      "Iteration: 9516/10000, Loss: 0.01290892157703638\n",
      "Iteration: 9517/10000, Loss: 0.009867023676633835\n",
      "Iteration: 9518/10000, Loss: 0.007314663380384445\n",
      "Iteration: 9519/10000, Loss: 0.0075379349291324615\n",
      "Iteration: 9520/10000, Loss: 0.007999231107532978\n",
      "Iteration: 9521/10000, Loss: 0.005730368662625551\n",
      "Iteration: 9522/10000, Loss: 0.005994362290948629\n",
      "Iteration: 9523/10000, Loss: 0.007697404827922583\n",
      "Iteration: 9524/10000, Loss: 0.010524790734052658\n",
      "Iteration: 9525/10000, Loss: 0.012033755891025066\n",
      "Iteration: 9526/10000, Loss: 0.008535741828382015\n",
      "Iteration: 9527/10000, Loss: 0.008944062516093254\n",
      "Iteration: 9528/10000, Loss: 0.007386252284049988\n",
      "Iteration: 9529/10000, Loss: 0.00887344777584076\n",
      "Iteration: 9530/10000, Loss: 0.01080869697034359\n",
      "Iteration: 9531/10000, Loss: 0.006340633146464825\n",
      "Iteration: 9532/10000, Loss: 0.008573011495172977\n",
      "Iteration: 9533/10000, Loss: 0.006977026350796223\n",
      "Iteration: 9534/10000, Loss: 0.008220191113650799\n",
      "Iteration: 9535/10000, Loss: 0.006975815165787935\n",
      "Iteration: 9536/10000, Loss: 0.010026747360825539\n",
      "Iteration: 9537/10000, Loss: 0.01275560725480318\n",
      "Iteration: 9538/10000, Loss: 0.006445418577641249\n",
      "Iteration: 9539/10000, Loss: 0.007529754191637039\n",
      "Iteration: 9540/10000, Loss: 0.011625594459474087\n",
      "Iteration: 9541/10000, Loss: 0.005746468435972929\n",
      "Iteration: 9542/10000, Loss: 0.01175691094249487\n",
      "Iteration: 9543/10000, Loss: 0.012181341648101807\n",
      "Iteration: 9544/10000, Loss: 0.007891125045716763\n",
      "Iteration: 9545/10000, Loss: 0.00938097108155489\n",
      "Iteration: 9546/10000, Loss: 0.009400594048202038\n",
      "Iteration: 9547/10000, Loss: 0.00764977652579546\n",
      "Iteration: 9548/10000, Loss: 0.009781663306057453\n",
      "Iteration: 9549/10000, Loss: 0.00708899088203907\n",
      "Iteration: 9550/10000, Loss: 0.009154547937214375\n",
      "Iteration: 9551/10000, Loss: 0.005414078943431377\n",
      "Iteration: 9552/10000, Loss: 0.005129508674144745\n",
      "Iteration: 9553/10000, Loss: 0.009862229228019714\n",
      "Iteration: 9554/10000, Loss: 0.0075418646447360516\n",
      "Iteration: 9555/10000, Loss: 0.010636960156261921\n",
      "Iteration: 9556/10000, Loss: 0.012473462149500847\n",
      "Iteration: 9557/10000, Loss: 0.012001639232039452\n",
      "Iteration: 9558/10000, Loss: 0.0099673205986619\n",
      "Iteration: 9559/10000, Loss: 0.010842767544090748\n",
      "Iteration: 9560/10000, Loss: 0.01111332606524229\n",
      "Iteration: 9561/10000, Loss: 0.007829844951629639\n",
      "Iteration: 9562/10000, Loss: 0.010160096921026707\n",
      "Iteration: 9563/10000, Loss: 0.009684786200523376\n",
      "Iteration: 9564/10000, Loss: 0.006791750900447369\n",
      "Iteration: 9565/10000, Loss: 0.009936120361089706\n",
      "Iteration: 9566/10000, Loss: 0.009216240607202053\n",
      "Iteration: 9567/10000, Loss: 0.008946859277784824\n",
      "Iteration: 9568/10000, Loss: 0.01270047202706337\n",
      "Iteration: 9569/10000, Loss: 0.00936589203774929\n",
      "Iteration: 9570/10000, Loss: 0.006593747064471245\n",
      "Iteration: 9571/10000, Loss: 0.006134639494121075\n",
      "Iteration: 9572/10000, Loss: 0.012004324235022068\n",
      "Iteration: 9573/10000, Loss: 0.003780362429097295\n",
      "Iteration: 9574/10000, Loss: 0.009521329775452614\n",
      "Iteration: 9575/10000, Loss: 0.008240113034844398\n",
      "Iteration: 9576/10000, Loss: 0.005012630484998226\n",
      "Iteration: 9577/10000, Loss: 0.007959209382534027\n",
      "Iteration: 9578/10000, Loss: 0.01607857085764408\n",
      "Iteration: 9579/10000, Loss: 0.00912310741841793\n",
      "Iteration: 9580/10000, Loss: 0.00554686039686203\n",
      "Iteration: 9581/10000, Loss: 0.009751548059284687\n",
      "Iteration: 9582/10000, Loss: 0.008227045647799969\n",
      "Iteration: 9583/10000, Loss: 0.004054276738315821\n",
      "Iteration: 9584/10000, Loss: 0.013847338035702705\n",
      "Iteration: 9585/10000, Loss: 0.008701473474502563\n",
      "Iteration: 9586/10000, Loss: 0.011740267276763916\n",
      "Iteration: 9587/10000, Loss: 0.007633440662175417\n",
      "Iteration: 9588/10000, Loss: 0.0073995767161250114\n",
      "Iteration: 9589/10000, Loss: 0.014784291386604309\n",
      "Iteration: 9590/10000, Loss: 0.008355293422937393\n",
      "Iteration: 9591/10000, Loss: 0.006192415487021208\n",
      "Iteration: 9592/10000, Loss: 0.011851859278976917\n",
      "Iteration: 9593/10000, Loss: 0.008018127642571926\n",
      "Iteration: 9594/10000, Loss: 0.008702677674591541\n",
      "Iteration: 9595/10000, Loss: 0.0093437684699893\n",
      "Iteration: 9596/10000, Loss: 0.008449002169072628\n",
      "Iteration: 9597/10000, Loss: 0.009051351808011532\n",
      "Iteration: 9598/10000, Loss: 0.010770479217171669\n",
      "Iteration: 9599/10000, Loss: 0.01211458072066307\n",
      "Iteration: 9600/10000, Loss: 0.007012126035988331\n",
      "Average test loss:  0.0026\n",
      "Iteration: 9601/10000, Loss: 0.009053314104676247\n",
      "Iteration: 9602/10000, Loss: 0.009778214618563652\n",
      "Iteration: 9603/10000, Loss: 0.010826910845935345\n",
      "Iteration: 9604/10000, Loss: 0.008403211832046509\n",
      "Iteration: 9605/10000, Loss: 0.009504272602498531\n",
      "Iteration: 9606/10000, Loss: 0.007911643013358116\n",
      "Iteration: 9607/10000, Loss: 0.008276151493191719\n",
      "Iteration: 9608/10000, Loss: 0.008087924681603909\n",
      "Iteration: 9609/10000, Loss: 0.004778233822435141\n",
      "Iteration: 9610/10000, Loss: 0.007499886676669121\n",
      "Iteration: 9611/10000, Loss: 0.008242853917181492\n",
      "Iteration: 9612/10000, Loss: 0.007066973485052586\n",
      "Iteration: 9613/10000, Loss: 0.007635169196873903\n",
      "Iteration: 9614/10000, Loss: 0.011565836146473885\n",
      "Iteration: 9615/10000, Loss: 0.009371047839522362\n",
      "Iteration: 9616/10000, Loss: 0.007872462272644043\n",
      "Iteration: 9617/10000, Loss: 0.010562584735453129\n",
      "Iteration: 9618/10000, Loss: 0.010318202897906303\n",
      "Iteration: 9619/10000, Loss: 0.0044693551026284695\n",
      "Iteration: 9620/10000, Loss: 0.00810184609144926\n",
      "Iteration: 9621/10000, Loss: 0.012439945712685585\n",
      "Iteration: 9622/10000, Loss: 0.0068535213358700275\n",
      "Iteration: 9623/10000, Loss: 0.0077972630970180035\n",
      "Iteration: 9624/10000, Loss: 0.009242767468094826\n",
      "Iteration: 9625/10000, Loss: 0.00694261584430933\n",
      "Iteration: 9626/10000, Loss: 0.006324635818600655\n",
      "Iteration: 9627/10000, Loss: 0.006815999746322632\n",
      "Iteration: 9628/10000, Loss: 0.011071322485804558\n",
      "Iteration: 9629/10000, Loss: 0.009583957493305206\n",
      "Iteration: 9630/10000, Loss: 0.008405557833611965\n",
      "Iteration: 9631/10000, Loss: 0.009558427147567272\n",
      "Iteration: 9632/10000, Loss: 0.0059244027361273766\n",
      "Iteration: 9633/10000, Loss: 0.013003240339457989\n",
      "Iteration: 9634/10000, Loss: 0.006804380565881729\n",
      "Iteration: 9635/10000, Loss: 0.0123524758964777\n",
      "Iteration: 9636/10000, Loss: 0.010147222317755222\n",
      "Iteration: 9637/10000, Loss: 0.007485023234039545\n",
      "Iteration: 9638/10000, Loss: 0.012845387682318687\n",
      "Iteration: 9639/10000, Loss: 0.01103608775883913\n",
      "Iteration: 9640/10000, Loss: 0.005953875835984945\n",
      "Iteration: 9641/10000, Loss: 0.007693228777498007\n",
      "Iteration: 9642/10000, Loss: 0.008860970847308636\n",
      "Iteration: 9643/10000, Loss: 0.011575604788959026\n",
      "Iteration: 9644/10000, Loss: 0.0074731349013745785\n",
      "Iteration: 9645/10000, Loss: 0.008132628165185452\n",
      "Iteration: 9646/10000, Loss: 0.006912965793162584\n",
      "Iteration: 9647/10000, Loss: 0.008210575208067894\n",
      "Iteration: 9648/10000, Loss: 0.01032069232314825\n",
      "Iteration: 9649/10000, Loss: 0.009029008448123932\n",
      "Iteration: 9650/10000, Loss: 0.008224000222980976\n",
      "Iteration: 9651/10000, Loss: 0.00901846494525671\n",
      "Iteration: 9652/10000, Loss: 0.0037300861440598965\n",
      "Iteration: 9653/10000, Loss: 0.00786456186324358\n",
      "Iteration: 9654/10000, Loss: 0.007443971000611782\n",
      "Iteration: 9655/10000, Loss: 0.012152907438576221\n",
      "Iteration: 9656/10000, Loss: 0.008066399022936821\n",
      "Iteration: 9657/10000, Loss: 0.003452006261795759\n",
      "Iteration: 9658/10000, Loss: 0.009036523289978504\n",
      "Iteration: 9659/10000, Loss: 0.009842111729085445\n",
      "Iteration: 9660/10000, Loss: 0.008167014457285404\n",
      "Iteration: 9661/10000, Loss: 0.009852384217083454\n",
      "Iteration: 9662/10000, Loss: 0.010090424679219723\n",
      "Iteration: 9663/10000, Loss: 0.01171506941318512\n",
      "Iteration: 9664/10000, Loss: 0.008525323122739792\n",
      "Iteration: 9665/10000, Loss: 0.0062645296566188335\n",
      "Iteration: 9666/10000, Loss: 0.008940571919083595\n",
      "Iteration: 9667/10000, Loss: 0.00984069425612688\n",
      "Iteration: 9668/10000, Loss: 0.007193890865892172\n",
      "Iteration: 9669/10000, Loss: 0.00955888070166111\n",
      "Iteration: 9670/10000, Loss: 0.011825112625956535\n",
      "Iteration: 9671/10000, Loss: 0.008136890828609467\n",
      "Iteration: 9672/10000, Loss: 0.012281081639230251\n",
      "Iteration: 9673/10000, Loss: 0.007713783998042345\n",
      "Iteration: 9674/10000, Loss: 0.006587616167962551\n",
      "Iteration: 9675/10000, Loss: 0.007294180803000927\n",
      "Iteration: 9676/10000, Loss: 0.009766807779669762\n",
      "Iteration: 9677/10000, Loss: 0.011707262136042118\n",
      "Iteration: 9678/10000, Loss: 0.007206886075437069\n",
      "Iteration: 9679/10000, Loss: 0.006948506459593773\n",
      "Iteration: 9680/10000, Loss: 0.010281556285917759\n",
      "Iteration: 9681/10000, Loss: 0.010285353288054466\n",
      "Iteration: 9682/10000, Loss: 0.010060479864478111\n",
      "Iteration: 9683/10000, Loss: 0.005704059731215239\n",
      "Iteration: 9684/10000, Loss: 0.00916445441544056\n",
      "Iteration: 9685/10000, Loss: 0.008799120783805847\n",
      "Iteration: 9686/10000, Loss: 0.010930614545941353\n",
      "Iteration: 9687/10000, Loss: 0.008092304691672325\n",
      "Iteration: 9688/10000, Loss: 0.007735136896371841\n",
      "Iteration: 9689/10000, Loss: 0.00953212846070528\n",
      "Iteration: 9690/10000, Loss: 0.009276485070586205\n",
      "Iteration: 9691/10000, Loss: 0.007399267517030239\n",
      "Iteration: 9692/10000, Loss: 0.005889095366001129\n",
      "Iteration: 9693/10000, Loss: 0.003496157703921199\n",
      "Iteration: 9694/10000, Loss: 0.008424414321780205\n",
      "Iteration: 9695/10000, Loss: 0.012623170390725136\n",
      "Iteration: 9696/10000, Loss: 0.015107998624444008\n",
      "Iteration: 9697/10000, Loss: 0.008457820862531662\n",
      "Iteration: 9698/10000, Loss: 0.009553085081279278\n",
      "Iteration: 9699/10000, Loss: 0.011012988165020943\n",
      "Iteration: 9700/10000, Loss: 0.010313308797776699\n",
      "Average test loss:  0.0032\n",
      "Iteration: 9701/10000, Loss: 0.00930943712592125\n",
      "Iteration: 9702/10000, Loss: 0.011586866341531277\n",
      "Iteration: 9703/10000, Loss: 0.009325851686298847\n",
      "Iteration: 9704/10000, Loss: 0.010073789395391941\n",
      "Iteration: 9705/10000, Loss: 0.009038515388965607\n",
      "Iteration: 9706/10000, Loss: 0.012518755160272121\n",
      "Iteration: 9707/10000, Loss: 0.007515523582696915\n",
      "Iteration: 9708/10000, Loss: 0.005852448288351297\n",
      "Iteration: 9709/10000, Loss: 0.006870121229439974\n",
      "Iteration: 9710/10000, Loss: 0.006176681723445654\n",
      "Iteration: 9711/10000, Loss: 0.007671286351978779\n",
      "Iteration: 9712/10000, Loss: 0.007418920285999775\n",
      "Iteration: 9713/10000, Loss: 0.00954591203480959\n",
      "Iteration: 9714/10000, Loss: 0.009971546940505505\n",
      "Iteration: 9715/10000, Loss: 0.010200620628893375\n",
      "Iteration: 9716/10000, Loss: 0.007803136017173529\n",
      "Iteration: 9717/10000, Loss: 0.0032271661330014467\n",
      "Iteration: 9718/10000, Loss: 0.012996934354305267\n",
      "Iteration: 9719/10000, Loss: 0.008252742700278759\n",
      "Iteration: 9720/10000, Loss: 0.0075437407940626144\n",
      "Iteration: 9721/10000, Loss: 0.005616537760943174\n",
      "Iteration: 9722/10000, Loss: 0.008790318854153156\n",
      "Iteration: 9723/10000, Loss: 0.01004132628440857\n",
      "Iteration: 9724/10000, Loss: 0.006843012757599354\n",
      "Iteration: 9725/10000, Loss: 0.008254117332398891\n",
      "Iteration: 9726/10000, Loss: 0.006815948989242315\n",
      "Iteration: 9727/10000, Loss: 0.013378103263676167\n",
      "Iteration: 9728/10000, Loss: 0.007219729479402304\n",
      "Iteration: 9729/10000, Loss: 0.00574183464050293\n",
      "Iteration: 9730/10000, Loss: 0.012772114016115665\n",
      "Iteration: 9731/10000, Loss: 0.00725206546485424\n",
      "Iteration: 9732/10000, Loss: 0.006167509593069553\n",
      "Iteration: 9733/10000, Loss: 0.006473300512880087\n",
      "Iteration: 9734/10000, Loss: 0.007354290224611759\n",
      "Iteration: 9735/10000, Loss: 0.013618647120893002\n",
      "Iteration: 9736/10000, Loss: 0.010120808146893978\n",
      "Iteration: 9737/10000, Loss: 0.01216920930892229\n",
      "Iteration: 9738/10000, Loss: 0.011848797090351582\n",
      "Iteration: 9739/10000, Loss: 0.009503093548119068\n",
      "Iteration: 9740/10000, Loss: 0.009947421960532665\n",
      "Iteration: 9741/10000, Loss: 0.007497095502912998\n",
      "Iteration: 9742/10000, Loss: 0.01059713214635849\n",
      "Iteration: 9743/10000, Loss: 0.006198638118803501\n",
      "Iteration: 9744/10000, Loss: 0.00658799335360527\n",
      "Iteration: 9745/10000, Loss: 0.01232172455638647\n",
      "Iteration: 9746/10000, Loss: 0.008536417037248611\n",
      "Iteration: 9747/10000, Loss: 0.007877192460000515\n",
      "Iteration: 9748/10000, Loss: 0.010617237538099289\n",
      "Iteration: 9749/10000, Loss: 0.012530188076198101\n",
      "Iteration: 9750/10000, Loss: 0.010061315260827541\n",
      "Iteration: 9751/10000, Loss: 0.007759482134133577\n",
      "Iteration: 9752/10000, Loss: 0.006434761453419924\n",
      "Iteration: 9753/10000, Loss: 0.008030992932617664\n",
      "Iteration: 9754/10000, Loss: 0.007237210404127836\n",
      "Iteration: 9755/10000, Loss: 0.007268412038683891\n",
      "Iteration: 9756/10000, Loss: 0.012448923662304878\n",
      "Iteration: 9757/10000, Loss: 0.00830503273755312\n",
      "Iteration: 9758/10000, Loss: 0.008976314216852188\n",
      "Iteration: 9759/10000, Loss: 0.013781803660094738\n",
      "Iteration: 9760/10000, Loss: 0.00880539882928133\n",
      "Iteration: 9761/10000, Loss: 0.009116236120462418\n",
      "Iteration: 9762/10000, Loss: 0.009476564824581146\n",
      "Iteration: 9763/10000, Loss: 0.009745195508003235\n",
      "Iteration: 9764/10000, Loss: 0.0064803240820765495\n",
      "Iteration: 9765/10000, Loss: 0.006390324793756008\n",
      "Iteration: 9766/10000, Loss: 0.011141645722091198\n",
      "Iteration: 9767/10000, Loss: 0.006634306162595749\n",
      "Iteration: 9768/10000, Loss: 0.006571623496711254\n",
      "Iteration: 9769/10000, Loss: 0.010551268234848976\n",
      "Iteration: 9770/10000, Loss: 0.003989604767411947\n",
      "Iteration: 9771/10000, Loss: 0.01000769529491663\n",
      "Iteration: 9772/10000, Loss: 0.008098408579826355\n",
      "Iteration: 9773/10000, Loss: 0.007567041553556919\n",
      "Iteration: 9774/10000, Loss: 0.004753082990646362\n",
      "Iteration: 9775/10000, Loss: 0.008008204400539398\n",
      "Iteration: 9776/10000, Loss: 0.010626859962940216\n",
      "Iteration: 9777/10000, Loss: 0.006766689009964466\n",
      "Iteration: 9778/10000, Loss: 0.009073787368834019\n",
      "Iteration: 9779/10000, Loss: 0.00933785829693079\n",
      "Iteration: 9780/10000, Loss: 0.007991683669388294\n",
      "Iteration: 9781/10000, Loss: 0.006354181095957756\n",
      "Iteration: 9782/10000, Loss: 0.005625492427498102\n",
      "Iteration: 9783/10000, Loss: 0.008869919925928116\n",
      "Iteration: 9784/10000, Loss: 0.004622337408363819\n",
      "Iteration: 9785/10000, Loss: 0.008607050403952599\n",
      "Iteration: 9786/10000, Loss: 0.006011419929563999\n",
      "Iteration: 9787/10000, Loss: 0.005921654868870974\n",
      "Iteration: 9788/10000, Loss: 0.007441565860062838\n",
      "Iteration: 9789/10000, Loss: 0.006911527365446091\n",
      "Iteration: 9790/10000, Loss: 0.007520849350839853\n",
      "Iteration: 9791/10000, Loss: 0.006909731775522232\n",
      "Iteration: 9792/10000, Loss: 0.009967586025595665\n",
      "Iteration: 9793/10000, Loss: 0.007655342109501362\n",
      "Iteration: 9794/10000, Loss: 0.010437190532684326\n",
      "Iteration: 9795/10000, Loss: 0.008852455765008926\n",
      "Iteration: 9796/10000, Loss: 0.010737787000834942\n",
      "Iteration: 9797/10000, Loss: 0.008071879856288433\n",
      "Iteration: 9798/10000, Loss: 0.012437756173312664\n",
      "Iteration: 9799/10000, Loss: 0.005565036553889513\n",
      "Iteration: 9800/10000, Loss: 0.009251114912331104\n",
      "Average test loss:  0.0022\n",
      "Iteration: 9801/10000, Loss: 0.006075732875615358\n",
      "Iteration: 9802/10000, Loss: 0.006778139621019363\n",
      "Iteration: 9803/10000, Loss: 0.007727089338004589\n",
      "Iteration: 9804/10000, Loss: 0.010905295610427856\n",
      "Iteration: 9805/10000, Loss: 0.013434167020022869\n",
      "Iteration: 9806/10000, Loss: 0.013704869896173477\n",
      "Iteration: 9807/10000, Loss: 0.009144566021859646\n",
      "Iteration: 9808/10000, Loss: 0.011452656239271164\n",
      "Iteration: 9809/10000, Loss: 0.00772137101739645\n",
      "Iteration: 9810/10000, Loss: 0.011266288347542286\n",
      "Iteration: 9811/10000, Loss: 0.011932705529034138\n",
      "Iteration: 9812/10000, Loss: 0.008865348063409328\n",
      "Iteration: 9813/10000, Loss: 0.006490671541541815\n",
      "Iteration: 9814/10000, Loss: 0.00990170706063509\n",
      "Iteration: 9815/10000, Loss: 0.005999700631946325\n",
      "Iteration: 9816/10000, Loss: 0.007410530932247639\n",
      "Iteration: 9817/10000, Loss: 0.010158577933907509\n",
      "Iteration: 9818/10000, Loss: 0.011215431615710258\n",
      "Iteration: 9819/10000, Loss: 0.006409450434148312\n",
      "Iteration: 9820/10000, Loss: 0.007294437848031521\n",
      "Iteration: 9821/10000, Loss: 0.012670367956161499\n",
      "Iteration: 9822/10000, Loss: 0.010778247378766537\n",
      "Iteration: 9823/10000, Loss: 0.009514507837593555\n",
      "Iteration: 9824/10000, Loss: 0.010263403877615929\n",
      "Iteration: 9825/10000, Loss: 0.01116914302110672\n",
      "Iteration: 9826/10000, Loss: 0.007973377592861652\n",
      "Iteration: 9827/10000, Loss: 0.014744410291314125\n",
      "Iteration: 9828/10000, Loss: 0.007493475917726755\n",
      "Iteration: 9829/10000, Loss: 0.007725055329501629\n",
      "Iteration: 9830/10000, Loss: 0.008115988224744797\n",
      "Iteration: 9831/10000, Loss: 0.008838137611746788\n",
      "Iteration: 9832/10000, Loss: 0.0069649843499064445\n",
      "Iteration: 9833/10000, Loss: 0.006700405851006508\n",
      "Iteration: 9834/10000, Loss: 0.007008349522948265\n",
      "Iteration: 9835/10000, Loss: 0.015671106055378914\n",
      "Iteration: 9836/10000, Loss: 0.009622768498957157\n",
      "Iteration: 9837/10000, Loss: 0.008910741657018661\n",
      "Iteration: 9838/10000, Loss: 0.010309434495866299\n",
      "Iteration: 9839/10000, Loss: 0.004900121595710516\n",
      "Iteration: 9840/10000, Loss: 0.007184978108853102\n",
      "Iteration: 9841/10000, Loss: 0.01162190455943346\n",
      "Iteration: 9842/10000, Loss: 0.006931770127266645\n",
      "Iteration: 9843/10000, Loss: 0.005298461765050888\n",
      "Iteration: 9844/10000, Loss: 0.0058129336684942245\n",
      "Iteration: 9845/10000, Loss: 0.010514074936509132\n",
      "Iteration: 9846/10000, Loss: 0.006508524063974619\n",
      "Iteration: 9847/10000, Loss: 0.011801902204751968\n",
      "Iteration: 9848/10000, Loss: 0.010444393381476402\n",
      "Iteration: 9849/10000, Loss: 0.009130961261689663\n",
      "Iteration: 9850/10000, Loss: 0.011870189569890499\n",
      "Iteration: 9851/10000, Loss: 0.01133667305111885\n",
      "Iteration: 9852/10000, Loss: 0.0064092655666172504\n",
      "Iteration: 9853/10000, Loss: 0.009015858173370361\n",
      "Iteration: 9854/10000, Loss: 0.009740790352225304\n",
      "Iteration: 9855/10000, Loss: 0.00806376151740551\n",
      "Iteration: 9856/10000, Loss: 0.009063695557415485\n",
      "Iteration: 9857/10000, Loss: 0.007463021669536829\n",
      "Iteration: 9858/10000, Loss: 0.012765614315867424\n",
      "Iteration: 9859/10000, Loss: 0.01149987243115902\n",
      "Iteration: 9860/10000, Loss: 0.005653835833072662\n",
      "Iteration: 9861/10000, Loss: 0.009364919736981392\n",
      "Iteration: 9862/10000, Loss: 0.005940433591604233\n",
      "Iteration: 9863/10000, Loss: 0.009308554232120514\n",
      "Iteration: 9864/10000, Loss: 0.0080099543556571\n",
      "Iteration: 9865/10000, Loss: 0.008702736347913742\n",
      "Iteration: 9866/10000, Loss: 0.010608852840960026\n",
      "Iteration: 9867/10000, Loss: 0.00946297962218523\n",
      "Iteration: 9868/10000, Loss: 0.009634925983846188\n",
      "Iteration: 9869/10000, Loss: 0.008376031182706356\n",
      "Iteration: 9870/10000, Loss: 0.009150361642241478\n",
      "Iteration: 9871/10000, Loss: 0.00872416328638792\n",
      "Iteration: 9872/10000, Loss: 0.010639085434377193\n",
      "Iteration: 9873/10000, Loss: 0.007183640729635954\n",
      "Iteration: 9874/10000, Loss: 0.00690988264977932\n",
      "Iteration: 9875/10000, Loss: 0.011648464947938919\n",
      "Iteration: 9876/10000, Loss: 0.007614263333380222\n",
      "Iteration: 9877/10000, Loss: 0.008548724465072155\n",
      "Iteration: 9878/10000, Loss: 0.007879097014665604\n",
      "Iteration: 9879/10000, Loss: 0.008799715898931026\n",
      "Iteration: 9880/10000, Loss: 0.00990599300712347\n",
      "Iteration: 9881/10000, Loss: 0.007954085245728493\n",
      "Iteration: 9882/10000, Loss: 0.011825015768408775\n",
      "Iteration: 9883/10000, Loss: 0.006500231102108955\n",
      "Iteration: 9884/10000, Loss: 0.00893422868102789\n",
      "Iteration: 9885/10000, Loss: 0.007821642793715\n",
      "Iteration: 9886/10000, Loss: 0.013155640102922916\n",
      "Iteration: 9887/10000, Loss: 0.011540844105184078\n",
      "Iteration: 9888/10000, Loss: 0.007791711483150721\n",
      "Iteration: 9889/10000, Loss: 0.007645877078175545\n",
      "Iteration: 9890/10000, Loss: 0.008262288756668568\n",
      "Iteration: 9891/10000, Loss: 0.009223061613738537\n",
      "Iteration: 9892/10000, Loss: 0.009746700525283813\n",
      "Iteration: 9893/10000, Loss: 0.014658280648291111\n",
      "Iteration: 9894/10000, Loss: 0.010378322564065456\n",
      "Iteration: 9895/10000, Loss: 0.006982030812650919\n",
      "Iteration: 9896/10000, Loss: 0.006425208877772093\n",
      "Iteration: 9897/10000, Loss: 0.008361352607607841\n",
      "Iteration: 9898/10000, Loss: 0.0072824060916900635\n",
      "Iteration: 9899/10000, Loss: 0.010903488844633102\n",
      "Iteration: 9900/10000, Loss: 0.008677930571138859\n",
      "Average test loss:  0.0036\n",
      "Iteration: 9901/10000, Loss: 0.009724587202072144\n",
      "Iteration: 9902/10000, Loss: 0.011707603931427002\n",
      "Iteration: 9903/10000, Loss: 0.011364338919520378\n",
      "Iteration: 9904/10000, Loss: 0.008098084479570389\n",
      "Iteration: 9905/10000, Loss: 0.009023269638419151\n",
      "Iteration: 9906/10000, Loss: 0.010444894433021545\n",
      "Iteration: 9907/10000, Loss: 0.004303911700844765\n",
      "Iteration: 9908/10000, Loss: 0.007820246741175652\n",
      "Iteration: 9909/10000, Loss: 0.01020747795701027\n",
      "Iteration: 9910/10000, Loss: 0.011621466837823391\n",
      "Iteration: 9911/10000, Loss: 0.005755115300416946\n",
      "Iteration: 9912/10000, Loss: 0.011262837797403336\n",
      "Iteration: 9913/10000, Loss: 0.010169483721256256\n",
      "Iteration: 9914/10000, Loss: 0.006102482322603464\n",
      "Iteration: 9915/10000, Loss: 0.008096585050225258\n",
      "Iteration: 9916/10000, Loss: 0.009891889989376068\n",
      "Iteration: 9917/10000, Loss: 0.009784805588424206\n",
      "Iteration: 9918/10000, Loss: 0.009333101101219654\n",
      "Iteration: 9919/10000, Loss: 0.004954934120178223\n",
      "Iteration: 9920/10000, Loss: 0.009372190572321415\n",
      "Iteration: 9921/10000, Loss: 0.008143465965986252\n",
      "Iteration: 9922/10000, Loss: 0.009381060488522053\n",
      "Iteration: 9923/10000, Loss: 0.010560575872659683\n",
      "Iteration: 9924/10000, Loss: 0.012384608387947083\n",
      "Iteration: 9925/10000, Loss: 0.006665444932878017\n",
      "Iteration: 9926/10000, Loss: 0.007964919321238995\n",
      "Iteration: 9927/10000, Loss: 0.012831166386604309\n",
      "Iteration: 9928/10000, Loss: 0.007852591574192047\n",
      "Iteration: 9929/10000, Loss: 0.013227528892457485\n",
      "Iteration: 9930/10000, Loss: 0.013085735961794853\n",
      "Iteration: 9931/10000, Loss: 0.00798127893358469\n",
      "Iteration: 9932/10000, Loss: 0.010056602768599987\n",
      "Iteration: 9933/10000, Loss: 0.00915084220468998\n",
      "Iteration: 9934/10000, Loss: 0.006752657704055309\n",
      "Iteration: 9935/10000, Loss: 0.006257898639887571\n",
      "Iteration: 9936/10000, Loss: 0.010679160244762897\n",
      "Iteration: 9937/10000, Loss: 0.008053180761635303\n",
      "Iteration: 9938/10000, Loss: 0.005204509012401104\n",
      "Iteration: 9939/10000, Loss: 0.008544896729290485\n",
      "Iteration: 9940/10000, Loss: 0.012771464884281158\n",
      "Iteration: 9941/10000, Loss: 0.009103595279157162\n",
      "Iteration: 9942/10000, Loss: 0.008516548201441765\n",
      "Iteration: 9943/10000, Loss: 0.008825177326798439\n",
      "Iteration: 9944/10000, Loss: 0.011400222778320312\n",
      "Iteration: 9945/10000, Loss: 0.00849513616412878\n",
      "Iteration: 9946/10000, Loss: 0.013778897002339363\n",
      "Iteration: 9947/10000, Loss: 0.015801817178726196\n",
      "Iteration: 9948/10000, Loss: 0.006393400952219963\n",
      "Iteration: 9949/10000, Loss: 0.009529397822916508\n",
      "Iteration: 9950/10000, Loss: 0.006687897723168135\n",
      "Iteration: 9951/10000, Loss: 0.01096375286579132\n",
      "Iteration: 9952/10000, Loss: 0.00598004087805748\n",
      "Iteration: 9953/10000, Loss: 0.00622417451813817\n",
      "Iteration: 9954/10000, Loss: 0.008290793746709824\n",
      "Iteration: 9955/10000, Loss: 0.006812973879277706\n",
      "Iteration: 9956/10000, Loss: 0.00949838012456894\n",
      "Iteration: 9957/10000, Loss: 0.008189484477043152\n",
      "Iteration: 9958/10000, Loss: 0.0061281342059373856\n",
      "Iteration: 9959/10000, Loss: 0.009365726262331009\n",
      "Iteration: 9960/10000, Loss: 0.0034769040066748857\n",
      "Iteration: 9961/10000, Loss: 0.008558614179491997\n",
      "Iteration: 9962/10000, Loss: 0.00894149113446474\n",
      "Iteration: 9963/10000, Loss: 0.008092820644378662\n",
      "Iteration: 9964/10000, Loss: 0.01171621959656477\n",
      "Iteration: 9965/10000, Loss: 0.0067093647085130215\n",
      "Iteration: 9966/10000, Loss: 0.01069855410605669\n",
      "Iteration: 9967/10000, Loss: 0.007375394459813833\n",
      "Iteration: 9968/10000, Loss: 0.005500206258147955\n",
      "Iteration: 9969/10000, Loss: 0.007366374135017395\n",
      "Iteration: 9970/10000, Loss: 0.008828531950712204\n",
      "Iteration: 9971/10000, Loss: 0.01153492834419012\n",
      "Iteration: 9972/10000, Loss: 0.00938136875629425\n",
      "Iteration: 9973/10000, Loss: 0.009157119318842888\n",
      "Iteration: 9974/10000, Loss: 0.008193663321435452\n",
      "Iteration: 9975/10000, Loss: 0.007468757219612598\n",
      "Iteration: 9976/10000, Loss: 0.010456746444106102\n",
      "Iteration: 9977/10000, Loss: 0.008507621474564075\n",
      "Iteration: 9978/10000, Loss: 0.014318961650133133\n",
      "Iteration: 9979/10000, Loss: 0.004792933352291584\n",
      "Iteration: 9980/10000, Loss: 0.00790080614387989\n",
      "Iteration: 9981/10000, Loss: 0.011041669175028801\n",
      "Iteration: 9982/10000, Loss: 0.006431071553379297\n",
      "Iteration: 9983/10000, Loss: 0.006285551469773054\n",
      "Iteration: 9984/10000, Loss: 0.008282286114990711\n",
      "Iteration: 9985/10000, Loss: 0.009397572837769985\n",
      "Iteration: 9986/10000, Loss: 0.009694165550172329\n",
      "Iteration: 9987/10000, Loss: 0.009067431092262268\n",
      "Iteration: 9988/10000, Loss: 0.008087906055152416\n",
      "Iteration: 9989/10000, Loss: 0.007674978580325842\n",
      "Iteration: 9990/10000, Loss: 0.006484124343842268\n",
      "Iteration: 9991/10000, Loss: 0.010661687701940536\n",
      "Iteration: 9992/10000, Loss: 0.010199555195868015\n",
      "Iteration: 9993/10000, Loss: 0.00668711680918932\n",
      "Iteration: 9994/10000, Loss: 0.01122978888452053\n",
      "Iteration: 9995/10000, Loss: 0.00778141338378191\n",
      "Iteration: 9996/10000, Loss: 0.00950926635414362\n",
      "Iteration: 9997/10000, Loss: 0.008504077792167664\n",
      "Iteration: 9998/10000, Loss: 0.011119559407234192\n",
      "Iteration: 9999/10000, Loss: 0.008421849459409714\n",
      "Iteration: 10000/10000, Loss: 0.005747240502387285\n",
      "Average test loss:  0.0059\n",
      "Training took 126.564s in total.\n"
     ]
    }
   ],
   "source": [
    "# CUDA device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {0}'.format(device))\n",
    "\n",
    "# Build the model\n",
    "num_class = 4\n",
    "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
    "model = model.to(device)\n",
    "params = list(model.parameters())\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "# Segmentation loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Datasets\n",
    "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
    "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
    "\n",
    "# Train the model\n",
    "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
    "num_iter = 10000\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "start = time.time()\n",
    "for it in range(1, 1 + num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = train_set.get_random_batch(train_batch_size)\n",
    "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    logits = model(images)\n",
    "\n",
    "\n",
    "    # Perform optimisation and print out the training loss\n",
    "    ### Insert your code ###\n",
    "    optimizer.zero_grad()  # Clear the gradients\n",
    "    loss = criterion(logits, labels)  # Calculate the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update the model parameters\n",
    "\n",
    "    print(f'Iteration: {it}/{num_iter}, Loss: {loss.item()}')\n",
    "    ### End of your code ###\n",
    "\n",
    "    # Evaluate\n",
    "    if it % 100 == 0:\n",
    "        model.eval()\n",
    "        # Disabling gradient calculation during reference to reduce memory consumption\n",
    "        with torch.no_grad():\n",
    "            # Evaluate on a batch of test images and print out the test loss\n",
    "            ### Insert your code ###\n",
    "            total_loss = 0\n",
    "            input_images, real_labels = test_set.get_random_batch(eval_batch_size)\n",
    "            input_images, real_labels = torch.from_numpy(input_images), torch.from_numpy(real_labels)\n",
    "            input_images, real_labels = input_images.to(device, dtype=torch.float32), real_labels.to(device, dtype=torch.long)\n",
    "            outputs = model(input_images)\n",
    "            \n",
    "            loss = criterion(outputs, real_labels)\n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / eval_batch_size\n",
    "            \n",
    "            print(f\"Average test loss: {avg_loss: .4f}\")\n",
    "            \n",
    "            \n",
    "            ### End of your code ###\n",
    "\n",
    "    # Save the model\n",
    "    if it % 5000 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yjxjGyb6yT"
   },
   "source": [
    "## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
    "\n",
    "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "wZeLE0qZjd2j"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "deploy_size = 4\n",
    "img_dim = (120, 120)\n",
    "\n",
    "model.eval()\n",
    "## Get a random set of 4 test images\n",
    "test_images, test_labels = test_set.get_random_batch(deploy_size)\n",
    "d_test_images = torch.from_numpy(test_images).to(device, dtype=torch.float32)\n",
    "\n",
    "## Perform inference on the test images\n",
    "outputs = model(d_test_images)\n",
    "predicted_labels = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "## Visualize the test images, automated segmentation, and ground truth segmentation\n",
    "fig, grid = plt.subplots(deploy_size, 3, figsize=(10, 10))\n",
    "\n",
    "## Add titles\n",
    "titles = [\"Test Image\", \"Auto Segmentation\", \"Ground Truth Segmentation\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(grid[0], titles)]\n",
    "\n",
    "for i in range(deploy_size):\n",
    "    grid[i, 0].imshow(test_images[i, 0], cmap=cmap_image)\n",
    "    grid[i, 0].axis('off')\n",
    "\n",
    "    grid[i, 1].imshow(predicted_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 1].axis('off')\n",
    "\n",
    "    grid[i, 2].imshow(test_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "\n",
    "### End of your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj3Qusin_s_r"
   },
   "source": [
    "## 6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Does your trained model work well?**\n",
    "To be able to comment on these there are few factors we need to consider. Big part that plays into this is the models performance, in terms of the average loss the model performs pretty well (0.0031) However, to comment on the full performance we should also bring in other metrics such as precision, recall and even evaluate the F1 score to get a better idea of the model.\n",
    "\n",
    "#### **How would you improve this model...**\n",
    "In terms of improvements, we can use a more complex or deeper convolutional neural network that can extract and 'learn' more information about the training data set and leverage that to be a better image segmentator. On top of this we can tune other hyperparameeters such as batch sizes or the number of convolutional steps (increase n to be more than 128 ...) .\n",
    "\n",
    "There can also be some data set improvements such as balancing our data set (not sure if this one is or not) but addressing a possible inbalanace will result in a more performant model. We should also  augment the data inputting into the modelby transforming the input data by: rotating, resizing, mirroring ... so the overall robustness of the model can be increased and it will perform better with real life data.\n",
    "\n",
    "Finally we can regularly test and evaluate the model so that we can make small adjustments or improvements to keep the model performant and robust.\n",
    "\n",
    "\n",
    "#### **...so it can deployed to a real clinic?**\n",
    "\n",
    "I think the most obvious first step would be to give some sort of meaning to this segmentation. Right now some colours are shown \n",
    "and whoever is interacting with this needs to be able to quickly understand what they are looking at. \n",
    "\n",
    "A really important second point is to have some sort of expert validation of these results beyond the testing of the model, so that we can be sure the model is aligning with what the medical professionals are expecting.\n",
    "\n",
    "Then, continuing on from the final point above, we need to be able to keep the model current. It cannot be trained then left alone as more data will become available over its lifespan and can be used to train and make the mdoel more robust.\n",
    "\n",
    "And finally, as any real system getting deployed it needs to have security measures and backups. Security is extra important as personal medical information is quite a sensitive piece of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
