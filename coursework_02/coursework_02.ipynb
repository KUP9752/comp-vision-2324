{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "# Coursework 2: Image segmentation\n",
    "\n",
    "In this coursework you will develop and train a convolutional neural network for brain tumour image segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
    "\n",
    "```\n",
    "### Insert your code ###\n",
    "...\n",
    "### End of your code ###\n",
    "```\n",
    "\n",
    "## What to do?\n",
    "\n",
    "* Complete and run the code using `jupyter-lab` or `jupyter-notebook` to get the results.\n",
    "\n",
    "* Export (File | Save and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
    "\n",
    "* Instead of clicking the Export button, you can also run the following command instead: `jupyter nbconvert coursework.ipynb --to pdf`\n",
    "\n",
    "* If Jupyter complains about some problems in exporting, it is likely that pandoc (https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry.\n",
    "\n",
    "* If Jupyter-lab does not work for you at the end, you can use Google Colab to write the code and export the PDF file.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
    "`pip3 install [package_name]`\n",
    "\n",
    "## GPU resource\n",
    "\n",
    "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
    "\n",
    "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this tutorial.\n",
    "# However, if any other library is needed, please install by yourself.\n",
    "import tarfile\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## 1. Download and visualise the imaging dataset.\n",
    "\n",
    "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
    "\n",
    "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
    "\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "mt93oQ8xZkE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-17 13:25:12--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6020:18::a27d:4012\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz [following]\n",
      "--2024-02-17 13:25:12--  https://www.dropbox.com/s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com/cd/0/inline/CNcE729SeL_26SJnP6I_NCiUhGfrUPF_KqYJc_A6JZ41K9jxAYaYqSa6VFv4CEDjymW1nMi8q_JXmtxoujmbBAfMTyGBRlauyOqW7kIBcFyw5AD1Wl8ID4GuuUT6i-H7mWU/file# [following]\n",
      "--2024-02-17 13:25:13--  https://uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com/cd/0/inline/CNcE729SeL_26SJnP6I_NCiUhGfrUPF_KqYJc_A6JZ41K9jxAYaYqSa6VFv4CEDjymW1nMi8q_JXmtxoujmbBAfMTyGBRlauyOqW7kIBcFyw5AD1Wl8ID4GuuUT6i-H7mWU/file\n",
      "Resolving uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com (uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n",
      "Connecting to uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com (uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CNfCuCqd7U33QbOICNANWbiPZgXc85XfIL-7td6AfglK8NCS7AsYJnsmqYJDpUOkIUfn2d7vedck1eEA4AF31kmaHIzgf1fU6nds5QP0-_v1Qz9YIT98Vq281YdaSOE-Tc9hVi84UPOhrZfqXeXKG5cuLRPZx2No4ZDe8EmFNnKqFSnImpSxONFLaactpJeQAPflNSz_JdVrfZriLlq-jVbtuHlLIwW51iFuG3Gm6M8PHtz7Q2BoUphaXogM9AiXUQQ-BaBOF3Bg2810qBKJc3KDQC1lxeTXaTxMdcxThW7a9grB7JYBy1ZDnHyT5xGnjmVP3-l5snfiPNlMeFqGH_a9fSPiGL--Fs1U-BKPbPY8Rg/file [following]\n",
      "--2024-02-17 13:25:13--  https://uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com/cd/0/inline2/CNfCuCqd7U33QbOICNANWbiPZgXc85XfIL-7td6AfglK8NCS7AsYJnsmqYJDpUOkIUfn2d7vedck1eEA4AF31kmaHIzgf1fU6nds5QP0-_v1Qz9YIT98Vq281YdaSOE-Tc9hVi84UPOhrZfqXeXKG5cuLRPZx2No4ZDe8EmFNnKqFSnImpSxONFLaactpJeQAPflNSz_JdVrfZriLlq-jVbtuHlLIwW51iFuG3Gm6M8PHtz7Q2BoUphaXogM9AiXUQQ-BaBOF3Bg2810qBKJc3KDQC1lxeTXaTxMdcxThW7a9grB7JYBy1ZDnHyT5xGnjmVP3-l5snfiPNlMeFqGH_a9fSPiGL--Fs1U-BKPbPY8Rg/file\n",
      "Reusing existing connection to uc3f7f8d9fc269e7c1dfa48b539b.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9251149 (8.8M) [application/octet-stream]\n",
      "Saving to: ‘Task01_BrainTumour_2D.tar.gz.2’\n",
      "\n",
      "Task01_BrainTumour_ 100%[===================>]   8.82M  26.2MB/s    in 0.3s    \n",
      "\n",
      "2024-02-17 13:25:15 (26.2 MB/s) - ‘Task01_BrainTumour_2D.tar.gz.2’ saved [9251149/9251149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
    "\n",
    "# Unzip the '.tar.gz' file to the current directory\n",
    "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
    "datafile.extractall()\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu_BTL0x6o5a"
   },
   "source": [
    "## Visualise a random set of 4 training images along with their label maps.\n",
    "\n",
    "Suggested colour map for brain MR image:\n",
    "```\n",
    "cmap = 'gray'\n",
    "```\n",
    "\n",
    "Suggested colour map for segmentation map:\n",
    "```\n",
    "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "3fgubCRC6m4k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36154/276553290.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(training_img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "cmap_image = \"gray\"\n",
    "cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "\n",
    "zs = [46, 62, 77, 93, 108, 124]\n",
    "IMAGES_FROM = 1\n",
    "IMAGES_TO = 483\n",
    "from random import randint\n",
    "from random import choice\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "\n",
    "# figure = plt.figure(figsize = (4, 2))\n",
    "# img_grid = ImageGrid(figure, 111, nrows_ncols = (4, 2), axes_pad =3)\n",
    "figure, img_grid = plt.subplots(nrows=4, ncols=2, figsize = (5, 10))\n",
    "\n",
    "titles = [\"Training Image\", \"Label\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(img_grid[0], titles)]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"./Task01_BrainTumour_2D/training_images/\", topdown = False):\n",
    "  chosen = []\n",
    "  for _ in range(4):\n",
    "    chosen.append(choice(files))\n",
    "\n",
    "path = \"Task01_BrainTumour_2D\"\n",
    "training_path = \"training_images\"\n",
    "label_path = \"training_labels\"\n",
    "\n",
    "for i, img_path in enumerate(chosen):\n",
    "  training_img_path = f\"{path}/{training_path}/{img_path}\"\n",
    "  label_img_path = f\"{path}/{label_path}/{img_path}\"\n",
    "  \n",
    "  ## Training Image\n",
    "  img = imageio.imread(training_img_path)\n",
    "  img_grid[i, 0].imshow(img, cmap = cmap_image)\n",
    "  img_grid[i, 0].axis(\"off\")\n",
    "  \n",
    "  ## Label Map\n",
    "  label_img= imageio.v3.imread(label_img_path)\n",
    "  \n",
    "  img_grid[i, 1].imshow(label_img, cmap = cmap_segmentation)\n",
    "  img_grid[i, 1].axis(\"off\")\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xWGT3KaML-D"
   },
   "source": [
    "## 2. Implement a dataset class.\n",
    "\n",
    "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "6p6wFZ3na5z9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalise_intensity(image, thres_roi=1.0):\n",
    "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
    "    # ROI defines the image foreground\n",
    "    val_l = np.percentile(image, thres_roi)\n",
    "    roi = (image >= val_l)\n",
    "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
    "    eps = 1e-6\n",
    "    image2 = (image - mu) / (sigma + eps)\n",
    "    return image2\n",
    "\n",
    "\n",
    "class BrainImageSet(Dataset):\n",
    "    \"\"\" Brain image set \"\"\"\n",
    "    def __init__(self, image_path, label_path='', deploy=False):\n",
    "        self.image_path = image_path\n",
    "        self.deploy = deploy\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        image_names = sorted(os.listdir(image_path))\n",
    "        for image_name in image_names:\n",
    "            # Read the image\n",
    "            image = imageio.v3.imread(os.path.join(image_path, image_name))\n",
    "            self.images += [image]\n",
    "\n",
    "            # Read the label map\n",
    "            if not self.deploy:\n",
    "                label_name = os.path.join(label_path, image_name)\n",
    "                label = imageio.v3.imread(label_name)\n",
    "                self.labels += [label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get an image and perform intensity normalisation\n",
    "        # Dimension: XY\n",
    "        image = normalise_intensity(self.images[idx])\n",
    "\n",
    "        # Get its label map\n",
    "        # Dimension: XY\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_random_batch(self, batch_size):\n",
    "        # Get a batch of paired images and label maps\n",
    "        # Dimension of images: NCXY\n",
    "        # Dimension of labels: NXY\n",
    "        # images, labels = [], []\n",
    "        \n",
    "        ### Insert your code ###\n",
    "        images = np.array(self.images)\n",
    "        labels = np.array(self.labels)\n",
    "        \n",
    "        seed = np.random.default_rng().integers(low=0, high=2048) # arbitratry range can be changed\n",
    "        \n",
    "        ## shuffle the same way\n",
    "        rg = np.random.default_rng(seed)\n",
    "        rg.shuffle(images)\n",
    "        rg = np.random.default_rng(seed)\n",
    "        rg.shuffle(labels)\n",
    "        \n",
    "        ## Select batch_size many\n",
    "        images, labels = images[:batch_size], labels[:batch_size]\n",
    "        \n",
    "        ## add the greyscale colour channel so conv2d works correctly\n",
    "        images = np.reshape(images, (batch_size, 1, images.shape[1], images.shape[2])) \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "        ### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4ZpawDNmwu"
   },
   "source": [
    "## 3. Build a U-net architecture.\n",
    "\n",
    "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
    "\n",
    "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
    "\n",
    "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "IMPmBZVGb1aI"
   },
   "outputs": [],
   "source": [
    "\"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        ### Insert your code ###\n",
    "        n //= 2 # 64\n",
    "        self.upconv5 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 128 -> 64 ch (x2 dims)\n",
    "        self.conv5 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        n //= 2 # 32\n",
    "        self.upconv6 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2 ) # 64 -> 32 ch (x2 dims)\n",
    "        self.conv6 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        n //= 2 # 16\n",
    "        self.upconv7 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 32 -> 16 ch (x2 dims)\n",
    "        self.conv7 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2 , n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, output_channel, kernel_size=1) ## final 1x1 conv\n",
    "        )\n",
    "        ### End of your code ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the convolutional operators defined above to build the U-net\n",
    "        # The encoder part is already done for you.\n",
    "        # You need to complete the decoder part.\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        conv1_skip = x\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        conv2_skip = x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        conv3_skip = x\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Decoder\n",
    "        ### Insert your code ###\n",
    "        x = self.conv5(torch.cat([self.upconv5(x), conv3_skip], dim=1))\n",
    "        \n",
    "        x = self.conv6(torch.cat([self.upconv6(x), conv2_skip], dim=1))\n",
    "        \n",
    "        x = self.conv7(torch.cat([self.upconv7(x), conv1_skip], dim=1))\n",
    "        \n",
    "        ### End of your code ###\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcNWZS08d47P"
   },
   "source": [
    "## 4. Train the segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "xaGGkKQndIaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Iteration: 1/10000, Loss: 1.460010290145874\n",
      "Iteration: 2/10000, Loss: 1.4087722301483154\n",
      "Iteration: 3/10000, Loss: 1.361584186553955\n",
      "Iteration: 4/10000, Loss: 1.3258066177368164\n",
      "Iteration: 5/10000, Loss: 1.2967392206192017\n",
      "Iteration: 6/10000, Loss: 1.2734233140945435\n",
      "Iteration: 7/10000, Loss: 1.2418675422668457\n",
      "Iteration: 8/10000, Loss: 1.2235240936279297\n",
      "Iteration: 9/10000, Loss: 1.1936761140823364\n",
      "Iteration: 10/10000, Loss: 1.1927976608276367\n",
      "Iteration: 11/10000, Loss: 1.1700009107589722\n",
      "Iteration: 12/10000, Loss: 1.157315731048584\n",
      "Iteration: 13/10000, Loss: 1.1498210430145264\n",
      "Iteration: 14/10000, Loss: 1.1405327320098877\n",
      "Iteration: 15/10000, Loss: 1.114136815071106\n",
      "Iteration: 16/10000, Loss: 1.106324553489685\n",
      "Iteration: 17/10000, Loss: 1.1013622283935547\n",
      "Iteration: 18/10000, Loss: 1.0853071212768555\n",
      "Iteration: 19/10000, Loss: 1.073927640914917\n",
      "Iteration: 20/10000, Loss: 1.0686824321746826\n",
      "Iteration: 21/10000, Loss: 1.0450844764709473\n",
      "Iteration: 22/10000, Loss: 1.037078619003296\n",
      "Iteration: 23/10000, Loss: 1.0300754308700562\n",
      "Iteration: 24/10000, Loss: 1.0120025873184204\n",
      "Iteration: 25/10000, Loss: 1.0047330856323242\n",
      "Iteration: 26/10000, Loss: 1.0138906240463257\n",
      "Iteration: 27/10000, Loss: 0.9898081421852112\n",
      "Iteration: 28/10000, Loss: 0.9770843982696533\n",
      "Iteration: 29/10000, Loss: 0.9697920680046082\n",
      "Iteration: 30/10000, Loss: 0.9571021199226379\n",
      "Iteration: 31/10000, Loss: 0.9495651125907898\n",
      "Iteration: 32/10000, Loss: 0.9469886422157288\n",
      "Iteration: 33/10000, Loss: 0.9385705590248108\n",
      "Iteration: 34/10000, Loss: 0.943784773349762\n",
      "Iteration: 35/10000, Loss: 0.9235862493515015\n",
      "Iteration: 36/10000, Loss: 0.9108132123947144\n",
      "Iteration: 37/10000, Loss: 0.9131784439086914\n",
      "Iteration: 38/10000, Loss: 0.8932403326034546\n",
      "Iteration: 39/10000, Loss: 0.8880482316017151\n",
      "Iteration: 40/10000, Loss: 0.8783628344535828\n",
      "Iteration: 41/10000, Loss: 0.8734514117240906\n",
      "Iteration: 42/10000, Loss: 0.8714426159858704\n",
      "Iteration: 43/10000, Loss: 0.8551905155181885\n",
      "Iteration: 44/10000, Loss: 0.8448798060417175\n",
      "Iteration: 45/10000, Loss: 0.8433917760848999\n",
      "Iteration: 46/10000, Loss: 0.8336243629455566\n",
      "Iteration: 47/10000, Loss: 0.842568576335907\n",
      "Iteration: 48/10000, Loss: 0.8243325352668762\n",
      "Iteration: 49/10000, Loss: 0.8110037446022034\n",
      "Iteration: 50/10000, Loss: 0.8114705681800842\n",
      "Iteration: 51/10000, Loss: 0.7970559597015381\n",
      "Iteration: 52/10000, Loss: 0.8016870617866516\n",
      "Iteration: 53/10000, Loss: 0.7659367322921753\n",
      "Iteration: 54/10000, Loss: 0.775154173374176\n",
      "Iteration: 55/10000, Loss: 0.7536603212356567\n",
      "Iteration: 56/10000, Loss: 0.742341935634613\n",
      "Iteration: 57/10000, Loss: 0.7477497458457947\n",
      "Iteration: 58/10000, Loss: 0.7527245283126831\n",
      "Iteration: 59/10000, Loss: 0.7308410406112671\n",
      "Iteration: 60/10000, Loss: 0.7264555096626282\n",
      "Iteration: 61/10000, Loss: 0.7183113098144531\n",
      "Iteration: 62/10000, Loss: 0.7039385437965393\n",
      "Iteration: 63/10000, Loss: 0.7006078362464905\n",
      "Iteration: 64/10000, Loss: 0.7017317414283752\n",
      "Iteration: 65/10000, Loss: 0.6779079437255859\n",
      "Iteration: 66/10000, Loss: 0.6789118647575378\n",
      "Iteration: 67/10000, Loss: 0.6734063625335693\n",
      "Iteration: 68/10000, Loss: 0.6774120926856995\n",
      "Iteration: 69/10000, Loss: 0.6540765762329102\n",
      "Iteration: 70/10000, Loss: 0.6397409439086914\n",
      "Iteration: 71/10000, Loss: 0.6269750595092773\n",
      "Iteration: 72/10000, Loss: 0.6445814371109009\n",
      "Iteration: 73/10000, Loss: 0.6250439286231995\n",
      "Iteration: 74/10000, Loss: 0.6183661818504333\n",
      "Iteration: 75/10000, Loss: 0.6081010103225708\n",
      "Iteration: 76/10000, Loss: 0.5983644723892212\n",
      "Iteration: 77/10000, Loss: 0.5980893969535828\n",
      "Iteration: 78/10000, Loss: 0.5912801027297974\n",
      "Iteration: 79/10000, Loss: 0.5732097029685974\n",
      "Iteration: 80/10000, Loss: 0.5796621441841125\n",
      "Iteration: 81/10000, Loss: 0.5618937611579895\n",
      "Iteration: 82/10000, Loss: 0.580157995223999\n",
      "Iteration: 83/10000, Loss: 0.5577499270439148\n",
      "Iteration: 84/10000, Loss: 0.5419477820396423\n",
      "Iteration: 85/10000, Loss: 0.527411162853241\n",
      "Iteration: 86/10000, Loss: 0.5296821594238281\n",
      "Iteration: 87/10000, Loss: 0.5125178098678589\n",
      "Iteration: 88/10000, Loss: 0.5196475982666016\n",
      "Iteration: 89/10000, Loss: 0.5177891254425049\n",
      "Iteration: 90/10000, Loss: 0.49992313981056213\n",
      "Iteration: 91/10000, Loss: 0.5019817352294922\n",
      "Iteration: 92/10000, Loss: 0.4895332455635071\n",
      "Iteration: 93/10000, Loss: 0.485589861869812\n",
      "Iteration: 94/10000, Loss: 0.4929988384246826\n",
      "Iteration: 95/10000, Loss: 0.47103384137153625\n",
      "Iteration: 96/10000, Loss: 0.4693487584590912\n",
      "Iteration: 97/10000, Loss: 0.46334168314933777\n",
      "Iteration: 98/10000, Loss: 0.46639150381088257\n",
      "Iteration: 99/10000, Loss: 0.4526137709617615\n",
      "Iteration: 100/10000, Loss: 0.444688618183136\n",
      "Average test loss:  0.0439\n",
      "Iteration: 101/10000, Loss: 0.4442581832408905\n",
      "Iteration: 102/10000, Loss: 0.4432481527328491\n",
      "Iteration: 103/10000, Loss: 0.4223807752132416\n",
      "Iteration: 104/10000, Loss: 0.4330221116542816\n",
      "Iteration: 105/10000, Loss: 0.4134671688079834\n",
      "Iteration: 106/10000, Loss: 0.40546008944511414\n",
      "Iteration: 107/10000, Loss: 0.41320252418518066\n",
      "Iteration: 108/10000, Loss: 0.40209558606147766\n",
      "Iteration: 109/10000, Loss: 0.39577990770339966\n",
      "Iteration: 110/10000, Loss: 0.3938457667827606\n",
      "Iteration: 111/10000, Loss: 0.38799476623535156\n",
      "Iteration: 112/10000, Loss: 0.3722976744174957\n",
      "Iteration: 113/10000, Loss: 0.3827461898326874\n",
      "Iteration: 114/10000, Loss: 0.36844542622566223\n",
      "Iteration: 115/10000, Loss: 0.36796140670776367\n",
      "Iteration: 116/10000, Loss: 0.36361557245254517\n",
      "Iteration: 117/10000, Loss: 0.35646963119506836\n",
      "Iteration: 118/10000, Loss: 0.3619568645954132\n",
      "Iteration: 119/10000, Loss: 0.36389973759651184\n",
      "Iteration: 120/10000, Loss: 0.335599422454834\n",
      "Iteration: 121/10000, Loss: 0.33710089325904846\n",
      "Iteration: 122/10000, Loss: 0.342175155878067\n",
      "Iteration: 123/10000, Loss: 0.34454792737960815\n",
      "Iteration: 124/10000, Loss: 0.33388686180114746\n",
      "Iteration: 125/10000, Loss: 0.33269497752189636\n",
      "Iteration: 126/10000, Loss: 0.3236640691757202\n",
      "Iteration: 127/10000, Loss: 0.31824347376823425\n",
      "Iteration: 128/10000, Loss: 0.3042939603328705\n",
      "Iteration: 129/10000, Loss: 0.3250342607498169\n",
      "Iteration: 130/10000, Loss: 0.2953730523586273\n",
      "Iteration: 131/10000, Loss: 0.3013169467449188\n",
      "Iteration: 132/10000, Loss: 0.29594147205352783\n",
      "Iteration: 133/10000, Loss: 0.3042983114719391\n",
      "Iteration: 134/10000, Loss: 0.3030560612678528\n",
      "Iteration: 135/10000, Loss: 0.2992366552352905\n",
      "Iteration: 136/10000, Loss: 0.2697531282901764\n",
      "Iteration: 137/10000, Loss: 0.2921377420425415\n",
      "Iteration: 138/10000, Loss: 0.2613637149333954\n",
      "Iteration: 139/10000, Loss: 0.2705921232700348\n",
      "Iteration: 140/10000, Loss: 0.26469671726226807\n",
      "Iteration: 141/10000, Loss: 0.2676905691623688\n",
      "Iteration: 142/10000, Loss: 0.25703850388526917\n",
      "Iteration: 143/10000, Loss: 0.24938511848449707\n",
      "Iteration: 144/10000, Loss: 0.2612398862838745\n",
      "Iteration: 145/10000, Loss: 0.24980682134628296\n",
      "Iteration: 146/10000, Loss: 0.23956461250782013\n",
      "Iteration: 147/10000, Loss: 0.24293488264083862\n",
      "Iteration: 148/10000, Loss: 0.2527557611465454\n",
      "Iteration: 149/10000, Loss: 0.24751228094100952\n",
      "Iteration: 150/10000, Loss: 0.25432682037353516\n",
      "Iteration: 151/10000, Loss: 0.22344215214252472\n",
      "Iteration: 152/10000, Loss: 0.2203063666820526\n",
      "Iteration: 153/10000, Loss: 0.2418607771396637\n",
      "Iteration: 154/10000, Loss: 0.22577382624149323\n",
      "Iteration: 155/10000, Loss: 0.24096176028251648\n",
      "Iteration: 156/10000, Loss: 0.24191391468048096\n",
      "Iteration: 157/10000, Loss: 0.22448372840881348\n",
      "Iteration: 158/10000, Loss: 0.22176362574100494\n",
      "Iteration: 159/10000, Loss: 0.22733211517333984\n",
      "Iteration: 160/10000, Loss: 0.2188727855682373\n",
      "Iteration: 161/10000, Loss: 0.21826493740081787\n",
      "Iteration: 162/10000, Loss: 0.23108462989330292\n",
      "Iteration: 163/10000, Loss: 0.20516008138656616\n",
      "Iteration: 164/10000, Loss: 0.22521337866783142\n",
      "Iteration: 165/10000, Loss: 0.21153640747070312\n",
      "Iteration: 166/10000, Loss: 0.22180812060832977\n",
      "Iteration: 167/10000, Loss: 0.23715336620807648\n",
      "Iteration: 168/10000, Loss: 0.19373884797096252\n",
      "Iteration: 169/10000, Loss: 0.20680351555347443\n",
      "Iteration: 170/10000, Loss: 0.21537579596042633\n",
      "Iteration: 171/10000, Loss: 0.19242006540298462\n",
      "Iteration: 172/10000, Loss: 0.22626334428787231\n",
      "Iteration: 173/10000, Loss: 0.21780116856098175\n",
      "Iteration: 174/10000, Loss: 0.1932907998561859\n",
      "Iteration: 175/10000, Loss: 0.20224076509475708\n",
      "Iteration: 176/10000, Loss: 0.18359002470970154\n",
      "Iteration: 177/10000, Loss: 0.16718964278697968\n",
      "Iteration: 178/10000, Loss: 0.2009415477514267\n",
      "Iteration: 179/10000, Loss: 0.1851045787334442\n",
      "Iteration: 180/10000, Loss: 0.1983128935098648\n",
      "Iteration: 181/10000, Loss: 0.16866913437843323\n",
      "Iteration: 182/10000, Loss: 0.1697012186050415\n",
      "Iteration: 183/10000, Loss: 0.18761751055717468\n",
      "Iteration: 184/10000, Loss: 0.16447527706623077\n",
      "Iteration: 185/10000, Loss: 0.1814037412405014\n",
      "Iteration: 186/10000, Loss: 0.17174383997917175\n",
      "Iteration: 187/10000, Loss: 0.18406042456626892\n",
      "Iteration: 188/10000, Loss: 0.1877882480621338\n",
      "Iteration: 189/10000, Loss: 0.18688145279884338\n",
      "Iteration: 190/10000, Loss: 0.18186089396476746\n",
      "Iteration: 191/10000, Loss: 0.17959889769554138\n",
      "Iteration: 192/10000, Loss: 0.17361891269683838\n",
      "Iteration: 193/10000, Loss: 0.18861576914787292\n",
      "Iteration: 194/10000, Loss: 0.19059382379055023\n",
      "Iteration: 195/10000, Loss: 0.18627268075942993\n",
      "Iteration: 196/10000, Loss: 0.16202396154403687\n",
      "Iteration: 197/10000, Loss: 0.15996110439300537\n",
      "Iteration: 198/10000, Loss: 0.1575111448764801\n",
      "Iteration: 199/10000, Loss: 0.1842755526304245\n",
      "Iteration: 200/10000, Loss: 0.1676844209432602\n",
      "Average test loss:  0.0093\n",
      "Iteration: 201/10000, Loss: 0.16288070380687714\n",
      "Iteration: 202/10000, Loss: 0.16845235228538513\n",
      "Iteration: 203/10000, Loss: 0.1575232595205307\n",
      "Iteration: 204/10000, Loss: 0.16308803856372833\n",
      "Iteration: 205/10000, Loss: 0.18318909406661987\n",
      "Iteration: 206/10000, Loss: 0.18461255729198456\n",
      "Iteration: 207/10000, Loss: 0.15670661628246307\n",
      "Iteration: 208/10000, Loss: 0.15011052787303925\n",
      "Iteration: 209/10000, Loss: 0.1901085078716278\n",
      "Iteration: 210/10000, Loss: 0.16302600502967834\n",
      "Iteration: 211/10000, Loss: 0.15617753565311432\n",
      "Iteration: 212/10000, Loss: 0.17979931831359863\n",
      "Iteration: 213/10000, Loss: 0.14491581916809082\n",
      "Iteration: 214/10000, Loss: 0.14445552229881287\n",
      "Iteration: 215/10000, Loss: 0.1554078310728073\n",
      "Iteration: 216/10000, Loss: 0.15410639345645905\n",
      "Iteration: 217/10000, Loss: 0.1626289337873459\n",
      "Iteration: 218/10000, Loss: 0.13994169235229492\n",
      "Iteration: 219/10000, Loss: 0.1880146861076355\n",
      "Iteration: 220/10000, Loss: 0.1425366848707199\n",
      "Iteration: 221/10000, Loss: 0.14376650750637054\n",
      "Iteration: 222/10000, Loss: 0.14322276413440704\n",
      "Iteration: 223/10000, Loss: 0.14084424078464508\n",
      "Iteration: 224/10000, Loss: 0.14631788432598114\n",
      "Iteration: 225/10000, Loss: 0.14978346228599548\n",
      "Iteration: 226/10000, Loss: 0.13738058507442474\n",
      "Iteration: 227/10000, Loss: 0.1409408003091812\n",
      "Iteration: 228/10000, Loss: 0.13240881264209747\n",
      "Iteration: 229/10000, Loss: 0.1440359503030777\n",
      "Iteration: 230/10000, Loss: 0.13491517305374146\n",
      "Iteration: 231/10000, Loss: 0.1469041109085083\n",
      "Iteration: 232/10000, Loss: 0.12881718575954437\n",
      "Iteration: 233/10000, Loss: 0.1447550654411316\n",
      "Iteration: 234/10000, Loss: 0.14014080166816711\n",
      "Iteration: 235/10000, Loss: 0.12968620657920837\n",
      "Iteration: 236/10000, Loss: 0.13158193230628967\n",
      "Iteration: 237/10000, Loss: 0.1315709352493286\n",
      "Iteration: 238/10000, Loss: 0.15318024158477783\n",
      "Iteration: 239/10000, Loss: 0.12221838533878326\n",
      "Iteration: 240/10000, Loss: 0.12328387796878815\n",
      "Iteration: 241/10000, Loss: 0.12498122453689575\n",
      "Iteration: 242/10000, Loss: 0.10399732738733292\n",
      "Iteration: 243/10000, Loss: 0.1291242390871048\n",
      "Iteration: 244/10000, Loss: 0.13629278540611267\n",
      "Iteration: 245/10000, Loss: 0.14565333724021912\n",
      "Iteration: 246/10000, Loss: 0.14230620861053467\n",
      "Iteration: 247/10000, Loss: 0.1550818383693695\n",
      "Iteration: 248/10000, Loss: 0.15105006098747253\n",
      "Iteration: 249/10000, Loss: 0.14988261461257935\n",
      "Iteration: 250/10000, Loss: 0.1321319043636322\n",
      "Iteration: 251/10000, Loss: 0.13239338994026184\n",
      "Iteration: 252/10000, Loss: 0.14449140429496765\n",
      "Iteration: 253/10000, Loss: 0.13371846079826355\n",
      "Iteration: 254/10000, Loss: 0.1183026134967804\n",
      "Iteration: 255/10000, Loss: 0.12072597444057465\n",
      "Iteration: 256/10000, Loss: 0.11495419591665268\n",
      "Iteration: 257/10000, Loss: 0.13731850683689117\n",
      "Iteration: 258/10000, Loss: 0.11620844155550003\n",
      "Iteration: 259/10000, Loss: 0.10695305466651917\n",
      "Iteration: 260/10000, Loss: 0.149277463555336\n",
      "Iteration: 261/10000, Loss: 0.135845348238945\n",
      "Iteration: 262/10000, Loss: 0.12694582343101501\n",
      "Iteration: 263/10000, Loss: 0.11963866651058197\n",
      "Iteration: 264/10000, Loss: 0.11096217483282089\n",
      "Iteration: 265/10000, Loss: 0.1577129065990448\n",
      "Iteration: 266/10000, Loss: 0.10147205740213394\n",
      "Iteration: 267/10000, Loss: 0.12695351243019104\n",
      "Iteration: 268/10000, Loss: 0.10080737620592117\n",
      "Iteration: 269/10000, Loss: 0.1338951587677002\n",
      "Iteration: 270/10000, Loss: 0.114930659532547\n",
      "Iteration: 271/10000, Loss: 0.11306260526180267\n",
      "Iteration: 272/10000, Loss: 0.10024290531873703\n",
      "Iteration: 273/10000, Loss: 0.11907659471035004\n",
      "Iteration: 274/10000, Loss: 0.096528559923172\n",
      "Iteration: 275/10000, Loss: 0.1465163677930832\n",
      "Iteration: 276/10000, Loss: 0.10553736239671707\n",
      "Iteration: 277/10000, Loss: 0.10527519136667252\n",
      "Iteration: 278/10000, Loss: 0.10478503257036209\n",
      "Iteration: 279/10000, Loss: 0.12703154981136322\n",
      "Iteration: 280/10000, Loss: 0.11899007856845856\n",
      "Iteration: 281/10000, Loss: 0.09889829903841019\n",
      "Iteration: 282/10000, Loss: 0.10772042721509933\n",
      "Iteration: 283/10000, Loss: 0.11495161056518555\n",
      "Iteration: 284/10000, Loss: 0.12616963684558868\n",
      "Iteration: 285/10000, Loss: 0.09533409774303436\n",
      "Iteration: 286/10000, Loss: 0.09975691139698029\n",
      "Iteration: 287/10000, Loss: 0.11524724215269089\n",
      "Iteration: 288/10000, Loss: 0.1189044937491417\n",
      "Iteration: 289/10000, Loss: 0.11977018415927887\n",
      "Iteration: 290/10000, Loss: 0.12924814224243164\n",
      "Iteration: 291/10000, Loss: 0.11029727011919022\n",
      "Iteration: 292/10000, Loss: 0.10917964577674866\n",
      "Iteration: 293/10000, Loss: 0.11692097783088684\n",
      "Iteration: 294/10000, Loss: 0.09866732358932495\n",
      "Iteration: 295/10000, Loss: 0.1316782832145691\n",
      "Iteration: 296/10000, Loss: 0.1066041886806488\n",
      "Iteration: 297/10000, Loss: 0.08294546604156494\n",
      "Iteration: 298/10000, Loss: 0.11681371927261353\n",
      "Iteration: 299/10000, Loss: 0.12277457118034363\n",
      "Iteration: 300/10000, Loss: 0.09192293882369995\n",
      "Average test loss:  0.0065\n",
      "Iteration: 301/10000, Loss: 0.12578962743282318\n",
      "Iteration: 302/10000, Loss: 0.10157383978366852\n",
      "Iteration: 303/10000, Loss: 0.10901830345392227\n",
      "Iteration: 304/10000, Loss: 0.12294961512088776\n",
      "Iteration: 305/10000, Loss: 0.10502783954143524\n",
      "Iteration: 306/10000, Loss: 0.11090808361768723\n",
      "Iteration: 307/10000, Loss: 0.10720380395650864\n",
      "Iteration: 308/10000, Loss: 0.10375721752643585\n",
      "Iteration: 309/10000, Loss: 0.0987364798784256\n",
      "Iteration: 310/10000, Loss: 0.09223195910453796\n",
      "Iteration: 311/10000, Loss: 0.0901356190443039\n",
      "Iteration: 312/10000, Loss: 0.08810844272375107\n",
      "Iteration: 313/10000, Loss: 0.10310238599777222\n",
      "Iteration: 314/10000, Loss: 0.08865141123533249\n",
      "Iteration: 315/10000, Loss: 0.10221163928508759\n",
      "Iteration: 316/10000, Loss: 0.09041877835988998\n",
      "Iteration: 317/10000, Loss: 0.07626071572303772\n",
      "Iteration: 318/10000, Loss: 0.09329710155725479\n",
      "Iteration: 319/10000, Loss: 0.09393693506717682\n",
      "Iteration: 320/10000, Loss: 0.1058654934167862\n",
      "Iteration: 321/10000, Loss: 0.08655775338411331\n",
      "Iteration: 322/10000, Loss: 0.10733064264059067\n",
      "Iteration: 323/10000, Loss: 0.09254749119281769\n",
      "Iteration: 324/10000, Loss: 0.11497198045253754\n",
      "Iteration: 325/10000, Loss: 0.09777627140283585\n",
      "Iteration: 326/10000, Loss: 0.09753712266683578\n",
      "Iteration: 327/10000, Loss: 0.11044209450483322\n",
      "Iteration: 328/10000, Loss: 0.09976334124803543\n",
      "Iteration: 329/10000, Loss: 0.0902448445558548\n",
      "Iteration: 330/10000, Loss: 0.08720576018095016\n",
      "Iteration: 331/10000, Loss: 0.08319055289030075\n",
      "Iteration: 332/10000, Loss: 0.07916592806577682\n",
      "Iteration: 333/10000, Loss: 0.10407151281833649\n",
      "Iteration: 334/10000, Loss: 0.10550893098115921\n",
      "Iteration: 335/10000, Loss: 0.10368223488330841\n",
      "Iteration: 336/10000, Loss: 0.08355235308408737\n",
      "Iteration: 337/10000, Loss: 0.09278849512338638\n",
      "Iteration: 338/10000, Loss: 0.10147751867771149\n",
      "Iteration: 339/10000, Loss: 0.09278221428394318\n",
      "Iteration: 340/10000, Loss: 0.0931096002459526\n",
      "Iteration: 341/10000, Loss: 0.07735630124807358\n",
      "Iteration: 342/10000, Loss: 0.10196216404438019\n",
      "Iteration: 343/10000, Loss: 0.09729374200105667\n",
      "Iteration: 344/10000, Loss: 0.11163889616727829\n",
      "Iteration: 345/10000, Loss: 0.09321681410074234\n",
      "Iteration: 346/10000, Loss: 0.09329523891210556\n",
      "Iteration: 347/10000, Loss: 0.11749555915594101\n",
      "Iteration: 348/10000, Loss: 0.10366266965866089\n",
      "Iteration: 349/10000, Loss: 0.08080402761697769\n",
      "Iteration: 350/10000, Loss: 0.08210210502147675\n",
      "Iteration: 351/10000, Loss: 0.09609740972518921\n",
      "Iteration: 352/10000, Loss: 0.09175461530685425\n",
      "Iteration: 353/10000, Loss: 0.07624376565217972\n",
      "Iteration: 354/10000, Loss: 0.10429278016090393\n",
      "Iteration: 355/10000, Loss: 0.11629882454872131\n",
      "Iteration: 356/10000, Loss: 0.09800493717193604\n",
      "Iteration: 357/10000, Loss: 0.10307900607585907\n",
      "Iteration: 358/10000, Loss: 0.07858742773532867\n",
      "Iteration: 359/10000, Loss: 0.07723618298768997\n",
      "Iteration: 360/10000, Loss: 0.10410100221633911\n",
      "Iteration: 361/10000, Loss: 0.09130550920963287\n",
      "Iteration: 362/10000, Loss: 0.08371083438396454\n",
      "Iteration: 363/10000, Loss: 0.07571476697921753\n",
      "Iteration: 364/10000, Loss: 0.10049953311681747\n",
      "Iteration: 365/10000, Loss: 0.09850521385669708\n",
      "Iteration: 366/10000, Loss: 0.09028744697570801\n",
      "Iteration: 367/10000, Loss: 0.09129450470209122\n",
      "Iteration: 368/10000, Loss: 0.07625582069158554\n",
      "Iteration: 369/10000, Loss: 0.08116728067398071\n",
      "Iteration: 370/10000, Loss: 0.0853160172700882\n",
      "Iteration: 371/10000, Loss: 0.1051257774233818\n",
      "Iteration: 372/10000, Loss: 0.09496477246284485\n",
      "Iteration: 373/10000, Loss: 0.08119199424982071\n",
      "Iteration: 374/10000, Loss: 0.07897858321666718\n",
      "Iteration: 375/10000, Loss: 0.09519139677286148\n",
      "Iteration: 376/10000, Loss: 0.09669899940490723\n",
      "Iteration: 377/10000, Loss: 0.09560687839984894\n",
      "Iteration: 378/10000, Loss: 0.0782637819647789\n",
      "Iteration: 379/10000, Loss: 0.09254510700702667\n",
      "Iteration: 380/10000, Loss: 0.08115726709365845\n",
      "Iteration: 381/10000, Loss: 0.08421505242586136\n",
      "Iteration: 382/10000, Loss: 0.07722172141075134\n",
      "Iteration: 383/10000, Loss: 0.09904251247644424\n",
      "Iteration: 384/10000, Loss: 0.09517563134431839\n",
      "Iteration: 385/10000, Loss: 0.08088882267475128\n",
      "Iteration: 386/10000, Loss: 0.08554733544588089\n",
      "Iteration: 387/10000, Loss: 0.07072287052869797\n",
      "Iteration: 388/10000, Loss: 0.07834182679653168\n",
      "Iteration: 389/10000, Loss: 0.10196758061647415\n",
      "Iteration: 390/10000, Loss: 0.07895681262016296\n",
      "Iteration: 391/10000, Loss: 0.07718748599290848\n",
      "Iteration: 392/10000, Loss: 0.07762864232063293\n",
      "Iteration: 393/10000, Loss: 0.07912734150886536\n",
      "Iteration: 394/10000, Loss: 0.07195151597261429\n",
      "Iteration: 395/10000, Loss: 0.07062605768442154\n",
      "Iteration: 396/10000, Loss: 0.10076112300157547\n",
      "Iteration: 397/10000, Loss: 0.09561899304389954\n",
      "Iteration: 398/10000, Loss: 0.07563365250825882\n",
      "Iteration: 399/10000, Loss: 0.09585621953010559\n",
      "Iteration: 400/10000, Loss: 0.09145808964967728\n",
      "Average test loss:  0.0063\n",
      "Iteration: 401/10000, Loss: 0.07028274238109589\n",
      "Iteration: 402/10000, Loss: 0.06412763148546219\n",
      "Iteration: 403/10000, Loss: 0.0842473953962326\n",
      "Iteration: 404/10000, Loss: 0.057988762855529785\n",
      "Iteration: 405/10000, Loss: 0.08889667689800262\n",
      "Iteration: 406/10000, Loss: 0.10610795766115189\n",
      "Iteration: 407/10000, Loss: 0.06677795946598053\n",
      "Iteration: 408/10000, Loss: 0.07452492415904999\n",
      "Iteration: 409/10000, Loss: 0.07016853988170624\n",
      "Iteration: 410/10000, Loss: 0.08445455878973007\n",
      "Iteration: 411/10000, Loss: 0.07454800605773926\n",
      "Iteration: 412/10000, Loss: 0.07687076181173325\n",
      "Iteration: 413/10000, Loss: 0.08147504925727844\n",
      "Iteration: 414/10000, Loss: 0.09434529393911362\n",
      "Iteration: 415/10000, Loss: 0.07318717986345291\n",
      "Iteration: 416/10000, Loss: 0.08881466835737228\n",
      "Iteration: 417/10000, Loss: 0.06643422693014145\n",
      "Iteration: 418/10000, Loss: 0.06311839073896408\n",
      "Iteration: 419/10000, Loss: 0.09030028432607651\n",
      "Iteration: 420/10000, Loss: 0.0749569684267044\n",
      "Iteration: 421/10000, Loss: 0.07942348718643188\n",
      "Iteration: 422/10000, Loss: 0.07477471232414246\n",
      "Iteration: 423/10000, Loss: 0.07340702414512634\n",
      "Iteration: 424/10000, Loss: 0.08101867139339447\n",
      "Iteration: 425/10000, Loss: 0.05888257175683975\n",
      "Iteration: 426/10000, Loss: 0.08496686816215515\n",
      "Iteration: 427/10000, Loss: 0.0759042352437973\n",
      "Iteration: 428/10000, Loss: 0.06375882774591446\n",
      "Iteration: 429/10000, Loss: 0.05826718732714653\n",
      "Iteration: 430/10000, Loss: 0.06830072402954102\n",
      "Iteration: 431/10000, Loss: 0.09114864468574524\n",
      "Iteration: 432/10000, Loss: 0.05869909003376961\n",
      "Iteration: 433/10000, Loss: 0.06683919578790665\n",
      "Iteration: 434/10000, Loss: 0.07512412965297699\n",
      "Iteration: 435/10000, Loss: 0.06910843402147293\n",
      "Iteration: 436/10000, Loss: 0.05457186698913574\n",
      "Iteration: 437/10000, Loss: 0.09919726103544235\n",
      "Iteration: 438/10000, Loss: 0.0936967059969902\n",
      "Iteration: 439/10000, Loss: 0.06774529814720154\n",
      "Iteration: 440/10000, Loss: 0.0932319238781929\n",
      "Iteration: 441/10000, Loss: 0.06472567468881607\n",
      "Iteration: 442/10000, Loss: 0.08699455112218857\n",
      "Iteration: 443/10000, Loss: 0.08427301049232483\n",
      "Iteration: 444/10000, Loss: 0.0800960436463356\n",
      "Iteration: 445/10000, Loss: 0.06302209943532944\n",
      "Iteration: 446/10000, Loss: 0.06911041587591171\n",
      "Iteration: 447/10000, Loss: 0.067528136074543\n",
      "Iteration: 448/10000, Loss: 0.06621313095092773\n",
      "Iteration: 449/10000, Loss: 0.06781389564275742\n",
      "Iteration: 450/10000, Loss: 0.10236001014709473\n",
      "Iteration: 451/10000, Loss: 0.06548193097114563\n",
      "Iteration: 452/10000, Loss: 0.07136061787605286\n",
      "Iteration: 453/10000, Loss: 0.05889022722840309\n",
      "Iteration: 454/10000, Loss: 0.06900253891944885\n",
      "Iteration: 455/10000, Loss: 0.05887489393353462\n",
      "Iteration: 456/10000, Loss: 0.07151967287063599\n",
      "Iteration: 457/10000, Loss: 0.10287760198116302\n",
      "Iteration: 458/10000, Loss: 0.06247536838054657\n",
      "Iteration: 459/10000, Loss: 0.07690953463315964\n",
      "Iteration: 460/10000, Loss: 0.05501573532819748\n",
      "Iteration: 461/10000, Loss: 0.07088959217071533\n",
      "Iteration: 462/10000, Loss: 0.06688346713781357\n",
      "Iteration: 463/10000, Loss: 0.07138161361217499\n",
      "Iteration: 464/10000, Loss: 0.08267797529697418\n",
      "Iteration: 465/10000, Loss: 0.07061073184013367\n",
      "Iteration: 466/10000, Loss: 0.09172128140926361\n",
      "Iteration: 467/10000, Loss: 0.06616183370351791\n",
      "Iteration: 468/10000, Loss: 0.059120483696460724\n",
      "Iteration: 469/10000, Loss: 0.08321458846330643\n",
      "Iteration: 470/10000, Loss: 0.06800777465105057\n",
      "Iteration: 471/10000, Loss: 0.0779515951871872\n",
      "Iteration: 472/10000, Loss: 0.06870406866073608\n",
      "Iteration: 473/10000, Loss: 0.07509742677211761\n",
      "Iteration: 474/10000, Loss: 0.07887624204158783\n",
      "Iteration: 475/10000, Loss: 0.07735287398099899\n",
      "Iteration: 476/10000, Loss: 0.07232152670621872\n",
      "Iteration: 477/10000, Loss: 0.08513442426919937\n",
      "Iteration: 478/10000, Loss: 0.0731208324432373\n",
      "Iteration: 479/10000, Loss: 0.08348876982927322\n",
      "Iteration: 480/10000, Loss: 0.07846346497535706\n",
      "Iteration: 481/10000, Loss: 0.08506216108798981\n",
      "Iteration: 482/10000, Loss: 0.0718785747885704\n",
      "Iteration: 483/10000, Loss: 0.07796590030193329\n",
      "Iteration: 484/10000, Loss: 0.07805083692073822\n",
      "Iteration: 485/10000, Loss: 0.06564394384622574\n",
      "Iteration: 486/10000, Loss: 0.06670159846544266\n",
      "Iteration: 487/10000, Loss: 0.07257576286792755\n",
      "Iteration: 488/10000, Loss: 0.0654846727848053\n",
      "Iteration: 489/10000, Loss: 0.08243918418884277\n",
      "Iteration: 490/10000, Loss: 0.07143061608076096\n",
      "Iteration: 491/10000, Loss: 0.0659831315279007\n",
      "Iteration: 492/10000, Loss: 0.050921522080898285\n",
      "Iteration: 493/10000, Loss: 0.060768984258174896\n",
      "Iteration: 494/10000, Loss: 0.05482681095600128\n",
      "Iteration: 495/10000, Loss: 0.07233181595802307\n",
      "Iteration: 496/10000, Loss: 0.06366574019193649\n",
      "Iteration: 497/10000, Loss: 0.07564731687307358\n",
      "Iteration: 498/10000, Loss: 0.06539908796548843\n",
      "Iteration: 499/10000, Loss: 0.06160625070333481\n",
      "Iteration: 500/10000, Loss: 0.09862653911113739\n",
      "Average test loss:  0.0046\n",
      "Iteration: 501/10000, Loss: 0.06771200150251389\n",
      "Iteration: 502/10000, Loss: 0.07216724753379822\n",
      "Iteration: 503/10000, Loss: 0.10435441136360168\n",
      "Iteration: 504/10000, Loss: 0.06440548598766327\n",
      "Iteration: 505/10000, Loss: 0.09684324264526367\n",
      "Iteration: 506/10000, Loss: 0.07719736546278\n",
      "Iteration: 507/10000, Loss: 0.0759202167391777\n",
      "Iteration: 508/10000, Loss: 0.08594074100255966\n",
      "Iteration: 509/10000, Loss: 0.05548427253961563\n",
      "Iteration: 510/10000, Loss: 0.08586936444044113\n",
      "Iteration: 511/10000, Loss: 0.056092917919158936\n",
      "Iteration: 512/10000, Loss: 0.06847256422042847\n",
      "Iteration: 513/10000, Loss: 0.07878638058900833\n",
      "Iteration: 514/10000, Loss: 0.05790163576602936\n",
      "Iteration: 515/10000, Loss: 0.07337268441915512\n",
      "Iteration: 516/10000, Loss: 0.05503879114985466\n",
      "Iteration: 517/10000, Loss: 0.06360509991645813\n",
      "Iteration: 518/10000, Loss: 0.06993097811937332\n",
      "Iteration: 519/10000, Loss: 0.05548934265971184\n",
      "Iteration: 520/10000, Loss: 0.06843315064907074\n",
      "Iteration: 521/10000, Loss: 0.050139378756284714\n",
      "Iteration: 522/10000, Loss: 0.06948895007371902\n",
      "Iteration: 523/10000, Loss: 0.07259657979011536\n",
      "Iteration: 524/10000, Loss: 0.051217515021562576\n",
      "Iteration: 525/10000, Loss: 0.0804014503955841\n",
      "Iteration: 526/10000, Loss: 0.06285597383975983\n",
      "Iteration: 527/10000, Loss: 0.08240523189306259\n",
      "Iteration: 528/10000, Loss: 0.08433942496776581\n",
      "Iteration: 529/10000, Loss: 0.05839857459068298\n",
      "Iteration: 530/10000, Loss: 0.04569718614220619\n",
      "Iteration: 531/10000, Loss: 0.07377088814973831\n",
      "Iteration: 532/10000, Loss: 0.05712227150797844\n",
      "Iteration: 533/10000, Loss: 0.04757677763700485\n",
      "Iteration: 534/10000, Loss: 0.058808546513319016\n",
      "Iteration: 535/10000, Loss: 0.05203881487250328\n",
      "Iteration: 536/10000, Loss: 0.07228369265794754\n",
      "Iteration: 537/10000, Loss: 0.08963946998119354\n",
      "Iteration: 538/10000, Loss: 0.09504298120737076\n",
      "Iteration: 539/10000, Loss: 0.07789333164691925\n",
      "Iteration: 540/10000, Loss: 0.06751486659049988\n",
      "Iteration: 541/10000, Loss: 0.0828045904636383\n",
      "Iteration: 542/10000, Loss: 0.05847947299480438\n",
      "Iteration: 543/10000, Loss: 0.08984333276748657\n",
      "Iteration: 544/10000, Loss: 0.05934855714440346\n",
      "Iteration: 545/10000, Loss: 0.053812671452760696\n",
      "Iteration: 546/10000, Loss: 0.05905867740511894\n",
      "Iteration: 547/10000, Loss: 0.06523538380861282\n",
      "Iteration: 548/10000, Loss: 0.07052425295114517\n",
      "Iteration: 549/10000, Loss: 0.05619508773088455\n",
      "Iteration: 550/10000, Loss: 0.046434469521045685\n",
      "Iteration: 551/10000, Loss: 0.06186477839946747\n",
      "Iteration: 552/10000, Loss: 0.08426845818758011\n",
      "Iteration: 553/10000, Loss: 0.06300631910562515\n",
      "Iteration: 554/10000, Loss: 0.06776446104049683\n",
      "Iteration: 555/10000, Loss: 0.05246931314468384\n",
      "Iteration: 556/10000, Loss: 0.0663047656416893\n",
      "Iteration: 557/10000, Loss: 0.06901174038648605\n",
      "Iteration: 558/10000, Loss: 0.04808034375309944\n",
      "Iteration: 559/10000, Loss: 0.0420730859041214\n",
      "Iteration: 560/10000, Loss: 0.05289006605744362\n",
      "Iteration: 561/10000, Loss: 0.05714952573180199\n",
      "Iteration: 562/10000, Loss: 0.08191011101007462\n",
      "Iteration: 563/10000, Loss: 0.07337064296007156\n",
      "Iteration: 564/10000, Loss: 0.08411246538162231\n",
      "Iteration: 565/10000, Loss: 0.07654895633459091\n",
      "Iteration: 566/10000, Loss: 0.08017724752426147\n",
      "Iteration: 567/10000, Loss: 0.06533419340848923\n",
      "Iteration: 568/10000, Loss: 0.06546478718519211\n",
      "Iteration: 569/10000, Loss: 0.07343590259552002\n",
      "Iteration: 570/10000, Loss: 0.06254536658525467\n",
      "Iteration: 571/10000, Loss: 0.05461154505610466\n",
      "Iteration: 572/10000, Loss: 0.05127502977848053\n",
      "Iteration: 573/10000, Loss: 0.06490844488143921\n",
      "Iteration: 574/10000, Loss: 0.08701231330633163\n",
      "Iteration: 575/10000, Loss: 0.05205535516142845\n",
      "Iteration: 576/10000, Loss: 0.05246808007359505\n",
      "Iteration: 577/10000, Loss: 0.053802717477083206\n",
      "Iteration: 578/10000, Loss: 0.06974738091230392\n",
      "Iteration: 579/10000, Loss: 0.05860837176442146\n",
      "Iteration: 580/10000, Loss: 0.07403869926929474\n",
      "Iteration: 581/10000, Loss: 0.06726601719856262\n",
      "Iteration: 582/10000, Loss: 0.06355544924736023\n",
      "Iteration: 583/10000, Loss: 0.05767972022294998\n",
      "Iteration: 584/10000, Loss: 0.08245500922203064\n",
      "Iteration: 585/10000, Loss: 0.058255501091480255\n",
      "Iteration: 586/10000, Loss: 0.08763045072555542\n",
      "Iteration: 587/10000, Loss: 0.05701935663819313\n",
      "Iteration: 588/10000, Loss: 0.06159742549061775\n",
      "Iteration: 589/10000, Loss: 0.07115131616592407\n",
      "Iteration: 590/10000, Loss: 0.053376879543066025\n",
      "Iteration: 591/10000, Loss: 0.05907303839921951\n",
      "Iteration: 592/10000, Loss: 0.05635330080986023\n",
      "Iteration: 593/10000, Loss: 0.05080443248152733\n",
      "Iteration: 594/10000, Loss: 0.06828759610652924\n",
      "Iteration: 595/10000, Loss: 0.06261244416236877\n",
      "Iteration: 596/10000, Loss: 0.05912568047642708\n",
      "Iteration: 597/10000, Loss: 0.047004420310258865\n",
      "Iteration: 598/10000, Loss: 0.05915963649749756\n",
      "Iteration: 599/10000, Loss: 0.053588517010211945\n",
      "Iteration: 600/10000, Loss: 0.05616457760334015\n",
      "Average test loss:  0.0044\n",
      "Iteration: 601/10000, Loss: 0.07025045901536942\n",
      "Iteration: 602/10000, Loss: 0.05779699236154556\n",
      "Iteration: 603/10000, Loss: 0.061901580542325974\n",
      "Iteration: 604/10000, Loss: 0.06844764947891235\n",
      "Iteration: 605/10000, Loss: 0.06463483721017838\n",
      "Iteration: 606/10000, Loss: 0.06553488969802856\n",
      "Iteration: 607/10000, Loss: 0.06907323747873306\n",
      "Iteration: 608/10000, Loss: 0.047965195029973984\n",
      "Iteration: 609/10000, Loss: 0.0592045933008194\n",
      "Iteration: 610/10000, Loss: 0.06785615533590317\n",
      "Iteration: 611/10000, Loss: 0.0758577287197113\n",
      "Iteration: 612/10000, Loss: 0.06719546020030975\n",
      "Iteration: 613/10000, Loss: 0.05093326047062874\n",
      "Iteration: 614/10000, Loss: 0.051987968385219574\n",
      "Iteration: 615/10000, Loss: 0.052521973848342896\n",
      "Iteration: 616/10000, Loss: 0.06868680566549301\n",
      "Iteration: 617/10000, Loss: 0.05491551384329796\n",
      "Iteration: 618/10000, Loss: 0.04541965201497078\n",
      "Iteration: 619/10000, Loss: 0.05215340852737427\n",
      "Iteration: 620/10000, Loss: 0.054586995393037796\n",
      "Iteration: 621/10000, Loss: 0.0351073294878006\n",
      "Iteration: 622/10000, Loss: 0.07038427889347076\n",
      "Iteration: 623/10000, Loss: 0.056847479194402695\n",
      "Iteration: 624/10000, Loss: 0.05264085531234741\n",
      "Iteration: 625/10000, Loss: 0.04990807920694351\n",
      "Iteration: 626/10000, Loss: 0.0758126899600029\n",
      "Iteration: 627/10000, Loss: 0.05555879697203636\n",
      "Iteration: 628/10000, Loss: 0.041912104934453964\n",
      "Iteration: 629/10000, Loss: 0.05497961863875389\n",
      "Iteration: 630/10000, Loss: 0.05427448824048042\n",
      "Iteration: 631/10000, Loss: 0.054064635187387466\n",
      "Iteration: 632/10000, Loss: 0.057710614055395126\n",
      "Iteration: 633/10000, Loss: 0.06407160311937332\n",
      "Iteration: 634/10000, Loss: 0.039181701838970184\n",
      "Iteration: 635/10000, Loss: 0.06133238226175308\n",
      "Iteration: 636/10000, Loss: 0.05942677706480026\n",
      "Iteration: 637/10000, Loss: 0.04663151130080223\n",
      "Iteration: 638/10000, Loss: 0.05868379771709442\n",
      "Iteration: 639/10000, Loss: 0.05206504836678505\n",
      "Iteration: 640/10000, Loss: 0.07063546031713486\n",
      "Iteration: 641/10000, Loss: 0.04698316752910614\n",
      "Iteration: 642/10000, Loss: 0.04534686356782913\n",
      "Iteration: 643/10000, Loss: 0.05438297986984253\n",
      "Iteration: 644/10000, Loss: 0.049631644040346146\n",
      "Iteration: 645/10000, Loss: 0.0630095824599266\n",
      "Iteration: 646/10000, Loss: 0.0445808582007885\n",
      "Iteration: 647/10000, Loss: 0.04727741703391075\n",
      "Iteration: 648/10000, Loss: 0.060578569769859314\n",
      "Iteration: 649/10000, Loss: 0.06074921414256096\n",
      "Iteration: 650/10000, Loss: 0.035583771765232086\n",
      "Iteration: 651/10000, Loss: 0.05095212161540985\n",
      "Iteration: 652/10000, Loss: 0.06696204841136932\n",
      "Iteration: 653/10000, Loss: 0.055769361555576324\n",
      "Iteration: 654/10000, Loss: 0.04455886781215668\n",
      "Iteration: 655/10000, Loss: 0.051380705088377\n",
      "Iteration: 656/10000, Loss: 0.05565867945551872\n",
      "Iteration: 657/10000, Loss: 0.06249167397618294\n",
      "Iteration: 658/10000, Loss: 0.051908742636442184\n",
      "Iteration: 659/10000, Loss: 0.058903634548187256\n",
      "Iteration: 660/10000, Loss: 0.046901002526283264\n",
      "Iteration: 661/10000, Loss: 0.046642277389764786\n",
      "Iteration: 662/10000, Loss: 0.07663604617118835\n",
      "Iteration: 663/10000, Loss: 0.0562717579305172\n",
      "Iteration: 664/10000, Loss: 0.05200991779565811\n",
      "Iteration: 665/10000, Loss: 0.06197941675782204\n",
      "Iteration: 666/10000, Loss: 0.04193585738539696\n",
      "Iteration: 667/10000, Loss: 0.04392101988196373\n",
      "Iteration: 668/10000, Loss: 0.042282409965991974\n",
      "Iteration: 669/10000, Loss: 0.055479444563388824\n",
      "Iteration: 670/10000, Loss: 0.054487165063619614\n",
      "Iteration: 671/10000, Loss: 0.049062829464673996\n",
      "Iteration: 672/10000, Loss: 0.05732140317559242\n",
      "Iteration: 673/10000, Loss: 0.0662197396159172\n",
      "Iteration: 674/10000, Loss: 0.07535108178853989\n",
      "Iteration: 675/10000, Loss: 0.05262955650687218\n",
      "Iteration: 676/10000, Loss: 0.04401843249797821\n",
      "Iteration: 677/10000, Loss: 0.04482970014214516\n",
      "Iteration: 678/10000, Loss: 0.047511059790849686\n",
      "Iteration: 679/10000, Loss: 0.041239798069000244\n",
      "Iteration: 680/10000, Loss: 0.06092453747987747\n",
      "Iteration: 681/10000, Loss: 0.05400092154741287\n",
      "Iteration: 682/10000, Loss: 0.06011892855167389\n",
      "Iteration: 683/10000, Loss: 0.03751188516616821\n",
      "Iteration: 684/10000, Loss: 0.04610279202461243\n",
      "Iteration: 685/10000, Loss: 0.04745298996567726\n",
      "Iteration: 686/10000, Loss: 0.0863826647400856\n",
      "Iteration: 687/10000, Loss: 0.052659597247838974\n",
      "Iteration: 688/10000, Loss: 0.05348490551114082\n",
      "Iteration: 689/10000, Loss: 0.04094139486551285\n",
      "Iteration: 690/10000, Loss: 0.0354984849691391\n",
      "Iteration: 691/10000, Loss: 0.05190280079841614\n",
      "Iteration: 692/10000, Loss: 0.040286459028720856\n",
      "Iteration: 693/10000, Loss: 0.04660281538963318\n",
      "Iteration: 694/10000, Loss: 0.0571218803524971\n",
      "Iteration: 695/10000, Loss: 0.050937626510858536\n",
      "Iteration: 696/10000, Loss: 0.04916371777653694\n",
      "Iteration: 697/10000, Loss: 0.04289085045456886\n",
      "Iteration: 698/10000, Loss: 0.06943663954734802\n",
      "Iteration: 699/10000, Loss: 0.042149778455495834\n",
      "Iteration: 700/10000, Loss: 0.046618346124887466\n",
      "Average test loss:  0.0040\n",
      "Iteration: 701/10000, Loss: 0.045924343168735504\n",
      "Iteration: 702/10000, Loss: 0.05688495934009552\n",
      "Iteration: 703/10000, Loss: 0.039352159947156906\n",
      "Iteration: 704/10000, Loss: 0.05376386269927025\n",
      "Iteration: 705/10000, Loss: 0.054290153086185455\n",
      "Iteration: 706/10000, Loss: 0.049014002084732056\n",
      "Iteration: 707/10000, Loss: 0.054912470281124115\n",
      "Iteration: 708/10000, Loss: 0.05254770815372467\n",
      "Iteration: 709/10000, Loss: 0.05371652543544769\n",
      "Iteration: 710/10000, Loss: 0.03739522024989128\n",
      "Iteration: 711/10000, Loss: 0.04489941895008087\n",
      "Iteration: 712/10000, Loss: 0.06917660683393478\n",
      "Iteration: 713/10000, Loss: 0.055344730615615845\n",
      "Iteration: 714/10000, Loss: 0.0677507147192955\n",
      "Iteration: 715/10000, Loss: 0.05241876095533371\n",
      "Iteration: 716/10000, Loss: 0.042429119348526\n",
      "Iteration: 717/10000, Loss: 0.045559756457805634\n",
      "Iteration: 718/10000, Loss: 0.05692924186587334\n",
      "Iteration: 719/10000, Loss: 0.06569261103868484\n",
      "Iteration: 720/10000, Loss: 0.053075361996889114\n",
      "Iteration: 721/10000, Loss: 0.060261569917201996\n",
      "Iteration: 722/10000, Loss: 0.04298538342118263\n",
      "Iteration: 723/10000, Loss: 0.037818361073732376\n",
      "Iteration: 724/10000, Loss: 0.04037877917289734\n",
      "Iteration: 725/10000, Loss: 0.0486258864402771\n",
      "Iteration: 726/10000, Loss: 0.050519708544015884\n",
      "Iteration: 727/10000, Loss: 0.06128022447228432\n",
      "Iteration: 728/10000, Loss: 0.05925440415740013\n",
      "Iteration: 729/10000, Loss: 0.056526217609643936\n",
      "Iteration: 730/10000, Loss: 0.052068810909986496\n",
      "Iteration: 731/10000, Loss: 0.0477767176926136\n",
      "Iteration: 732/10000, Loss: 0.046313848346471786\n",
      "Iteration: 733/10000, Loss: 0.04640926048159599\n",
      "Iteration: 734/10000, Loss: 0.05881880968809128\n",
      "Iteration: 735/10000, Loss: 0.0358666330575943\n",
      "Iteration: 736/10000, Loss: 0.04806859418749809\n",
      "Iteration: 737/10000, Loss: 0.03990791365504265\n",
      "Iteration: 738/10000, Loss: 0.052253358066082\n",
      "Iteration: 739/10000, Loss: 0.07047530263662338\n",
      "Iteration: 740/10000, Loss: 0.040835268795490265\n",
      "Iteration: 741/10000, Loss: 0.049279678612947464\n",
      "Iteration: 742/10000, Loss: 0.064241923391819\n",
      "Iteration: 743/10000, Loss: 0.042380351573228836\n",
      "Iteration: 744/10000, Loss: 0.057709950953722\n",
      "Iteration: 745/10000, Loss: 0.05154775455594063\n",
      "Iteration: 746/10000, Loss: 0.06424438208341599\n",
      "Iteration: 747/10000, Loss: 0.05833306163549423\n",
      "Iteration: 748/10000, Loss: 0.05586637184023857\n",
      "Iteration: 749/10000, Loss: 0.04615134745836258\n",
      "Iteration: 750/10000, Loss: 0.062253739684820175\n",
      "Iteration: 751/10000, Loss: 0.05464696139097214\n",
      "Iteration: 752/10000, Loss: 0.05563141778111458\n",
      "Iteration: 753/10000, Loss: 0.03933148458600044\n",
      "Iteration: 754/10000, Loss: 0.03550797700881958\n",
      "Iteration: 755/10000, Loss: 0.06338759511709213\n",
      "Iteration: 756/10000, Loss: 0.034201979637145996\n",
      "Iteration: 757/10000, Loss: 0.034644775092601776\n",
      "Iteration: 758/10000, Loss: 0.04034000635147095\n",
      "Iteration: 759/10000, Loss: 0.04182584211230278\n",
      "Iteration: 760/10000, Loss: 0.06284783035516739\n",
      "Iteration: 761/10000, Loss: 0.056138236075639725\n",
      "Iteration: 762/10000, Loss: 0.04436350241303444\n",
      "Iteration: 763/10000, Loss: 0.0532771460711956\n",
      "Iteration: 764/10000, Loss: 0.0454121008515358\n",
      "Iteration: 765/10000, Loss: 0.06611866503953934\n",
      "Iteration: 766/10000, Loss: 0.04799690097570419\n",
      "Iteration: 767/10000, Loss: 0.04274485260248184\n",
      "Iteration: 768/10000, Loss: 0.04795776307582855\n",
      "Iteration: 769/10000, Loss: 0.058499403297901154\n",
      "Iteration: 770/10000, Loss: 0.05534853786230087\n",
      "Iteration: 771/10000, Loss: 0.04434317722916603\n",
      "Iteration: 772/10000, Loss: 0.0416647270321846\n",
      "Iteration: 773/10000, Loss: 0.07335566729307175\n",
      "Iteration: 774/10000, Loss: 0.055111248046159744\n",
      "Iteration: 775/10000, Loss: 0.05217945948243141\n",
      "Iteration: 776/10000, Loss: 0.05165655165910721\n",
      "Iteration: 777/10000, Loss: 0.05482344329357147\n",
      "Iteration: 778/10000, Loss: 0.044217634946107864\n",
      "Iteration: 779/10000, Loss: 0.042584050446748734\n",
      "Iteration: 780/10000, Loss: 0.03828027844429016\n",
      "Iteration: 781/10000, Loss: 0.06627991795539856\n",
      "Iteration: 782/10000, Loss: 0.038200996816158295\n",
      "Iteration: 783/10000, Loss: 0.042657624930143356\n",
      "Iteration: 784/10000, Loss: 0.05185646936297417\n",
      "Iteration: 785/10000, Loss: 0.03337538242340088\n",
      "Iteration: 786/10000, Loss: 0.050492919981479645\n",
      "Iteration: 787/10000, Loss: 0.06231179088354111\n",
      "Iteration: 788/10000, Loss: 0.03706562519073486\n",
      "Iteration: 789/10000, Loss: 0.061256371438503265\n",
      "Iteration: 790/10000, Loss: 0.06762658804655075\n",
      "Iteration: 791/10000, Loss: 0.04047324135899544\n",
      "Iteration: 792/10000, Loss: 0.0329904742538929\n",
      "Iteration: 793/10000, Loss: 0.05353056266903877\n",
      "Iteration: 794/10000, Loss: 0.044126518070697784\n",
      "Iteration: 795/10000, Loss: 0.038732752203941345\n",
      "Iteration: 796/10000, Loss: 0.03201402723789215\n",
      "Iteration: 797/10000, Loss: 0.04864268749952316\n",
      "Iteration: 798/10000, Loss: 0.05413258820772171\n",
      "Iteration: 799/10000, Loss: 0.053606241941452026\n",
      "Iteration: 800/10000, Loss: 0.034804780036211014\n",
      "Average test loss:  0.0048\n",
      "Iteration: 801/10000, Loss: 0.04144422337412834\n",
      "Iteration: 802/10000, Loss: 0.037302374839782715\n",
      "Iteration: 803/10000, Loss: 0.05971711501479149\n",
      "Iteration: 804/10000, Loss: 0.048752181231975555\n",
      "Iteration: 805/10000, Loss: 0.03227505460381508\n",
      "Iteration: 806/10000, Loss: 0.04402213543653488\n",
      "Iteration: 807/10000, Loss: 0.04597238078713417\n",
      "Iteration: 808/10000, Loss: 0.049061182886362076\n",
      "Iteration: 809/10000, Loss: 0.07057339698076248\n",
      "Iteration: 810/10000, Loss: 0.0779782310128212\n",
      "Iteration: 811/10000, Loss: 0.05291726812720299\n",
      "Iteration: 812/10000, Loss: 0.055172983556985855\n",
      "Iteration: 813/10000, Loss: 0.038871463388204575\n",
      "Iteration: 814/10000, Loss: 0.044657379388809204\n",
      "Iteration: 815/10000, Loss: 0.05555193871259689\n",
      "Iteration: 816/10000, Loss: 0.03634730353951454\n",
      "Iteration: 817/10000, Loss: 0.05460050702095032\n",
      "Iteration: 818/10000, Loss: 0.057940781116485596\n",
      "Iteration: 819/10000, Loss: 0.03689407929778099\n",
      "Iteration: 820/10000, Loss: 0.03753038868308067\n",
      "Iteration: 821/10000, Loss: 0.06084549054503441\n",
      "Iteration: 822/10000, Loss: 0.06688570976257324\n",
      "Iteration: 823/10000, Loss: 0.04570412263274193\n",
      "Iteration: 824/10000, Loss: 0.053288452327251434\n",
      "Iteration: 825/10000, Loss: 0.04789719730615616\n",
      "Iteration: 826/10000, Loss: 0.035585615783929825\n",
      "Iteration: 827/10000, Loss: 0.04661685228347778\n",
      "Iteration: 828/10000, Loss: 0.06786318123340607\n",
      "Iteration: 829/10000, Loss: 0.05978022515773773\n",
      "Iteration: 830/10000, Loss: 0.05779295042157173\n",
      "Iteration: 831/10000, Loss: 0.055247481912374496\n",
      "Iteration: 832/10000, Loss: 0.0387914776802063\n",
      "Iteration: 833/10000, Loss: 0.043949030339717865\n",
      "Iteration: 834/10000, Loss: 0.04088073596358299\n",
      "Iteration: 835/10000, Loss: 0.04725531116127968\n",
      "Iteration: 836/10000, Loss: 0.05006251856684685\n",
      "Iteration: 837/10000, Loss: 0.050674643367528915\n",
      "Iteration: 838/10000, Loss: 0.04139747470617294\n",
      "Iteration: 839/10000, Loss: 0.06892798095941544\n",
      "Iteration: 840/10000, Loss: 0.03421659767627716\n",
      "Iteration: 841/10000, Loss: 0.051146067678928375\n",
      "Iteration: 842/10000, Loss: 0.06090640649199486\n",
      "Iteration: 843/10000, Loss: 0.05284379422664642\n",
      "Iteration: 844/10000, Loss: 0.041279759258031845\n",
      "Iteration: 845/10000, Loss: 0.03751479089260101\n",
      "Iteration: 846/10000, Loss: 0.03617590293288231\n",
      "Iteration: 847/10000, Loss: 0.04985705390572548\n",
      "Iteration: 848/10000, Loss: 0.04469921067357063\n",
      "Iteration: 849/10000, Loss: 0.06696271151304245\n",
      "Iteration: 850/10000, Loss: 0.0401017926633358\n",
      "Iteration: 851/10000, Loss: 0.0504322424530983\n",
      "Iteration: 852/10000, Loss: 0.053076256066560745\n",
      "Iteration: 853/10000, Loss: 0.03995421528816223\n",
      "Iteration: 854/10000, Loss: 0.03874137997627258\n",
      "Iteration: 855/10000, Loss: 0.0521567203104496\n",
      "Iteration: 856/10000, Loss: 0.049557000398635864\n",
      "Iteration: 857/10000, Loss: 0.03955472260713577\n",
      "Iteration: 858/10000, Loss: 0.05405120924115181\n",
      "Iteration: 859/10000, Loss: 0.0445045605301857\n",
      "Iteration: 860/10000, Loss: 0.0495450422167778\n",
      "Iteration: 861/10000, Loss: 0.03918321803212166\n",
      "Iteration: 862/10000, Loss: 0.04159020259976387\n",
      "Iteration: 863/10000, Loss: 0.045116864144802094\n",
      "Iteration: 864/10000, Loss: 0.0741734504699707\n",
      "Iteration: 865/10000, Loss: 0.046242743730545044\n",
      "Iteration: 866/10000, Loss: 0.047639939934015274\n",
      "Iteration: 867/10000, Loss: 0.059933777898550034\n",
      "Iteration: 868/10000, Loss: 0.05733120068907738\n",
      "Iteration: 869/10000, Loss: 0.04062759503722191\n",
      "Iteration: 870/10000, Loss: 0.05103295296430588\n",
      "Iteration: 871/10000, Loss: 0.0585944764316082\n",
      "Iteration: 872/10000, Loss: 0.042771488428115845\n",
      "Iteration: 873/10000, Loss: 0.031911447644233704\n",
      "Iteration: 874/10000, Loss: 0.0364510640501976\n",
      "Iteration: 875/10000, Loss: 0.06358244270086288\n",
      "Iteration: 876/10000, Loss: 0.02993638813495636\n",
      "Iteration: 877/10000, Loss: 0.04067768156528473\n",
      "Iteration: 878/10000, Loss: 0.06149226799607277\n",
      "Iteration: 879/10000, Loss: 0.03310852125287056\n",
      "Iteration: 880/10000, Loss: 0.060652486979961395\n",
      "Iteration: 881/10000, Loss: 0.05736538767814636\n",
      "Iteration: 882/10000, Loss: 0.04611008241772652\n",
      "Iteration: 883/10000, Loss: 0.04549899697303772\n",
      "Iteration: 884/10000, Loss: 0.04536714032292366\n",
      "Iteration: 885/10000, Loss: 0.03807705268263817\n",
      "Iteration: 886/10000, Loss: 0.04703199118375778\n",
      "Iteration: 887/10000, Loss: 0.04712064191699028\n",
      "Iteration: 888/10000, Loss: 0.04774996265769005\n",
      "Iteration: 889/10000, Loss: 0.04846927523612976\n",
      "Iteration: 890/10000, Loss: 0.054684169590473175\n",
      "Iteration: 891/10000, Loss: 0.0940481573343277\n",
      "Iteration: 892/10000, Loss: 0.07387197017669678\n",
      "Iteration: 893/10000, Loss: 0.056565988808870316\n",
      "Iteration: 894/10000, Loss: 0.0462866872549057\n",
      "Iteration: 895/10000, Loss: 0.04984350502490997\n",
      "Iteration: 896/10000, Loss: 0.05104351416230202\n",
      "Iteration: 897/10000, Loss: 0.05143684148788452\n",
      "Iteration: 898/10000, Loss: 0.04344365373253822\n",
      "Iteration: 899/10000, Loss: 0.05796670541167259\n",
      "Iteration: 900/10000, Loss: 0.04669218137860298\n",
      "Average test loss:  0.0043\n",
      "Iteration: 901/10000, Loss: 0.03921587020158768\n",
      "Iteration: 902/10000, Loss: 0.060355234891176224\n",
      "Iteration: 903/10000, Loss: 0.037382517009973526\n",
      "Iteration: 904/10000, Loss: 0.03423101827502251\n",
      "Iteration: 905/10000, Loss: 0.05043104290962219\n",
      "Iteration: 906/10000, Loss: 0.05170836299657822\n",
      "Iteration: 907/10000, Loss: 0.04091847687959671\n",
      "Iteration: 908/10000, Loss: 0.044508740305900574\n",
      "Iteration: 909/10000, Loss: 0.046883467584848404\n",
      "Iteration: 910/10000, Loss: 0.060899537056684494\n",
      "Iteration: 911/10000, Loss: 0.05946492403745651\n",
      "Iteration: 912/10000, Loss: 0.051612675189971924\n",
      "Iteration: 913/10000, Loss: 0.029949994757771492\n",
      "Iteration: 914/10000, Loss: 0.05155067518353462\n",
      "Iteration: 915/10000, Loss: 0.04122839495539665\n",
      "Iteration: 916/10000, Loss: 0.03879586234688759\n",
      "Iteration: 917/10000, Loss: 0.03500240668654442\n",
      "Iteration: 918/10000, Loss: 0.04544079303741455\n",
      "Iteration: 919/10000, Loss: 0.0459216944873333\n",
      "Iteration: 920/10000, Loss: 0.039853621274232864\n",
      "Iteration: 921/10000, Loss: 0.046288829296827316\n",
      "Iteration: 922/10000, Loss: 0.03917517885565758\n",
      "Iteration: 923/10000, Loss: 0.0458076037466526\n",
      "Iteration: 924/10000, Loss: 0.04600837454199791\n",
      "Iteration: 925/10000, Loss: 0.0358014851808548\n",
      "Iteration: 926/10000, Loss: 0.05404293164610863\n",
      "Iteration: 927/10000, Loss: 0.04021843522787094\n",
      "Iteration: 928/10000, Loss: 0.04679334536194801\n",
      "Iteration: 929/10000, Loss: 0.04081694781780243\n",
      "Iteration: 930/10000, Loss: 0.03676164895296097\n",
      "Iteration: 931/10000, Loss: 0.04517008736729622\n",
      "Iteration: 932/10000, Loss: 0.05325430631637573\n",
      "Iteration: 933/10000, Loss: 0.06387916207313538\n",
      "Iteration: 934/10000, Loss: 0.049303799867630005\n",
      "Iteration: 935/10000, Loss: 0.03648962825536728\n",
      "Iteration: 936/10000, Loss: 0.04017699509859085\n",
      "Iteration: 937/10000, Loss: 0.050272148102521896\n",
      "Iteration: 938/10000, Loss: 0.05289581045508385\n",
      "Iteration: 939/10000, Loss: 0.06333030015230179\n",
      "Iteration: 940/10000, Loss: 0.041080620139837265\n",
      "Iteration: 941/10000, Loss: 0.04054192826151848\n",
      "Iteration: 942/10000, Loss: 0.057116758078336716\n",
      "Iteration: 943/10000, Loss: 0.0360029973089695\n",
      "Iteration: 944/10000, Loss: 0.03992437571287155\n",
      "Iteration: 945/10000, Loss: 0.05159914121031761\n",
      "Iteration: 946/10000, Loss: 0.04149950295686722\n",
      "Iteration: 947/10000, Loss: 0.05275506153702736\n",
      "Iteration: 948/10000, Loss: 0.033418457955121994\n",
      "Iteration: 949/10000, Loss: 0.04582662507891655\n",
      "Iteration: 950/10000, Loss: 0.03887039050459862\n",
      "Iteration: 951/10000, Loss: 0.049291323870420456\n",
      "Iteration: 952/10000, Loss: 0.03348740190267563\n",
      "Iteration: 953/10000, Loss: 0.030634816735982895\n",
      "Iteration: 954/10000, Loss: 0.03599029779434204\n",
      "Iteration: 955/10000, Loss: 0.03999974578619003\n",
      "Iteration: 956/10000, Loss: 0.045610181987285614\n",
      "Iteration: 957/10000, Loss: 0.03334136679768562\n",
      "Iteration: 958/10000, Loss: 0.054085053503513336\n",
      "Iteration: 959/10000, Loss: 0.05910058319568634\n",
      "Iteration: 960/10000, Loss: 0.049141887575387955\n",
      "Iteration: 961/10000, Loss: 0.045326072722673416\n",
      "Iteration: 962/10000, Loss: 0.045036934316158295\n",
      "Iteration: 963/10000, Loss: 0.04117969051003456\n",
      "Iteration: 964/10000, Loss: 0.04663271829485893\n",
      "Iteration: 965/10000, Loss: 0.03507520630955696\n",
      "Iteration: 966/10000, Loss: 0.04279245063662529\n",
      "Iteration: 967/10000, Loss: 0.055695414543151855\n",
      "Iteration: 968/10000, Loss: 0.04153793677687645\n",
      "Iteration: 969/10000, Loss: 0.044067319482564926\n",
      "Iteration: 970/10000, Loss: 0.06296786665916443\n",
      "Iteration: 971/10000, Loss: 0.05609738081693649\n",
      "Iteration: 972/10000, Loss: 0.030591445043683052\n",
      "Iteration: 973/10000, Loss: 0.040888674557209015\n",
      "Iteration: 974/10000, Loss: 0.06708187609910965\n",
      "Iteration: 975/10000, Loss: 0.0507514514029026\n",
      "Iteration: 976/10000, Loss: 0.04314820468425751\n",
      "Iteration: 977/10000, Loss: 0.0404924638569355\n",
      "Iteration: 978/10000, Loss: 0.05030135437846184\n",
      "Iteration: 979/10000, Loss: 0.0601537749171257\n",
      "Iteration: 980/10000, Loss: 0.0394599586725235\n",
      "Iteration: 981/10000, Loss: 0.03996894136071205\n",
      "Iteration: 982/10000, Loss: 0.0385453961789608\n",
      "Iteration: 983/10000, Loss: 0.0672059878706932\n",
      "Iteration: 984/10000, Loss: 0.03158160299062729\n",
      "Iteration: 985/10000, Loss: 0.045490384101867676\n",
      "Iteration: 986/10000, Loss: 0.04207621514797211\n",
      "Iteration: 987/10000, Loss: 0.04055166617035866\n",
      "Iteration: 988/10000, Loss: 0.028602737933397293\n",
      "Iteration: 989/10000, Loss: 0.034545764327049255\n",
      "Iteration: 990/10000, Loss: 0.03985075652599335\n",
      "Iteration: 991/10000, Loss: 0.052677854895591736\n",
      "Iteration: 992/10000, Loss: 0.042894475162029266\n",
      "Iteration: 993/10000, Loss: 0.062074143439531326\n",
      "Iteration: 994/10000, Loss: 0.05349789932370186\n",
      "Iteration: 995/10000, Loss: 0.046941302716732025\n",
      "Iteration: 996/10000, Loss: 0.03519666939973831\n",
      "Iteration: 997/10000, Loss: 0.046958841383457184\n",
      "Iteration: 998/10000, Loss: 0.04540490359067917\n",
      "Iteration: 999/10000, Loss: 0.06317267566919327\n",
      "Iteration: 1000/10000, Loss: 0.05743822455406189\n",
      "Average test loss:  0.0036\n",
      "Iteration: 1001/10000, Loss: 0.03926745802164078\n",
      "Iteration: 1002/10000, Loss: 0.03828255459666252\n",
      "Iteration: 1003/10000, Loss: 0.03822966665029526\n",
      "Iteration: 1004/10000, Loss: 0.03951305150985718\n",
      "Iteration: 1005/10000, Loss: 0.047994956374168396\n",
      "Iteration: 1006/10000, Loss: 0.04784119501709938\n",
      "Iteration: 1007/10000, Loss: 0.029054313898086548\n",
      "Iteration: 1008/10000, Loss: 0.07848823815584183\n",
      "Iteration: 1009/10000, Loss: 0.06195332482457161\n",
      "Iteration: 1010/10000, Loss: 0.05237255617976189\n",
      "Iteration: 1011/10000, Loss: 0.04760124161839485\n",
      "Iteration: 1012/10000, Loss: 0.033973414450883865\n",
      "Iteration: 1013/10000, Loss: 0.05087484419345856\n",
      "Iteration: 1014/10000, Loss: 0.03541718050837517\n",
      "Iteration: 1015/10000, Loss: 0.03538360446691513\n",
      "Iteration: 1016/10000, Loss: 0.041534461081027985\n",
      "Iteration: 1017/10000, Loss: 0.029815925285220146\n",
      "Iteration: 1018/10000, Loss: 0.04022178053855896\n",
      "Iteration: 1019/10000, Loss: 0.0415959395468235\n",
      "Iteration: 1020/10000, Loss: 0.043259479105472565\n",
      "Iteration: 1021/10000, Loss: 0.039564017206430435\n",
      "Iteration: 1022/10000, Loss: 0.05361311882734299\n",
      "Iteration: 1023/10000, Loss: 0.026640858501195908\n",
      "Iteration: 1024/10000, Loss: 0.04300627112388611\n",
      "Iteration: 1025/10000, Loss: 0.03355039656162262\n",
      "Iteration: 1026/10000, Loss: 0.04237649217247963\n",
      "Iteration: 1027/10000, Loss: 0.035981759428977966\n",
      "Iteration: 1028/10000, Loss: 0.042045705020427704\n",
      "Iteration: 1029/10000, Loss: 0.05217481404542923\n",
      "Iteration: 1030/10000, Loss: 0.05053781345486641\n",
      "Iteration: 1031/10000, Loss: 0.04859151691198349\n",
      "Iteration: 1032/10000, Loss: 0.04978371784090996\n",
      "Iteration: 1033/10000, Loss: 0.05011959373950958\n",
      "Iteration: 1034/10000, Loss: 0.044110797345638275\n",
      "Iteration: 1035/10000, Loss: 0.040933772921562195\n",
      "Iteration: 1036/10000, Loss: 0.04608207941055298\n",
      "Iteration: 1037/10000, Loss: 0.03751455619931221\n",
      "Iteration: 1038/10000, Loss: 0.048959359526634216\n",
      "Iteration: 1039/10000, Loss: 0.03451419994235039\n",
      "Iteration: 1040/10000, Loss: 0.03572019189596176\n",
      "Iteration: 1041/10000, Loss: 0.04823567345738411\n",
      "Iteration: 1042/10000, Loss: 0.046343497931957245\n",
      "Iteration: 1043/10000, Loss: 0.05841628462076187\n",
      "Iteration: 1044/10000, Loss: 0.04478198289871216\n",
      "Iteration: 1045/10000, Loss: 0.040701135993003845\n",
      "Iteration: 1046/10000, Loss: 0.056801408529281616\n",
      "Iteration: 1047/10000, Loss: 0.057783935219049454\n",
      "Iteration: 1048/10000, Loss: 0.04750364273786545\n",
      "Iteration: 1049/10000, Loss: 0.03643358126282692\n",
      "Iteration: 1050/10000, Loss: 0.06532112509012222\n",
      "Iteration: 1051/10000, Loss: 0.041517384350299835\n",
      "Iteration: 1052/10000, Loss: 0.04938683286309242\n",
      "Iteration: 1053/10000, Loss: 0.05284928157925606\n",
      "Iteration: 1054/10000, Loss: 0.045663438737392426\n",
      "Iteration: 1055/10000, Loss: 0.037969429045915604\n",
      "Iteration: 1056/10000, Loss: 0.040210794657468796\n",
      "Iteration: 1057/10000, Loss: 0.039557475596666336\n",
      "Iteration: 1058/10000, Loss: 0.0292873065918684\n",
      "Iteration: 1059/10000, Loss: 0.0333365872502327\n",
      "Iteration: 1060/10000, Loss: 0.04273553192615509\n",
      "Iteration: 1061/10000, Loss: 0.04240598529577255\n",
      "Iteration: 1062/10000, Loss: 0.050559964030981064\n",
      "Iteration: 1063/10000, Loss: 0.04662971571087837\n",
      "Iteration: 1064/10000, Loss: 0.06263909488916397\n",
      "Iteration: 1065/10000, Loss: 0.047734878957271576\n",
      "Iteration: 1066/10000, Loss: 0.03235326707363129\n",
      "Iteration: 1067/10000, Loss: 0.033955302089452744\n",
      "Iteration: 1068/10000, Loss: 0.04154974967241287\n",
      "Iteration: 1069/10000, Loss: 0.035853490233421326\n",
      "Iteration: 1070/10000, Loss: 0.039136484265327454\n",
      "Iteration: 1071/10000, Loss: 0.032541707158088684\n",
      "Iteration: 1072/10000, Loss: 0.042355917394161224\n",
      "Iteration: 1073/10000, Loss: 0.030009733512997627\n",
      "Iteration: 1074/10000, Loss: 0.05417352169752121\n",
      "Iteration: 1075/10000, Loss: 0.04865533486008644\n",
      "Iteration: 1076/10000, Loss: 0.044860683381557465\n",
      "Iteration: 1077/10000, Loss: 0.041814155876636505\n",
      "Iteration: 1078/10000, Loss: 0.04614883288741112\n",
      "Iteration: 1079/10000, Loss: 0.047245271503925323\n",
      "Iteration: 1080/10000, Loss: 0.0315212681889534\n",
      "Iteration: 1081/10000, Loss: 0.0468863882124424\n",
      "Iteration: 1082/10000, Loss: 0.03774630278348923\n",
      "Iteration: 1083/10000, Loss: 0.04357289522886276\n",
      "Iteration: 1084/10000, Loss: 0.04364563897252083\n",
      "Iteration: 1085/10000, Loss: 0.05404547229409218\n",
      "Iteration: 1086/10000, Loss: 0.04254712164402008\n",
      "Iteration: 1087/10000, Loss: 0.03406690061092377\n",
      "Iteration: 1088/10000, Loss: 0.025714745745062828\n",
      "Iteration: 1089/10000, Loss: 0.032363951206207275\n",
      "Iteration: 1090/10000, Loss: 0.027178121730685234\n",
      "Iteration: 1091/10000, Loss: 0.055214062333106995\n",
      "Iteration: 1092/10000, Loss: 0.05571996048092842\n",
      "Iteration: 1093/10000, Loss: 0.03294239565730095\n",
      "Iteration: 1094/10000, Loss: 0.05544088035821915\n",
      "Iteration: 1095/10000, Loss: 0.051413726061582565\n",
      "Iteration: 1096/10000, Loss: 0.03933677077293396\n",
      "Iteration: 1097/10000, Loss: 0.05204084515571594\n",
      "Iteration: 1098/10000, Loss: 0.0314062125980854\n",
      "Iteration: 1099/10000, Loss: 0.04375886172056198\n",
      "Iteration: 1100/10000, Loss: 0.04775222763419151\n",
      "Average test loss:  0.0023\n",
      "Iteration: 1101/10000, Loss: 0.04047514498233795\n",
      "Iteration: 1102/10000, Loss: 0.03572768718004227\n",
      "Iteration: 1103/10000, Loss: 0.040644899010658264\n",
      "Iteration: 1104/10000, Loss: 0.037354420870542526\n",
      "Iteration: 1105/10000, Loss: 0.034535255283117294\n",
      "Iteration: 1106/10000, Loss: 0.07326477766036987\n",
      "Iteration: 1107/10000, Loss: 0.03897152468562126\n",
      "Iteration: 1108/10000, Loss: 0.04350976645946503\n",
      "Iteration: 1109/10000, Loss: 0.04499093443155289\n",
      "Iteration: 1110/10000, Loss: 0.03580237552523613\n",
      "Iteration: 1111/10000, Loss: 0.052823979407548904\n",
      "Iteration: 1112/10000, Loss: 0.030676137655973434\n",
      "Iteration: 1113/10000, Loss: 0.04736736789345741\n",
      "Iteration: 1114/10000, Loss: 0.034695982933044434\n",
      "Iteration: 1115/10000, Loss: 0.04050282761454582\n",
      "Iteration: 1116/10000, Loss: 0.04609600454568863\n",
      "Iteration: 1117/10000, Loss: 0.049384575337171555\n",
      "Iteration: 1118/10000, Loss: 0.041747163981199265\n",
      "Iteration: 1119/10000, Loss: 0.04528726637363434\n",
      "Iteration: 1120/10000, Loss: 0.04788180813193321\n",
      "Iteration: 1121/10000, Loss: 0.05399278178811073\n",
      "Iteration: 1122/10000, Loss: 0.0390765480697155\n",
      "Iteration: 1123/10000, Loss: 0.04477714002132416\n",
      "Iteration: 1124/10000, Loss: 0.0383327454328537\n",
      "Iteration: 1125/10000, Loss: 0.039397671818733215\n",
      "Iteration: 1126/10000, Loss: 0.03842776268720627\n",
      "Iteration: 1127/10000, Loss: 0.04757684841752052\n",
      "Iteration: 1128/10000, Loss: 0.037496600300073624\n",
      "Iteration: 1129/10000, Loss: 0.04208395630121231\n",
      "Iteration: 1130/10000, Loss: 0.03800567239522934\n",
      "Iteration: 1131/10000, Loss: 0.033638034015893936\n",
      "Iteration: 1132/10000, Loss: 0.03702910616993904\n",
      "Iteration: 1133/10000, Loss: 0.03744308650493622\n",
      "Iteration: 1134/10000, Loss: 0.04420246556401253\n",
      "Iteration: 1135/10000, Loss: 0.03966856747865677\n",
      "Iteration: 1136/10000, Loss: 0.026408035308122635\n",
      "Iteration: 1137/10000, Loss: 0.05003548786044121\n",
      "Iteration: 1138/10000, Loss: 0.05331287905573845\n",
      "Iteration: 1139/10000, Loss: 0.044410496950149536\n",
      "Iteration: 1140/10000, Loss: 0.0793604925274849\n",
      "Iteration: 1141/10000, Loss: 0.03164250776171684\n",
      "Iteration: 1142/10000, Loss: 0.03281628340482712\n",
      "Iteration: 1143/10000, Loss: 0.0314275287091732\n",
      "Iteration: 1144/10000, Loss: 0.03779677674174309\n",
      "Iteration: 1145/10000, Loss: 0.044797785580158234\n",
      "Iteration: 1146/10000, Loss: 0.04235868528485298\n",
      "Iteration: 1147/10000, Loss: 0.03130875527858734\n",
      "Iteration: 1148/10000, Loss: 0.06609939783811569\n",
      "Iteration: 1149/10000, Loss: 0.05017050355672836\n",
      "Iteration: 1150/10000, Loss: 0.0365387462079525\n",
      "Iteration: 1151/10000, Loss: 0.06210677698254585\n",
      "Iteration: 1152/10000, Loss: 0.04569343104958534\n",
      "Iteration: 1153/10000, Loss: 0.04007754474878311\n",
      "Iteration: 1154/10000, Loss: 0.0417754203081131\n",
      "Iteration: 1155/10000, Loss: 0.04344019666314125\n",
      "Iteration: 1156/10000, Loss: 0.027627993375062943\n",
      "Iteration: 1157/10000, Loss: 0.044050432741642\n",
      "Iteration: 1158/10000, Loss: 0.05463215336203575\n",
      "Iteration: 1159/10000, Loss: 0.04802527651190758\n",
      "Iteration: 1160/10000, Loss: 0.05662078037858009\n",
      "Iteration: 1161/10000, Loss: 0.033847421407699585\n",
      "Iteration: 1162/10000, Loss: 0.03622271120548248\n",
      "Iteration: 1163/10000, Loss: 0.03254976123571396\n",
      "Iteration: 1164/10000, Loss: 0.039336975663900375\n",
      "Iteration: 1165/10000, Loss: 0.05084551125764847\n",
      "Iteration: 1166/10000, Loss: 0.041371505707502365\n",
      "Iteration: 1167/10000, Loss: 0.05396483838558197\n",
      "Iteration: 1168/10000, Loss: 0.042227450758218765\n",
      "Iteration: 1169/10000, Loss: 0.02746887132525444\n",
      "Iteration: 1170/10000, Loss: 0.02922162599861622\n",
      "Iteration: 1171/10000, Loss: 0.04293637350201607\n",
      "Iteration: 1172/10000, Loss: 0.05334681645035744\n",
      "Iteration: 1173/10000, Loss: 0.04660434275865555\n",
      "Iteration: 1174/10000, Loss: 0.039455562829971313\n",
      "Iteration: 1175/10000, Loss: 0.04729089513421059\n",
      "Iteration: 1176/10000, Loss: 0.02789558470249176\n",
      "Iteration: 1177/10000, Loss: 0.04692092165350914\n",
      "Iteration: 1178/10000, Loss: 0.031158728525042534\n",
      "Iteration: 1179/10000, Loss: 0.029621632769703865\n",
      "Iteration: 1180/10000, Loss: 0.02825874276459217\n",
      "Iteration: 1181/10000, Loss: 0.036160435527563095\n",
      "Iteration: 1182/10000, Loss: 0.08034010231494904\n",
      "Iteration: 1183/10000, Loss: 0.04482726752758026\n",
      "Iteration: 1184/10000, Loss: 0.03563655540347099\n",
      "Iteration: 1185/10000, Loss: 0.03661486133933067\n",
      "Iteration: 1186/10000, Loss: 0.04639315605163574\n",
      "Iteration: 1187/10000, Loss: 0.04065069556236267\n",
      "Iteration: 1188/10000, Loss: 0.042868226766586304\n",
      "Iteration: 1189/10000, Loss: 0.03049575351178646\n",
      "Iteration: 1190/10000, Loss: 0.049556050449609756\n",
      "Iteration: 1191/10000, Loss: 0.034243471920490265\n",
      "Iteration: 1192/10000, Loss: 0.02324390970170498\n",
      "Iteration: 1193/10000, Loss: 0.037034135311841965\n",
      "Iteration: 1194/10000, Loss: 0.04416460916399956\n",
      "Iteration: 1195/10000, Loss: 0.029939956963062286\n",
      "Iteration: 1196/10000, Loss: 0.04016917943954468\n",
      "Iteration: 1197/10000, Loss: 0.0324653759598732\n",
      "Iteration: 1198/10000, Loss: 0.038878392428159714\n",
      "Iteration: 1199/10000, Loss: 0.033697519451379776\n",
      "Iteration: 1200/10000, Loss: 0.04230472445487976\n",
      "Average test loss:  0.0057\n",
      "Iteration: 1201/10000, Loss: 0.04495786130428314\n",
      "Iteration: 1202/10000, Loss: 0.036203350871801376\n",
      "Iteration: 1203/10000, Loss: 0.04688359424471855\n",
      "Iteration: 1204/10000, Loss: 0.041190411895513535\n",
      "Iteration: 1205/10000, Loss: 0.024197541177272797\n",
      "Iteration: 1206/10000, Loss: 0.025511227548122406\n",
      "Iteration: 1207/10000, Loss: 0.03215576708316803\n",
      "Iteration: 1208/10000, Loss: 0.031003357842564583\n",
      "Iteration: 1209/10000, Loss: 0.03370155394077301\n",
      "Iteration: 1210/10000, Loss: 0.026727642863988876\n",
      "Iteration: 1211/10000, Loss: 0.03120438940823078\n",
      "Iteration: 1212/10000, Loss: 0.03333035856485367\n",
      "Iteration: 1213/10000, Loss: 0.023896466940641403\n",
      "Iteration: 1214/10000, Loss: 0.03792617842555046\n",
      "Iteration: 1215/10000, Loss: 0.03909894451498985\n",
      "Iteration: 1216/10000, Loss: 0.0570952333509922\n",
      "Iteration: 1217/10000, Loss: 0.044104013592004776\n",
      "Iteration: 1218/10000, Loss: 0.03600514307618141\n",
      "Iteration: 1219/10000, Loss: 0.03807641938328743\n",
      "Iteration: 1220/10000, Loss: 0.03750142455101013\n",
      "Iteration: 1221/10000, Loss: 0.03484645113348961\n",
      "Iteration: 1222/10000, Loss: 0.0426175557076931\n",
      "Iteration: 1223/10000, Loss: 0.04269281029701233\n",
      "Iteration: 1224/10000, Loss: 0.03736855089664459\n",
      "Iteration: 1225/10000, Loss: 0.028270132839679718\n",
      "Iteration: 1226/10000, Loss: 0.032530270516872406\n",
      "Iteration: 1227/10000, Loss: 0.03315754234790802\n",
      "Iteration: 1228/10000, Loss: 0.029183629900217056\n",
      "Iteration: 1229/10000, Loss: 0.04037335887551308\n",
      "Iteration: 1230/10000, Loss: 0.05041999742388725\n",
      "Iteration: 1231/10000, Loss: 0.031435463577508926\n",
      "Iteration: 1232/10000, Loss: 0.03181999549269676\n",
      "Iteration: 1233/10000, Loss: 0.028701791539788246\n",
      "Iteration: 1234/10000, Loss: 0.05666521564126015\n",
      "Iteration: 1235/10000, Loss: 0.042713552713394165\n",
      "Iteration: 1236/10000, Loss: 0.03838628903031349\n",
      "Iteration: 1237/10000, Loss: 0.036905307322740555\n",
      "Iteration: 1238/10000, Loss: 0.030191218480467796\n",
      "Iteration: 1239/10000, Loss: 0.03904056176543236\n",
      "Iteration: 1240/10000, Loss: 0.03322659060359001\n",
      "Iteration: 1241/10000, Loss: 0.03981521725654602\n",
      "Iteration: 1242/10000, Loss: 0.033775534480810165\n",
      "Iteration: 1243/10000, Loss: 0.028343375772237778\n",
      "Iteration: 1244/10000, Loss: 0.051072120666503906\n",
      "Iteration: 1245/10000, Loss: 0.031481027603149414\n",
      "Iteration: 1246/10000, Loss: 0.03483301401138306\n",
      "Iteration: 1247/10000, Loss: 0.04746634513139725\n",
      "Iteration: 1248/10000, Loss: 0.02897040918469429\n",
      "Iteration: 1249/10000, Loss: 0.049226872622966766\n",
      "Iteration: 1250/10000, Loss: 0.028929993510246277\n",
      "Iteration: 1251/10000, Loss: 0.030226657167077065\n",
      "Iteration: 1252/10000, Loss: 0.033214177936315536\n",
      "Iteration: 1253/10000, Loss: 0.04170661047101021\n",
      "Iteration: 1254/10000, Loss: 0.049053240567445755\n",
      "Iteration: 1255/10000, Loss: 0.05259852856397629\n",
      "Iteration: 1256/10000, Loss: 0.04071404039859772\n",
      "Iteration: 1257/10000, Loss: 0.03518078848719597\n",
      "Iteration: 1258/10000, Loss: 0.028257375583052635\n",
      "Iteration: 1259/10000, Loss: 0.03148053213953972\n",
      "Iteration: 1260/10000, Loss: 0.05023878440260887\n",
      "Iteration: 1261/10000, Loss: 0.04587828367948532\n",
      "Iteration: 1262/10000, Loss: 0.05696247145533562\n",
      "Iteration: 1263/10000, Loss: 0.035682640969753265\n",
      "Iteration: 1264/10000, Loss: 0.041801754385232925\n",
      "Iteration: 1265/10000, Loss: 0.040882404893636703\n",
      "Iteration: 1266/10000, Loss: 0.03396811708807945\n",
      "Iteration: 1267/10000, Loss: 0.048032552003860474\n",
      "Iteration: 1268/10000, Loss: 0.03694915398955345\n",
      "Iteration: 1269/10000, Loss: 0.025001637637615204\n",
      "Iteration: 1270/10000, Loss: 0.030915256589651108\n",
      "Iteration: 1271/10000, Loss: 0.04447054862976074\n",
      "Iteration: 1272/10000, Loss: 0.0575626865029335\n",
      "Iteration: 1273/10000, Loss: 0.039037641137838364\n",
      "Iteration: 1274/10000, Loss: 0.03658783435821533\n",
      "Iteration: 1275/10000, Loss: 0.03915158659219742\n",
      "Iteration: 1276/10000, Loss: 0.04706677049398422\n",
      "Iteration: 1277/10000, Loss: 0.042846862226724625\n",
      "Iteration: 1278/10000, Loss: 0.03291558101773262\n",
      "Iteration: 1279/10000, Loss: 0.04725579917430878\n",
      "Iteration: 1280/10000, Loss: 0.036371052265167236\n",
      "Iteration: 1281/10000, Loss: 0.04265377297997475\n",
      "Iteration: 1282/10000, Loss: 0.037562623620033264\n",
      "Iteration: 1283/10000, Loss: 0.03157423064112663\n",
      "Iteration: 1284/10000, Loss: 0.04249407723546028\n",
      "Iteration: 1285/10000, Loss: 0.05028737336397171\n",
      "Iteration: 1286/10000, Loss: 0.037868693470954895\n",
      "Iteration: 1287/10000, Loss: 0.024493461474776268\n",
      "Iteration: 1288/10000, Loss: 0.04115811362862587\n",
      "Iteration: 1289/10000, Loss: 0.042382389307022095\n",
      "Iteration: 1290/10000, Loss: 0.03656986728310585\n",
      "Iteration: 1291/10000, Loss: 0.04129729047417641\n",
      "Iteration: 1292/10000, Loss: 0.03310554102063179\n",
      "Iteration: 1293/10000, Loss: 0.04450776055455208\n",
      "Iteration: 1294/10000, Loss: 0.029716722667217255\n",
      "Iteration: 1295/10000, Loss: 0.04264388978481293\n",
      "Iteration: 1296/10000, Loss: 0.04240526258945465\n",
      "Iteration: 1297/10000, Loss: 0.037949081510305405\n",
      "Iteration: 1298/10000, Loss: 0.04092145338654518\n",
      "Iteration: 1299/10000, Loss: 0.034257929772138596\n",
      "Iteration: 1300/10000, Loss: 0.03827469050884247\n",
      "Average test loss:  0.0026\n",
      "Iteration: 1301/10000, Loss: 0.040149882435798645\n",
      "Iteration: 1302/10000, Loss: 0.03986912593245506\n",
      "Iteration: 1303/10000, Loss: 0.03620743751525879\n",
      "Iteration: 1304/10000, Loss: 0.0378621406853199\n",
      "Iteration: 1305/10000, Loss: 0.045318715274333954\n",
      "Iteration: 1306/10000, Loss: 0.04345225170254707\n",
      "Iteration: 1307/10000, Loss: 0.024140775203704834\n",
      "Iteration: 1308/10000, Loss: 0.021100228652358055\n",
      "Iteration: 1309/10000, Loss: 0.04395284131169319\n",
      "Iteration: 1310/10000, Loss: 0.04014616087079048\n",
      "Iteration: 1311/10000, Loss: 0.022807598114013672\n",
      "Iteration: 1312/10000, Loss: 0.02291531302034855\n",
      "Iteration: 1313/10000, Loss: 0.04191557690501213\n",
      "Iteration: 1314/10000, Loss: 0.03944395110011101\n",
      "Iteration: 1315/10000, Loss: 0.03137391060590744\n",
      "Iteration: 1316/10000, Loss: 0.01814747415482998\n",
      "Iteration: 1317/10000, Loss: 0.04485749080777168\n",
      "Iteration: 1318/10000, Loss: 0.04441872611641884\n",
      "Iteration: 1319/10000, Loss: 0.03673051297664642\n",
      "Iteration: 1320/10000, Loss: 0.040867879986763\n",
      "Iteration: 1321/10000, Loss: 0.03795044124126434\n",
      "Iteration: 1322/10000, Loss: 0.026662278920412064\n",
      "Iteration: 1323/10000, Loss: 0.04459712654352188\n",
      "Iteration: 1324/10000, Loss: 0.039435550570487976\n",
      "Iteration: 1325/10000, Loss: 0.034532707184553146\n",
      "Iteration: 1326/10000, Loss: 0.02961345948278904\n",
      "Iteration: 1327/10000, Loss: 0.02854881063103676\n",
      "Iteration: 1328/10000, Loss: 0.03229745477437973\n",
      "Iteration: 1329/10000, Loss: 0.0359472893178463\n",
      "Iteration: 1330/10000, Loss: 0.04032273218035698\n",
      "Iteration: 1331/10000, Loss: 0.0318051315844059\n",
      "Iteration: 1332/10000, Loss: 0.022375907748937607\n",
      "Iteration: 1333/10000, Loss: 0.03409672528505325\n",
      "Iteration: 1334/10000, Loss: 0.029903093352913857\n",
      "Iteration: 1335/10000, Loss: 0.029143160209059715\n",
      "Iteration: 1336/10000, Loss: 0.033981990069150925\n",
      "Iteration: 1337/10000, Loss: 0.03297116979956627\n",
      "Iteration: 1338/10000, Loss: 0.038452956825494766\n",
      "Iteration: 1339/10000, Loss: 0.0413852296769619\n",
      "Iteration: 1340/10000, Loss: 0.038787294179201126\n",
      "Iteration: 1341/10000, Loss: 0.03652703016996384\n",
      "Iteration: 1342/10000, Loss: 0.0319027341902256\n",
      "Iteration: 1343/10000, Loss: 0.036320071667432785\n",
      "Iteration: 1344/10000, Loss: 0.03687632083892822\n",
      "Iteration: 1345/10000, Loss: 0.04140841215848923\n",
      "Iteration: 1346/10000, Loss: 0.04630230367183685\n",
      "Iteration: 1347/10000, Loss: 0.03341718390583992\n",
      "Iteration: 1348/10000, Loss: 0.026994286105036736\n",
      "Iteration: 1349/10000, Loss: 0.037760354578495026\n",
      "Iteration: 1350/10000, Loss: 0.029074611142277718\n",
      "Iteration: 1351/10000, Loss: 0.02656819298863411\n",
      "Iteration: 1352/10000, Loss: 0.02284189872443676\n",
      "Iteration: 1353/10000, Loss: 0.028498293831944466\n",
      "Iteration: 1354/10000, Loss: 0.03555164858698845\n",
      "Iteration: 1355/10000, Loss: 0.04353608936071396\n",
      "Iteration: 1356/10000, Loss: 0.04428371787071228\n",
      "Iteration: 1357/10000, Loss: 0.026110593229532242\n",
      "Iteration: 1358/10000, Loss: 0.036638882011175156\n",
      "Iteration: 1359/10000, Loss: 0.037160929292440414\n",
      "Iteration: 1360/10000, Loss: 0.044790927320718765\n",
      "Iteration: 1361/10000, Loss: 0.02546338364481926\n",
      "Iteration: 1362/10000, Loss: 0.04376992955803871\n",
      "Iteration: 1363/10000, Loss: 0.03320329263806343\n",
      "Iteration: 1364/10000, Loss: 0.03255337476730347\n",
      "Iteration: 1365/10000, Loss: 0.033473797142505646\n",
      "Iteration: 1366/10000, Loss: 0.034891922026872635\n",
      "Iteration: 1367/10000, Loss: 0.03011494129896164\n",
      "Iteration: 1368/10000, Loss: 0.03357969596982002\n",
      "Iteration: 1369/10000, Loss: 0.03280846029520035\n",
      "Iteration: 1370/10000, Loss: 0.03385559469461441\n",
      "Iteration: 1371/10000, Loss: 0.048794955015182495\n",
      "Iteration: 1372/10000, Loss: 0.036245740950107574\n",
      "Iteration: 1373/10000, Loss: 0.03528666868805885\n",
      "Iteration: 1374/10000, Loss: 0.02165815979242325\n",
      "Iteration: 1375/10000, Loss: 0.029019795358181\n",
      "Iteration: 1376/10000, Loss: 0.03221282362937927\n",
      "Iteration: 1377/10000, Loss: 0.04745246842503548\n",
      "Iteration: 1378/10000, Loss: 0.054171182215213776\n",
      "Iteration: 1379/10000, Loss: 0.03632517158985138\n",
      "Iteration: 1380/10000, Loss: 0.04097619652748108\n",
      "Iteration: 1381/10000, Loss: 0.02616255357861519\n",
      "Iteration: 1382/10000, Loss: 0.04061063006520271\n",
      "Iteration: 1383/10000, Loss: 0.03131870925426483\n",
      "Iteration: 1384/10000, Loss: 0.04100864753127098\n",
      "Iteration: 1385/10000, Loss: 0.026495059952139854\n",
      "Iteration: 1386/10000, Loss: 0.021533194929361343\n",
      "Iteration: 1387/10000, Loss: 0.041090600192546844\n",
      "Iteration: 1388/10000, Loss: 0.03979284316301346\n",
      "Iteration: 1389/10000, Loss: 0.03712072595953941\n",
      "Iteration: 1390/10000, Loss: 0.03925291821360588\n",
      "Iteration: 1391/10000, Loss: 0.035272300243377686\n",
      "Iteration: 1392/10000, Loss: 0.038646288216114044\n",
      "Iteration: 1393/10000, Loss: 0.04334428533911705\n",
      "Iteration: 1394/10000, Loss: 0.020593130961060524\n",
      "Iteration: 1395/10000, Loss: 0.04015503451228142\n",
      "Iteration: 1396/10000, Loss: 0.025747567415237427\n",
      "Iteration: 1397/10000, Loss: 0.024483870714902878\n",
      "Iteration: 1398/10000, Loss: 0.04651834815740585\n",
      "Iteration: 1399/10000, Loss: 0.03344282880425453\n",
      "Iteration: 1400/10000, Loss: 0.041833069175481796\n",
      "Average test loss:  0.0033\n",
      "Iteration: 1401/10000, Loss: 0.05111823230981827\n",
      "Iteration: 1402/10000, Loss: 0.0390709824860096\n",
      "Iteration: 1403/10000, Loss: 0.03042156621813774\n",
      "Iteration: 1404/10000, Loss: 0.03411899134516716\n",
      "Iteration: 1405/10000, Loss: 0.03709608316421509\n",
      "Iteration: 1406/10000, Loss: 0.03241998329758644\n",
      "Iteration: 1407/10000, Loss: 0.026617739349603653\n",
      "Iteration: 1408/10000, Loss: 0.029109664261341095\n",
      "Iteration: 1409/10000, Loss: 0.032213032245635986\n",
      "Iteration: 1410/10000, Loss: 0.025066031143069267\n",
      "Iteration: 1411/10000, Loss: 0.028935745358467102\n",
      "Iteration: 1412/10000, Loss: 0.024004289880394936\n",
      "Iteration: 1413/10000, Loss: 0.04846416786313057\n",
      "Iteration: 1414/10000, Loss: 0.06061292439699173\n",
      "Iteration: 1415/10000, Loss: 0.018576912581920624\n",
      "Iteration: 1416/10000, Loss: 0.02708815038204193\n",
      "Iteration: 1417/10000, Loss: 0.0389791876077652\n",
      "Iteration: 1418/10000, Loss: 0.028725920245051384\n",
      "Iteration: 1419/10000, Loss: 0.04317315295338631\n",
      "Iteration: 1420/10000, Loss: 0.034490130841732025\n",
      "Iteration: 1421/10000, Loss: 0.031471386551856995\n",
      "Iteration: 1422/10000, Loss: 0.035023827105760574\n",
      "Iteration: 1423/10000, Loss: 0.04381905496120453\n",
      "Iteration: 1424/10000, Loss: 0.04784869775176048\n",
      "Iteration: 1425/10000, Loss: 0.030954698100686073\n",
      "Iteration: 1426/10000, Loss: 0.03735337406396866\n",
      "Iteration: 1427/10000, Loss: 0.02489791065454483\n",
      "Iteration: 1428/10000, Loss: 0.03934173658490181\n",
      "Iteration: 1429/10000, Loss: 0.04548860341310501\n",
      "Iteration: 1430/10000, Loss: 0.03424430266022682\n",
      "Iteration: 1431/10000, Loss: 0.0291706845164299\n",
      "Iteration: 1432/10000, Loss: 0.034640178084373474\n",
      "Iteration: 1433/10000, Loss: 0.03317907452583313\n",
      "Iteration: 1434/10000, Loss: 0.02990635484457016\n",
      "Iteration: 1435/10000, Loss: 0.024078061804175377\n",
      "Iteration: 1436/10000, Loss: 0.024416496977210045\n",
      "Iteration: 1437/10000, Loss: 0.04243333265185356\n",
      "Iteration: 1438/10000, Loss: 0.034237537533044815\n",
      "Iteration: 1439/10000, Loss: 0.02598823979496956\n",
      "Iteration: 1440/10000, Loss: 0.024175001308321953\n",
      "Iteration: 1441/10000, Loss: 0.030165934935212135\n",
      "Iteration: 1442/10000, Loss: 0.03562590107321739\n",
      "Iteration: 1443/10000, Loss: 0.027252070605754852\n",
      "Iteration: 1444/10000, Loss: 0.03020942211151123\n",
      "Iteration: 1445/10000, Loss: 0.04423876851797104\n",
      "Iteration: 1446/10000, Loss: 0.032373879104852676\n",
      "Iteration: 1447/10000, Loss: 0.029245363548398018\n",
      "Iteration: 1448/10000, Loss: 0.038578812032938004\n",
      "Iteration: 1449/10000, Loss: 0.03917691484093666\n",
      "Iteration: 1450/10000, Loss: 0.036293674260377884\n",
      "Iteration: 1451/10000, Loss: 0.06248876452445984\n",
      "Iteration: 1452/10000, Loss: 0.036015238612890244\n",
      "Iteration: 1453/10000, Loss: 0.039051640778779984\n",
      "Iteration: 1454/10000, Loss: 0.03671463578939438\n",
      "Iteration: 1455/10000, Loss: 0.046744778752326965\n",
      "Iteration: 1456/10000, Loss: 0.03038318082690239\n",
      "Iteration: 1457/10000, Loss: 0.026028791442513466\n",
      "Iteration: 1458/10000, Loss: 0.025837749242782593\n",
      "Iteration: 1459/10000, Loss: 0.02452722378075123\n",
      "Iteration: 1460/10000, Loss: 0.04819542169570923\n",
      "Iteration: 1461/10000, Loss: 0.04148968681693077\n",
      "Iteration: 1462/10000, Loss: 0.05957731977105141\n",
      "Iteration: 1463/10000, Loss: 0.046477336436510086\n",
      "Iteration: 1464/10000, Loss: 0.03638559207320213\n",
      "Iteration: 1465/10000, Loss: 0.040412649512290955\n",
      "Iteration: 1466/10000, Loss: 0.04627467319369316\n",
      "Iteration: 1467/10000, Loss: 0.034463394433259964\n",
      "Iteration: 1468/10000, Loss: 0.03882069140672684\n",
      "Iteration: 1469/10000, Loss: 0.037803106009960175\n",
      "Iteration: 1470/10000, Loss: 0.030482297763228416\n",
      "Iteration: 1471/10000, Loss: 0.036349713802337646\n",
      "Iteration: 1472/10000, Loss: 0.03818982467055321\n",
      "Iteration: 1473/10000, Loss: 0.03439696505665779\n",
      "Iteration: 1474/10000, Loss: 0.03570132330060005\n",
      "Iteration: 1475/10000, Loss: 0.0383150577545166\n",
      "Iteration: 1476/10000, Loss: 0.03858950734138489\n",
      "Iteration: 1477/10000, Loss: 0.04065360873937607\n",
      "Iteration: 1478/10000, Loss: 0.02649664133787155\n",
      "Iteration: 1479/10000, Loss: 0.04210076481103897\n",
      "Iteration: 1480/10000, Loss: 0.04157533869147301\n",
      "Iteration: 1481/10000, Loss: 0.025755619630217552\n",
      "Iteration: 1482/10000, Loss: 0.044579315930604935\n",
      "Iteration: 1483/10000, Loss: 0.02703753113746643\n",
      "Iteration: 1484/10000, Loss: 0.032715968787670135\n",
      "Iteration: 1485/10000, Loss: 0.026279231533408165\n",
      "Iteration: 1486/10000, Loss: 0.026814866811037064\n",
      "Iteration: 1487/10000, Loss: 0.03230539709329605\n",
      "Iteration: 1488/10000, Loss: 0.030880099162459373\n",
      "Iteration: 1489/10000, Loss: 0.04026619344949722\n",
      "Iteration: 1490/10000, Loss: 0.02599218487739563\n",
      "Iteration: 1491/10000, Loss: 0.037650104612112045\n",
      "Iteration: 1492/10000, Loss: 0.02264459989964962\n",
      "Iteration: 1493/10000, Loss: 0.03246752917766571\n",
      "Iteration: 1494/10000, Loss: 0.020100068300962448\n",
      "Iteration: 1495/10000, Loss: 0.03620096296072006\n",
      "Iteration: 1496/10000, Loss: 0.022634534165263176\n",
      "Iteration: 1497/10000, Loss: 0.0405951663851738\n",
      "Iteration: 1498/10000, Loss: 0.03776572644710541\n",
      "Iteration: 1499/10000, Loss: 0.0379265733063221\n",
      "Iteration: 1500/10000, Loss: 0.02679288201034069\n",
      "Average test loss:  0.0035\n",
      "Iteration: 1501/10000, Loss: 0.01816137321293354\n",
      "Iteration: 1502/10000, Loss: 0.030724428594112396\n",
      "Iteration: 1503/10000, Loss: 0.031820472329854965\n",
      "Iteration: 1504/10000, Loss: 0.03301110491156578\n",
      "Iteration: 1505/10000, Loss: 0.04127111658453941\n",
      "Iteration: 1506/10000, Loss: 0.023633116856217384\n",
      "Iteration: 1507/10000, Loss: 0.031995344907045364\n",
      "Iteration: 1508/10000, Loss: 0.0292647834867239\n",
      "Iteration: 1509/10000, Loss: 0.02461247704923153\n",
      "Iteration: 1510/10000, Loss: 0.039484549313783646\n",
      "Iteration: 1511/10000, Loss: 0.03016946092247963\n",
      "Iteration: 1512/10000, Loss: 0.025315288454294205\n",
      "Iteration: 1513/10000, Loss: 0.024754252284765244\n",
      "Iteration: 1514/10000, Loss: 0.04948454722762108\n",
      "Iteration: 1515/10000, Loss: 0.031804051250219345\n",
      "Iteration: 1516/10000, Loss: 0.03223727270960808\n",
      "Iteration: 1517/10000, Loss: 0.039733707904815674\n",
      "Iteration: 1518/10000, Loss: 0.029960259795188904\n",
      "Iteration: 1519/10000, Loss: 0.04638287425041199\n",
      "Iteration: 1520/10000, Loss: 0.03883357718586922\n",
      "Iteration: 1521/10000, Loss: 0.04043805971741676\n",
      "Iteration: 1522/10000, Loss: 0.03174251317977905\n",
      "Iteration: 1523/10000, Loss: 0.025304345414042473\n",
      "Iteration: 1524/10000, Loss: 0.04243087396025658\n",
      "Iteration: 1525/10000, Loss: 0.02393394522368908\n",
      "Iteration: 1526/10000, Loss: 0.02441617287695408\n",
      "Iteration: 1527/10000, Loss: 0.02264140173792839\n",
      "Iteration: 1528/10000, Loss: 0.02821722999215126\n",
      "Iteration: 1529/10000, Loss: 0.039247769862413406\n",
      "Iteration: 1530/10000, Loss: 0.045681972056627274\n",
      "Iteration: 1531/10000, Loss: 0.021274570375680923\n",
      "Iteration: 1532/10000, Loss: 0.03356921672821045\n",
      "Iteration: 1533/10000, Loss: 0.03971981629729271\n",
      "Iteration: 1534/10000, Loss: 0.021663879975676537\n",
      "Iteration: 1535/10000, Loss: 0.029701124876737595\n",
      "Iteration: 1536/10000, Loss: 0.028309756889939308\n",
      "Iteration: 1537/10000, Loss: 0.04026167467236519\n",
      "Iteration: 1538/10000, Loss: 0.03825663775205612\n",
      "Iteration: 1539/10000, Loss: 0.03708881512284279\n",
      "Iteration: 1540/10000, Loss: 0.029586996883153915\n",
      "Iteration: 1541/10000, Loss: 0.022787533700466156\n",
      "Iteration: 1542/10000, Loss: 0.026726221665740013\n",
      "Iteration: 1543/10000, Loss: 0.027550332248210907\n",
      "Iteration: 1544/10000, Loss: 0.03320366144180298\n",
      "Iteration: 1545/10000, Loss: 0.027891060337424278\n",
      "Iteration: 1546/10000, Loss: 0.026976756751537323\n",
      "Iteration: 1547/10000, Loss: 0.02535197325050831\n",
      "Iteration: 1548/10000, Loss: 0.026082679629325867\n",
      "Iteration: 1549/10000, Loss: 0.031496562063694\n",
      "Iteration: 1550/10000, Loss: 0.0302847009152174\n",
      "Iteration: 1551/10000, Loss: 0.030234692618250847\n",
      "Iteration: 1552/10000, Loss: 0.037691641598939896\n",
      "Iteration: 1553/10000, Loss: 0.021937565878033638\n",
      "Iteration: 1554/10000, Loss: 0.057472702115774155\n",
      "Iteration: 1555/10000, Loss: 0.027317320927977562\n",
      "Iteration: 1556/10000, Loss: 0.02769405022263527\n",
      "Iteration: 1557/10000, Loss: 0.042641352862119675\n",
      "Iteration: 1558/10000, Loss: 0.03649633377790451\n",
      "Iteration: 1559/10000, Loss: 0.03163273632526398\n",
      "Iteration: 1560/10000, Loss: 0.019268158823251724\n",
      "Iteration: 1561/10000, Loss: 0.04165961220860481\n",
      "Iteration: 1562/10000, Loss: 0.03061634488403797\n",
      "Iteration: 1563/10000, Loss: 0.025569312274456024\n",
      "Iteration: 1564/10000, Loss: 0.03303204104304314\n",
      "Iteration: 1565/10000, Loss: 0.03169284015893936\n",
      "Iteration: 1566/10000, Loss: 0.02982611209154129\n",
      "Iteration: 1567/10000, Loss: 0.02323564700782299\n",
      "Iteration: 1568/10000, Loss: 0.04572081193327904\n",
      "Iteration: 1569/10000, Loss: 0.04865366965532303\n",
      "Iteration: 1570/10000, Loss: 0.04314110800623894\n",
      "Iteration: 1571/10000, Loss: 0.029519274830818176\n",
      "Iteration: 1572/10000, Loss: 0.02817976474761963\n",
      "Iteration: 1573/10000, Loss: 0.02599494531750679\n",
      "Iteration: 1574/10000, Loss: 0.028176942840218544\n",
      "Iteration: 1575/10000, Loss: 0.02585122175514698\n",
      "Iteration: 1576/10000, Loss: 0.034099459648132324\n",
      "Iteration: 1577/10000, Loss: 0.03316159173846245\n",
      "Iteration: 1578/10000, Loss: 0.03405994176864624\n",
      "Iteration: 1579/10000, Loss: 0.02702564001083374\n",
      "Iteration: 1580/10000, Loss: 0.0403749942779541\n",
      "Iteration: 1581/10000, Loss: 0.02834904193878174\n",
      "Iteration: 1582/10000, Loss: 0.022840047255158424\n",
      "Iteration: 1583/10000, Loss: 0.046239789575338364\n",
      "Iteration: 1584/10000, Loss: 0.03193998709321022\n",
      "Iteration: 1585/10000, Loss: 0.03369021788239479\n",
      "Iteration: 1586/10000, Loss: 0.02699877880513668\n",
      "Iteration: 1587/10000, Loss: 0.025276770815253258\n",
      "Iteration: 1588/10000, Loss: 0.032013822346925735\n",
      "Iteration: 1589/10000, Loss: 0.023861980065703392\n",
      "Iteration: 1590/10000, Loss: 0.02507101185619831\n",
      "Iteration: 1591/10000, Loss: 0.04307328909635544\n",
      "Iteration: 1592/10000, Loss: 0.026825761422514915\n",
      "Iteration: 1593/10000, Loss: 0.056981395930051804\n",
      "Iteration: 1594/10000, Loss: 0.032588258385658264\n",
      "Iteration: 1595/10000, Loss: 0.028786903247237206\n",
      "Iteration: 1596/10000, Loss: 0.03099912405014038\n",
      "Iteration: 1597/10000, Loss: 0.03667512536048889\n",
      "Iteration: 1598/10000, Loss: 0.030001461505889893\n",
      "Iteration: 1599/10000, Loss: 0.028682313859462738\n",
      "Iteration: 1600/10000, Loss: 0.026292327791452408\n",
      "Average test loss:  0.0037\n",
      "Iteration: 1601/10000, Loss: 0.023945968598127365\n",
      "Iteration: 1602/10000, Loss: 0.03528634086251259\n",
      "Iteration: 1603/10000, Loss: 0.02297215722501278\n",
      "Iteration: 1604/10000, Loss: 0.024352408945560455\n",
      "Iteration: 1605/10000, Loss: 0.039269089698791504\n",
      "Iteration: 1606/10000, Loss: 0.0283626988530159\n",
      "Iteration: 1607/10000, Loss: 0.024198705330491066\n",
      "Iteration: 1608/10000, Loss: 0.028702443465590477\n",
      "Iteration: 1609/10000, Loss: 0.027892060577869415\n",
      "Iteration: 1610/10000, Loss: 0.0353909395635128\n",
      "Iteration: 1611/10000, Loss: 0.031753093004226685\n",
      "Iteration: 1612/10000, Loss: 0.035411205142736435\n",
      "Iteration: 1613/10000, Loss: 0.023941336199641228\n",
      "Iteration: 1614/10000, Loss: 0.028046078979969025\n",
      "Iteration: 1615/10000, Loss: 0.03557108715176582\n",
      "Iteration: 1616/10000, Loss: 0.03373946622014046\n",
      "Iteration: 1617/10000, Loss: 0.02932235598564148\n",
      "Iteration: 1618/10000, Loss: 0.0319778136909008\n",
      "Iteration: 1619/10000, Loss: 0.025072162970900536\n",
      "Iteration: 1620/10000, Loss: 0.05202718824148178\n",
      "Iteration: 1621/10000, Loss: 0.031793881207704544\n",
      "Iteration: 1622/10000, Loss: 0.022605832666158676\n",
      "Iteration: 1623/10000, Loss: 0.048545774072408676\n",
      "Iteration: 1624/10000, Loss: 0.024974428117275238\n",
      "Iteration: 1625/10000, Loss: 0.02288525179028511\n",
      "Iteration: 1626/10000, Loss: 0.03339746221899986\n",
      "Iteration: 1627/10000, Loss: 0.03111293353140354\n",
      "Iteration: 1628/10000, Loss: 0.03850493207573891\n",
      "Iteration: 1629/10000, Loss: 0.031476859003305435\n",
      "Iteration: 1630/10000, Loss: 0.038777776062488556\n",
      "Iteration: 1631/10000, Loss: 0.046488769352436066\n",
      "Iteration: 1632/10000, Loss: 0.02471359260380268\n",
      "Iteration: 1633/10000, Loss: 0.02585904859006405\n",
      "Iteration: 1634/10000, Loss: 0.03226501867175102\n",
      "Iteration: 1635/10000, Loss: 0.022452760487794876\n",
      "Iteration: 1636/10000, Loss: 0.027712112292647362\n",
      "Iteration: 1637/10000, Loss: 0.03727876767516136\n",
      "Iteration: 1638/10000, Loss: 0.029704442247748375\n",
      "Iteration: 1639/10000, Loss: 0.03192642331123352\n",
      "Iteration: 1640/10000, Loss: 0.025866655632853508\n",
      "Iteration: 1641/10000, Loss: 0.02217724546790123\n",
      "Iteration: 1642/10000, Loss: 0.044651590287685394\n",
      "Iteration: 1643/10000, Loss: 0.04625723510980606\n",
      "Iteration: 1644/10000, Loss: 0.028506772592663765\n",
      "Iteration: 1645/10000, Loss: 0.031085660681128502\n",
      "Iteration: 1646/10000, Loss: 0.03413418307900429\n",
      "Iteration: 1647/10000, Loss: 0.030426116660237312\n",
      "Iteration: 1648/10000, Loss: 0.03452475368976593\n",
      "Iteration: 1649/10000, Loss: 0.039530474692583084\n",
      "Iteration: 1650/10000, Loss: 0.03225819021463394\n",
      "Iteration: 1651/10000, Loss: 0.025105025619268417\n",
      "Iteration: 1652/10000, Loss: 0.027543455362319946\n",
      "Iteration: 1653/10000, Loss: 0.034972235560417175\n",
      "Iteration: 1654/10000, Loss: 0.023445211350917816\n",
      "Iteration: 1655/10000, Loss: 0.024211062118411064\n",
      "Iteration: 1656/10000, Loss: 0.037115518003702164\n",
      "Iteration: 1657/10000, Loss: 0.028955956920981407\n",
      "Iteration: 1658/10000, Loss: 0.02189371921122074\n",
      "Iteration: 1659/10000, Loss: 0.02229601889848709\n",
      "Iteration: 1660/10000, Loss: 0.04075663164258003\n",
      "Iteration: 1661/10000, Loss: 0.023579111322760582\n",
      "Iteration: 1662/10000, Loss: 0.033289410173892975\n",
      "Iteration: 1663/10000, Loss: 0.030425595119595528\n",
      "Iteration: 1664/10000, Loss: 0.03845767676830292\n",
      "Iteration: 1665/10000, Loss: 0.030505262315273285\n",
      "Iteration: 1666/10000, Loss: 0.021937787532806396\n",
      "Iteration: 1667/10000, Loss: 0.021901143714785576\n",
      "Iteration: 1668/10000, Loss: 0.033000003546476364\n",
      "Iteration: 1669/10000, Loss: 0.03620884194970131\n",
      "Iteration: 1670/10000, Loss: 0.036663640290498734\n",
      "Iteration: 1671/10000, Loss: 0.023935461416840553\n",
      "Iteration: 1672/10000, Loss: 0.023209111765027046\n",
      "Iteration: 1673/10000, Loss: 0.01720070280134678\n",
      "Iteration: 1674/10000, Loss: 0.026205360889434814\n",
      "Iteration: 1675/10000, Loss: 0.03130638226866722\n",
      "Iteration: 1676/10000, Loss: 0.024405935779213905\n",
      "Iteration: 1677/10000, Loss: 0.01820160634815693\n",
      "Iteration: 1678/10000, Loss: 0.03772148862481117\n",
      "Iteration: 1679/10000, Loss: 0.03139527514576912\n",
      "Iteration: 1680/10000, Loss: 0.02727571316063404\n",
      "Iteration: 1681/10000, Loss: 0.023685280233621597\n",
      "Iteration: 1682/10000, Loss: 0.03673584386706352\n",
      "Iteration: 1683/10000, Loss: 0.046890441328287125\n",
      "Iteration: 1684/10000, Loss: 0.029443129897117615\n",
      "Iteration: 1685/10000, Loss: 0.026335282251238823\n",
      "Iteration: 1686/10000, Loss: 0.025334736332297325\n",
      "Iteration: 1687/10000, Loss: 0.025111598894000053\n",
      "Iteration: 1688/10000, Loss: 0.027946943417191505\n",
      "Iteration: 1689/10000, Loss: 0.03193700313568115\n",
      "Iteration: 1690/10000, Loss: 0.03539601340889931\n",
      "Iteration: 1691/10000, Loss: 0.039808738976716995\n",
      "Iteration: 1692/10000, Loss: 0.02393077127635479\n",
      "Iteration: 1693/10000, Loss: 0.0307895690202713\n",
      "Iteration: 1694/10000, Loss: 0.03014826960861683\n",
      "Iteration: 1695/10000, Loss: 0.02750641666352749\n",
      "Iteration: 1696/10000, Loss: 0.02730206586420536\n",
      "Iteration: 1697/10000, Loss: 0.025631433352828026\n",
      "Iteration: 1698/10000, Loss: 0.023251229897141457\n",
      "Iteration: 1699/10000, Loss: 0.021738773211836815\n",
      "Iteration: 1700/10000, Loss: 0.020377501845359802\n",
      "Average test loss:  0.0029\n",
      "Iteration: 1701/10000, Loss: 0.03833591938018799\n",
      "Iteration: 1702/10000, Loss: 0.014343146234750748\n",
      "Iteration: 1703/10000, Loss: 0.026132607832551003\n",
      "Iteration: 1704/10000, Loss: 0.028026144951581955\n",
      "Iteration: 1705/10000, Loss: 0.02699245512485504\n",
      "Iteration: 1706/10000, Loss: 0.026034392416477203\n",
      "Iteration: 1707/10000, Loss: 0.0159529447555542\n",
      "Iteration: 1708/10000, Loss: 0.029728740453720093\n",
      "Iteration: 1709/10000, Loss: 0.02167375013232231\n",
      "Iteration: 1710/10000, Loss: 0.0307740680873394\n",
      "Iteration: 1711/10000, Loss: 0.030559521168470383\n",
      "Iteration: 1712/10000, Loss: 0.04162993282079697\n",
      "Iteration: 1713/10000, Loss: 0.03407113254070282\n",
      "Iteration: 1714/10000, Loss: 0.030569370836019516\n",
      "Iteration: 1715/10000, Loss: 0.03484269976615906\n",
      "Iteration: 1716/10000, Loss: 0.02693355083465576\n",
      "Iteration: 1717/10000, Loss: 0.026960238814353943\n",
      "Iteration: 1718/10000, Loss: 0.028028713539242744\n",
      "Iteration: 1719/10000, Loss: 0.024306941777467728\n",
      "Iteration: 1720/10000, Loss: 0.043353673070669174\n",
      "Iteration: 1721/10000, Loss: 0.02922213263809681\n",
      "Iteration: 1722/10000, Loss: 0.031156031414866447\n",
      "Iteration: 1723/10000, Loss: 0.03382549807429314\n",
      "Iteration: 1724/10000, Loss: 0.028060976415872574\n",
      "Iteration: 1725/10000, Loss: 0.02664782665669918\n",
      "Iteration: 1726/10000, Loss: 0.03025120683014393\n",
      "Iteration: 1727/10000, Loss: 0.03535490110516548\n",
      "Iteration: 1728/10000, Loss: 0.026141539216041565\n",
      "Iteration: 1729/10000, Loss: 0.028761476278305054\n",
      "Iteration: 1730/10000, Loss: 0.04790281131863594\n",
      "Iteration: 1731/10000, Loss: 0.03251044079661369\n",
      "Iteration: 1732/10000, Loss: 0.040945712476968765\n",
      "Iteration: 1733/10000, Loss: 0.02680778130888939\n",
      "Iteration: 1734/10000, Loss: 0.030407246202230453\n",
      "Iteration: 1735/10000, Loss: 0.024801505729556084\n",
      "Iteration: 1736/10000, Loss: 0.033520203083753586\n",
      "Iteration: 1737/10000, Loss: 0.025085747241973877\n",
      "Iteration: 1738/10000, Loss: 0.03018094226717949\n",
      "Iteration: 1739/10000, Loss: 0.0380101278424263\n",
      "Iteration: 1740/10000, Loss: 0.02618389204144478\n",
      "Iteration: 1741/10000, Loss: 0.018927285447716713\n",
      "Iteration: 1742/10000, Loss: 0.02864917367696762\n",
      "Iteration: 1743/10000, Loss: 0.03757288679480553\n",
      "Iteration: 1744/10000, Loss: 0.0308036170899868\n",
      "Iteration: 1745/10000, Loss: 0.02246030420064926\n",
      "Iteration: 1746/10000, Loss: 0.02027985453605652\n",
      "Iteration: 1747/10000, Loss: 0.025819044560194016\n",
      "Iteration: 1748/10000, Loss: 0.022451845929026604\n",
      "Iteration: 1749/10000, Loss: 0.016434960067272186\n",
      "Iteration: 1750/10000, Loss: 0.015847962349653244\n",
      "Iteration: 1751/10000, Loss: 0.04908651113510132\n",
      "Iteration: 1752/10000, Loss: 0.02544616535305977\n",
      "Iteration: 1753/10000, Loss: 0.020402750000357628\n",
      "Iteration: 1754/10000, Loss: 0.028620202094316483\n",
      "Iteration: 1755/10000, Loss: 0.045247022062540054\n",
      "Iteration: 1756/10000, Loss: 0.030780581757426262\n",
      "Iteration: 1757/10000, Loss: 0.028809916228055954\n",
      "Iteration: 1758/10000, Loss: 0.026297230273485184\n",
      "Iteration: 1759/10000, Loss: 0.031360819935798645\n",
      "Iteration: 1760/10000, Loss: 0.030182121321558952\n",
      "Iteration: 1761/10000, Loss: 0.02607940509915352\n",
      "Iteration: 1762/10000, Loss: 0.03405383974313736\n",
      "Iteration: 1763/10000, Loss: 0.027078785002231598\n",
      "Iteration: 1764/10000, Loss: 0.06619088351726532\n",
      "Iteration: 1765/10000, Loss: 0.018660878762602806\n",
      "Iteration: 1766/10000, Loss: 0.027682092040777206\n",
      "Iteration: 1767/10000, Loss: 0.036259859800338745\n",
      "Iteration: 1768/10000, Loss: 0.03576749190688133\n",
      "Iteration: 1769/10000, Loss: 0.030945520848035812\n",
      "Iteration: 1770/10000, Loss: 0.024937260895967484\n",
      "Iteration: 1771/10000, Loss: 0.026515988633036613\n",
      "Iteration: 1772/10000, Loss: 0.025097180157899857\n",
      "Iteration: 1773/10000, Loss: 0.024213571101427078\n",
      "Iteration: 1774/10000, Loss: 0.02884710766375065\n",
      "Iteration: 1775/10000, Loss: 0.024449262768030167\n",
      "Iteration: 1776/10000, Loss: 0.027317851781845093\n",
      "Iteration: 1777/10000, Loss: 0.032703958451747894\n",
      "Iteration: 1778/10000, Loss: 0.03983971104025841\n",
      "Iteration: 1779/10000, Loss: 0.02105857990682125\n",
      "Iteration: 1780/10000, Loss: 0.019334599375724792\n",
      "Iteration: 1781/10000, Loss: 0.04038238152861595\n",
      "Iteration: 1782/10000, Loss: 0.042587485164403915\n",
      "Iteration: 1783/10000, Loss: 0.02379778027534485\n",
      "Iteration: 1784/10000, Loss: 0.03589233011007309\n",
      "Iteration: 1785/10000, Loss: 0.03798379749059677\n",
      "Iteration: 1786/10000, Loss: 0.020955687388777733\n",
      "Iteration: 1787/10000, Loss: 0.03275187313556671\n",
      "Iteration: 1788/10000, Loss: 0.02635776810348034\n",
      "Iteration: 1789/10000, Loss: 0.02839931659400463\n",
      "Iteration: 1790/10000, Loss: 0.02361033670604229\n",
      "Iteration: 1791/10000, Loss: 0.02045685611665249\n",
      "Iteration: 1792/10000, Loss: 0.0389593169093132\n",
      "Iteration: 1793/10000, Loss: 0.015058309771120548\n",
      "Iteration: 1794/10000, Loss: 0.026643341407179832\n",
      "Iteration: 1795/10000, Loss: 0.023051412776112556\n",
      "Iteration: 1796/10000, Loss: 0.02502073533833027\n",
      "Iteration: 1797/10000, Loss: 0.025898795574903488\n",
      "Iteration: 1798/10000, Loss: 0.022573938593268394\n",
      "Iteration: 1799/10000, Loss: 0.03800666332244873\n",
      "Iteration: 1800/10000, Loss: 0.03253472223877907\n",
      "Average test loss:  0.0037\n",
      "Iteration: 1801/10000, Loss: 0.02323012612760067\n",
      "Iteration: 1802/10000, Loss: 0.030605865642428398\n",
      "Iteration: 1803/10000, Loss: 0.02897917479276657\n",
      "Iteration: 1804/10000, Loss: 0.026496650651097298\n",
      "Iteration: 1805/10000, Loss: 0.03679027035832405\n",
      "Iteration: 1806/10000, Loss: 0.03645174205303192\n",
      "Iteration: 1807/10000, Loss: 0.034733403474092484\n",
      "Iteration: 1808/10000, Loss: 0.02538965828716755\n",
      "Iteration: 1809/10000, Loss: 0.029493996873497963\n",
      "Iteration: 1810/10000, Loss: 0.021633636206388474\n",
      "Iteration: 1811/10000, Loss: 0.03351815417408943\n",
      "Iteration: 1812/10000, Loss: 0.02081155776977539\n",
      "Iteration: 1813/10000, Loss: 0.022648397833108902\n",
      "Iteration: 1814/10000, Loss: 0.028719434514641762\n",
      "Iteration: 1815/10000, Loss: 0.04403366148471832\n",
      "Iteration: 1816/10000, Loss: 0.024343211203813553\n",
      "Iteration: 1817/10000, Loss: 0.029738089069724083\n",
      "Iteration: 1818/10000, Loss: 0.019111230969429016\n",
      "Iteration: 1819/10000, Loss: 0.03418084233999252\n",
      "Iteration: 1820/10000, Loss: 0.034943804144859314\n",
      "Iteration: 1821/10000, Loss: 0.042328137904405594\n",
      "Iteration: 1822/10000, Loss: 0.03316893428564072\n",
      "Iteration: 1823/10000, Loss: 0.027808209881186485\n",
      "Iteration: 1824/10000, Loss: 0.027316315099596977\n",
      "Iteration: 1825/10000, Loss: 0.026778418570756912\n",
      "Iteration: 1826/10000, Loss: 0.019086074084043503\n",
      "Iteration: 1827/10000, Loss: 0.0367070809006691\n",
      "Iteration: 1828/10000, Loss: 0.03673800453543663\n",
      "Iteration: 1829/10000, Loss: 0.021711189299821854\n",
      "Iteration: 1830/10000, Loss: 0.022324105724692345\n",
      "Iteration: 1831/10000, Loss: 0.0551663301885128\n",
      "Iteration: 1832/10000, Loss: 0.02440323308110237\n",
      "Iteration: 1833/10000, Loss: 0.03115944191813469\n",
      "Iteration: 1834/10000, Loss: 0.03361416980624199\n",
      "Iteration: 1835/10000, Loss: 0.029323728755116463\n",
      "Iteration: 1836/10000, Loss: 0.022270910441875458\n",
      "Iteration: 1837/10000, Loss: 0.021475858986377716\n",
      "Iteration: 1838/10000, Loss: 0.024672552943229675\n",
      "Iteration: 1839/10000, Loss: 0.036437150090932846\n",
      "Iteration: 1840/10000, Loss: 0.021443115547299385\n",
      "Iteration: 1841/10000, Loss: 0.028304526582360268\n",
      "Iteration: 1842/10000, Loss: 0.0333731584250927\n",
      "Iteration: 1843/10000, Loss: 0.026060471311211586\n",
      "Iteration: 1844/10000, Loss: 0.027664244174957275\n",
      "Iteration: 1845/10000, Loss: 0.0274222232401371\n",
      "Iteration: 1846/10000, Loss: 0.029985956847667694\n",
      "Iteration: 1847/10000, Loss: 0.029116276651620865\n",
      "Iteration: 1848/10000, Loss: 0.02559894137084484\n",
      "Iteration: 1849/10000, Loss: 0.02853284776210785\n",
      "Iteration: 1850/10000, Loss: 0.03135235235095024\n",
      "Iteration: 1851/10000, Loss: 0.03921882063150406\n",
      "Iteration: 1852/10000, Loss: 0.024556264281272888\n",
      "Iteration: 1853/10000, Loss: 0.027462031692266464\n",
      "Iteration: 1854/10000, Loss: 0.03909986838698387\n",
      "Iteration: 1855/10000, Loss: 0.034553878009319305\n",
      "Iteration: 1856/10000, Loss: 0.037703823298215866\n",
      "Iteration: 1857/10000, Loss: 0.04586006700992584\n",
      "Iteration: 1858/10000, Loss: 0.021615272387862206\n",
      "Iteration: 1859/10000, Loss: 0.028448287397623062\n",
      "Iteration: 1860/10000, Loss: 0.026470167562365532\n",
      "Iteration: 1861/10000, Loss: 0.02480161190032959\n",
      "Iteration: 1862/10000, Loss: 0.03418226167559624\n",
      "Iteration: 1863/10000, Loss: 0.03176916018128395\n",
      "Iteration: 1864/10000, Loss: 0.03041684813797474\n",
      "Iteration: 1865/10000, Loss: 0.021955937147140503\n",
      "Iteration: 1866/10000, Loss: 0.030190693214535713\n",
      "Iteration: 1867/10000, Loss: 0.030767880380153656\n",
      "Iteration: 1868/10000, Loss: 0.02139044739305973\n",
      "Iteration: 1869/10000, Loss: 0.03056730329990387\n",
      "Iteration: 1870/10000, Loss: 0.03915783762931824\n",
      "Iteration: 1871/10000, Loss: 0.02815689891576767\n",
      "Iteration: 1872/10000, Loss: 0.018429480493068695\n",
      "Iteration: 1873/10000, Loss: 0.02784472145140171\n",
      "Iteration: 1874/10000, Loss: 0.028708545491099358\n",
      "Iteration: 1875/10000, Loss: 0.0235122162848711\n",
      "Iteration: 1876/10000, Loss: 0.021288352087140083\n",
      "Iteration: 1877/10000, Loss: 0.02415558695793152\n",
      "Iteration: 1878/10000, Loss: 0.03348218649625778\n",
      "Iteration: 1879/10000, Loss: 0.019355742260813713\n",
      "Iteration: 1880/10000, Loss: 0.029784971848130226\n",
      "Iteration: 1881/10000, Loss: 0.027667773887515068\n",
      "Iteration: 1882/10000, Loss: 0.030604807659983635\n",
      "Iteration: 1883/10000, Loss: 0.021661944687366486\n",
      "Iteration: 1884/10000, Loss: 0.020977677777409554\n",
      "Iteration: 1885/10000, Loss: 0.022433007135987282\n",
      "Iteration: 1886/10000, Loss: 0.03362375125288963\n",
      "Iteration: 1887/10000, Loss: 0.027436569333076477\n",
      "Iteration: 1888/10000, Loss: 0.023959053680300713\n",
      "Iteration: 1889/10000, Loss: 0.031208064407110214\n",
      "Iteration: 1890/10000, Loss: 0.021194415166974068\n",
      "Iteration: 1891/10000, Loss: 0.023062938824295998\n",
      "Iteration: 1892/10000, Loss: 0.02714673802256584\n",
      "Iteration: 1893/10000, Loss: 0.03134595975279808\n",
      "Iteration: 1894/10000, Loss: 0.023396827280521393\n",
      "Iteration: 1895/10000, Loss: 0.0205827709287405\n",
      "Iteration: 1896/10000, Loss: 0.034773822873830795\n",
      "Iteration: 1897/10000, Loss: 0.04583602771162987\n",
      "Iteration: 1898/10000, Loss: 0.030564773827791214\n",
      "Iteration: 1899/10000, Loss: 0.03464296832680702\n",
      "Iteration: 1900/10000, Loss: 0.027258776128292084\n",
      "Average test loss:  0.0024\n",
      "Iteration: 1901/10000, Loss: 0.02191394940018654\n",
      "Iteration: 1902/10000, Loss: 0.03129292652010918\n",
      "Iteration: 1903/10000, Loss: 0.0265455711632967\n",
      "Iteration: 1904/10000, Loss: 0.02441510558128357\n",
      "Iteration: 1905/10000, Loss: 0.021261800080537796\n",
      "Iteration: 1906/10000, Loss: 0.030240222811698914\n",
      "Iteration: 1907/10000, Loss: 0.027765749022364616\n",
      "Iteration: 1908/10000, Loss: 0.02255517989397049\n",
      "Iteration: 1909/10000, Loss: 0.028602255508303642\n",
      "Iteration: 1910/10000, Loss: 0.028779232874512672\n",
      "Iteration: 1911/10000, Loss: 0.02632993459701538\n",
      "Iteration: 1912/10000, Loss: 0.03903815895318985\n",
      "Iteration: 1913/10000, Loss: 0.032409049570560455\n",
      "Iteration: 1914/10000, Loss: 0.028525276109576225\n",
      "Iteration: 1915/10000, Loss: 0.03227682784199715\n",
      "Iteration: 1916/10000, Loss: 0.030585877597332\n",
      "Iteration: 1917/10000, Loss: 0.0236242413520813\n",
      "Iteration: 1918/10000, Loss: 0.025113653391599655\n",
      "Iteration: 1919/10000, Loss: 0.026037124916911125\n",
      "Iteration: 1920/10000, Loss: 0.028557682409882545\n",
      "Iteration: 1921/10000, Loss: 0.016304368153214455\n",
      "Iteration: 1922/10000, Loss: 0.03245406597852707\n",
      "Iteration: 1923/10000, Loss: 0.020551955327391624\n",
      "Iteration: 1924/10000, Loss: 0.027544338256120682\n",
      "Iteration: 1925/10000, Loss: 0.018466029316186905\n",
      "Iteration: 1926/10000, Loss: 0.035502705723047256\n",
      "Iteration: 1927/10000, Loss: 0.018349742516875267\n",
      "Iteration: 1928/10000, Loss: 0.01882728934288025\n",
      "Iteration: 1929/10000, Loss: 0.040047939866781235\n",
      "Iteration: 1930/10000, Loss: 0.04689166322350502\n",
      "Iteration: 1931/10000, Loss: 0.028092527762055397\n",
      "Iteration: 1932/10000, Loss: 0.027488602325320244\n",
      "Iteration: 1933/10000, Loss: 0.024488531053066254\n",
      "Iteration: 1934/10000, Loss: 0.028629165142774582\n",
      "Iteration: 1935/10000, Loss: 0.015817230567336082\n",
      "Iteration: 1936/10000, Loss: 0.027006518095731735\n",
      "Iteration: 1937/10000, Loss: 0.03148963674902916\n",
      "Iteration: 1938/10000, Loss: 0.028604039922356606\n",
      "Iteration: 1939/10000, Loss: 0.02319035865366459\n",
      "Iteration: 1940/10000, Loss: 0.02355486899614334\n",
      "Iteration: 1941/10000, Loss: 0.034626901149749756\n",
      "Iteration: 1942/10000, Loss: 0.03322321176528931\n",
      "Iteration: 1943/10000, Loss: 0.036767613142728806\n",
      "Iteration: 1944/10000, Loss: 0.03809003159403801\n",
      "Iteration: 1945/10000, Loss: 0.034411441534757614\n",
      "Iteration: 1946/10000, Loss: 0.03772898018360138\n",
      "Iteration: 1947/10000, Loss: 0.04601731896400452\n",
      "Iteration: 1948/10000, Loss: 0.026759734377264977\n",
      "Iteration: 1949/10000, Loss: 0.025027094408869743\n",
      "Iteration: 1950/10000, Loss: 0.02460896596312523\n",
      "Iteration: 1951/10000, Loss: 0.03963876888155937\n",
      "Iteration: 1952/10000, Loss: 0.02062089741230011\n",
      "Iteration: 1953/10000, Loss: 0.02575220912694931\n",
      "Iteration: 1954/10000, Loss: 0.027960587292909622\n",
      "Iteration: 1955/10000, Loss: 0.038714129477739334\n",
      "Iteration: 1956/10000, Loss: 0.019886862486600876\n",
      "Iteration: 1957/10000, Loss: 0.037117812782526016\n",
      "Iteration: 1958/10000, Loss: 0.02719315141439438\n",
      "Iteration: 1959/10000, Loss: 0.021324660629034042\n",
      "Iteration: 1960/10000, Loss: 0.021455995738506317\n",
      "Iteration: 1961/10000, Loss: 0.017970316112041473\n",
      "Iteration: 1962/10000, Loss: 0.0210268571972847\n",
      "Iteration: 1963/10000, Loss: 0.03181327134370804\n",
      "Iteration: 1964/10000, Loss: 0.021978547796607018\n",
      "Iteration: 1965/10000, Loss: 0.0292999055236578\n",
      "Iteration: 1966/10000, Loss: 0.02544410526752472\n",
      "Iteration: 1967/10000, Loss: 0.028553960844874382\n",
      "Iteration: 1968/10000, Loss: 0.022036783397197723\n",
      "Iteration: 1969/10000, Loss: 0.03096403181552887\n",
      "Iteration: 1970/10000, Loss: 0.018554329872131348\n",
      "Iteration: 1971/10000, Loss: 0.027213962748646736\n",
      "Iteration: 1972/10000, Loss: 0.025240248069167137\n",
      "Iteration: 1973/10000, Loss: 0.023260975256562233\n",
      "Iteration: 1974/10000, Loss: 0.02006727084517479\n",
      "Iteration: 1975/10000, Loss: 0.030832845717668533\n",
      "Iteration: 1976/10000, Loss: 0.02408924698829651\n",
      "Iteration: 1977/10000, Loss: 0.02372661419212818\n",
      "Iteration: 1978/10000, Loss: 0.03500913083553314\n",
      "Iteration: 1979/10000, Loss: 0.029913820326328278\n",
      "Iteration: 1980/10000, Loss: 0.020136121660470963\n",
      "Iteration: 1981/10000, Loss: 0.035540662705898285\n",
      "Iteration: 1982/10000, Loss: 0.02303522825241089\n",
      "Iteration: 1983/10000, Loss: 0.022598791867494583\n",
      "Iteration: 1984/10000, Loss: 0.02088044211268425\n",
      "Iteration: 1985/10000, Loss: 0.023908153176307678\n",
      "Iteration: 1986/10000, Loss: 0.023662889376282692\n",
      "Iteration: 1987/10000, Loss: 0.03816380724310875\n",
      "Iteration: 1988/10000, Loss: 0.016749868169426918\n",
      "Iteration: 1989/10000, Loss: 0.012458434328436852\n",
      "Iteration: 1990/10000, Loss: 0.030876748263835907\n",
      "Iteration: 1991/10000, Loss: 0.042648158967494965\n",
      "Iteration: 1992/10000, Loss: 0.03325401619076729\n",
      "Iteration: 1993/10000, Loss: 0.03154953569173813\n",
      "Iteration: 1994/10000, Loss: 0.01948612555861473\n",
      "Iteration: 1995/10000, Loss: 0.023197224363684654\n",
      "Iteration: 1996/10000, Loss: 0.03441343456506729\n",
      "Iteration: 1997/10000, Loss: 0.028501465916633606\n",
      "Iteration: 1998/10000, Loss: 0.02861497364938259\n",
      "Iteration: 1999/10000, Loss: 0.029392268508672714\n",
      "Iteration: 2000/10000, Loss: 0.026389172300696373\n",
      "Average test loss:  0.0030\n",
      "Iteration: 2001/10000, Loss: 0.02727975696325302\n",
      "Iteration: 2002/10000, Loss: 0.0186244398355484\n",
      "Iteration: 2003/10000, Loss: 0.028541654348373413\n",
      "Iteration: 2004/10000, Loss: 0.036318808794021606\n",
      "Iteration: 2005/10000, Loss: 0.0289042629301548\n",
      "Iteration: 2006/10000, Loss: 0.019284535199403763\n",
      "Iteration: 2007/10000, Loss: 0.03584950044751167\n",
      "Iteration: 2008/10000, Loss: 0.032531581819057465\n",
      "Iteration: 2009/10000, Loss: 0.026554523035883904\n",
      "Iteration: 2010/10000, Loss: 0.028046607971191406\n",
      "Iteration: 2011/10000, Loss: 0.023689329624176025\n",
      "Iteration: 2012/10000, Loss: 0.022399719804525375\n",
      "Iteration: 2013/10000, Loss: 0.02362634800374508\n",
      "Iteration: 2014/10000, Loss: 0.019400961697101593\n",
      "Iteration: 2015/10000, Loss: 0.02110789157450199\n",
      "Iteration: 2016/10000, Loss: 0.025154171511530876\n",
      "Iteration: 2017/10000, Loss: 0.02496371790766716\n",
      "Iteration: 2018/10000, Loss: 0.02037239633500576\n",
      "Iteration: 2019/10000, Loss: 0.01578810252249241\n",
      "Iteration: 2020/10000, Loss: 0.03220318257808685\n",
      "Iteration: 2021/10000, Loss: 0.04221634194254875\n",
      "Iteration: 2022/10000, Loss: 0.02237885631620884\n",
      "Iteration: 2023/10000, Loss: 0.03024635650217533\n",
      "Iteration: 2024/10000, Loss: 0.02737203799188137\n",
      "Iteration: 2025/10000, Loss: 0.0218560341745615\n",
      "Iteration: 2026/10000, Loss: 0.033790793269872665\n",
      "Iteration: 2027/10000, Loss: 0.02389376610517502\n",
      "Iteration: 2028/10000, Loss: 0.02229207381606102\n",
      "Iteration: 2029/10000, Loss: 0.025720778852701187\n",
      "Iteration: 2030/10000, Loss: 0.021364882588386536\n",
      "Iteration: 2031/10000, Loss: 0.04703798517584801\n",
      "Iteration: 2032/10000, Loss: 0.025085581466555595\n",
      "Iteration: 2033/10000, Loss: 0.023748895153403282\n",
      "Iteration: 2034/10000, Loss: 0.030836455523967743\n",
      "Iteration: 2035/10000, Loss: 0.030825801193714142\n",
      "Iteration: 2036/10000, Loss: 0.034262754023075104\n",
      "Iteration: 2037/10000, Loss: 0.02853943593800068\n",
      "Iteration: 2038/10000, Loss: 0.020593471825122833\n",
      "Iteration: 2039/10000, Loss: 0.023590609431266785\n",
      "Iteration: 2040/10000, Loss: 0.02542375959455967\n",
      "Iteration: 2041/10000, Loss: 0.021807756274938583\n",
      "Iteration: 2042/10000, Loss: 0.04667636752128601\n",
      "Iteration: 2043/10000, Loss: 0.02202199213206768\n",
      "Iteration: 2044/10000, Loss: 0.032239943742752075\n",
      "Iteration: 2045/10000, Loss: 0.0300152488052845\n",
      "Iteration: 2046/10000, Loss: 0.024303516373038292\n",
      "Iteration: 2047/10000, Loss: 0.023776056244969368\n",
      "Iteration: 2048/10000, Loss: 0.028001004830002785\n",
      "Iteration: 2049/10000, Loss: 0.023904016241431236\n",
      "Iteration: 2050/10000, Loss: 0.02906828001141548\n",
      "Iteration: 2051/10000, Loss: 0.02299494855105877\n",
      "Iteration: 2052/10000, Loss: 0.028304418548941612\n",
      "Iteration: 2053/10000, Loss: 0.024898095056414604\n",
      "Iteration: 2054/10000, Loss: 0.029672179371118546\n",
      "Iteration: 2055/10000, Loss: 0.026092469692230225\n",
      "Iteration: 2056/10000, Loss: 0.02240234613418579\n",
      "Iteration: 2057/10000, Loss: 0.02740657888352871\n",
      "Iteration: 2058/10000, Loss: 0.02449016273021698\n",
      "Iteration: 2059/10000, Loss: 0.03037022426724434\n",
      "Iteration: 2060/10000, Loss: 0.025578558444976807\n",
      "Iteration: 2061/10000, Loss: 0.019533276557922363\n",
      "Iteration: 2062/10000, Loss: 0.02360180765390396\n",
      "Iteration: 2063/10000, Loss: 0.025594819337129593\n",
      "Iteration: 2064/10000, Loss: 0.01971973292529583\n",
      "Iteration: 2065/10000, Loss: 0.02432284504175186\n",
      "Iteration: 2066/10000, Loss: 0.024694038555026054\n",
      "Iteration: 2067/10000, Loss: 0.01788506843149662\n",
      "Iteration: 2068/10000, Loss: 0.015301934443414211\n",
      "Iteration: 2069/10000, Loss: 0.014775444753468037\n",
      "Iteration: 2070/10000, Loss: 0.035478997975587845\n",
      "Iteration: 2071/10000, Loss: 0.016332892701029778\n",
      "Iteration: 2072/10000, Loss: 0.02382047101855278\n",
      "Iteration: 2073/10000, Loss: 0.028337528929114342\n",
      "Iteration: 2074/10000, Loss: 0.017322823405265808\n",
      "Iteration: 2075/10000, Loss: 0.021011773496866226\n",
      "Iteration: 2076/10000, Loss: 0.02063443884253502\n",
      "Iteration: 2077/10000, Loss: 0.024582741782069206\n",
      "Iteration: 2078/10000, Loss: 0.019571244716644287\n",
      "Iteration: 2079/10000, Loss: 0.02410048246383667\n",
      "Iteration: 2080/10000, Loss: 0.033383458852767944\n",
      "Iteration: 2081/10000, Loss: 0.020035341382026672\n",
      "Iteration: 2082/10000, Loss: 0.029466930776834488\n",
      "Iteration: 2083/10000, Loss: 0.02636544406414032\n",
      "Iteration: 2084/10000, Loss: 0.021375583484768867\n",
      "Iteration: 2085/10000, Loss: 0.02427704446017742\n",
      "Iteration: 2086/10000, Loss: 0.026145892217755318\n",
      "Iteration: 2087/10000, Loss: 0.020151412114501\n",
      "Iteration: 2088/10000, Loss: 0.02108120545744896\n",
      "Iteration: 2089/10000, Loss: 0.021368857473134995\n",
      "Iteration: 2090/10000, Loss: 0.03717830404639244\n",
      "Iteration: 2091/10000, Loss: 0.024079829454421997\n",
      "Iteration: 2092/10000, Loss: 0.027427267283201218\n",
      "Iteration: 2093/10000, Loss: 0.029725879430770874\n",
      "Iteration: 2094/10000, Loss: 0.028175391256809235\n",
      "Iteration: 2095/10000, Loss: 0.02207709476351738\n",
      "Iteration: 2096/10000, Loss: 0.027542464435100555\n",
      "Iteration: 2097/10000, Loss: 0.025467975065112114\n",
      "Iteration: 2098/10000, Loss: 0.025132954120635986\n",
      "Iteration: 2099/10000, Loss: 0.02505047433078289\n",
      "Iteration: 2100/10000, Loss: 0.024835797026753426\n",
      "Average test loss:  0.0021\n",
      "Iteration: 2101/10000, Loss: 0.019270727410912514\n",
      "Iteration: 2102/10000, Loss: 0.021225428208708763\n",
      "Iteration: 2103/10000, Loss: 0.03233736753463745\n",
      "Iteration: 2104/10000, Loss: 0.014011512510478497\n",
      "Iteration: 2105/10000, Loss: 0.017105795443058014\n",
      "Iteration: 2106/10000, Loss: 0.023934749886393547\n",
      "Iteration: 2107/10000, Loss: 0.030697649344801903\n",
      "Iteration: 2108/10000, Loss: 0.03194960951805115\n",
      "Iteration: 2109/10000, Loss: 0.017303941771388054\n",
      "Iteration: 2110/10000, Loss: 0.02512509934604168\n",
      "Iteration: 2111/10000, Loss: 0.019745824858546257\n",
      "Iteration: 2112/10000, Loss: 0.025448407977819443\n",
      "Iteration: 2113/10000, Loss: 0.022781740874052048\n",
      "Iteration: 2114/10000, Loss: 0.020915314555168152\n",
      "Iteration: 2115/10000, Loss: 0.029178481549024582\n",
      "Iteration: 2116/10000, Loss: 0.026135489344596863\n",
      "Iteration: 2117/10000, Loss: 0.028132550418376923\n",
      "Iteration: 2118/10000, Loss: 0.026478465646505356\n",
      "Iteration: 2119/10000, Loss: 0.025150824338197708\n",
      "Iteration: 2120/10000, Loss: 0.03986833617091179\n",
      "Iteration: 2121/10000, Loss: 0.022483794018626213\n",
      "Iteration: 2122/10000, Loss: 0.025421109050512314\n",
      "Iteration: 2123/10000, Loss: 0.03134641796350479\n",
      "Iteration: 2124/10000, Loss: 0.02163301594555378\n",
      "Iteration: 2125/10000, Loss: 0.023652367293834686\n",
      "Iteration: 2126/10000, Loss: 0.022562678903341293\n",
      "Iteration: 2127/10000, Loss: 0.020917125046253204\n",
      "Iteration: 2128/10000, Loss: 0.026702554896473885\n",
      "Iteration: 2129/10000, Loss: 0.02794618345797062\n",
      "Iteration: 2130/10000, Loss: 0.022657975554466248\n",
      "Iteration: 2131/10000, Loss: 0.03448024392127991\n",
      "Iteration: 2132/10000, Loss: 0.01633216254413128\n",
      "Iteration: 2133/10000, Loss: 0.020278749987483025\n",
      "Iteration: 2134/10000, Loss: 0.017659202218055725\n",
      "Iteration: 2135/10000, Loss: 0.024843567982316017\n",
      "Iteration: 2136/10000, Loss: 0.01885201223194599\n",
      "Iteration: 2137/10000, Loss: 0.03122316114604473\n",
      "Iteration: 2138/10000, Loss: 0.023464860394597054\n",
      "Iteration: 2139/10000, Loss: 0.02480020746588707\n",
      "Iteration: 2140/10000, Loss: 0.01885334402322769\n",
      "Iteration: 2141/10000, Loss: 0.018713446334004402\n",
      "Iteration: 2142/10000, Loss: 0.015608631074428558\n",
      "Iteration: 2143/10000, Loss: 0.04268839955329895\n",
      "Iteration: 2144/10000, Loss: 0.022272326052188873\n",
      "Iteration: 2145/10000, Loss: 0.03539738059043884\n",
      "Iteration: 2146/10000, Loss: 0.018847405910491943\n",
      "Iteration: 2147/10000, Loss: 0.0296299047768116\n",
      "Iteration: 2148/10000, Loss: 0.026049533858895302\n",
      "Iteration: 2149/10000, Loss: 0.02421131730079651\n",
      "Iteration: 2150/10000, Loss: 0.023563195019960403\n",
      "Iteration: 2151/10000, Loss: 0.029835443943738937\n",
      "Iteration: 2152/10000, Loss: 0.028853487223386765\n",
      "Iteration: 2153/10000, Loss: 0.021927759051322937\n",
      "Iteration: 2154/10000, Loss: 0.0338987335562706\n",
      "Iteration: 2155/10000, Loss: 0.016600515693426132\n",
      "Iteration: 2156/10000, Loss: 0.017559895291924477\n",
      "Iteration: 2157/10000, Loss: 0.024099646136164665\n",
      "Iteration: 2158/10000, Loss: 0.02316908724606037\n",
      "Iteration: 2159/10000, Loss: 0.021350445225834846\n",
      "Iteration: 2160/10000, Loss: 0.016861390322446823\n",
      "Iteration: 2161/10000, Loss: 0.03453666344285011\n",
      "Iteration: 2162/10000, Loss: 0.02203887142241001\n",
      "Iteration: 2163/10000, Loss: 0.022878877818584442\n",
      "Iteration: 2164/10000, Loss: 0.023485610261559486\n",
      "Iteration: 2165/10000, Loss: 0.023298783227801323\n",
      "Iteration: 2166/10000, Loss: 0.03720308840274811\n",
      "Iteration: 2167/10000, Loss: 0.02546185627579689\n",
      "Iteration: 2168/10000, Loss: 0.019331861287355423\n",
      "Iteration: 2169/10000, Loss: 0.02835252322256565\n",
      "Iteration: 2170/10000, Loss: 0.024284640327095985\n",
      "Iteration: 2171/10000, Loss: 0.022057950496673584\n",
      "Iteration: 2172/10000, Loss: 0.022532396018505096\n",
      "Iteration: 2173/10000, Loss: 0.021645251661539078\n",
      "Iteration: 2174/10000, Loss: 0.019845863804221153\n",
      "Iteration: 2175/10000, Loss: 0.025513362139463425\n",
      "Iteration: 2176/10000, Loss: 0.026884863153100014\n",
      "Iteration: 2177/10000, Loss: 0.021502550691366196\n",
      "Iteration: 2178/10000, Loss: 0.0220982376486063\n",
      "Iteration: 2179/10000, Loss: 0.021079692989587784\n",
      "Iteration: 2180/10000, Loss: 0.022092081606388092\n",
      "Iteration: 2181/10000, Loss: 0.02427951991558075\n",
      "Iteration: 2182/10000, Loss: 0.028918791562318802\n",
      "Iteration: 2183/10000, Loss: 0.027164103463292122\n",
      "Iteration: 2184/10000, Loss: 0.031345661729574203\n",
      "Iteration: 2185/10000, Loss: 0.0325324721634388\n",
      "Iteration: 2186/10000, Loss: 0.019454484805464745\n",
      "Iteration: 2187/10000, Loss: 0.02618643082678318\n",
      "Iteration: 2188/10000, Loss: 0.026921041309833527\n",
      "Iteration: 2189/10000, Loss: 0.03216208890080452\n",
      "Iteration: 2190/10000, Loss: 0.039498090744018555\n",
      "Iteration: 2191/10000, Loss: 0.02414669282734394\n",
      "Iteration: 2192/10000, Loss: 0.022746436297893524\n",
      "Iteration: 2193/10000, Loss: 0.015449846163392067\n",
      "Iteration: 2194/10000, Loss: 0.028225576505064964\n",
      "Iteration: 2195/10000, Loss: 0.023658785969018936\n",
      "Iteration: 2196/10000, Loss: 0.025504404678940773\n",
      "Iteration: 2197/10000, Loss: 0.020908553153276443\n",
      "Iteration: 2198/10000, Loss: 0.0120391845703125\n",
      "Iteration: 2199/10000, Loss: 0.015755336731672287\n",
      "Iteration: 2200/10000, Loss: 0.03227289393544197\n",
      "Average test loss:  0.0018\n",
      "Iteration: 2201/10000, Loss: 0.03028874658048153\n",
      "Iteration: 2202/10000, Loss: 0.015840211883187294\n",
      "Iteration: 2203/10000, Loss: 0.025707900524139404\n",
      "Iteration: 2204/10000, Loss: 0.021748995408415794\n",
      "Iteration: 2205/10000, Loss: 0.018647274002432823\n",
      "Iteration: 2206/10000, Loss: 0.022990908473730087\n",
      "Iteration: 2207/10000, Loss: 0.027840103954076767\n",
      "Iteration: 2208/10000, Loss: 0.024238934740424156\n",
      "Iteration: 2209/10000, Loss: 0.023956285789608955\n",
      "Iteration: 2210/10000, Loss: 0.0258858073502779\n",
      "Iteration: 2211/10000, Loss: 0.018475376069545746\n",
      "Iteration: 2212/10000, Loss: 0.039681438356637955\n",
      "Iteration: 2213/10000, Loss: 0.02738378569483757\n",
      "Iteration: 2214/10000, Loss: 0.022414734587073326\n",
      "Iteration: 2215/10000, Loss: 0.025933925062417984\n",
      "Iteration: 2216/10000, Loss: 0.03342065215110779\n",
      "Iteration: 2217/10000, Loss: 0.027549510821700096\n",
      "Iteration: 2218/10000, Loss: 0.027077510952949524\n",
      "Iteration: 2219/10000, Loss: 0.024812020361423492\n",
      "Iteration: 2220/10000, Loss: 0.02012665942311287\n",
      "Iteration: 2221/10000, Loss: 0.02736026979982853\n",
      "Iteration: 2222/10000, Loss: 0.027060585096478462\n",
      "Iteration: 2223/10000, Loss: 0.03975760191679001\n",
      "Iteration: 2224/10000, Loss: 0.02102547138929367\n",
      "Iteration: 2225/10000, Loss: 0.02265148237347603\n",
      "Iteration: 2226/10000, Loss: 0.020430922508239746\n",
      "Iteration: 2227/10000, Loss: 0.029304398223757744\n",
      "Iteration: 2228/10000, Loss: 0.03138710558414459\n",
      "Iteration: 2229/10000, Loss: 0.040090691298246384\n",
      "Iteration: 2230/10000, Loss: 0.018989043310284615\n",
      "Iteration: 2231/10000, Loss: 0.029017962515354156\n",
      "Iteration: 2232/10000, Loss: 0.018022002652287483\n",
      "Iteration: 2233/10000, Loss: 0.027571065351366997\n",
      "Iteration: 2234/10000, Loss: 0.03103814832866192\n",
      "Iteration: 2235/10000, Loss: 0.03219585493206978\n",
      "Iteration: 2236/10000, Loss: 0.024781731888651848\n",
      "Iteration: 2237/10000, Loss: 0.018737617880105972\n",
      "Iteration: 2238/10000, Loss: 0.024979986250400543\n",
      "Iteration: 2239/10000, Loss: 0.02289070188999176\n",
      "Iteration: 2240/10000, Loss: 0.02684701792895794\n",
      "Iteration: 2241/10000, Loss: 0.02903982810676098\n",
      "Iteration: 2242/10000, Loss: 0.03746362403035164\n",
      "Iteration: 2243/10000, Loss: 0.025445593520998955\n",
      "Iteration: 2244/10000, Loss: 0.023701848462224007\n",
      "Iteration: 2245/10000, Loss: 0.02287898026406765\n",
      "Iteration: 2246/10000, Loss: 0.027286915108561516\n",
      "Iteration: 2247/10000, Loss: 0.026278408244252205\n",
      "Iteration: 2248/10000, Loss: 0.023134587332606316\n",
      "Iteration: 2249/10000, Loss: 0.029701313003897667\n",
      "Iteration: 2250/10000, Loss: 0.02739076316356659\n",
      "Iteration: 2251/10000, Loss: 0.01994883082807064\n",
      "Iteration: 2252/10000, Loss: 0.022000346332788467\n",
      "Iteration: 2253/10000, Loss: 0.020383846014738083\n",
      "Iteration: 2254/10000, Loss: 0.014114939607679844\n",
      "Iteration: 2255/10000, Loss: 0.02133253961801529\n",
      "Iteration: 2256/10000, Loss: 0.027506375685334206\n",
      "Iteration: 2257/10000, Loss: 0.02012563683092594\n",
      "Iteration: 2258/10000, Loss: 0.03468670696020126\n",
      "Iteration: 2259/10000, Loss: 0.01802181825041771\n",
      "Iteration: 2260/10000, Loss: 0.027995310723781586\n",
      "Iteration: 2261/10000, Loss: 0.02932368591427803\n",
      "Iteration: 2262/10000, Loss: 0.026481468230485916\n",
      "Iteration: 2263/10000, Loss: 0.03038271889090538\n",
      "Iteration: 2264/10000, Loss: 0.029914159327745438\n",
      "Iteration: 2265/10000, Loss: 0.024838311597704887\n",
      "Iteration: 2266/10000, Loss: 0.024757934734225273\n",
      "Iteration: 2267/10000, Loss: 0.02459702640771866\n",
      "Iteration: 2268/10000, Loss: 0.029169807210564613\n",
      "Iteration: 2269/10000, Loss: 0.023683393374085426\n",
      "Iteration: 2270/10000, Loss: 0.03015245869755745\n",
      "Iteration: 2271/10000, Loss: 0.016732554882764816\n",
      "Iteration: 2272/10000, Loss: 0.028807420283555984\n",
      "Iteration: 2273/10000, Loss: 0.025629544630646706\n",
      "Iteration: 2274/10000, Loss: 0.01578293740749359\n",
      "Iteration: 2275/10000, Loss: 0.027532048523426056\n",
      "Iteration: 2276/10000, Loss: 0.022645870223641396\n",
      "Iteration: 2277/10000, Loss: 0.029960043728351593\n",
      "Iteration: 2278/10000, Loss: 0.016982130706310272\n",
      "Iteration: 2279/10000, Loss: 0.021333185955882072\n",
      "Iteration: 2280/10000, Loss: 0.024473266676068306\n",
      "Iteration: 2281/10000, Loss: 0.02568204700946808\n",
      "Iteration: 2282/10000, Loss: 0.03501400724053383\n",
      "Iteration: 2283/10000, Loss: 0.021987048909068108\n",
      "Iteration: 2284/10000, Loss: 0.030310457572340965\n",
      "Iteration: 2285/10000, Loss: 0.022945579141378403\n",
      "Iteration: 2286/10000, Loss: 0.029276220127940178\n",
      "Iteration: 2287/10000, Loss: 0.022414909675717354\n",
      "Iteration: 2288/10000, Loss: 0.01728544384241104\n",
      "Iteration: 2289/10000, Loss: 0.02678775228559971\n",
      "Iteration: 2290/10000, Loss: 0.023448269814252853\n",
      "Iteration: 2291/10000, Loss: 0.031390346586704254\n",
      "Iteration: 2292/10000, Loss: 0.0296180322766304\n",
      "Iteration: 2293/10000, Loss: 0.03366805613040924\n",
      "Iteration: 2294/10000, Loss: 0.01925351284444332\n",
      "Iteration: 2295/10000, Loss: 0.019929252564907074\n",
      "Iteration: 2296/10000, Loss: 0.02465285360813141\n",
      "Iteration: 2297/10000, Loss: 0.013760560192167759\n",
      "Iteration: 2298/10000, Loss: 0.026386307552456856\n",
      "Iteration: 2299/10000, Loss: 0.03974529728293419\n",
      "Iteration: 2300/10000, Loss: 0.026695961132645607\n",
      "Average test loss:  0.0030\n",
      "Iteration: 2301/10000, Loss: 0.01955382712185383\n",
      "Iteration: 2302/10000, Loss: 0.019881421700119972\n",
      "Iteration: 2303/10000, Loss: 0.045967988669872284\n",
      "Iteration: 2304/10000, Loss: 0.017245862632989883\n",
      "Iteration: 2305/10000, Loss: 0.017334390431642532\n",
      "Iteration: 2306/10000, Loss: 0.022398490458726883\n",
      "Iteration: 2307/10000, Loss: 0.01920696720480919\n",
      "Iteration: 2308/10000, Loss: 0.02077067270874977\n",
      "Iteration: 2309/10000, Loss: 0.023488961160182953\n",
      "Iteration: 2310/10000, Loss: 0.028467433527112007\n",
      "Iteration: 2311/10000, Loss: 0.017399607226252556\n",
      "Iteration: 2312/10000, Loss: 0.01267560850828886\n",
      "Iteration: 2313/10000, Loss: 0.02402505837380886\n",
      "Iteration: 2314/10000, Loss: 0.028892390429973602\n",
      "Iteration: 2315/10000, Loss: 0.016643624752759933\n",
      "Iteration: 2316/10000, Loss: 0.02223016321659088\n",
      "Iteration: 2317/10000, Loss: 0.020797111093997955\n",
      "Iteration: 2318/10000, Loss: 0.019021760672330856\n",
      "Iteration: 2319/10000, Loss: 0.020317459478974342\n",
      "Iteration: 2320/10000, Loss: 0.014539430849254131\n",
      "Iteration: 2321/10000, Loss: 0.0259009450674057\n",
      "Iteration: 2322/10000, Loss: 0.028251497074961662\n",
      "Iteration: 2323/10000, Loss: 0.01553879864513874\n",
      "Iteration: 2324/10000, Loss: 0.030921056866645813\n",
      "Iteration: 2325/10000, Loss: 0.028899461030960083\n",
      "Iteration: 2326/10000, Loss: 0.020851895213127136\n",
      "Iteration: 2327/10000, Loss: 0.04634399339556694\n",
      "Iteration: 2328/10000, Loss: 0.022273987531661987\n",
      "Iteration: 2329/10000, Loss: 0.02253732644021511\n",
      "Iteration: 2330/10000, Loss: 0.023173058405518532\n",
      "Iteration: 2331/10000, Loss: 0.038952648639678955\n",
      "Iteration: 2332/10000, Loss: 0.026652725413441658\n",
      "Iteration: 2333/10000, Loss: 0.03373262658715248\n",
      "Iteration: 2334/10000, Loss: 0.019441425800323486\n",
      "Iteration: 2335/10000, Loss: 0.014220346696674824\n",
      "Iteration: 2336/10000, Loss: 0.027004241943359375\n",
      "Iteration: 2337/10000, Loss: 0.0264406930655241\n",
      "Iteration: 2338/10000, Loss: 0.031189458444714546\n",
      "Iteration: 2339/10000, Loss: 0.024129433557391167\n",
      "Iteration: 2340/10000, Loss: 0.032141342759132385\n",
      "Iteration: 2341/10000, Loss: 0.029776018112897873\n",
      "Iteration: 2342/10000, Loss: 0.02790655381977558\n",
      "Iteration: 2343/10000, Loss: 0.01608435809612274\n",
      "Iteration: 2344/10000, Loss: 0.018922027200460434\n",
      "Iteration: 2345/10000, Loss: 0.02339472807943821\n",
      "Iteration: 2346/10000, Loss: 0.017107950523495674\n",
      "Iteration: 2347/10000, Loss: 0.026492809876799583\n",
      "Iteration: 2348/10000, Loss: 0.02809108793735504\n",
      "Iteration: 2349/10000, Loss: 0.01798161119222641\n",
      "Iteration: 2350/10000, Loss: 0.029577095061540604\n",
      "Iteration: 2351/10000, Loss: 0.019158661365509033\n",
      "Iteration: 2352/10000, Loss: 0.02522467076778412\n",
      "Iteration: 2353/10000, Loss: 0.027001461014151573\n",
      "Iteration: 2354/10000, Loss: 0.02338789589703083\n",
      "Iteration: 2355/10000, Loss: 0.023885922506451607\n",
      "Iteration: 2356/10000, Loss: 0.026335464790463448\n",
      "Iteration: 2357/10000, Loss: 0.019908715039491653\n",
      "Iteration: 2358/10000, Loss: 0.02520138770341873\n",
      "Iteration: 2359/10000, Loss: 0.021266348659992218\n",
      "Iteration: 2360/10000, Loss: 0.019096719101071358\n",
      "Iteration: 2361/10000, Loss: 0.016556860879063606\n",
      "Iteration: 2362/10000, Loss: 0.01828986033797264\n",
      "Iteration: 2363/10000, Loss: 0.01614130660891533\n",
      "Iteration: 2364/10000, Loss: 0.034340135753154755\n",
      "Iteration: 2365/10000, Loss: 0.018127229064702988\n",
      "Iteration: 2366/10000, Loss: 0.012811711989343166\n",
      "Iteration: 2367/10000, Loss: 0.019606836140155792\n",
      "Iteration: 2368/10000, Loss: 0.03151454031467438\n",
      "Iteration: 2369/10000, Loss: 0.02539444901049137\n",
      "Iteration: 2370/10000, Loss: 0.028633777052164078\n",
      "Iteration: 2371/10000, Loss: 0.02544175647199154\n",
      "Iteration: 2372/10000, Loss: 0.025110475718975067\n",
      "Iteration: 2373/10000, Loss: 0.03123052790760994\n",
      "Iteration: 2374/10000, Loss: 0.03177923336625099\n",
      "Iteration: 2375/10000, Loss: 0.02860415354371071\n",
      "Iteration: 2376/10000, Loss: 0.028910746797919273\n",
      "Iteration: 2377/10000, Loss: 0.023890763521194458\n",
      "Iteration: 2378/10000, Loss: 0.025234395638108253\n",
      "Iteration: 2379/10000, Loss: 0.01769278757274151\n",
      "Iteration: 2380/10000, Loss: 0.01681181974709034\n",
      "Iteration: 2381/10000, Loss: 0.023199371993541718\n",
      "Iteration: 2382/10000, Loss: 0.026866383850574493\n",
      "Iteration: 2383/10000, Loss: 0.02331702597439289\n",
      "Iteration: 2384/10000, Loss: 0.02668876014649868\n",
      "Iteration: 2385/10000, Loss: 0.02475634403526783\n",
      "Iteration: 2386/10000, Loss: 0.0215651486068964\n",
      "Iteration: 2387/10000, Loss: 0.017549259588122368\n",
      "Iteration: 2388/10000, Loss: 0.02433609776198864\n",
      "Iteration: 2389/10000, Loss: 0.02172565460205078\n",
      "Iteration: 2390/10000, Loss: 0.0199871975928545\n",
      "Iteration: 2391/10000, Loss: 0.022633684799075127\n",
      "Iteration: 2392/10000, Loss: 0.02559606358408928\n",
      "Iteration: 2393/10000, Loss: 0.016415435820817947\n",
      "Iteration: 2394/10000, Loss: 0.04140877351164818\n",
      "Iteration: 2395/10000, Loss: 0.02472766675055027\n",
      "Iteration: 2396/10000, Loss: 0.029565246775746346\n",
      "Iteration: 2397/10000, Loss: 0.029938651248812675\n",
      "Iteration: 2398/10000, Loss: 0.03199208900332451\n",
      "Iteration: 2399/10000, Loss: 0.02606302872300148\n",
      "Iteration: 2400/10000, Loss: 0.033184994012117386\n",
      "Average test loss:  0.0015\n",
      "Iteration: 2401/10000, Loss: 0.015184253454208374\n",
      "Iteration: 2402/10000, Loss: 0.019950514659285545\n",
      "Iteration: 2403/10000, Loss: 0.023685097694396973\n",
      "Iteration: 2404/10000, Loss: 0.027429113164544106\n",
      "Iteration: 2405/10000, Loss: 0.01730933226644993\n",
      "Iteration: 2406/10000, Loss: 0.019593602046370506\n",
      "Iteration: 2407/10000, Loss: 0.024210311472415924\n",
      "Iteration: 2408/10000, Loss: 0.02503887005150318\n",
      "Iteration: 2409/10000, Loss: 0.02520533837378025\n",
      "Iteration: 2410/10000, Loss: 0.02323763445019722\n",
      "Iteration: 2411/10000, Loss: 0.028615988790988922\n",
      "Iteration: 2412/10000, Loss: 0.023135406896471977\n",
      "Iteration: 2413/10000, Loss: 0.02850787527859211\n",
      "Iteration: 2414/10000, Loss: 0.024995163083076477\n",
      "Iteration: 2415/10000, Loss: 0.01790992170572281\n",
      "Iteration: 2416/10000, Loss: 0.028866838663816452\n",
      "Iteration: 2417/10000, Loss: 0.015395309776067734\n",
      "Iteration: 2418/10000, Loss: 0.015744252130389214\n",
      "Iteration: 2419/10000, Loss: 0.01743091084063053\n",
      "Iteration: 2420/10000, Loss: 0.03865879774093628\n",
      "Iteration: 2421/10000, Loss: 0.028344180434942245\n",
      "Iteration: 2422/10000, Loss: 0.024108871817588806\n",
      "Iteration: 2423/10000, Loss: 0.016040129587054253\n",
      "Iteration: 2424/10000, Loss: 0.02732072025537491\n",
      "Iteration: 2425/10000, Loss: 0.02852286957204342\n",
      "Iteration: 2426/10000, Loss: 0.02369803562760353\n",
      "Iteration: 2427/10000, Loss: 0.022711431607604027\n",
      "Iteration: 2428/10000, Loss: 0.021321948617696762\n",
      "Iteration: 2429/10000, Loss: 0.03049534745514393\n",
      "Iteration: 2430/10000, Loss: 0.019443850964307785\n",
      "Iteration: 2431/10000, Loss: 0.02460135519504547\n",
      "Iteration: 2432/10000, Loss: 0.024184713140130043\n",
      "Iteration: 2433/10000, Loss: 0.022435851395130157\n",
      "Iteration: 2434/10000, Loss: 0.018071657046675682\n",
      "Iteration: 2435/10000, Loss: 0.019329067319631577\n",
      "Iteration: 2436/10000, Loss: 0.02426079846918583\n",
      "Iteration: 2437/10000, Loss: 0.03685762360692024\n",
      "Iteration: 2438/10000, Loss: 0.018630947917699814\n",
      "Iteration: 2439/10000, Loss: 0.015977179631590843\n",
      "Iteration: 2440/10000, Loss: 0.02016565203666687\n",
      "Iteration: 2441/10000, Loss: 0.02496735006570816\n",
      "Iteration: 2442/10000, Loss: 0.020741526037454605\n",
      "Iteration: 2443/10000, Loss: 0.023775067180395126\n",
      "Iteration: 2444/10000, Loss: 0.02528608776628971\n",
      "Iteration: 2445/10000, Loss: 0.021399138495326042\n",
      "Iteration: 2446/10000, Loss: 0.026243723928928375\n",
      "Iteration: 2447/10000, Loss: 0.028403202071785927\n",
      "Iteration: 2448/10000, Loss: 0.022165756672620773\n",
      "Iteration: 2449/10000, Loss: 0.027394823729991913\n",
      "Iteration: 2450/10000, Loss: 0.03110329434275627\n",
      "Iteration: 2451/10000, Loss: 0.021377475932240486\n",
      "Iteration: 2452/10000, Loss: 0.01733127050101757\n",
      "Iteration: 2453/10000, Loss: 0.024910930544137955\n",
      "Iteration: 2454/10000, Loss: 0.02136874757707119\n",
      "Iteration: 2455/10000, Loss: 0.031012123450636864\n",
      "Iteration: 2456/10000, Loss: 0.022802388295531273\n",
      "Iteration: 2457/10000, Loss: 0.024463266134262085\n",
      "Iteration: 2458/10000, Loss: 0.030225342139601707\n",
      "Iteration: 2459/10000, Loss: 0.02411782369017601\n",
      "Iteration: 2460/10000, Loss: 0.029962170869112015\n",
      "Iteration: 2461/10000, Loss: 0.02484874799847603\n",
      "Iteration: 2462/10000, Loss: 0.01748933456838131\n",
      "Iteration: 2463/10000, Loss: 0.020677998661994934\n",
      "Iteration: 2464/10000, Loss: 0.021209144964814186\n",
      "Iteration: 2465/10000, Loss: 0.027161376550793648\n",
      "Iteration: 2466/10000, Loss: 0.023395463824272156\n",
      "Iteration: 2467/10000, Loss: 0.021820157766342163\n",
      "Iteration: 2468/10000, Loss: 0.014939723536372185\n",
      "Iteration: 2469/10000, Loss: 0.017947379499673843\n",
      "Iteration: 2470/10000, Loss: 0.02142452634871006\n",
      "Iteration: 2471/10000, Loss: 0.024286804720759392\n",
      "Iteration: 2472/10000, Loss: 0.02237454056739807\n",
      "Iteration: 2473/10000, Loss: 0.032872363924980164\n",
      "Iteration: 2474/10000, Loss: 0.01575484313070774\n",
      "Iteration: 2475/10000, Loss: 0.016303671523928642\n",
      "Iteration: 2476/10000, Loss: 0.02385241538286209\n",
      "Iteration: 2477/10000, Loss: 0.016503892838954926\n",
      "Iteration: 2478/10000, Loss: 0.01893339864909649\n",
      "Iteration: 2479/10000, Loss: 0.023651815950870514\n",
      "Iteration: 2480/10000, Loss: 0.02292872779071331\n",
      "Iteration: 2481/10000, Loss: 0.01684318669140339\n",
      "Iteration: 2482/10000, Loss: 0.017576852813363075\n",
      "Iteration: 2483/10000, Loss: 0.026865316554903984\n",
      "Iteration: 2484/10000, Loss: 0.023868566378951073\n",
      "Iteration: 2485/10000, Loss: 0.0160361435264349\n",
      "Iteration: 2486/10000, Loss: 0.029235534369945526\n",
      "Iteration: 2487/10000, Loss: 0.023763958364725113\n",
      "Iteration: 2488/10000, Loss: 0.023765413090586662\n",
      "Iteration: 2489/10000, Loss: 0.02150491625070572\n",
      "Iteration: 2490/10000, Loss: 0.020941466093063354\n",
      "Iteration: 2491/10000, Loss: 0.019802860915660858\n",
      "Iteration: 2492/10000, Loss: 0.026969967409968376\n",
      "Iteration: 2493/10000, Loss: 0.02444036863744259\n",
      "Iteration: 2494/10000, Loss: 0.02129257656633854\n",
      "Iteration: 2495/10000, Loss: 0.017498383298516273\n",
      "Iteration: 2496/10000, Loss: 0.02860902063548565\n",
      "Iteration: 2497/10000, Loss: 0.020345143973827362\n",
      "Iteration: 2498/10000, Loss: 0.01315342728048563\n",
      "Iteration: 2499/10000, Loss: 0.020079948008060455\n",
      "Iteration: 2500/10000, Loss: 0.01868356019258499\n",
      "Average test loss:  0.0028\n",
      "Iteration: 2501/10000, Loss: 0.02321106195449829\n",
      "Iteration: 2502/10000, Loss: 0.02063525654375553\n",
      "Iteration: 2503/10000, Loss: 0.013835543766617775\n",
      "Iteration: 2504/10000, Loss: 0.018533829599618912\n",
      "Iteration: 2505/10000, Loss: 0.02578291855752468\n",
      "Iteration: 2506/10000, Loss: 0.01805674284696579\n",
      "Iteration: 2507/10000, Loss: 0.02337750606238842\n",
      "Iteration: 2508/10000, Loss: 0.0264500230550766\n",
      "Iteration: 2509/10000, Loss: 0.01930994726717472\n",
      "Iteration: 2510/10000, Loss: 0.020048249512910843\n",
      "Iteration: 2511/10000, Loss: 0.01818249560892582\n",
      "Iteration: 2512/10000, Loss: 0.023239653557538986\n",
      "Iteration: 2513/10000, Loss: 0.020131563767790794\n",
      "Iteration: 2514/10000, Loss: 0.01578235998749733\n",
      "Iteration: 2515/10000, Loss: 0.01694798842072487\n",
      "Iteration: 2516/10000, Loss: 0.03288404643535614\n",
      "Iteration: 2517/10000, Loss: 0.022740596905350685\n",
      "Iteration: 2518/10000, Loss: 0.018127446994185448\n",
      "Iteration: 2519/10000, Loss: 0.025841934606432915\n",
      "Iteration: 2520/10000, Loss: 0.0252106711268425\n",
      "Iteration: 2521/10000, Loss: 0.014479811303317547\n",
      "Iteration: 2522/10000, Loss: 0.027842016890645027\n",
      "Iteration: 2523/10000, Loss: 0.024374036118388176\n",
      "Iteration: 2524/10000, Loss: 0.01702205091714859\n",
      "Iteration: 2525/10000, Loss: 0.019006745889782906\n",
      "Iteration: 2526/10000, Loss: 0.024775950238108635\n",
      "Iteration: 2527/10000, Loss: 0.028126157820224762\n",
      "Iteration: 2528/10000, Loss: 0.015893930569291115\n",
      "Iteration: 2529/10000, Loss: 0.016938945278525352\n",
      "Iteration: 2530/10000, Loss: 0.016980698332190514\n",
      "Iteration: 2531/10000, Loss: 0.02432059682905674\n",
      "Iteration: 2532/10000, Loss: 0.02209600619971752\n",
      "Iteration: 2533/10000, Loss: 0.020961811766028404\n",
      "Iteration: 2534/10000, Loss: 0.018133800476789474\n",
      "Iteration: 2535/10000, Loss: 0.01485268585383892\n",
      "Iteration: 2536/10000, Loss: 0.013890688307583332\n",
      "Iteration: 2537/10000, Loss: 0.023638620972633362\n",
      "Iteration: 2538/10000, Loss: 0.016710074618458748\n",
      "Iteration: 2539/10000, Loss: 0.024702483788132668\n",
      "Iteration: 2540/10000, Loss: 0.014466844499111176\n",
      "Iteration: 2541/10000, Loss: 0.023297280073165894\n",
      "Iteration: 2542/10000, Loss: 0.019459564238786697\n",
      "Iteration: 2543/10000, Loss: 0.02082582749426365\n",
      "Iteration: 2544/10000, Loss: 0.025683274492621422\n",
      "Iteration: 2545/10000, Loss: 0.020974326878786087\n",
      "Iteration: 2546/10000, Loss: 0.01811918057501316\n",
      "Iteration: 2547/10000, Loss: 0.022776849567890167\n",
      "Iteration: 2548/10000, Loss: 0.030920857563614845\n",
      "Iteration: 2549/10000, Loss: 0.022042248398065567\n",
      "Iteration: 2550/10000, Loss: 0.018120914697647095\n",
      "Iteration: 2551/10000, Loss: 0.015412542968988419\n",
      "Iteration: 2552/10000, Loss: 0.014834221452474594\n",
      "Iteration: 2553/10000, Loss: 0.020879754796624184\n",
      "Iteration: 2554/10000, Loss: 0.03516722470521927\n",
      "Iteration: 2555/10000, Loss: 0.016306865960359573\n",
      "Iteration: 2556/10000, Loss: 0.01798771135509014\n",
      "Iteration: 2557/10000, Loss: 0.019526081159710884\n",
      "Iteration: 2558/10000, Loss: 0.02607046253979206\n",
      "Iteration: 2559/10000, Loss: 0.020725835114717484\n",
      "Iteration: 2560/10000, Loss: 0.022841066122055054\n",
      "Iteration: 2561/10000, Loss: 0.03662564605474472\n",
      "Iteration: 2562/10000, Loss: 0.020892711356282234\n",
      "Iteration: 2563/10000, Loss: 0.024653930217027664\n",
      "Iteration: 2564/10000, Loss: 0.031150104478001595\n",
      "Iteration: 2565/10000, Loss: 0.016540182754397392\n",
      "Iteration: 2566/10000, Loss: 0.02997647598385811\n",
      "Iteration: 2567/10000, Loss: 0.019514096900820732\n",
      "Iteration: 2568/10000, Loss: 0.02335643209517002\n",
      "Iteration: 2569/10000, Loss: 0.024225562810897827\n",
      "Iteration: 2570/10000, Loss: 0.017841866239905357\n",
      "Iteration: 2571/10000, Loss: 0.03105490654706955\n",
      "Iteration: 2572/10000, Loss: 0.017170727252960205\n",
      "Iteration: 2573/10000, Loss: 0.01586895063519478\n",
      "Iteration: 2574/10000, Loss: 0.016732072457671165\n",
      "Iteration: 2575/10000, Loss: 0.02055271342396736\n",
      "Iteration: 2576/10000, Loss: 0.016492405906319618\n",
      "Iteration: 2577/10000, Loss: 0.014940217137336731\n",
      "Iteration: 2578/10000, Loss: 0.03239644318819046\n",
      "Iteration: 2579/10000, Loss: 0.009870498441159725\n",
      "Iteration: 2580/10000, Loss: 0.018265755847096443\n",
      "Iteration: 2581/10000, Loss: 0.01809762232005596\n",
      "Iteration: 2582/10000, Loss: 0.023412853479385376\n",
      "Iteration: 2583/10000, Loss: 0.01863468810915947\n",
      "Iteration: 2584/10000, Loss: 0.022118495777249336\n",
      "Iteration: 2585/10000, Loss: 0.018014831468462944\n",
      "Iteration: 2586/10000, Loss: 0.01314097922295332\n",
      "Iteration: 2587/10000, Loss: 0.01839545927941799\n",
      "Iteration: 2588/10000, Loss: 0.01573862135410309\n",
      "Iteration: 2589/10000, Loss: 0.017309190705418587\n",
      "Iteration: 2590/10000, Loss: 0.017543496564030647\n",
      "Iteration: 2591/10000, Loss: 0.01963919773697853\n",
      "Iteration: 2592/10000, Loss: 0.01452577393501997\n",
      "Iteration: 2593/10000, Loss: 0.0190364271402359\n",
      "Iteration: 2594/10000, Loss: 0.03276738524436951\n",
      "Iteration: 2595/10000, Loss: 0.029769429937005043\n",
      "Iteration: 2596/10000, Loss: 0.019792648032307625\n",
      "Iteration: 2597/10000, Loss: 0.016099143773317337\n",
      "Iteration: 2598/10000, Loss: 0.01964225433766842\n",
      "Iteration: 2599/10000, Loss: 0.024669846519827843\n",
      "Iteration: 2600/10000, Loss: 0.016056865453720093\n",
      "Average test loss:  0.0021\n",
      "Iteration: 2601/10000, Loss: 0.01480377372354269\n",
      "Iteration: 2602/10000, Loss: 0.02690736949443817\n",
      "Iteration: 2603/10000, Loss: 0.015528799965977669\n",
      "Iteration: 2604/10000, Loss: 0.028756234794855118\n",
      "Iteration: 2605/10000, Loss: 0.027936499565839767\n",
      "Iteration: 2606/10000, Loss: 0.01721627451479435\n",
      "Iteration: 2607/10000, Loss: 0.0203934907913208\n",
      "Iteration: 2608/10000, Loss: 0.02074551209807396\n",
      "Iteration: 2609/10000, Loss: 0.016530407592654228\n",
      "Iteration: 2610/10000, Loss: 0.023607386276125908\n",
      "Iteration: 2611/10000, Loss: 0.015903208404779434\n",
      "Iteration: 2612/10000, Loss: 0.020745379850268364\n",
      "Iteration: 2613/10000, Loss: 0.01134636253118515\n",
      "Iteration: 2614/10000, Loss: 0.01805782876908779\n",
      "Iteration: 2615/10000, Loss: 0.04181523993611336\n",
      "Iteration: 2616/10000, Loss: 0.022239234298467636\n",
      "Iteration: 2617/10000, Loss: 0.023786377161741257\n",
      "Iteration: 2618/10000, Loss: 0.021035127341747284\n",
      "Iteration: 2619/10000, Loss: 0.01956675574183464\n",
      "Iteration: 2620/10000, Loss: 0.0279490165412426\n",
      "Iteration: 2621/10000, Loss: 0.018407205119729042\n",
      "Iteration: 2622/10000, Loss: 0.02453039027750492\n",
      "Iteration: 2623/10000, Loss: 0.021912451833486557\n",
      "Iteration: 2624/10000, Loss: 0.019534986466169357\n",
      "Iteration: 2625/10000, Loss: 0.03077610582113266\n",
      "Iteration: 2626/10000, Loss: 0.022850288078188896\n",
      "Iteration: 2627/10000, Loss: 0.02553165704011917\n",
      "Iteration: 2628/10000, Loss: 0.03133983165025711\n",
      "Iteration: 2629/10000, Loss: 0.016393272206187248\n",
      "Iteration: 2630/10000, Loss: 0.0286090150475502\n",
      "Iteration: 2631/10000, Loss: 0.02231590449810028\n",
      "Iteration: 2632/10000, Loss: 0.01577490195631981\n",
      "Iteration: 2633/10000, Loss: 0.02063390612602234\n",
      "Iteration: 2634/10000, Loss: 0.0202286746352911\n",
      "Iteration: 2635/10000, Loss: 0.02442277781665325\n",
      "Iteration: 2636/10000, Loss: 0.014130561612546444\n",
      "Iteration: 2637/10000, Loss: 0.015352442860603333\n",
      "Iteration: 2638/10000, Loss: 0.0216144397854805\n",
      "Iteration: 2639/10000, Loss: 0.028846442699432373\n",
      "Iteration: 2640/10000, Loss: 0.02763110212981701\n",
      "Iteration: 2641/10000, Loss: 0.018070928752422333\n",
      "Iteration: 2642/10000, Loss: 0.01734265871345997\n",
      "Iteration: 2643/10000, Loss: 0.02147746831178665\n",
      "Iteration: 2644/10000, Loss: 0.022899072617292404\n",
      "Iteration: 2645/10000, Loss: 0.021709106862545013\n",
      "Iteration: 2646/10000, Loss: 0.01623707078397274\n",
      "Iteration: 2647/10000, Loss: 0.019942935556173325\n",
      "Iteration: 2648/10000, Loss: 0.018340108916163445\n",
      "Iteration: 2649/10000, Loss: 0.02072324976325035\n",
      "Iteration: 2650/10000, Loss: 0.019137751311063766\n",
      "Iteration: 2651/10000, Loss: 0.0306209996342659\n",
      "Iteration: 2652/10000, Loss: 0.022310955449938774\n",
      "Iteration: 2653/10000, Loss: 0.0214043278247118\n",
      "Iteration: 2654/10000, Loss: 0.020262375473976135\n",
      "Iteration: 2655/10000, Loss: 0.010738568380475044\n",
      "Iteration: 2656/10000, Loss: 0.015503273345530033\n",
      "Iteration: 2657/10000, Loss: 0.021758761256933212\n",
      "Iteration: 2658/10000, Loss: 0.02580730989575386\n",
      "Iteration: 2659/10000, Loss: 0.014822199940681458\n",
      "Iteration: 2660/10000, Loss: 0.01571374200284481\n",
      "Iteration: 2661/10000, Loss: 0.017791299149394035\n",
      "Iteration: 2662/10000, Loss: 0.021421678364276886\n",
      "Iteration: 2663/10000, Loss: 0.02046315371990204\n",
      "Iteration: 2664/10000, Loss: 0.014001723378896713\n",
      "Iteration: 2665/10000, Loss: 0.020757632330060005\n",
      "Iteration: 2666/10000, Loss: 0.012338067404925823\n",
      "Iteration: 2667/10000, Loss: 0.015650199726223946\n",
      "Iteration: 2668/10000, Loss: 0.03196291998028755\n",
      "Iteration: 2669/10000, Loss: 0.022708745673298836\n",
      "Iteration: 2670/10000, Loss: 0.02557140775024891\n",
      "Iteration: 2671/10000, Loss: 0.017946390435099602\n",
      "Iteration: 2672/10000, Loss: 0.02159358374774456\n",
      "Iteration: 2673/10000, Loss: 0.02059788815677166\n",
      "Iteration: 2674/10000, Loss: 0.025122299790382385\n",
      "Iteration: 2675/10000, Loss: 0.02133827842772007\n",
      "Iteration: 2676/10000, Loss: 0.023647289723157883\n",
      "Iteration: 2677/10000, Loss: 0.01960773952305317\n",
      "Iteration: 2678/10000, Loss: 0.023891229182481766\n",
      "Iteration: 2679/10000, Loss: 0.025441154837608337\n",
      "Iteration: 2680/10000, Loss: 0.027977976948022842\n",
      "Iteration: 2681/10000, Loss: 0.03321053460240364\n",
      "Iteration: 2682/10000, Loss: 0.020788628607988358\n",
      "Iteration: 2683/10000, Loss: 0.0185738243162632\n",
      "Iteration: 2684/10000, Loss: 0.015052963979542255\n",
      "Iteration: 2685/10000, Loss: 0.015761977061629295\n",
      "Iteration: 2686/10000, Loss: 0.02152300253510475\n",
      "Iteration: 2687/10000, Loss: 0.02700147219002247\n",
      "Iteration: 2688/10000, Loss: 0.02329198643565178\n",
      "Iteration: 2689/10000, Loss: 0.02477499097585678\n",
      "Iteration: 2690/10000, Loss: 0.023033075034618378\n",
      "Iteration: 2691/10000, Loss: 0.018900353461503983\n",
      "Iteration: 2692/10000, Loss: 0.014850646257400513\n",
      "Iteration: 2693/10000, Loss: 0.015157822519540787\n",
      "Iteration: 2694/10000, Loss: 0.014230404049158096\n",
      "Iteration: 2695/10000, Loss: 0.01594332605600357\n",
      "Iteration: 2696/10000, Loss: 0.025783782824873924\n",
      "Iteration: 2697/10000, Loss: 0.01811952143907547\n",
      "Iteration: 2698/10000, Loss: 0.01745578460395336\n",
      "Iteration: 2699/10000, Loss: 0.01594885252416134\n",
      "Iteration: 2700/10000, Loss: 0.012049312703311443\n",
      "Average test loss:  0.0027\n",
      "Iteration: 2701/10000, Loss: 0.022236542776226997\n",
      "Iteration: 2702/10000, Loss: 0.027255410328507423\n",
      "Iteration: 2703/10000, Loss: 0.019029200077056885\n",
      "Iteration: 2704/10000, Loss: 0.019832467660307884\n",
      "Iteration: 2705/10000, Loss: 0.021914353594183922\n",
      "Iteration: 2706/10000, Loss: 0.027400357648730278\n",
      "Iteration: 2707/10000, Loss: 0.02099616825580597\n",
      "Iteration: 2708/10000, Loss: 0.013892294839024544\n",
      "Iteration: 2709/10000, Loss: 0.01631726510822773\n",
      "Iteration: 2710/10000, Loss: 0.017233841121196747\n",
      "Iteration: 2711/10000, Loss: 0.02498871274292469\n",
      "Iteration: 2712/10000, Loss: 0.021148085594177246\n",
      "Iteration: 2713/10000, Loss: 0.018421877175569534\n",
      "Iteration: 2714/10000, Loss: 0.022952547296881676\n",
      "Iteration: 2715/10000, Loss: 0.021529823541641235\n",
      "Iteration: 2716/10000, Loss: 0.02159801870584488\n",
      "Iteration: 2717/10000, Loss: 0.01466972753405571\n",
      "Iteration: 2718/10000, Loss: 0.0161251462996006\n",
      "Iteration: 2719/10000, Loss: 0.01381723117083311\n",
      "Iteration: 2720/10000, Loss: 0.021025806665420532\n",
      "Iteration: 2721/10000, Loss: 0.01536810863763094\n",
      "Iteration: 2722/10000, Loss: 0.02261703461408615\n",
      "Iteration: 2723/10000, Loss: 0.024186035618185997\n",
      "Iteration: 2724/10000, Loss: 0.025463471189141273\n",
      "Iteration: 2725/10000, Loss: 0.019565079361200333\n",
      "Iteration: 2726/10000, Loss: 0.021439647302031517\n",
      "Iteration: 2727/10000, Loss: 0.02306341752409935\n",
      "Iteration: 2728/10000, Loss: 0.017436079680919647\n",
      "Iteration: 2729/10000, Loss: 0.019042275846004486\n",
      "Iteration: 2730/10000, Loss: 0.016400126740336418\n",
      "Iteration: 2731/10000, Loss: 0.019083429127931595\n",
      "Iteration: 2732/10000, Loss: 0.021610209718346596\n",
      "Iteration: 2733/10000, Loss: 0.01690913736820221\n",
      "Iteration: 2734/10000, Loss: 0.02207161858677864\n",
      "Iteration: 2735/10000, Loss: 0.01854173094034195\n",
      "Iteration: 2736/10000, Loss: 0.019364066421985626\n",
      "Iteration: 2737/10000, Loss: 0.020010458305478096\n",
      "Iteration: 2738/10000, Loss: 0.021808436140418053\n",
      "Iteration: 2739/10000, Loss: 0.015927333384752274\n",
      "Iteration: 2740/10000, Loss: 0.025655649602413177\n",
      "Iteration: 2741/10000, Loss: 0.021743664517998695\n",
      "Iteration: 2742/10000, Loss: 0.016706088557839394\n",
      "Iteration: 2743/10000, Loss: 0.017957840114831924\n",
      "Iteration: 2744/10000, Loss: 0.018513290211558342\n",
      "Iteration: 2745/10000, Loss: 0.020566526800394058\n",
      "Iteration: 2746/10000, Loss: 0.016961297020316124\n",
      "Iteration: 2747/10000, Loss: 0.020540503785014153\n",
      "Iteration: 2748/10000, Loss: 0.02181900106370449\n",
      "Iteration: 2749/10000, Loss: 0.023389343172311783\n",
      "Iteration: 2750/10000, Loss: 0.022469526156783104\n",
      "Iteration: 2751/10000, Loss: 0.02458689548075199\n",
      "Iteration: 2752/10000, Loss: 0.02082391269505024\n",
      "Iteration: 2753/10000, Loss: 0.014920933172106743\n",
      "Iteration: 2754/10000, Loss: 0.01431855745613575\n",
      "Iteration: 2755/10000, Loss: 0.021351387724280357\n",
      "Iteration: 2756/10000, Loss: 0.014429320581257343\n",
      "Iteration: 2757/10000, Loss: 0.027713971212506294\n",
      "Iteration: 2758/10000, Loss: 0.021279431879520416\n",
      "Iteration: 2759/10000, Loss: 0.017177443951368332\n",
      "Iteration: 2760/10000, Loss: 0.022204292938113213\n",
      "Iteration: 2761/10000, Loss: 0.03341452404856682\n",
      "Iteration: 2762/10000, Loss: 0.02326057478785515\n",
      "Iteration: 2763/10000, Loss: 0.014887850731611252\n",
      "Iteration: 2764/10000, Loss: 0.025854269042611122\n",
      "Iteration: 2765/10000, Loss: 0.011756711639463902\n",
      "Iteration: 2766/10000, Loss: 0.019136663526296616\n",
      "Iteration: 2767/10000, Loss: 0.02061089687049389\n",
      "Iteration: 2768/10000, Loss: 0.027142252773046494\n",
      "Iteration: 2769/10000, Loss: 0.01408244576305151\n",
      "Iteration: 2770/10000, Loss: 0.023884886875748634\n",
      "Iteration: 2771/10000, Loss: 0.019634714350104332\n",
      "Iteration: 2772/10000, Loss: 0.022179419174790382\n",
      "Iteration: 2773/10000, Loss: 0.020660938695073128\n",
      "Iteration: 2774/10000, Loss: 0.01859765127301216\n",
      "Iteration: 2775/10000, Loss: 0.015005366876721382\n",
      "Iteration: 2776/10000, Loss: 0.017703287303447723\n",
      "Iteration: 2777/10000, Loss: 0.013201006688177586\n",
      "Iteration: 2778/10000, Loss: 0.023670831695199013\n",
      "Iteration: 2779/10000, Loss: 0.02123943157494068\n",
      "Iteration: 2780/10000, Loss: 0.021745527163147926\n",
      "Iteration: 2781/10000, Loss: 0.019484102725982666\n",
      "Iteration: 2782/10000, Loss: 0.01837494596838951\n",
      "Iteration: 2783/10000, Loss: 0.020687179639935493\n",
      "Iteration: 2784/10000, Loss: 0.01986824721097946\n",
      "Iteration: 2785/10000, Loss: 0.02059338614344597\n",
      "Iteration: 2786/10000, Loss: 0.017601165920495987\n",
      "Iteration: 2787/10000, Loss: 0.028012044727802277\n",
      "Iteration: 2788/10000, Loss: 0.032582301646471024\n",
      "Iteration: 2789/10000, Loss: 0.01784130185842514\n",
      "Iteration: 2790/10000, Loss: 0.019642125815153122\n",
      "Iteration: 2791/10000, Loss: 0.022363942116498947\n",
      "Iteration: 2792/10000, Loss: 0.02061133086681366\n",
      "Iteration: 2793/10000, Loss: 0.02042854018509388\n",
      "Iteration: 2794/10000, Loss: 0.023749567568302155\n",
      "Iteration: 2795/10000, Loss: 0.02483988180756569\n",
      "Iteration: 2796/10000, Loss: 0.023083161562681198\n",
      "Iteration: 2797/10000, Loss: 0.024646375328302383\n",
      "Iteration: 2798/10000, Loss: 0.019963396713137627\n",
      "Iteration: 2799/10000, Loss: 0.026030216366052628\n",
      "Iteration: 2800/10000, Loss: 0.019703345373272896\n",
      "Average test loss:  0.0027\n",
      "Iteration: 2801/10000, Loss: 0.021984955295920372\n",
      "Iteration: 2802/10000, Loss: 0.026842040941119194\n",
      "Iteration: 2803/10000, Loss: 0.020015068352222443\n",
      "Iteration: 2804/10000, Loss: 0.01787756197154522\n",
      "Iteration: 2805/10000, Loss: 0.02162303775548935\n",
      "Iteration: 2806/10000, Loss: 0.016779249534010887\n",
      "Iteration: 2807/10000, Loss: 0.021928494796156883\n",
      "Iteration: 2808/10000, Loss: 0.028441037982702255\n",
      "Iteration: 2809/10000, Loss: 0.02379690296947956\n",
      "Iteration: 2810/10000, Loss: 0.013820134103298187\n",
      "Iteration: 2811/10000, Loss: 0.02125047892332077\n",
      "Iteration: 2812/10000, Loss: 0.020608697086572647\n",
      "Iteration: 2813/10000, Loss: 0.02804548107087612\n",
      "Iteration: 2814/10000, Loss: 0.02520166151225567\n",
      "Iteration: 2815/10000, Loss: 0.020294109359383583\n",
      "Iteration: 2816/10000, Loss: 0.020795438438653946\n",
      "Iteration: 2817/10000, Loss: 0.025522643700242043\n",
      "Iteration: 2818/10000, Loss: 0.017077786847949028\n",
      "Iteration: 2819/10000, Loss: 0.018814867362380028\n",
      "Iteration: 2820/10000, Loss: 0.027237169444561005\n",
      "Iteration: 2821/10000, Loss: 0.020551709458231926\n",
      "Iteration: 2822/10000, Loss: 0.027383331209421158\n",
      "Iteration: 2823/10000, Loss: 0.019130578264594078\n",
      "Iteration: 2824/10000, Loss: 0.017898663878440857\n",
      "Iteration: 2825/10000, Loss: 0.015926161780953407\n",
      "Iteration: 2826/10000, Loss: 0.022873904556035995\n",
      "Iteration: 2827/10000, Loss: 0.018967004492878914\n",
      "Iteration: 2828/10000, Loss: 0.016421517357230186\n",
      "Iteration: 2829/10000, Loss: 0.020685561001300812\n",
      "Iteration: 2830/10000, Loss: 0.02169172652065754\n",
      "Iteration: 2831/10000, Loss: 0.018650224432349205\n",
      "Iteration: 2832/10000, Loss: 0.020944509655237198\n",
      "Iteration: 2833/10000, Loss: 0.03037983551621437\n",
      "Iteration: 2834/10000, Loss: 0.021226344630122185\n",
      "Iteration: 2835/10000, Loss: 0.020654385909438133\n",
      "Iteration: 2836/10000, Loss: 0.024976134300231934\n",
      "Iteration: 2837/10000, Loss: 0.01585228741168976\n",
      "Iteration: 2838/10000, Loss: 0.022890033200383186\n",
      "Iteration: 2839/10000, Loss: 0.025453919544816017\n",
      "Iteration: 2840/10000, Loss: 0.019239375367760658\n",
      "Iteration: 2841/10000, Loss: 0.030947944149374962\n",
      "Iteration: 2842/10000, Loss: 0.025820136070251465\n",
      "Iteration: 2843/10000, Loss: 0.016256513074040413\n",
      "Iteration: 2844/10000, Loss: 0.01732972450554371\n",
      "Iteration: 2845/10000, Loss: 0.019765537232160568\n",
      "Iteration: 2846/10000, Loss: 0.021221740171313286\n",
      "Iteration: 2847/10000, Loss: 0.020884310826659203\n",
      "Iteration: 2848/10000, Loss: 0.018712786957621574\n",
      "Iteration: 2849/10000, Loss: 0.020839525386691093\n",
      "Iteration: 2850/10000, Loss: 0.023229416459798813\n",
      "Iteration: 2851/10000, Loss: 0.019416091963648796\n",
      "Iteration: 2852/10000, Loss: 0.01948537491261959\n",
      "Iteration: 2853/10000, Loss: 0.017432857304811478\n",
      "Iteration: 2854/10000, Loss: 0.014067918993532658\n",
      "Iteration: 2855/10000, Loss: 0.013912019319832325\n",
      "Iteration: 2856/10000, Loss: 0.032355304807424545\n",
      "Iteration: 2857/10000, Loss: 0.03213362768292427\n",
      "Iteration: 2858/10000, Loss: 0.025946175679564476\n",
      "Iteration: 2859/10000, Loss: 0.023420793935656548\n",
      "Iteration: 2860/10000, Loss: 0.028875168412923813\n",
      "Iteration: 2861/10000, Loss: 0.022374244406819344\n",
      "Iteration: 2862/10000, Loss: 0.021694106981158257\n",
      "Iteration: 2863/10000, Loss: 0.017509935423731804\n",
      "Iteration: 2864/10000, Loss: 0.018807921558618546\n",
      "Iteration: 2865/10000, Loss: 0.024735337123274803\n",
      "Iteration: 2866/10000, Loss: 0.02385854162275791\n",
      "Iteration: 2867/10000, Loss: 0.01466719526797533\n",
      "Iteration: 2868/10000, Loss: 0.02312987484037876\n",
      "Iteration: 2869/10000, Loss: 0.019047165289521217\n",
      "Iteration: 2870/10000, Loss: 0.033498868346214294\n",
      "Iteration: 2871/10000, Loss: 0.031985051929950714\n",
      "Iteration: 2872/10000, Loss: 0.023387989029288292\n",
      "Iteration: 2873/10000, Loss: 0.023829469457268715\n",
      "Iteration: 2874/10000, Loss: 0.02216993272304535\n",
      "Iteration: 2875/10000, Loss: 0.03512540087103844\n",
      "Iteration: 2876/10000, Loss: 0.03135793283581734\n",
      "Iteration: 2877/10000, Loss: 0.022374387830495834\n",
      "Iteration: 2878/10000, Loss: 0.018674680963158607\n",
      "Iteration: 2879/10000, Loss: 0.009797266684472561\n",
      "Iteration: 2880/10000, Loss: 0.028191762045025826\n",
      "Iteration: 2881/10000, Loss: 0.035352278500795364\n",
      "Iteration: 2882/10000, Loss: 0.025658156722784042\n",
      "Iteration: 2883/10000, Loss: 0.021977003663778305\n",
      "Iteration: 2884/10000, Loss: 0.018073491752147675\n",
      "Iteration: 2885/10000, Loss: 0.021712088957428932\n",
      "Iteration: 2886/10000, Loss: 0.019439417868852615\n",
      "Iteration: 2887/10000, Loss: 0.015678592026233673\n",
      "Iteration: 2888/10000, Loss: 0.018705569207668304\n",
      "Iteration: 2889/10000, Loss: 0.020476259291172028\n",
      "Iteration: 2890/10000, Loss: 0.01782773807644844\n",
      "Iteration: 2891/10000, Loss: 0.028307901695370674\n",
      "Iteration: 2892/10000, Loss: 0.02416134998202324\n",
      "Iteration: 2893/10000, Loss: 0.017188897356390953\n",
      "Iteration: 2894/10000, Loss: 0.031767942011356354\n",
      "Iteration: 2895/10000, Loss: 0.018320204690098763\n",
      "Iteration: 2896/10000, Loss: 0.013410740531980991\n",
      "Iteration: 2897/10000, Loss: 0.019129140302538872\n",
      "Iteration: 2898/10000, Loss: 0.026771316304802895\n",
      "Iteration: 2899/10000, Loss: 0.016732381656765938\n",
      "Iteration: 2900/10000, Loss: 0.01349517609924078\n",
      "Average test loss:  0.0026\n",
      "Iteration: 2901/10000, Loss: 0.021644823253154755\n",
      "Iteration: 2902/10000, Loss: 0.0201482605189085\n",
      "Iteration: 2903/10000, Loss: 0.02665524370968342\n",
      "Iteration: 2904/10000, Loss: 0.02050154097378254\n",
      "Iteration: 2905/10000, Loss: 0.01316655334085226\n",
      "Iteration: 2906/10000, Loss: 0.025436384603381157\n",
      "Iteration: 2907/10000, Loss: 0.02002996951341629\n",
      "Iteration: 2908/10000, Loss: 0.018964461982250214\n",
      "Iteration: 2909/10000, Loss: 0.020478960126638412\n",
      "Iteration: 2910/10000, Loss: 0.0205971859395504\n",
      "Iteration: 2911/10000, Loss: 0.01545027643442154\n",
      "Iteration: 2912/10000, Loss: 0.017467889934778214\n",
      "Iteration: 2913/10000, Loss: 0.018830087035894394\n",
      "Iteration: 2914/10000, Loss: 0.01768835447728634\n",
      "Iteration: 2915/10000, Loss: 0.014110914431512356\n",
      "Iteration: 2916/10000, Loss: 0.017961161211133003\n",
      "Iteration: 2917/10000, Loss: 0.021934237331151962\n",
      "Iteration: 2918/10000, Loss: 0.021913671866059303\n",
      "Iteration: 2919/10000, Loss: 0.020610623061656952\n",
      "Iteration: 2920/10000, Loss: 0.016061794012784958\n",
      "Iteration: 2921/10000, Loss: 0.020014122128486633\n",
      "Iteration: 2922/10000, Loss: 0.019025340676307678\n",
      "Iteration: 2923/10000, Loss: 0.01658993773162365\n",
      "Iteration: 2924/10000, Loss: 0.022605866193771362\n",
      "Iteration: 2925/10000, Loss: 0.01683509722352028\n",
      "Iteration: 2926/10000, Loss: 0.016423603519797325\n",
      "Iteration: 2927/10000, Loss: 0.02063373290002346\n",
      "Iteration: 2928/10000, Loss: 0.014283847063779831\n",
      "Iteration: 2929/10000, Loss: 0.02164873667061329\n",
      "Iteration: 2930/10000, Loss: 0.014293679036200047\n",
      "Iteration: 2931/10000, Loss: 0.03058926947414875\n",
      "Iteration: 2932/10000, Loss: 0.01520345825701952\n",
      "Iteration: 2933/10000, Loss: 0.023202013224363327\n",
      "Iteration: 2934/10000, Loss: 0.015671486034989357\n",
      "Iteration: 2935/10000, Loss: 0.023683741688728333\n",
      "Iteration: 2936/10000, Loss: 0.014162542298436165\n",
      "Iteration: 2937/10000, Loss: 0.021387500688433647\n",
      "Iteration: 2938/10000, Loss: 0.017460456117987633\n",
      "Iteration: 2939/10000, Loss: 0.015239766798913479\n",
      "Iteration: 2940/10000, Loss: 0.016364822164177895\n",
      "Iteration: 2941/10000, Loss: 0.014127172529697418\n",
      "Iteration: 2942/10000, Loss: 0.01671384461224079\n",
      "Iteration: 2943/10000, Loss: 0.015957769006490707\n",
      "Iteration: 2944/10000, Loss: 0.019340839236974716\n",
      "Iteration: 2945/10000, Loss: 0.018667789176106453\n",
      "Iteration: 2946/10000, Loss: 0.013979865238070488\n",
      "Iteration: 2947/10000, Loss: 0.018573492765426636\n",
      "Iteration: 2948/10000, Loss: 0.014041125774383545\n",
      "Iteration: 2949/10000, Loss: 0.01727326586842537\n",
      "Iteration: 2950/10000, Loss: 0.018148336559534073\n",
      "Iteration: 2951/10000, Loss: 0.013708739541471004\n",
      "Iteration: 2952/10000, Loss: 0.011274123564362526\n",
      "Iteration: 2953/10000, Loss: 0.018510185182094574\n",
      "Iteration: 2954/10000, Loss: 0.014728877693414688\n",
      "Iteration: 2955/10000, Loss: 0.026737915351986885\n",
      "Iteration: 2956/10000, Loss: 0.020409399643540382\n",
      "Iteration: 2957/10000, Loss: 0.025428086519241333\n",
      "Iteration: 2958/10000, Loss: 0.0264196265488863\n",
      "Iteration: 2959/10000, Loss: 0.014238625764846802\n",
      "Iteration: 2960/10000, Loss: 0.017783483490347862\n",
      "Iteration: 2961/10000, Loss: 0.022452708333730698\n",
      "Iteration: 2962/10000, Loss: 0.024721499532461166\n",
      "Iteration: 2963/10000, Loss: 0.0147916404530406\n",
      "Iteration: 2964/10000, Loss: 0.020554786548018456\n",
      "Iteration: 2965/10000, Loss: 0.016455436125397682\n",
      "Iteration: 2966/10000, Loss: 0.022272614762187004\n",
      "Iteration: 2967/10000, Loss: 0.021784096956253052\n",
      "Iteration: 2968/10000, Loss: 0.019346708431839943\n",
      "Iteration: 2969/10000, Loss: 0.017656859010457993\n",
      "Iteration: 2970/10000, Loss: 0.01657235063612461\n",
      "Iteration: 2971/10000, Loss: 0.013938095420598984\n",
      "Iteration: 2972/10000, Loss: 0.022651176899671555\n",
      "Iteration: 2973/10000, Loss: 0.021078797057271004\n",
      "Iteration: 2974/10000, Loss: 0.02227427437901497\n",
      "Iteration: 2975/10000, Loss: 0.019777726382017136\n",
      "Iteration: 2976/10000, Loss: 0.019350649788975716\n",
      "Iteration: 2977/10000, Loss: 0.017215421423316002\n",
      "Iteration: 2978/10000, Loss: 0.018853694200515747\n",
      "Iteration: 2979/10000, Loss: 0.0199454165995121\n",
      "Iteration: 2980/10000, Loss: 0.018285147845745087\n",
      "Iteration: 2981/10000, Loss: 0.023646175861358643\n",
      "Iteration: 2982/10000, Loss: 0.015130658634006977\n",
      "Iteration: 2983/10000, Loss: 0.023806018754839897\n",
      "Iteration: 2984/10000, Loss: 0.017498958855867386\n",
      "Iteration: 2985/10000, Loss: 0.015363754704594612\n",
      "Iteration: 2986/10000, Loss: 0.02104051038622856\n",
      "Iteration: 2987/10000, Loss: 0.012107972986996174\n",
      "Iteration: 2988/10000, Loss: 0.023639535531401634\n",
      "Iteration: 2989/10000, Loss: 0.012995971366763115\n",
      "Iteration: 2990/10000, Loss: 0.021194400265812874\n",
      "Iteration: 2991/10000, Loss: 0.017379075288772583\n",
      "Iteration: 2992/10000, Loss: 0.021539362147450447\n",
      "Iteration: 2993/10000, Loss: 0.021670544520020485\n",
      "Iteration: 2994/10000, Loss: 0.015488150529563427\n",
      "Iteration: 2995/10000, Loss: 0.021320447325706482\n",
      "Iteration: 2996/10000, Loss: 0.02028627134859562\n",
      "Iteration: 2997/10000, Loss: 0.022286856546998024\n",
      "Iteration: 2998/10000, Loss: 0.020329685881733894\n",
      "Iteration: 2999/10000, Loss: 0.018320508301258087\n",
      "Iteration: 3000/10000, Loss: 0.011774667538702488\n",
      "Average test loss:  0.0031\n",
      "Iteration: 3001/10000, Loss: 0.020359864458441734\n",
      "Iteration: 3002/10000, Loss: 0.02347450889647007\n",
      "Iteration: 3003/10000, Loss: 0.023758547380566597\n",
      "Iteration: 3004/10000, Loss: 0.021785367280244827\n",
      "Iteration: 3005/10000, Loss: 0.01919378526508808\n",
      "Iteration: 3006/10000, Loss: 0.016925498843193054\n",
      "Iteration: 3007/10000, Loss: 0.019191967323422432\n",
      "Iteration: 3008/10000, Loss: 0.03235886991024017\n",
      "Iteration: 3009/10000, Loss: 0.018068956211209297\n",
      "Iteration: 3010/10000, Loss: 0.01627412810921669\n",
      "Iteration: 3011/10000, Loss: 0.020492902025580406\n",
      "Iteration: 3012/10000, Loss: 0.01864580437541008\n",
      "Iteration: 3013/10000, Loss: 0.015210659243166447\n",
      "Iteration: 3014/10000, Loss: 0.023696735501289368\n",
      "Iteration: 3015/10000, Loss: 0.020817125216126442\n",
      "Iteration: 3016/10000, Loss: 0.015311001800000668\n",
      "Iteration: 3017/10000, Loss: 0.015796076506376266\n",
      "Iteration: 3018/10000, Loss: 0.021637869998812675\n",
      "Iteration: 3019/10000, Loss: 0.014666678383946419\n",
      "Iteration: 3020/10000, Loss: 0.013025796040892601\n",
      "Iteration: 3021/10000, Loss: 0.019053909927606583\n",
      "Iteration: 3022/10000, Loss: 0.014522921293973923\n",
      "Iteration: 3023/10000, Loss: 0.02552896738052368\n",
      "Iteration: 3024/10000, Loss: 0.014016253873705864\n",
      "Iteration: 3025/10000, Loss: 0.025274384766817093\n",
      "Iteration: 3026/10000, Loss: 0.013488438911736012\n",
      "Iteration: 3027/10000, Loss: 0.015699353069067\n",
      "Iteration: 3028/10000, Loss: 0.018186848610639572\n",
      "Iteration: 3029/10000, Loss: 0.01655033603310585\n",
      "Iteration: 3030/10000, Loss: 0.022477706894278526\n",
      "Iteration: 3031/10000, Loss: 0.01589876040816307\n",
      "Iteration: 3032/10000, Loss: 0.023919831961393356\n",
      "Iteration: 3033/10000, Loss: 0.022123517468571663\n",
      "Iteration: 3034/10000, Loss: 0.017562776803970337\n",
      "Iteration: 3035/10000, Loss: 0.02239249460399151\n",
      "Iteration: 3036/10000, Loss: 0.017762599512934685\n",
      "Iteration: 3037/10000, Loss: 0.012596338987350464\n",
      "Iteration: 3038/10000, Loss: 0.014839296229183674\n",
      "Iteration: 3039/10000, Loss: 0.01662556640803814\n",
      "Iteration: 3040/10000, Loss: 0.012095730751752853\n",
      "Iteration: 3041/10000, Loss: 0.020609501749277115\n",
      "Iteration: 3042/10000, Loss: 0.01306405570358038\n",
      "Iteration: 3043/10000, Loss: 0.022489892318844795\n",
      "Iteration: 3044/10000, Loss: 0.023761318996548653\n",
      "Iteration: 3045/10000, Loss: 0.010371592827141285\n",
      "Iteration: 3046/10000, Loss: 0.01701059192419052\n",
      "Iteration: 3047/10000, Loss: 0.024933474138379097\n",
      "Iteration: 3048/10000, Loss: 0.014554278925061226\n",
      "Iteration: 3049/10000, Loss: 0.014753240160644054\n",
      "Iteration: 3050/10000, Loss: 0.018676377832889557\n",
      "Iteration: 3051/10000, Loss: 0.027260715141892433\n",
      "Iteration: 3052/10000, Loss: 0.01038854569196701\n",
      "Iteration: 3053/10000, Loss: 0.018003597855567932\n",
      "Iteration: 3054/10000, Loss: 0.016306286677718163\n",
      "Iteration: 3055/10000, Loss: 0.011435163207352161\n",
      "Iteration: 3056/10000, Loss: 0.01932039111852646\n",
      "Iteration: 3057/10000, Loss: 0.014590765349566936\n",
      "Iteration: 3058/10000, Loss: 0.023250462487339973\n",
      "Iteration: 3059/10000, Loss: 0.024446317926049232\n",
      "Iteration: 3060/10000, Loss: 0.017707156017422676\n",
      "Iteration: 3061/10000, Loss: 0.015733903273940086\n",
      "Iteration: 3062/10000, Loss: 0.020314328372478485\n",
      "Iteration: 3063/10000, Loss: 0.01609010435640812\n",
      "Iteration: 3064/10000, Loss: 0.01411828026175499\n",
      "Iteration: 3065/10000, Loss: 0.028770016506314278\n",
      "Iteration: 3066/10000, Loss: 0.015235706232488155\n",
      "Iteration: 3067/10000, Loss: 0.014209408313035965\n",
      "Iteration: 3068/10000, Loss: 0.016085486859083176\n",
      "Iteration: 3069/10000, Loss: 0.02398674190044403\n",
      "Iteration: 3070/10000, Loss: 0.0116316182538867\n",
      "Iteration: 3071/10000, Loss: 0.013773735612630844\n",
      "Iteration: 3072/10000, Loss: 0.024067942053079605\n",
      "Iteration: 3073/10000, Loss: 0.016596876084804535\n",
      "Iteration: 3074/10000, Loss: 0.01502727810293436\n",
      "Iteration: 3075/10000, Loss: 0.02000231295824051\n",
      "Iteration: 3076/10000, Loss: 0.021881960332393646\n",
      "Iteration: 3077/10000, Loss: 0.020757829770445824\n",
      "Iteration: 3078/10000, Loss: 0.019956136122345924\n",
      "Iteration: 3079/10000, Loss: 0.012056124396622181\n",
      "Iteration: 3080/10000, Loss: 0.010343048721551895\n",
      "Iteration: 3081/10000, Loss: 0.012002144008874893\n",
      "Iteration: 3082/10000, Loss: 0.02864990197122097\n",
      "Iteration: 3083/10000, Loss: 0.02135763317346573\n",
      "Iteration: 3084/10000, Loss: 0.013901282101869583\n",
      "Iteration: 3085/10000, Loss: 0.013029467314481735\n",
      "Iteration: 3086/10000, Loss: 0.013821068219840527\n",
      "Iteration: 3087/10000, Loss: 0.02378123812377453\n",
      "Iteration: 3088/10000, Loss: 0.012197263538837433\n",
      "Iteration: 3089/10000, Loss: 0.017209401354193687\n",
      "Iteration: 3090/10000, Loss: 0.017814796417951584\n",
      "Iteration: 3091/10000, Loss: 0.021493783220648766\n",
      "Iteration: 3092/10000, Loss: 0.012369828298687935\n",
      "Iteration: 3093/10000, Loss: 0.018877016380429268\n",
      "Iteration: 3094/10000, Loss: 0.014787545427680016\n",
      "Iteration: 3095/10000, Loss: 0.02213531918823719\n",
      "Iteration: 3096/10000, Loss: 0.01821020245552063\n",
      "Iteration: 3097/10000, Loss: 0.014237196184694767\n",
      "Iteration: 3098/10000, Loss: 0.021070009097456932\n",
      "Iteration: 3099/10000, Loss: 0.022114982828497887\n",
      "Iteration: 3100/10000, Loss: 0.011760637164115906\n",
      "Average test loss:  0.0028\n",
      "Iteration: 3101/10000, Loss: 0.019591793417930603\n",
      "Iteration: 3102/10000, Loss: 0.01381518505513668\n",
      "Iteration: 3103/10000, Loss: 0.019807355478405952\n",
      "Iteration: 3104/10000, Loss: 0.0174859669059515\n",
      "Iteration: 3105/10000, Loss: 0.019116079434752464\n",
      "Iteration: 3106/10000, Loss: 0.01133502647280693\n",
      "Iteration: 3107/10000, Loss: 0.01472433377057314\n",
      "Iteration: 3108/10000, Loss: 0.023271286860108376\n",
      "Iteration: 3109/10000, Loss: 0.01914404146373272\n",
      "Iteration: 3110/10000, Loss: 0.01440446451306343\n",
      "Iteration: 3111/10000, Loss: 0.02835746854543686\n",
      "Iteration: 3112/10000, Loss: 0.01660115458071232\n",
      "Iteration: 3113/10000, Loss: 0.018043335527181625\n",
      "Iteration: 3114/10000, Loss: 0.015320639126002789\n",
      "Iteration: 3115/10000, Loss: 0.020662659779191017\n",
      "Iteration: 3116/10000, Loss: 0.015198232606053352\n",
      "Iteration: 3117/10000, Loss: 0.016078121960163116\n",
      "Iteration: 3118/10000, Loss: 0.01589682511985302\n",
      "Iteration: 3119/10000, Loss: 0.018479445949196815\n",
      "Iteration: 3120/10000, Loss: 0.01826053112745285\n",
      "Iteration: 3121/10000, Loss: 0.014288296923041344\n",
      "Iteration: 3122/10000, Loss: 0.01730399951338768\n",
      "Iteration: 3123/10000, Loss: 0.008844992145895958\n",
      "Iteration: 3124/10000, Loss: 0.01916159689426422\n",
      "Iteration: 3125/10000, Loss: 0.01712705008685589\n",
      "Iteration: 3126/10000, Loss: 0.02154587209224701\n",
      "Iteration: 3127/10000, Loss: 0.013026420958340168\n",
      "Iteration: 3128/10000, Loss: 0.01772957295179367\n",
      "Iteration: 3129/10000, Loss: 0.01384600531309843\n",
      "Iteration: 3130/10000, Loss: 0.016078626736998558\n",
      "Iteration: 3131/10000, Loss: 0.01939958706498146\n",
      "Iteration: 3132/10000, Loss: 0.019605962559580803\n",
      "Iteration: 3133/10000, Loss: 0.016835832968354225\n",
      "Iteration: 3134/10000, Loss: 0.01413311529904604\n",
      "Iteration: 3135/10000, Loss: 0.022900415584445\n",
      "Iteration: 3136/10000, Loss: 0.01980743557214737\n",
      "Iteration: 3137/10000, Loss: 0.01581336185336113\n",
      "Iteration: 3138/10000, Loss: 0.015450961887836456\n",
      "Iteration: 3139/10000, Loss: 0.01568068005144596\n",
      "Iteration: 3140/10000, Loss: 0.02671072445809841\n",
      "Iteration: 3141/10000, Loss: 0.013567525893449783\n",
      "Iteration: 3142/10000, Loss: 0.026363924145698547\n",
      "Iteration: 3143/10000, Loss: 0.02319800667464733\n",
      "Iteration: 3144/10000, Loss: 0.016857052221894264\n",
      "Iteration: 3145/10000, Loss: 0.022128894925117493\n",
      "Iteration: 3146/10000, Loss: 0.025674667209386826\n",
      "Iteration: 3147/10000, Loss: 0.015295487828552723\n",
      "Iteration: 3148/10000, Loss: 0.03312453255057335\n",
      "Iteration: 3149/10000, Loss: 0.026392579078674316\n",
      "Iteration: 3150/10000, Loss: 0.012321646325290203\n",
      "Iteration: 3151/10000, Loss: 0.021106453612446785\n",
      "Iteration: 3152/10000, Loss: 0.013565055094659328\n",
      "Iteration: 3153/10000, Loss: 0.018599674105644226\n",
      "Iteration: 3154/10000, Loss: 0.01933327317237854\n",
      "Iteration: 3155/10000, Loss: 0.020451905205845833\n",
      "Iteration: 3156/10000, Loss: 0.020200597122311592\n",
      "Iteration: 3157/10000, Loss: 0.014485450461506844\n",
      "Iteration: 3158/10000, Loss: 0.009018528275191784\n",
      "Iteration: 3159/10000, Loss: 0.029022404924035072\n",
      "Iteration: 3160/10000, Loss: 0.013539435341954231\n",
      "Iteration: 3161/10000, Loss: 0.017253486439585686\n",
      "Iteration: 3162/10000, Loss: 0.02274463139474392\n",
      "Iteration: 3163/10000, Loss: 0.022468551993370056\n",
      "Iteration: 3164/10000, Loss: 0.017446011304855347\n",
      "Iteration: 3165/10000, Loss: 0.012749943882226944\n",
      "Iteration: 3166/10000, Loss: 0.019287606701254845\n",
      "Iteration: 3167/10000, Loss: 0.015985671430826187\n",
      "Iteration: 3168/10000, Loss: 0.012121440842747688\n",
      "Iteration: 3169/10000, Loss: 0.017604099586606026\n",
      "Iteration: 3170/10000, Loss: 0.02514500729739666\n",
      "Iteration: 3171/10000, Loss: 0.013250580057501793\n",
      "Iteration: 3172/10000, Loss: 0.011651047505438328\n",
      "Iteration: 3173/10000, Loss: 0.02238371968269348\n",
      "Iteration: 3174/10000, Loss: 0.013306585140526295\n",
      "Iteration: 3175/10000, Loss: 0.017184291034936905\n",
      "Iteration: 3176/10000, Loss: 0.0206860713660717\n",
      "Iteration: 3177/10000, Loss: 0.014348906464874744\n",
      "Iteration: 3178/10000, Loss: 0.01212681457400322\n",
      "Iteration: 3179/10000, Loss: 0.017351631075143814\n",
      "Iteration: 3180/10000, Loss: 0.020009005442261696\n",
      "Iteration: 3181/10000, Loss: 0.016233839094638824\n",
      "Iteration: 3182/10000, Loss: 0.01973261684179306\n",
      "Iteration: 3183/10000, Loss: 0.019993679597973824\n",
      "Iteration: 3184/10000, Loss: 0.01971384510397911\n",
      "Iteration: 3185/10000, Loss: 0.013958479277789593\n",
      "Iteration: 3186/10000, Loss: 0.01572507806122303\n",
      "Iteration: 3187/10000, Loss: 0.024823185056447983\n",
      "Iteration: 3188/10000, Loss: 0.012229233048856258\n",
      "Iteration: 3189/10000, Loss: 0.013227480463683605\n",
      "Iteration: 3190/10000, Loss: 0.01944795437157154\n",
      "Iteration: 3191/10000, Loss: 0.015946753323078156\n",
      "Iteration: 3192/10000, Loss: 0.01179424487054348\n",
      "Iteration: 3193/10000, Loss: 0.018533460795879364\n",
      "Iteration: 3194/10000, Loss: 0.01629026234149933\n",
      "Iteration: 3195/10000, Loss: 0.023705700412392616\n",
      "Iteration: 3196/10000, Loss: 0.010842940770089626\n",
      "Iteration: 3197/10000, Loss: 0.016675172373652458\n",
      "Iteration: 3198/10000, Loss: 0.014061721973121166\n",
      "Iteration: 3199/10000, Loss: 0.019325148314237595\n",
      "Iteration: 3200/10000, Loss: 0.020529072731733322\n",
      "Average test loss:  0.0023\n",
      "Iteration: 3201/10000, Loss: 0.016792237758636475\n",
      "Iteration: 3202/10000, Loss: 0.017581071704626083\n",
      "Iteration: 3203/10000, Loss: 0.022582242265343666\n",
      "Iteration: 3204/10000, Loss: 0.016266101971268654\n",
      "Iteration: 3205/10000, Loss: 0.015432863496243954\n",
      "Iteration: 3206/10000, Loss: 0.01893213763833046\n",
      "Iteration: 3207/10000, Loss: 0.012808213010430336\n",
      "Iteration: 3208/10000, Loss: 0.010771799832582474\n",
      "Iteration: 3209/10000, Loss: 0.01787302829325199\n",
      "Iteration: 3210/10000, Loss: 0.017801083624362946\n",
      "Iteration: 3211/10000, Loss: 0.020015597343444824\n",
      "Iteration: 3212/10000, Loss: 0.014611409045755863\n",
      "Iteration: 3213/10000, Loss: 0.014586164616048336\n",
      "Iteration: 3214/10000, Loss: 0.010200676508247852\n",
      "Iteration: 3215/10000, Loss: 0.01749877817928791\n",
      "Iteration: 3216/10000, Loss: 0.016752170398831367\n",
      "Iteration: 3217/10000, Loss: 0.012898552231490612\n",
      "Iteration: 3218/10000, Loss: 0.015389347448945045\n",
      "Iteration: 3219/10000, Loss: 0.014728006906807423\n",
      "Iteration: 3220/10000, Loss: 0.021472647786140442\n",
      "Iteration: 3221/10000, Loss: 0.012553221546113491\n",
      "Iteration: 3222/10000, Loss: 0.031341470777988434\n",
      "Iteration: 3223/10000, Loss: 0.01544133946299553\n",
      "Iteration: 3224/10000, Loss: 0.014382809400558472\n",
      "Iteration: 3225/10000, Loss: 0.0228187944740057\n",
      "Iteration: 3226/10000, Loss: 0.020971909165382385\n",
      "Iteration: 3227/10000, Loss: 0.02462051622569561\n",
      "Iteration: 3228/10000, Loss: 0.012400074861943722\n",
      "Iteration: 3229/10000, Loss: 0.013731410726904869\n",
      "Iteration: 3230/10000, Loss: 0.021160157397389412\n",
      "Iteration: 3231/10000, Loss: 0.015426495112478733\n",
      "Iteration: 3232/10000, Loss: 0.015899239107966423\n",
      "Iteration: 3233/10000, Loss: 0.014575432986021042\n",
      "Iteration: 3234/10000, Loss: 0.019494783133268356\n",
      "Iteration: 3235/10000, Loss: 0.01839851588010788\n",
      "Iteration: 3236/10000, Loss: 0.020747413858771324\n",
      "Iteration: 3237/10000, Loss: 0.01437094435095787\n",
      "Iteration: 3238/10000, Loss: 0.014016359113156796\n",
      "Iteration: 3239/10000, Loss: 0.020897937938570976\n",
      "Iteration: 3240/10000, Loss: 0.012181821279227734\n",
      "Iteration: 3241/10000, Loss: 0.013948670588433743\n",
      "Iteration: 3242/10000, Loss: 0.016239706426858902\n",
      "Iteration: 3243/10000, Loss: 0.008804942481219769\n",
      "Iteration: 3244/10000, Loss: 0.021986857056617737\n",
      "Iteration: 3245/10000, Loss: 0.019171366468071938\n",
      "Iteration: 3246/10000, Loss: 0.015242482535541058\n",
      "Iteration: 3247/10000, Loss: 0.010633370839059353\n",
      "Iteration: 3248/10000, Loss: 0.01999889314174652\n",
      "Iteration: 3249/10000, Loss: 0.01606822945177555\n",
      "Iteration: 3250/10000, Loss: 0.017473045736551285\n",
      "Iteration: 3251/10000, Loss: 0.020997336134314537\n",
      "Iteration: 3252/10000, Loss: 0.02056017704308033\n",
      "Iteration: 3253/10000, Loss: 0.01628093048930168\n",
      "Iteration: 3254/10000, Loss: 0.010098686441779137\n",
      "Iteration: 3255/10000, Loss: 0.02052156627178192\n",
      "Iteration: 3256/10000, Loss: 0.016057489439845085\n",
      "Iteration: 3257/10000, Loss: 0.02235042303800583\n",
      "Iteration: 3258/10000, Loss: 0.02057129330933094\n",
      "Iteration: 3259/10000, Loss: 0.017438188195228577\n",
      "Iteration: 3260/10000, Loss: 0.012997942976653576\n",
      "Iteration: 3261/10000, Loss: 0.012944439426064491\n",
      "Iteration: 3262/10000, Loss: 0.023730704560875893\n",
      "Iteration: 3263/10000, Loss: 0.021651094779372215\n",
      "Iteration: 3264/10000, Loss: 0.02406882867217064\n",
      "Iteration: 3265/10000, Loss: 0.019992997869849205\n",
      "Iteration: 3266/10000, Loss: 0.010582763701677322\n",
      "Iteration: 3267/10000, Loss: 0.018183523789048195\n",
      "Iteration: 3268/10000, Loss: 0.016411224380135536\n",
      "Iteration: 3269/10000, Loss: 0.014302116818726063\n",
      "Iteration: 3270/10000, Loss: 0.02270631119608879\n",
      "Iteration: 3271/10000, Loss: 0.018334567546844482\n",
      "Iteration: 3272/10000, Loss: 0.02217881754040718\n",
      "Iteration: 3273/10000, Loss: 0.01778232306241989\n",
      "Iteration: 3274/10000, Loss: 0.019998153671622276\n",
      "Iteration: 3275/10000, Loss: 0.015266316942870617\n",
      "Iteration: 3276/10000, Loss: 0.015055626630783081\n",
      "Iteration: 3277/10000, Loss: 0.020137637853622437\n",
      "Iteration: 3278/10000, Loss: 0.016708021983504295\n",
      "Iteration: 3279/10000, Loss: 0.018219145014882088\n",
      "Iteration: 3280/10000, Loss: 0.016342153772711754\n",
      "Iteration: 3281/10000, Loss: 0.010598682798445225\n",
      "Iteration: 3282/10000, Loss: 0.019979938864707947\n",
      "Iteration: 3283/10000, Loss: 0.008643217384815216\n",
      "Iteration: 3284/10000, Loss: 0.014598929323256016\n",
      "Iteration: 3285/10000, Loss: 0.015281510539352894\n",
      "Iteration: 3286/10000, Loss: 0.016282983124256134\n",
      "Iteration: 3287/10000, Loss: 0.016098132357001305\n",
      "Iteration: 3288/10000, Loss: 0.014007152989506721\n",
      "Iteration: 3289/10000, Loss: 0.019766274839639664\n",
      "Iteration: 3290/10000, Loss: 0.010261284187436104\n",
      "Iteration: 3291/10000, Loss: 0.018469953909516335\n",
      "Iteration: 3292/10000, Loss: 0.019803665578365326\n",
      "Iteration: 3293/10000, Loss: 0.018425310030579567\n",
      "Iteration: 3294/10000, Loss: 0.021138740703463554\n",
      "Iteration: 3295/10000, Loss: 0.01882215030491352\n",
      "Iteration: 3296/10000, Loss: 0.02323552407324314\n",
      "Iteration: 3297/10000, Loss: 0.01477621216326952\n",
      "Iteration: 3298/10000, Loss: 0.016933327540755272\n",
      "Iteration: 3299/10000, Loss: 0.02330181375145912\n",
      "Iteration: 3300/10000, Loss: 0.014929722063243389\n",
      "Average test loss:  0.0030\n",
      "Iteration: 3301/10000, Loss: 0.022925108671188354\n",
      "Iteration: 3302/10000, Loss: 0.015111077576875687\n",
      "Iteration: 3303/10000, Loss: 0.018402498215436935\n",
      "Iteration: 3304/10000, Loss: 0.016070103272795677\n",
      "Iteration: 3305/10000, Loss: 0.015394025482237339\n",
      "Iteration: 3306/10000, Loss: 0.019454972818493843\n",
      "Iteration: 3307/10000, Loss: 0.02085173688828945\n",
      "Iteration: 3308/10000, Loss: 0.014185495674610138\n",
      "Iteration: 3309/10000, Loss: 0.019475780427455902\n",
      "Iteration: 3310/10000, Loss: 0.008921352215111256\n",
      "Iteration: 3311/10000, Loss: 0.018321363255381584\n",
      "Iteration: 3312/10000, Loss: 0.013932906091213226\n",
      "Iteration: 3313/10000, Loss: 0.01690615713596344\n",
      "Iteration: 3314/10000, Loss: 0.02227259986102581\n",
      "Iteration: 3315/10000, Loss: 0.01981106586754322\n",
      "Iteration: 3316/10000, Loss: 0.01602281630039215\n",
      "Iteration: 3317/10000, Loss: 0.012726250104606152\n",
      "Iteration: 3318/10000, Loss: 0.01578906737267971\n",
      "Iteration: 3319/10000, Loss: 0.018903756514191628\n",
      "Iteration: 3320/10000, Loss: 0.0245648305863142\n",
      "Iteration: 3321/10000, Loss: 0.020448416471481323\n",
      "Iteration: 3322/10000, Loss: 0.011801321059465408\n",
      "Iteration: 3323/10000, Loss: 0.011320036835968494\n",
      "Iteration: 3324/10000, Loss: 0.013879068195819855\n",
      "Iteration: 3325/10000, Loss: 0.019837163388729095\n",
      "Iteration: 3326/10000, Loss: 0.019320493564009666\n",
      "Iteration: 3327/10000, Loss: 0.02224835939705372\n",
      "Iteration: 3328/10000, Loss: 0.014572986401617527\n",
      "Iteration: 3329/10000, Loss: 0.01747700199484825\n",
      "Iteration: 3330/10000, Loss: 0.016814090311527252\n",
      "Iteration: 3331/10000, Loss: 0.017431270331144333\n",
      "Iteration: 3332/10000, Loss: 0.011166667565703392\n",
      "Iteration: 3333/10000, Loss: 0.013336628675460815\n",
      "Iteration: 3334/10000, Loss: 0.014413085766136646\n",
      "Iteration: 3335/10000, Loss: 0.014312817715108395\n",
      "Iteration: 3336/10000, Loss: 0.015065341256558895\n",
      "Iteration: 3337/10000, Loss: 0.014793263748288155\n",
      "Iteration: 3338/10000, Loss: 0.01225886307656765\n",
      "Iteration: 3339/10000, Loss: 0.010896936058998108\n",
      "Iteration: 3340/10000, Loss: 0.019280776381492615\n",
      "Iteration: 3341/10000, Loss: 0.017430437728762627\n",
      "Iteration: 3342/10000, Loss: 0.021156469359993935\n",
      "Iteration: 3343/10000, Loss: 0.012510731816291809\n",
      "Iteration: 3344/10000, Loss: 0.01698926091194153\n",
      "Iteration: 3345/10000, Loss: 0.01664617471396923\n",
      "Iteration: 3346/10000, Loss: 0.012976346537470818\n",
      "Iteration: 3347/10000, Loss: 0.014491545036435127\n",
      "Iteration: 3348/10000, Loss: 0.018780384212732315\n",
      "Iteration: 3349/10000, Loss: 0.014776007272303104\n",
      "Iteration: 3350/10000, Loss: 0.010213549248874187\n",
      "Iteration: 3351/10000, Loss: 0.010411747731268406\n",
      "Iteration: 3352/10000, Loss: 0.010829836130142212\n",
      "Iteration: 3353/10000, Loss: 0.01018303632736206\n",
      "Iteration: 3354/10000, Loss: 0.01950216107070446\n",
      "Iteration: 3355/10000, Loss: 0.014312964864075184\n",
      "Iteration: 3356/10000, Loss: 0.022286994382739067\n",
      "Iteration: 3357/10000, Loss: 0.01996423304080963\n",
      "Iteration: 3358/10000, Loss: 0.01447849441319704\n",
      "Iteration: 3359/10000, Loss: 0.02367139421403408\n",
      "Iteration: 3360/10000, Loss: 0.022532153874635696\n",
      "Iteration: 3361/10000, Loss: 0.012654448859393597\n",
      "Iteration: 3362/10000, Loss: 0.01875687576830387\n",
      "Iteration: 3363/10000, Loss: 0.01972532458603382\n",
      "Iteration: 3364/10000, Loss: 0.020371124148368835\n",
      "Iteration: 3365/10000, Loss: 0.019737763330340385\n",
      "Iteration: 3366/10000, Loss: 0.011111226864159107\n",
      "Iteration: 3367/10000, Loss: 0.010496614500880241\n",
      "Iteration: 3368/10000, Loss: 0.012358564883470535\n",
      "Iteration: 3369/10000, Loss: 0.01868397183716297\n",
      "Iteration: 3370/10000, Loss: 0.018849583342671394\n",
      "Iteration: 3371/10000, Loss: 0.02675088867545128\n",
      "Iteration: 3372/10000, Loss: 0.009671295993030071\n",
      "Iteration: 3373/10000, Loss: 0.01648053713142872\n",
      "Iteration: 3374/10000, Loss: 0.018574481830000877\n",
      "Iteration: 3375/10000, Loss: 0.0163500364869833\n",
      "Iteration: 3376/10000, Loss: 0.020159509032964706\n",
      "Iteration: 3377/10000, Loss: 0.015268716961145401\n",
      "Iteration: 3378/10000, Loss: 0.018779611214995384\n",
      "Iteration: 3379/10000, Loss: 0.014498348347842693\n",
      "Iteration: 3380/10000, Loss: 0.013283789157867432\n",
      "Iteration: 3381/10000, Loss: 0.012437422759830952\n",
      "Iteration: 3382/10000, Loss: 0.018147220835089684\n",
      "Iteration: 3383/10000, Loss: 0.015026300214231014\n",
      "Iteration: 3384/10000, Loss: 0.017462780699133873\n",
      "Iteration: 3385/10000, Loss: 0.018398519605398178\n",
      "Iteration: 3386/10000, Loss: 0.009500251151621342\n",
      "Iteration: 3387/10000, Loss: 0.012713054195046425\n",
      "Iteration: 3388/10000, Loss: 0.014853683300316334\n",
      "Iteration: 3389/10000, Loss: 0.016892461106181145\n",
      "Iteration: 3390/10000, Loss: 0.01387864537537098\n",
      "Iteration: 3391/10000, Loss: 0.01386521477252245\n",
      "Iteration: 3392/10000, Loss: 0.011698047630488873\n",
      "Iteration: 3393/10000, Loss: 0.024577638134360313\n",
      "Iteration: 3394/10000, Loss: 0.01517377607524395\n",
      "Iteration: 3395/10000, Loss: 0.011249658651649952\n",
      "Iteration: 3396/10000, Loss: 0.020271779969334602\n",
      "Iteration: 3397/10000, Loss: 0.01066575013101101\n",
      "Iteration: 3398/10000, Loss: 0.01918741874396801\n",
      "Iteration: 3399/10000, Loss: 0.018026096746325493\n",
      "Iteration: 3400/10000, Loss: 0.015399501658976078\n",
      "Average test loss:  0.0025\n",
      "Iteration: 3401/10000, Loss: 0.020564666017889977\n",
      "Iteration: 3402/10000, Loss: 0.013357813470065594\n",
      "Iteration: 3403/10000, Loss: 0.019891802221536636\n",
      "Iteration: 3404/10000, Loss: 0.02210492081940174\n",
      "Iteration: 3405/10000, Loss: 0.014637826010584831\n",
      "Iteration: 3406/10000, Loss: 0.014239239506423473\n",
      "Iteration: 3407/10000, Loss: 0.01608288288116455\n",
      "Iteration: 3408/10000, Loss: 0.01955089531838894\n",
      "Iteration: 3409/10000, Loss: 0.020279843360185623\n",
      "Iteration: 3410/10000, Loss: 0.020039141178131104\n",
      "Iteration: 3411/10000, Loss: 0.010835347697138786\n",
      "Iteration: 3412/10000, Loss: 0.010715783573687077\n",
      "Iteration: 3413/10000, Loss: 0.01568363793194294\n",
      "Iteration: 3414/10000, Loss: 0.013964452780783176\n",
      "Iteration: 3415/10000, Loss: 0.013806678354740143\n",
      "Iteration: 3416/10000, Loss: 0.01674065738916397\n",
      "Iteration: 3417/10000, Loss: 0.02124388888478279\n",
      "Iteration: 3418/10000, Loss: 0.023523373529314995\n",
      "Iteration: 3419/10000, Loss: 0.014096870087087154\n",
      "Iteration: 3420/10000, Loss: 0.02076641470193863\n",
      "Iteration: 3421/10000, Loss: 0.01816888526082039\n",
      "Iteration: 3422/10000, Loss: 0.019698267802596092\n",
      "Iteration: 3423/10000, Loss: 0.019764481112360954\n",
      "Iteration: 3424/10000, Loss: 0.01223985105752945\n",
      "Iteration: 3425/10000, Loss: 0.01515032909810543\n",
      "Iteration: 3426/10000, Loss: 0.027201766148209572\n",
      "Iteration: 3427/10000, Loss: 0.01934461109340191\n",
      "Iteration: 3428/10000, Loss: 0.02178903855383396\n",
      "Iteration: 3429/10000, Loss: 0.016560500487685204\n",
      "Iteration: 3430/10000, Loss: 0.019939856603741646\n",
      "Iteration: 3431/10000, Loss: 0.011374481953680515\n",
      "Iteration: 3432/10000, Loss: 0.017029771581292152\n",
      "Iteration: 3433/10000, Loss: 0.01790512353181839\n",
      "Iteration: 3434/10000, Loss: 0.009372025728225708\n",
      "Iteration: 3435/10000, Loss: 0.016652900725603104\n",
      "Iteration: 3436/10000, Loss: 0.009992044419050217\n",
      "Iteration: 3437/10000, Loss: 0.019133562222123146\n",
      "Iteration: 3438/10000, Loss: 0.012493148446083069\n",
      "Iteration: 3439/10000, Loss: 0.020500410348176956\n",
      "Iteration: 3440/10000, Loss: 0.01315589901059866\n",
      "Iteration: 3441/10000, Loss: 0.01149069145321846\n",
      "Iteration: 3442/10000, Loss: 0.02193804457783699\n",
      "Iteration: 3443/10000, Loss: 0.009160800836980343\n",
      "Iteration: 3444/10000, Loss: 0.021595796570181847\n",
      "Iteration: 3445/10000, Loss: 0.01961434818804264\n",
      "Iteration: 3446/10000, Loss: 0.022378593683242798\n",
      "Iteration: 3447/10000, Loss: 0.015444151125848293\n",
      "Iteration: 3448/10000, Loss: 0.016554556787014008\n",
      "Iteration: 3449/10000, Loss: 0.015229959040880203\n",
      "Iteration: 3450/10000, Loss: 0.015461564995348454\n",
      "Iteration: 3451/10000, Loss: 0.019955895841121674\n",
      "Iteration: 3452/10000, Loss: 0.01702733524143696\n",
      "Iteration: 3453/10000, Loss: 0.012840577401220798\n",
      "Iteration: 3454/10000, Loss: 0.020574718713760376\n",
      "Iteration: 3455/10000, Loss: 0.01795058511197567\n",
      "Iteration: 3456/10000, Loss: 0.013764332979917526\n",
      "Iteration: 3457/10000, Loss: 0.013263438828289509\n",
      "Iteration: 3458/10000, Loss: 0.014944346621632576\n",
      "Iteration: 3459/10000, Loss: 0.023447340354323387\n",
      "Iteration: 3460/10000, Loss: 0.020778976380825043\n",
      "Iteration: 3461/10000, Loss: 0.012857072986662388\n",
      "Iteration: 3462/10000, Loss: 0.019212966784834862\n",
      "Iteration: 3463/10000, Loss: 0.008438920602202415\n",
      "Iteration: 3464/10000, Loss: 0.022866344079375267\n",
      "Iteration: 3465/10000, Loss: 0.022288937121629715\n",
      "Iteration: 3466/10000, Loss: 0.013149280101060867\n",
      "Iteration: 3467/10000, Loss: 0.0207077469676733\n",
      "Iteration: 3468/10000, Loss: 0.019000958651304245\n",
      "Iteration: 3469/10000, Loss: 0.019344406202435493\n",
      "Iteration: 3470/10000, Loss: 0.019856732338666916\n",
      "Iteration: 3471/10000, Loss: 0.022381838411092758\n",
      "Iteration: 3472/10000, Loss: 0.014191780239343643\n",
      "Iteration: 3473/10000, Loss: 0.01396123692393303\n",
      "Iteration: 3474/10000, Loss: 0.016938405111432076\n",
      "Iteration: 3475/10000, Loss: 0.022279830649495125\n",
      "Iteration: 3476/10000, Loss: 0.016292857006192207\n",
      "Iteration: 3477/10000, Loss: 0.012478812597692013\n",
      "Iteration: 3478/10000, Loss: 0.013376977294683456\n",
      "Iteration: 3479/10000, Loss: 0.015986982733011246\n",
      "Iteration: 3480/10000, Loss: 0.008718360215425491\n",
      "Iteration: 3481/10000, Loss: 0.011960220523178577\n",
      "Iteration: 3482/10000, Loss: 0.012753323651850224\n",
      "Iteration: 3483/10000, Loss: 0.02073661796748638\n",
      "Iteration: 3484/10000, Loss: 0.017178034409880638\n",
      "Iteration: 3485/10000, Loss: 0.019586019217967987\n",
      "Iteration: 3486/10000, Loss: 0.016032524406909943\n",
      "Iteration: 3487/10000, Loss: 0.015737393870949745\n",
      "Iteration: 3488/10000, Loss: 0.016869189217686653\n",
      "Iteration: 3489/10000, Loss: 0.016974613070487976\n",
      "Iteration: 3490/10000, Loss: 0.020017817616462708\n",
      "Iteration: 3491/10000, Loss: 0.014935041777789593\n",
      "Iteration: 3492/10000, Loss: 0.01564285345375538\n",
      "Iteration: 3493/10000, Loss: 0.011839022859930992\n",
      "Iteration: 3494/10000, Loss: 0.018096957355737686\n",
      "Iteration: 3495/10000, Loss: 0.01947336457669735\n",
      "Iteration: 3496/10000, Loss: 0.016774356365203857\n",
      "Iteration: 3497/10000, Loss: 0.018963659182190895\n",
      "Iteration: 3498/10000, Loss: 0.01860210858285427\n",
      "Iteration: 3499/10000, Loss: 0.017078781500458717\n",
      "Iteration: 3500/10000, Loss: 0.017480451613664627\n",
      "Average test loss:  0.0018\n",
      "Iteration: 3501/10000, Loss: 0.017508920282125473\n",
      "Iteration: 3502/10000, Loss: 0.016497930511832237\n",
      "Iteration: 3503/10000, Loss: 0.010623778216540813\n",
      "Iteration: 3504/10000, Loss: 0.0200682133436203\n",
      "Iteration: 3505/10000, Loss: 0.01654435507953167\n",
      "Iteration: 3506/10000, Loss: 0.014337308704853058\n",
      "Iteration: 3507/10000, Loss: 0.012023111805319786\n",
      "Iteration: 3508/10000, Loss: 0.022277379408478737\n",
      "Iteration: 3509/10000, Loss: 0.013145455159246922\n",
      "Iteration: 3510/10000, Loss: 0.0189516581594944\n",
      "Iteration: 3511/10000, Loss: 0.013042396865785122\n",
      "Iteration: 3512/10000, Loss: 0.019401874393224716\n",
      "Iteration: 3513/10000, Loss: 0.012001993134617805\n",
      "Iteration: 3514/10000, Loss: 0.017101554200053215\n",
      "Iteration: 3515/10000, Loss: 0.015829887241125107\n",
      "Iteration: 3516/10000, Loss: 0.018689552322030067\n",
      "Iteration: 3517/10000, Loss: 0.01117416936904192\n",
      "Iteration: 3518/10000, Loss: 0.016880681738257408\n",
      "Iteration: 3519/10000, Loss: 0.02077748440206051\n",
      "Iteration: 3520/10000, Loss: 0.013041478581726551\n",
      "Iteration: 3521/10000, Loss: 0.017496977001428604\n",
      "Iteration: 3522/10000, Loss: 0.01683647930622101\n",
      "Iteration: 3523/10000, Loss: 0.019314872100949287\n",
      "Iteration: 3524/10000, Loss: 0.01809730753302574\n",
      "Iteration: 3525/10000, Loss: 0.01352210994809866\n",
      "Iteration: 3526/10000, Loss: 0.022255102172493935\n",
      "Iteration: 3527/10000, Loss: 0.018611904233694077\n",
      "Iteration: 3528/10000, Loss: 0.022432807832956314\n",
      "Iteration: 3529/10000, Loss: 0.015198961831629276\n",
      "Iteration: 3530/10000, Loss: 0.018947025761008263\n",
      "Iteration: 3531/10000, Loss: 0.013437648303806782\n",
      "Iteration: 3532/10000, Loss: 0.019058428704738617\n",
      "Iteration: 3533/10000, Loss: 0.01675874926149845\n",
      "Iteration: 3534/10000, Loss: 0.010791035369038582\n",
      "Iteration: 3535/10000, Loss: 0.01330939494073391\n",
      "Iteration: 3536/10000, Loss: 0.027465250343084335\n",
      "Iteration: 3537/10000, Loss: 0.014686047099530697\n",
      "Iteration: 3538/10000, Loss: 0.01581094041466713\n",
      "Iteration: 3539/10000, Loss: 0.012868974357843399\n",
      "Iteration: 3540/10000, Loss: 0.01208662148565054\n",
      "Iteration: 3541/10000, Loss: 0.01375060249119997\n",
      "Iteration: 3542/10000, Loss: 0.01700870878994465\n",
      "Iteration: 3543/10000, Loss: 0.017538486048579216\n",
      "Iteration: 3544/10000, Loss: 0.01391755510121584\n",
      "Iteration: 3545/10000, Loss: 0.02044876478612423\n",
      "Iteration: 3546/10000, Loss: 0.013084998354315758\n",
      "Iteration: 3547/10000, Loss: 0.01738293468952179\n",
      "Iteration: 3548/10000, Loss: 0.015101145021617413\n",
      "Iteration: 3549/10000, Loss: 0.021569713950157166\n",
      "Iteration: 3550/10000, Loss: 0.02219375967979431\n",
      "Iteration: 3551/10000, Loss: 0.01735447347164154\n",
      "Iteration: 3552/10000, Loss: 0.014961437322199345\n",
      "Iteration: 3553/10000, Loss: 0.01462358795106411\n",
      "Iteration: 3554/10000, Loss: 0.01164955273270607\n",
      "Iteration: 3555/10000, Loss: 0.015516581945121288\n",
      "Iteration: 3556/10000, Loss: 0.014842460863292217\n",
      "Iteration: 3557/10000, Loss: 0.01766117475926876\n",
      "Iteration: 3558/10000, Loss: 0.02311917208135128\n",
      "Iteration: 3559/10000, Loss: 0.022109387442469597\n",
      "Iteration: 3560/10000, Loss: 0.018757270649075508\n",
      "Iteration: 3561/10000, Loss: 0.017966443672776222\n",
      "Iteration: 3562/10000, Loss: 0.011961990036070347\n",
      "Iteration: 3563/10000, Loss: 0.017184169963002205\n",
      "Iteration: 3564/10000, Loss: 0.012363088317215443\n",
      "Iteration: 3565/10000, Loss: 0.009131678380072117\n",
      "Iteration: 3566/10000, Loss: 0.012965680100023746\n",
      "Iteration: 3567/10000, Loss: 0.01581643708050251\n",
      "Iteration: 3568/10000, Loss: 0.013774177059531212\n",
      "Iteration: 3569/10000, Loss: 0.01916537992656231\n",
      "Iteration: 3570/10000, Loss: 0.012912330217659473\n",
      "Iteration: 3571/10000, Loss: 0.01096100453287363\n",
      "Iteration: 3572/10000, Loss: 0.015230361372232437\n",
      "Iteration: 3573/10000, Loss: 0.020458899438381195\n",
      "Iteration: 3574/10000, Loss: 0.021486051380634308\n",
      "Iteration: 3575/10000, Loss: 0.017778975889086723\n",
      "Iteration: 3576/10000, Loss: 0.01382994931191206\n",
      "Iteration: 3577/10000, Loss: 0.02023543231189251\n",
      "Iteration: 3578/10000, Loss: 0.013997661881148815\n",
      "Iteration: 3579/10000, Loss: 0.012115119025111198\n",
      "Iteration: 3580/10000, Loss: 0.012234189547598362\n",
      "Iteration: 3581/10000, Loss: 0.023570410907268524\n",
      "Iteration: 3582/10000, Loss: 0.01510039996355772\n",
      "Iteration: 3583/10000, Loss: 0.022115793079137802\n",
      "Iteration: 3584/10000, Loss: 0.01677227020263672\n",
      "Iteration: 3585/10000, Loss: 0.016460200771689415\n",
      "Iteration: 3586/10000, Loss: 0.011929797008633614\n",
      "Iteration: 3587/10000, Loss: 0.017010264098644257\n",
      "Iteration: 3588/10000, Loss: 0.010979273356497288\n",
      "Iteration: 3589/10000, Loss: 0.012492294423282146\n",
      "Iteration: 3590/10000, Loss: 0.014171737246215343\n",
      "Iteration: 3591/10000, Loss: 0.016735276207327843\n",
      "Iteration: 3592/10000, Loss: 0.01707855798304081\n",
      "Iteration: 3593/10000, Loss: 0.014379099942743778\n",
      "Iteration: 3594/10000, Loss: 0.01204778254032135\n",
      "Iteration: 3595/10000, Loss: 0.01929660327732563\n",
      "Iteration: 3596/10000, Loss: 0.013191194273531437\n",
      "Iteration: 3597/10000, Loss: 0.010283982381224632\n",
      "Iteration: 3598/10000, Loss: 0.019061332568526268\n",
      "Iteration: 3599/10000, Loss: 0.017947161570191383\n",
      "Iteration: 3600/10000, Loss: 0.024882741272449493\n",
      "Average test loss:  0.0028\n",
      "Iteration: 3601/10000, Loss: 0.01121734082698822\n",
      "Iteration: 3602/10000, Loss: 0.017888901755213737\n",
      "Iteration: 3603/10000, Loss: 0.013234874233603477\n",
      "Iteration: 3604/10000, Loss: 0.013801627792418003\n",
      "Iteration: 3605/10000, Loss: 0.013912552036345005\n",
      "Iteration: 3606/10000, Loss: 0.029393836855888367\n",
      "Iteration: 3607/10000, Loss: 0.010385447181761265\n",
      "Iteration: 3608/10000, Loss: 0.0219027791172266\n",
      "Iteration: 3609/10000, Loss: 0.010691630654036999\n",
      "Iteration: 3610/10000, Loss: 0.008378689177334309\n",
      "Iteration: 3611/10000, Loss: 0.018252650275826454\n",
      "Iteration: 3612/10000, Loss: 0.01644221879541874\n",
      "Iteration: 3613/10000, Loss: 0.01752632111310959\n",
      "Iteration: 3614/10000, Loss: 0.013781516812741756\n",
      "Iteration: 3615/10000, Loss: 0.013655313290655613\n",
      "Iteration: 3616/10000, Loss: 0.019422214478254318\n",
      "Iteration: 3617/10000, Loss: 0.019074635580182076\n",
      "Iteration: 3618/10000, Loss: 0.01164423767477274\n",
      "Iteration: 3619/10000, Loss: 0.014730752445757389\n",
      "Iteration: 3620/10000, Loss: 0.014257376082241535\n",
      "Iteration: 3621/10000, Loss: 0.011863276362419128\n",
      "Iteration: 3622/10000, Loss: 0.01539542805403471\n",
      "Iteration: 3623/10000, Loss: 0.01845650188624859\n",
      "Iteration: 3624/10000, Loss: 0.022698746994137764\n",
      "Iteration: 3625/10000, Loss: 0.009435692802071571\n",
      "Iteration: 3626/10000, Loss: 0.016465310007333755\n",
      "Iteration: 3627/10000, Loss: 0.022728504613041878\n",
      "Iteration: 3628/10000, Loss: 0.01659933105111122\n",
      "Iteration: 3629/10000, Loss: 0.01949702575802803\n",
      "Iteration: 3630/10000, Loss: 0.013280514627695084\n",
      "Iteration: 3631/10000, Loss: 0.016106901690363884\n",
      "Iteration: 3632/10000, Loss: 0.012640470638871193\n",
      "Iteration: 3633/10000, Loss: 0.01310482807457447\n",
      "Iteration: 3634/10000, Loss: 0.019883323460817337\n",
      "Iteration: 3635/10000, Loss: 0.024685045704245567\n",
      "Iteration: 3636/10000, Loss: 0.01493127178400755\n",
      "Iteration: 3637/10000, Loss: 0.016516586765646935\n",
      "Iteration: 3638/10000, Loss: 0.014050490222871304\n",
      "Iteration: 3639/10000, Loss: 0.01834714598953724\n",
      "Iteration: 3640/10000, Loss: 0.015382234007120132\n",
      "Iteration: 3641/10000, Loss: 0.02245243452489376\n",
      "Iteration: 3642/10000, Loss: 0.012823855504393578\n",
      "Iteration: 3643/10000, Loss: 0.020237287506461143\n",
      "Iteration: 3644/10000, Loss: 0.014523145742714405\n",
      "Iteration: 3645/10000, Loss: 0.014330980367958546\n",
      "Iteration: 3646/10000, Loss: 0.010595283471047878\n",
      "Iteration: 3647/10000, Loss: 0.025148527696728706\n",
      "Iteration: 3648/10000, Loss: 0.014673301950097084\n",
      "Iteration: 3649/10000, Loss: 0.016123658046126366\n",
      "Iteration: 3650/10000, Loss: 0.013328349217772484\n",
      "Iteration: 3651/10000, Loss: 0.014069636352360249\n",
      "Iteration: 3652/10000, Loss: 0.012911578640341759\n",
      "Iteration: 3653/10000, Loss: 0.017092939466238022\n",
      "Iteration: 3654/10000, Loss: 0.020347151905298233\n",
      "Iteration: 3655/10000, Loss: 0.016777288168668747\n",
      "Iteration: 3656/10000, Loss: 0.012535208836197853\n",
      "Iteration: 3657/10000, Loss: 0.01669188030064106\n",
      "Iteration: 3658/10000, Loss: 0.016271840780973434\n",
      "Iteration: 3659/10000, Loss: 0.015532626770436764\n",
      "Iteration: 3660/10000, Loss: 0.013077573850750923\n",
      "Iteration: 3661/10000, Loss: 0.013322971761226654\n",
      "Iteration: 3662/10000, Loss: 0.023126253858208656\n",
      "Iteration: 3663/10000, Loss: 0.01879720203578472\n",
      "Iteration: 3664/10000, Loss: 0.02025633119046688\n",
      "Iteration: 3665/10000, Loss: 0.018742624670267105\n",
      "Iteration: 3666/10000, Loss: 0.020736198872327805\n",
      "Iteration: 3667/10000, Loss: 0.014828641898930073\n",
      "Iteration: 3668/10000, Loss: 0.014214130118489265\n",
      "Iteration: 3669/10000, Loss: 0.012962657026946545\n",
      "Iteration: 3670/10000, Loss: 0.014824544079601765\n",
      "Iteration: 3671/10000, Loss: 0.01484926138073206\n",
      "Iteration: 3672/10000, Loss: 0.00880569126456976\n",
      "Iteration: 3673/10000, Loss: 0.017355043441057205\n",
      "Iteration: 3674/10000, Loss: 0.017195750027894974\n",
      "Iteration: 3675/10000, Loss: 0.015567927621304989\n",
      "Iteration: 3676/10000, Loss: 0.0111626535654068\n",
      "Iteration: 3677/10000, Loss: 0.00942413043230772\n",
      "Iteration: 3678/10000, Loss: 0.009083068929612637\n",
      "Iteration: 3679/10000, Loss: 0.01969323121011257\n",
      "Iteration: 3680/10000, Loss: 0.015052464790642262\n",
      "Iteration: 3681/10000, Loss: 0.01738765835762024\n",
      "Iteration: 3682/10000, Loss: 0.014631387777626514\n",
      "Iteration: 3683/10000, Loss: 0.01366342417895794\n",
      "Iteration: 3684/10000, Loss: 0.014938182197511196\n",
      "Iteration: 3685/10000, Loss: 0.012794543989002705\n",
      "Iteration: 3686/10000, Loss: 0.012733018957078457\n",
      "Iteration: 3687/10000, Loss: 0.01559064257889986\n",
      "Iteration: 3688/10000, Loss: 0.011046674102544785\n",
      "Iteration: 3689/10000, Loss: 0.018739180639386177\n",
      "Iteration: 3690/10000, Loss: 0.017857858911156654\n",
      "Iteration: 3691/10000, Loss: 0.015956714749336243\n",
      "Iteration: 3692/10000, Loss: 0.015230640769004822\n",
      "Iteration: 3693/10000, Loss: 0.012650934047996998\n",
      "Iteration: 3694/10000, Loss: 0.015499943867325783\n",
      "Iteration: 3695/10000, Loss: 0.013022569008171558\n",
      "Iteration: 3696/10000, Loss: 0.017565635964274406\n",
      "Iteration: 3697/10000, Loss: 0.019177159294486046\n",
      "Iteration: 3698/10000, Loss: 0.012703548185527325\n",
      "Iteration: 3699/10000, Loss: 0.0160952378064394\n",
      "Iteration: 3700/10000, Loss: 0.013289706781506538\n",
      "Average test loss:  0.0027\n",
      "Iteration: 3701/10000, Loss: 0.010144436731934547\n",
      "Iteration: 3702/10000, Loss: 0.008871860802173615\n",
      "Iteration: 3703/10000, Loss: 0.015448571182787418\n",
      "Iteration: 3704/10000, Loss: 0.015880191698670387\n",
      "Iteration: 3705/10000, Loss: 0.01790124736726284\n",
      "Iteration: 3706/10000, Loss: 0.0194956474006176\n",
      "Iteration: 3707/10000, Loss: 0.01306720171123743\n",
      "Iteration: 3708/10000, Loss: 0.013844260014593601\n",
      "Iteration: 3709/10000, Loss: 0.01346034649759531\n",
      "Iteration: 3710/10000, Loss: 0.012375455349683762\n",
      "Iteration: 3711/10000, Loss: 0.014066001400351524\n",
      "Iteration: 3712/10000, Loss: 0.012222283519804478\n",
      "Iteration: 3713/10000, Loss: 0.016144005581736565\n",
      "Iteration: 3714/10000, Loss: 0.01885645091533661\n",
      "Iteration: 3715/10000, Loss: 0.011793971993029118\n",
      "Iteration: 3716/10000, Loss: 0.015123721212148666\n",
      "Iteration: 3717/10000, Loss: 0.013459021225571632\n",
      "Iteration: 3718/10000, Loss: 0.00915481522679329\n",
      "Iteration: 3719/10000, Loss: 0.015031800605356693\n",
      "Iteration: 3720/10000, Loss: 0.0224455539137125\n",
      "Iteration: 3721/10000, Loss: 0.020978301763534546\n",
      "Iteration: 3722/10000, Loss: 0.018981339409947395\n",
      "Iteration: 3723/10000, Loss: 0.013307491317391396\n",
      "Iteration: 3724/10000, Loss: 0.017364244908094406\n",
      "Iteration: 3725/10000, Loss: 0.014610636979341507\n",
      "Iteration: 3726/10000, Loss: 0.014345445670187473\n",
      "Iteration: 3727/10000, Loss: 0.012004981748759747\n",
      "Iteration: 3728/10000, Loss: 0.014277367852628231\n",
      "Iteration: 3729/10000, Loss: 0.01684986613690853\n",
      "Iteration: 3730/10000, Loss: 0.010009531863033772\n",
      "Iteration: 3731/10000, Loss: 0.011924020014703274\n",
      "Iteration: 3732/10000, Loss: 0.01158895157277584\n",
      "Iteration: 3733/10000, Loss: 0.019362585619091988\n",
      "Iteration: 3734/10000, Loss: 0.017098097130656242\n",
      "Iteration: 3735/10000, Loss: 0.019933955743908882\n",
      "Iteration: 3736/10000, Loss: 0.019771795719861984\n",
      "Iteration: 3737/10000, Loss: 0.019621089100837708\n",
      "Iteration: 3738/10000, Loss: 0.025392889976501465\n",
      "Iteration: 3739/10000, Loss: 0.0195101760327816\n",
      "Iteration: 3740/10000, Loss: 0.013579820282757282\n",
      "Iteration: 3741/10000, Loss: 0.012800497934222221\n",
      "Iteration: 3742/10000, Loss: 0.014068885706365108\n",
      "Iteration: 3743/10000, Loss: 0.02014557644724846\n",
      "Iteration: 3744/10000, Loss: 0.02642817236483097\n",
      "Iteration: 3745/10000, Loss: 0.018150508403778076\n",
      "Iteration: 3746/10000, Loss: 0.013987536542117596\n",
      "Iteration: 3747/10000, Loss: 0.01854601874947548\n",
      "Iteration: 3748/10000, Loss: 0.018961139023303986\n",
      "Iteration: 3749/10000, Loss: 0.020663460716605186\n",
      "Iteration: 3750/10000, Loss: 0.013463897630572319\n",
      "Iteration: 3751/10000, Loss: 0.008757870644330978\n",
      "Iteration: 3752/10000, Loss: 0.016832327470183372\n",
      "Iteration: 3753/10000, Loss: 0.014834088273346424\n",
      "Iteration: 3754/10000, Loss: 0.022023338824510574\n",
      "Iteration: 3755/10000, Loss: 0.010514828376471996\n",
      "Iteration: 3756/10000, Loss: 0.01578960195183754\n",
      "Iteration: 3757/10000, Loss: 0.01889650523662567\n",
      "Iteration: 3758/10000, Loss: 0.014128641225397587\n",
      "Iteration: 3759/10000, Loss: 0.012061833404004574\n",
      "Iteration: 3760/10000, Loss: 0.015298441983759403\n",
      "Iteration: 3761/10000, Loss: 0.013834892772138119\n",
      "Iteration: 3762/10000, Loss: 0.014892232604324818\n",
      "Iteration: 3763/10000, Loss: 0.023504523560404778\n",
      "Iteration: 3764/10000, Loss: 0.018440332263708115\n",
      "Iteration: 3765/10000, Loss: 0.012845586985349655\n",
      "Iteration: 3766/10000, Loss: 0.012886116281151772\n",
      "Iteration: 3767/10000, Loss: 0.01743224635720253\n",
      "Iteration: 3768/10000, Loss: 0.01462529320269823\n",
      "Iteration: 3769/10000, Loss: 0.017133966088294983\n",
      "Iteration: 3770/10000, Loss: 0.01399129256606102\n",
      "Iteration: 3771/10000, Loss: 0.011861921288073063\n",
      "Iteration: 3772/10000, Loss: 0.014554129913449287\n",
      "Iteration: 3773/10000, Loss: 0.014539136551320553\n",
      "Iteration: 3774/10000, Loss: 0.018318116664886475\n",
      "Iteration: 3775/10000, Loss: 0.016897577792406082\n",
      "Iteration: 3776/10000, Loss: 0.016898728907108307\n",
      "Iteration: 3777/10000, Loss: 0.030086135491728783\n",
      "Iteration: 3778/10000, Loss: 0.014455960132181644\n",
      "Iteration: 3779/10000, Loss: 0.01571735367178917\n",
      "Iteration: 3780/10000, Loss: 0.013070105575025082\n",
      "Iteration: 3781/10000, Loss: 0.025036659091711044\n",
      "Iteration: 3782/10000, Loss: 0.01743338443338871\n",
      "Iteration: 3783/10000, Loss: 0.016123704612255096\n",
      "Iteration: 3784/10000, Loss: 0.009902974590659142\n",
      "Iteration: 3785/10000, Loss: 0.015291592106223106\n",
      "Iteration: 3786/10000, Loss: 0.018907325342297554\n",
      "Iteration: 3787/10000, Loss: 0.021111728623509407\n",
      "Iteration: 3788/10000, Loss: 0.01035701297223568\n",
      "Iteration: 3789/10000, Loss: 0.014217962510883808\n",
      "Iteration: 3790/10000, Loss: 0.01621297374367714\n",
      "Iteration: 3791/10000, Loss: 0.016343260183930397\n",
      "Iteration: 3792/10000, Loss: 0.018976209685206413\n",
      "Iteration: 3793/10000, Loss: 0.0149205531924963\n",
      "Iteration: 3794/10000, Loss: 0.019377240911126137\n",
      "Iteration: 3795/10000, Loss: 0.013079303316771984\n",
      "Iteration: 3796/10000, Loss: 0.02100023813545704\n",
      "Iteration: 3797/10000, Loss: 0.014260048046708107\n",
      "Iteration: 3798/10000, Loss: 0.010001885704696178\n",
      "Iteration: 3799/10000, Loss: 0.0202958807349205\n",
      "Iteration: 3800/10000, Loss: 0.015701361000537872\n",
      "Average test loss:  0.0039\n",
      "Iteration: 3801/10000, Loss: 0.020911630243062973\n",
      "Iteration: 3802/10000, Loss: 0.012318802066147327\n",
      "Iteration: 3803/10000, Loss: 0.02142789401113987\n",
      "Iteration: 3804/10000, Loss: 0.010018727742135525\n",
      "Iteration: 3805/10000, Loss: 0.010518726892769337\n",
      "Iteration: 3806/10000, Loss: 0.012197592295706272\n",
      "Iteration: 3807/10000, Loss: 0.022854464128613472\n",
      "Iteration: 3808/10000, Loss: 0.016901779919862747\n",
      "Iteration: 3809/10000, Loss: 0.027990879490971565\n",
      "Iteration: 3810/10000, Loss: 0.014143804088234901\n",
      "Iteration: 3811/10000, Loss: 0.015360439196228981\n",
      "Iteration: 3812/10000, Loss: 0.008359155617654324\n",
      "Iteration: 3813/10000, Loss: 0.023974500596523285\n",
      "Iteration: 3814/10000, Loss: 0.019736357033252716\n",
      "Iteration: 3815/10000, Loss: 0.011098703369498253\n",
      "Iteration: 3816/10000, Loss: 0.018025264143943787\n",
      "Iteration: 3817/10000, Loss: 0.016966836526989937\n",
      "Iteration: 3818/10000, Loss: 0.02137688733637333\n",
      "Iteration: 3819/10000, Loss: 0.019826550036668777\n",
      "Iteration: 3820/10000, Loss: 0.010815920308232307\n",
      "Iteration: 3821/10000, Loss: 0.015490595251321793\n",
      "Iteration: 3822/10000, Loss: 0.01162699144333601\n",
      "Iteration: 3823/10000, Loss: 0.018503831699490547\n",
      "Iteration: 3824/10000, Loss: 0.012302573770284653\n",
      "Iteration: 3825/10000, Loss: 0.014087817631661892\n",
      "Iteration: 3826/10000, Loss: 0.01211187057197094\n",
      "Iteration: 3827/10000, Loss: 0.010115290991961956\n",
      "Iteration: 3828/10000, Loss: 0.019869502633810043\n",
      "Iteration: 3829/10000, Loss: 0.01706165447831154\n",
      "Iteration: 3830/10000, Loss: 0.014921322464942932\n",
      "Iteration: 3831/10000, Loss: 0.009448006749153137\n",
      "Iteration: 3832/10000, Loss: 0.011093168519437313\n",
      "Iteration: 3833/10000, Loss: 0.015693124383687973\n",
      "Iteration: 3834/10000, Loss: 0.014437958598136902\n",
      "Iteration: 3835/10000, Loss: 0.02221481315791607\n",
      "Iteration: 3836/10000, Loss: 0.017627060413360596\n",
      "Iteration: 3837/10000, Loss: 0.01827823370695114\n",
      "Iteration: 3838/10000, Loss: 0.008899291045963764\n",
      "Iteration: 3839/10000, Loss: 0.012724209576845169\n",
      "Iteration: 3840/10000, Loss: 0.013876205310225487\n",
      "Iteration: 3841/10000, Loss: 0.015685101971030235\n",
      "Iteration: 3842/10000, Loss: 0.022404948249459267\n",
      "Iteration: 3843/10000, Loss: 0.01989283598959446\n",
      "Iteration: 3844/10000, Loss: 0.021520311012864113\n",
      "Iteration: 3845/10000, Loss: 0.013042810373008251\n",
      "Iteration: 3846/10000, Loss: 0.016732968389987946\n",
      "Iteration: 3847/10000, Loss: 0.023105597123503685\n",
      "Iteration: 3848/10000, Loss: 0.011455421335995197\n",
      "Iteration: 3849/10000, Loss: 0.01529915165156126\n",
      "Iteration: 3850/10000, Loss: 0.015181469731032848\n",
      "Iteration: 3851/10000, Loss: 0.01676820032298565\n",
      "Iteration: 3852/10000, Loss: 0.010141788050532341\n",
      "Iteration: 3853/10000, Loss: 0.023397505283355713\n",
      "Iteration: 3854/10000, Loss: 0.012073058634996414\n",
      "Iteration: 3855/10000, Loss: 0.01714484766125679\n",
      "Iteration: 3856/10000, Loss: 0.009790793061256409\n",
      "Iteration: 3857/10000, Loss: 0.014933271333575249\n",
      "Iteration: 3858/10000, Loss: 0.01207153033465147\n",
      "Iteration: 3859/10000, Loss: 0.017291070893406868\n",
      "Iteration: 3860/10000, Loss: 0.019659563899040222\n",
      "Iteration: 3861/10000, Loss: 0.015420211479067802\n",
      "Iteration: 3862/10000, Loss: 0.012266058474779129\n",
      "Iteration: 3863/10000, Loss: 0.019509654492139816\n",
      "Iteration: 3864/10000, Loss: 0.010901441797614098\n",
      "Iteration: 3865/10000, Loss: 0.017247866839170456\n",
      "Iteration: 3866/10000, Loss: 0.015241993591189384\n",
      "Iteration: 3867/10000, Loss: 0.014942814595997334\n",
      "Iteration: 3868/10000, Loss: 0.014571855776011944\n",
      "Iteration: 3869/10000, Loss: 0.014897767454385757\n",
      "Iteration: 3870/10000, Loss: 0.010384046472609043\n",
      "Iteration: 3871/10000, Loss: 0.01632354035973549\n",
      "Iteration: 3872/10000, Loss: 0.020940657705068588\n",
      "Iteration: 3873/10000, Loss: 0.010157376527786255\n",
      "Iteration: 3874/10000, Loss: 0.01310847420245409\n",
      "Iteration: 3875/10000, Loss: 0.017789436504244804\n",
      "Iteration: 3876/10000, Loss: 0.013910502195358276\n",
      "Iteration: 3877/10000, Loss: 0.01262502372264862\n",
      "Iteration: 3878/10000, Loss: 0.014701050706207752\n",
      "Iteration: 3879/10000, Loss: 0.016254998743534088\n",
      "Iteration: 3880/10000, Loss: 0.024858573451638222\n",
      "Iteration: 3881/10000, Loss: 0.018768250942230225\n",
      "Iteration: 3882/10000, Loss: 0.01844346523284912\n",
      "Iteration: 3883/10000, Loss: 0.014944799244403839\n",
      "Iteration: 3884/10000, Loss: 0.013998917303979397\n",
      "Iteration: 3885/10000, Loss: 0.019108818843960762\n",
      "Iteration: 3886/10000, Loss: 0.013860753737390041\n",
      "Iteration: 3887/10000, Loss: 0.024058232083916664\n",
      "Iteration: 3888/10000, Loss: 0.02176743373274803\n",
      "Iteration: 3889/10000, Loss: 0.01364282425493002\n",
      "Iteration: 3890/10000, Loss: 0.011291895993053913\n",
      "Iteration: 3891/10000, Loss: 0.015123691409826279\n",
      "Iteration: 3892/10000, Loss: 0.017596662044525146\n",
      "Iteration: 3893/10000, Loss: 0.015100871212780476\n",
      "Iteration: 3894/10000, Loss: 0.017367850989103317\n",
      "Iteration: 3895/10000, Loss: 0.01230883039534092\n",
      "Iteration: 3896/10000, Loss: 0.011974974535405636\n",
      "Iteration: 3897/10000, Loss: 0.015378201380372047\n",
      "Iteration: 3898/10000, Loss: 0.018620116636157036\n",
      "Iteration: 3899/10000, Loss: 0.012910055927932262\n",
      "Iteration: 3900/10000, Loss: 0.01140242163091898\n",
      "Average test loss:  0.0036\n",
      "Iteration: 3901/10000, Loss: 0.017937416210770607\n",
      "Iteration: 3902/10000, Loss: 0.01328230556100607\n",
      "Iteration: 3903/10000, Loss: 0.015714777633547783\n",
      "Iteration: 3904/10000, Loss: 0.014753407798707485\n",
      "Iteration: 3905/10000, Loss: 0.015247758477926254\n",
      "Iteration: 3906/10000, Loss: 0.014646259136497974\n",
      "Iteration: 3907/10000, Loss: 0.01616954244673252\n",
      "Iteration: 3908/10000, Loss: 0.01822236366569996\n",
      "Iteration: 3909/10000, Loss: 0.01753545179963112\n",
      "Iteration: 3910/10000, Loss: 0.01588541828095913\n",
      "Iteration: 3911/10000, Loss: 0.01470276527106762\n",
      "Iteration: 3912/10000, Loss: 0.010742916725575924\n",
      "Iteration: 3913/10000, Loss: 0.019824333488941193\n",
      "Iteration: 3914/10000, Loss: 0.012842969968914986\n",
      "Iteration: 3915/10000, Loss: 0.013753137551248074\n",
      "Iteration: 3916/10000, Loss: 0.01674986444413662\n",
      "Iteration: 3917/10000, Loss: 0.007895913906395435\n",
      "Iteration: 3918/10000, Loss: 0.014732957817614079\n",
      "Iteration: 3919/10000, Loss: 0.012830575928092003\n",
      "Iteration: 3920/10000, Loss: 0.012187782675027847\n",
      "Iteration: 3921/10000, Loss: 0.01802702806890011\n",
      "Iteration: 3922/10000, Loss: 0.018242131918668747\n",
      "Iteration: 3923/10000, Loss: 0.01387022901326418\n",
      "Iteration: 3924/10000, Loss: 0.017938723787665367\n",
      "Iteration: 3925/10000, Loss: 0.020984720438718796\n",
      "Iteration: 3926/10000, Loss: 0.010334597900509834\n",
      "Iteration: 3927/10000, Loss: 0.013170620426535606\n",
      "Iteration: 3928/10000, Loss: 0.014827165752649307\n",
      "Iteration: 3929/10000, Loss: 0.017984315752983093\n",
      "Iteration: 3930/10000, Loss: 0.01710398495197296\n",
      "Iteration: 3931/10000, Loss: 0.01029314287006855\n",
      "Iteration: 3932/10000, Loss: 0.015902239829301834\n",
      "Iteration: 3933/10000, Loss: 0.011686291545629501\n",
      "Iteration: 3934/10000, Loss: 0.021633850410580635\n",
      "Iteration: 3935/10000, Loss: 0.010960831306874752\n",
      "Iteration: 3936/10000, Loss: 0.01940426230430603\n",
      "Iteration: 3937/10000, Loss: 0.016867030411958694\n",
      "Iteration: 3938/10000, Loss: 0.013986362144351006\n",
      "Iteration: 3939/10000, Loss: 0.020421776920557022\n",
      "Iteration: 3940/10000, Loss: 0.010789754800498486\n",
      "Iteration: 3941/10000, Loss: 0.01172031369060278\n",
      "Iteration: 3942/10000, Loss: 0.01649041846394539\n",
      "Iteration: 3943/10000, Loss: 0.024594472721219063\n",
      "Iteration: 3944/10000, Loss: 0.01126634981483221\n",
      "Iteration: 3945/10000, Loss: 0.01593586429953575\n",
      "Iteration: 3946/10000, Loss: 0.015883885324001312\n",
      "Iteration: 3947/10000, Loss: 0.01684916764497757\n",
      "Iteration: 3948/10000, Loss: 0.013639566488564014\n",
      "Iteration: 3949/10000, Loss: 0.013239345513284206\n",
      "Iteration: 3950/10000, Loss: 0.013279483653604984\n",
      "Iteration: 3951/10000, Loss: 0.01625111512839794\n",
      "Iteration: 3952/10000, Loss: 0.0174516960978508\n",
      "Iteration: 3953/10000, Loss: 0.015355180948972702\n",
      "Iteration: 3954/10000, Loss: 0.016337888315320015\n",
      "Iteration: 3955/10000, Loss: 0.012290110811591148\n",
      "Iteration: 3956/10000, Loss: 0.015554501675069332\n",
      "Iteration: 3957/10000, Loss: 0.011155121959745884\n",
      "Iteration: 3958/10000, Loss: 0.011732902377843857\n",
      "Iteration: 3959/10000, Loss: 0.01470134872943163\n",
      "Iteration: 3960/10000, Loss: 0.016284750774502754\n",
      "Iteration: 3961/10000, Loss: 0.01689736172556877\n",
      "Iteration: 3962/10000, Loss: 0.01126902922987938\n",
      "Iteration: 3963/10000, Loss: 0.0187433660030365\n",
      "Iteration: 3964/10000, Loss: 0.0226981770247221\n",
      "Iteration: 3965/10000, Loss: 0.01762586459517479\n",
      "Iteration: 3966/10000, Loss: 0.019017774611711502\n",
      "Iteration: 3967/10000, Loss: 0.011593290604650974\n",
      "Iteration: 3968/10000, Loss: 0.013108381070196629\n",
      "Iteration: 3969/10000, Loss: 0.03148677945137024\n",
      "Iteration: 3970/10000, Loss: 0.016759146004915237\n",
      "Iteration: 3971/10000, Loss: 0.014883334748446941\n",
      "Iteration: 3972/10000, Loss: 0.022811423987150192\n",
      "Iteration: 3973/10000, Loss: 0.01498198602348566\n",
      "Iteration: 3974/10000, Loss: 0.015353158116340637\n",
      "Iteration: 3975/10000, Loss: 0.011987842619419098\n",
      "Iteration: 3976/10000, Loss: 0.00944629218429327\n",
      "Iteration: 3977/10000, Loss: 0.017467934638261795\n",
      "Iteration: 3978/10000, Loss: 0.016138533130288124\n",
      "Iteration: 3979/10000, Loss: 0.01574058271944523\n",
      "Iteration: 3980/10000, Loss: 0.020121484994888306\n",
      "Iteration: 3981/10000, Loss: 0.016084522008895874\n",
      "Iteration: 3982/10000, Loss: 0.01246340200304985\n",
      "Iteration: 3983/10000, Loss: 0.017457665875554085\n",
      "Iteration: 3984/10000, Loss: 0.015032630413770676\n",
      "Iteration: 3985/10000, Loss: 0.018352314829826355\n",
      "Iteration: 3986/10000, Loss: 0.01844014972448349\n",
      "Iteration: 3987/10000, Loss: 0.0127310985699296\n",
      "Iteration: 3988/10000, Loss: 0.0166010819375515\n",
      "Iteration: 3989/10000, Loss: 0.014413363300263882\n",
      "Iteration: 3990/10000, Loss: 0.022616837173700333\n",
      "Iteration: 3991/10000, Loss: 0.014453934505581856\n",
      "Iteration: 3992/10000, Loss: 0.015092173591256142\n",
      "Iteration: 3993/10000, Loss: 0.01212190929800272\n",
      "Iteration: 3994/10000, Loss: 0.016767216846346855\n",
      "Iteration: 3995/10000, Loss: 0.01598201133310795\n",
      "Iteration: 3996/10000, Loss: 0.015634721145033836\n",
      "Iteration: 3997/10000, Loss: 0.011459369212388992\n",
      "Iteration: 3998/10000, Loss: 0.010208504274487495\n",
      "Iteration: 3999/10000, Loss: 0.012416121549904346\n",
      "Iteration: 4000/10000, Loss: 0.010857222601771355\n",
      "Average test loss:  0.0029\n",
      "Iteration: 4001/10000, Loss: 0.010922949761152267\n",
      "Iteration: 4002/10000, Loss: 0.012290933169424534\n",
      "Iteration: 4003/10000, Loss: 0.009828495793044567\n",
      "Iteration: 4004/10000, Loss: 0.00821914803236723\n",
      "Iteration: 4005/10000, Loss: 0.016723066568374634\n",
      "Iteration: 4006/10000, Loss: 0.011754676699638367\n",
      "Iteration: 4007/10000, Loss: 0.01784197986125946\n",
      "Iteration: 4008/10000, Loss: 0.012931745499372482\n",
      "Iteration: 4009/10000, Loss: 0.011432248167693615\n",
      "Iteration: 4010/10000, Loss: 0.01004784181714058\n",
      "Iteration: 4011/10000, Loss: 0.016526781022548676\n",
      "Iteration: 4012/10000, Loss: 0.01814957708120346\n",
      "Iteration: 4013/10000, Loss: 0.023480365052819252\n",
      "Iteration: 4014/10000, Loss: 0.012710434384644032\n",
      "Iteration: 4015/10000, Loss: 0.013399813324213028\n",
      "Iteration: 4016/10000, Loss: 0.010185347869992256\n",
      "Iteration: 4017/10000, Loss: 0.010478763841092587\n",
      "Iteration: 4018/10000, Loss: 0.019082702696323395\n",
      "Iteration: 4019/10000, Loss: 0.013312003575265408\n",
      "Iteration: 4020/10000, Loss: 0.015589278191328049\n",
      "Iteration: 4021/10000, Loss: 0.011308634653687477\n",
      "Iteration: 4022/10000, Loss: 0.013832379132509232\n",
      "Iteration: 4023/10000, Loss: 0.015328142791986465\n",
      "Iteration: 4024/10000, Loss: 0.016388628631830215\n",
      "Iteration: 4025/10000, Loss: 0.01750512607395649\n",
      "Iteration: 4026/10000, Loss: 0.01528270822018385\n",
      "Iteration: 4027/10000, Loss: 0.017404356971383095\n",
      "Iteration: 4028/10000, Loss: 0.012221754528582096\n",
      "Iteration: 4029/10000, Loss: 0.013354990631341934\n",
      "Iteration: 4030/10000, Loss: 0.020800678059458733\n",
      "Iteration: 4031/10000, Loss: 0.013734946958720684\n",
      "Iteration: 4032/10000, Loss: 0.011644815094769001\n",
      "Iteration: 4033/10000, Loss: 0.013930086977779865\n",
      "Iteration: 4034/10000, Loss: 0.01396193727850914\n",
      "Iteration: 4035/10000, Loss: 0.009357216767966747\n",
      "Iteration: 4036/10000, Loss: 0.013721256516873837\n",
      "Iteration: 4037/10000, Loss: 0.014624500647187233\n",
      "Iteration: 4038/10000, Loss: 0.01834920234978199\n",
      "Iteration: 4039/10000, Loss: 0.01654774136841297\n",
      "Iteration: 4040/10000, Loss: 0.01290634274482727\n",
      "Iteration: 4041/10000, Loss: 0.014543440192937851\n",
      "Iteration: 4042/10000, Loss: 0.015215743333101273\n",
      "Iteration: 4043/10000, Loss: 0.01743495650589466\n",
      "Iteration: 4044/10000, Loss: 0.014816720969974995\n",
      "Iteration: 4045/10000, Loss: 0.0120090888813138\n",
      "Iteration: 4046/10000, Loss: 0.011537929996848106\n",
      "Iteration: 4047/10000, Loss: 0.013551334850490093\n",
      "Iteration: 4048/10000, Loss: 0.013389972038567066\n",
      "Iteration: 4049/10000, Loss: 0.02148997224867344\n",
      "Iteration: 4050/10000, Loss: 0.022202173247933388\n",
      "Iteration: 4051/10000, Loss: 0.015224742703139782\n",
      "Iteration: 4052/10000, Loss: 0.012748847715556622\n",
      "Iteration: 4053/10000, Loss: 0.013509002514183521\n",
      "Iteration: 4054/10000, Loss: 0.01069051306694746\n",
      "Iteration: 4055/10000, Loss: 0.011751503683626652\n",
      "Iteration: 4056/10000, Loss: 0.0213936660438776\n",
      "Iteration: 4057/10000, Loss: 0.020068366080522537\n",
      "Iteration: 4058/10000, Loss: 0.019178975373506546\n",
      "Iteration: 4059/10000, Loss: 0.01806114986538887\n",
      "Iteration: 4060/10000, Loss: 0.016851363703608513\n",
      "Iteration: 4061/10000, Loss: 0.01485002413392067\n",
      "Iteration: 4062/10000, Loss: 0.015035019256174564\n",
      "Iteration: 4063/10000, Loss: 0.0177675299346447\n",
      "Iteration: 4064/10000, Loss: 0.012990185059607029\n",
      "Iteration: 4065/10000, Loss: 0.016972575336694717\n",
      "Iteration: 4066/10000, Loss: 0.015564518049359322\n",
      "Iteration: 4067/10000, Loss: 0.01224940363317728\n",
      "Iteration: 4068/10000, Loss: 0.016842884942889214\n",
      "Iteration: 4069/10000, Loss: 0.013908701948821545\n",
      "Iteration: 4070/10000, Loss: 0.014132371172308922\n",
      "Iteration: 4071/10000, Loss: 0.014681076630949974\n",
      "Iteration: 4072/10000, Loss: 0.009280289523303509\n",
      "Iteration: 4073/10000, Loss: 0.01051587425172329\n",
      "Iteration: 4074/10000, Loss: 0.014796106144785881\n",
      "Iteration: 4075/10000, Loss: 0.01812761090695858\n",
      "Iteration: 4076/10000, Loss: 0.014923183247447014\n",
      "Iteration: 4077/10000, Loss: 0.012475281953811646\n",
      "Iteration: 4078/10000, Loss: 0.019012222066521645\n",
      "Iteration: 4079/10000, Loss: 0.01630549319088459\n",
      "Iteration: 4080/10000, Loss: 0.009537619538605213\n",
      "Iteration: 4081/10000, Loss: 0.011812981218099594\n",
      "Iteration: 4082/10000, Loss: 0.015077944844961166\n",
      "Iteration: 4083/10000, Loss: 0.027609657496213913\n",
      "Iteration: 4084/10000, Loss: 0.01805478148162365\n",
      "Iteration: 4085/10000, Loss: 0.013193315826356411\n",
      "Iteration: 4086/10000, Loss: 0.009982709772884846\n",
      "Iteration: 4087/10000, Loss: 0.012688126415014267\n",
      "Iteration: 4088/10000, Loss: 0.01785653829574585\n",
      "Iteration: 4089/10000, Loss: 0.013191348873078823\n",
      "Iteration: 4090/10000, Loss: 0.01379680447280407\n",
      "Iteration: 4091/10000, Loss: 0.014948678202927113\n",
      "Iteration: 4092/10000, Loss: 0.014554201625287533\n",
      "Iteration: 4093/10000, Loss: 0.01367073692381382\n",
      "Iteration: 4094/10000, Loss: 0.019143499433994293\n",
      "Iteration: 4095/10000, Loss: 0.017812853679060936\n",
      "Iteration: 4096/10000, Loss: 0.015423779375851154\n",
      "Iteration: 4097/10000, Loss: 0.010039331391453743\n",
      "Iteration: 4098/10000, Loss: 0.013631579466164112\n",
      "Iteration: 4099/10000, Loss: 0.01566055230796337\n",
      "Iteration: 4100/10000, Loss: 0.015880174934864044\n",
      "Average test loss:  0.0033\n",
      "Iteration: 4101/10000, Loss: 0.01847870461642742\n",
      "Iteration: 4102/10000, Loss: 0.013543026521801949\n",
      "Iteration: 4103/10000, Loss: 0.016241753473877907\n",
      "Iteration: 4104/10000, Loss: 0.012447211891412735\n",
      "Iteration: 4105/10000, Loss: 0.025498734787106514\n",
      "Iteration: 4106/10000, Loss: 0.011382059194147587\n",
      "Iteration: 4107/10000, Loss: 0.012474038638174534\n",
      "Iteration: 4108/10000, Loss: 0.024753229692578316\n",
      "Iteration: 4109/10000, Loss: 0.010517384856939316\n",
      "Iteration: 4110/10000, Loss: 0.02335665002465248\n",
      "Iteration: 4111/10000, Loss: 0.0218693558126688\n",
      "Iteration: 4112/10000, Loss: 0.010113331489264965\n",
      "Iteration: 4113/10000, Loss: 0.015019535087049007\n",
      "Iteration: 4114/10000, Loss: 0.010086677968502045\n",
      "Iteration: 4115/10000, Loss: 0.01689353957772255\n",
      "Iteration: 4116/10000, Loss: 0.012820170260965824\n",
      "Iteration: 4117/10000, Loss: 0.010883807204663754\n",
      "Iteration: 4118/10000, Loss: 0.012991725467145443\n",
      "Iteration: 4119/10000, Loss: 0.010706131346523762\n",
      "Iteration: 4120/10000, Loss: 0.014546611346304417\n",
      "Iteration: 4121/10000, Loss: 0.01121911033987999\n",
      "Iteration: 4122/10000, Loss: 0.013713238760828972\n",
      "Iteration: 4123/10000, Loss: 0.01104618702083826\n",
      "Iteration: 4124/10000, Loss: 0.01864018477499485\n",
      "Iteration: 4125/10000, Loss: 0.012325681746006012\n",
      "Iteration: 4126/10000, Loss: 0.016470957547426224\n",
      "Iteration: 4127/10000, Loss: 0.01857306994497776\n",
      "Iteration: 4128/10000, Loss: 0.015053072944283485\n",
      "Iteration: 4129/10000, Loss: 0.013979271054267883\n",
      "Iteration: 4130/10000, Loss: 0.013609201647341251\n",
      "Iteration: 4131/10000, Loss: 0.014716064557433128\n",
      "Iteration: 4132/10000, Loss: 0.01467045582830906\n",
      "Iteration: 4133/10000, Loss: 0.018100246787071228\n",
      "Iteration: 4134/10000, Loss: 0.012234106659889221\n",
      "Iteration: 4135/10000, Loss: 0.0178386140614748\n",
      "Iteration: 4136/10000, Loss: 0.013776854611933231\n",
      "Iteration: 4137/10000, Loss: 0.014898807741701603\n",
      "Iteration: 4138/10000, Loss: 0.010151332244277\n",
      "Iteration: 4139/10000, Loss: 0.014378342777490616\n",
      "Iteration: 4140/10000, Loss: 0.018517520278692245\n",
      "Iteration: 4141/10000, Loss: 0.00953854899853468\n",
      "Iteration: 4142/10000, Loss: 0.014238186180591583\n",
      "Iteration: 4143/10000, Loss: 0.014441543258726597\n",
      "Iteration: 4144/10000, Loss: 0.01334358099848032\n",
      "Iteration: 4145/10000, Loss: 0.013566289097070694\n",
      "Iteration: 4146/10000, Loss: 0.011102274991571903\n",
      "Iteration: 4147/10000, Loss: 0.012377232313156128\n",
      "Iteration: 4148/10000, Loss: 0.009807523339986801\n",
      "Iteration: 4149/10000, Loss: 0.011135856620967388\n",
      "Iteration: 4150/10000, Loss: 0.014874916523694992\n",
      "Iteration: 4151/10000, Loss: 0.014312545768916607\n",
      "Iteration: 4152/10000, Loss: 0.012310373596847057\n",
      "Iteration: 4153/10000, Loss: 0.014259717427194118\n",
      "Iteration: 4154/10000, Loss: 0.009046009741723537\n",
      "Iteration: 4155/10000, Loss: 0.01664818823337555\n",
      "Iteration: 4156/10000, Loss: 0.015165041200816631\n",
      "Iteration: 4157/10000, Loss: 0.009012208320200443\n",
      "Iteration: 4158/10000, Loss: 0.017398763447999954\n",
      "Iteration: 4159/10000, Loss: 0.017529282718896866\n",
      "Iteration: 4160/10000, Loss: 0.010949867777526379\n",
      "Iteration: 4161/10000, Loss: 0.014490196481347084\n",
      "Iteration: 4162/10000, Loss: 0.020789021626114845\n",
      "Iteration: 4163/10000, Loss: 0.01628355123102665\n",
      "Iteration: 4164/10000, Loss: 0.015997333452105522\n",
      "Iteration: 4165/10000, Loss: 0.021275561302900314\n",
      "Iteration: 4166/10000, Loss: 0.010085167363286018\n",
      "Iteration: 4167/10000, Loss: 0.009329869411885738\n",
      "Iteration: 4168/10000, Loss: 0.011904694139957428\n",
      "Iteration: 4169/10000, Loss: 0.011908415704965591\n",
      "Iteration: 4170/10000, Loss: 0.010896227322518826\n",
      "Iteration: 4171/10000, Loss: 0.015156223438680172\n",
      "Iteration: 4172/10000, Loss: 0.012804705649614334\n",
      "Iteration: 4173/10000, Loss: 0.012132284231483936\n",
      "Iteration: 4174/10000, Loss: 0.017822140827775\n",
      "Iteration: 4175/10000, Loss: 0.009551639668643475\n",
      "Iteration: 4176/10000, Loss: 0.011934502981603146\n",
      "Iteration: 4177/10000, Loss: 0.020442243665456772\n",
      "Iteration: 4178/10000, Loss: 0.012538940645754337\n",
      "Iteration: 4179/10000, Loss: 0.014594885520637035\n",
      "Iteration: 4180/10000, Loss: 0.010347751900553703\n",
      "Iteration: 4181/10000, Loss: 0.01807139441370964\n",
      "Iteration: 4182/10000, Loss: 0.015622320584952831\n",
      "Iteration: 4183/10000, Loss: 0.011856922879815102\n",
      "Iteration: 4184/10000, Loss: 0.010034547187387943\n",
      "Iteration: 4185/10000, Loss: 0.014543961733579636\n",
      "Iteration: 4186/10000, Loss: 0.008592966943979263\n",
      "Iteration: 4187/10000, Loss: 0.011927091516554356\n",
      "Iteration: 4188/10000, Loss: 0.013338889926671982\n",
      "Iteration: 4189/10000, Loss: 0.012388517148792744\n",
      "Iteration: 4190/10000, Loss: 0.006599459797143936\n",
      "Iteration: 4191/10000, Loss: 0.010784057900309563\n",
      "Iteration: 4192/10000, Loss: 0.011061687022447586\n",
      "Iteration: 4193/10000, Loss: 0.011454440653324127\n",
      "Iteration: 4194/10000, Loss: 0.012386527843773365\n",
      "Iteration: 4195/10000, Loss: 0.013312960974872112\n",
      "Iteration: 4196/10000, Loss: 0.01303882896900177\n",
      "Iteration: 4197/10000, Loss: 0.01662636362016201\n",
      "Iteration: 4198/10000, Loss: 0.01777471788227558\n",
      "Iteration: 4199/10000, Loss: 0.013659768737852573\n",
      "Iteration: 4200/10000, Loss: 0.013127656653523445\n",
      "Average test loss:  0.0030\n",
      "Iteration: 4201/10000, Loss: 0.011714529246091843\n",
      "Iteration: 4202/10000, Loss: 0.011404260993003845\n",
      "Iteration: 4203/10000, Loss: 0.016911352053284645\n",
      "Iteration: 4204/10000, Loss: 0.014532660134136677\n",
      "Iteration: 4205/10000, Loss: 0.013803023844957352\n",
      "Iteration: 4206/10000, Loss: 0.01734674721956253\n",
      "Iteration: 4207/10000, Loss: 0.013909158296883106\n",
      "Iteration: 4208/10000, Loss: 0.012002338655292988\n",
      "Iteration: 4209/10000, Loss: 0.013151276856660843\n",
      "Iteration: 4210/10000, Loss: 0.021698376163840294\n",
      "Iteration: 4211/10000, Loss: 0.01671484485268593\n",
      "Iteration: 4212/10000, Loss: 0.015365374274551868\n",
      "Iteration: 4213/10000, Loss: 0.015197494998574257\n",
      "Iteration: 4214/10000, Loss: 0.012594238854944706\n",
      "Iteration: 4215/10000, Loss: 0.01184029970318079\n",
      "Iteration: 4216/10000, Loss: 0.011975904926657677\n",
      "Iteration: 4217/10000, Loss: 0.016608795151114464\n",
      "Iteration: 4218/10000, Loss: 0.009692256338894367\n",
      "Iteration: 4219/10000, Loss: 0.013840236701071262\n",
      "Iteration: 4220/10000, Loss: 0.018151206895709038\n",
      "Iteration: 4221/10000, Loss: 0.013387003913521767\n",
      "Iteration: 4222/10000, Loss: 0.010391217656433582\n",
      "Iteration: 4223/10000, Loss: 0.009335805661976337\n",
      "Iteration: 4224/10000, Loss: 0.017999501898884773\n",
      "Iteration: 4225/10000, Loss: 0.01844985969364643\n",
      "Iteration: 4226/10000, Loss: 0.011884557083249092\n",
      "Iteration: 4227/10000, Loss: 0.009209218434989452\n",
      "Iteration: 4228/10000, Loss: 0.01739523746073246\n",
      "Iteration: 4229/10000, Loss: 0.01296900399029255\n",
      "Iteration: 4230/10000, Loss: 0.011905130930244923\n",
      "Iteration: 4231/10000, Loss: 0.021273469552397728\n",
      "Iteration: 4232/10000, Loss: 0.019516581669449806\n",
      "Iteration: 4233/10000, Loss: 0.012184124439954758\n",
      "Iteration: 4234/10000, Loss: 0.015933725982904434\n",
      "Iteration: 4235/10000, Loss: 0.01377197913825512\n",
      "Iteration: 4236/10000, Loss: 0.00832622405141592\n",
      "Iteration: 4237/10000, Loss: 0.010031335987150669\n",
      "Iteration: 4238/10000, Loss: 0.01227383129298687\n",
      "Iteration: 4239/10000, Loss: 0.013430596329271793\n",
      "Iteration: 4240/10000, Loss: 0.009365763515233994\n",
      "Iteration: 4241/10000, Loss: 0.012288887053728104\n",
      "Iteration: 4242/10000, Loss: 0.01798105426132679\n",
      "Iteration: 4243/10000, Loss: 0.007401319220662117\n",
      "Iteration: 4244/10000, Loss: 0.01646874099969864\n",
      "Iteration: 4245/10000, Loss: 0.01952754333615303\n",
      "Iteration: 4246/10000, Loss: 0.021709637716412544\n",
      "Iteration: 4247/10000, Loss: 0.013052279129624367\n",
      "Iteration: 4248/10000, Loss: 0.017140723764896393\n",
      "Iteration: 4249/10000, Loss: 0.012397187761962414\n",
      "Iteration: 4250/10000, Loss: 0.012646513991057873\n",
      "Iteration: 4251/10000, Loss: 0.017000379040837288\n",
      "Iteration: 4252/10000, Loss: 0.011905103921890259\n",
      "Iteration: 4253/10000, Loss: 0.01771467551589012\n",
      "Iteration: 4254/10000, Loss: 0.011739294044673443\n",
      "Iteration: 4255/10000, Loss: 0.009437681175768375\n",
      "Iteration: 4256/10000, Loss: 0.018779633566737175\n",
      "Iteration: 4257/10000, Loss: 0.01102761272341013\n",
      "Iteration: 4258/10000, Loss: 0.008555040694773197\n",
      "Iteration: 4259/10000, Loss: 0.01702478528022766\n",
      "Iteration: 4260/10000, Loss: 0.011159578338265419\n",
      "Iteration: 4261/10000, Loss: 0.010593591257929802\n",
      "Iteration: 4262/10000, Loss: 0.013849399983882904\n",
      "Iteration: 4263/10000, Loss: 0.012723015621304512\n",
      "Iteration: 4264/10000, Loss: 0.012737072072923183\n",
      "Iteration: 4265/10000, Loss: 0.013642014004290104\n",
      "Iteration: 4266/10000, Loss: 0.013230256736278534\n",
      "Iteration: 4267/10000, Loss: 0.011324729770421982\n",
      "Iteration: 4268/10000, Loss: 0.008062207140028477\n",
      "Iteration: 4269/10000, Loss: 0.01674380898475647\n",
      "Iteration: 4270/10000, Loss: 0.01613885909318924\n",
      "Iteration: 4271/10000, Loss: 0.011028056964278221\n",
      "Iteration: 4272/10000, Loss: 0.008886211551725864\n",
      "Iteration: 4273/10000, Loss: 0.01469082199037075\n",
      "Iteration: 4274/10000, Loss: 0.01426337007433176\n",
      "Iteration: 4275/10000, Loss: 0.015037511475384235\n",
      "Iteration: 4276/10000, Loss: 0.010825525037944317\n",
      "Iteration: 4277/10000, Loss: 0.013000749051570892\n",
      "Iteration: 4278/10000, Loss: 0.021033797413110733\n",
      "Iteration: 4279/10000, Loss: 0.020020125433802605\n",
      "Iteration: 4280/10000, Loss: 0.011442062444984913\n",
      "Iteration: 4281/10000, Loss: 0.011509505100548267\n",
      "Iteration: 4282/10000, Loss: 0.007520855404436588\n",
      "Iteration: 4283/10000, Loss: 0.009948674589395523\n",
      "Iteration: 4284/10000, Loss: 0.016884563490748405\n",
      "Iteration: 4285/10000, Loss: 0.016631407663226128\n",
      "Iteration: 4286/10000, Loss: 0.017185837030410767\n",
      "Iteration: 4287/10000, Loss: 0.017319604754447937\n",
      "Iteration: 4288/10000, Loss: 0.012518088333308697\n",
      "Iteration: 4289/10000, Loss: 0.010962022468447685\n",
      "Iteration: 4290/10000, Loss: 0.0127750588580966\n",
      "Iteration: 4291/10000, Loss: 0.014592928811907768\n",
      "Iteration: 4292/10000, Loss: 0.01535416953265667\n",
      "Iteration: 4293/10000, Loss: 0.01733924075961113\n",
      "Iteration: 4294/10000, Loss: 0.013263414613902569\n",
      "Iteration: 4295/10000, Loss: 0.015087933279573917\n",
      "Iteration: 4296/10000, Loss: 0.020390477031469345\n",
      "Iteration: 4297/10000, Loss: 0.015772171318531036\n",
      "Iteration: 4298/10000, Loss: 0.012888622470200062\n",
      "Iteration: 4299/10000, Loss: 0.02208814024925232\n",
      "Iteration: 4300/10000, Loss: 0.0179681908339262\n",
      "Average test loss:  0.0042\n",
      "Iteration: 4301/10000, Loss: 0.01752239279448986\n",
      "Iteration: 4302/10000, Loss: 0.019045978784561157\n",
      "Iteration: 4303/10000, Loss: 0.014007220976054668\n",
      "Iteration: 4304/10000, Loss: 0.017970098182559013\n",
      "Iteration: 4305/10000, Loss: 0.013977167196571827\n",
      "Iteration: 4306/10000, Loss: 0.013319461606442928\n",
      "Iteration: 4307/10000, Loss: 0.00953676737844944\n",
      "Iteration: 4308/10000, Loss: 0.010932309553027153\n",
      "Iteration: 4309/10000, Loss: 0.01389410998672247\n",
      "Iteration: 4310/10000, Loss: 0.017301445826888084\n",
      "Iteration: 4311/10000, Loss: 0.013095441274344921\n",
      "Iteration: 4312/10000, Loss: 0.015960216522216797\n",
      "Iteration: 4313/10000, Loss: 0.017224030569195747\n",
      "Iteration: 4314/10000, Loss: 0.014590551145374775\n",
      "Iteration: 4315/10000, Loss: 0.012869903817772865\n",
      "Iteration: 4316/10000, Loss: 0.0171250868588686\n",
      "Iteration: 4317/10000, Loss: 0.014730283990502357\n",
      "Iteration: 4318/10000, Loss: 0.01688101515173912\n",
      "Iteration: 4319/10000, Loss: 0.0100641418248415\n",
      "Iteration: 4320/10000, Loss: 0.009089679457247257\n",
      "Iteration: 4321/10000, Loss: 0.015695519745349884\n",
      "Iteration: 4322/10000, Loss: 0.01753152534365654\n",
      "Iteration: 4323/10000, Loss: 0.020088857039809227\n",
      "Iteration: 4324/10000, Loss: 0.014384442009031773\n",
      "Iteration: 4325/10000, Loss: 0.016720177605748177\n",
      "Iteration: 4326/10000, Loss: 0.010593336075544357\n",
      "Iteration: 4327/10000, Loss: 0.012040460482239723\n",
      "Iteration: 4328/10000, Loss: 0.014961513690650463\n",
      "Iteration: 4329/10000, Loss: 0.02048172801733017\n",
      "Iteration: 4330/10000, Loss: 0.015398466028273106\n",
      "Iteration: 4331/10000, Loss: 0.01815294660627842\n",
      "Iteration: 4332/10000, Loss: 0.013713814318180084\n",
      "Iteration: 4333/10000, Loss: 0.015386588871479034\n",
      "Iteration: 4334/10000, Loss: 0.011634265072643757\n",
      "Iteration: 4335/10000, Loss: 0.010382844135165215\n",
      "Iteration: 4336/10000, Loss: 0.013092059642076492\n",
      "Iteration: 4337/10000, Loss: 0.013539676554501057\n",
      "Iteration: 4338/10000, Loss: 0.015894610434770584\n",
      "Iteration: 4339/10000, Loss: 0.01908900961279869\n",
      "Iteration: 4340/10000, Loss: 0.014316894114017487\n",
      "Iteration: 4341/10000, Loss: 0.019645461812615395\n",
      "Iteration: 4342/10000, Loss: 0.010670456103980541\n",
      "Iteration: 4343/10000, Loss: 0.017891081050038338\n",
      "Iteration: 4344/10000, Loss: 0.015147699043154716\n",
      "Iteration: 4345/10000, Loss: 0.012930494733154774\n",
      "Iteration: 4346/10000, Loss: 0.016505582258105278\n",
      "Iteration: 4347/10000, Loss: 0.01689605787396431\n",
      "Iteration: 4348/10000, Loss: 0.014596438966691494\n",
      "Iteration: 4349/10000, Loss: 0.010993409901857376\n",
      "Iteration: 4350/10000, Loss: 0.01331713330000639\n",
      "Iteration: 4351/10000, Loss: 0.015992339700460434\n",
      "Iteration: 4352/10000, Loss: 0.010456438176333904\n",
      "Iteration: 4353/10000, Loss: 0.01694381982088089\n",
      "Iteration: 4354/10000, Loss: 0.013038898818194866\n",
      "Iteration: 4355/10000, Loss: 0.011569666676223278\n",
      "Iteration: 4356/10000, Loss: 0.018609343096613884\n",
      "Iteration: 4357/10000, Loss: 0.01515972800552845\n",
      "Iteration: 4358/10000, Loss: 0.01153440773487091\n",
      "Iteration: 4359/10000, Loss: 0.01568259857594967\n",
      "Iteration: 4360/10000, Loss: 0.016027512028813362\n",
      "Iteration: 4361/10000, Loss: 0.015572641976177692\n",
      "Iteration: 4362/10000, Loss: 0.02358146943151951\n",
      "Iteration: 4363/10000, Loss: 0.01246497593820095\n",
      "Iteration: 4364/10000, Loss: 0.02377154864370823\n",
      "Iteration: 4365/10000, Loss: 0.010542487725615501\n",
      "Iteration: 4366/10000, Loss: 0.008106854744255543\n",
      "Iteration: 4367/10000, Loss: 0.009395338594913483\n",
      "Iteration: 4368/10000, Loss: 0.011135123670101166\n",
      "Iteration: 4369/10000, Loss: 0.00774540426209569\n",
      "Iteration: 4370/10000, Loss: 0.011682296171784401\n",
      "Iteration: 4371/10000, Loss: 0.011907480657100677\n",
      "Iteration: 4372/10000, Loss: 0.012838480994105339\n",
      "Iteration: 4373/10000, Loss: 0.010421070270240307\n",
      "Iteration: 4374/10000, Loss: 0.012628450989723206\n",
      "Iteration: 4375/10000, Loss: 0.015154329128563404\n",
      "Iteration: 4376/10000, Loss: 0.017431076616048813\n",
      "Iteration: 4377/10000, Loss: 0.017369313165545464\n",
      "Iteration: 4378/10000, Loss: 0.015390579588711262\n",
      "Iteration: 4379/10000, Loss: 0.0086550647392869\n",
      "Iteration: 4380/10000, Loss: 0.013727701269090176\n",
      "Iteration: 4381/10000, Loss: 0.009554073214530945\n",
      "Iteration: 4382/10000, Loss: 0.01681537739932537\n",
      "Iteration: 4383/10000, Loss: 0.014121919870376587\n",
      "Iteration: 4384/10000, Loss: 0.0156287532299757\n",
      "Iteration: 4385/10000, Loss: 0.010592006146907806\n",
      "Iteration: 4386/10000, Loss: 0.013182194903492928\n",
      "Iteration: 4387/10000, Loss: 0.011282566003501415\n",
      "Iteration: 4388/10000, Loss: 0.017486678436398506\n",
      "Iteration: 4389/10000, Loss: 0.01532980427145958\n",
      "Iteration: 4390/10000, Loss: 0.012941589578986168\n",
      "Iteration: 4391/10000, Loss: 0.01583782397210598\n",
      "Iteration: 4392/10000, Loss: 0.016468163579702377\n",
      "Iteration: 4393/10000, Loss: 0.01747211441397667\n",
      "Iteration: 4394/10000, Loss: 0.012384862639009953\n",
      "Iteration: 4395/10000, Loss: 0.020807325839996338\n",
      "Iteration: 4396/10000, Loss: 0.015451114624738693\n",
      "Iteration: 4397/10000, Loss: 0.010174165479838848\n",
      "Iteration: 4398/10000, Loss: 0.010819921270012856\n",
      "Iteration: 4399/10000, Loss: 0.01497455034404993\n",
      "Iteration: 4400/10000, Loss: 0.018141288310289383\n",
      "Average test loss:  0.0026\n",
      "Iteration: 4401/10000, Loss: 0.014073407277464867\n",
      "Iteration: 4402/10000, Loss: 0.008796598762273788\n",
      "Iteration: 4403/10000, Loss: 0.013819616287946701\n",
      "Iteration: 4404/10000, Loss: 0.019355356693267822\n",
      "Iteration: 4405/10000, Loss: 0.01205414067953825\n",
      "Iteration: 4406/10000, Loss: 0.013638014905154705\n",
      "Iteration: 4407/10000, Loss: 0.01939665712416172\n",
      "Iteration: 4408/10000, Loss: 0.01650402508676052\n",
      "Iteration: 4409/10000, Loss: 0.01308535784482956\n",
      "Iteration: 4410/10000, Loss: 0.013132273219525814\n",
      "Iteration: 4411/10000, Loss: 0.013548482209444046\n",
      "Iteration: 4412/10000, Loss: 0.019591517746448517\n",
      "Iteration: 4413/10000, Loss: 0.016253337264060974\n",
      "Iteration: 4414/10000, Loss: 0.021753592416644096\n",
      "Iteration: 4415/10000, Loss: 0.015069774352014065\n",
      "Iteration: 4416/10000, Loss: 0.015542428940534592\n",
      "Iteration: 4417/10000, Loss: 0.012060189619660378\n",
      "Iteration: 4418/10000, Loss: 0.015366391278803349\n",
      "Iteration: 4419/10000, Loss: 0.011134603060781956\n",
      "Iteration: 4420/10000, Loss: 0.024596309289336205\n",
      "Iteration: 4421/10000, Loss: 0.01586202159523964\n",
      "Iteration: 4422/10000, Loss: 0.019813312217593193\n",
      "Iteration: 4423/10000, Loss: 0.010545587167143822\n",
      "Iteration: 4424/10000, Loss: 0.013644373044371605\n",
      "Iteration: 4425/10000, Loss: 0.01617964170873165\n",
      "Iteration: 4426/10000, Loss: 0.011650594882667065\n",
      "Iteration: 4427/10000, Loss: 0.013909148052334785\n",
      "Iteration: 4428/10000, Loss: 0.009967107325792313\n",
      "Iteration: 4429/10000, Loss: 0.015884682536125183\n",
      "Iteration: 4430/10000, Loss: 0.01295597292482853\n",
      "Iteration: 4431/10000, Loss: 0.012327988632023335\n",
      "Iteration: 4432/10000, Loss: 0.01482008583843708\n",
      "Iteration: 4433/10000, Loss: 0.009798204526305199\n",
      "Iteration: 4434/10000, Loss: 0.014346035197377205\n",
      "Iteration: 4435/10000, Loss: 0.01405111700296402\n",
      "Iteration: 4436/10000, Loss: 0.008271998725831509\n",
      "Iteration: 4437/10000, Loss: 0.018573252484202385\n",
      "Iteration: 4438/10000, Loss: 0.01816313900053501\n",
      "Iteration: 4439/10000, Loss: 0.015355640091001987\n",
      "Iteration: 4440/10000, Loss: 0.012918616645038128\n",
      "Iteration: 4441/10000, Loss: 0.013376973569393158\n",
      "Iteration: 4442/10000, Loss: 0.01855442300438881\n",
      "Iteration: 4443/10000, Loss: 0.017935430631041527\n",
      "Iteration: 4444/10000, Loss: 0.009088840335607529\n",
      "Iteration: 4445/10000, Loss: 0.013110832311213017\n",
      "Iteration: 4446/10000, Loss: 0.011076229624450207\n",
      "Iteration: 4447/10000, Loss: 0.01119616162031889\n",
      "Iteration: 4448/10000, Loss: 0.010646019130945206\n",
      "Iteration: 4449/10000, Loss: 0.013473989441990852\n",
      "Iteration: 4450/10000, Loss: 0.020111866295337677\n",
      "Iteration: 4451/10000, Loss: 0.008921363390982151\n",
      "Iteration: 4452/10000, Loss: 0.00871994998306036\n",
      "Iteration: 4453/10000, Loss: 0.0143390828743577\n",
      "Iteration: 4454/10000, Loss: 0.012128053233027458\n",
      "Iteration: 4455/10000, Loss: 0.013613719493150711\n",
      "Iteration: 4456/10000, Loss: 0.008978147059679031\n",
      "Iteration: 4457/10000, Loss: 0.015212021768093109\n",
      "Iteration: 4458/10000, Loss: 0.013847007416188717\n",
      "Iteration: 4459/10000, Loss: 0.013319425284862518\n",
      "Iteration: 4460/10000, Loss: 0.011800050735473633\n",
      "Iteration: 4461/10000, Loss: 0.008854142390191555\n",
      "Iteration: 4462/10000, Loss: 0.007508477196097374\n",
      "Iteration: 4463/10000, Loss: 0.015129360370337963\n",
      "Iteration: 4464/10000, Loss: 0.013529016636312008\n",
      "Iteration: 4465/10000, Loss: 0.011770620942115784\n",
      "Iteration: 4466/10000, Loss: 0.013285800814628601\n",
      "Iteration: 4467/10000, Loss: 0.018949665129184723\n",
      "Iteration: 4468/10000, Loss: 0.01454054843634367\n",
      "Iteration: 4469/10000, Loss: 0.012326434254646301\n",
      "Iteration: 4470/10000, Loss: 0.01469480898231268\n",
      "Iteration: 4471/10000, Loss: 0.013294557109475136\n",
      "Iteration: 4472/10000, Loss: 0.013733633793890476\n",
      "Iteration: 4473/10000, Loss: 0.01568782702088356\n",
      "Iteration: 4474/10000, Loss: 0.013111943379044533\n",
      "Iteration: 4475/10000, Loss: 0.00906503014266491\n",
      "Iteration: 4476/10000, Loss: 0.015060312114655972\n",
      "Iteration: 4477/10000, Loss: 0.012412389740347862\n",
      "Iteration: 4478/10000, Loss: 0.011131380684673786\n",
      "Iteration: 4479/10000, Loss: 0.016790878027677536\n",
      "Iteration: 4480/10000, Loss: 0.015305551700294018\n",
      "Iteration: 4481/10000, Loss: 0.01581733301281929\n",
      "Iteration: 4482/10000, Loss: 0.011954479850828648\n",
      "Iteration: 4483/10000, Loss: 0.013677442446351051\n",
      "Iteration: 4484/10000, Loss: 0.007933483459055424\n",
      "Iteration: 4485/10000, Loss: 0.012625901959836483\n",
      "Iteration: 4486/10000, Loss: 0.012180081568658352\n",
      "Iteration: 4487/10000, Loss: 0.017631279304623604\n",
      "Iteration: 4488/10000, Loss: 0.013917720876634121\n",
      "Iteration: 4489/10000, Loss: 0.011679628863930702\n",
      "Iteration: 4490/10000, Loss: 0.01833811216056347\n",
      "Iteration: 4491/10000, Loss: 0.015076793730258942\n",
      "Iteration: 4492/10000, Loss: 0.013862734660506248\n",
      "Iteration: 4493/10000, Loss: 0.012495707720518112\n",
      "Iteration: 4494/10000, Loss: 0.011951800435781479\n",
      "Iteration: 4495/10000, Loss: 0.010532745160162449\n",
      "Iteration: 4496/10000, Loss: 0.010769672691822052\n",
      "Iteration: 4497/10000, Loss: 0.013506419956684113\n",
      "Iteration: 4498/10000, Loss: 0.01550210639834404\n",
      "Iteration: 4499/10000, Loss: 0.013740842230618\n",
      "Iteration: 4500/10000, Loss: 0.017308592796325684\n",
      "Average test loss:  0.0032\n",
      "Iteration: 4501/10000, Loss: 0.015124245546758175\n",
      "Iteration: 4502/10000, Loss: 0.012588385492563248\n",
      "Iteration: 4503/10000, Loss: 0.010849055834114552\n",
      "Iteration: 4504/10000, Loss: 0.012504941783845425\n",
      "Iteration: 4505/10000, Loss: 0.015825198963284492\n",
      "Iteration: 4506/10000, Loss: 0.0182400643825531\n",
      "Iteration: 4507/10000, Loss: 0.014486921019852161\n",
      "Iteration: 4508/10000, Loss: 0.012380353175103664\n",
      "Iteration: 4509/10000, Loss: 0.01425859797745943\n",
      "Iteration: 4510/10000, Loss: 0.016438225284218788\n",
      "Iteration: 4511/10000, Loss: 0.012954575940966606\n",
      "Iteration: 4512/10000, Loss: 0.017161155119538307\n",
      "Iteration: 4513/10000, Loss: 0.019873294979333878\n",
      "Iteration: 4514/10000, Loss: 0.00761376041918993\n",
      "Iteration: 4515/10000, Loss: 0.010969351045787334\n",
      "Iteration: 4516/10000, Loss: 0.00979495607316494\n",
      "Iteration: 4517/10000, Loss: 0.017422962933778763\n",
      "Iteration: 4518/10000, Loss: 0.013166853226721287\n",
      "Iteration: 4519/10000, Loss: 0.014165856875479221\n",
      "Iteration: 4520/10000, Loss: 0.017882926389575005\n",
      "Iteration: 4521/10000, Loss: 0.015942176803946495\n",
      "Iteration: 4522/10000, Loss: 0.012709587812423706\n",
      "Iteration: 4523/10000, Loss: 0.008093014359474182\n",
      "Iteration: 4524/10000, Loss: 0.012487417086958885\n",
      "Iteration: 4525/10000, Loss: 0.01722407154738903\n",
      "Iteration: 4526/10000, Loss: 0.018834255635738373\n",
      "Iteration: 4527/10000, Loss: 0.018186695873737335\n",
      "Iteration: 4528/10000, Loss: 0.013028527610003948\n",
      "Iteration: 4529/10000, Loss: 0.012573514133691788\n",
      "Iteration: 4530/10000, Loss: 0.0146836768835783\n",
      "Iteration: 4531/10000, Loss: 0.015955442562699318\n",
      "Iteration: 4532/10000, Loss: 0.01883445493876934\n",
      "Iteration: 4533/10000, Loss: 0.013939328491687775\n",
      "Iteration: 4534/10000, Loss: 0.013006308116018772\n",
      "Iteration: 4535/10000, Loss: 0.0072366842068731785\n",
      "Iteration: 4536/10000, Loss: 0.018385691568255424\n",
      "Iteration: 4537/10000, Loss: 0.021644601598381996\n",
      "Iteration: 4538/10000, Loss: 0.013858651742339134\n",
      "Iteration: 4539/10000, Loss: 0.011731901206076145\n",
      "Iteration: 4540/10000, Loss: 0.009620383381843567\n",
      "Iteration: 4541/10000, Loss: 0.010991963557898998\n",
      "Iteration: 4542/10000, Loss: 0.017060332000255585\n",
      "Iteration: 4543/10000, Loss: 0.013274868950247765\n",
      "Iteration: 4544/10000, Loss: 0.00995260663330555\n",
      "Iteration: 4545/10000, Loss: 0.010270395316183567\n",
      "Iteration: 4546/10000, Loss: 0.011322843842208385\n",
      "Iteration: 4547/10000, Loss: 0.014682045206427574\n",
      "Iteration: 4548/10000, Loss: 0.022895224392414093\n",
      "Iteration: 4549/10000, Loss: 0.020057635381817818\n",
      "Iteration: 4550/10000, Loss: 0.013926707208156586\n",
      "Iteration: 4551/10000, Loss: 0.02178739383816719\n",
      "Iteration: 4552/10000, Loss: 0.013899705372750759\n",
      "Iteration: 4553/10000, Loss: 0.010646351613104343\n",
      "Iteration: 4554/10000, Loss: 0.01810675859451294\n",
      "Iteration: 4555/10000, Loss: 0.01728666014969349\n",
      "Iteration: 4556/10000, Loss: 0.008265096694231033\n",
      "Iteration: 4557/10000, Loss: 0.007657351903617382\n",
      "Iteration: 4558/10000, Loss: 0.009357484057545662\n",
      "Iteration: 4559/10000, Loss: 0.013690195046365261\n",
      "Iteration: 4560/10000, Loss: 0.014158673584461212\n",
      "Iteration: 4561/10000, Loss: 0.01892172545194626\n",
      "Iteration: 4562/10000, Loss: 0.009765200316905975\n",
      "Iteration: 4563/10000, Loss: 0.014135665260255337\n",
      "Iteration: 4564/10000, Loss: 0.014870710670948029\n",
      "Iteration: 4565/10000, Loss: 0.01532302238047123\n",
      "Iteration: 4566/10000, Loss: 0.010696690529584885\n",
      "Iteration: 4567/10000, Loss: 0.010015872307121754\n",
      "Iteration: 4568/10000, Loss: 0.01538830902427435\n",
      "Iteration: 4569/10000, Loss: 0.009007866494357586\n",
      "Iteration: 4570/10000, Loss: 0.017031071707606316\n",
      "Iteration: 4571/10000, Loss: 0.013876782730221748\n",
      "Iteration: 4572/10000, Loss: 0.014229575172066689\n",
      "Iteration: 4573/10000, Loss: 0.02075537107884884\n",
      "Iteration: 4574/10000, Loss: 0.009382161311805248\n",
      "Iteration: 4575/10000, Loss: 0.01586722955107689\n",
      "Iteration: 4576/10000, Loss: 0.012569550424814224\n",
      "Iteration: 4577/10000, Loss: 0.01411614753305912\n",
      "Iteration: 4578/10000, Loss: 0.013305054977536201\n",
      "Iteration: 4579/10000, Loss: 0.009912312030792236\n",
      "Iteration: 4580/10000, Loss: 0.010050524957478046\n",
      "Iteration: 4581/10000, Loss: 0.012040282599627972\n",
      "Iteration: 4582/10000, Loss: 0.016083868220448494\n",
      "Iteration: 4583/10000, Loss: 0.014202505350112915\n",
      "Iteration: 4584/10000, Loss: 0.010975407436490059\n",
      "Iteration: 4585/10000, Loss: 0.014326969161629677\n",
      "Iteration: 4586/10000, Loss: 0.011363239027559757\n",
      "Iteration: 4587/10000, Loss: 0.011874305084347725\n",
      "Iteration: 4588/10000, Loss: 0.01501969899982214\n",
      "Iteration: 4589/10000, Loss: 0.015032811090350151\n",
      "Iteration: 4590/10000, Loss: 0.012922358699142933\n",
      "Iteration: 4591/10000, Loss: 0.011773379519581795\n",
      "Iteration: 4592/10000, Loss: 0.010403689928352833\n",
      "Iteration: 4593/10000, Loss: 0.013737686909735203\n",
      "Iteration: 4594/10000, Loss: 0.010115480050444603\n",
      "Iteration: 4595/10000, Loss: 0.01242902036756277\n",
      "Iteration: 4596/10000, Loss: 0.015592887066304684\n",
      "Iteration: 4597/10000, Loss: 0.012066042982041836\n",
      "Iteration: 4598/10000, Loss: 0.015528096817433834\n",
      "Iteration: 4599/10000, Loss: 0.014309080317616463\n",
      "Iteration: 4600/10000, Loss: 0.011152567341923714\n",
      "Average test loss:  0.0019\n",
      "Iteration: 4601/10000, Loss: 0.0049835997633636\n",
      "Iteration: 4602/10000, Loss: 0.017518404871225357\n",
      "Iteration: 4603/10000, Loss: 0.013608626089990139\n",
      "Iteration: 4604/10000, Loss: 0.00911006424576044\n",
      "Iteration: 4605/10000, Loss: 0.01508680172264576\n",
      "Iteration: 4606/10000, Loss: 0.01391613855957985\n",
      "Iteration: 4607/10000, Loss: 0.01342049241065979\n",
      "Iteration: 4608/10000, Loss: 0.011678331531584263\n",
      "Iteration: 4609/10000, Loss: 0.017200671136379242\n",
      "Iteration: 4610/10000, Loss: 0.01750805415213108\n",
      "Iteration: 4611/10000, Loss: 0.01241550873965025\n",
      "Iteration: 4612/10000, Loss: 0.015829896554350853\n",
      "Iteration: 4613/10000, Loss: 0.012227067723870277\n",
      "Iteration: 4614/10000, Loss: 0.010968838818371296\n",
      "Iteration: 4615/10000, Loss: 0.01480422168970108\n",
      "Iteration: 4616/10000, Loss: 0.010372036136686802\n",
      "Iteration: 4617/10000, Loss: 0.01697283610701561\n",
      "Iteration: 4618/10000, Loss: 0.013624130748212337\n",
      "Iteration: 4619/10000, Loss: 0.014121352694928646\n",
      "Iteration: 4620/10000, Loss: 0.01463373750448227\n",
      "Iteration: 4621/10000, Loss: 0.01721973717212677\n",
      "Iteration: 4622/10000, Loss: 0.016434350982308388\n",
      "Iteration: 4623/10000, Loss: 0.00906964112073183\n",
      "Iteration: 4624/10000, Loss: 0.01060833502560854\n",
      "Iteration: 4625/10000, Loss: 0.008395776152610779\n",
      "Iteration: 4626/10000, Loss: 0.013614799827337265\n",
      "Iteration: 4627/10000, Loss: 0.02007172629237175\n",
      "Iteration: 4628/10000, Loss: 0.013297127559781075\n",
      "Iteration: 4629/10000, Loss: 0.011592237278819084\n",
      "Iteration: 4630/10000, Loss: 0.020028650760650635\n",
      "Iteration: 4631/10000, Loss: 0.014271306805312634\n",
      "Iteration: 4632/10000, Loss: 0.013955137692391872\n",
      "Iteration: 4633/10000, Loss: 0.0170601699501276\n",
      "Iteration: 4634/10000, Loss: 0.010416547767817974\n",
      "Iteration: 4635/10000, Loss: 0.009137459099292755\n",
      "Iteration: 4636/10000, Loss: 0.009883834980428219\n",
      "Iteration: 4637/10000, Loss: 0.01890774630010128\n",
      "Iteration: 4638/10000, Loss: 0.0142988171428442\n",
      "Iteration: 4639/10000, Loss: 0.014399450272321701\n",
      "Iteration: 4640/10000, Loss: 0.010259103961288929\n",
      "Iteration: 4641/10000, Loss: 0.017858663573861122\n",
      "Iteration: 4642/10000, Loss: 0.014980229549109936\n",
      "Iteration: 4643/10000, Loss: 0.01308040414005518\n",
      "Iteration: 4644/10000, Loss: 0.010701625607907772\n",
      "Iteration: 4645/10000, Loss: 0.010010662488639355\n",
      "Iteration: 4646/10000, Loss: 0.01417869795113802\n",
      "Iteration: 4647/10000, Loss: 0.013352014124393463\n",
      "Iteration: 4648/10000, Loss: 0.014614840969443321\n",
      "Iteration: 4649/10000, Loss: 0.01415018830448389\n",
      "Iteration: 4650/10000, Loss: 0.014891833998262882\n",
      "Iteration: 4651/10000, Loss: 0.013385280035436153\n",
      "Iteration: 4652/10000, Loss: 0.01173966284841299\n",
      "Iteration: 4653/10000, Loss: 0.011907333508133888\n",
      "Iteration: 4654/10000, Loss: 0.011859709396958351\n",
      "Iteration: 4655/10000, Loss: 0.0169941708445549\n",
      "Iteration: 4656/10000, Loss: 0.012821564450860023\n",
      "Iteration: 4657/10000, Loss: 0.022880489006638527\n",
      "Iteration: 4658/10000, Loss: 0.018930772319436073\n",
      "Iteration: 4659/10000, Loss: 0.016252225264906883\n",
      "Iteration: 4660/10000, Loss: 0.010192514397203922\n",
      "Iteration: 4661/10000, Loss: 0.011516275815665722\n",
      "Iteration: 4662/10000, Loss: 0.014451703988015652\n",
      "Iteration: 4663/10000, Loss: 0.017569463700056076\n",
      "Iteration: 4664/10000, Loss: 0.01599639095366001\n",
      "Iteration: 4665/10000, Loss: 0.012927715666592121\n",
      "Iteration: 4666/10000, Loss: 0.009012793190777302\n",
      "Iteration: 4667/10000, Loss: 0.0111428527161479\n",
      "Iteration: 4668/10000, Loss: 0.013930076733231544\n",
      "Iteration: 4669/10000, Loss: 0.016605108976364136\n",
      "Iteration: 4670/10000, Loss: 0.014023931697010994\n",
      "Iteration: 4671/10000, Loss: 0.010675004683434963\n",
      "Iteration: 4672/10000, Loss: 0.013126153498888016\n",
      "Iteration: 4673/10000, Loss: 0.01080088596791029\n",
      "Iteration: 4674/10000, Loss: 0.012557152658700943\n",
      "Iteration: 4675/10000, Loss: 0.009326393716037273\n",
      "Iteration: 4676/10000, Loss: 0.021284665912389755\n",
      "Iteration: 4677/10000, Loss: 0.008050981909036636\n",
      "Iteration: 4678/10000, Loss: 0.01174441259354353\n",
      "Iteration: 4679/10000, Loss: 0.015668002888560295\n",
      "Iteration: 4680/10000, Loss: 0.01468302495777607\n",
      "Iteration: 4681/10000, Loss: 0.009530843235552311\n",
      "Iteration: 4682/10000, Loss: 0.015484887175261974\n",
      "Iteration: 4683/10000, Loss: 0.010571149177849293\n",
      "Iteration: 4684/10000, Loss: 0.016207467764616013\n",
      "Iteration: 4685/10000, Loss: 0.010624687187373638\n",
      "Iteration: 4686/10000, Loss: 0.007507431786507368\n",
      "Iteration: 4687/10000, Loss: 0.010283153504133224\n",
      "Iteration: 4688/10000, Loss: 0.012007607147097588\n",
      "Iteration: 4689/10000, Loss: 0.01883985474705696\n",
      "Iteration: 4690/10000, Loss: 0.012901530601084232\n",
      "Iteration: 4691/10000, Loss: 0.012799748219549656\n",
      "Iteration: 4692/10000, Loss: 0.012820251286029816\n",
      "Iteration: 4693/10000, Loss: 0.014588046818971634\n",
      "Iteration: 4694/10000, Loss: 0.007247562520205975\n",
      "Iteration: 4695/10000, Loss: 0.009284197352826595\n",
      "Iteration: 4696/10000, Loss: 0.017079096287488937\n",
      "Iteration: 4697/10000, Loss: 0.01585269533097744\n",
      "Iteration: 4698/10000, Loss: 0.0163552388548851\n",
      "Iteration: 4699/10000, Loss: 0.014621051028370857\n",
      "Iteration: 4700/10000, Loss: 0.013085227459669113\n",
      "Average test loss:  0.0030\n",
      "Iteration: 4701/10000, Loss: 0.011125672608613968\n",
      "Iteration: 4702/10000, Loss: 0.016593821346759796\n",
      "Iteration: 4703/10000, Loss: 0.00857103057205677\n",
      "Iteration: 4704/10000, Loss: 0.011862296611070633\n",
      "Iteration: 4705/10000, Loss: 0.008135747164487839\n",
      "Iteration: 4706/10000, Loss: 0.011565006338059902\n",
      "Iteration: 4707/10000, Loss: 0.01821586862206459\n",
      "Iteration: 4708/10000, Loss: 0.013434288091957569\n",
      "Iteration: 4709/10000, Loss: 0.0063184103928506374\n",
      "Iteration: 4710/10000, Loss: 0.01139289140701294\n",
      "Iteration: 4711/10000, Loss: 0.00832111481577158\n",
      "Iteration: 4712/10000, Loss: 0.014821221120655537\n",
      "Iteration: 4713/10000, Loss: 0.011792385950684547\n",
      "Iteration: 4714/10000, Loss: 0.013925370760262012\n",
      "Iteration: 4715/10000, Loss: 0.011614404618740082\n",
      "Iteration: 4716/10000, Loss: 0.01387636736035347\n",
      "Iteration: 4717/10000, Loss: 0.009183960035443306\n",
      "Iteration: 4718/10000, Loss: 0.009384538978338242\n",
      "Iteration: 4719/10000, Loss: 0.011522608809173107\n",
      "Iteration: 4720/10000, Loss: 0.009649532847106457\n",
      "Iteration: 4721/10000, Loss: 0.01579192653298378\n",
      "Iteration: 4722/10000, Loss: 0.007550625130534172\n",
      "Iteration: 4723/10000, Loss: 0.011785298585891724\n",
      "Iteration: 4724/10000, Loss: 0.006073312368243933\n",
      "Iteration: 4725/10000, Loss: 0.010462276637554169\n",
      "Iteration: 4726/10000, Loss: 0.009070662781596184\n",
      "Iteration: 4727/10000, Loss: 0.017624778673052788\n",
      "Iteration: 4728/10000, Loss: 0.009951181709766388\n",
      "Iteration: 4729/10000, Loss: 0.011854605749249458\n",
      "Iteration: 4730/10000, Loss: 0.013968108221888542\n",
      "Iteration: 4731/10000, Loss: 0.012701733969151974\n",
      "Iteration: 4732/10000, Loss: 0.01740773767232895\n",
      "Iteration: 4733/10000, Loss: 0.01318376325070858\n",
      "Iteration: 4734/10000, Loss: 0.01088944636285305\n",
      "Iteration: 4735/10000, Loss: 0.012850762344896793\n",
      "Iteration: 4736/10000, Loss: 0.012935291044414043\n",
      "Iteration: 4737/10000, Loss: 0.01131970901042223\n",
      "Iteration: 4738/10000, Loss: 0.00832410342991352\n",
      "Iteration: 4739/10000, Loss: 0.01280912384390831\n",
      "Iteration: 4740/10000, Loss: 0.0161550622433424\n",
      "Iteration: 4741/10000, Loss: 0.011777479201555252\n",
      "Iteration: 4742/10000, Loss: 0.016377467662096024\n",
      "Iteration: 4743/10000, Loss: 0.013277539052069187\n",
      "Iteration: 4744/10000, Loss: 0.00699857622385025\n",
      "Iteration: 4745/10000, Loss: 0.015086352825164795\n",
      "Iteration: 4746/10000, Loss: 0.013980049639940262\n",
      "Iteration: 4747/10000, Loss: 0.011077278293669224\n",
      "Iteration: 4748/10000, Loss: 0.017171811312437057\n",
      "Iteration: 4749/10000, Loss: 0.012514862231910229\n",
      "Iteration: 4750/10000, Loss: 0.02229936234652996\n",
      "Iteration: 4751/10000, Loss: 0.014772011898458004\n",
      "Iteration: 4752/10000, Loss: 0.014403228648006916\n",
      "Iteration: 4753/10000, Loss: 0.015289929695427418\n",
      "Iteration: 4754/10000, Loss: 0.01664535142481327\n",
      "Iteration: 4755/10000, Loss: 0.016018100082874298\n",
      "Iteration: 4756/10000, Loss: 0.010649858973920345\n",
      "Iteration: 4757/10000, Loss: 0.008489413186907768\n",
      "Iteration: 4758/10000, Loss: 0.0141270337626338\n",
      "Iteration: 4759/10000, Loss: 0.012911138124763966\n",
      "Iteration: 4760/10000, Loss: 0.01569734513759613\n",
      "Iteration: 4761/10000, Loss: 0.009715566411614418\n",
      "Iteration: 4762/10000, Loss: 0.011816807091236115\n",
      "Iteration: 4763/10000, Loss: 0.012846793979406357\n",
      "Iteration: 4764/10000, Loss: 0.013857482932507992\n",
      "Iteration: 4765/10000, Loss: 0.012785532511770725\n",
      "Iteration: 4766/10000, Loss: 0.012985601089894772\n",
      "Iteration: 4767/10000, Loss: 0.014381742104887962\n",
      "Iteration: 4768/10000, Loss: 0.01398222055286169\n",
      "Iteration: 4769/10000, Loss: 0.012642260640859604\n",
      "Iteration: 4770/10000, Loss: 0.010413140058517456\n",
      "Iteration: 4771/10000, Loss: 0.015248247422277927\n",
      "Iteration: 4772/10000, Loss: 0.010075206868350506\n",
      "Iteration: 4773/10000, Loss: 0.013355592265725136\n",
      "Iteration: 4774/10000, Loss: 0.0183090902864933\n",
      "Iteration: 4775/10000, Loss: 0.007112469524145126\n",
      "Iteration: 4776/10000, Loss: 0.015925439074635506\n",
      "Iteration: 4777/10000, Loss: 0.01315031386911869\n",
      "Iteration: 4778/10000, Loss: 0.00989437848329544\n",
      "Iteration: 4779/10000, Loss: 0.013822580687701702\n",
      "Iteration: 4780/10000, Loss: 0.007720150053501129\n",
      "Iteration: 4781/10000, Loss: 0.008824635297060013\n",
      "Iteration: 4782/10000, Loss: 0.015103877522051334\n",
      "Iteration: 4783/10000, Loss: 0.010240117087960243\n",
      "Iteration: 4784/10000, Loss: 0.011394064873456955\n",
      "Iteration: 4785/10000, Loss: 0.012526197358965874\n",
      "Iteration: 4786/10000, Loss: 0.008943231776356697\n",
      "Iteration: 4787/10000, Loss: 0.014103611931204796\n",
      "Iteration: 4788/10000, Loss: 0.012589992955327034\n",
      "Iteration: 4789/10000, Loss: 0.011248777620494366\n",
      "Iteration: 4790/10000, Loss: 0.018891964107751846\n",
      "Iteration: 4791/10000, Loss: 0.014057807624340057\n",
      "Iteration: 4792/10000, Loss: 0.013036787509918213\n",
      "Iteration: 4793/10000, Loss: 0.016662033274769783\n",
      "Iteration: 4794/10000, Loss: 0.014560508541762829\n",
      "Iteration: 4795/10000, Loss: 0.011629399843513966\n",
      "Iteration: 4796/10000, Loss: 0.01320344116538763\n",
      "Iteration: 4797/10000, Loss: 0.012812969274818897\n",
      "Iteration: 4798/10000, Loss: 0.008803746663033962\n",
      "Iteration: 4799/10000, Loss: 0.009749973192811012\n",
      "Iteration: 4800/10000, Loss: 0.008613161742687225\n",
      "Average test loss:  0.0019\n",
      "Iteration: 4801/10000, Loss: 0.01846790872514248\n",
      "Iteration: 4802/10000, Loss: 0.01839374378323555\n",
      "Iteration: 4803/10000, Loss: 0.010048266500234604\n",
      "Iteration: 4804/10000, Loss: 0.011841737665235996\n",
      "Iteration: 4805/10000, Loss: 0.019232816994190216\n",
      "Iteration: 4806/10000, Loss: 0.012901724316179752\n",
      "Iteration: 4807/10000, Loss: 0.0159908514469862\n",
      "Iteration: 4808/10000, Loss: 0.01599493809044361\n",
      "Iteration: 4809/10000, Loss: 0.010466414503753185\n",
      "Iteration: 4810/10000, Loss: 0.013977124355733395\n",
      "Iteration: 4811/10000, Loss: 0.02360941283404827\n",
      "Iteration: 4812/10000, Loss: 0.013116075657308102\n",
      "Iteration: 4813/10000, Loss: 0.012899265624582767\n",
      "Iteration: 4814/10000, Loss: 0.008226319216191769\n",
      "Iteration: 4815/10000, Loss: 0.018521955236792564\n",
      "Iteration: 4816/10000, Loss: 0.01337727252393961\n",
      "Iteration: 4817/10000, Loss: 0.012047064490616322\n",
      "Iteration: 4818/10000, Loss: 0.01512508187443018\n",
      "Iteration: 4819/10000, Loss: 0.015445981174707413\n",
      "Iteration: 4820/10000, Loss: 0.015746045857667923\n",
      "Iteration: 4821/10000, Loss: 0.017033834010362625\n",
      "Iteration: 4822/10000, Loss: 0.014480055309832096\n",
      "Iteration: 4823/10000, Loss: 0.009127121418714523\n",
      "Iteration: 4824/10000, Loss: 0.013909355737268925\n",
      "Iteration: 4825/10000, Loss: 0.013462853617966175\n",
      "Iteration: 4826/10000, Loss: 0.008665576577186584\n",
      "Iteration: 4827/10000, Loss: 0.012381566688418388\n",
      "Iteration: 4828/10000, Loss: 0.010432509705424309\n",
      "Iteration: 4829/10000, Loss: 0.019596075639128685\n",
      "Iteration: 4830/10000, Loss: 0.012568526901304722\n",
      "Iteration: 4831/10000, Loss: 0.015721037983894348\n",
      "Iteration: 4832/10000, Loss: 0.0124238645657897\n",
      "Iteration: 4833/10000, Loss: 0.013753884471952915\n",
      "Iteration: 4834/10000, Loss: 0.01813088357448578\n",
      "Iteration: 4835/10000, Loss: 0.012823029421269894\n",
      "Iteration: 4836/10000, Loss: 0.014589104801416397\n",
      "Iteration: 4837/10000, Loss: 0.015520181506872177\n",
      "Iteration: 4838/10000, Loss: 0.01642259955406189\n",
      "Iteration: 4839/10000, Loss: 0.013071645982563496\n",
      "Iteration: 4840/10000, Loss: 0.012932371348142624\n",
      "Iteration: 4841/10000, Loss: 0.007125732488930225\n",
      "Iteration: 4842/10000, Loss: 0.008730446919798851\n",
      "Iteration: 4843/10000, Loss: 0.011224915273487568\n",
      "Iteration: 4844/10000, Loss: 0.01262811478227377\n",
      "Iteration: 4845/10000, Loss: 0.011239688843488693\n",
      "Iteration: 4846/10000, Loss: 0.01660456508398056\n",
      "Iteration: 4847/10000, Loss: 0.010878222994506359\n",
      "Iteration: 4848/10000, Loss: 0.008808028884232044\n",
      "Iteration: 4849/10000, Loss: 0.009882633574306965\n",
      "Iteration: 4850/10000, Loss: 0.020199332386255264\n",
      "Iteration: 4851/10000, Loss: 0.013156535103917122\n",
      "Iteration: 4852/10000, Loss: 0.011210435070097446\n",
      "Iteration: 4853/10000, Loss: 0.010316134430468082\n",
      "Iteration: 4854/10000, Loss: 0.013007564470171928\n",
      "Iteration: 4855/10000, Loss: 0.008751073852181435\n",
      "Iteration: 4856/10000, Loss: 0.012764561921358109\n",
      "Iteration: 4857/10000, Loss: 0.009851595386862755\n",
      "Iteration: 4858/10000, Loss: 0.014961585402488708\n",
      "Iteration: 4859/10000, Loss: 0.014608167111873627\n",
      "Iteration: 4860/10000, Loss: 0.014828363433480263\n",
      "Iteration: 4861/10000, Loss: 0.011008559726178646\n",
      "Iteration: 4862/10000, Loss: 0.017012175172567368\n",
      "Iteration: 4863/10000, Loss: 0.02006426826119423\n",
      "Iteration: 4864/10000, Loss: 0.011553946882486343\n",
      "Iteration: 4865/10000, Loss: 0.015773802995681763\n",
      "Iteration: 4866/10000, Loss: 0.011851996183395386\n",
      "Iteration: 4867/10000, Loss: 0.008576241321861744\n",
      "Iteration: 4868/10000, Loss: 0.014714747667312622\n",
      "Iteration: 4869/10000, Loss: 0.019310111179947853\n",
      "Iteration: 4870/10000, Loss: 0.018370062112808228\n",
      "Iteration: 4871/10000, Loss: 0.014072115533053875\n",
      "Iteration: 4872/10000, Loss: 0.009510188363492489\n",
      "Iteration: 4873/10000, Loss: 0.008763196878135204\n",
      "Iteration: 4874/10000, Loss: 0.015071294270455837\n",
      "Iteration: 4875/10000, Loss: 0.013195378705859184\n",
      "Iteration: 4876/10000, Loss: 0.01773921772837639\n",
      "Iteration: 4877/10000, Loss: 0.011984361335635185\n",
      "Iteration: 4878/10000, Loss: 0.015360241755843163\n",
      "Iteration: 4879/10000, Loss: 0.01087210513651371\n",
      "Iteration: 4880/10000, Loss: 0.01404110249131918\n",
      "Iteration: 4881/10000, Loss: 0.014854701235890388\n",
      "Iteration: 4882/10000, Loss: 0.019705507904291153\n",
      "Iteration: 4883/10000, Loss: 0.009557770565152168\n",
      "Iteration: 4884/10000, Loss: 0.014373558573424816\n",
      "Iteration: 4885/10000, Loss: 0.0116819366812706\n",
      "Iteration: 4886/10000, Loss: 0.015610400587320328\n",
      "Iteration: 4887/10000, Loss: 0.013129009865224361\n",
      "Iteration: 4888/10000, Loss: 0.009161367081105709\n",
      "Iteration: 4889/10000, Loss: 0.014902913942933083\n",
      "Iteration: 4890/10000, Loss: 0.011587289161980152\n",
      "Iteration: 4891/10000, Loss: 0.01841633766889572\n",
      "Iteration: 4892/10000, Loss: 0.008195818401873112\n",
      "Iteration: 4893/10000, Loss: 0.009106380864977837\n",
      "Iteration: 4894/10000, Loss: 0.010644867084920406\n",
      "Iteration: 4895/10000, Loss: 0.017143409699201584\n",
      "Iteration: 4896/10000, Loss: 0.01044144295156002\n",
      "Iteration: 4897/10000, Loss: 0.01314877811819315\n",
      "Iteration: 4898/10000, Loss: 0.012266267091035843\n",
      "Iteration: 4899/10000, Loss: 0.010728930123150349\n",
      "Iteration: 4900/10000, Loss: 0.011778109706938267\n",
      "Average test loss:  0.0034\n",
      "Iteration: 4901/10000, Loss: 0.01494375430047512\n",
      "Iteration: 4902/10000, Loss: 0.01139831729233265\n",
      "Iteration: 4903/10000, Loss: 0.011965504847466946\n",
      "Iteration: 4904/10000, Loss: 0.015045104548335075\n",
      "Iteration: 4905/10000, Loss: 0.013619432225823402\n",
      "Iteration: 4906/10000, Loss: 0.008259437046945095\n",
      "Iteration: 4907/10000, Loss: 0.013442294672131538\n",
      "Iteration: 4908/10000, Loss: 0.013948574662208557\n",
      "Iteration: 4909/10000, Loss: 0.010986821725964546\n",
      "Iteration: 4910/10000, Loss: 0.011282841674983501\n",
      "Iteration: 4911/10000, Loss: 0.011324368417263031\n",
      "Iteration: 4912/10000, Loss: 0.012170645408332348\n",
      "Iteration: 4913/10000, Loss: 0.011670748703181744\n",
      "Iteration: 4914/10000, Loss: 0.01680617779493332\n",
      "Iteration: 4915/10000, Loss: 0.009306303225457668\n",
      "Iteration: 4916/10000, Loss: 0.015607144683599472\n",
      "Iteration: 4917/10000, Loss: 0.01204169075936079\n",
      "Iteration: 4918/10000, Loss: 0.015360609628260136\n",
      "Iteration: 4919/10000, Loss: 0.013603589497506618\n",
      "Iteration: 4920/10000, Loss: 0.009341375902295113\n",
      "Iteration: 4921/10000, Loss: 0.013843712396919727\n",
      "Iteration: 4922/10000, Loss: 0.009732221253216267\n",
      "Iteration: 4923/10000, Loss: 0.015581833198666573\n",
      "Iteration: 4924/10000, Loss: 0.011157097294926643\n",
      "Iteration: 4925/10000, Loss: 0.01179401483386755\n",
      "Iteration: 4926/10000, Loss: 0.012678147293627262\n",
      "Iteration: 4927/10000, Loss: 0.016685176640748978\n",
      "Iteration: 4928/10000, Loss: 0.01279790885746479\n",
      "Iteration: 4929/10000, Loss: 0.009720816276967525\n",
      "Iteration: 4930/10000, Loss: 0.018775632604956627\n",
      "Iteration: 4931/10000, Loss: 0.014959101565182209\n",
      "Iteration: 4932/10000, Loss: 0.012192338705062866\n",
      "Iteration: 4933/10000, Loss: 0.011270254850387573\n",
      "Iteration: 4934/10000, Loss: 0.014429517090320587\n",
      "Iteration: 4935/10000, Loss: 0.008160186000168324\n",
      "Iteration: 4936/10000, Loss: 0.01318659633398056\n",
      "Iteration: 4937/10000, Loss: 0.010565337724983692\n",
      "Iteration: 4938/10000, Loss: 0.014636293053627014\n",
      "Iteration: 4939/10000, Loss: 0.012465820647776127\n",
      "Iteration: 4940/10000, Loss: 0.014424852095544338\n",
      "Iteration: 4941/10000, Loss: 0.015415520407259464\n",
      "Iteration: 4942/10000, Loss: 0.014982271939516068\n",
      "Iteration: 4943/10000, Loss: 0.014631849713623524\n",
      "Iteration: 4944/10000, Loss: 0.019824719056487083\n",
      "Iteration: 4945/10000, Loss: 0.01228223368525505\n",
      "Iteration: 4946/10000, Loss: 0.019007636234164238\n",
      "Iteration: 4947/10000, Loss: 0.013203876093029976\n",
      "Iteration: 4948/10000, Loss: 0.012697860598564148\n",
      "Iteration: 4949/10000, Loss: 0.017120804637670517\n",
      "Iteration: 4950/10000, Loss: 0.011945052072405815\n",
      "Iteration: 4951/10000, Loss: 0.01481882855296135\n",
      "Iteration: 4952/10000, Loss: 0.008491018787026405\n",
      "Iteration: 4953/10000, Loss: 0.0154277253895998\n",
      "Iteration: 4954/10000, Loss: 0.01613808237016201\n",
      "Iteration: 4955/10000, Loss: 0.01285509578883648\n",
      "Iteration: 4956/10000, Loss: 0.019655006006360054\n",
      "Iteration: 4957/10000, Loss: 0.016883308067917824\n",
      "Iteration: 4958/10000, Loss: 0.014442774467170238\n",
      "Iteration: 4959/10000, Loss: 0.014627351425588131\n",
      "Iteration: 4960/10000, Loss: 0.015759456902742386\n",
      "Iteration: 4961/10000, Loss: 0.007931680418550968\n",
      "Iteration: 4962/10000, Loss: 0.014079504646360874\n",
      "Iteration: 4963/10000, Loss: 0.008273308165371418\n",
      "Iteration: 4964/10000, Loss: 0.012407703325152397\n",
      "Iteration: 4965/10000, Loss: 0.013553271070122719\n",
      "Iteration: 4966/10000, Loss: 0.016745660454034805\n",
      "Iteration: 4967/10000, Loss: 0.00778536219149828\n",
      "Iteration: 4968/10000, Loss: 0.013548051938414574\n",
      "Iteration: 4969/10000, Loss: 0.014074613340198994\n",
      "Iteration: 4970/10000, Loss: 0.014549522660672665\n",
      "Iteration: 4971/10000, Loss: 0.01891034096479416\n",
      "Iteration: 4972/10000, Loss: 0.019381042569875717\n",
      "Iteration: 4973/10000, Loss: 0.013101997785270214\n",
      "Iteration: 4974/10000, Loss: 0.016422921791672707\n",
      "Iteration: 4975/10000, Loss: 0.011778046377003193\n",
      "Iteration: 4976/10000, Loss: 0.010349959135055542\n",
      "Iteration: 4977/10000, Loss: 0.013059413060545921\n",
      "Iteration: 4978/10000, Loss: 0.01600749045610428\n",
      "Iteration: 4979/10000, Loss: 0.009244869463145733\n",
      "Iteration: 4980/10000, Loss: 0.014023593626916409\n",
      "Iteration: 4981/10000, Loss: 0.009781146422028542\n",
      "Iteration: 4982/10000, Loss: 0.012979448772966862\n",
      "Iteration: 4983/10000, Loss: 0.015229255892336369\n",
      "Iteration: 4984/10000, Loss: 0.010960274375975132\n",
      "Iteration: 4985/10000, Loss: 0.011489566415548325\n",
      "Iteration: 4986/10000, Loss: 0.014462839812040329\n",
      "Iteration: 4987/10000, Loss: 0.01878039725124836\n",
      "Iteration: 4988/10000, Loss: 0.013875694945454597\n",
      "Iteration: 4989/10000, Loss: 0.009639257565140724\n",
      "Iteration: 4990/10000, Loss: 0.012192058376967907\n",
      "Iteration: 4991/10000, Loss: 0.01651197299361229\n",
      "Iteration: 4992/10000, Loss: 0.012534425593912601\n",
      "Iteration: 4993/10000, Loss: 0.01770958863198757\n",
      "Iteration: 4994/10000, Loss: 0.008424879983067513\n",
      "Iteration: 4995/10000, Loss: 0.01629711501300335\n",
      "Iteration: 4996/10000, Loss: 0.013210881501436234\n",
      "Iteration: 4997/10000, Loss: 0.01405360084027052\n",
      "Iteration: 4998/10000, Loss: 0.016632040962576866\n",
      "Iteration: 4999/10000, Loss: 0.009443335235118866\n",
      "Iteration: 5000/10000, Loss: 0.008660868741571903\n",
      "Average test loss:  0.0032\n",
      "Iteration: 5001/10000, Loss: 0.011337748728692532\n",
      "Iteration: 5002/10000, Loss: 0.01763804815709591\n",
      "Iteration: 5003/10000, Loss: 0.012592531740665436\n",
      "Iteration: 5004/10000, Loss: 0.010005888529121876\n",
      "Iteration: 5005/10000, Loss: 0.01191631332039833\n",
      "Iteration: 5006/10000, Loss: 0.013685221783816814\n",
      "Iteration: 5007/10000, Loss: 0.013667970895767212\n",
      "Iteration: 5008/10000, Loss: 0.01265717577189207\n",
      "Iteration: 5009/10000, Loss: 0.00901851337403059\n",
      "Iteration: 5010/10000, Loss: 0.010384375229477882\n",
      "Iteration: 5011/10000, Loss: 0.013479731976985931\n",
      "Iteration: 5012/10000, Loss: 0.017730282619595528\n",
      "Iteration: 5013/10000, Loss: 0.016527749598026276\n",
      "Iteration: 5014/10000, Loss: 0.01567164435982704\n",
      "Iteration: 5015/10000, Loss: 0.010900536552071571\n",
      "Iteration: 5016/10000, Loss: 0.010476570576429367\n",
      "Iteration: 5017/10000, Loss: 0.012119641527533531\n",
      "Iteration: 5018/10000, Loss: 0.011177905835211277\n",
      "Iteration: 5019/10000, Loss: 0.005535507574677467\n",
      "Iteration: 5020/10000, Loss: 0.012447346933186054\n",
      "Iteration: 5021/10000, Loss: 0.011039363220334053\n",
      "Iteration: 5022/10000, Loss: 0.013288798741996288\n",
      "Iteration: 5023/10000, Loss: 0.0063384766690433025\n",
      "Iteration: 5024/10000, Loss: 0.013581860810518265\n",
      "Iteration: 5025/10000, Loss: 0.007907378487288952\n",
      "Iteration: 5026/10000, Loss: 0.01502186805009842\n",
      "Iteration: 5027/10000, Loss: 0.007883861660957336\n",
      "Iteration: 5028/10000, Loss: 0.011830124072730541\n",
      "Iteration: 5029/10000, Loss: 0.01520340982824564\n",
      "Iteration: 5030/10000, Loss: 0.011788527481257915\n",
      "Iteration: 5031/10000, Loss: 0.01502543967217207\n",
      "Iteration: 5032/10000, Loss: 0.008428222499787807\n",
      "Iteration: 5033/10000, Loss: 0.008812341839075089\n",
      "Iteration: 5034/10000, Loss: 0.016424046829342842\n",
      "Iteration: 5035/10000, Loss: 0.011699361726641655\n",
      "Iteration: 5036/10000, Loss: 0.009988756850361824\n",
      "Iteration: 5037/10000, Loss: 0.014290391467511654\n",
      "Iteration: 5038/10000, Loss: 0.00843701884150505\n",
      "Iteration: 5039/10000, Loss: 0.011067895218729973\n",
      "Iteration: 5040/10000, Loss: 0.01570211350917816\n",
      "Iteration: 5041/10000, Loss: 0.013739937916398048\n",
      "Iteration: 5042/10000, Loss: 0.011014449410140514\n",
      "Iteration: 5043/10000, Loss: 0.01965976692736149\n",
      "Iteration: 5044/10000, Loss: 0.01788337342441082\n",
      "Iteration: 5045/10000, Loss: 0.01685437560081482\n",
      "Iteration: 5046/10000, Loss: 0.012918896041810513\n",
      "Iteration: 5047/10000, Loss: 0.015127388760447502\n",
      "Iteration: 5048/10000, Loss: 0.010734871961176395\n",
      "Iteration: 5049/10000, Loss: 0.014927126467227936\n",
      "Iteration: 5050/10000, Loss: 0.014650457538664341\n",
      "Iteration: 5051/10000, Loss: 0.015853170305490494\n",
      "Iteration: 5052/10000, Loss: 0.011130116879940033\n",
      "Iteration: 5053/10000, Loss: 0.007677065674215555\n",
      "Iteration: 5054/10000, Loss: 0.01141001284122467\n",
      "Iteration: 5055/10000, Loss: 0.012762077152729034\n",
      "Iteration: 5056/10000, Loss: 0.012514383532106876\n",
      "Iteration: 5057/10000, Loss: 0.012447220273315907\n",
      "Iteration: 5058/10000, Loss: 0.013567681424319744\n",
      "Iteration: 5059/10000, Loss: 0.014510447159409523\n",
      "Iteration: 5060/10000, Loss: 0.01343724224716425\n",
      "Iteration: 5061/10000, Loss: 0.01631256565451622\n",
      "Iteration: 5062/10000, Loss: 0.017351914197206497\n",
      "Iteration: 5063/10000, Loss: 0.009224679321050644\n",
      "Iteration: 5064/10000, Loss: 0.01761537790298462\n",
      "Iteration: 5065/10000, Loss: 0.008515867404639721\n",
      "Iteration: 5066/10000, Loss: 0.016897404566407204\n",
      "Iteration: 5067/10000, Loss: 0.01409824751317501\n",
      "Iteration: 5068/10000, Loss: 0.017470605671405792\n",
      "Iteration: 5069/10000, Loss: 0.009110983461141586\n",
      "Iteration: 5070/10000, Loss: 0.011932381428778172\n",
      "Iteration: 5071/10000, Loss: 0.012289962731301785\n",
      "Iteration: 5072/10000, Loss: 0.013369185850024223\n",
      "Iteration: 5073/10000, Loss: 0.01571088284254074\n",
      "Iteration: 5074/10000, Loss: 0.016415273770689964\n",
      "Iteration: 5075/10000, Loss: 0.00926065444946289\n",
      "Iteration: 5076/10000, Loss: 0.00826498307287693\n",
      "Iteration: 5077/10000, Loss: 0.0167718343436718\n",
      "Iteration: 5078/10000, Loss: 0.013789554126560688\n",
      "Iteration: 5079/10000, Loss: 0.011692672036588192\n",
      "Iteration: 5080/10000, Loss: 0.0100927222520113\n",
      "Iteration: 5081/10000, Loss: 0.008054126985371113\n",
      "Iteration: 5082/10000, Loss: 0.015342936851084232\n",
      "Iteration: 5083/10000, Loss: 0.013074700720608234\n",
      "Iteration: 5084/10000, Loss: 0.021215714514255524\n",
      "Iteration: 5085/10000, Loss: 0.014942724257707596\n",
      "Iteration: 5086/10000, Loss: 0.015405014157295227\n",
      "Iteration: 5087/10000, Loss: 0.00855799950659275\n",
      "Iteration: 5088/10000, Loss: 0.01475314237177372\n",
      "Iteration: 5089/10000, Loss: 0.009964244440197945\n",
      "Iteration: 5090/10000, Loss: 0.016630882397294044\n",
      "Iteration: 5091/10000, Loss: 0.011660444550216198\n",
      "Iteration: 5092/10000, Loss: 0.013865935616195202\n",
      "Iteration: 5093/10000, Loss: 0.00736123276874423\n",
      "Iteration: 5094/10000, Loss: 0.01179055031388998\n",
      "Iteration: 5095/10000, Loss: 0.01038682647049427\n",
      "Iteration: 5096/10000, Loss: 0.010969998314976692\n",
      "Iteration: 5097/10000, Loss: 0.014642134308815002\n",
      "Iteration: 5098/10000, Loss: 0.008681696839630604\n",
      "Iteration: 5099/10000, Loss: 0.010081090964376926\n",
      "Iteration: 5100/10000, Loss: 0.01088338065892458\n",
      "Average test loss:  0.0042\n",
      "Iteration: 5101/10000, Loss: 0.0063877105712890625\n",
      "Iteration: 5102/10000, Loss: 0.013488623313605785\n",
      "Iteration: 5103/10000, Loss: 0.008253021165728569\n",
      "Iteration: 5104/10000, Loss: 0.017488554120063782\n",
      "Iteration: 5105/10000, Loss: 0.009005638770759106\n",
      "Iteration: 5106/10000, Loss: 0.011967712081968784\n",
      "Iteration: 5107/10000, Loss: 0.013783383183181286\n",
      "Iteration: 5108/10000, Loss: 0.01520142238587141\n",
      "Iteration: 5109/10000, Loss: 0.008958660066127777\n",
      "Iteration: 5110/10000, Loss: 0.01843455247581005\n",
      "Iteration: 5111/10000, Loss: 0.012252653017640114\n",
      "Iteration: 5112/10000, Loss: 0.01773245632648468\n",
      "Iteration: 5113/10000, Loss: 0.011925194412469864\n",
      "Iteration: 5114/10000, Loss: 0.01766989752650261\n",
      "Iteration: 5115/10000, Loss: 0.00988499540835619\n",
      "Iteration: 5116/10000, Loss: 0.01207059994339943\n",
      "Iteration: 5117/10000, Loss: 0.01785268820822239\n",
      "Iteration: 5118/10000, Loss: 0.009607010520994663\n",
      "Iteration: 5119/10000, Loss: 0.012657858431339264\n",
      "Iteration: 5120/10000, Loss: 0.012940996326506138\n",
      "Iteration: 5121/10000, Loss: 0.014220417477190495\n",
      "Iteration: 5122/10000, Loss: 0.012219029478728771\n",
      "Iteration: 5123/10000, Loss: 0.013815403915941715\n",
      "Iteration: 5124/10000, Loss: 0.008837489411234856\n",
      "Iteration: 5125/10000, Loss: 0.012095240876078606\n",
      "Iteration: 5126/10000, Loss: 0.012930837459862232\n",
      "Iteration: 5127/10000, Loss: 0.014387915842235088\n",
      "Iteration: 5128/10000, Loss: 0.017923999577760696\n",
      "Iteration: 5129/10000, Loss: 0.01055856142193079\n",
      "Iteration: 5130/10000, Loss: 0.010185879655182362\n",
      "Iteration: 5131/10000, Loss: 0.009788408875465393\n",
      "Iteration: 5132/10000, Loss: 0.014921064488589764\n",
      "Iteration: 5133/10000, Loss: 0.008832398802042007\n",
      "Iteration: 5134/10000, Loss: 0.010528351180255413\n",
      "Iteration: 5135/10000, Loss: 0.010305171832442284\n",
      "Iteration: 5136/10000, Loss: 0.025494830682873726\n",
      "Iteration: 5137/10000, Loss: 0.010848346166312695\n",
      "Iteration: 5138/10000, Loss: 0.00904855690896511\n",
      "Iteration: 5139/10000, Loss: 0.010570026002824306\n",
      "Iteration: 5140/10000, Loss: 0.011598346754908562\n",
      "Iteration: 5141/10000, Loss: 0.015063302591443062\n",
      "Iteration: 5142/10000, Loss: 0.012185626663267612\n",
      "Iteration: 5143/10000, Loss: 0.014966575428843498\n",
      "Iteration: 5144/10000, Loss: 0.01545904204249382\n",
      "Iteration: 5145/10000, Loss: 0.012620128691196442\n",
      "Iteration: 5146/10000, Loss: 0.014945236966013908\n",
      "Iteration: 5147/10000, Loss: 0.01158731710165739\n",
      "Iteration: 5148/10000, Loss: 0.01419187430292368\n",
      "Iteration: 5149/10000, Loss: 0.006107422057539225\n",
      "Iteration: 5150/10000, Loss: 0.011024395935237408\n",
      "Iteration: 5151/10000, Loss: 0.01688258908689022\n",
      "Iteration: 5152/10000, Loss: 0.013430172577500343\n",
      "Iteration: 5153/10000, Loss: 0.006826924625784159\n",
      "Iteration: 5154/10000, Loss: 0.00789359025657177\n",
      "Iteration: 5155/10000, Loss: 0.008721944876015186\n",
      "Iteration: 5156/10000, Loss: 0.007436450105160475\n",
      "Iteration: 5157/10000, Loss: 0.01082862913608551\n",
      "Iteration: 5158/10000, Loss: 0.010712647810578346\n",
      "Iteration: 5159/10000, Loss: 0.009675861336290836\n",
      "Iteration: 5160/10000, Loss: 0.015000317245721817\n",
      "Iteration: 5161/10000, Loss: 0.012294137850403786\n",
      "Iteration: 5162/10000, Loss: 0.013134913519024849\n",
      "Iteration: 5163/10000, Loss: 0.014735103584825993\n",
      "Iteration: 5164/10000, Loss: 0.007651377469301224\n",
      "Iteration: 5165/10000, Loss: 0.008547076024115086\n",
      "Iteration: 5166/10000, Loss: 0.008392274379730225\n",
      "Iteration: 5167/10000, Loss: 0.01605430245399475\n",
      "Iteration: 5168/10000, Loss: 0.01581914722919464\n",
      "Iteration: 5169/10000, Loss: 0.009592762216925621\n",
      "Iteration: 5170/10000, Loss: 0.01772002875804901\n",
      "Iteration: 5171/10000, Loss: 0.011897340416908264\n",
      "Iteration: 5172/10000, Loss: 0.004786726087331772\n",
      "Iteration: 5173/10000, Loss: 0.016247669234871864\n",
      "Iteration: 5174/10000, Loss: 0.016329199075698853\n",
      "Iteration: 5175/10000, Loss: 0.01048021949827671\n",
      "Iteration: 5176/10000, Loss: 0.007320822682231665\n",
      "Iteration: 5177/10000, Loss: 0.015453243628144264\n",
      "Iteration: 5178/10000, Loss: 0.009741145186126232\n",
      "Iteration: 5179/10000, Loss: 0.006786431185901165\n",
      "Iteration: 5180/10000, Loss: 0.009506181813776493\n",
      "Iteration: 5181/10000, Loss: 0.012419168837368488\n",
      "Iteration: 5182/10000, Loss: 0.011663608253002167\n",
      "Iteration: 5183/10000, Loss: 0.010017558000981808\n",
      "Iteration: 5184/10000, Loss: 0.013277082704007626\n",
      "Iteration: 5185/10000, Loss: 0.010666568763554096\n",
      "Iteration: 5186/10000, Loss: 0.012045634910464287\n",
      "Iteration: 5187/10000, Loss: 0.010880510322749615\n",
      "Iteration: 5188/10000, Loss: 0.011996190994977951\n",
      "Iteration: 5189/10000, Loss: 0.006923924665898085\n",
      "Iteration: 5190/10000, Loss: 0.016077620908617973\n",
      "Iteration: 5191/10000, Loss: 0.008449718356132507\n",
      "Iteration: 5192/10000, Loss: 0.009646082296967506\n",
      "Iteration: 5193/10000, Loss: 0.015508067794144154\n",
      "Iteration: 5194/10000, Loss: 0.01484716311097145\n",
      "Iteration: 5195/10000, Loss: 0.015253003686666489\n",
      "Iteration: 5196/10000, Loss: 0.01773063838481903\n",
      "Iteration: 5197/10000, Loss: 0.0071130297146737576\n",
      "Iteration: 5198/10000, Loss: 0.009616658091545105\n",
      "Iteration: 5199/10000, Loss: 0.021357247605919838\n",
      "Iteration: 5200/10000, Loss: 0.013537915423512459\n",
      "Average test loss:  0.0036\n",
      "Iteration: 5201/10000, Loss: 0.014621664769947529\n",
      "Iteration: 5202/10000, Loss: 0.011388735845685005\n",
      "Iteration: 5203/10000, Loss: 0.00934327207505703\n",
      "Iteration: 5204/10000, Loss: 0.00964080635458231\n",
      "Iteration: 5205/10000, Loss: 0.011567245237529278\n",
      "Iteration: 5206/10000, Loss: 0.013540796935558319\n",
      "Iteration: 5207/10000, Loss: 0.013995648361742496\n",
      "Iteration: 5208/10000, Loss: 0.014318153262138367\n",
      "Iteration: 5209/10000, Loss: 0.006407263223081827\n",
      "Iteration: 5210/10000, Loss: 0.013101416639983654\n",
      "Iteration: 5211/10000, Loss: 0.015776172280311584\n",
      "Iteration: 5212/10000, Loss: 0.01328321360051632\n",
      "Iteration: 5213/10000, Loss: 0.010145287960767746\n",
      "Iteration: 5214/10000, Loss: 0.012740855105221272\n",
      "Iteration: 5215/10000, Loss: 0.008422339335083961\n",
      "Iteration: 5216/10000, Loss: 0.010214791633188725\n",
      "Iteration: 5217/10000, Loss: 0.009283583611249924\n",
      "Iteration: 5218/10000, Loss: 0.013105574995279312\n",
      "Iteration: 5219/10000, Loss: 0.009159431792795658\n",
      "Iteration: 5220/10000, Loss: 0.012947323732078075\n",
      "Iteration: 5221/10000, Loss: 0.011356261558830738\n",
      "Iteration: 5222/10000, Loss: 0.01415223628282547\n",
      "Iteration: 5223/10000, Loss: 0.012484905309975147\n",
      "Iteration: 5224/10000, Loss: 0.012338479049503803\n",
      "Iteration: 5225/10000, Loss: 0.011512519791722298\n",
      "Iteration: 5226/10000, Loss: 0.014680269174277782\n",
      "Iteration: 5227/10000, Loss: 0.012103325687348843\n",
      "Iteration: 5228/10000, Loss: 0.013658883050084114\n",
      "Iteration: 5229/10000, Loss: 0.017232514917850494\n",
      "Iteration: 5230/10000, Loss: 0.012943831272423267\n",
      "Iteration: 5231/10000, Loss: 0.008549937978386879\n",
      "Iteration: 5232/10000, Loss: 0.012147403322160244\n",
      "Iteration: 5233/10000, Loss: 0.013531520962715149\n",
      "Iteration: 5234/10000, Loss: 0.01104715745896101\n",
      "Iteration: 5235/10000, Loss: 0.010768996551632881\n",
      "Iteration: 5236/10000, Loss: 0.013941026292741299\n",
      "Iteration: 5237/10000, Loss: 0.012536485679447651\n",
      "Iteration: 5238/10000, Loss: 0.012407143600285053\n",
      "Iteration: 5239/10000, Loss: 0.011662047356367111\n",
      "Iteration: 5240/10000, Loss: 0.0157596617937088\n",
      "Iteration: 5241/10000, Loss: 0.016019869595766068\n",
      "Iteration: 5242/10000, Loss: 0.012525586411356926\n",
      "Iteration: 5243/10000, Loss: 0.01091966312378645\n",
      "Iteration: 5244/10000, Loss: 0.01442810706794262\n",
      "Iteration: 5245/10000, Loss: 0.007907538674771786\n",
      "Iteration: 5246/10000, Loss: 0.010418645106256008\n",
      "Iteration: 5247/10000, Loss: 0.008403144776821136\n",
      "Iteration: 5248/10000, Loss: 0.012985899113118649\n",
      "Iteration: 5249/10000, Loss: 0.012162437662482262\n",
      "Iteration: 5250/10000, Loss: 0.012840041890740395\n",
      "Iteration: 5251/10000, Loss: 0.013820725493133068\n",
      "Iteration: 5252/10000, Loss: 0.013244214467704296\n",
      "Iteration: 5253/10000, Loss: 0.01248498447239399\n",
      "Iteration: 5254/10000, Loss: 0.010273662395775318\n",
      "Iteration: 5255/10000, Loss: 0.012339645996689796\n",
      "Iteration: 5256/10000, Loss: 0.007061520125716925\n",
      "Iteration: 5257/10000, Loss: 0.009930931031703949\n",
      "Iteration: 5258/10000, Loss: 0.01776394620537758\n",
      "Iteration: 5259/10000, Loss: 0.014603951014578342\n",
      "Iteration: 5260/10000, Loss: 0.008405979722738266\n",
      "Iteration: 5261/10000, Loss: 0.009561518207192421\n",
      "Iteration: 5262/10000, Loss: 0.01474456675350666\n",
      "Iteration: 5263/10000, Loss: 0.006365918088704348\n",
      "Iteration: 5264/10000, Loss: 0.01958305761218071\n",
      "Iteration: 5265/10000, Loss: 0.006654951721429825\n",
      "Iteration: 5266/10000, Loss: 0.005916091147810221\n",
      "Iteration: 5267/10000, Loss: 0.010088306851685047\n",
      "Iteration: 5268/10000, Loss: 0.011875293217599392\n",
      "Iteration: 5269/10000, Loss: 0.010264357551932335\n",
      "Iteration: 5270/10000, Loss: 0.011494360864162445\n",
      "Iteration: 5271/10000, Loss: 0.014136191457509995\n",
      "Iteration: 5272/10000, Loss: 0.014292266219854355\n",
      "Iteration: 5273/10000, Loss: 0.01214142981916666\n",
      "Iteration: 5274/10000, Loss: 0.014669885858893394\n",
      "Iteration: 5275/10000, Loss: 0.010189748369157314\n",
      "Iteration: 5276/10000, Loss: 0.01695961505174637\n",
      "Iteration: 5277/10000, Loss: 0.008204261772334576\n",
      "Iteration: 5278/10000, Loss: 0.016026800498366356\n",
      "Iteration: 5279/10000, Loss: 0.016498452052474022\n",
      "Iteration: 5280/10000, Loss: 0.011307759210467339\n",
      "Iteration: 5281/10000, Loss: 0.014305198565125465\n",
      "Iteration: 5282/10000, Loss: 0.008939459919929504\n",
      "Iteration: 5283/10000, Loss: 0.012933092191815376\n",
      "Iteration: 5284/10000, Loss: 0.013965780846774578\n",
      "Iteration: 5285/10000, Loss: 0.012676910497248173\n",
      "Iteration: 5286/10000, Loss: 0.013639265671372414\n",
      "Iteration: 5287/10000, Loss: 0.016658570617437363\n",
      "Iteration: 5288/10000, Loss: 0.01088378019630909\n",
      "Iteration: 5289/10000, Loss: 0.011858342215418816\n",
      "Iteration: 5290/10000, Loss: 0.011167856864631176\n",
      "Iteration: 5291/10000, Loss: 0.01282830722630024\n",
      "Iteration: 5292/10000, Loss: 0.01352889183908701\n",
      "Iteration: 5293/10000, Loss: 0.01594235934317112\n",
      "Iteration: 5294/10000, Loss: 0.007333822548389435\n",
      "Iteration: 5295/10000, Loss: 0.015377449803054333\n",
      "Iteration: 5296/10000, Loss: 0.008788595907390118\n",
      "Iteration: 5297/10000, Loss: 0.01851314678788185\n",
      "Iteration: 5298/10000, Loss: 0.01080295816063881\n",
      "Iteration: 5299/10000, Loss: 0.013885707594454288\n",
      "Iteration: 5300/10000, Loss: 0.013370458967983723\n",
      "Average test loss:  0.0011\n",
      "Iteration: 5301/10000, Loss: 0.009670333936810493\n",
      "Iteration: 5302/10000, Loss: 0.018243780359625816\n",
      "Iteration: 5303/10000, Loss: 0.008972653187811375\n",
      "Iteration: 5304/10000, Loss: 0.0090135233476758\n",
      "Iteration: 5305/10000, Loss: 0.01575392857193947\n",
      "Iteration: 5306/10000, Loss: 0.0099891172721982\n",
      "Iteration: 5307/10000, Loss: 0.009844725951552391\n",
      "Iteration: 5308/10000, Loss: 0.008112508803606033\n",
      "Iteration: 5309/10000, Loss: 0.01284911297261715\n",
      "Iteration: 5310/10000, Loss: 0.008406667970120907\n",
      "Iteration: 5311/10000, Loss: 0.0156390443444252\n",
      "Iteration: 5312/10000, Loss: 0.013497049920260906\n",
      "Iteration: 5313/10000, Loss: 0.02051728405058384\n",
      "Iteration: 5314/10000, Loss: 0.011704693548381329\n",
      "Iteration: 5315/10000, Loss: 0.01110376138240099\n",
      "Iteration: 5316/10000, Loss: 0.014121674001216888\n",
      "Iteration: 5317/10000, Loss: 0.010444645769894123\n",
      "Iteration: 5318/10000, Loss: 0.015059441328048706\n",
      "Iteration: 5319/10000, Loss: 0.013922224752604961\n",
      "Iteration: 5320/10000, Loss: 0.016143616288900375\n",
      "Iteration: 5321/10000, Loss: 0.01480250433087349\n",
      "Iteration: 5322/10000, Loss: 0.016443466767668724\n",
      "Iteration: 5323/10000, Loss: 0.008773301728069782\n",
      "Iteration: 5324/10000, Loss: 0.012282119132578373\n",
      "Iteration: 5325/10000, Loss: 0.011338585056364536\n",
      "Iteration: 5326/10000, Loss: 0.01204981654882431\n",
      "Iteration: 5327/10000, Loss: 0.009445150382816792\n",
      "Iteration: 5328/10000, Loss: 0.006403937935829163\n",
      "Iteration: 5329/10000, Loss: 0.009544174186885357\n",
      "Iteration: 5330/10000, Loss: 0.009078489616513252\n",
      "Iteration: 5331/10000, Loss: 0.012553605251014233\n",
      "Iteration: 5332/10000, Loss: 0.011843282729387283\n",
      "Iteration: 5333/10000, Loss: 0.012706608511507511\n",
      "Iteration: 5334/10000, Loss: 0.009466918185353279\n",
      "Iteration: 5335/10000, Loss: 0.010901429690420628\n",
      "Iteration: 5336/10000, Loss: 0.01226264238357544\n",
      "Iteration: 5337/10000, Loss: 0.016131142154335976\n",
      "Iteration: 5338/10000, Loss: 0.012884456664323807\n",
      "Iteration: 5339/10000, Loss: 0.00994955562055111\n",
      "Iteration: 5340/10000, Loss: 0.011894319206476212\n",
      "Iteration: 5341/10000, Loss: 0.01169571466743946\n",
      "Iteration: 5342/10000, Loss: 0.00986870564520359\n",
      "Iteration: 5343/10000, Loss: 0.013406943529844284\n",
      "Iteration: 5344/10000, Loss: 0.01483254972845316\n",
      "Iteration: 5345/10000, Loss: 0.008928692899644375\n",
      "Iteration: 5346/10000, Loss: 0.014803258702158928\n",
      "Iteration: 5347/10000, Loss: 0.0110767912119627\n",
      "Iteration: 5348/10000, Loss: 0.01672356016933918\n",
      "Iteration: 5349/10000, Loss: 0.01056879572570324\n",
      "Iteration: 5350/10000, Loss: 0.011558415368199348\n",
      "Iteration: 5351/10000, Loss: 0.009783783927559853\n",
      "Iteration: 5352/10000, Loss: 0.011522953398525715\n",
      "Iteration: 5353/10000, Loss: 0.010005894117057323\n",
      "Iteration: 5354/10000, Loss: 0.015047297812998295\n",
      "Iteration: 5355/10000, Loss: 0.010643300600349903\n",
      "Iteration: 5356/10000, Loss: 0.011736749671399593\n",
      "Iteration: 5357/10000, Loss: 0.011616568081080914\n",
      "Iteration: 5358/10000, Loss: 0.006362158805131912\n",
      "Iteration: 5359/10000, Loss: 0.01003247033804655\n",
      "Iteration: 5360/10000, Loss: 0.006487576756626368\n",
      "Iteration: 5361/10000, Loss: 0.0161847285926342\n",
      "Iteration: 5362/10000, Loss: 0.016238832846283913\n",
      "Iteration: 5363/10000, Loss: 0.012987707741558552\n",
      "Iteration: 5364/10000, Loss: 0.013583499006927013\n",
      "Iteration: 5365/10000, Loss: 0.008046318776905537\n",
      "Iteration: 5366/10000, Loss: 0.01631217449903488\n",
      "Iteration: 5367/10000, Loss: 0.010795468464493752\n",
      "Iteration: 5368/10000, Loss: 0.012320389971137047\n",
      "Iteration: 5369/10000, Loss: 0.013918209820985794\n",
      "Iteration: 5370/10000, Loss: 0.011601011268794537\n",
      "Iteration: 5371/10000, Loss: 0.011963801458477974\n",
      "Iteration: 5372/10000, Loss: 0.00910603441298008\n",
      "Iteration: 5373/10000, Loss: 0.012665457092225552\n",
      "Iteration: 5374/10000, Loss: 0.013960500247776508\n",
      "Iteration: 5375/10000, Loss: 0.014121615327894688\n",
      "Iteration: 5376/10000, Loss: 0.009722976014018059\n",
      "Iteration: 5377/10000, Loss: 0.013771172612905502\n",
      "Iteration: 5378/10000, Loss: 0.014835434034466743\n",
      "Iteration: 5379/10000, Loss: 0.008867692202329636\n",
      "Iteration: 5380/10000, Loss: 0.013373573310673237\n",
      "Iteration: 5381/10000, Loss: 0.012747944332659245\n",
      "Iteration: 5382/10000, Loss: 0.01040913537144661\n",
      "Iteration: 5383/10000, Loss: 0.014007060788571835\n",
      "Iteration: 5384/10000, Loss: 0.011654390022158623\n",
      "Iteration: 5385/10000, Loss: 0.009120618924498558\n",
      "Iteration: 5386/10000, Loss: 0.014828959479928017\n",
      "Iteration: 5387/10000, Loss: 0.01136668212711811\n",
      "Iteration: 5388/10000, Loss: 0.010689666494727135\n",
      "Iteration: 5389/10000, Loss: 0.015288786962628365\n",
      "Iteration: 5390/10000, Loss: 0.013344760052859783\n",
      "Iteration: 5391/10000, Loss: 0.012971283867955208\n",
      "Iteration: 5392/10000, Loss: 0.01176964957267046\n",
      "Iteration: 5393/10000, Loss: 0.008496436290442944\n",
      "Iteration: 5394/10000, Loss: 0.014004775322973728\n",
      "Iteration: 5395/10000, Loss: 0.0140623664483428\n",
      "Iteration: 5396/10000, Loss: 0.010498286224901676\n",
      "Iteration: 5397/10000, Loss: 0.01450510323047638\n",
      "Iteration: 5398/10000, Loss: 0.011825738474726677\n",
      "Iteration: 5399/10000, Loss: 0.00812079943716526\n",
      "Iteration: 5400/10000, Loss: 0.0060850526206195354\n",
      "Average test loss:  0.0034\n",
      "Iteration: 5401/10000, Loss: 0.009380171075463295\n",
      "Iteration: 5402/10000, Loss: 0.007615423761308193\n",
      "Iteration: 5403/10000, Loss: 0.01671202853322029\n",
      "Iteration: 5404/10000, Loss: 0.01635408215224743\n",
      "Iteration: 5405/10000, Loss: 0.009263739921152592\n",
      "Iteration: 5406/10000, Loss: 0.012482704594731331\n",
      "Iteration: 5407/10000, Loss: 0.01588568277657032\n",
      "Iteration: 5408/10000, Loss: 0.009491568431258202\n",
      "Iteration: 5409/10000, Loss: 0.011982695199549198\n",
      "Iteration: 5410/10000, Loss: 0.010965052992105484\n",
      "Iteration: 5411/10000, Loss: 0.01411467231810093\n",
      "Iteration: 5412/10000, Loss: 0.008967091329395771\n",
      "Iteration: 5413/10000, Loss: 0.011314771138131618\n",
      "Iteration: 5414/10000, Loss: 0.013869826681911945\n",
      "Iteration: 5415/10000, Loss: 0.01553150825202465\n",
      "Iteration: 5416/10000, Loss: 0.014060004614293575\n",
      "Iteration: 5417/10000, Loss: 0.010415286757051945\n",
      "Iteration: 5418/10000, Loss: 0.01055004820227623\n",
      "Iteration: 5419/10000, Loss: 0.011897256597876549\n",
      "Iteration: 5420/10000, Loss: 0.011821366846561432\n",
      "Iteration: 5421/10000, Loss: 0.01190691813826561\n",
      "Iteration: 5422/10000, Loss: 0.011647162958979607\n",
      "Iteration: 5423/10000, Loss: 0.01560346782207489\n",
      "Iteration: 5424/10000, Loss: 0.010464911349117756\n",
      "Iteration: 5425/10000, Loss: 0.00764775974676013\n",
      "Iteration: 5426/10000, Loss: 0.007464590948075056\n",
      "Iteration: 5427/10000, Loss: 0.014648807235062122\n",
      "Iteration: 5428/10000, Loss: 0.013620921410620213\n",
      "Iteration: 5429/10000, Loss: 0.01071639358997345\n",
      "Iteration: 5430/10000, Loss: 0.012079725973308086\n",
      "Iteration: 5431/10000, Loss: 0.0068979570642113686\n",
      "Iteration: 5432/10000, Loss: 0.011292435228824615\n",
      "Iteration: 5433/10000, Loss: 0.010391983203589916\n",
      "Iteration: 5434/10000, Loss: 0.011343881487846375\n",
      "Iteration: 5435/10000, Loss: 0.009860552847385406\n",
      "Iteration: 5436/10000, Loss: 0.011812061071395874\n",
      "Iteration: 5437/10000, Loss: 0.014187567867338657\n",
      "Iteration: 5438/10000, Loss: 0.01292293518781662\n",
      "Iteration: 5439/10000, Loss: 0.013699809089303017\n",
      "Iteration: 5440/10000, Loss: 0.015701275318861008\n",
      "Iteration: 5441/10000, Loss: 0.01610531285405159\n",
      "Iteration: 5442/10000, Loss: 0.010217041708528996\n",
      "Iteration: 5443/10000, Loss: 0.0134956743568182\n",
      "Iteration: 5444/10000, Loss: 0.01165254320949316\n",
      "Iteration: 5445/10000, Loss: 0.013687580823898315\n",
      "Iteration: 5446/10000, Loss: 0.008956925943493843\n",
      "Iteration: 5447/10000, Loss: 0.011516915634274483\n",
      "Iteration: 5448/10000, Loss: 0.007087739184498787\n",
      "Iteration: 5449/10000, Loss: 0.010050363838672638\n",
      "Iteration: 5450/10000, Loss: 0.012892856262624264\n",
      "Iteration: 5451/10000, Loss: 0.013398932293057442\n",
      "Iteration: 5452/10000, Loss: 0.008830232545733452\n",
      "Iteration: 5453/10000, Loss: 0.013230101205408573\n",
      "Iteration: 5454/10000, Loss: 0.013294701464474201\n",
      "Iteration: 5455/10000, Loss: 0.010578014887869358\n",
      "Iteration: 5456/10000, Loss: 0.013559774495661259\n",
      "Iteration: 5457/10000, Loss: 0.00945510994642973\n",
      "Iteration: 5458/10000, Loss: 0.006974591873586178\n",
      "Iteration: 5459/10000, Loss: 0.009641177020967007\n",
      "Iteration: 5460/10000, Loss: 0.012243656441569328\n",
      "Iteration: 5461/10000, Loss: 0.017137879505753517\n",
      "Iteration: 5462/10000, Loss: 0.012497205287218094\n",
      "Iteration: 5463/10000, Loss: 0.014274366199970245\n",
      "Iteration: 5464/10000, Loss: 0.00914340652525425\n",
      "Iteration: 5465/10000, Loss: 0.011931675486266613\n",
      "Iteration: 5466/10000, Loss: 0.010250343009829521\n",
      "Iteration: 5467/10000, Loss: 0.015866678208112717\n",
      "Iteration: 5468/10000, Loss: 0.01095893606543541\n",
      "Iteration: 5469/10000, Loss: 0.008567079901695251\n",
      "Iteration: 5470/10000, Loss: 0.008919581770896912\n",
      "Iteration: 5471/10000, Loss: 0.004467638675123453\n",
      "Iteration: 5472/10000, Loss: 0.017506612464785576\n",
      "Iteration: 5473/10000, Loss: 0.012264827266335487\n",
      "Iteration: 5474/10000, Loss: 0.015587403438985348\n",
      "Iteration: 5475/10000, Loss: 0.012875540181994438\n",
      "Iteration: 5476/10000, Loss: 0.010121655650436878\n",
      "Iteration: 5477/10000, Loss: 0.009054047055542469\n",
      "Iteration: 5478/10000, Loss: 0.008805030956864357\n",
      "Iteration: 5479/10000, Loss: 0.013680513016879559\n",
      "Iteration: 5480/10000, Loss: 0.007950594648718834\n",
      "Iteration: 5481/10000, Loss: 0.011420240625739098\n",
      "Iteration: 5482/10000, Loss: 0.011630071327090263\n",
      "Iteration: 5483/10000, Loss: 0.010686926543712616\n",
      "Iteration: 5484/10000, Loss: 0.006868066731840372\n",
      "Iteration: 5485/10000, Loss: 0.012017498724162579\n",
      "Iteration: 5486/10000, Loss: 0.011632696725428104\n",
      "Iteration: 5487/10000, Loss: 0.01496445294469595\n",
      "Iteration: 5488/10000, Loss: 0.01272613275796175\n",
      "Iteration: 5489/10000, Loss: 0.014232775196433067\n",
      "Iteration: 5490/10000, Loss: 0.013493729755282402\n",
      "Iteration: 5491/10000, Loss: 0.011387703940272331\n",
      "Iteration: 5492/10000, Loss: 0.007980603724718094\n",
      "Iteration: 5493/10000, Loss: 0.0120990676805377\n",
      "Iteration: 5494/10000, Loss: 0.013831308111548424\n",
      "Iteration: 5495/10000, Loss: 0.011286815628409386\n",
      "Iteration: 5496/10000, Loss: 0.006837005726993084\n",
      "Iteration: 5497/10000, Loss: 0.012438924983143806\n",
      "Iteration: 5498/10000, Loss: 0.010345520451664925\n",
      "Iteration: 5499/10000, Loss: 0.011870315298438072\n",
      "Iteration: 5500/10000, Loss: 0.010392280295491219\n",
      "Average test loss:  0.0013\n",
      "Iteration: 5501/10000, Loss: 0.01291926484555006\n",
      "Iteration: 5502/10000, Loss: 0.01366467121988535\n",
      "Iteration: 5503/10000, Loss: 0.01061819214373827\n",
      "Iteration: 5504/10000, Loss: 0.011223364621400833\n",
      "Iteration: 5505/10000, Loss: 0.010419453494250774\n",
      "Iteration: 5506/10000, Loss: 0.010691172443330288\n",
      "Iteration: 5507/10000, Loss: 0.013697994872927666\n",
      "Iteration: 5508/10000, Loss: 0.0076150246895849705\n",
      "Iteration: 5509/10000, Loss: 0.017113272100687027\n",
      "Iteration: 5510/10000, Loss: 0.01609388366341591\n",
      "Iteration: 5511/10000, Loss: 0.010436653159558773\n",
      "Iteration: 5512/10000, Loss: 0.016271309927105904\n",
      "Iteration: 5513/10000, Loss: 0.009653625078499317\n",
      "Iteration: 5514/10000, Loss: 0.015249021351337433\n",
      "Iteration: 5515/10000, Loss: 0.007769626099616289\n",
      "Iteration: 5516/10000, Loss: 0.011875873431563377\n",
      "Iteration: 5517/10000, Loss: 0.020656678825616837\n",
      "Iteration: 5518/10000, Loss: 0.012449816800653934\n",
      "Iteration: 5519/10000, Loss: 0.011573068797588348\n",
      "Iteration: 5520/10000, Loss: 0.008045382797718048\n",
      "Iteration: 5521/10000, Loss: 0.01348327100276947\n",
      "Iteration: 5522/10000, Loss: 0.014317391440272331\n",
      "Iteration: 5523/10000, Loss: 0.017584284767508507\n",
      "Iteration: 5524/10000, Loss: 0.011292844079434872\n",
      "Iteration: 5525/10000, Loss: 0.0072058723308146\n",
      "Iteration: 5526/10000, Loss: 0.011256134137511253\n",
      "Iteration: 5527/10000, Loss: 0.009057081304490566\n",
      "Iteration: 5528/10000, Loss: 0.006045268848538399\n",
      "Iteration: 5529/10000, Loss: 0.01120921690016985\n",
      "Iteration: 5530/10000, Loss: 0.01256980374455452\n",
      "Iteration: 5531/10000, Loss: 0.01686977967619896\n",
      "Iteration: 5532/10000, Loss: 0.005864500068128109\n",
      "Iteration: 5533/10000, Loss: 0.009518525563180447\n",
      "Iteration: 5534/10000, Loss: 0.008433830924332142\n",
      "Iteration: 5535/10000, Loss: 0.007494759745895863\n",
      "Iteration: 5536/10000, Loss: 0.011435733176767826\n",
      "Iteration: 5537/10000, Loss: 0.00969449058175087\n",
      "Iteration: 5538/10000, Loss: 0.015335637144744396\n",
      "Iteration: 5539/10000, Loss: 0.014692917466163635\n",
      "Iteration: 5540/10000, Loss: 0.012106659822165966\n",
      "Iteration: 5541/10000, Loss: 0.008705426007509232\n",
      "Iteration: 5542/10000, Loss: 0.01099538616836071\n",
      "Iteration: 5543/10000, Loss: 0.007987147197127342\n",
      "Iteration: 5544/10000, Loss: 0.011041848920285702\n",
      "Iteration: 5545/10000, Loss: 0.015069516375660896\n",
      "Iteration: 5546/10000, Loss: 0.010388318449258804\n",
      "Iteration: 5547/10000, Loss: 0.010677950456738472\n",
      "Iteration: 5548/10000, Loss: 0.01052881870418787\n",
      "Iteration: 5549/10000, Loss: 0.010370380245149136\n",
      "Iteration: 5550/10000, Loss: 0.011488235555589199\n",
      "Iteration: 5551/10000, Loss: 0.01123660709708929\n",
      "Iteration: 5552/10000, Loss: 0.011800714768469334\n",
      "Iteration: 5553/10000, Loss: 0.014828259125351906\n",
      "Iteration: 5554/10000, Loss: 0.010952658951282501\n",
      "Iteration: 5555/10000, Loss: 0.0063295550644397736\n",
      "Iteration: 5556/10000, Loss: 0.011866152286529541\n",
      "Iteration: 5557/10000, Loss: 0.01483802031725645\n",
      "Iteration: 5558/10000, Loss: 0.009793183766305447\n",
      "Iteration: 5559/10000, Loss: 0.011900430545210838\n",
      "Iteration: 5560/10000, Loss: 0.010930556803941727\n",
      "Iteration: 5561/10000, Loss: 0.007907380349934101\n",
      "Iteration: 5562/10000, Loss: 0.015504690818488598\n",
      "Iteration: 5563/10000, Loss: 0.01372032705694437\n",
      "Iteration: 5564/10000, Loss: 0.008684813976287842\n",
      "Iteration: 5565/10000, Loss: 0.008306685835123062\n",
      "Iteration: 5566/10000, Loss: 0.008401811122894287\n",
      "Iteration: 5567/10000, Loss: 0.012641658075153828\n",
      "Iteration: 5568/10000, Loss: 0.014311648905277252\n",
      "Iteration: 5569/10000, Loss: 0.01114217471331358\n",
      "Iteration: 5570/10000, Loss: 0.009695032611489296\n",
      "Iteration: 5571/10000, Loss: 0.013876959681510925\n",
      "Iteration: 5572/10000, Loss: 0.01165387686342001\n",
      "Iteration: 5573/10000, Loss: 0.015318755060434341\n",
      "Iteration: 5574/10000, Loss: 0.01051864493638277\n",
      "Iteration: 5575/10000, Loss: 0.014715038239955902\n",
      "Iteration: 5576/10000, Loss: 0.010011913254857063\n",
      "Iteration: 5577/10000, Loss: 0.012159304693341255\n",
      "Iteration: 5578/10000, Loss: 0.015086309984326363\n",
      "Iteration: 5579/10000, Loss: 0.012891339138150215\n",
      "Iteration: 5580/10000, Loss: 0.009386810474097729\n",
      "Iteration: 5581/10000, Loss: 0.00849329773336649\n",
      "Iteration: 5582/10000, Loss: 0.014419956132769585\n",
      "Iteration: 5583/10000, Loss: 0.009252886287868023\n",
      "Iteration: 5584/10000, Loss: 0.01221406739205122\n",
      "Iteration: 5585/10000, Loss: 0.009112125262618065\n",
      "Iteration: 5586/10000, Loss: 0.009709147736430168\n",
      "Iteration: 5587/10000, Loss: 0.01042195875197649\n",
      "Iteration: 5588/10000, Loss: 0.009474643506109715\n",
      "Iteration: 5589/10000, Loss: 0.012663633562624454\n",
      "Iteration: 5590/10000, Loss: 0.011200027540326118\n",
      "Iteration: 5591/10000, Loss: 0.0085072573274374\n",
      "Iteration: 5592/10000, Loss: 0.013536106795072556\n",
      "Iteration: 5593/10000, Loss: 0.013276705518364906\n",
      "Iteration: 5594/10000, Loss: 0.009850533679127693\n",
      "Iteration: 5595/10000, Loss: 0.009559720754623413\n",
      "Iteration: 5596/10000, Loss: 0.008366024121642113\n",
      "Iteration: 5597/10000, Loss: 0.014656390994787216\n",
      "Iteration: 5598/10000, Loss: 0.012752796523272991\n",
      "Iteration: 5599/10000, Loss: 0.012722267769277096\n",
      "Iteration: 5600/10000, Loss: 0.011626053601503372\n",
      "Average test loss:  0.0029\n",
      "Iteration: 5601/10000, Loss: 0.012842809781432152\n",
      "Iteration: 5602/10000, Loss: 0.01637120172381401\n",
      "Iteration: 5603/10000, Loss: 0.007170029915869236\n",
      "Iteration: 5604/10000, Loss: 0.014321566559374332\n",
      "Iteration: 5605/10000, Loss: 0.008205381222069263\n",
      "Iteration: 5606/10000, Loss: 0.012928752228617668\n",
      "Iteration: 5607/10000, Loss: 0.006466934457421303\n",
      "Iteration: 5608/10000, Loss: 0.008527485653758049\n",
      "Iteration: 5609/10000, Loss: 0.012539183720946312\n",
      "Iteration: 5610/10000, Loss: 0.012858147732913494\n",
      "Iteration: 5611/10000, Loss: 0.008830733597278595\n",
      "Iteration: 5612/10000, Loss: 0.007916389964520931\n",
      "Iteration: 5613/10000, Loss: 0.008729738183319569\n",
      "Iteration: 5614/10000, Loss: 0.015085212886333466\n",
      "Iteration: 5615/10000, Loss: 0.014691397547721863\n",
      "Iteration: 5616/10000, Loss: 0.013393580913543701\n",
      "Iteration: 5617/10000, Loss: 0.014752771705389023\n",
      "Iteration: 5618/10000, Loss: 0.011682904325425625\n",
      "Iteration: 5619/10000, Loss: 0.009036369621753693\n",
      "Iteration: 5620/10000, Loss: 0.01155157946050167\n",
      "Iteration: 5621/10000, Loss: 0.007612759247422218\n",
      "Iteration: 5622/10000, Loss: 0.013728789053857327\n",
      "Iteration: 5623/10000, Loss: 0.01161486841738224\n",
      "Iteration: 5624/10000, Loss: 0.01413203775882721\n",
      "Iteration: 5625/10000, Loss: 0.013565858826041222\n",
      "Iteration: 5626/10000, Loss: 0.009764843620359898\n",
      "Iteration: 5627/10000, Loss: 0.018033917993307114\n",
      "Iteration: 5628/10000, Loss: 0.015203981660306454\n",
      "Iteration: 5629/10000, Loss: 0.009876607917249203\n",
      "Iteration: 5630/10000, Loss: 0.01608247309923172\n",
      "Iteration: 5631/10000, Loss: 0.016093304380774498\n",
      "Iteration: 5632/10000, Loss: 0.011771240271627903\n",
      "Iteration: 5633/10000, Loss: 0.012811990454792976\n",
      "Iteration: 5634/10000, Loss: 0.01192426960915327\n",
      "Iteration: 5635/10000, Loss: 0.013736944645643234\n",
      "Iteration: 5636/10000, Loss: 0.006915030535310507\n",
      "Iteration: 5637/10000, Loss: 0.008916836231946945\n",
      "Iteration: 5638/10000, Loss: 0.01441914588212967\n",
      "Iteration: 5639/10000, Loss: 0.012061042711138725\n",
      "Iteration: 5640/10000, Loss: 0.012256906367838383\n",
      "Iteration: 5641/10000, Loss: 0.00934517290443182\n",
      "Iteration: 5642/10000, Loss: 0.012550737708806992\n",
      "Iteration: 5643/10000, Loss: 0.010775022208690643\n",
      "Iteration: 5644/10000, Loss: 0.01102080661803484\n",
      "Iteration: 5645/10000, Loss: 0.008668704889714718\n",
      "Iteration: 5646/10000, Loss: 0.0129016675055027\n",
      "Iteration: 5647/10000, Loss: 0.01331348717212677\n",
      "Iteration: 5648/10000, Loss: 0.01058217603713274\n",
      "Iteration: 5649/10000, Loss: 0.012115424498915672\n",
      "Iteration: 5650/10000, Loss: 0.009602289646863937\n",
      "Iteration: 5651/10000, Loss: 0.012807932682335377\n",
      "Iteration: 5652/10000, Loss: 0.009723872877657413\n",
      "Iteration: 5653/10000, Loss: 0.012631860561668873\n",
      "Iteration: 5654/10000, Loss: 0.00895344652235508\n",
      "Iteration: 5655/10000, Loss: 0.009440701454877853\n",
      "Iteration: 5656/10000, Loss: 0.013285012915730476\n",
      "Iteration: 5657/10000, Loss: 0.01297787670046091\n",
      "Iteration: 5658/10000, Loss: 0.016264982521533966\n",
      "Iteration: 5659/10000, Loss: 0.01089764479547739\n",
      "Iteration: 5660/10000, Loss: 0.010407759808003902\n",
      "Iteration: 5661/10000, Loss: 0.011928492225706577\n",
      "Iteration: 5662/10000, Loss: 0.012714684009552002\n",
      "Iteration: 5663/10000, Loss: 0.012394260615110397\n",
      "Iteration: 5664/10000, Loss: 0.014469416812062263\n",
      "Iteration: 5665/10000, Loss: 0.014645474962890148\n",
      "Iteration: 5666/10000, Loss: 0.014053353108465672\n",
      "Iteration: 5667/10000, Loss: 0.015803871676325798\n",
      "Iteration: 5668/10000, Loss: 0.011858289130032063\n",
      "Iteration: 5669/10000, Loss: 0.007161403074860573\n",
      "Iteration: 5670/10000, Loss: 0.009122589603066444\n",
      "Iteration: 5671/10000, Loss: 0.0061531150713562965\n",
      "Iteration: 5672/10000, Loss: 0.012850540690124035\n",
      "Iteration: 5673/10000, Loss: 0.010090299881994724\n",
      "Iteration: 5674/10000, Loss: 0.00905466265976429\n",
      "Iteration: 5675/10000, Loss: 0.009146359749138355\n",
      "Iteration: 5676/10000, Loss: 0.017283109948039055\n",
      "Iteration: 5677/10000, Loss: 0.011027052067220211\n",
      "Iteration: 5678/10000, Loss: 0.014062461443245411\n",
      "Iteration: 5679/10000, Loss: 0.0146505581215024\n",
      "Iteration: 5680/10000, Loss: 0.010668219067156315\n",
      "Iteration: 5681/10000, Loss: 0.0158162210136652\n",
      "Iteration: 5682/10000, Loss: 0.009392406791448593\n",
      "Iteration: 5683/10000, Loss: 0.0107335289940238\n",
      "Iteration: 5684/10000, Loss: 0.010408377274870872\n",
      "Iteration: 5685/10000, Loss: 0.01509291771799326\n",
      "Iteration: 5686/10000, Loss: 0.011440962553024292\n",
      "Iteration: 5687/10000, Loss: 0.009347548708319664\n",
      "Iteration: 5688/10000, Loss: 0.011109334416687489\n",
      "Iteration: 5689/10000, Loss: 0.010642320849001408\n",
      "Iteration: 5690/10000, Loss: 0.009455493651330471\n",
      "Iteration: 5691/10000, Loss: 0.009402506984770298\n",
      "Iteration: 5692/10000, Loss: 0.012458832934498787\n",
      "Iteration: 5693/10000, Loss: 0.010854397900402546\n",
      "Iteration: 5694/10000, Loss: 0.012091810815036297\n",
      "Iteration: 5695/10000, Loss: 0.009719250723719597\n",
      "Iteration: 5696/10000, Loss: 0.01000055018812418\n",
      "Iteration: 5697/10000, Loss: 0.01155609916895628\n",
      "Iteration: 5698/10000, Loss: 0.011688717640936375\n",
      "Iteration: 5699/10000, Loss: 0.012828989885747433\n",
      "Iteration: 5700/10000, Loss: 0.015973858535289764\n",
      "Average test loss:  0.0035\n",
      "Iteration: 5701/10000, Loss: 0.011683707125484943\n",
      "Iteration: 5702/10000, Loss: 0.012948758900165558\n",
      "Iteration: 5703/10000, Loss: 0.00859756674617529\n",
      "Iteration: 5704/10000, Loss: 0.014383300207555294\n",
      "Iteration: 5705/10000, Loss: 0.014013170264661312\n",
      "Iteration: 5706/10000, Loss: 0.012456781230866909\n",
      "Iteration: 5707/10000, Loss: 0.011870716698467731\n",
      "Iteration: 5708/10000, Loss: 0.008787679485976696\n",
      "Iteration: 5709/10000, Loss: 0.011709881946444511\n",
      "Iteration: 5710/10000, Loss: 0.0129615543410182\n",
      "Iteration: 5711/10000, Loss: 0.01723611354827881\n",
      "Iteration: 5712/10000, Loss: 0.016245875507593155\n",
      "Iteration: 5713/10000, Loss: 0.008664754219353199\n",
      "Iteration: 5714/10000, Loss: 0.008160384371876717\n",
      "Iteration: 5715/10000, Loss: 0.011554116383194923\n",
      "Iteration: 5716/10000, Loss: 0.013117710128426552\n",
      "Iteration: 5717/10000, Loss: 0.010070477612316608\n",
      "Iteration: 5718/10000, Loss: 0.011657345108687878\n",
      "Iteration: 5719/10000, Loss: 0.014327287673950195\n",
      "Iteration: 5720/10000, Loss: 0.009291105903685093\n",
      "Iteration: 5721/10000, Loss: 0.012155952863395214\n",
      "Iteration: 5722/10000, Loss: 0.00557521590963006\n",
      "Iteration: 5723/10000, Loss: 0.00921606458723545\n",
      "Iteration: 5724/10000, Loss: 0.00943516381084919\n",
      "Iteration: 5725/10000, Loss: 0.014792652800679207\n",
      "Iteration: 5726/10000, Loss: 0.011478184722363949\n",
      "Iteration: 5727/10000, Loss: 0.008592724800109863\n",
      "Iteration: 5728/10000, Loss: 0.013006147928535938\n",
      "Iteration: 5729/10000, Loss: 0.005877630785107613\n",
      "Iteration: 5730/10000, Loss: 0.015331124886870384\n",
      "Iteration: 5731/10000, Loss: 0.02053249627351761\n",
      "Iteration: 5732/10000, Loss: 0.013020006939768791\n",
      "Iteration: 5733/10000, Loss: 0.009754474274814129\n",
      "Iteration: 5734/10000, Loss: 0.014176570810377598\n",
      "Iteration: 5735/10000, Loss: 0.018681654706597328\n",
      "Iteration: 5736/10000, Loss: 0.005728613119572401\n",
      "Iteration: 5737/10000, Loss: 0.008036484010517597\n",
      "Iteration: 5738/10000, Loss: 0.011022422462701797\n",
      "Iteration: 5739/10000, Loss: 0.011539054103195667\n",
      "Iteration: 5740/10000, Loss: 0.008307242766022682\n",
      "Iteration: 5741/10000, Loss: 0.012734819203615189\n",
      "Iteration: 5742/10000, Loss: 0.011549857445061207\n",
      "Iteration: 5743/10000, Loss: 0.012647928670048714\n",
      "Iteration: 5744/10000, Loss: 0.011607838794589043\n",
      "Iteration: 5745/10000, Loss: 0.011723093688488007\n",
      "Iteration: 5746/10000, Loss: 0.01203150674700737\n",
      "Iteration: 5747/10000, Loss: 0.012772549875080585\n",
      "Iteration: 5748/10000, Loss: 0.017200840637087822\n",
      "Iteration: 5749/10000, Loss: 0.01232072152197361\n",
      "Iteration: 5750/10000, Loss: 0.012684904970228672\n",
      "Iteration: 5751/10000, Loss: 0.008592821657657623\n",
      "Iteration: 5752/10000, Loss: 0.010518517345190048\n",
      "Iteration: 5753/10000, Loss: 0.011714358814060688\n",
      "Iteration: 5754/10000, Loss: 0.01215409580618143\n",
      "Iteration: 5755/10000, Loss: 0.016413163393735886\n",
      "Iteration: 5756/10000, Loss: 0.0063560656271874905\n",
      "Iteration: 5757/10000, Loss: 0.0160063523799181\n",
      "Iteration: 5758/10000, Loss: 0.010775670409202576\n",
      "Iteration: 5759/10000, Loss: 0.009846581146121025\n",
      "Iteration: 5760/10000, Loss: 0.01123655866831541\n",
      "Iteration: 5761/10000, Loss: 0.011874796822667122\n",
      "Iteration: 5762/10000, Loss: 0.008203173987567425\n",
      "Iteration: 5763/10000, Loss: 0.009061373770236969\n",
      "Iteration: 5764/10000, Loss: 0.011038319207727909\n",
      "Iteration: 5765/10000, Loss: 0.006642383988946676\n",
      "Iteration: 5766/10000, Loss: 0.011992577463388443\n",
      "Iteration: 5767/10000, Loss: 0.019436385482549667\n",
      "Iteration: 5768/10000, Loss: 0.0109294718131423\n",
      "Iteration: 5769/10000, Loss: 0.012860752642154694\n",
      "Iteration: 5770/10000, Loss: 0.006507234647870064\n",
      "Iteration: 5771/10000, Loss: 0.00900002010166645\n",
      "Iteration: 5772/10000, Loss: 0.006880365312099457\n",
      "Iteration: 5773/10000, Loss: 0.006556357257068157\n",
      "Iteration: 5774/10000, Loss: 0.009642140939831734\n",
      "Iteration: 5775/10000, Loss: 0.010673175565898418\n",
      "Iteration: 5776/10000, Loss: 0.012996640987694263\n",
      "Iteration: 5777/10000, Loss: 0.009840802289545536\n",
      "Iteration: 5778/10000, Loss: 0.005840891040861607\n",
      "Iteration: 5779/10000, Loss: 0.011198212392628193\n",
      "Iteration: 5780/10000, Loss: 0.008375175297260284\n",
      "Iteration: 5781/10000, Loss: 0.012543891556560993\n",
      "Iteration: 5782/10000, Loss: 0.009334655478596687\n",
      "Iteration: 5783/10000, Loss: 0.01341395452618599\n",
      "Iteration: 5784/10000, Loss: 0.02007712423801422\n",
      "Iteration: 5785/10000, Loss: 0.009829208254814148\n",
      "Iteration: 5786/10000, Loss: 0.012368589639663696\n",
      "Iteration: 5787/10000, Loss: 0.017282407730817795\n",
      "Iteration: 5788/10000, Loss: 0.013724954798817635\n",
      "Iteration: 5789/10000, Loss: 0.007938819006085396\n",
      "Iteration: 5790/10000, Loss: 0.013448492623865604\n",
      "Iteration: 5791/10000, Loss: 0.013944095931947231\n",
      "Iteration: 5792/10000, Loss: 0.009636053815484047\n",
      "Iteration: 5793/10000, Loss: 0.011773304082453251\n",
      "Iteration: 5794/10000, Loss: 0.01038159430027008\n",
      "Iteration: 5795/10000, Loss: 0.008739306591451168\n",
      "Iteration: 5796/10000, Loss: 0.010214987210929394\n",
      "Iteration: 5797/10000, Loss: 0.019952915608882904\n",
      "Iteration: 5798/10000, Loss: 0.01785413734614849\n",
      "Iteration: 5799/10000, Loss: 0.015604725107550621\n",
      "Iteration: 5800/10000, Loss: 0.015965914353728294\n",
      "Average test loss:  0.0020\n",
      "Iteration: 5801/10000, Loss: 0.013228039257228374\n",
      "Iteration: 5802/10000, Loss: 0.01729411818087101\n",
      "Iteration: 5803/10000, Loss: 0.011165744625031948\n",
      "Iteration: 5804/10000, Loss: 0.013337935321033001\n",
      "Iteration: 5805/10000, Loss: 0.013303819112479687\n",
      "Iteration: 5806/10000, Loss: 0.013388666324317455\n",
      "Iteration: 5807/10000, Loss: 0.008861886337399483\n",
      "Iteration: 5808/10000, Loss: 0.012167475186288357\n",
      "Iteration: 5809/10000, Loss: 0.014902040362358093\n",
      "Iteration: 5810/10000, Loss: 0.008954061195254326\n",
      "Iteration: 5811/10000, Loss: 0.014577922411262989\n",
      "Iteration: 5812/10000, Loss: 0.012369896285235882\n",
      "Iteration: 5813/10000, Loss: 0.009203126654028893\n",
      "Iteration: 5814/10000, Loss: 0.01081041805446148\n",
      "Iteration: 5815/10000, Loss: 0.00907161831855774\n",
      "Iteration: 5816/10000, Loss: 0.011570033617317677\n",
      "Iteration: 5817/10000, Loss: 0.012339428998529911\n",
      "Iteration: 5818/10000, Loss: 0.009594432078301907\n",
      "Iteration: 5819/10000, Loss: 0.014433331787586212\n",
      "Iteration: 5820/10000, Loss: 0.012736039236187935\n",
      "Iteration: 5821/10000, Loss: 0.010406507179141045\n",
      "Iteration: 5822/10000, Loss: 0.014836997725069523\n",
      "Iteration: 5823/10000, Loss: 0.006084977649152279\n",
      "Iteration: 5824/10000, Loss: 0.007013889029622078\n",
      "Iteration: 5825/10000, Loss: 0.010078039020299911\n",
      "Iteration: 5826/10000, Loss: 0.015668965876102448\n",
      "Iteration: 5827/10000, Loss: 0.011955797672271729\n",
      "Iteration: 5828/10000, Loss: 0.010232101194560528\n",
      "Iteration: 5829/10000, Loss: 0.0088829779997468\n",
      "Iteration: 5830/10000, Loss: 0.016874564811587334\n",
      "Iteration: 5831/10000, Loss: 0.013702085241675377\n",
      "Iteration: 5832/10000, Loss: 0.01161440834403038\n",
      "Iteration: 5833/10000, Loss: 0.011733423918485641\n",
      "Iteration: 5834/10000, Loss: 0.011521648615598679\n",
      "Iteration: 5835/10000, Loss: 0.009144201874732971\n",
      "Iteration: 5836/10000, Loss: 0.011097840033471584\n",
      "Iteration: 5837/10000, Loss: 0.011115046218037605\n",
      "Iteration: 5838/10000, Loss: 0.014181040227413177\n",
      "Iteration: 5839/10000, Loss: 0.01239633560180664\n",
      "Iteration: 5840/10000, Loss: 0.014653059653937817\n",
      "Iteration: 5841/10000, Loss: 0.01106406468898058\n",
      "Iteration: 5842/10000, Loss: 0.014861243776977062\n",
      "Iteration: 5843/10000, Loss: 0.013860327191650867\n",
      "Iteration: 5844/10000, Loss: 0.01162850484251976\n",
      "Iteration: 5845/10000, Loss: 0.010951812379062176\n",
      "Iteration: 5846/10000, Loss: 0.008219731971621513\n",
      "Iteration: 5847/10000, Loss: 0.012402932159602642\n",
      "Iteration: 5848/10000, Loss: 0.008308909833431244\n",
      "Iteration: 5849/10000, Loss: 0.009194222278892994\n",
      "Iteration: 5850/10000, Loss: 0.013081834651529789\n",
      "Iteration: 5851/10000, Loss: 0.015569454990327358\n",
      "Iteration: 5852/10000, Loss: 0.015790848061442375\n",
      "Iteration: 5853/10000, Loss: 0.016242925077676773\n",
      "Iteration: 5854/10000, Loss: 0.01263490691781044\n",
      "Iteration: 5855/10000, Loss: 0.01115392241626978\n",
      "Iteration: 5856/10000, Loss: 0.01353374868631363\n",
      "Iteration: 5857/10000, Loss: 0.013150599785149097\n",
      "Iteration: 5858/10000, Loss: 0.010693448595702648\n",
      "Iteration: 5859/10000, Loss: 0.013792877085506916\n",
      "Iteration: 5860/10000, Loss: 0.011415358632802963\n",
      "Iteration: 5861/10000, Loss: 0.014309308491647243\n",
      "Iteration: 5862/10000, Loss: 0.008436749689280987\n",
      "Iteration: 5863/10000, Loss: 0.019496837630867958\n",
      "Iteration: 5864/10000, Loss: 0.012562049552798271\n",
      "Iteration: 5865/10000, Loss: 0.016228003427386284\n",
      "Iteration: 5866/10000, Loss: 0.015199228189885616\n",
      "Iteration: 5867/10000, Loss: 0.01230715773999691\n",
      "Iteration: 5868/10000, Loss: 0.011835961602628231\n",
      "Iteration: 5869/10000, Loss: 0.01067500188946724\n",
      "Iteration: 5870/10000, Loss: 0.010046923533082008\n",
      "Iteration: 5871/10000, Loss: 0.013551891781389713\n",
      "Iteration: 5872/10000, Loss: 0.009488629177212715\n",
      "Iteration: 5873/10000, Loss: 0.014626918360590935\n",
      "Iteration: 5874/10000, Loss: 0.007402596063911915\n",
      "Iteration: 5875/10000, Loss: 0.008140958845615387\n",
      "Iteration: 5876/10000, Loss: 0.013865146785974503\n",
      "Iteration: 5877/10000, Loss: 0.00896988995373249\n",
      "Iteration: 5878/10000, Loss: 0.007134879939258099\n",
      "Iteration: 5879/10000, Loss: 0.008188251405954361\n",
      "Iteration: 5880/10000, Loss: 0.014274428598582745\n",
      "Iteration: 5881/10000, Loss: 0.00999851617962122\n",
      "Iteration: 5882/10000, Loss: 0.01089510414749384\n",
      "Iteration: 5883/10000, Loss: 0.010132825933396816\n",
      "Iteration: 5884/10000, Loss: 0.010580806992948055\n",
      "Iteration: 5885/10000, Loss: 0.011458338238298893\n",
      "Iteration: 5886/10000, Loss: 0.008932280354201794\n",
      "Iteration: 5887/10000, Loss: 0.012796507216989994\n",
      "Iteration: 5888/10000, Loss: 0.010331956669688225\n",
      "Iteration: 5889/10000, Loss: 0.010734304785728455\n",
      "Iteration: 5890/10000, Loss: 0.009212839417159557\n",
      "Iteration: 5891/10000, Loss: 0.012322632595896721\n",
      "Iteration: 5892/10000, Loss: 0.011684720404446125\n",
      "Iteration: 5893/10000, Loss: 0.015246989205479622\n",
      "Iteration: 5894/10000, Loss: 0.01370857935398817\n",
      "Iteration: 5895/10000, Loss: 0.010512644425034523\n",
      "Iteration: 5896/10000, Loss: 0.011518404819071293\n",
      "Iteration: 5897/10000, Loss: 0.01679767668247223\n",
      "Iteration: 5898/10000, Loss: 0.008830505423247814\n",
      "Iteration: 5899/10000, Loss: 0.010574397630989552\n",
      "Iteration: 5900/10000, Loss: 0.014361497946083546\n",
      "Average test loss:  0.0030\n",
      "Iteration: 5901/10000, Loss: 0.012218952178955078\n",
      "Iteration: 5902/10000, Loss: 0.01479481440037489\n",
      "Iteration: 5903/10000, Loss: 0.014938091859221458\n",
      "Iteration: 5904/10000, Loss: 0.00956718623638153\n",
      "Iteration: 5905/10000, Loss: 0.01597561128437519\n",
      "Iteration: 5906/10000, Loss: 0.008645517751574516\n",
      "Iteration: 5907/10000, Loss: 0.012417168356478214\n",
      "Iteration: 5908/10000, Loss: 0.010288747027516365\n",
      "Iteration: 5909/10000, Loss: 0.009506522677838802\n",
      "Iteration: 5910/10000, Loss: 0.01095367781817913\n",
      "Iteration: 5911/10000, Loss: 0.011016285046935081\n",
      "Iteration: 5912/10000, Loss: 0.005577158182859421\n",
      "Iteration: 5913/10000, Loss: 0.018283814191818237\n",
      "Iteration: 5914/10000, Loss: 0.0132447499781847\n",
      "Iteration: 5915/10000, Loss: 0.010433672927320004\n",
      "Iteration: 5916/10000, Loss: 0.011224818415939808\n",
      "Iteration: 5917/10000, Loss: 0.01701377145946026\n",
      "Iteration: 5918/10000, Loss: 0.00808047503232956\n",
      "Iteration: 5919/10000, Loss: 0.01357809454202652\n",
      "Iteration: 5920/10000, Loss: 0.008583654649555683\n",
      "Iteration: 5921/10000, Loss: 0.011516015976667404\n",
      "Iteration: 5922/10000, Loss: 0.011687117628753185\n",
      "Iteration: 5923/10000, Loss: 0.006367964670062065\n",
      "Iteration: 5924/10000, Loss: 0.012609167024493217\n",
      "Iteration: 5925/10000, Loss: 0.013499075546860695\n",
      "Iteration: 5926/10000, Loss: 0.011569763533771038\n",
      "Iteration: 5927/10000, Loss: 0.01366336364299059\n",
      "Iteration: 5928/10000, Loss: 0.012427636422216892\n",
      "Iteration: 5929/10000, Loss: 0.009063583798706532\n",
      "Iteration: 5930/10000, Loss: 0.012865998782217503\n",
      "Iteration: 5931/10000, Loss: 0.006968507543206215\n",
      "Iteration: 5932/10000, Loss: 0.010553175583481789\n",
      "Iteration: 5933/10000, Loss: 0.011210167780518532\n",
      "Iteration: 5934/10000, Loss: 0.014898206107318401\n",
      "Iteration: 5935/10000, Loss: 0.006594635546207428\n",
      "Iteration: 5936/10000, Loss: 0.015057099051773548\n",
      "Iteration: 5937/10000, Loss: 0.013079818338155746\n",
      "Iteration: 5938/10000, Loss: 0.010933216661214828\n",
      "Iteration: 5939/10000, Loss: 0.011262611486017704\n",
      "Iteration: 5940/10000, Loss: 0.012248128652572632\n",
      "Iteration: 5941/10000, Loss: 0.011353602632880211\n",
      "Iteration: 5942/10000, Loss: 0.012315081432461739\n",
      "Iteration: 5943/10000, Loss: 0.009733600541949272\n",
      "Iteration: 5944/10000, Loss: 0.013263385742902756\n",
      "Iteration: 5945/10000, Loss: 0.013214005157351494\n",
      "Iteration: 5946/10000, Loss: 0.013380955904722214\n",
      "Iteration: 5947/10000, Loss: 0.01228436827659607\n",
      "Iteration: 5948/10000, Loss: 0.01050963532179594\n",
      "Iteration: 5949/10000, Loss: 0.017530689015984535\n",
      "Iteration: 5950/10000, Loss: 0.010968144983053207\n",
      "Iteration: 5951/10000, Loss: 0.01128353551030159\n",
      "Iteration: 5952/10000, Loss: 0.01081941369920969\n",
      "Iteration: 5953/10000, Loss: 0.012565656565129757\n",
      "Iteration: 5954/10000, Loss: 0.011649706400930882\n",
      "Iteration: 5955/10000, Loss: 0.013021309860050678\n",
      "Iteration: 5956/10000, Loss: 0.014448221772909164\n",
      "Iteration: 5957/10000, Loss: 0.008103170432150364\n",
      "Iteration: 5958/10000, Loss: 0.010981807485222816\n",
      "Iteration: 5959/10000, Loss: 0.010422509163618088\n",
      "Iteration: 5960/10000, Loss: 0.00796282384544611\n",
      "Iteration: 5961/10000, Loss: 0.012750595808029175\n",
      "Iteration: 5962/10000, Loss: 0.007114718668162823\n",
      "Iteration: 5963/10000, Loss: 0.013005956076085567\n",
      "Iteration: 5964/10000, Loss: 0.0070261042565107346\n",
      "Iteration: 5965/10000, Loss: 0.0107998326420784\n",
      "Iteration: 5966/10000, Loss: 0.010562832467257977\n",
      "Iteration: 5967/10000, Loss: 0.009444622322916985\n",
      "Iteration: 5968/10000, Loss: 0.008567489683628082\n",
      "Iteration: 5969/10000, Loss: 0.011486717499792576\n",
      "Iteration: 5970/10000, Loss: 0.012246094644069672\n",
      "Iteration: 5971/10000, Loss: 0.010523431934416294\n",
      "Iteration: 5972/10000, Loss: 0.006901714485138655\n",
      "Iteration: 5973/10000, Loss: 0.013451767154037952\n",
      "Iteration: 5974/10000, Loss: 0.014724763110280037\n",
      "Iteration: 5975/10000, Loss: 0.011335541494190693\n",
      "Iteration: 5976/10000, Loss: 0.008899728767573833\n",
      "Iteration: 5977/10000, Loss: 0.01114816777408123\n",
      "Iteration: 5978/10000, Loss: 0.008604355156421661\n",
      "Iteration: 5979/10000, Loss: 0.007877231575548649\n",
      "Iteration: 5980/10000, Loss: 0.009909274987876415\n",
      "Iteration: 5981/10000, Loss: 0.006413973402231932\n",
      "Iteration: 5982/10000, Loss: 0.01135071087628603\n",
      "Iteration: 5983/10000, Loss: 0.010709743946790695\n",
      "Iteration: 5984/10000, Loss: 0.010865744203329086\n",
      "Iteration: 5985/10000, Loss: 0.009611650370061398\n",
      "Iteration: 5986/10000, Loss: 0.008910146541893482\n",
      "Iteration: 5987/10000, Loss: 0.01214279979467392\n",
      "Iteration: 5988/10000, Loss: 0.00900044571608305\n",
      "Iteration: 5989/10000, Loss: 0.01546461507678032\n",
      "Iteration: 5990/10000, Loss: 0.011669368483126163\n",
      "Iteration: 5991/10000, Loss: 0.013708463869988918\n",
      "Iteration: 5992/10000, Loss: 0.013750392012298107\n",
      "Iteration: 5993/10000, Loss: 0.012911106459796429\n",
      "Iteration: 5994/10000, Loss: 0.013903315179049969\n",
      "Iteration: 5995/10000, Loss: 0.011688480153679848\n",
      "Iteration: 5996/10000, Loss: 0.014133930206298828\n",
      "Iteration: 5997/10000, Loss: 0.00957219023257494\n",
      "Iteration: 5998/10000, Loss: 0.00920889712870121\n",
      "Iteration: 5999/10000, Loss: 0.014558834955096245\n",
      "Iteration: 6000/10000, Loss: 0.011799396947026253\n",
      "Average test loss:  0.0029\n",
      "Iteration: 6001/10000, Loss: 0.009324287995696068\n",
      "Iteration: 6002/10000, Loss: 0.014321943745017052\n",
      "Iteration: 6003/10000, Loss: 0.012437369674444199\n",
      "Iteration: 6004/10000, Loss: 0.008118707686662674\n",
      "Iteration: 6005/10000, Loss: 0.010167759843170643\n",
      "Iteration: 6006/10000, Loss: 0.00856871996074915\n",
      "Iteration: 6007/10000, Loss: 0.009411688894033432\n",
      "Iteration: 6008/10000, Loss: 0.011852211318910122\n",
      "Iteration: 6009/10000, Loss: 0.01129971444606781\n",
      "Iteration: 6010/10000, Loss: 0.010844890028238297\n",
      "Iteration: 6011/10000, Loss: 0.014329303987324238\n",
      "Iteration: 6012/10000, Loss: 0.014159389771521091\n",
      "Iteration: 6013/10000, Loss: 0.010018733330070972\n",
      "Iteration: 6014/10000, Loss: 0.009479369968175888\n",
      "Iteration: 6015/10000, Loss: 0.013804877176880836\n",
      "Iteration: 6016/10000, Loss: 0.008393710479140282\n",
      "Iteration: 6017/10000, Loss: 0.009620207361876965\n",
      "Iteration: 6018/10000, Loss: 0.011239120736718178\n",
      "Iteration: 6019/10000, Loss: 0.007569919805973768\n",
      "Iteration: 6020/10000, Loss: 0.012906004674732685\n",
      "Iteration: 6021/10000, Loss: 0.017618967220187187\n",
      "Iteration: 6022/10000, Loss: 0.013172052800655365\n",
      "Iteration: 6023/10000, Loss: 0.009644240140914917\n",
      "Iteration: 6024/10000, Loss: 0.010315562598407269\n",
      "Iteration: 6025/10000, Loss: 0.010093320161104202\n",
      "Iteration: 6026/10000, Loss: 0.011563555337488651\n",
      "Iteration: 6027/10000, Loss: 0.006718187127262354\n",
      "Iteration: 6028/10000, Loss: 0.010095217265188694\n",
      "Iteration: 6029/10000, Loss: 0.019832320511341095\n",
      "Iteration: 6030/10000, Loss: 0.014522753655910492\n",
      "Iteration: 6031/10000, Loss: 0.009744437411427498\n",
      "Iteration: 6032/10000, Loss: 0.012848099693655968\n",
      "Iteration: 6033/10000, Loss: 0.009473326615989208\n",
      "Iteration: 6034/10000, Loss: 0.0076369731687009335\n",
      "Iteration: 6035/10000, Loss: 0.0148323280736804\n",
      "Iteration: 6036/10000, Loss: 0.01001032255589962\n",
      "Iteration: 6037/10000, Loss: 0.007711889687925577\n",
      "Iteration: 6038/10000, Loss: 0.010876011103391647\n",
      "Iteration: 6039/10000, Loss: 0.015555702149868011\n",
      "Iteration: 6040/10000, Loss: 0.011648431420326233\n",
      "Iteration: 6041/10000, Loss: 0.009461836889386177\n",
      "Iteration: 6042/10000, Loss: 0.009307843632996082\n",
      "Iteration: 6043/10000, Loss: 0.012289902195334435\n",
      "Iteration: 6044/10000, Loss: 0.008961280807852745\n",
      "Iteration: 6045/10000, Loss: 0.013832408003509045\n",
      "Iteration: 6046/10000, Loss: 0.010467861779034138\n",
      "Iteration: 6047/10000, Loss: 0.013060105964541435\n",
      "Iteration: 6048/10000, Loss: 0.013625837862491608\n",
      "Iteration: 6049/10000, Loss: 0.011686373502016068\n",
      "Iteration: 6050/10000, Loss: 0.012208359315991402\n",
      "Iteration: 6051/10000, Loss: 0.008526969701051712\n",
      "Iteration: 6052/10000, Loss: 0.00953642837703228\n",
      "Iteration: 6053/10000, Loss: 0.010697216726839542\n",
      "Iteration: 6054/10000, Loss: 0.007478261366486549\n",
      "Iteration: 6055/10000, Loss: 0.009587946347892284\n",
      "Iteration: 6056/10000, Loss: 0.010519690811634064\n",
      "Iteration: 6057/10000, Loss: 0.01851903460919857\n",
      "Iteration: 6058/10000, Loss: 0.018388092517852783\n",
      "Iteration: 6059/10000, Loss: 0.010513045825064182\n",
      "Iteration: 6060/10000, Loss: 0.01044275052845478\n",
      "Iteration: 6061/10000, Loss: 0.009785251691937447\n",
      "Iteration: 6062/10000, Loss: 0.010823729448020458\n",
      "Iteration: 6063/10000, Loss: 0.016029201447963715\n",
      "Iteration: 6064/10000, Loss: 0.012385462410748005\n",
      "Iteration: 6065/10000, Loss: 0.01532534509897232\n",
      "Iteration: 6066/10000, Loss: 0.012666091322898865\n",
      "Iteration: 6067/10000, Loss: 0.006790706422179937\n",
      "Iteration: 6068/10000, Loss: 0.009594103321433067\n",
      "Iteration: 6069/10000, Loss: 0.012321538291871548\n",
      "Iteration: 6070/10000, Loss: 0.00968064833432436\n",
      "Iteration: 6071/10000, Loss: 0.01104445569217205\n",
      "Iteration: 6072/10000, Loss: 0.014197951182723045\n",
      "Iteration: 6073/10000, Loss: 0.008438685908913612\n",
      "Iteration: 6074/10000, Loss: 0.013789646327495575\n",
      "Iteration: 6075/10000, Loss: 0.008763633668422699\n",
      "Iteration: 6076/10000, Loss: 0.016350198537111282\n",
      "Iteration: 6077/10000, Loss: 0.0076969824731349945\n",
      "Iteration: 6078/10000, Loss: 0.013863781467080116\n",
      "Iteration: 6079/10000, Loss: 0.008348794654011726\n",
      "Iteration: 6080/10000, Loss: 0.011304931715130806\n",
      "Iteration: 6081/10000, Loss: 0.013860986568033695\n",
      "Iteration: 6082/10000, Loss: 0.011900381185114384\n",
      "Iteration: 6083/10000, Loss: 0.014359311200678349\n",
      "Iteration: 6084/10000, Loss: 0.007130713667720556\n",
      "Iteration: 6085/10000, Loss: 0.012759570963680744\n",
      "Iteration: 6086/10000, Loss: 0.010971003212034702\n",
      "Iteration: 6087/10000, Loss: 0.01052880845963955\n",
      "Iteration: 6088/10000, Loss: 0.005640024784952402\n",
      "Iteration: 6089/10000, Loss: 0.009315292350947857\n",
      "Iteration: 6090/10000, Loss: 0.010212335735559464\n",
      "Iteration: 6091/10000, Loss: 0.011707930825650692\n",
      "Iteration: 6092/10000, Loss: 0.010055731050670147\n",
      "Iteration: 6093/10000, Loss: 0.009415148757398129\n",
      "Iteration: 6094/10000, Loss: 0.013215598650276661\n",
      "Iteration: 6095/10000, Loss: 0.009781175293028355\n",
      "Iteration: 6096/10000, Loss: 0.00978481862694025\n",
      "Iteration: 6097/10000, Loss: 0.010446186177432537\n",
      "Iteration: 6098/10000, Loss: 0.00849095918238163\n",
      "Iteration: 6099/10000, Loss: 0.005467172246426344\n",
      "Iteration: 6100/10000, Loss: 0.011063066311180592\n",
      "Average test loss:  0.0027\n",
      "Iteration: 6101/10000, Loss: 0.013354041613638401\n",
      "Iteration: 6102/10000, Loss: 0.010709400288760662\n",
      "Iteration: 6103/10000, Loss: 0.010948524810373783\n",
      "Iteration: 6104/10000, Loss: 0.010017276741564274\n",
      "Iteration: 6105/10000, Loss: 0.01243301946669817\n",
      "Iteration: 6106/10000, Loss: 0.013291076757013798\n",
      "Iteration: 6107/10000, Loss: 0.014853357337415218\n",
      "Iteration: 6108/10000, Loss: 0.013923888094723225\n",
      "Iteration: 6109/10000, Loss: 0.01288390252739191\n",
      "Iteration: 6110/10000, Loss: 0.01104626152664423\n",
      "Iteration: 6111/10000, Loss: 0.012746174819767475\n",
      "Iteration: 6112/10000, Loss: 0.010430587455630302\n",
      "Iteration: 6113/10000, Loss: 0.007309687789529562\n",
      "Iteration: 6114/10000, Loss: 0.011484728194773197\n",
      "Iteration: 6115/10000, Loss: 0.012541393749415874\n",
      "Iteration: 6116/10000, Loss: 0.01097381766885519\n",
      "Iteration: 6117/10000, Loss: 0.0073707569390535355\n",
      "Iteration: 6118/10000, Loss: 0.01252244133502245\n",
      "Iteration: 6119/10000, Loss: 0.012428617104887962\n",
      "Iteration: 6120/10000, Loss: 0.008925436064600945\n",
      "Iteration: 6121/10000, Loss: 0.008494258858263493\n",
      "Iteration: 6122/10000, Loss: 0.00875081866979599\n",
      "Iteration: 6123/10000, Loss: 0.012146485038101673\n",
      "Iteration: 6124/10000, Loss: 0.012114896439015865\n",
      "Iteration: 6125/10000, Loss: 0.013810493052005768\n",
      "Iteration: 6126/10000, Loss: 0.009282275103032589\n",
      "Iteration: 6127/10000, Loss: 0.008462256751954556\n",
      "Iteration: 6128/10000, Loss: 0.011862674728035927\n",
      "Iteration: 6129/10000, Loss: 0.012478785589337349\n",
      "Iteration: 6130/10000, Loss: 0.010410752147436142\n",
      "Iteration: 6131/10000, Loss: 0.007300225552171469\n",
      "Iteration: 6132/10000, Loss: 0.00971092190593481\n",
      "Iteration: 6133/10000, Loss: 0.021336158737540245\n",
      "Iteration: 6134/10000, Loss: 0.012464492581784725\n",
      "Iteration: 6135/10000, Loss: 0.014053951017558575\n",
      "Iteration: 6136/10000, Loss: 0.010346838273108006\n",
      "Iteration: 6137/10000, Loss: 0.010467829182744026\n",
      "Iteration: 6138/10000, Loss: 0.01005785446614027\n",
      "Iteration: 6139/10000, Loss: 0.010002258233726025\n",
      "Iteration: 6140/10000, Loss: 0.015529471449553967\n",
      "Iteration: 6141/10000, Loss: 0.007607469335198402\n",
      "Iteration: 6142/10000, Loss: 0.0077925194054841995\n",
      "Iteration: 6143/10000, Loss: 0.006104819476604462\n",
      "Iteration: 6144/10000, Loss: 0.012516182847321033\n",
      "Iteration: 6145/10000, Loss: 0.01553359441459179\n",
      "Iteration: 6146/10000, Loss: 0.011906110681593418\n",
      "Iteration: 6147/10000, Loss: 0.011742950417101383\n",
      "Iteration: 6148/10000, Loss: 0.00910932570695877\n",
      "Iteration: 6149/10000, Loss: 0.011240028776228428\n",
      "Iteration: 6150/10000, Loss: 0.014977593906223774\n",
      "Iteration: 6151/10000, Loss: 0.01418180763721466\n",
      "Iteration: 6152/10000, Loss: 0.00994055811315775\n",
      "Iteration: 6153/10000, Loss: 0.011471668258309364\n",
      "Iteration: 6154/10000, Loss: 0.008108045905828476\n",
      "Iteration: 6155/10000, Loss: 0.008952830918133259\n",
      "Iteration: 6156/10000, Loss: 0.01717844046652317\n",
      "Iteration: 6157/10000, Loss: 0.01126014906913042\n",
      "Iteration: 6158/10000, Loss: 0.00936790183186531\n",
      "Iteration: 6159/10000, Loss: 0.01096748560667038\n",
      "Iteration: 6160/10000, Loss: 0.009527767077088356\n",
      "Iteration: 6161/10000, Loss: 0.013941378332674503\n",
      "Iteration: 6162/10000, Loss: 0.005972441751509905\n",
      "Iteration: 6163/10000, Loss: 0.01157362014055252\n",
      "Iteration: 6164/10000, Loss: 0.009346943348646164\n",
      "Iteration: 6165/10000, Loss: 0.012470209039747715\n",
      "Iteration: 6166/10000, Loss: 0.01587367057800293\n",
      "Iteration: 6167/10000, Loss: 0.015055699273943901\n",
      "Iteration: 6168/10000, Loss: 0.00651325611397624\n",
      "Iteration: 6169/10000, Loss: 0.013835017569363117\n",
      "Iteration: 6170/10000, Loss: 0.009740345180034637\n",
      "Iteration: 6171/10000, Loss: 0.013328255154192448\n",
      "Iteration: 6172/10000, Loss: 0.013447625562548637\n",
      "Iteration: 6173/10000, Loss: 0.012448267079889774\n",
      "Iteration: 6174/10000, Loss: 0.014686910435557365\n",
      "Iteration: 6175/10000, Loss: 0.005888647865504026\n",
      "Iteration: 6176/10000, Loss: 0.009278335608541965\n",
      "Iteration: 6177/10000, Loss: 0.00540509819984436\n",
      "Iteration: 6178/10000, Loss: 0.00830113422125578\n",
      "Iteration: 6179/10000, Loss: 0.012215295806527138\n",
      "Iteration: 6180/10000, Loss: 0.01198978815227747\n",
      "Iteration: 6181/10000, Loss: 0.0151335708796978\n",
      "Iteration: 6182/10000, Loss: 0.018581882119178772\n",
      "Iteration: 6183/10000, Loss: 0.010300436057150364\n",
      "Iteration: 6184/10000, Loss: 0.011226587928831577\n",
      "Iteration: 6185/10000, Loss: 0.007631818298250437\n",
      "Iteration: 6186/10000, Loss: 0.010808447375893593\n",
      "Iteration: 6187/10000, Loss: 0.009863033890724182\n",
      "Iteration: 6188/10000, Loss: 0.011400575749576092\n",
      "Iteration: 6189/10000, Loss: 0.014153046533465385\n",
      "Iteration: 6190/10000, Loss: 0.014301474206149578\n",
      "Iteration: 6191/10000, Loss: 0.008532899431884289\n",
      "Iteration: 6192/10000, Loss: 0.008557812310755253\n",
      "Iteration: 6193/10000, Loss: 0.009802804328501225\n",
      "Iteration: 6194/10000, Loss: 0.014424366876482964\n",
      "Iteration: 6195/10000, Loss: 0.010998690500855446\n",
      "Iteration: 6196/10000, Loss: 0.009835323318839073\n",
      "Iteration: 6197/10000, Loss: 0.010785285383462906\n",
      "Iteration: 6198/10000, Loss: 0.014809239655733109\n",
      "Iteration: 6199/10000, Loss: 0.011731862090528011\n",
      "Iteration: 6200/10000, Loss: 0.01428193412721157\n",
      "Average test loss:  0.0026\n",
      "Iteration: 6201/10000, Loss: 0.008993901312351227\n",
      "Iteration: 6202/10000, Loss: 0.00991969183087349\n",
      "Iteration: 6203/10000, Loss: 0.011479745618999004\n",
      "Iteration: 6204/10000, Loss: 0.007372546941041946\n",
      "Iteration: 6205/10000, Loss: 0.0113957105204463\n",
      "Iteration: 6206/10000, Loss: 0.011693845503032207\n",
      "Iteration: 6207/10000, Loss: 0.013558782637119293\n",
      "Iteration: 6208/10000, Loss: 0.013964473269879818\n",
      "Iteration: 6209/10000, Loss: 0.012586901895701885\n",
      "Iteration: 6210/10000, Loss: 0.011988380923867226\n",
      "Iteration: 6211/10000, Loss: 0.006796843372285366\n",
      "Iteration: 6212/10000, Loss: 0.012511991895735264\n",
      "Iteration: 6213/10000, Loss: 0.013201270252466202\n",
      "Iteration: 6214/10000, Loss: 0.009840218350291252\n",
      "Iteration: 6215/10000, Loss: 0.013888060115277767\n",
      "Iteration: 6216/10000, Loss: 0.011741407215595245\n",
      "Iteration: 6217/10000, Loss: 0.01149116549640894\n",
      "Iteration: 6218/10000, Loss: 0.014537268318235874\n",
      "Iteration: 6219/10000, Loss: 0.016087280586361885\n",
      "Iteration: 6220/10000, Loss: 0.014969476498663425\n",
      "Iteration: 6221/10000, Loss: 0.010727284476161003\n",
      "Iteration: 6222/10000, Loss: 0.008794590830802917\n",
      "Iteration: 6223/10000, Loss: 0.011285929009318352\n",
      "Iteration: 6224/10000, Loss: 0.00787440687417984\n",
      "Iteration: 6225/10000, Loss: 0.00833262037485838\n",
      "Iteration: 6226/10000, Loss: 0.010678389109671116\n",
      "Iteration: 6227/10000, Loss: 0.009310931898653507\n",
      "Iteration: 6228/10000, Loss: 0.01130583230406046\n",
      "Iteration: 6229/10000, Loss: 0.011127385310828686\n",
      "Iteration: 6230/10000, Loss: 0.01689627766609192\n",
      "Iteration: 6231/10000, Loss: 0.013357206247746944\n",
      "Iteration: 6232/10000, Loss: 0.01147198211401701\n",
      "Iteration: 6233/10000, Loss: 0.01257948949933052\n",
      "Iteration: 6234/10000, Loss: 0.009682150557637215\n",
      "Iteration: 6235/10000, Loss: 0.010567615740001202\n",
      "Iteration: 6236/10000, Loss: 0.01219838485121727\n",
      "Iteration: 6237/10000, Loss: 0.01695185899734497\n",
      "Iteration: 6238/10000, Loss: 0.017644762992858887\n",
      "Iteration: 6239/10000, Loss: 0.010542009025812149\n",
      "Iteration: 6240/10000, Loss: 0.0061048162169754505\n",
      "Iteration: 6241/10000, Loss: 0.0125637361779809\n",
      "Iteration: 6242/10000, Loss: 0.014230555854737759\n",
      "Iteration: 6243/10000, Loss: 0.012989500537514687\n",
      "Iteration: 6244/10000, Loss: 0.009305120445787907\n",
      "Iteration: 6245/10000, Loss: 0.010893922299146652\n",
      "Iteration: 6246/10000, Loss: 0.005580394994467497\n",
      "Iteration: 6247/10000, Loss: 0.009840366430580616\n",
      "Iteration: 6248/10000, Loss: 0.016059916466474533\n",
      "Iteration: 6249/10000, Loss: 0.014758300967514515\n",
      "Iteration: 6250/10000, Loss: 0.01400653924793005\n",
      "Iteration: 6251/10000, Loss: 0.008874238468706608\n",
      "Iteration: 6252/10000, Loss: 0.006353709846735001\n",
      "Iteration: 6253/10000, Loss: 0.009768449701368809\n",
      "Iteration: 6254/10000, Loss: 0.018368985503911972\n",
      "Iteration: 6255/10000, Loss: 0.011295170523226261\n",
      "Iteration: 6256/10000, Loss: 0.008640012703835964\n",
      "Iteration: 6257/10000, Loss: 0.009018057957291603\n",
      "Iteration: 6258/10000, Loss: 0.013569816946983337\n",
      "Iteration: 6259/10000, Loss: 0.008956747129559517\n",
      "Iteration: 6260/10000, Loss: 0.01614510267972946\n",
      "Iteration: 6261/10000, Loss: 0.015649504959583282\n",
      "Iteration: 6262/10000, Loss: 0.012978693470358849\n",
      "Iteration: 6263/10000, Loss: 0.012755787931382656\n",
      "Iteration: 6264/10000, Loss: 0.010824217461049557\n",
      "Iteration: 6265/10000, Loss: 0.014616595581173897\n",
      "Iteration: 6266/10000, Loss: 0.007430415600538254\n",
      "Iteration: 6267/10000, Loss: 0.010215203277766705\n",
      "Iteration: 6268/10000, Loss: 0.016216473653912544\n",
      "Iteration: 6269/10000, Loss: 0.007899722084403038\n",
      "Iteration: 6270/10000, Loss: 0.013205179944634438\n",
      "Iteration: 6271/10000, Loss: 0.009555039927363396\n",
      "Iteration: 6272/10000, Loss: 0.005640082992613316\n",
      "Iteration: 6273/10000, Loss: 0.011996260844171047\n",
      "Iteration: 6274/10000, Loss: 0.011335520073771477\n",
      "Iteration: 6275/10000, Loss: 0.015290621668100357\n",
      "Iteration: 6276/10000, Loss: 0.010889511555433273\n",
      "Iteration: 6277/10000, Loss: 0.014243066310882568\n",
      "Iteration: 6278/10000, Loss: 0.011229069903492928\n",
      "Iteration: 6279/10000, Loss: 0.008040963672101498\n",
      "Iteration: 6280/10000, Loss: 0.009846607223153114\n",
      "Iteration: 6281/10000, Loss: 0.01208762638270855\n",
      "Iteration: 6282/10000, Loss: 0.012114660814404488\n",
      "Iteration: 6283/10000, Loss: 0.008130177855491638\n",
      "Iteration: 6284/10000, Loss: 0.006043857894837856\n",
      "Iteration: 6285/10000, Loss: 0.01522726472467184\n",
      "Iteration: 6286/10000, Loss: 0.011179054155945778\n",
      "Iteration: 6287/10000, Loss: 0.010400893166661263\n",
      "Iteration: 6288/10000, Loss: 0.009019891731441021\n",
      "Iteration: 6289/10000, Loss: 0.007926738820970058\n",
      "Iteration: 6290/10000, Loss: 0.00980584416538477\n",
      "Iteration: 6291/10000, Loss: 0.01343571301549673\n",
      "Iteration: 6292/10000, Loss: 0.007507216185331345\n",
      "Iteration: 6293/10000, Loss: 0.009132846258580685\n",
      "Iteration: 6294/10000, Loss: 0.006676497869193554\n",
      "Iteration: 6295/10000, Loss: 0.0065152584575116634\n",
      "Iteration: 6296/10000, Loss: 0.009689942002296448\n",
      "Iteration: 6297/10000, Loss: 0.012929350137710571\n",
      "Iteration: 6298/10000, Loss: 0.005611696280539036\n",
      "Iteration: 6299/10000, Loss: 0.005060477182269096\n",
      "Iteration: 6300/10000, Loss: 0.012443752959370613\n",
      "Average test loss:  0.0040\n",
      "Iteration: 6301/10000, Loss: 0.010058715008199215\n",
      "Iteration: 6302/10000, Loss: 0.015209551900625229\n",
      "Iteration: 6303/10000, Loss: 0.015467521734535694\n",
      "Iteration: 6304/10000, Loss: 0.011933006346225739\n",
      "Iteration: 6305/10000, Loss: 0.00988649670034647\n",
      "Iteration: 6306/10000, Loss: 0.012843291275203228\n",
      "Iteration: 6307/10000, Loss: 0.005438664928078651\n",
      "Iteration: 6308/10000, Loss: 0.010005480609834194\n",
      "Iteration: 6309/10000, Loss: 0.012134146876633167\n",
      "Iteration: 6310/10000, Loss: 0.012066144496202469\n",
      "Iteration: 6311/10000, Loss: 0.009588656947016716\n",
      "Iteration: 6312/10000, Loss: 0.0102592334151268\n",
      "Iteration: 6313/10000, Loss: 0.013336394913494587\n",
      "Iteration: 6314/10000, Loss: 0.009253071621060371\n",
      "Iteration: 6315/10000, Loss: 0.010646629147231579\n",
      "Iteration: 6316/10000, Loss: 0.009047661907970905\n",
      "Iteration: 6317/10000, Loss: 0.013227198272943497\n",
      "Iteration: 6318/10000, Loss: 0.009440639987587929\n",
      "Iteration: 6319/10000, Loss: 0.015288729220628738\n",
      "Iteration: 6320/10000, Loss: 0.01306605339050293\n",
      "Iteration: 6321/10000, Loss: 0.010276863351464272\n",
      "Iteration: 6322/10000, Loss: 0.013617060147225857\n",
      "Iteration: 6323/10000, Loss: 0.011646291241049767\n",
      "Iteration: 6324/10000, Loss: 0.0105922631919384\n",
      "Iteration: 6325/10000, Loss: 0.01395900547504425\n",
      "Iteration: 6326/10000, Loss: 0.00846552848815918\n",
      "Iteration: 6327/10000, Loss: 0.009792694821953773\n",
      "Iteration: 6328/10000, Loss: 0.01245888415724039\n",
      "Iteration: 6329/10000, Loss: 0.01464096736162901\n",
      "Iteration: 6330/10000, Loss: 0.009568072855472565\n",
      "Iteration: 6331/10000, Loss: 0.0106359189376235\n",
      "Iteration: 6332/10000, Loss: 0.00864125695079565\n",
      "Iteration: 6333/10000, Loss: 0.01377683412283659\n",
      "Iteration: 6334/10000, Loss: 0.0093760434538126\n",
      "Iteration: 6335/10000, Loss: 0.010044693015515804\n",
      "Iteration: 6336/10000, Loss: 0.007047827821224928\n",
      "Iteration: 6337/10000, Loss: 0.008646676316857338\n",
      "Iteration: 6338/10000, Loss: 0.013299752026796341\n",
      "Iteration: 6339/10000, Loss: 0.007458688225597143\n",
      "Iteration: 6340/10000, Loss: 0.014094321057200432\n",
      "Iteration: 6341/10000, Loss: 0.014147858135402203\n",
      "Iteration: 6342/10000, Loss: 0.012433349154889584\n",
      "Iteration: 6343/10000, Loss: 0.012479051016271114\n",
      "Iteration: 6344/10000, Loss: 0.019772447645664215\n",
      "Iteration: 6345/10000, Loss: 0.0127345509827137\n",
      "Iteration: 6346/10000, Loss: 0.016714468598365784\n",
      "Iteration: 6347/10000, Loss: 0.01053483784198761\n",
      "Iteration: 6348/10000, Loss: 0.012384757399559021\n",
      "Iteration: 6349/10000, Loss: 0.013805515132844448\n",
      "Iteration: 6350/10000, Loss: 0.013385782018303871\n",
      "Iteration: 6351/10000, Loss: 0.010324959643185139\n",
      "Iteration: 6352/10000, Loss: 0.009917598217725754\n",
      "Iteration: 6353/10000, Loss: 0.01190788485109806\n",
      "Iteration: 6354/10000, Loss: 0.012372409924864769\n",
      "Iteration: 6355/10000, Loss: 0.01118030771613121\n",
      "Iteration: 6356/10000, Loss: 0.01293179765343666\n",
      "Iteration: 6357/10000, Loss: 0.011213492602109909\n",
      "Iteration: 6358/10000, Loss: 0.011347494088113308\n",
      "Iteration: 6359/10000, Loss: 0.00969654694199562\n",
      "Iteration: 6360/10000, Loss: 0.00965831894427538\n",
      "Iteration: 6361/10000, Loss: 0.005543542094528675\n",
      "Iteration: 6362/10000, Loss: 0.013309999369084835\n",
      "Iteration: 6363/10000, Loss: 0.013911186717450619\n",
      "Iteration: 6364/10000, Loss: 0.011853635311126709\n",
      "Iteration: 6365/10000, Loss: 0.007747037801891565\n",
      "Iteration: 6366/10000, Loss: 0.008125112392008305\n",
      "Iteration: 6367/10000, Loss: 0.013113426975905895\n",
      "Iteration: 6368/10000, Loss: 0.009831268340349197\n",
      "Iteration: 6369/10000, Loss: 0.01263375673443079\n",
      "Iteration: 6370/10000, Loss: 0.016502156853675842\n",
      "Iteration: 6371/10000, Loss: 0.005257315468043089\n",
      "Iteration: 6372/10000, Loss: 0.0052870167419314384\n",
      "Iteration: 6373/10000, Loss: 0.009354124777019024\n",
      "Iteration: 6374/10000, Loss: 0.011232475750148296\n",
      "Iteration: 6375/10000, Loss: 0.01170001644641161\n",
      "Iteration: 6376/10000, Loss: 0.010179794393479824\n",
      "Iteration: 6377/10000, Loss: 0.00856040883809328\n",
      "Iteration: 6378/10000, Loss: 0.007960943505167961\n",
      "Iteration: 6379/10000, Loss: 0.005516452249139547\n",
      "Iteration: 6380/10000, Loss: 0.010182819329202175\n",
      "Iteration: 6381/10000, Loss: 0.00765268737450242\n",
      "Iteration: 6382/10000, Loss: 0.010534738190472126\n",
      "Iteration: 6383/10000, Loss: 0.00993951503187418\n",
      "Iteration: 6384/10000, Loss: 0.010451438836753368\n",
      "Iteration: 6385/10000, Loss: 0.011783938854932785\n",
      "Iteration: 6386/10000, Loss: 0.007151022087782621\n",
      "Iteration: 6387/10000, Loss: 0.009237002581357956\n",
      "Iteration: 6388/10000, Loss: 0.00938803143799305\n",
      "Iteration: 6389/10000, Loss: 0.00973865482956171\n",
      "Iteration: 6390/10000, Loss: 0.01412160973995924\n",
      "Iteration: 6391/10000, Loss: 0.01016734167933464\n",
      "Iteration: 6392/10000, Loss: 0.008601222187280655\n",
      "Iteration: 6393/10000, Loss: 0.014108993113040924\n",
      "Iteration: 6394/10000, Loss: 0.00897196214646101\n",
      "Iteration: 6395/10000, Loss: 0.01152016781270504\n",
      "Iteration: 6396/10000, Loss: 0.011479780077934265\n",
      "Iteration: 6397/10000, Loss: 0.011577365919947624\n",
      "Iteration: 6398/10000, Loss: 0.009889901615679264\n",
      "Iteration: 6399/10000, Loss: 0.008623026311397552\n",
      "Iteration: 6400/10000, Loss: 0.012114409357309341\n",
      "Average test loss:  0.0029\n",
      "Iteration: 6401/10000, Loss: 0.005689220502972603\n",
      "Iteration: 6402/10000, Loss: 0.012761680409312248\n",
      "Iteration: 6403/10000, Loss: 0.009174548089504242\n",
      "Iteration: 6404/10000, Loss: 0.01074659638106823\n",
      "Iteration: 6405/10000, Loss: 0.00992355216294527\n",
      "Iteration: 6406/10000, Loss: 0.012264174409210682\n",
      "Iteration: 6407/10000, Loss: 0.010544192977249622\n",
      "Iteration: 6408/10000, Loss: 0.012100487016141415\n",
      "Iteration: 6409/10000, Loss: 0.011419919319450855\n",
      "Iteration: 6410/10000, Loss: 0.009813091717660427\n",
      "Iteration: 6411/10000, Loss: 0.007654597982764244\n",
      "Iteration: 6412/10000, Loss: 0.010600092820823193\n",
      "Iteration: 6413/10000, Loss: 0.01138302031904459\n",
      "Iteration: 6414/10000, Loss: 0.015559104271233082\n",
      "Iteration: 6415/10000, Loss: 0.008922483772039413\n",
      "Iteration: 6416/10000, Loss: 0.011906039901077747\n",
      "Iteration: 6417/10000, Loss: 0.009121869690716267\n",
      "Iteration: 6418/10000, Loss: 0.009682534262537956\n",
      "Iteration: 6419/10000, Loss: 0.011802734807133675\n",
      "Iteration: 6420/10000, Loss: 0.01390246581286192\n",
      "Iteration: 6421/10000, Loss: 0.008263975381851196\n",
      "Iteration: 6422/10000, Loss: 0.008168322965502739\n",
      "Iteration: 6423/10000, Loss: 0.00781090697273612\n",
      "Iteration: 6424/10000, Loss: 0.009763932786881924\n",
      "Iteration: 6425/10000, Loss: 0.016670916229486465\n",
      "Iteration: 6426/10000, Loss: 0.011144977062940598\n",
      "Iteration: 6427/10000, Loss: 0.008113086223602295\n",
      "Iteration: 6428/10000, Loss: 0.009178566746413708\n",
      "Iteration: 6429/10000, Loss: 0.00909736193716526\n",
      "Iteration: 6430/10000, Loss: 0.007685891352593899\n",
      "Iteration: 6431/10000, Loss: 0.012233265675604343\n",
      "Iteration: 6432/10000, Loss: 0.01107705757021904\n",
      "Iteration: 6433/10000, Loss: 0.0092180036008358\n",
      "Iteration: 6434/10000, Loss: 0.006323777139186859\n",
      "Iteration: 6435/10000, Loss: 0.007179932668805122\n",
      "Iteration: 6436/10000, Loss: 0.009258950129151344\n",
      "Iteration: 6437/10000, Loss: 0.009562562219798565\n",
      "Iteration: 6438/10000, Loss: 0.016418984159827232\n",
      "Iteration: 6439/10000, Loss: 0.013862794265151024\n",
      "Iteration: 6440/10000, Loss: 0.010536295361816883\n",
      "Iteration: 6441/10000, Loss: 0.007223094813525677\n",
      "Iteration: 6442/10000, Loss: 0.010836275294423103\n",
      "Iteration: 6443/10000, Loss: 0.014361106790602207\n",
      "Iteration: 6444/10000, Loss: 0.01303026732057333\n",
      "Iteration: 6445/10000, Loss: 0.008154982700943947\n",
      "Iteration: 6446/10000, Loss: 0.008282213471829891\n",
      "Iteration: 6447/10000, Loss: 0.010191699489951134\n",
      "Iteration: 6448/10000, Loss: 0.010254588909447193\n",
      "Iteration: 6449/10000, Loss: 0.007569680921733379\n",
      "Iteration: 6450/10000, Loss: 0.00574952969327569\n",
      "Iteration: 6451/10000, Loss: 0.015411277301609516\n",
      "Iteration: 6452/10000, Loss: 0.01637263596057892\n",
      "Iteration: 6453/10000, Loss: 0.013344113714993\n",
      "Iteration: 6454/10000, Loss: 0.011493531987071037\n",
      "Iteration: 6455/10000, Loss: 0.010409003123641014\n",
      "Iteration: 6456/10000, Loss: 0.012177669443190098\n",
      "Iteration: 6457/10000, Loss: 0.01155852060765028\n",
      "Iteration: 6458/10000, Loss: 0.012515276670455933\n",
      "Iteration: 6459/10000, Loss: 0.009612992405891418\n",
      "Iteration: 6460/10000, Loss: 0.01767681911587715\n",
      "Iteration: 6461/10000, Loss: 0.012819451279938221\n",
      "Iteration: 6462/10000, Loss: 0.009178855456411839\n",
      "Iteration: 6463/10000, Loss: 0.012824563309550285\n",
      "Iteration: 6464/10000, Loss: 0.011428355239331722\n",
      "Iteration: 6465/10000, Loss: 0.010584553703665733\n",
      "Iteration: 6466/10000, Loss: 0.013177788816392422\n",
      "Iteration: 6467/10000, Loss: 0.013601132668554783\n",
      "Iteration: 6468/10000, Loss: 0.0070959473960101604\n",
      "Iteration: 6469/10000, Loss: 0.01186864823102951\n",
      "Iteration: 6470/10000, Loss: 0.009187445975840092\n",
      "Iteration: 6471/10000, Loss: 0.009362665936350822\n",
      "Iteration: 6472/10000, Loss: 0.006431328598409891\n",
      "Iteration: 6473/10000, Loss: 0.012121492996811867\n",
      "Iteration: 6474/10000, Loss: 0.015038575045764446\n",
      "Iteration: 6475/10000, Loss: 0.007746181450784206\n",
      "Iteration: 6476/10000, Loss: 0.00828537903726101\n",
      "Iteration: 6477/10000, Loss: 0.011390607804059982\n",
      "Iteration: 6478/10000, Loss: 0.006851170677691698\n",
      "Iteration: 6479/10000, Loss: 0.013545520603656769\n",
      "Iteration: 6480/10000, Loss: 0.011294395662844181\n",
      "Iteration: 6481/10000, Loss: 0.013943657279014587\n",
      "Iteration: 6482/10000, Loss: 0.010706372559070587\n",
      "Iteration: 6483/10000, Loss: 0.009303692728281021\n",
      "Iteration: 6484/10000, Loss: 0.01419447548687458\n",
      "Iteration: 6485/10000, Loss: 0.016033198684453964\n",
      "Iteration: 6486/10000, Loss: 0.011100513860583305\n",
      "Iteration: 6487/10000, Loss: 0.0076131620444357395\n",
      "Iteration: 6488/10000, Loss: 0.00880103837698698\n",
      "Iteration: 6489/10000, Loss: 0.008158094249665737\n",
      "Iteration: 6490/10000, Loss: 0.010434688068926334\n",
      "Iteration: 6491/10000, Loss: 0.010732589289546013\n",
      "Iteration: 6492/10000, Loss: 0.012004776857793331\n",
      "Iteration: 6493/10000, Loss: 0.007804517634212971\n",
      "Iteration: 6494/10000, Loss: 0.011665775440633297\n",
      "Iteration: 6495/10000, Loss: 0.010446982458233833\n",
      "Iteration: 6496/10000, Loss: 0.007918466813862324\n",
      "Iteration: 6497/10000, Loss: 0.00924996379762888\n",
      "Iteration: 6498/10000, Loss: 0.005930905230343342\n",
      "Iteration: 6499/10000, Loss: 0.009925798512995243\n",
      "Iteration: 6500/10000, Loss: 0.012050705961883068\n",
      "Average test loss:  0.0025\n",
      "Iteration: 6501/10000, Loss: 0.015632107853889465\n",
      "Iteration: 6502/10000, Loss: 0.012579986825585365\n",
      "Iteration: 6503/10000, Loss: 0.018735438585281372\n",
      "Iteration: 6504/10000, Loss: 0.012472120113670826\n",
      "Iteration: 6505/10000, Loss: 0.011532551608979702\n",
      "Iteration: 6506/10000, Loss: 0.01265865471214056\n",
      "Iteration: 6507/10000, Loss: 0.010660943575203419\n",
      "Iteration: 6508/10000, Loss: 0.011547521688044071\n",
      "Iteration: 6509/10000, Loss: 0.0144112603738904\n",
      "Iteration: 6510/10000, Loss: 0.009498479776084423\n",
      "Iteration: 6511/10000, Loss: 0.010785535909235477\n",
      "Iteration: 6512/10000, Loss: 0.012526202946901321\n",
      "Iteration: 6513/10000, Loss: 0.01088624820113182\n",
      "Iteration: 6514/10000, Loss: 0.00820799358189106\n",
      "Iteration: 6515/10000, Loss: 0.008608302101492882\n",
      "Iteration: 6516/10000, Loss: 0.009132408536970615\n",
      "Iteration: 6517/10000, Loss: 0.013024844229221344\n",
      "Iteration: 6518/10000, Loss: 0.010122696869075298\n",
      "Iteration: 6519/10000, Loss: 0.011697543784976006\n",
      "Iteration: 6520/10000, Loss: 0.010896432213485241\n",
      "Iteration: 6521/10000, Loss: 0.016702039167284966\n",
      "Iteration: 6522/10000, Loss: 0.009571388363838196\n",
      "Iteration: 6523/10000, Loss: 0.014731504954397678\n",
      "Iteration: 6524/10000, Loss: 0.012173475697636604\n",
      "Iteration: 6525/10000, Loss: 0.010040382854640484\n",
      "Iteration: 6526/10000, Loss: 0.011081987991929054\n",
      "Iteration: 6527/10000, Loss: 0.013654768466949463\n",
      "Iteration: 6528/10000, Loss: 0.013109005987644196\n",
      "Iteration: 6529/10000, Loss: 0.009103482589125633\n",
      "Iteration: 6530/10000, Loss: 0.010101496241986752\n",
      "Iteration: 6531/10000, Loss: 0.01137080229818821\n",
      "Iteration: 6532/10000, Loss: 0.010377712547779083\n",
      "Iteration: 6533/10000, Loss: 0.009074063040316105\n",
      "Iteration: 6534/10000, Loss: 0.0091874860227108\n",
      "Iteration: 6535/10000, Loss: 0.011879420839250088\n",
      "Iteration: 6536/10000, Loss: 0.011721228249371052\n",
      "Iteration: 6537/10000, Loss: 0.007178457919508219\n",
      "Iteration: 6538/10000, Loss: 0.013648212887346745\n",
      "Iteration: 6539/10000, Loss: 0.006510215811431408\n",
      "Iteration: 6540/10000, Loss: 0.009498686529695988\n",
      "Iteration: 6541/10000, Loss: 0.016193795949220657\n",
      "Iteration: 6542/10000, Loss: 0.013057113625109196\n",
      "Iteration: 6543/10000, Loss: 0.007300637662410736\n",
      "Iteration: 6544/10000, Loss: 0.01121794804930687\n",
      "Iteration: 6545/10000, Loss: 0.010262587107717991\n",
      "Iteration: 6546/10000, Loss: 0.014344120398163795\n",
      "Iteration: 6547/10000, Loss: 0.014545607380568981\n",
      "Iteration: 6548/10000, Loss: 0.007334503810852766\n",
      "Iteration: 6549/10000, Loss: 0.011056113988161087\n",
      "Iteration: 6550/10000, Loss: 0.005473025143146515\n",
      "Iteration: 6551/10000, Loss: 0.010551546700298786\n",
      "Iteration: 6552/10000, Loss: 0.006321694701910019\n",
      "Iteration: 6553/10000, Loss: 0.011361110024154186\n",
      "Iteration: 6554/10000, Loss: 0.008905423805117607\n",
      "Iteration: 6555/10000, Loss: 0.012393689714372158\n",
      "Iteration: 6556/10000, Loss: 0.011065270751714706\n",
      "Iteration: 6557/10000, Loss: 0.012251068837940693\n",
      "Iteration: 6558/10000, Loss: 0.00617607869207859\n",
      "Iteration: 6559/10000, Loss: 0.011951550841331482\n",
      "Iteration: 6560/10000, Loss: 0.010469874367117882\n",
      "Iteration: 6561/10000, Loss: 0.011272866278886795\n",
      "Iteration: 6562/10000, Loss: 0.012741225771605968\n",
      "Iteration: 6563/10000, Loss: 0.01069660298526287\n",
      "Iteration: 6564/10000, Loss: 0.012021197937428951\n",
      "Iteration: 6565/10000, Loss: 0.008584187366068363\n",
      "Iteration: 6566/10000, Loss: 0.009321199730038643\n",
      "Iteration: 6567/10000, Loss: 0.011624918319284916\n",
      "Iteration: 6568/10000, Loss: 0.010660854168236256\n",
      "Iteration: 6569/10000, Loss: 0.01638721488416195\n",
      "Iteration: 6570/10000, Loss: 0.011665110476315022\n",
      "Iteration: 6571/10000, Loss: 0.0046937121078372\n",
      "Iteration: 6572/10000, Loss: 0.007711627520620823\n",
      "Iteration: 6573/10000, Loss: 0.0092038968577981\n",
      "Iteration: 6574/10000, Loss: 0.011088106781244278\n",
      "Iteration: 6575/10000, Loss: 0.00979465153068304\n",
      "Iteration: 6576/10000, Loss: 0.012204447761178017\n",
      "Iteration: 6577/10000, Loss: 0.01123489998281002\n",
      "Iteration: 6578/10000, Loss: 0.013214770704507828\n",
      "Iteration: 6579/10000, Loss: 0.013245656155049801\n",
      "Iteration: 6580/10000, Loss: 0.011422192677855492\n",
      "Iteration: 6581/10000, Loss: 0.012963954359292984\n",
      "Iteration: 6582/10000, Loss: 0.014136213809251785\n",
      "Iteration: 6583/10000, Loss: 0.01396147720515728\n",
      "Iteration: 6584/10000, Loss: 0.010944060049951077\n",
      "Iteration: 6585/10000, Loss: 0.01279480755329132\n",
      "Iteration: 6586/10000, Loss: 0.011218884959816933\n",
      "Iteration: 6587/10000, Loss: 0.011517046019434929\n",
      "Iteration: 6588/10000, Loss: 0.007246721535921097\n",
      "Iteration: 6589/10000, Loss: 0.008837800472974777\n",
      "Iteration: 6590/10000, Loss: 0.01267905905842781\n",
      "Iteration: 6591/10000, Loss: 0.011916236020624638\n",
      "Iteration: 6592/10000, Loss: 0.011005564592778683\n",
      "Iteration: 6593/10000, Loss: 0.011289303191006184\n",
      "Iteration: 6594/10000, Loss: 0.012896665371954441\n",
      "Iteration: 6595/10000, Loss: 0.00876721739768982\n",
      "Iteration: 6596/10000, Loss: 0.010440219193696976\n",
      "Iteration: 6597/10000, Loss: 0.014327621087431908\n",
      "Iteration: 6598/10000, Loss: 0.012162159197032452\n",
      "Iteration: 6599/10000, Loss: 0.009668391197919846\n",
      "Iteration: 6600/10000, Loss: 0.008625921793282032\n",
      "Average test loss:  0.0023\n",
      "Iteration: 6601/10000, Loss: 0.009308292530477047\n",
      "Iteration: 6602/10000, Loss: 0.014827229082584381\n",
      "Iteration: 6603/10000, Loss: 0.015341559424996376\n",
      "Iteration: 6604/10000, Loss: 0.011930437758564949\n",
      "Iteration: 6605/10000, Loss: 0.00926545262336731\n",
      "Iteration: 6606/10000, Loss: 0.013694980181753635\n",
      "Iteration: 6607/10000, Loss: 0.01373747643083334\n",
      "Iteration: 6608/10000, Loss: 0.012522303499281406\n",
      "Iteration: 6609/10000, Loss: 0.0096029257401824\n",
      "Iteration: 6610/10000, Loss: 0.008987221866846085\n",
      "Iteration: 6611/10000, Loss: 0.008145658299326897\n",
      "Iteration: 6612/10000, Loss: 0.011827907525002956\n",
      "Iteration: 6613/10000, Loss: 0.013380459509789944\n",
      "Iteration: 6614/10000, Loss: 0.024383993819355965\n",
      "Iteration: 6615/10000, Loss: 0.007854758761823177\n",
      "Iteration: 6616/10000, Loss: 0.01655937358736992\n",
      "Iteration: 6617/10000, Loss: 0.012653510086238384\n",
      "Iteration: 6618/10000, Loss: 0.007383690215647221\n",
      "Iteration: 6619/10000, Loss: 0.010295173153281212\n",
      "Iteration: 6620/10000, Loss: 0.010788909159600735\n",
      "Iteration: 6621/10000, Loss: 0.013555601239204407\n",
      "Iteration: 6622/10000, Loss: 0.012811127118766308\n",
      "Iteration: 6623/10000, Loss: 0.013955313712358475\n",
      "Iteration: 6624/10000, Loss: 0.013503036461770535\n",
      "Iteration: 6625/10000, Loss: 0.006807038560509682\n",
      "Iteration: 6626/10000, Loss: 0.00892000924795866\n",
      "Iteration: 6627/10000, Loss: 0.009035930037498474\n",
      "Iteration: 6628/10000, Loss: 0.011671251617372036\n",
      "Iteration: 6629/10000, Loss: 0.007026260253041983\n",
      "Iteration: 6630/10000, Loss: 0.012092268094420433\n",
      "Iteration: 6631/10000, Loss: 0.009865308180451393\n",
      "Iteration: 6632/10000, Loss: 0.012878949753940105\n",
      "Iteration: 6633/10000, Loss: 0.009954337030649185\n",
      "Iteration: 6634/10000, Loss: 0.017685722559690475\n",
      "Iteration: 6635/10000, Loss: 0.00975753366947174\n",
      "Iteration: 6636/10000, Loss: 0.010718021541833878\n",
      "Iteration: 6637/10000, Loss: 0.009380879811942577\n",
      "Iteration: 6638/10000, Loss: 0.010984759777784348\n",
      "Iteration: 6639/10000, Loss: 0.01168050430715084\n",
      "Iteration: 6640/10000, Loss: 0.009177220053970814\n",
      "Iteration: 6641/10000, Loss: 0.018393894657492638\n",
      "Iteration: 6642/10000, Loss: 0.01540490984916687\n",
      "Iteration: 6643/10000, Loss: 0.012268411926925182\n",
      "Iteration: 6644/10000, Loss: 0.008581217378377914\n",
      "Iteration: 6645/10000, Loss: 0.010392231866717339\n",
      "Iteration: 6646/10000, Loss: 0.014205501414835453\n",
      "Iteration: 6647/10000, Loss: 0.011041225865483284\n",
      "Iteration: 6648/10000, Loss: 0.009157517924904823\n",
      "Iteration: 6649/10000, Loss: 0.010203247889876366\n",
      "Iteration: 6650/10000, Loss: 0.012888524681329727\n",
      "Iteration: 6651/10000, Loss: 0.011968088336288929\n",
      "Iteration: 6652/10000, Loss: 0.011022958904504776\n",
      "Iteration: 6653/10000, Loss: 0.007865803316235542\n",
      "Iteration: 6654/10000, Loss: 0.013438981026411057\n",
      "Iteration: 6655/10000, Loss: 0.010209797881543636\n",
      "Iteration: 6656/10000, Loss: 0.009311017580330372\n",
      "Iteration: 6657/10000, Loss: 0.011617111973464489\n",
      "Iteration: 6658/10000, Loss: 0.011232351884245872\n",
      "Iteration: 6659/10000, Loss: 0.012464707717299461\n",
      "Iteration: 6660/10000, Loss: 0.005544832907617092\n",
      "Iteration: 6661/10000, Loss: 0.009539807215332985\n",
      "Iteration: 6662/10000, Loss: 0.013843713328242302\n",
      "Iteration: 6663/10000, Loss: 0.012401155196130276\n",
      "Iteration: 6664/10000, Loss: 0.009242541156709194\n",
      "Iteration: 6665/10000, Loss: 0.010993847623467445\n",
      "Iteration: 6666/10000, Loss: 0.015459221787750721\n",
      "Iteration: 6667/10000, Loss: 0.012744959443807602\n",
      "Iteration: 6668/10000, Loss: 0.010134226642549038\n",
      "Iteration: 6669/10000, Loss: 0.008787306025624275\n",
      "Iteration: 6670/10000, Loss: 0.011675718240439892\n",
      "Iteration: 6671/10000, Loss: 0.008346443995833397\n",
      "Iteration: 6672/10000, Loss: 0.007741734851151705\n",
      "Iteration: 6673/10000, Loss: 0.010657820850610733\n",
      "Iteration: 6674/10000, Loss: 0.008760707452893257\n",
      "Iteration: 6675/10000, Loss: 0.009162704460322857\n",
      "Iteration: 6676/10000, Loss: 0.011024916544556618\n",
      "Iteration: 6677/10000, Loss: 0.01244684960693121\n",
      "Iteration: 6678/10000, Loss: 0.012006773613393307\n",
      "Iteration: 6679/10000, Loss: 0.012315290980041027\n",
      "Iteration: 6680/10000, Loss: 0.011759419925510883\n",
      "Iteration: 6681/10000, Loss: 0.010301650501787663\n",
      "Iteration: 6682/10000, Loss: 0.01606566831469536\n",
      "Iteration: 6683/10000, Loss: 0.013173328712582588\n",
      "Iteration: 6684/10000, Loss: 0.010622881352901459\n",
      "Iteration: 6685/10000, Loss: 0.012394709512591362\n",
      "Iteration: 6686/10000, Loss: 0.011091334745287895\n",
      "Iteration: 6687/10000, Loss: 0.010892865248024464\n",
      "Iteration: 6688/10000, Loss: 0.013294537551701069\n",
      "Iteration: 6689/10000, Loss: 0.010871585458517075\n",
      "Iteration: 6690/10000, Loss: 0.009025518782436848\n",
      "Iteration: 6691/10000, Loss: 0.009708116762340069\n",
      "Iteration: 6692/10000, Loss: 0.00879661925137043\n",
      "Iteration: 6693/10000, Loss: 0.012780548073351383\n",
      "Iteration: 6694/10000, Loss: 0.0071572670713067055\n",
      "Iteration: 6695/10000, Loss: 0.008004027418792248\n",
      "Iteration: 6696/10000, Loss: 0.012433567084372044\n",
      "Iteration: 6697/10000, Loss: 0.009364219382405281\n",
      "Iteration: 6698/10000, Loss: 0.009165141731500626\n",
      "Iteration: 6699/10000, Loss: 0.014876122586429119\n",
      "Iteration: 6700/10000, Loss: 0.007265280932188034\n",
      "Average test loss:  0.0031\n",
      "Iteration: 6701/10000, Loss: 0.009700611233711243\n",
      "Iteration: 6702/10000, Loss: 0.010325383394956589\n",
      "Iteration: 6703/10000, Loss: 0.008818383328616619\n",
      "Iteration: 6704/10000, Loss: 0.014305874705314636\n",
      "Iteration: 6705/10000, Loss: 0.011565182358026505\n",
      "Iteration: 6706/10000, Loss: 0.01087575126439333\n",
      "Iteration: 6707/10000, Loss: 0.010764706879854202\n",
      "Iteration: 6708/10000, Loss: 0.012794683687388897\n",
      "Iteration: 6709/10000, Loss: 0.010964656248688698\n",
      "Iteration: 6710/10000, Loss: 0.010809977538883686\n",
      "Iteration: 6711/10000, Loss: 0.011836743913590908\n",
      "Iteration: 6712/10000, Loss: 0.008663247339427471\n",
      "Iteration: 6713/10000, Loss: 0.011518808081746101\n",
      "Iteration: 6714/10000, Loss: 0.00985662266612053\n",
      "Iteration: 6715/10000, Loss: 0.008456183597445488\n",
      "Iteration: 6716/10000, Loss: 0.010735375806689262\n",
      "Iteration: 6717/10000, Loss: 0.01000287290662527\n",
      "Iteration: 6718/10000, Loss: 0.008807845413684845\n",
      "Iteration: 6719/10000, Loss: 0.010254718363285065\n",
      "Iteration: 6720/10000, Loss: 0.012058437801897526\n",
      "Iteration: 6721/10000, Loss: 0.005083371885120869\n",
      "Iteration: 6722/10000, Loss: 0.009079713374376297\n",
      "Iteration: 6723/10000, Loss: 0.009714165702462196\n",
      "Iteration: 6724/10000, Loss: 0.009859764948487282\n",
      "Iteration: 6725/10000, Loss: 0.015618853271007538\n",
      "Iteration: 6726/10000, Loss: 0.012461251579225063\n",
      "Iteration: 6727/10000, Loss: 0.010358934290707111\n",
      "Iteration: 6728/10000, Loss: 0.012954826466739178\n",
      "Iteration: 6729/10000, Loss: 0.006997637916356325\n",
      "Iteration: 6730/10000, Loss: 0.010554162785410881\n",
      "Iteration: 6731/10000, Loss: 0.011244161054491997\n",
      "Iteration: 6732/10000, Loss: 0.008964289911091328\n",
      "Iteration: 6733/10000, Loss: 0.009776863269507885\n",
      "Iteration: 6734/10000, Loss: 0.0065653580240905285\n",
      "Iteration: 6735/10000, Loss: 0.011191409081220627\n",
      "Iteration: 6736/10000, Loss: 0.013784359209239483\n",
      "Iteration: 6737/10000, Loss: 0.01353374868631363\n",
      "Iteration: 6738/10000, Loss: 0.010051313787698746\n",
      "Iteration: 6739/10000, Loss: 0.008269375190138817\n",
      "Iteration: 6740/10000, Loss: 0.010644352063536644\n",
      "Iteration: 6741/10000, Loss: 0.011913682334125042\n",
      "Iteration: 6742/10000, Loss: 0.011753268539905548\n",
      "Iteration: 6743/10000, Loss: 0.01076197437942028\n",
      "Iteration: 6744/10000, Loss: 0.008998150937259197\n",
      "Iteration: 6745/10000, Loss: 0.013433314859867096\n",
      "Iteration: 6746/10000, Loss: 0.011510313488543034\n",
      "Iteration: 6747/10000, Loss: 0.012843695469200611\n",
      "Iteration: 6748/10000, Loss: 0.013516701757907867\n",
      "Iteration: 6749/10000, Loss: 0.008028287440538406\n",
      "Iteration: 6750/10000, Loss: 0.009289794601500034\n",
      "Iteration: 6751/10000, Loss: 0.006756620481610298\n",
      "Iteration: 6752/10000, Loss: 0.011287343688309193\n",
      "Iteration: 6753/10000, Loss: 0.01282294001430273\n",
      "Iteration: 6754/10000, Loss: 0.013951145112514496\n",
      "Iteration: 6755/10000, Loss: 0.007577105425298214\n",
      "Iteration: 6756/10000, Loss: 0.012404641136527061\n",
      "Iteration: 6757/10000, Loss: 0.018139656633138657\n",
      "Iteration: 6758/10000, Loss: 0.011263116262853146\n",
      "Iteration: 6759/10000, Loss: 0.011683142744004726\n",
      "Iteration: 6760/10000, Loss: 0.012794196605682373\n",
      "Iteration: 6761/10000, Loss: 0.008810252882540226\n",
      "Iteration: 6762/10000, Loss: 0.009586362168192863\n",
      "Iteration: 6763/10000, Loss: 0.013213535770773888\n",
      "Iteration: 6764/10000, Loss: 0.008974060416221619\n",
      "Iteration: 6765/10000, Loss: 0.0055823964066803455\n",
      "Iteration: 6766/10000, Loss: 0.013292795047163963\n",
      "Iteration: 6767/10000, Loss: 0.007947453297674656\n",
      "Iteration: 6768/10000, Loss: 0.01064999308437109\n",
      "Iteration: 6769/10000, Loss: 0.010075239464640617\n",
      "Iteration: 6770/10000, Loss: 0.013576751574873924\n",
      "Iteration: 6771/10000, Loss: 0.009102197363972664\n",
      "Iteration: 6772/10000, Loss: 0.009495770558714867\n",
      "Iteration: 6773/10000, Loss: 0.011839786544442177\n",
      "Iteration: 6774/10000, Loss: 0.012410827912390232\n",
      "Iteration: 6775/10000, Loss: 0.011987270787358284\n",
      "Iteration: 6776/10000, Loss: 0.008868719451129436\n",
      "Iteration: 6777/10000, Loss: 0.01063388679176569\n",
      "Iteration: 6778/10000, Loss: 0.008135689422488213\n",
      "Iteration: 6779/10000, Loss: 0.011076067574322224\n",
      "Iteration: 6780/10000, Loss: 0.011521884240210056\n",
      "Iteration: 6781/10000, Loss: 0.010454326868057251\n",
      "Iteration: 6782/10000, Loss: 0.014454840682446957\n",
      "Iteration: 6783/10000, Loss: 0.008547989651560783\n",
      "Iteration: 6784/10000, Loss: 0.012778228148818016\n",
      "Iteration: 6785/10000, Loss: 0.00780746154487133\n",
      "Iteration: 6786/10000, Loss: 0.02095835842192173\n",
      "Iteration: 6787/10000, Loss: 0.007969897240400314\n",
      "Iteration: 6788/10000, Loss: 0.010106188245117664\n",
      "Iteration: 6789/10000, Loss: 0.010979666374623775\n",
      "Iteration: 6790/10000, Loss: 0.007020649500191212\n",
      "Iteration: 6791/10000, Loss: 0.010695824399590492\n",
      "Iteration: 6792/10000, Loss: 0.00870023388415575\n",
      "Iteration: 6793/10000, Loss: 0.010839883238077164\n",
      "Iteration: 6794/10000, Loss: 0.010946933180093765\n",
      "Iteration: 6795/10000, Loss: 0.010108832269906998\n",
      "Iteration: 6796/10000, Loss: 0.007592309266328812\n",
      "Iteration: 6797/10000, Loss: 0.009487099945545197\n",
      "Iteration: 6798/10000, Loss: 0.013499542139470577\n",
      "Iteration: 6799/10000, Loss: 0.011396193876862526\n",
      "Iteration: 6800/10000, Loss: 0.012442078441381454\n",
      "Average test loss:  0.0030\n",
      "Iteration: 6801/10000, Loss: 0.0076474533416330814\n",
      "Iteration: 6802/10000, Loss: 0.008909584954380989\n",
      "Iteration: 6803/10000, Loss: 0.011834966950118542\n",
      "Iteration: 6804/10000, Loss: 0.010359430685639381\n",
      "Iteration: 6805/10000, Loss: 0.011236661113798618\n",
      "Iteration: 6806/10000, Loss: 0.007246777880936861\n",
      "Iteration: 6807/10000, Loss: 0.007127062417566776\n",
      "Iteration: 6808/10000, Loss: 0.010402930900454521\n",
      "Iteration: 6809/10000, Loss: 0.007915148511528969\n",
      "Iteration: 6810/10000, Loss: 0.009826384484767914\n",
      "Iteration: 6811/10000, Loss: 0.011497143656015396\n",
      "Iteration: 6812/10000, Loss: 0.011551112867891788\n",
      "Iteration: 6813/10000, Loss: 0.009385748766362667\n",
      "Iteration: 6814/10000, Loss: 0.00868068728595972\n",
      "Iteration: 6815/10000, Loss: 0.012385904788970947\n",
      "Iteration: 6816/10000, Loss: 0.012998887337744236\n",
      "Iteration: 6817/10000, Loss: 0.011803698725998402\n",
      "Iteration: 6818/10000, Loss: 0.010706416331231594\n",
      "Iteration: 6819/10000, Loss: 0.009458028711378574\n",
      "Iteration: 6820/10000, Loss: 0.01936563104391098\n",
      "Iteration: 6821/10000, Loss: 0.007617074530571699\n",
      "Iteration: 6822/10000, Loss: 0.010570956394076347\n",
      "Iteration: 6823/10000, Loss: 0.008739739656448364\n",
      "Iteration: 6824/10000, Loss: 0.010477728210389614\n",
      "Iteration: 6825/10000, Loss: 0.010136793367564678\n",
      "Iteration: 6826/10000, Loss: 0.013750104233622551\n",
      "Iteration: 6827/10000, Loss: 0.012677818536758423\n",
      "Iteration: 6828/10000, Loss: 0.0052983700297772884\n",
      "Iteration: 6829/10000, Loss: 0.0076070488430559635\n",
      "Iteration: 6830/10000, Loss: 0.01058247871696949\n",
      "Iteration: 6831/10000, Loss: 0.012465676292777061\n",
      "Iteration: 6832/10000, Loss: 0.009746980853378773\n",
      "Iteration: 6833/10000, Loss: 0.01029962208122015\n",
      "Iteration: 6834/10000, Loss: 0.00797448679804802\n",
      "Iteration: 6835/10000, Loss: 0.02193981409072876\n",
      "Iteration: 6836/10000, Loss: 0.011262429878115654\n",
      "Iteration: 6837/10000, Loss: 0.016668817028403282\n",
      "Iteration: 6838/10000, Loss: 0.011432732455432415\n",
      "Iteration: 6839/10000, Loss: 0.013336479663848877\n",
      "Iteration: 6840/10000, Loss: 0.006784441880881786\n",
      "Iteration: 6841/10000, Loss: 0.009249741211533546\n",
      "Iteration: 6842/10000, Loss: 0.006834056228399277\n",
      "Iteration: 6843/10000, Loss: 0.02084225043654442\n",
      "Iteration: 6844/10000, Loss: 0.005287470296025276\n",
      "Iteration: 6845/10000, Loss: 0.00812844093888998\n",
      "Iteration: 6846/10000, Loss: 0.008253104984760284\n",
      "Iteration: 6847/10000, Loss: 0.012550137005746365\n",
      "Iteration: 6848/10000, Loss: 0.008743134327232838\n",
      "Iteration: 6849/10000, Loss: 0.009364883415400982\n",
      "Iteration: 6850/10000, Loss: 0.00992173608392477\n",
      "Iteration: 6851/10000, Loss: 0.01024613156914711\n",
      "Iteration: 6852/10000, Loss: 0.01127928588539362\n",
      "Iteration: 6853/10000, Loss: 0.008983801119029522\n",
      "Iteration: 6854/10000, Loss: 0.014274932444095612\n",
      "Iteration: 6855/10000, Loss: 0.012289517559111118\n",
      "Iteration: 6856/10000, Loss: 0.010002726688981056\n",
      "Iteration: 6857/10000, Loss: 0.012339913286268711\n",
      "Iteration: 6858/10000, Loss: 0.010810626670718193\n",
      "Iteration: 6859/10000, Loss: 0.011561917141079903\n",
      "Iteration: 6860/10000, Loss: 0.007036067545413971\n",
      "Iteration: 6861/10000, Loss: 0.012026697397232056\n",
      "Iteration: 6862/10000, Loss: 0.013065564446151257\n",
      "Iteration: 6863/10000, Loss: 0.012018180452287197\n",
      "Iteration: 6864/10000, Loss: 0.008205427788197994\n",
      "Iteration: 6865/10000, Loss: 0.010921476408839226\n",
      "Iteration: 6866/10000, Loss: 0.014032632112503052\n",
      "Iteration: 6867/10000, Loss: 0.009244177490472794\n",
      "Iteration: 6868/10000, Loss: 0.010696473531425\n",
      "Iteration: 6869/10000, Loss: 0.011725319549441338\n",
      "Iteration: 6870/10000, Loss: 0.011405865661799908\n",
      "Iteration: 6871/10000, Loss: 0.011733891442418098\n",
      "Iteration: 6872/10000, Loss: 0.011783028952777386\n",
      "Iteration: 6873/10000, Loss: 0.010786667466163635\n",
      "Iteration: 6874/10000, Loss: 0.011703216470777988\n",
      "Iteration: 6875/10000, Loss: 0.008306329138576984\n",
      "Iteration: 6876/10000, Loss: 0.009427741169929504\n",
      "Iteration: 6877/10000, Loss: 0.015952832996845245\n",
      "Iteration: 6878/10000, Loss: 0.010591777972877026\n",
      "Iteration: 6879/10000, Loss: 0.009014050476253033\n",
      "Iteration: 6880/10000, Loss: 0.0076742591336369514\n",
      "Iteration: 6881/10000, Loss: 0.012993660755455494\n",
      "Iteration: 6882/10000, Loss: 0.010401645675301552\n",
      "Iteration: 6883/10000, Loss: 0.007553501054644585\n",
      "Iteration: 6884/10000, Loss: 0.006708596367388964\n",
      "Iteration: 6885/10000, Loss: 0.011353808455169201\n",
      "Iteration: 6886/10000, Loss: 0.007623360492289066\n",
      "Iteration: 6887/10000, Loss: 0.00957320723682642\n",
      "Iteration: 6888/10000, Loss: 0.00867075752466917\n",
      "Iteration: 6889/10000, Loss: 0.010568356141448021\n",
      "Iteration: 6890/10000, Loss: 0.009620161727070808\n",
      "Iteration: 6891/10000, Loss: 0.006740453653037548\n",
      "Iteration: 6892/10000, Loss: 0.012272041290998459\n",
      "Iteration: 6893/10000, Loss: 0.005517780315130949\n",
      "Iteration: 6894/10000, Loss: 0.0060751293785870075\n",
      "Iteration: 6895/10000, Loss: 0.008921205066144466\n",
      "Iteration: 6896/10000, Loss: 0.011512910947203636\n",
      "Iteration: 6897/10000, Loss: 0.009498300962150097\n",
      "Iteration: 6898/10000, Loss: 0.00923946127295494\n",
      "Iteration: 6899/10000, Loss: 0.010728097520768642\n",
      "Iteration: 6900/10000, Loss: 0.010610896162688732\n",
      "Average test loss:  0.0025\n",
      "Iteration: 6901/10000, Loss: 0.011410568840801716\n",
      "Iteration: 6902/10000, Loss: 0.012777245603501797\n",
      "Iteration: 6903/10000, Loss: 0.009105858393013477\n",
      "Iteration: 6904/10000, Loss: 0.01167382299900055\n",
      "Iteration: 6905/10000, Loss: 0.013333100825548172\n",
      "Iteration: 6906/10000, Loss: 0.014174350537359715\n",
      "Iteration: 6907/10000, Loss: 0.012534146197140217\n",
      "Iteration: 6908/10000, Loss: 0.011240696534514427\n",
      "Iteration: 6909/10000, Loss: 0.007958173751831055\n",
      "Iteration: 6910/10000, Loss: 0.004805437289178371\n",
      "Iteration: 6911/10000, Loss: 0.010687094181776047\n",
      "Iteration: 6912/10000, Loss: 0.01494008582085371\n",
      "Iteration: 6913/10000, Loss: 0.00909355841577053\n",
      "Iteration: 6914/10000, Loss: 0.005907024722546339\n",
      "Iteration: 6915/10000, Loss: 0.009844215586781502\n",
      "Iteration: 6916/10000, Loss: 0.011484012007713318\n",
      "Iteration: 6917/10000, Loss: 0.015775253996253014\n",
      "Iteration: 6918/10000, Loss: 0.009626602753996849\n",
      "Iteration: 6919/10000, Loss: 0.00924956239759922\n",
      "Iteration: 6920/10000, Loss: 0.010467399843037128\n",
      "Iteration: 6921/10000, Loss: 0.007374065928161144\n",
      "Iteration: 6922/10000, Loss: 0.007443496026098728\n",
      "Iteration: 6923/10000, Loss: 0.011009486392140388\n",
      "Iteration: 6924/10000, Loss: 0.009555816650390625\n",
      "Iteration: 6925/10000, Loss: 0.010438206605613232\n",
      "Iteration: 6926/10000, Loss: 0.011141655035316944\n",
      "Iteration: 6927/10000, Loss: 0.011885232292115688\n",
      "Iteration: 6928/10000, Loss: 0.011621851474046707\n",
      "Iteration: 6929/10000, Loss: 0.006352233234792948\n",
      "Iteration: 6930/10000, Loss: 0.010377512313425541\n",
      "Iteration: 6931/10000, Loss: 0.009082001633942127\n",
      "Iteration: 6932/10000, Loss: 0.012611253187060356\n",
      "Iteration: 6933/10000, Loss: 0.015877697616815567\n",
      "Iteration: 6934/10000, Loss: 0.00897525530308485\n",
      "Iteration: 6935/10000, Loss: 0.008262447081506252\n",
      "Iteration: 6936/10000, Loss: 0.011098981834948063\n",
      "Iteration: 6937/10000, Loss: 0.0111029502004385\n",
      "Iteration: 6938/10000, Loss: 0.008025984279811382\n",
      "Iteration: 6939/10000, Loss: 0.008693147450685501\n",
      "Iteration: 6940/10000, Loss: 0.010380778461694717\n",
      "Iteration: 6941/10000, Loss: 0.011067352257668972\n",
      "Iteration: 6942/10000, Loss: 0.00880519300699234\n",
      "Iteration: 6943/10000, Loss: 0.013906332664191723\n",
      "Iteration: 6944/10000, Loss: 0.009908027946949005\n",
      "Iteration: 6945/10000, Loss: 0.012602555565536022\n",
      "Iteration: 6946/10000, Loss: 0.012345789931714535\n",
      "Iteration: 6947/10000, Loss: 0.008226449601352215\n",
      "Iteration: 6948/10000, Loss: 0.007715160492807627\n",
      "Iteration: 6949/10000, Loss: 0.013967030681669712\n",
      "Iteration: 6950/10000, Loss: 0.010660136118531227\n",
      "Iteration: 6951/10000, Loss: 0.0056458208709955215\n",
      "Iteration: 6952/10000, Loss: 0.011874205432832241\n",
      "Iteration: 6953/10000, Loss: 0.01077253744006157\n",
      "Iteration: 6954/10000, Loss: 0.008074212819337845\n",
      "Iteration: 6955/10000, Loss: 0.011661792173981667\n",
      "Iteration: 6956/10000, Loss: 0.008390032686293125\n",
      "Iteration: 6957/10000, Loss: 0.009456545114517212\n",
      "Iteration: 6958/10000, Loss: 0.011655399575829506\n",
      "Iteration: 6959/10000, Loss: 0.012303156778216362\n",
      "Iteration: 6960/10000, Loss: 0.007672449573874474\n",
      "Iteration: 6961/10000, Loss: 0.011684785597026348\n",
      "Iteration: 6962/10000, Loss: 0.01330339815467596\n",
      "Iteration: 6963/10000, Loss: 0.010863790288567543\n",
      "Iteration: 6964/10000, Loss: 0.00830234307795763\n",
      "Iteration: 6965/10000, Loss: 0.011224295012652874\n",
      "Iteration: 6966/10000, Loss: 0.0077976807951927185\n",
      "Iteration: 6967/10000, Loss: 0.012378199957311153\n",
      "Iteration: 6968/10000, Loss: 0.0047518410719931126\n",
      "Iteration: 6969/10000, Loss: 0.008999116718769073\n",
      "Iteration: 6970/10000, Loss: 0.014533847570419312\n",
      "Iteration: 6971/10000, Loss: 0.01031502429395914\n",
      "Iteration: 6972/10000, Loss: 0.006852992344647646\n",
      "Iteration: 6973/10000, Loss: 0.010428917594254017\n",
      "Iteration: 6974/10000, Loss: 0.010110798291862011\n",
      "Iteration: 6975/10000, Loss: 0.007685315329581499\n",
      "Iteration: 6976/10000, Loss: 0.011493743397295475\n",
      "Iteration: 6977/10000, Loss: 0.005424796603620052\n",
      "Iteration: 6978/10000, Loss: 0.013758192770183086\n",
      "Iteration: 6979/10000, Loss: 0.008314422331750393\n",
      "Iteration: 6980/10000, Loss: 0.01085346657782793\n",
      "Iteration: 6981/10000, Loss: 0.011583087034523487\n",
      "Iteration: 6982/10000, Loss: 0.010590704157948494\n",
      "Iteration: 6983/10000, Loss: 0.01455113384872675\n",
      "Iteration: 6984/10000, Loss: 0.008016567677259445\n",
      "Iteration: 6985/10000, Loss: 0.006620783358812332\n",
      "Iteration: 6986/10000, Loss: 0.011094173416495323\n",
      "Iteration: 6987/10000, Loss: 0.012539448216557503\n",
      "Iteration: 6988/10000, Loss: 0.011028789915144444\n",
      "Iteration: 6989/10000, Loss: 0.010240095667541027\n",
      "Iteration: 6990/10000, Loss: 0.010419734753668308\n",
      "Iteration: 6991/10000, Loss: 0.006729489658027887\n",
      "Iteration: 6992/10000, Loss: 0.010441026650369167\n",
      "Iteration: 6993/10000, Loss: 0.00942176952958107\n",
      "Iteration: 6994/10000, Loss: 0.010267604142427444\n",
      "Iteration: 6995/10000, Loss: 0.011289563961327076\n",
      "Iteration: 6996/10000, Loss: 0.011367679573595524\n",
      "Iteration: 6997/10000, Loss: 0.010131701827049255\n",
      "Iteration: 6998/10000, Loss: 0.005918276961892843\n",
      "Iteration: 6999/10000, Loss: 0.011498192325234413\n",
      "Iteration: 7000/10000, Loss: 0.010463813319802284\n",
      "Average test loss:  0.0022\n",
      "Iteration: 7001/10000, Loss: 0.01020883210003376\n",
      "Iteration: 7002/10000, Loss: 0.0068723964504897594\n",
      "Iteration: 7003/10000, Loss: 0.009717981331050396\n",
      "Iteration: 7004/10000, Loss: 0.006790254730731249\n",
      "Iteration: 7005/10000, Loss: 0.011441709473729134\n",
      "Iteration: 7006/10000, Loss: 0.008674203418195248\n",
      "Iteration: 7007/10000, Loss: 0.009493498131632805\n",
      "Iteration: 7008/10000, Loss: 0.006073106080293655\n",
      "Iteration: 7009/10000, Loss: 0.01138712465763092\n",
      "Iteration: 7010/10000, Loss: 0.0076765152625739574\n",
      "Iteration: 7011/10000, Loss: 0.009892869740724564\n",
      "Iteration: 7012/10000, Loss: 0.01033667754381895\n",
      "Iteration: 7013/10000, Loss: 0.0063278572633862495\n",
      "Iteration: 7014/10000, Loss: 0.013545307330787182\n",
      "Iteration: 7015/10000, Loss: 0.0052105337381362915\n",
      "Iteration: 7016/10000, Loss: 0.007609929423779249\n",
      "Iteration: 7017/10000, Loss: 0.01475218590348959\n",
      "Iteration: 7018/10000, Loss: 0.009073548950254917\n",
      "Iteration: 7019/10000, Loss: 0.007760997395962477\n",
      "Iteration: 7020/10000, Loss: 0.008899402804672718\n",
      "Iteration: 7021/10000, Loss: 0.011592777445912361\n",
      "Iteration: 7022/10000, Loss: 0.016572091728448868\n",
      "Iteration: 7023/10000, Loss: 0.006068394985049963\n",
      "Iteration: 7024/10000, Loss: 0.008735734038054943\n",
      "Iteration: 7025/10000, Loss: 0.009723400697112083\n",
      "Iteration: 7026/10000, Loss: 0.007250266149640083\n",
      "Iteration: 7027/10000, Loss: 0.006242772098630667\n",
      "Iteration: 7028/10000, Loss: 0.015256453305482864\n",
      "Iteration: 7029/10000, Loss: 0.00883522443473339\n",
      "Iteration: 7030/10000, Loss: 0.008831002749502659\n",
      "Iteration: 7031/10000, Loss: 0.010337003506720066\n",
      "Iteration: 7032/10000, Loss: 0.008407304994761944\n",
      "Iteration: 7033/10000, Loss: 0.016427721828222275\n",
      "Iteration: 7034/10000, Loss: 0.008920417167246342\n",
      "Iteration: 7035/10000, Loss: 0.010467862710356712\n",
      "Iteration: 7036/10000, Loss: 0.009928073734045029\n",
      "Iteration: 7037/10000, Loss: 0.007660195231437683\n",
      "Iteration: 7038/10000, Loss: 0.008216679096221924\n",
      "Iteration: 7039/10000, Loss: 0.010392011143267155\n",
      "Iteration: 7040/10000, Loss: 0.011648648418486118\n",
      "Iteration: 7041/10000, Loss: 0.011355442926287651\n",
      "Iteration: 7042/10000, Loss: 0.010131970047950745\n",
      "Iteration: 7043/10000, Loss: 0.012434250675141811\n",
      "Iteration: 7044/10000, Loss: 0.008211970329284668\n",
      "Iteration: 7045/10000, Loss: 0.01141933910548687\n",
      "Iteration: 7046/10000, Loss: 0.013804374262690544\n",
      "Iteration: 7047/10000, Loss: 0.009912030771374702\n",
      "Iteration: 7048/10000, Loss: 0.006857401225715876\n",
      "Iteration: 7049/10000, Loss: 0.008548193611204624\n",
      "Iteration: 7050/10000, Loss: 0.007768035400658846\n",
      "Iteration: 7051/10000, Loss: 0.010025096125900745\n",
      "Iteration: 7052/10000, Loss: 0.009473276324570179\n",
      "Iteration: 7053/10000, Loss: 0.009927405044436455\n",
      "Iteration: 7054/10000, Loss: 0.007901838049292564\n",
      "Iteration: 7055/10000, Loss: 0.01327970065176487\n",
      "Iteration: 7056/10000, Loss: 0.009151706472039223\n",
      "Iteration: 7057/10000, Loss: 0.010311894118785858\n",
      "Iteration: 7058/10000, Loss: 0.012168977409601212\n",
      "Iteration: 7059/10000, Loss: 0.0062696319073438644\n",
      "Iteration: 7060/10000, Loss: 0.011780530214309692\n",
      "Iteration: 7061/10000, Loss: 0.014042945578694344\n",
      "Iteration: 7062/10000, Loss: 0.012923205271363258\n",
      "Iteration: 7063/10000, Loss: 0.012046346440911293\n",
      "Iteration: 7064/10000, Loss: 0.006924482528120279\n",
      "Iteration: 7065/10000, Loss: 0.013713464140892029\n",
      "Iteration: 7066/10000, Loss: 0.008540330454707146\n",
      "Iteration: 7067/10000, Loss: 0.006756022106856108\n",
      "Iteration: 7068/10000, Loss: 0.012867175973951817\n",
      "Iteration: 7069/10000, Loss: 0.01059639547020197\n",
      "Iteration: 7070/10000, Loss: 0.007832422852516174\n",
      "Iteration: 7071/10000, Loss: 0.010792907327413559\n",
      "Iteration: 7072/10000, Loss: 0.007962788455188274\n",
      "Iteration: 7073/10000, Loss: 0.009807197377085686\n",
      "Iteration: 7074/10000, Loss: 0.009139793924987316\n",
      "Iteration: 7075/10000, Loss: 0.00770531315356493\n",
      "Iteration: 7076/10000, Loss: 0.009239652194082737\n",
      "Iteration: 7077/10000, Loss: 0.010335609316825867\n",
      "Iteration: 7078/10000, Loss: 0.00809120200574398\n",
      "Iteration: 7079/10000, Loss: 0.005505119450390339\n",
      "Iteration: 7080/10000, Loss: 0.01136107835918665\n",
      "Iteration: 7081/10000, Loss: 0.0077858902513980865\n",
      "Iteration: 7082/10000, Loss: 0.013596284203231335\n",
      "Iteration: 7083/10000, Loss: 0.009622867219150066\n",
      "Iteration: 7084/10000, Loss: 0.012594668194651604\n",
      "Iteration: 7085/10000, Loss: 0.010737300850450993\n",
      "Iteration: 7086/10000, Loss: 0.009542456828057766\n",
      "Iteration: 7087/10000, Loss: 0.008474688977003098\n",
      "Iteration: 7088/10000, Loss: 0.007853594608604908\n",
      "Iteration: 7089/10000, Loss: 0.008748247288167477\n",
      "Iteration: 7090/10000, Loss: 0.005966927390545607\n",
      "Iteration: 7091/10000, Loss: 0.008762220852077007\n",
      "Iteration: 7092/10000, Loss: 0.009982774965465069\n",
      "Iteration: 7093/10000, Loss: 0.011112828738987446\n",
      "Iteration: 7094/10000, Loss: 0.009001386351883411\n",
      "Iteration: 7095/10000, Loss: 0.012124556116759777\n",
      "Iteration: 7096/10000, Loss: 0.009651020169258118\n",
      "Iteration: 7097/10000, Loss: 0.011594540439546108\n",
      "Iteration: 7098/10000, Loss: 0.011282925494015217\n",
      "Iteration: 7099/10000, Loss: 0.01290325727313757\n",
      "Iteration: 7100/10000, Loss: 0.011139978654682636\n",
      "Average test loss:  0.0024\n",
      "Iteration: 7101/10000, Loss: 0.011158849112689495\n",
      "Iteration: 7102/10000, Loss: 0.013007142581045628\n",
      "Iteration: 7103/10000, Loss: 0.011226250790059566\n",
      "Iteration: 7104/10000, Loss: 0.008674785494804382\n",
      "Iteration: 7105/10000, Loss: 0.008633985184133053\n",
      "Iteration: 7106/10000, Loss: 0.009589740075170994\n",
      "Iteration: 7107/10000, Loss: 0.011408996768295765\n",
      "Iteration: 7108/10000, Loss: 0.005440421402454376\n",
      "Iteration: 7109/10000, Loss: 0.004846496041864157\n",
      "Iteration: 7110/10000, Loss: 0.011388188228011131\n",
      "Iteration: 7111/10000, Loss: 0.009679053910076618\n",
      "Iteration: 7112/10000, Loss: 0.008326486684381962\n",
      "Iteration: 7113/10000, Loss: 0.009921104647219181\n",
      "Iteration: 7114/10000, Loss: 0.013790852390229702\n",
      "Iteration: 7115/10000, Loss: 0.009709266945719719\n",
      "Iteration: 7116/10000, Loss: 0.006119787227362394\n",
      "Iteration: 7117/10000, Loss: 0.012567357160151005\n",
      "Iteration: 7118/10000, Loss: 0.011630218476057053\n",
      "Iteration: 7119/10000, Loss: 0.013105521909892559\n",
      "Iteration: 7120/10000, Loss: 0.010705888271331787\n",
      "Iteration: 7121/10000, Loss: 0.013520012609660625\n",
      "Iteration: 7122/10000, Loss: 0.008641095831990242\n",
      "Iteration: 7123/10000, Loss: 0.012231368571519852\n",
      "Iteration: 7124/10000, Loss: 0.010775045491755009\n",
      "Iteration: 7125/10000, Loss: 0.007317016366869211\n",
      "Iteration: 7126/10000, Loss: 0.00928355474025011\n",
      "Iteration: 7127/10000, Loss: 0.010383382439613342\n",
      "Iteration: 7128/10000, Loss: 0.008262136951088905\n",
      "Iteration: 7129/10000, Loss: 0.008709952235221863\n",
      "Iteration: 7130/10000, Loss: 0.011824640445411205\n",
      "Iteration: 7131/10000, Loss: 0.010927064344286919\n",
      "Iteration: 7132/10000, Loss: 0.008898451924324036\n",
      "Iteration: 7133/10000, Loss: 0.01057075709104538\n",
      "Iteration: 7134/10000, Loss: 0.012569683603942394\n",
      "Iteration: 7135/10000, Loss: 0.010004819370806217\n",
      "Iteration: 7136/10000, Loss: 0.014223642647266388\n",
      "Iteration: 7137/10000, Loss: 0.012148702517151833\n",
      "Iteration: 7138/10000, Loss: 0.007995562627911568\n",
      "Iteration: 7139/10000, Loss: 0.008027907460927963\n",
      "Iteration: 7140/10000, Loss: 0.010625509545207024\n",
      "Iteration: 7141/10000, Loss: 0.011479629203677177\n",
      "Iteration: 7142/10000, Loss: 0.011411934159696102\n",
      "Iteration: 7143/10000, Loss: 0.008682885207235813\n",
      "Iteration: 7144/10000, Loss: 0.008060261607170105\n",
      "Iteration: 7145/10000, Loss: 0.00823906622827053\n",
      "Iteration: 7146/10000, Loss: 0.011733883991837502\n",
      "Iteration: 7147/10000, Loss: 0.0120209576562047\n",
      "Iteration: 7148/10000, Loss: 0.010023766197264194\n",
      "Iteration: 7149/10000, Loss: 0.011040008626878262\n",
      "Iteration: 7150/10000, Loss: 0.010060318745672703\n",
      "Iteration: 7151/10000, Loss: 0.012404249981045723\n",
      "Iteration: 7152/10000, Loss: 0.009800921194255352\n",
      "Iteration: 7153/10000, Loss: 0.010484266094863415\n",
      "Iteration: 7154/10000, Loss: 0.010581068694591522\n",
      "Iteration: 7155/10000, Loss: 0.005489815957844257\n",
      "Iteration: 7156/10000, Loss: 0.008308805525302887\n",
      "Iteration: 7157/10000, Loss: 0.013743292540311813\n",
      "Iteration: 7158/10000, Loss: 0.004203885328024626\n",
      "Iteration: 7159/10000, Loss: 0.006561193615198135\n",
      "Iteration: 7160/10000, Loss: 0.013584504835307598\n",
      "Iteration: 7161/10000, Loss: 0.009169146418571472\n",
      "Iteration: 7162/10000, Loss: 0.011663799174129963\n",
      "Iteration: 7163/10000, Loss: 0.009456419385969639\n",
      "Iteration: 7164/10000, Loss: 0.01045920979231596\n",
      "Iteration: 7165/10000, Loss: 0.011057618074119091\n",
      "Iteration: 7166/10000, Loss: 0.006460566073656082\n",
      "Iteration: 7167/10000, Loss: 0.013502877205610275\n",
      "Iteration: 7168/10000, Loss: 0.012705218978226185\n",
      "Iteration: 7169/10000, Loss: 0.009909607470035553\n",
      "Iteration: 7170/10000, Loss: 0.010122604668140411\n",
      "Iteration: 7171/10000, Loss: 0.017184045165777206\n",
      "Iteration: 7172/10000, Loss: 0.01149173453450203\n",
      "Iteration: 7173/10000, Loss: 0.011623704805970192\n",
      "Iteration: 7174/10000, Loss: 0.01086296048015356\n",
      "Iteration: 7175/10000, Loss: 0.009899046272039413\n",
      "Iteration: 7176/10000, Loss: 0.011673287488520145\n",
      "Iteration: 7177/10000, Loss: 0.008215514943003654\n",
      "Iteration: 7178/10000, Loss: 0.010170058347284794\n",
      "Iteration: 7179/10000, Loss: 0.007692982908338308\n",
      "Iteration: 7180/10000, Loss: 0.009800185449421406\n",
      "Iteration: 7181/10000, Loss: 0.008871941827237606\n",
      "Iteration: 7182/10000, Loss: 0.013619610108435154\n",
      "Iteration: 7183/10000, Loss: 0.007663387339562178\n",
      "Iteration: 7184/10000, Loss: 0.007524386513978243\n",
      "Iteration: 7185/10000, Loss: 0.009612230584025383\n",
      "Iteration: 7186/10000, Loss: 0.007746726740151644\n",
      "Iteration: 7187/10000, Loss: 0.011911996640264988\n",
      "Iteration: 7188/10000, Loss: 0.013078045099973679\n",
      "Iteration: 7189/10000, Loss: 0.010818568989634514\n",
      "Iteration: 7190/10000, Loss: 0.011400889605283737\n",
      "Iteration: 7191/10000, Loss: 0.006774478126317263\n",
      "Iteration: 7192/10000, Loss: 0.00852743536233902\n",
      "Iteration: 7193/10000, Loss: 0.005575920920819044\n",
      "Iteration: 7194/10000, Loss: 0.011423998512327671\n",
      "Iteration: 7195/10000, Loss: 0.010718617588281631\n",
      "Iteration: 7196/10000, Loss: 0.009089822880923748\n",
      "Iteration: 7197/10000, Loss: 0.009303794242441654\n",
      "Iteration: 7198/10000, Loss: 0.00917869247496128\n",
      "Iteration: 7199/10000, Loss: 0.012592795304954052\n",
      "Iteration: 7200/10000, Loss: 0.012460813857614994\n",
      "Average test loss:  0.0025\n",
      "Iteration: 7201/10000, Loss: 0.010368100367486477\n",
      "Iteration: 7202/10000, Loss: 0.008514530025422573\n",
      "Iteration: 7203/10000, Loss: 0.010953639633953571\n",
      "Iteration: 7204/10000, Loss: 0.008567501790821552\n",
      "Iteration: 7205/10000, Loss: 0.009014979004859924\n",
      "Iteration: 7206/10000, Loss: 0.006129267625510693\n",
      "Iteration: 7207/10000, Loss: 0.011671125888824463\n",
      "Iteration: 7208/10000, Loss: 0.0106965322047472\n",
      "Iteration: 7209/10000, Loss: 0.01349671371281147\n",
      "Iteration: 7210/10000, Loss: 0.011213209480047226\n",
      "Iteration: 7211/10000, Loss: 0.011476225219666958\n",
      "Iteration: 7212/10000, Loss: 0.00886724516749382\n",
      "Iteration: 7213/10000, Loss: 0.010346397757530212\n",
      "Iteration: 7214/10000, Loss: 0.012990351766347885\n",
      "Iteration: 7215/10000, Loss: 0.010537272319197655\n",
      "Iteration: 7216/10000, Loss: 0.010928094387054443\n",
      "Iteration: 7217/10000, Loss: 0.01032022200524807\n",
      "Iteration: 7218/10000, Loss: 0.006431899033486843\n",
      "Iteration: 7219/10000, Loss: 0.012773055583238602\n",
      "Iteration: 7220/10000, Loss: 0.011385596357285976\n",
      "Iteration: 7221/10000, Loss: 0.008432219736278057\n",
      "Iteration: 7222/10000, Loss: 0.011754061095416546\n",
      "Iteration: 7223/10000, Loss: 0.008655215613543987\n",
      "Iteration: 7224/10000, Loss: 0.007280441932380199\n",
      "Iteration: 7225/10000, Loss: 0.011047093197703362\n",
      "Iteration: 7226/10000, Loss: 0.017812933772802353\n",
      "Iteration: 7227/10000, Loss: 0.009032593108713627\n",
      "Iteration: 7228/10000, Loss: 0.010427351109683514\n",
      "Iteration: 7229/10000, Loss: 0.00796874612569809\n",
      "Iteration: 7230/10000, Loss: 0.009748275391757488\n",
      "Iteration: 7231/10000, Loss: 0.01720065250992775\n",
      "Iteration: 7232/10000, Loss: 0.01179723534733057\n",
      "Iteration: 7233/10000, Loss: 0.007453028578311205\n",
      "Iteration: 7234/10000, Loss: 0.011290092021226883\n",
      "Iteration: 7235/10000, Loss: 0.010396371595561504\n",
      "Iteration: 7236/10000, Loss: 0.01089666597545147\n",
      "Iteration: 7237/10000, Loss: 0.006735699251294136\n",
      "Iteration: 7238/10000, Loss: 0.011791951023042202\n",
      "Iteration: 7239/10000, Loss: 0.010350926779210567\n",
      "Iteration: 7240/10000, Loss: 0.008269069716334343\n",
      "Iteration: 7241/10000, Loss: 0.005598666612058878\n",
      "Iteration: 7242/10000, Loss: 0.008206738159060478\n",
      "Iteration: 7243/10000, Loss: 0.013225496746599674\n",
      "Iteration: 7244/10000, Loss: 0.010969508439302444\n",
      "Iteration: 7245/10000, Loss: 0.008065239526331425\n",
      "Iteration: 7246/10000, Loss: 0.01046991627663374\n",
      "Iteration: 7247/10000, Loss: 0.009565362706780434\n",
      "Iteration: 7248/10000, Loss: 0.008416101336479187\n",
      "Iteration: 7249/10000, Loss: 0.007088956423103809\n",
      "Iteration: 7250/10000, Loss: 0.005773813463747501\n",
      "Iteration: 7251/10000, Loss: 0.00854706671088934\n",
      "Iteration: 7252/10000, Loss: 0.01414397917687893\n",
      "Iteration: 7253/10000, Loss: 0.009764911606907845\n",
      "Iteration: 7254/10000, Loss: 0.008240990340709686\n",
      "Iteration: 7255/10000, Loss: 0.009985038079321384\n",
      "Iteration: 7256/10000, Loss: 0.009871546179056168\n",
      "Iteration: 7257/10000, Loss: 0.010400276631116867\n",
      "Iteration: 7258/10000, Loss: 0.010015508159995079\n",
      "Iteration: 7259/10000, Loss: 0.009610667824745178\n",
      "Iteration: 7260/10000, Loss: 0.009206565096974373\n",
      "Iteration: 7261/10000, Loss: 0.008452114649116993\n",
      "Iteration: 7262/10000, Loss: 0.009967649355530739\n",
      "Iteration: 7263/10000, Loss: 0.008877456188201904\n",
      "Iteration: 7264/10000, Loss: 0.006974890362471342\n",
      "Iteration: 7265/10000, Loss: 0.00872104987502098\n",
      "Iteration: 7266/10000, Loss: 0.01035970076918602\n",
      "Iteration: 7267/10000, Loss: 0.011508078314363956\n",
      "Iteration: 7268/10000, Loss: 0.009069678373634815\n",
      "Iteration: 7269/10000, Loss: 0.01268711220473051\n",
      "Iteration: 7270/10000, Loss: 0.00782318226993084\n",
      "Iteration: 7271/10000, Loss: 0.011087441816926003\n",
      "Iteration: 7272/10000, Loss: 0.007499034516513348\n",
      "Iteration: 7273/10000, Loss: 0.012541991658508778\n",
      "Iteration: 7274/10000, Loss: 0.011138825677335262\n",
      "Iteration: 7275/10000, Loss: 0.009339338168501854\n",
      "Iteration: 7276/10000, Loss: 0.007216678000986576\n",
      "Iteration: 7277/10000, Loss: 0.012132212519645691\n",
      "Iteration: 7278/10000, Loss: 0.011521616950631142\n",
      "Iteration: 7279/10000, Loss: 0.017170803621411324\n",
      "Iteration: 7280/10000, Loss: 0.009006870910525322\n",
      "Iteration: 7281/10000, Loss: 0.013265862129628658\n",
      "Iteration: 7282/10000, Loss: 0.01123788021504879\n",
      "Iteration: 7283/10000, Loss: 0.008489883504807949\n",
      "Iteration: 7284/10000, Loss: 0.007635795045644045\n",
      "Iteration: 7285/10000, Loss: 0.007905818521976471\n",
      "Iteration: 7286/10000, Loss: 0.008563035167753696\n",
      "Iteration: 7287/10000, Loss: 0.008593549020588398\n",
      "Iteration: 7288/10000, Loss: 0.008586431853473186\n",
      "Iteration: 7289/10000, Loss: 0.011765402741730213\n",
      "Iteration: 7290/10000, Loss: 0.014441652223467827\n",
      "Iteration: 7291/10000, Loss: 0.01941027119755745\n",
      "Iteration: 7292/10000, Loss: 0.011378660798072815\n",
      "Iteration: 7293/10000, Loss: 0.010554320178925991\n",
      "Iteration: 7294/10000, Loss: 0.011190677061676979\n",
      "Iteration: 7295/10000, Loss: 0.010120252147316933\n",
      "Iteration: 7296/10000, Loss: 0.011030372232198715\n",
      "Iteration: 7297/10000, Loss: 0.011768415570259094\n",
      "Iteration: 7298/10000, Loss: 0.008461768738925457\n",
      "Iteration: 7299/10000, Loss: 0.016552146524190903\n",
      "Iteration: 7300/10000, Loss: 0.006142295431345701\n",
      "Average test loss:  0.0034\n",
      "Iteration: 7301/10000, Loss: 0.009062866680324078\n",
      "Iteration: 7302/10000, Loss: 0.005465590860694647\n",
      "Iteration: 7303/10000, Loss: 0.011167381890118122\n",
      "Iteration: 7304/10000, Loss: 0.010485667735338211\n",
      "Iteration: 7305/10000, Loss: 0.00978770386427641\n",
      "Iteration: 7306/10000, Loss: 0.009442297741770744\n",
      "Iteration: 7307/10000, Loss: 0.007618876174092293\n",
      "Iteration: 7308/10000, Loss: 0.010179753415286541\n",
      "Iteration: 7309/10000, Loss: 0.013560695573687553\n",
      "Iteration: 7310/10000, Loss: 0.012730824761092663\n",
      "Iteration: 7311/10000, Loss: 0.009888667613267899\n",
      "Iteration: 7312/10000, Loss: 0.008001744747161865\n",
      "Iteration: 7313/10000, Loss: 0.010591368190944195\n",
      "Iteration: 7314/10000, Loss: 0.009422491304576397\n",
      "Iteration: 7315/10000, Loss: 0.007159371394664049\n",
      "Iteration: 7316/10000, Loss: 0.012472862377762794\n",
      "Iteration: 7317/10000, Loss: 0.008096273057162762\n",
      "Iteration: 7318/10000, Loss: 0.009912042878568172\n",
      "Iteration: 7319/10000, Loss: 0.009289141744375229\n",
      "Iteration: 7320/10000, Loss: 0.008559370413422585\n",
      "Iteration: 7321/10000, Loss: 0.007313447538763285\n",
      "Iteration: 7322/10000, Loss: 0.008778137154877186\n",
      "Iteration: 7323/10000, Loss: 0.009601357392966747\n",
      "Iteration: 7324/10000, Loss: 0.013027316890656948\n",
      "Iteration: 7325/10000, Loss: 0.011419842019677162\n",
      "Iteration: 7326/10000, Loss: 0.009675856679677963\n",
      "Iteration: 7327/10000, Loss: 0.013285390101373196\n",
      "Iteration: 7328/10000, Loss: 0.007768718060106039\n",
      "Iteration: 7329/10000, Loss: 0.006853644736111164\n",
      "Iteration: 7330/10000, Loss: 0.013111492618918419\n",
      "Iteration: 7331/10000, Loss: 0.008936623111367226\n",
      "Iteration: 7332/10000, Loss: 0.010423896834254265\n",
      "Iteration: 7333/10000, Loss: 0.010054661892354488\n",
      "Iteration: 7334/10000, Loss: 0.010484996251761913\n",
      "Iteration: 7335/10000, Loss: 0.01012770738452673\n",
      "Iteration: 7336/10000, Loss: 0.008221540600061417\n",
      "Iteration: 7337/10000, Loss: 0.011545998044312\n",
      "Iteration: 7338/10000, Loss: 0.00885141920298338\n",
      "Iteration: 7339/10000, Loss: 0.010527496226131916\n",
      "Iteration: 7340/10000, Loss: 0.00867498479783535\n",
      "Iteration: 7341/10000, Loss: 0.008349896408617496\n",
      "Iteration: 7342/10000, Loss: 0.012475825846195221\n",
      "Iteration: 7343/10000, Loss: 0.011945409700274467\n",
      "Iteration: 7344/10000, Loss: 0.01963052898645401\n",
      "Iteration: 7345/10000, Loss: 0.009857711382210255\n",
      "Iteration: 7346/10000, Loss: 0.0072563085705041885\n",
      "Iteration: 7347/10000, Loss: 0.012745031155645847\n",
      "Iteration: 7348/10000, Loss: 0.016177436336874962\n",
      "Iteration: 7349/10000, Loss: 0.009282189421355724\n",
      "Iteration: 7350/10000, Loss: 0.015341886319220066\n",
      "Iteration: 7351/10000, Loss: 0.008227485232055187\n",
      "Iteration: 7352/10000, Loss: 0.00652889721095562\n",
      "Iteration: 7353/10000, Loss: 0.01987672597169876\n",
      "Iteration: 7354/10000, Loss: 0.010205739177763462\n",
      "Iteration: 7355/10000, Loss: 0.00695457449182868\n",
      "Iteration: 7356/10000, Loss: 0.013595562428236008\n",
      "Iteration: 7357/10000, Loss: 0.008186401799321175\n",
      "Iteration: 7358/10000, Loss: 0.013937095180153847\n",
      "Iteration: 7359/10000, Loss: 0.007691807579249144\n",
      "Iteration: 7360/10000, Loss: 0.012779217213392258\n",
      "Iteration: 7361/10000, Loss: 0.00710286246612668\n",
      "Iteration: 7362/10000, Loss: 0.00923673715442419\n",
      "Iteration: 7363/10000, Loss: 0.011602692306041718\n",
      "Iteration: 7364/10000, Loss: 0.009094092063605785\n",
      "Iteration: 7365/10000, Loss: 0.009496165439486504\n",
      "Iteration: 7366/10000, Loss: 0.010602560825645924\n",
      "Iteration: 7367/10000, Loss: 0.0096686240285635\n",
      "Iteration: 7368/10000, Loss: 0.00698769511654973\n",
      "Iteration: 7369/10000, Loss: 0.011097200214862823\n",
      "Iteration: 7370/10000, Loss: 0.010889245197176933\n",
      "Iteration: 7371/10000, Loss: 0.008539307862520218\n",
      "Iteration: 7372/10000, Loss: 0.012485271319746971\n",
      "Iteration: 7373/10000, Loss: 0.011571483686566353\n",
      "Iteration: 7374/10000, Loss: 0.009552898816764355\n",
      "Iteration: 7375/10000, Loss: 0.011894689872860909\n",
      "Iteration: 7376/10000, Loss: 0.00848464947193861\n",
      "Iteration: 7377/10000, Loss: 0.012601352296769619\n",
      "Iteration: 7378/10000, Loss: 0.009789333678781986\n",
      "Iteration: 7379/10000, Loss: 0.013516918756067753\n",
      "Iteration: 7380/10000, Loss: 0.010739426128566265\n",
      "Iteration: 7381/10000, Loss: 0.009027271531522274\n",
      "Iteration: 7382/10000, Loss: 0.007473836652934551\n",
      "Iteration: 7383/10000, Loss: 0.0090944180265069\n",
      "Iteration: 7384/10000, Loss: 0.008568921126425266\n",
      "Iteration: 7385/10000, Loss: 0.011891761794686317\n",
      "Iteration: 7386/10000, Loss: 0.005116418935358524\n",
      "Iteration: 7387/10000, Loss: 0.01432534959167242\n",
      "Iteration: 7388/10000, Loss: 0.008861114270985126\n",
      "Iteration: 7389/10000, Loss: 0.005750237498432398\n",
      "Iteration: 7390/10000, Loss: 0.009830759838223457\n",
      "Iteration: 7391/10000, Loss: 0.010390014387667179\n",
      "Iteration: 7392/10000, Loss: 0.010556142777204514\n",
      "Iteration: 7393/10000, Loss: 0.007765207905322313\n",
      "Iteration: 7394/10000, Loss: 0.009051568806171417\n",
      "Iteration: 7395/10000, Loss: 0.008648557588458061\n",
      "Iteration: 7396/10000, Loss: 0.009057813324034214\n",
      "Iteration: 7397/10000, Loss: 0.0117042800411582\n",
      "Iteration: 7398/10000, Loss: 0.01289837621152401\n",
      "Iteration: 7399/10000, Loss: 0.00911139976233244\n",
      "Iteration: 7400/10000, Loss: 0.010335619561374187\n",
      "Average test loss:  0.0044\n",
      "Iteration: 7401/10000, Loss: 0.01033504493534565\n",
      "Iteration: 7402/10000, Loss: 0.00710480660200119\n",
      "Iteration: 7403/10000, Loss: 0.009230977855622768\n",
      "Iteration: 7404/10000, Loss: 0.01196361519396305\n",
      "Iteration: 7405/10000, Loss: 0.01185572985559702\n",
      "Iteration: 7406/10000, Loss: 0.01091016735881567\n",
      "Iteration: 7407/10000, Loss: 0.008678531274199486\n",
      "Iteration: 7408/10000, Loss: 0.00672886474058032\n",
      "Iteration: 7409/10000, Loss: 0.007609838154166937\n",
      "Iteration: 7410/10000, Loss: 0.010823186486959457\n",
      "Iteration: 7411/10000, Loss: 0.015860095620155334\n",
      "Iteration: 7412/10000, Loss: 0.010526733472943306\n",
      "Iteration: 7413/10000, Loss: 0.009619666263461113\n",
      "Iteration: 7414/10000, Loss: 0.007755900267511606\n",
      "Iteration: 7415/10000, Loss: 0.011220875196158886\n",
      "Iteration: 7416/10000, Loss: 0.006478358060121536\n",
      "Iteration: 7417/10000, Loss: 0.009892091155052185\n",
      "Iteration: 7418/10000, Loss: 0.012853077612817287\n",
      "Iteration: 7419/10000, Loss: 0.011057053692638874\n",
      "Iteration: 7420/10000, Loss: 0.011012466624379158\n",
      "Iteration: 7421/10000, Loss: 0.006210089661180973\n",
      "Iteration: 7422/10000, Loss: 0.012285979464650154\n",
      "Iteration: 7423/10000, Loss: 0.008176063187420368\n",
      "Iteration: 7424/10000, Loss: 0.0076196747832000256\n",
      "Iteration: 7425/10000, Loss: 0.009927271865308285\n",
      "Iteration: 7426/10000, Loss: 0.010384516790509224\n",
      "Iteration: 7427/10000, Loss: 0.0077176783233881\n",
      "Iteration: 7428/10000, Loss: 0.012422868981957436\n",
      "Iteration: 7429/10000, Loss: 0.009312048554420471\n",
      "Iteration: 7430/10000, Loss: 0.010756966657936573\n",
      "Iteration: 7431/10000, Loss: 0.007650347892194986\n",
      "Iteration: 7432/10000, Loss: 0.011768769472837448\n",
      "Iteration: 7433/10000, Loss: 0.007536404300481081\n",
      "Iteration: 7434/10000, Loss: 0.015442815609276295\n",
      "Iteration: 7435/10000, Loss: 0.009216582402586937\n",
      "Iteration: 7436/10000, Loss: 0.017289238050580025\n",
      "Iteration: 7437/10000, Loss: 0.008577491156756878\n",
      "Iteration: 7438/10000, Loss: 0.007613570895045996\n",
      "Iteration: 7439/10000, Loss: 0.013376929797232151\n",
      "Iteration: 7440/10000, Loss: 0.008086155168712139\n",
      "Iteration: 7441/10000, Loss: 0.009491879492998123\n",
      "Iteration: 7442/10000, Loss: 0.008883772417902946\n",
      "Iteration: 7443/10000, Loss: 0.006808669306337833\n",
      "Iteration: 7444/10000, Loss: 0.010047496296465397\n",
      "Iteration: 7445/10000, Loss: 0.008629054762423038\n",
      "Iteration: 7446/10000, Loss: 0.007626289967447519\n",
      "Iteration: 7447/10000, Loss: 0.008340071886777878\n",
      "Iteration: 7448/10000, Loss: 0.008939270861446857\n",
      "Iteration: 7449/10000, Loss: 0.006890292279422283\n",
      "Iteration: 7450/10000, Loss: 0.010254429653286934\n",
      "Iteration: 7451/10000, Loss: 0.010093629360198975\n",
      "Iteration: 7452/10000, Loss: 0.012545153498649597\n",
      "Iteration: 7453/10000, Loss: 0.008011058904230595\n",
      "Iteration: 7454/10000, Loss: 0.00798128079622984\n",
      "Iteration: 7455/10000, Loss: 0.0054760584607720375\n",
      "Iteration: 7456/10000, Loss: 0.006789737846702337\n",
      "Iteration: 7457/10000, Loss: 0.010417928919196129\n",
      "Iteration: 7458/10000, Loss: 0.011953099630773067\n",
      "Iteration: 7459/10000, Loss: 0.01575574465095997\n",
      "Iteration: 7460/10000, Loss: 0.010212144814431667\n",
      "Iteration: 7461/10000, Loss: 0.007763957604765892\n",
      "Iteration: 7462/10000, Loss: 0.009549496695399284\n",
      "Iteration: 7463/10000, Loss: 0.008388657122850418\n",
      "Iteration: 7464/10000, Loss: 0.012365789152681828\n",
      "Iteration: 7465/10000, Loss: 0.015275047160685062\n",
      "Iteration: 7466/10000, Loss: 0.00983835756778717\n",
      "Iteration: 7467/10000, Loss: 0.014099105261266232\n",
      "Iteration: 7468/10000, Loss: 0.010242056101560593\n",
      "Iteration: 7469/10000, Loss: 0.01227966882288456\n",
      "Iteration: 7470/10000, Loss: 0.005092694889754057\n",
      "Iteration: 7471/10000, Loss: 0.011678923852741718\n",
      "Iteration: 7472/10000, Loss: 0.01010497473180294\n",
      "Iteration: 7473/10000, Loss: 0.009365093894302845\n",
      "Iteration: 7474/10000, Loss: 0.011263702996075153\n",
      "Iteration: 7475/10000, Loss: 0.00844497513025999\n",
      "Iteration: 7476/10000, Loss: 0.012559667229652405\n",
      "Iteration: 7477/10000, Loss: 0.010432926937937737\n",
      "Iteration: 7478/10000, Loss: 0.007376227993518114\n",
      "Iteration: 7479/10000, Loss: 0.008824613876640797\n",
      "Iteration: 7480/10000, Loss: 0.008804920129477978\n",
      "Iteration: 7481/10000, Loss: 0.0065164947882294655\n",
      "Iteration: 7482/10000, Loss: 0.012958675622940063\n",
      "Iteration: 7483/10000, Loss: 0.014409198425710201\n",
      "Iteration: 7484/10000, Loss: 0.007053548935800791\n",
      "Iteration: 7485/10000, Loss: 0.007116843480616808\n",
      "Iteration: 7486/10000, Loss: 0.008985093794763088\n",
      "Iteration: 7487/10000, Loss: 0.007393909152597189\n",
      "Iteration: 7488/10000, Loss: 0.0103162731975317\n",
      "Iteration: 7489/10000, Loss: 0.01007823646068573\n",
      "Iteration: 7490/10000, Loss: 0.00937320850789547\n",
      "Iteration: 7491/10000, Loss: 0.009112861007452011\n",
      "Iteration: 7492/10000, Loss: 0.0066884178668260574\n",
      "Iteration: 7493/10000, Loss: 0.01211056299507618\n",
      "Iteration: 7494/10000, Loss: 0.008054608479142189\n",
      "Iteration: 7495/10000, Loss: 0.009334972128272057\n",
      "Iteration: 7496/10000, Loss: 0.011751829646527767\n",
      "Iteration: 7497/10000, Loss: 0.008980398066341877\n",
      "Iteration: 7498/10000, Loss: 0.009453576058149338\n",
      "Iteration: 7499/10000, Loss: 0.006412363611161709\n",
      "Iteration: 7500/10000, Loss: 0.006873256992548704\n",
      "Average test loss:  0.0029\n",
      "Iteration: 7501/10000, Loss: 0.008636383339762688\n",
      "Iteration: 7502/10000, Loss: 0.008975092321634293\n",
      "Iteration: 7503/10000, Loss: 0.01189522072672844\n",
      "Iteration: 7504/10000, Loss: 0.014205285347998142\n",
      "Iteration: 7505/10000, Loss: 0.009563930332660675\n",
      "Iteration: 7506/10000, Loss: 0.005560330115258694\n",
      "Iteration: 7507/10000, Loss: 0.006825147662311792\n",
      "Iteration: 7508/10000, Loss: 0.004889865405857563\n",
      "Iteration: 7509/10000, Loss: 0.007610689383000135\n",
      "Iteration: 7510/10000, Loss: 0.008231600746512413\n",
      "Iteration: 7511/10000, Loss: 0.009499048814177513\n",
      "Iteration: 7512/10000, Loss: 0.009108548052608967\n",
      "Iteration: 7513/10000, Loss: 0.01112344954162836\n",
      "Iteration: 7514/10000, Loss: 0.01281713042408228\n",
      "Iteration: 7515/10000, Loss: 0.011313008144497871\n",
      "Iteration: 7516/10000, Loss: 0.007650743704289198\n",
      "Iteration: 7517/10000, Loss: 0.016397180035710335\n",
      "Iteration: 7518/10000, Loss: 0.015626966953277588\n",
      "Iteration: 7519/10000, Loss: 0.0072762188501656055\n",
      "Iteration: 7520/10000, Loss: 0.010143494233489037\n",
      "Iteration: 7521/10000, Loss: 0.01311599649488926\n",
      "Iteration: 7522/10000, Loss: 0.00871502049267292\n",
      "Iteration: 7523/10000, Loss: 0.011262334883213043\n",
      "Iteration: 7524/10000, Loss: 0.011131158098578453\n",
      "Iteration: 7525/10000, Loss: 0.006792753003537655\n",
      "Iteration: 7526/10000, Loss: 0.021738357841968536\n",
      "Iteration: 7527/10000, Loss: 0.010909108445048332\n",
      "Iteration: 7528/10000, Loss: 0.013180560432374477\n",
      "Iteration: 7529/10000, Loss: 0.012150201015174389\n",
      "Iteration: 7530/10000, Loss: 0.01630718633532524\n",
      "Iteration: 7531/10000, Loss: 0.012451693415641785\n",
      "Iteration: 7532/10000, Loss: 0.013385239988565445\n",
      "Iteration: 7533/10000, Loss: 0.007243611849844456\n",
      "Iteration: 7534/10000, Loss: 0.009954203851521015\n",
      "Iteration: 7535/10000, Loss: 0.007305491715669632\n",
      "Iteration: 7536/10000, Loss: 0.007527191191911697\n",
      "Iteration: 7537/10000, Loss: 0.013660485856235027\n",
      "Iteration: 7538/10000, Loss: 0.010460837744176388\n",
      "Iteration: 7539/10000, Loss: 0.008429042063653469\n",
      "Iteration: 7540/10000, Loss: 0.010630205273628235\n",
      "Iteration: 7541/10000, Loss: 0.00816937256604433\n",
      "Iteration: 7542/10000, Loss: 0.009240399114787579\n",
      "Iteration: 7543/10000, Loss: 0.009988008998334408\n",
      "Iteration: 7544/10000, Loss: 0.008455117233097553\n",
      "Iteration: 7545/10000, Loss: 0.009276153519749641\n",
      "Iteration: 7546/10000, Loss: 0.012569199316203594\n",
      "Iteration: 7547/10000, Loss: 0.011918323114514351\n",
      "Iteration: 7548/10000, Loss: 0.014644005335867405\n",
      "Iteration: 7549/10000, Loss: 0.00814287830144167\n",
      "Iteration: 7550/10000, Loss: 0.007507871836423874\n",
      "Iteration: 7551/10000, Loss: 0.008262106217443943\n",
      "Iteration: 7552/10000, Loss: 0.007122334558516741\n",
      "Iteration: 7553/10000, Loss: 0.007667708210647106\n",
      "Iteration: 7554/10000, Loss: 0.005434892140328884\n",
      "Iteration: 7555/10000, Loss: 0.006544274277985096\n",
      "Iteration: 7556/10000, Loss: 0.009569116868078709\n",
      "Iteration: 7557/10000, Loss: 0.007832647301256657\n",
      "Iteration: 7558/10000, Loss: 0.006944768596440554\n",
      "Iteration: 7559/10000, Loss: 0.010719760321080685\n",
      "Iteration: 7560/10000, Loss: 0.010734206065535545\n",
      "Iteration: 7561/10000, Loss: 0.008414934389293194\n",
      "Iteration: 7562/10000, Loss: 0.00981077179312706\n",
      "Iteration: 7563/10000, Loss: 0.011927079409360886\n",
      "Iteration: 7564/10000, Loss: 0.009060625918209553\n",
      "Iteration: 7565/10000, Loss: 0.009833469055593014\n",
      "Iteration: 7566/10000, Loss: 0.007391934748739004\n",
      "Iteration: 7567/10000, Loss: 0.007493089884519577\n",
      "Iteration: 7568/10000, Loss: 0.009297581389546394\n",
      "Iteration: 7569/10000, Loss: 0.010793160647153854\n",
      "Iteration: 7570/10000, Loss: 0.007838836871087551\n",
      "Iteration: 7571/10000, Loss: 0.011857952922582626\n",
      "Iteration: 7572/10000, Loss: 0.012033654376864433\n",
      "Iteration: 7573/10000, Loss: 0.013778386637568474\n",
      "Iteration: 7574/10000, Loss: 0.010768752545118332\n",
      "Iteration: 7575/10000, Loss: 0.010901788249611855\n",
      "Iteration: 7576/10000, Loss: 0.008433562703430653\n",
      "Iteration: 7577/10000, Loss: 0.009550274349749088\n",
      "Iteration: 7578/10000, Loss: 0.007923897355794907\n",
      "Iteration: 7579/10000, Loss: 0.011137401685118675\n",
      "Iteration: 7580/10000, Loss: 0.016552411019802094\n",
      "Iteration: 7581/10000, Loss: 0.00981036014854908\n",
      "Iteration: 7582/10000, Loss: 0.009021253325045109\n",
      "Iteration: 7583/10000, Loss: 0.012147735804319382\n",
      "Iteration: 7584/10000, Loss: 0.009348900057375431\n",
      "Iteration: 7585/10000, Loss: 0.011156819760799408\n",
      "Iteration: 7586/10000, Loss: 0.011452688835561275\n",
      "Iteration: 7587/10000, Loss: 0.011539896950125694\n",
      "Iteration: 7588/10000, Loss: 0.01122292596846819\n",
      "Iteration: 7589/10000, Loss: 0.01235169731080532\n",
      "Iteration: 7590/10000, Loss: 0.008963016793131828\n",
      "Iteration: 7591/10000, Loss: 0.013640097342431545\n",
      "Iteration: 7592/10000, Loss: 0.010471127927303314\n",
      "Iteration: 7593/10000, Loss: 0.008192799985408783\n",
      "Iteration: 7594/10000, Loss: 0.010262884199619293\n",
      "Iteration: 7595/10000, Loss: 0.010328831151127815\n",
      "Iteration: 7596/10000, Loss: 0.01277767401188612\n",
      "Iteration: 7597/10000, Loss: 0.006579621694982052\n",
      "Iteration: 7598/10000, Loss: 0.005513887386769056\n",
      "Iteration: 7599/10000, Loss: 0.008556167595088482\n",
      "Iteration: 7600/10000, Loss: 0.010581239126622677\n",
      "Average test loss:  0.0029\n",
      "Iteration: 7601/10000, Loss: 0.011695723049342632\n",
      "Iteration: 7602/10000, Loss: 0.007117221597582102\n",
      "Iteration: 7603/10000, Loss: 0.00824808795005083\n",
      "Iteration: 7604/10000, Loss: 0.008373251184821129\n",
      "Iteration: 7605/10000, Loss: 0.00836553517729044\n",
      "Iteration: 7606/10000, Loss: 0.015301295556128025\n",
      "Iteration: 7607/10000, Loss: 0.011962034739553928\n",
      "Iteration: 7608/10000, Loss: 0.008891995996236801\n",
      "Iteration: 7609/10000, Loss: 0.009279199875891209\n",
      "Iteration: 7610/10000, Loss: 0.01131046935915947\n",
      "Iteration: 7611/10000, Loss: 0.012007556855678558\n",
      "Iteration: 7612/10000, Loss: 0.01159915141761303\n",
      "Iteration: 7613/10000, Loss: 0.008216205053031445\n",
      "Iteration: 7614/10000, Loss: 0.007959859445691109\n",
      "Iteration: 7615/10000, Loss: 0.012640944682061672\n",
      "Iteration: 7616/10000, Loss: 0.0088174007833004\n",
      "Iteration: 7617/10000, Loss: 0.0036520715802907944\n",
      "Iteration: 7618/10000, Loss: 0.00756071088835597\n",
      "Iteration: 7619/10000, Loss: 0.01183912344276905\n",
      "Iteration: 7620/10000, Loss: 0.009499851614236832\n",
      "Iteration: 7621/10000, Loss: 0.014433188363909721\n",
      "Iteration: 7622/10000, Loss: 0.0111158462241292\n",
      "Iteration: 7623/10000, Loss: 0.009859895333647728\n",
      "Iteration: 7624/10000, Loss: 0.007315502036362886\n",
      "Iteration: 7625/10000, Loss: 0.008975264616310596\n",
      "Iteration: 7626/10000, Loss: 0.009178263135254383\n",
      "Iteration: 7627/10000, Loss: 0.009872367605566978\n",
      "Iteration: 7628/10000, Loss: 0.012085646390914917\n",
      "Iteration: 7629/10000, Loss: 0.012782379984855652\n",
      "Iteration: 7630/10000, Loss: 0.009065963327884674\n",
      "Iteration: 7631/10000, Loss: 0.010183794423937798\n",
      "Iteration: 7632/10000, Loss: 0.007236786186695099\n",
      "Iteration: 7633/10000, Loss: 0.0073653715662658215\n",
      "Iteration: 7634/10000, Loss: 0.012230303138494492\n",
      "Iteration: 7635/10000, Loss: 0.008994990028440952\n",
      "Iteration: 7636/10000, Loss: 0.007559207733720541\n",
      "Iteration: 7637/10000, Loss: 0.009131740778684616\n",
      "Iteration: 7638/10000, Loss: 0.010494906455278397\n",
      "Iteration: 7639/10000, Loss: 0.007225976325571537\n",
      "Iteration: 7640/10000, Loss: 0.009800096042454243\n",
      "Iteration: 7641/10000, Loss: 0.010982261039316654\n",
      "Iteration: 7642/10000, Loss: 0.010285339318215847\n",
      "Iteration: 7643/10000, Loss: 0.00886080227792263\n",
      "Iteration: 7644/10000, Loss: 0.007555435411632061\n",
      "Iteration: 7645/10000, Loss: 0.010044028051197529\n",
      "Iteration: 7646/10000, Loss: 0.011109710671007633\n",
      "Iteration: 7647/10000, Loss: 0.009805184789001942\n",
      "Iteration: 7648/10000, Loss: 0.00782131589949131\n",
      "Iteration: 7649/10000, Loss: 0.007971657440066338\n",
      "Iteration: 7650/10000, Loss: 0.013876624405384064\n",
      "Iteration: 7651/10000, Loss: 0.013642221689224243\n",
      "Iteration: 7652/10000, Loss: 0.008419356308877468\n",
      "Iteration: 7653/10000, Loss: 0.006951788440346718\n",
      "Iteration: 7654/10000, Loss: 0.008242921903729439\n",
      "Iteration: 7655/10000, Loss: 0.0056002880446612835\n",
      "Iteration: 7656/10000, Loss: 0.012351579032838345\n",
      "Iteration: 7657/10000, Loss: 0.008164278231561184\n",
      "Iteration: 7658/10000, Loss: 0.00948325265198946\n",
      "Iteration: 7659/10000, Loss: 0.006434853654354811\n",
      "Iteration: 7660/10000, Loss: 0.014643792062997818\n",
      "Iteration: 7661/10000, Loss: 0.011116334237158298\n",
      "Iteration: 7662/10000, Loss: 0.008873901329934597\n",
      "Iteration: 7663/10000, Loss: 0.010250022634863853\n",
      "Iteration: 7664/10000, Loss: 0.004782599397003651\n",
      "Iteration: 7665/10000, Loss: 0.012369858101010323\n",
      "Iteration: 7666/10000, Loss: 0.01108314748853445\n",
      "Iteration: 7667/10000, Loss: 0.008404402062296867\n",
      "Iteration: 7668/10000, Loss: 0.00876593217253685\n",
      "Iteration: 7669/10000, Loss: 0.011429471895098686\n",
      "Iteration: 7670/10000, Loss: 0.00956566073000431\n",
      "Iteration: 7671/10000, Loss: 0.0107460031285882\n",
      "Iteration: 7672/10000, Loss: 0.006954014766961336\n",
      "Iteration: 7673/10000, Loss: 0.008551406674087048\n",
      "Iteration: 7674/10000, Loss: 0.014142623171210289\n",
      "Iteration: 7675/10000, Loss: 0.011362414807081223\n",
      "Iteration: 7676/10000, Loss: 0.009035411290824413\n",
      "Iteration: 7677/10000, Loss: 0.009618137963116169\n",
      "Iteration: 7678/10000, Loss: 0.010279734618961811\n",
      "Iteration: 7679/10000, Loss: 0.004178808536380529\n",
      "Iteration: 7680/10000, Loss: 0.011552327312529087\n",
      "Iteration: 7681/10000, Loss: 0.01448118593543768\n",
      "Iteration: 7682/10000, Loss: 0.010412498377263546\n",
      "Iteration: 7683/10000, Loss: 0.004970763344317675\n",
      "Iteration: 7684/10000, Loss: 0.012106700800359249\n",
      "Iteration: 7685/10000, Loss: 0.007554280571639538\n",
      "Iteration: 7686/10000, Loss: 0.013323156163096428\n",
      "Iteration: 7687/10000, Loss: 0.012512890622019768\n",
      "Iteration: 7688/10000, Loss: 0.010773390531539917\n",
      "Iteration: 7689/10000, Loss: 0.01222927775233984\n",
      "Iteration: 7690/10000, Loss: 0.0123534444719553\n",
      "Iteration: 7691/10000, Loss: 0.012090407311916351\n",
      "Iteration: 7692/10000, Loss: 0.009768307209014893\n",
      "Iteration: 7693/10000, Loss: 0.00944211333990097\n",
      "Iteration: 7694/10000, Loss: 0.01730256713926792\n",
      "Iteration: 7695/10000, Loss: 0.006520972587168217\n",
      "Iteration: 7696/10000, Loss: 0.012520790100097656\n",
      "Iteration: 7697/10000, Loss: 0.008479220792651176\n",
      "Iteration: 7698/10000, Loss: 0.00844664964824915\n",
      "Iteration: 7699/10000, Loss: 0.01119052991271019\n",
      "Iteration: 7700/10000, Loss: 0.010926439426839352\n",
      "Average test loss:  0.0022\n",
      "Iteration: 7701/10000, Loss: 0.008219017647206783\n",
      "Iteration: 7702/10000, Loss: 0.007155914790928364\n",
      "Iteration: 7703/10000, Loss: 0.008167553693056107\n",
      "Iteration: 7704/10000, Loss: 0.009165712632238865\n",
      "Iteration: 7705/10000, Loss: 0.011958193965256214\n",
      "Iteration: 7706/10000, Loss: 0.006250644568353891\n",
      "Iteration: 7707/10000, Loss: 0.007702326867729425\n",
      "Iteration: 7708/10000, Loss: 0.011629126034677029\n",
      "Iteration: 7709/10000, Loss: 0.009125966578722\n",
      "Iteration: 7710/10000, Loss: 0.010226830840110779\n",
      "Iteration: 7711/10000, Loss: 0.013150649145245552\n",
      "Iteration: 7712/10000, Loss: 0.011753682047128677\n",
      "Iteration: 7713/10000, Loss: 0.012044550850987434\n",
      "Iteration: 7714/10000, Loss: 0.008786656893789768\n",
      "Iteration: 7715/10000, Loss: 0.011609494686126709\n",
      "Iteration: 7716/10000, Loss: 0.011062780395150185\n",
      "Iteration: 7717/10000, Loss: 0.012310435064136982\n",
      "Iteration: 7718/10000, Loss: 0.008900146931409836\n",
      "Iteration: 7719/10000, Loss: 0.007439992856234312\n",
      "Iteration: 7720/10000, Loss: 0.0065949163399636745\n",
      "Iteration: 7721/10000, Loss: 0.007611284032464027\n",
      "Iteration: 7722/10000, Loss: 0.011209606193006039\n",
      "Iteration: 7723/10000, Loss: 0.009007731452584267\n",
      "Iteration: 7724/10000, Loss: 0.0047997585497796535\n",
      "Iteration: 7725/10000, Loss: 0.009179227985441685\n",
      "Iteration: 7726/10000, Loss: 0.009753548540174961\n",
      "Iteration: 7727/10000, Loss: 0.007807391695678234\n",
      "Iteration: 7728/10000, Loss: 0.007433122955262661\n",
      "Iteration: 7729/10000, Loss: 0.006873538251966238\n",
      "Iteration: 7730/10000, Loss: 0.011015468277037144\n",
      "Iteration: 7731/10000, Loss: 0.00799508299678564\n",
      "Iteration: 7732/10000, Loss: 0.014252787455916405\n",
      "Iteration: 7733/10000, Loss: 0.011154863983392715\n",
      "Iteration: 7734/10000, Loss: 0.008568561635911465\n",
      "Iteration: 7735/10000, Loss: 0.01103444304317236\n",
      "Iteration: 7736/10000, Loss: 0.005390532780438662\n",
      "Iteration: 7737/10000, Loss: 0.009466128423810005\n",
      "Iteration: 7738/10000, Loss: 0.009726510383188725\n",
      "Iteration: 7739/10000, Loss: 0.011330063454806805\n",
      "Iteration: 7740/10000, Loss: 0.0072676013223826885\n",
      "Iteration: 7741/10000, Loss: 0.005746148061007261\n",
      "Iteration: 7742/10000, Loss: 0.009355619549751282\n",
      "Iteration: 7743/10000, Loss: 0.003505133790895343\n",
      "Iteration: 7744/10000, Loss: 0.011553702875971794\n",
      "Iteration: 7745/10000, Loss: 0.010080413892865181\n",
      "Iteration: 7746/10000, Loss: 0.011104684323072433\n",
      "Iteration: 7747/10000, Loss: 0.006644278299063444\n",
      "Iteration: 7748/10000, Loss: 0.006038146559149027\n",
      "Iteration: 7749/10000, Loss: 0.009479094296693802\n",
      "Iteration: 7750/10000, Loss: 0.010275963693857193\n",
      "Iteration: 7751/10000, Loss: 0.0114689189940691\n",
      "Iteration: 7752/10000, Loss: 0.012508918531239033\n",
      "Iteration: 7753/10000, Loss: 0.012185724452137947\n",
      "Iteration: 7754/10000, Loss: 0.008212646469473839\n",
      "Iteration: 7755/10000, Loss: 0.008089425042271614\n",
      "Iteration: 7756/10000, Loss: 0.008793527260422707\n",
      "Iteration: 7757/10000, Loss: 0.008215764537453651\n",
      "Iteration: 7758/10000, Loss: 0.009457611478865147\n",
      "Iteration: 7759/10000, Loss: 0.009745234623551369\n",
      "Iteration: 7760/10000, Loss: 0.00841500423848629\n",
      "Iteration: 7761/10000, Loss: 0.007550548762083054\n",
      "Iteration: 7762/10000, Loss: 0.006835867650806904\n",
      "Iteration: 7763/10000, Loss: 0.012662850320339203\n",
      "Iteration: 7764/10000, Loss: 0.007343428209424019\n",
      "Iteration: 7765/10000, Loss: 0.009223571978509426\n",
      "Iteration: 7766/10000, Loss: 0.009778445586562157\n",
      "Iteration: 7767/10000, Loss: 0.007829328998923302\n",
      "Iteration: 7768/10000, Loss: 0.005477046128362417\n",
      "Iteration: 7769/10000, Loss: 0.013378883711993694\n",
      "Iteration: 7770/10000, Loss: 0.007503846660256386\n",
      "Iteration: 7771/10000, Loss: 0.00925386231392622\n",
      "Iteration: 7772/10000, Loss: 0.008251319639384747\n",
      "Iteration: 7773/10000, Loss: 0.0053290692158043385\n",
      "Iteration: 7774/10000, Loss: 0.00905566941946745\n",
      "Iteration: 7775/10000, Loss: 0.010576824657619\n",
      "Iteration: 7776/10000, Loss: 0.013804610818624496\n",
      "Iteration: 7777/10000, Loss: 0.0072661517187952995\n",
      "Iteration: 7778/10000, Loss: 0.007986128330230713\n",
      "Iteration: 7779/10000, Loss: 0.005048956256359816\n",
      "Iteration: 7780/10000, Loss: 0.01113048754632473\n",
      "Iteration: 7781/10000, Loss: 0.01170598529279232\n",
      "Iteration: 7782/10000, Loss: 0.008934469893574715\n",
      "Iteration: 7783/10000, Loss: 0.01220005378127098\n",
      "Iteration: 7784/10000, Loss: 0.008089663460850716\n",
      "Iteration: 7785/10000, Loss: 0.009346156381070614\n",
      "Iteration: 7786/10000, Loss: 0.007530788891017437\n",
      "Iteration: 7787/10000, Loss: 0.006150813773274422\n",
      "Iteration: 7788/10000, Loss: 0.01007886417210102\n",
      "Iteration: 7789/10000, Loss: 0.0105380704626441\n",
      "Iteration: 7790/10000, Loss: 0.008434806950390339\n",
      "Iteration: 7791/10000, Loss: 0.009939825162291527\n",
      "Iteration: 7792/10000, Loss: 0.01169204618781805\n",
      "Iteration: 7793/10000, Loss: 0.008125911466777325\n",
      "Iteration: 7794/10000, Loss: 0.011834678240120411\n",
      "Iteration: 7795/10000, Loss: 0.012016033753752708\n",
      "Iteration: 7796/10000, Loss: 0.010349404066801071\n",
      "Iteration: 7797/10000, Loss: 0.004330853465944529\n",
      "Iteration: 7798/10000, Loss: 0.013713301159441471\n",
      "Iteration: 7799/10000, Loss: 0.009610180743038654\n",
      "Iteration: 7800/10000, Loss: 0.012578477151691914\n",
      "Average test loss:  0.0015\n",
      "Iteration: 7801/10000, Loss: 0.014017297886312008\n",
      "Iteration: 7802/10000, Loss: 0.00860133022069931\n",
      "Iteration: 7803/10000, Loss: 0.010423406027257442\n",
      "Iteration: 7804/10000, Loss: 0.007588760927319527\n",
      "Iteration: 7805/10000, Loss: 0.016935838386416435\n",
      "Iteration: 7806/10000, Loss: 0.0072137825191020966\n",
      "Iteration: 7807/10000, Loss: 0.009287233464419842\n",
      "Iteration: 7808/10000, Loss: 0.009240144863724709\n",
      "Iteration: 7809/10000, Loss: 0.007031060755252838\n",
      "Iteration: 7810/10000, Loss: 0.012106851674616337\n",
      "Iteration: 7811/10000, Loss: 0.008618014864623547\n",
      "Iteration: 7812/10000, Loss: 0.015132036060094833\n",
      "Iteration: 7813/10000, Loss: 0.010474052280187607\n",
      "Iteration: 7814/10000, Loss: 0.01044481247663498\n",
      "Iteration: 7815/10000, Loss: 0.011805389076471329\n",
      "Iteration: 7816/10000, Loss: 0.008563579991459846\n",
      "Iteration: 7817/10000, Loss: 0.00870463252067566\n",
      "Iteration: 7818/10000, Loss: 0.009921167977154255\n",
      "Iteration: 7819/10000, Loss: 0.011252297088503838\n",
      "Iteration: 7820/10000, Loss: 0.009688377380371094\n",
      "Iteration: 7821/10000, Loss: 0.009521168656647205\n",
      "Iteration: 7822/10000, Loss: 0.017530644312500954\n",
      "Iteration: 7823/10000, Loss: 0.012200755067169666\n",
      "Iteration: 7824/10000, Loss: 0.008920498192310333\n",
      "Iteration: 7825/10000, Loss: 0.012967708520591259\n",
      "Iteration: 7826/10000, Loss: 0.012010549195110798\n",
      "Iteration: 7827/10000, Loss: 0.01449776254594326\n",
      "Iteration: 7828/10000, Loss: 0.011077395640313625\n",
      "Iteration: 7829/10000, Loss: 0.00980643555521965\n",
      "Iteration: 7830/10000, Loss: 0.00828852504491806\n",
      "Iteration: 7831/10000, Loss: 0.008196622133255005\n",
      "Iteration: 7832/10000, Loss: 0.00871255062520504\n",
      "Iteration: 7833/10000, Loss: 0.007449864409863949\n",
      "Iteration: 7834/10000, Loss: 0.011387424543499947\n",
      "Iteration: 7835/10000, Loss: 0.005711775738745928\n",
      "Iteration: 7836/10000, Loss: 0.01142507791519165\n",
      "Iteration: 7837/10000, Loss: 0.016976315528154373\n",
      "Iteration: 7838/10000, Loss: 0.006420864723622799\n",
      "Iteration: 7839/10000, Loss: 0.009560462087392807\n",
      "Iteration: 7840/10000, Loss: 0.009153086692094803\n",
      "Iteration: 7841/10000, Loss: 0.015322364866733551\n",
      "Iteration: 7842/10000, Loss: 0.007494267541915178\n",
      "Iteration: 7843/10000, Loss: 0.012113673612475395\n",
      "Iteration: 7844/10000, Loss: 0.019160374999046326\n",
      "Iteration: 7845/10000, Loss: 0.007031352259218693\n",
      "Iteration: 7846/10000, Loss: 0.009464433416724205\n",
      "Iteration: 7847/10000, Loss: 0.007615984883159399\n",
      "Iteration: 7848/10000, Loss: 0.01058579795062542\n",
      "Iteration: 7849/10000, Loss: 0.015697700902819633\n",
      "Iteration: 7850/10000, Loss: 0.010920641012489796\n",
      "Iteration: 7851/10000, Loss: 0.009359116666018963\n",
      "Iteration: 7852/10000, Loss: 0.010065988637506962\n",
      "Iteration: 7853/10000, Loss: 0.009323939681053162\n",
      "Iteration: 7854/10000, Loss: 0.011167071759700775\n",
      "Iteration: 7855/10000, Loss: 0.012295054271817207\n",
      "Iteration: 7856/10000, Loss: 0.007331403438001871\n",
      "Iteration: 7857/10000, Loss: 0.0062369415536522865\n",
      "Iteration: 7858/10000, Loss: 0.01004254724830389\n",
      "Iteration: 7859/10000, Loss: 0.009538707323372364\n",
      "Iteration: 7860/10000, Loss: 0.009411394596099854\n",
      "Iteration: 7861/10000, Loss: 0.009441758506000042\n",
      "Iteration: 7862/10000, Loss: 0.006554565392434597\n",
      "Iteration: 7863/10000, Loss: 0.009435516782104969\n",
      "Iteration: 7864/10000, Loss: 0.010783976875245571\n",
      "Iteration: 7865/10000, Loss: 0.007501904387027025\n",
      "Iteration: 7866/10000, Loss: 0.0096924789249897\n",
      "Iteration: 7867/10000, Loss: 0.00645756721496582\n",
      "Iteration: 7868/10000, Loss: 0.008039096370339394\n",
      "Iteration: 7869/10000, Loss: 0.011175177060067654\n",
      "Iteration: 7870/10000, Loss: 0.012270578183233738\n",
      "Iteration: 7871/10000, Loss: 0.012544261291623116\n",
      "Iteration: 7872/10000, Loss: 0.0058707790449261665\n",
      "Iteration: 7873/10000, Loss: 0.010770813561975956\n",
      "Iteration: 7874/10000, Loss: 0.008491789922118187\n",
      "Iteration: 7875/10000, Loss: 0.009736308827996254\n",
      "Iteration: 7876/10000, Loss: 0.00865526869893074\n",
      "Iteration: 7877/10000, Loss: 0.007113415282219648\n",
      "Iteration: 7878/10000, Loss: 0.008597859181463718\n",
      "Iteration: 7879/10000, Loss: 0.011508048512041569\n",
      "Iteration: 7880/10000, Loss: 0.007423097267746925\n",
      "Iteration: 7881/10000, Loss: 0.005707899108529091\n",
      "Iteration: 7882/10000, Loss: 0.0068277399986982346\n",
      "Iteration: 7883/10000, Loss: 0.010666292160749435\n",
      "Iteration: 7884/10000, Loss: 0.013902111910283566\n",
      "Iteration: 7885/10000, Loss: 0.01093369908630848\n",
      "Iteration: 7886/10000, Loss: 0.006912990473210812\n",
      "Iteration: 7887/10000, Loss: 0.006207730621099472\n",
      "Iteration: 7888/10000, Loss: 0.0057004536502063274\n",
      "Iteration: 7889/10000, Loss: 0.015018454752862453\n",
      "Iteration: 7890/10000, Loss: 0.011874654330313206\n",
      "Iteration: 7891/10000, Loss: 0.006584525108337402\n",
      "Iteration: 7892/10000, Loss: 0.0075467973947525024\n",
      "Iteration: 7893/10000, Loss: 0.006217002868652344\n",
      "Iteration: 7894/10000, Loss: 0.011517220176756382\n",
      "Iteration: 7895/10000, Loss: 0.011993536725640297\n",
      "Iteration: 7896/10000, Loss: 0.008108483627438545\n",
      "Iteration: 7897/10000, Loss: 0.006597868632525206\n",
      "Iteration: 7898/10000, Loss: 0.011724911630153656\n",
      "Iteration: 7899/10000, Loss: 0.007231432478874922\n",
      "Iteration: 7900/10000, Loss: 0.015720829367637634\n",
      "Average test loss:  0.0054\n",
      "Iteration: 7901/10000, Loss: 0.010552058927714825\n",
      "Iteration: 7902/10000, Loss: 0.00900043174624443\n",
      "Iteration: 7903/10000, Loss: 0.006824969779700041\n",
      "Iteration: 7904/10000, Loss: 0.010697685182094574\n",
      "Iteration: 7905/10000, Loss: 0.012336845509707928\n",
      "Iteration: 7906/10000, Loss: 0.009647779166698456\n",
      "Iteration: 7907/10000, Loss: 0.009466389194130898\n",
      "Iteration: 7908/10000, Loss: 0.0078037204220891\n",
      "Iteration: 7909/10000, Loss: 0.010011388920247555\n",
      "Iteration: 7910/10000, Loss: 0.015020273625850677\n",
      "Iteration: 7911/10000, Loss: 0.007989871315658092\n",
      "Iteration: 7912/10000, Loss: 0.008632520213723183\n",
      "Iteration: 7913/10000, Loss: 0.013640939258038998\n",
      "Iteration: 7914/10000, Loss: 0.01209437008947134\n",
      "Iteration: 7915/10000, Loss: 0.013365868479013443\n",
      "Iteration: 7916/10000, Loss: 0.016467103734612465\n",
      "Iteration: 7917/10000, Loss: 0.009226038120687008\n",
      "Iteration: 7918/10000, Loss: 0.010736729949712753\n",
      "Iteration: 7919/10000, Loss: 0.010863278061151505\n",
      "Iteration: 7920/10000, Loss: 0.012896585278213024\n",
      "Iteration: 7921/10000, Loss: 0.00787263736128807\n",
      "Iteration: 7922/10000, Loss: 0.0082481624558568\n",
      "Iteration: 7923/10000, Loss: 0.012613189406692982\n",
      "Iteration: 7924/10000, Loss: 0.005915529560297728\n",
      "Iteration: 7925/10000, Loss: 0.011660480871796608\n",
      "Iteration: 7926/10000, Loss: 0.011042974889278412\n",
      "Iteration: 7927/10000, Loss: 0.009699370712041855\n",
      "Iteration: 7928/10000, Loss: 0.011084028519690037\n",
      "Iteration: 7929/10000, Loss: 0.010043787769973278\n",
      "Iteration: 7930/10000, Loss: 0.011060282588005066\n",
      "Iteration: 7931/10000, Loss: 0.009178864769637585\n",
      "Iteration: 7932/10000, Loss: 0.009435485117137432\n",
      "Iteration: 7933/10000, Loss: 0.0093487948179245\n",
      "Iteration: 7934/10000, Loss: 0.01068872306495905\n",
      "Iteration: 7935/10000, Loss: 0.021119022741913795\n",
      "Iteration: 7936/10000, Loss: 0.010117259807884693\n",
      "Iteration: 7937/10000, Loss: 0.0067672645673155785\n",
      "Iteration: 7938/10000, Loss: 0.00919318851083517\n",
      "Iteration: 7939/10000, Loss: 0.011282628402113914\n",
      "Iteration: 7940/10000, Loss: 0.011964769102633\n",
      "Iteration: 7941/10000, Loss: 0.014286707155406475\n",
      "Iteration: 7942/10000, Loss: 0.0075171212665736675\n",
      "Iteration: 7943/10000, Loss: 0.010425955057144165\n",
      "Iteration: 7944/10000, Loss: 0.009491520933806896\n",
      "Iteration: 7945/10000, Loss: 0.005367554724216461\n",
      "Iteration: 7946/10000, Loss: 0.009444005787372589\n",
      "Iteration: 7947/10000, Loss: 0.01111496053636074\n",
      "Iteration: 7948/10000, Loss: 0.012555898167192936\n",
      "Iteration: 7949/10000, Loss: 0.009503246285021305\n",
      "Iteration: 7950/10000, Loss: 0.012406321242451668\n",
      "Iteration: 7951/10000, Loss: 0.008751887828111649\n",
      "Iteration: 7952/10000, Loss: 0.013058049604296684\n",
      "Iteration: 7953/10000, Loss: 0.00789425615221262\n",
      "Iteration: 7954/10000, Loss: 0.010495861060917377\n",
      "Iteration: 7955/10000, Loss: 0.00899563916027546\n",
      "Iteration: 7956/10000, Loss: 0.007840005680918694\n",
      "Iteration: 7957/10000, Loss: 0.006554450839757919\n",
      "Iteration: 7958/10000, Loss: 0.006180222611874342\n",
      "Iteration: 7959/10000, Loss: 0.008430840447545052\n",
      "Iteration: 7960/10000, Loss: 0.00770434970036149\n",
      "Iteration: 7961/10000, Loss: 0.010244832374155521\n",
      "Iteration: 7962/10000, Loss: 0.01206053514033556\n",
      "Iteration: 7963/10000, Loss: 0.012122983112931252\n",
      "Iteration: 7964/10000, Loss: 0.009655947797000408\n",
      "Iteration: 7965/10000, Loss: 0.01013658381998539\n",
      "Iteration: 7966/10000, Loss: 0.010082704946398735\n",
      "Iteration: 7967/10000, Loss: 0.009817483834922314\n",
      "Iteration: 7968/10000, Loss: 0.009552108123898506\n",
      "Iteration: 7969/10000, Loss: 0.00905549991875887\n",
      "Iteration: 7970/10000, Loss: 0.01196487620472908\n",
      "Iteration: 7971/10000, Loss: 0.006654068827629089\n",
      "Iteration: 7972/10000, Loss: 0.007406820077449083\n",
      "Iteration: 7973/10000, Loss: 0.011652792803943157\n",
      "Iteration: 7974/10000, Loss: 0.010309875942766666\n",
      "Iteration: 7975/10000, Loss: 0.012497661635279655\n",
      "Iteration: 7976/10000, Loss: 0.011771873570978642\n",
      "Iteration: 7977/10000, Loss: 0.007572765927761793\n",
      "Iteration: 7978/10000, Loss: 0.010881953872740269\n",
      "Iteration: 7979/10000, Loss: 0.005083980970084667\n",
      "Iteration: 7980/10000, Loss: 0.008664160035550594\n",
      "Iteration: 7981/10000, Loss: 0.01002932246774435\n",
      "Iteration: 7982/10000, Loss: 0.010174102149903774\n",
      "Iteration: 7983/10000, Loss: 0.0073620653711259365\n",
      "Iteration: 7984/10000, Loss: 0.009683849290013313\n",
      "Iteration: 7985/10000, Loss: 0.009267491288483143\n",
      "Iteration: 7986/10000, Loss: 0.010245931334793568\n",
      "Iteration: 7987/10000, Loss: 0.008056845515966415\n",
      "Iteration: 7988/10000, Loss: 0.00679534999653697\n",
      "Iteration: 7989/10000, Loss: 0.00957776140421629\n",
      "Iteration: 7990/10000, Loss: 0.0059126801788806915\n",
      "Iteration: 7991/10000, Loss: 0.005811559036374092\n",
      "Iteration: 7992/10000, Loss: 0.006115575321018696\n",
      "Iteration: 7993/10000, Loss: 0.009255309589207172\n",
      "Iteration: 7994/10000, Loss: 0.0106757627800107\n",
      "Iteration: 7995/10000, Loss: 0.009716564789414406\n",
      "Iteration: 7996/10000, Loss: 0.009423772804439068\n",
      "Iteration: 7997/10000, Loss: 0.0073194545693695545\n",
      "Iteration: 7998/10000, Loss: 0.007020063232630491\n",
      "Iteration: 7999/10000, Loss: 0.010031874291598797\n",
      "Iteration: 8000/10000, Loss: 0.00635520089417696\n",
      "Average test loss:  0.0022\n",
      "Iteration: 8001/10000, Loss: 0.007383901625871658\n",
      "Iteration: 8002/10000, Loss: 0.0044678496196866035\n",
      "Iteration: 8003/10000, Loss: 0.006950997281819582\n",
      "Iteration: 8004/10000, Loss: 0.007392825558781624\n",
      "Iteration: 8005/10000, Loss: 0.011610424146056175\n",
      "Iteration: 8006/10000, Loss: 0.013421180658042431\n",
      "Iteration: 8007/10000, Loss: 0.005075083114206791\n",
      "Iteration: 8008/10000, Loss: 0.012528135441243649\n",
      "Iteration: 8009/10000, Loss: 0.008987952023744583\n",
      "Iteration: 8010/10000, Loss: 0.010325283743441105\n",
      "Iteration: 8011/10000, Loss: 0.011163482442498207\n",
      "Iteration: 8012/10000, Loss: 0.01256025955080986\n",
      "Iteration: 8013/10000, Loss: 0.013236473314464092\n",
      "Iteration: 8014/10000, Loss: 0.012439964339137077\n",
      "Iteration: 8015/10000, Loss: 0.010994936339557171\n",
      "Iteration: 8016/10000, Loss: 0.008467026986181736\n",
      "Iteration: 8017/10000, Loss: 0.006027993280440569\n",
      "Iteration: 8018/10000, Loss: 0.011930212378501892\n",
      "Iteration: 8019/10000, Loss: 0.010319815948605537\n",
      "Iteration: 8020/10000, Loss: 0.012386301532387733\n",
      "Iteration: 8021/10000, Loss: 0.007321659009903669\n",
      "Iteration: 8022/10000, Loss: 0.014690383337438107\n",
      "Iteration: 8023/10000, Loss: 0.01283327303826809\n",
      "Iteration: 8024/10000, Loss: 0.011711684055626392\n",
      "Iteration: 8025/10000, Loss: 0.008983815088868141\n",
      "Iteration: 8026/10000, Loss: 0.01216517947614193\n",
      "Iteration: 8027/10000, Loss: 0.011275719851255417\n",
      "Iteration: 8028/10000, Loss: 0.011040455661714077\n",
      "Iteration: 8029/10000, Loss: 0.01176005695015192\n",
      "Iteration: 8030/10000, Loss: 0.009060152806341648\n",
      "Iteration: 8031/10000, Loss: 0.00847531296312809\n",
      "Iteration: 8032/10000, Loss: 0.0054038651287555695\n",
      "Iteration: 8033/10000, Loss: 0.009556378237903118\n",
      "Iteration: 8034/10000, Loss: 0.007850115187466145\n",
      "Iteration: 8035/10000, Loss: 0.007916310802102089\n",
      "Iteration: 8036/10000, Loss: 0.00799591839313507\n",
      "Iteration: 8037/10000, Loss: 0.009632441215217113\n",
      "Iteration: 8038/10000, Loss: 0.009635626338422298\n",
      "Iteration: 8039/10000, Loss: 0.005232471041381359\n",
      "Iteration: 8040/10000, Loss: 0.011994387954473495\n",
      "Iteration: 8041/10000, Loss: 0.00648960005491972\n",
      "Iteration: 8042/10000, Loss: 0.011697889305651188\n",
      "Iteration: 8043/10000, Loss: 0.009896548464894295\n",
      "Iteration: 8044/10000, Loss: 0.007748811971396208\n",
      "Iteration: 8045/10000, Loss: 0.0076574888080358505\n",
      "Iteration: 8046/10000, Loss: 0.007843192666769028\n",
      "Iteration: 8047/10000, Loss: 0.013362046331167221\n",
      "Iteration: 8048/10000, Loss: 0.011800620704889297\n",
      "Iteration: 8049/10000, Loss: 0.015531973913311958\n",
      "Iteration: 8050/10000, Loss: 0.009058319963514805\n",
      "Iteration: 8051/10000, Loss: 0.013431607745587826\n",
      "Iteration: 8052/10000, Loss: 0.008322971872985363\n",
      "Iteration: 8053/10000, Loss: 0.007401004899293184\n",
      "Iteration: 8054/10000, Loss: 0.010498841293156147\n",
      "Iteration: 8055/10000, Loss: 0.012562951073050499\n",
      "Iteration: 8056/10000, Loss: 0.009676625952124596\n",
      "Iteration: 8057/10000, Loss: 0.00977137591689825\n",
      "Iteration: 8058/10000, Loss: 0.007312334608286619\n",
      "Iteration: 8059/10000, Loss: 0.008163430728018284\n",
      "Iteration: 8060/10000, Loss: 0.014527813531458378\n",
      "Iteration: 8061/10000, Loss: 0.010579253546893597\n",
      "Iteration: 8062/10000, Loss: 0.009203395806252956\n",
      "Iteration: 8063/10000, Loss: 0.006414883304387331\n",
      "Iteration: 8064/10000, Loss: 0.009046089835464954\n",
      "Iteration: 8065/10000, Loss: 0.007842670194804668\n",
      "Iteration: 8066/10000, Loss: 0.006369294133037329\n",
      "Iteration: 8067/10000, Loss: 0.006961713545024395\n",
      "Iteration: 8068/10000, Loss: 0.0077902344055473804\n",
      "Iteration: 8069/10000, Loss: 0.010927238501608372\n",
      "Iteration: 8070/10000, Loss: 0.009224885143339634\n",
      "Iteration: 8071/10000, Loss: 0.008625832386314869\n",
      "Iteration: 8072/10000, Loss: 0.008058455772697926\n",
      "Iteration: 8073/10000, Loss: 0.01024511270225048\n",
      "Iteration: 8074/10000, Loss: 0.006692023482173681\n",
      "Iteration: 8075/10000, Loss: 0.011914842762053013\n",
      "Iteration: 8076/10000, Loss: 0.005868857726454735\n",
      "Iteration: 8077/10000, Loss: 0.00846773199737072\n",
      "Iteration: 8078/10000, Loss: 0.009772387333214283\n",
      "Iteration: 8079/10000, Loss: 0.010078073479235172\n",
      "Iteration: 8080/10000, Loss: 0.005553188733756542\n",
      "Iteration: 8081/10000, Loss: 0.01249095518141985\n",
      "Iteration: 8082/10000, Loss: 0.014929492957890034\n",
      "Iteration: 8083/10000, Loss: 0.007000282406806946\n",
      "Iteration: 8084/10000, Loss: 0.009578638710081577\n",
      "Iteration: 8085/10000, Loss: 0.01199228037148714\n",
      "Iteration: 8086/10000, Loss: 0.012171922251582146\n",
      "Iteration: 8087/10000, Loss: 0.012446440756320953\n",
      "Iteration: 8088/10000, Loss: 0.008577607572078705\n",
      "Iteration: 8089/10000, Loss: 0.010395858436822891\n",
      "Iteration: 8090/10000, Loss: 0.006194813642650843\n",
      "Iteration: 8091/10000, Loss: 0.012616214342415333\n",
      "Iteration: 8092/10000, Loss: 0.013266902416944504\n",
      "Iteration: 8093/10000, Loss: 0.009568502195179462\n",
      "Iteration: 8094/10000, Loss: 0.005774382967501879\n",
      "Iteration: 8095/10000, Loss: 0.006162845995277166\n",
      "Iteration: 8096/10000, Loss: 0.011159016750752926\n",
      "Iteration: 8097/10000, Loss: 0.0068186125718057156\n",
      "Iteration: 8098/10000, Loss: 0.009347084909677505\n",
      "Iteration: 8099/10000, Loss: 0.007706053089350462\n",
      "Iteration: 8100/10000, Loss: 0.007864533923566341\n",
      "Average test loss:  0.0046\n",
      "Iteration: 8101/10000, Loss: 0.012216057628393173\n",
      "Iteration: 8102/10000, Loss: 0.007902867160737514\n",
      "Iteration: 8103/10000, Loss: 0.00985000655055046\n",
      "Iteration: 8104/10000, Loss: 0.005803681444376707\n",
      "Iteration: 8105/10000, Loss: 0.006396965589374304\n",
      "Iteration: 8106/10000, Loss: 0.012740856036543846\n",
      "Iteration: 8107/10000, Loss: 0.007253954187035561\n",
      "Iteration: 8108/10000, Loss: 0.011133960448205471\n",
      "Iteration: 8109/10000, Loss: 0.011664065532386303\n",
      "Iteration: 8110/10000, Loss: 0.009864342398941517\n",
      "Iteration: 8111/10000, Loss: 0.007643671240657568\n",
      "Iteration: 8112/10000, Loss: 0.007149631157517433\n",
      "Iteration: 8113/10000, Loss: 0.006646876223385334\n",
      "Iteration: 8114/10000, Loss: 0.0070614926517009735\n",
      "Iteration: 8115/10000, Loss: 0.008591365069150925\n",
      "Iteration: 8116/10000, Loss: 0.00834579486399889\n",
      "Iteration: 8117/10000, Loss: 0.007935691624879837\n",
      "Iteration: 8118/10000, Loss: 0.008370318450033665\n",
      "Iteration: 8119/10000, Loss: 0.010712036862969398\n",
      "Iteration: 8120/10000, Loss: 0.016447901725769043\n",
      "Iteration: 8121/10000, Loss: 0.006868424825370312\n",
      "Iteration: 8122/10000, Loss: 0.009709305129945278\n",
      "Iteration: 8123/10000, Loss: 0.004183981567621231\n",
      "Iteration: 8124/10000, Loss: 0.017778601497411728\n",
      "Iteration: 8125/10000, Loss: 0.011337530799210072\n",
      "Iteration: 8126/10000, Loss: 0.012361956760287285\n",
      "Iteration: 8127/10000, Loss: 0.00907295010983944\n",
      "Iteration: 8128/10000, Loss: 0.009512017481029034\n",
      "Iteration: 8129/10000, Loss: 0.008547627367079258\n",
      "Iteration: 8130/10000, Loss: 0.010082898661494255\n",
      "Iteration: 8131/10000, Loss: 0.005299974698573351\n",
      "Iteration: 8132/10000, Loss: 0.006570057477802038\n",
      "Iteration: 8133/10000, Loss: 0.008761651813983917\n",
      "Iteration: 8134/10000, Loss: 0.006653939839452505\n",
      "Iteration: 8135/10000, Loss: 0.0058478619903326035\n",
      "Iteration: 8136/10000, Loss: 0.008324112743139267\n",
      "Iteration: 8137/10000, Loss: 0.00792655348777771\n",
      "Iteration: 8138/10000, Loss: 0.008593831211328506\n",
      "Iteration: 8139/10000, Loss: 0.007846449501812458\n",
      "Iteration: 8140/10000, Loss: 0.008897853083908558\n",
      "Iteration: 8141/10000, Loss: 0.009745508432388306\n",
      "Iteration: 8142/10000, Loss: 0.010051161050796509\n",
      "Iteration: 8143/10000, Loss: 0.010222404263913631\n",
      "Iteration: 8144/10000, Loss: 0.0069652884267270565\n",
      "Iteration: 8145/10000, Loss: 0.011291291564702988\n",
      "Iteration: 8146/10000, Loss: 0.007323006633669138\n",
      "Iteration: 8147/10000, Loss: 0.0063881054520606995\n",
      "Iteration: 8148/10000, Loss: 0.007134670857340097\n",
      "Iteration: 8149/10000, Loss: 0.006997056305408478\n",
      "Iteration: 8150/10000, Loss: 0.007215240970253944\n",
      "Iteration: 8151/10000, Loss: 0.010131126269698143\n",
      "Iteration: 8152/10000, Loss: 0.009908424690365791\n",
      "Iteration: 8153/10000, Loss: 0.00921733770519495\n",
      "Iteration: 8154/10000, Loss: 0.013184705749154091\n",
      "Iteration: 8155/10000, Loss: 0.006268913857638836\n",
      "Iteration: 8156/10000, Loss: 0.008479470387101173\n",
      "Iteration: 8157/10000, Loss: 0.006924707442522049\n",
      "Iteration: 8158/10000, Loss: 0.007048718631267548\n",
      "Iteration: 8159/10000, Loss: 0.00747365178540349\n",
      "Iteration: 8160/10000, Loss: 0.006031794007867575\n",
      "Iteration: 8161/10000, Loss: 0.007750719785690308\n",
      "Iteration: 8162/10000, Loss: 0.013303373008966446\n",
      "Iteration: 8163/10000, Loss: 0.010314565151929855\n",
      "Iteration: 8164/10000, Loss: 0.003114905674010515\n",
      "Iteration: 8165/10000, Loss: 0.009262481704354286\n",
      "Iteration: 8166/10000, Loss: 0.011538567021489143\n",
      "Iteration: 8167/10000, Loss: 0.012011632323265076\n",
      "Iteration: 8168/10000, Loss: 0.00952157098799944\n",
      "Iteration: 8169/10000, Loss: 0.011143396608531475\n",
      "Iteration: 8170/10000, Loss: 0.007947692647576332\n",
      "Iteration: 8171/10000, Loss: 0.010151855647563934\n",
      "Iteration: 8172/10000, Loss: 0.00988044310361147\n",
      "Iteration: 8173/10000, Loss: 0.00976446084678173\n",
      "Iteration: 8174/10000, Loss: 0.008404314517974854\n",
      "Iteration: 8175/10000, Loss: 0.007741848938167095\n",
      "Iteration: 8176/10000, Loss: 0.009452766738831997\n",
      "Iteration: 8177/10000, Loss: 0.008118201047182083\n",
      "Iteration: 8178/10000, Loss: 0.007985717616975307\n",
      "Iteration: 8179/10000, Loss: 0.012453854084014893\n",
      "Iteration: 8180/10000, Loss: 0.01199412066489458\n",
      "Iteration: 8181/10000, Loss: 0.00559205561876297\n",
      "Iteration: 8182/10000, Loss: 0.01027725636959076\n",
      "Iteration: 8183/10000, Loss: 0.009914298541843891\n",
      "Iteration: 8184/10000, Loss: 0.008730362169444561\n",
      "Iteration: 8185/10000, Loss: 0.006474814377725124\n",
      "Iteration: 8186/10000, Loss: 0.006063374225050211\n",
      "Iteration: 8187/10000, Loss: 0.011111997067928314\n",
      "Iteration: 8188/10000, Loss: 0.01059812679886818\n",
      "Iteration: 8189/10000, Loss: 0.010255611501634121\n",
      "Iteration: 8190/10000, Loss: 0.010411113500595093\n",
      "Iteration: 8191/10000, Loss: 0.007544142194092274\n",
      "Iteration: 8192/10000, Loss: 0.010438570752739906\n",
      "Iteration: 8193/10000, Loss: 0.007677742745727301\n",
      "Iteration: 8194/10000, Loss: 0.009601905941963196\n",
      "Iteration: 8195/10000, Loss: 0.011749481782317162\n",
      "Iteration: 8196/10000, Loss: 0.010194579139351845\n",
      "Iteration: 8197/10000, Loss: 0.00491294264793396\n",
      "Iteration: 8198/10000, Loss: 0.00694481935352087\n",
      "Iteration: 8199/10000, Loss: 0.014370748773217201\n",
      "Iteration: 8200/10000, Loss: 0.009341525845229626\n",
      "Average test loss:  0.0022\n",
      "Iteration: 8201/10000, Loss: 0.00996251218020916\n",
      "Iteration: 8202/10000, Loss: 0.009219524450600147\n",
      "Iteration: 8203/10000, Loss: 0.010383285582065582\n",
      "Iteration: 8204/10000, Loss: 0.01678171008825302\n",
      "Iteration: 8205/10000, Loss: 0.00973495189100504\n",
      "Iteration: 8206/10000, Loss: 0.011258095502853394\n",
      "Iteration: 8207/10000, Loss: 0.007337355520576239\n",
      "Iteration: 8208/10000, Loss: 0.00844733789563179\n",
      "Iteration: 8209/10000, Loss: 0.008611013181507587\n",
      "Iteration: 8210/10000, Loss: 0.00934575591236353\n",
      "Iteration: 8211/10000, Loss: 0.008368113078176975\n",
      "Iteration: 8212/10000, Loss: 0.006859264336526394\n",
      "Iteration: 8213/10000, Loss: 0.008514742366969585\n",
      "Iteration: 8214/10000, Loss: 0.012053358368575573\n",
      "Iteration: 8215/10000, Loss: 0.011237122118473053\n",
      "Iteration: 8216/10000, Loss: 0.005176963284611702\n",
      "Iteration: 8217/10000, Loss: 0.012530687265098095\n",
      "Iteration: 8218/10000, Loss: 0.011118883267045021\n",
      "Iteration: 8219/10000, Loss: 0.00808155257254839\n",
      "Iteration: 8220/10000, Loss: 0.010298075154423714\n",
      "Iteration: 8221/10000, Loss: 0.012912129983305931\n",
      "Iteration: 8222/10000, Loss: 0.007345546502619982\n",
      "Iteration: 8223/10000, Loss: 0.011488070711493492\n",
      "Iteration: 8224/10000, Loss: 0.008941271342337132\n",
      "Iteration: 8225/10000, Loss: 0.01307355985045433\n",
      "Iteration: 8226/10000, Loss: 0.01043790951371193\n",
      "Iteration: 8227/10000, Loss: 0.010314119048416615\n",
      "Iteration: 8228/10000, Loss: 0.010498317889869213\n",
      "Iteration: 8229/10000, Loss: 0.009640187956392765\n",
      "Iteration: 8230/10000, Loss: 0.01043781079351902\n",
      "Iteration: 8231/10000, Loss: 0.01029367744922638\n",
      "Iteration: 8232/10000, Loss: 0.005820385180413723\n",
      "Iteration: 8233/10000, Loss: 0.011986817233264446\n",
      "Iteration: 8234/10000, Loss: 0.011046811006963253\n",
      "Iteration: 8235/10000, Loss: 0.006817199755460024\n",
      "Iteration: 8236/10000, Loss: 0.008595536462962627\n",
      "Iteration: 8237/10000, Loss: 0.009708860889077187\n",
      "Iteration: 8238/10000, Loss: 0.008191718719899654\n",
      "Iteration: 8239/10000, Loss: 0.006075643468648195\n",
      "Iteration: 8240/10000, Loss: 0.007374407257884741\n",
      "Iteration: 8241/10000, Loss: 0.007855434902012348\n",
      "Iteration: 8242/10000, Loss: 0.007871684618294239\n",
      "Iteration: 8243/10000, Loss: 0.008309523575007915\n",
      "Iteration: 8244/10000, Loss: 0.007441953755915165\n",
      "Iteration: 8245/10000, Loss: 0.01069781556725502\n",
      "Iteration: 8246/10000, Loss: 0.00656600808724761\n",
      "Iteration: 8247/10000, Loss: 0.008676732890307903\n",
      "Iteration: 8248/10000, Loss: 0.01030812133103609\n",
      "Iteration: 8249/10000, Loss: 0.007624310906976461\n",
      "Iteration: 8250/10000, Loss: 0.0073317973874509335\n",
      "Iteration: 8251/10000, Loss: 0.009246595203876495\n",
      "Iteration: 8252/10000, Loss: 0.007478567771613598\n",
      "Iteration: 8253/10000, Loss: 0.009798326529562473\n",
      "Iteration: 8254/10000, Loss: 0.014317864552140236\n",
      "Iteration: 8255/10000, Loss: 0.011429985985159874\n",
      "Iteration: 8256/10000, Loss: 0.0054984623566269875\n",
      "Iteration: 8257/10000, Loss: 0.009636118076741695\n",
      "Iteration: 8258/10000, Loss: 0.009848534129559994\n",
      "Iteration: 8259/10000, Loss: 0.014344729483127594\n",
      "Iteration: 8260/10000, Loss: 0.010478501208126545\n",
      "Iteration: 8261/10000, Loss: 0.007533603813499212\n",
      "Iteration: 8262/10000, Loss: 0.01039328332990408\n",
      "Iteration: 8263/10000, Loss: 0.010267363861203194\n",
      "Iteration: 8264/10000, Loss: 0.004950349684804678\n",
      "Iteration: 8265/10000, Loss: 0.007706745062023401\n",
      "Iteration: 8266/10000, Loss: 0.009894581511616707\n",
      "Iteration: 8267/10000, Loss: 0.008995609357953072\n",
      "Iteration: 8268/10000, Loss: 0.0061002434231340885\n",
      "Iteration: 8269/10000, Loss: 0.008191161789000034\n",
      "Iteration: 8270/10000, Loss: 0.0065390607342123985\n",
      "Iteration: 8271/10000, Loss: 0.006766395643353462\n",
      "Iteration: 8272/10000, Loss: 0.008875388652086258\n",
      "Iteration: 8273/10000, Loss: 0.006090913899242878\n",
      "Iteration: 8274/10000, Loss: 0.0077135744504630566\n",
      "Iteration: 8275/10000, Loss: 0.01468260120600462\n",
      "Iteration: 8276/10000, Loss: 0.009300685487687588\n",
      "Iteration: 8277/10000, Loss: 0.008249803446233273\n",
      "Iteration: 8278/10000, Loss: 0.0113246263936162\n",
      "Iteration: 8279/10000, Loss: 0.007848384790122509\n",
      "Iteration: 8280/10000, Loss: 0.010408801026642323\n",
      "Iteration: 8281/10000, Loss: 0.010503268800675869\n",
      "Iteration: 8282/10000, Loss: 0.011637009680271149\n",
      "Iteration: 8283/10000, Loss: 0.008900433778762817\n",
      "Iteration: 8284/10000, Loss: 0.010311988182365894\n",
      "Iteration: 8285/10000, Loss: 0.010642196983098984\n",
      "Iteration: 8286/10000, Loss: 0.009048878215253353\n",
      "Iteration: 8287/10000, Loss: 0.008911448530852795\n",
      "Iteration: 8288/10000, Loss: 0.0068176984786987305\n",
      "Iteration: 8289/10000, Loss: 0.006303870584815741\n",
      "Iteration: 8290/10000, Loss: 0.007432460319250822\n",
      "Iteration: 8291/10000, Loss: 0.011084027588367462\n",
      "Iteration: 8292/10000, Loss: 0.011482722125947475\n",
      "Iteration: 8293/10000, Loss: 0.008725783787667751\n",
      "Iteration: 8294/10000, Loss: 0.007228371221572161\n",
      "Iteration: 8295/10000, Loss: 0.011850829236209393\n",
      "Iteration: 8296/10000, Loss: 0.00543726421892643\n",
      "Iteration: 8297/10000, Loss: 0.00728587293997407\n",
      "Iteration: 8298/10000, Loss: 0.008175279945135117\n",
      "Iteration: 8299/10000, Loss: 0.012256898917257786\n",
      "Iteration: 8300/10000, Loss: 0.010834711603820324\n",
      "Average test loss:  0.0026\n",
      "Iteration: 8301/10000, Loss: 0.009480060078203678\n",
      "Iteration: 8302/10000, Loss: 0.010244953446090221\n",
      "Iteration: 8303/10000, Loss: 0.007027551997452974\n",
      "Iteration: 8304/10000, Loss: 0.008977948687970638\n",
      "Iteration: 8305/10000, Loss: 0.00947944913059473\n",
      "Iteration: 8306/10000, Loss: 0.006548689678311348\n",
      "Iteration: 8307/10000, Loss: 0.00714003574103117\n",
      "Iteration: 8308/10000, Loss: 0.006012493744492531\n",
      "Iteration: 8309/10000, Loss: 0.010230849497020245\n",
      "Iteration: 8310/10000, Loss: 0.01740849018096924\n",
      "Iteration: 8311/10000, Loss: 0.012771660462021828\n",
      "Iteration: 8312/10000, Loss: 0.00945698656141758\n",
      "Iteration: 8313/10000, Loss: 0.01224968209862709\n",
      "Iteration: 8314/10000, Loss: 0.012368741445243359\n",
      "Iteration: 8315/10000, Loss: 0.006222444586455822\n",
      "Iteration: 8316/10000, Loss: 0.008459801785647869\n",
      "Iteration: 8317/10000, Loss: 0.008471050299704075\n",
      "Iteration: 8318/10000, Loss: 0.010666687972843647\n",
      "Iteration: 8319/10000, Loss: 0.006998872850090265\n",
      "Iteration: 8320/10000, Loss: 0.013204134069383144\n",
      "Iteration: 8321/10000, Loss: 0.009653137065470219\n",
      "Iteration: 8322/10000, Loss: 0.01415626797825098\n",
      "Iteration: 8323/10000, Loss: 0.008219475857913494\n",
      "Iteration: 8324/10000, Loss: 0.009881074540317059\n",
      "Iteration: 8325/10000, Loss: 0.010193783789873123\n",
      "Iteration: 8326/10000, Loss: 0.005238399375230074\n",
      "Iteration: 8327/10000, Loss: 0.008757182396948338\n",
      "Iteration: 8328/10000, Loss: 0.011086161248385906\n",
      "Iteration: 8329/10000, Loss: 0.015189029276371002\n",
      "Iteration: 8330/10000, Loss: 0.007955103181302547\n",
      "Iteration: 8331/10000, Loss: 0.007422057446092367\n",
      "Iteration: 8332/10000, Loss: 0.00796031579375267\n",
      "Iteration: 8333/10000, Loss: 0.009747284464538097\n",
      "Iteration: 8334/10000, Loss: 0.005965045187622309\n",
      "Iteration: 8335/10000, Loss: 0.00994026567786932\n",
      "Iteration: 8336/10000, Loss: 0.006265395786613226\n",
      "Iteration: 8337/10000, Loss: 0.010337832383811474\n",
      "Iteration: 8338/10000, Loss: 0.01322647649794817\n",
      "Iteration: 8339/10000, Loss: 0.008793205954134464\n",
      "Iteration: 8340/10000, Loss: 0.01192187424749136\n",
      "Iteration: 8341/10000, Loss: 0.008961905725300312\n",
      "Iteration: 8342/10000, Loss: 0.008330678567290306\n",
      "Iteration: 8343/10000, Loss: 0.011321235448122025\n",
      "Iteration: 8344/10000, Loss: 0.006780036725103855\n",
      "Iteration: 8345/10000, Loss: 0.009451663121581078\n",
      "Iteration: 8346/10000, Loss: 0.00802523922175169\n",
      "Iteration: 8347/10000, Loss: 0.008452292531728745\n",
      "Iteration: 8348/10000, Loss: 0.008804083801805973\n",
      "Iteration: 8349/10000, Loss: 0.008459530770778656\n",
      "Iteration: 8350/10000, Loss: 0.00757079990580678\n",
      "Iteration: 8351/10000, Loss: 0.01176122110337019\n",
      "Iteration: 8352/10000, Loss: 0.00895718764513731\n",
      "Iteration: 8353/10000, Loss: 0.010839014314115047\n",
      "Iteration: 8354/10000, Loss: 0.007555145304650068\n",
      "Iteration: 8355/10000, Loss: 0.010577716864645481\n",
      "Iteration: 8356/10000, Loss: 0.006003574933856726\n",
      "Iteration: 8357/10000, Loss: 0.009663577191531658\n",
      "Iteration: 8358/10000, Loss: 0.011805598624050617\n",
      "Iteration: 8359/10000, Loss: 0.010524006560444832\n",
      "Iteration: 8360/10000, Loss: 0.01322389580309391\n",
      "Iteration: 8361/10000, Loss: 0.009600551798939705\n",
      "Iteration: 8362/10000, Loss: 0.00807633250951767\n",
      "Iteration: 8363/10000, Loss: 0.008678658865392208\n",
      "Iteration: 8364/10000, Loss: 0.008372832089662552\n",
      "Iteration: 8365/10000, Loss: 0.006738579366356134\n",
      "Iteration: 8366/10000, Loss: 0.007670633960515261\n",
      "Iteration: 8367/10000, Loss: 0.008878825232386589\n",
      "Iteration: 8368/10000, Loss: 0.0086485231295228\n",
      "Iteration: 8369/10000, Loss: 0.01145093608647585\n",
      "Iteration: 8370/10000, Loss: 0.00913733709603548\n",
      "Iteration: 8371/10000, Loss: 0.006311366334557533\n",
      "Iteration: 8372/10000, Loss: 0.008213215507566929\n",
      "Iteration: 8373/10000, Loss: 0.009239355102181435\n",
      "Iteration: 8374/10000, Loss: 0.009991646744310856\n",
      "Iteration: 8375/10000, Loss: 0.009990125894546509\n",
      "Iteration: 8376/10000, Loss: 0.004836255218833685\n",
      "Iteration: 8377/10000, Loss: 0.014059903100132942\n",
      "Iteration: 8378/10000, Loss: 0.009653981775045395\n",
      "Iteration: 8379/10000, Loss: 0.007257411722093821\n",
      "Iteration: 8380/10000, Loss: 0.011634772643446922\n",
      "Iteration: 8381/10000, Loss: 0.009076534770429134\n",
      "Iteration: 8382/10000, Loss: 0.00866467785090208\n",
      "Iteration: 8383/10000, Loss: 0.011422197334468365\n",
      "Iteration: 8384/10000, Loss: 0.009204458445310593\n",
      "Iteration: 8385/10000, Loss: 0.011337635107338428\n",
      "Iteration: 8386/10000, Loss: 0.008762284182012081\n",
      "Iteration: 8387/10000, Loss: 0.010710194706916809\n",
      "Iteration: 8388/10000, Loss: 0.011274135671555996\n",
      "Iteration: 8389/10000, Loss: 0.012802391313016415\n",
      "Iteration: 8390/10000, Loss: 0.007369663566350937\n",
      "Iteration: 8391/10000, Loss: 0.00849101971834898\n",
      "Iteration: 8392/10000, Loss: 0.009122208692133427\n",
      "Iteration: 8393/10000, Loss: 0.008179777301847935\n",
      "Iteration: 8394/10000, Loss: 0.011655651032924652\n",
      "Iteration: 8395/10000, Loss: 0.009975457563996315\n",
      "Iteration: 8396/10000, Loss: 0.0073655447922647\n",
      "Iteration: 8397/10000, Loss: 0.007327796425670385\n",
      "Iteration: 8398/10000, Loss: 0.010918870568275452\n",
      "Iteration: 8399/10000, Loss: 0.012477723881602287\n",
      "Iteration: 8400/10000, Loss: 0.010467649437487125\n",
      "Average test loss:  0.0028\n",
      "Iteration: 8401/10000, Loss: 0.009841152466833591\n",
      "Iteration: 8402/10000, Loss: 0.007526713889092207\n",
      "Iteration: 8403/10000, Loss: 0.008778584189713001\n",
      "Iteration: 8404/10000, Loss: 0.008654969744384289\n",
      "Iteration: 8405/10000, Loss: 0.010680962353944778\n",
      "Iteration: 8406/10000, Loss: 0.011400245130062103\n",
      "Iteration: 8407/10000, Loss: 0.0057573989033699036\n",
      "Iteration: 8408/10000, Loss: 0.007035409100353718\n",
      "Iteration: 8409/10000, Loss: 0.015537712723016739\n",
      "Iteration: 8410/10000, Loss: 0.005230866372585297\n",
      "Iteration: 8411/10000, Loss: 0.009724349714815617\n",
      "Iteration: 8412/10000, Loss: 0.008424037136137486\n",
      "Iteration: 8413/10000, Loss: 0.005670316983014345\n",
      "Iteration: 8414/10000, Loss: 0.005367504898458719\n",
      "Iteration: 8415/10000, Loss: 0.010925207287073135\n",
      "Iteration: 8416/10000, Loss: 0.011740286834537983\n",
      "Iteration: 8417/10000, Loss: 0.012189091183245182\n",
      "Iteration: 8418/10000, Loss: 0.011822253465652466\n",
      "Iteration: 8419/10000, Loss: 0.011272761039435863\n",
      "Iteration: 8420/10000, Loss: 0.01045274455100298\n",
      "Iteration: 8421/10000, Loss: 0.010077036917209625\n",
      "Iteration: 8422/10000, Loss: 0.009247619658708572\n",
      "Iteration: 8423/10000, Loss: 0.0066572981886565685\n",
      "Iteration: 8424/10000, Loss: 0.007304500788450241\n",
      "Iteration: 8425/10000, Loss: 0.011183383874595165\n",
      "Iteration: 8426/10000, Loss: 0.007177185267210007\n",
      "Iteration: 8427/10000, Loss: 0.011489059776067734\n",
      "Iteration: 8428/10000, Loss: 0.008283506147563457\n",
      "Iteration: 8429/10000, Loss: 0.009910444729030132\n",
      "Iteration: 8430/10000, Loss: 0.01014767587184906\n",
      "Iteration: 8431/10000, Loss: 0.00475643016397953\n",
      "Iteration: 8432/10000, Loss: 0.01089428085833788\n",
      "Iteration: 8433/10000, Loss: 0.007784287445247173\n",
      "Iteration: 8434/10000, Loss: 0.008161257952451706\n",
      "Iteration: 8435/10000, Loss: 0.010583342052996159\n",
      "Iteration: 8436/10000, Loss: 0.007415520492941141\n",
      "Iteration: 8437/10000, Loss: 0.010711261071264744\n",
      "Iteration: 8438/10000, Loss: 0.007327609229832888\n",
      "Iteration: 8439/10000, Loss: 0.006827330682426691\n",
      "Iteration: 8440/10000, Loss: 0.006415302865207195\n",
      "Iteration: 8441/10000, Loss: 0.011252397671341896\n",
      "Iteration: 8442/10000, Loss: 0.009992051869630814\n",
      "Iteration: 8443/10000, Loss: 0.010362502187490463\n",
      "Iteration: 8444/10000, Loss: 0.010169323533773422\n",
      "Iteration: 8445/10000, Loss: 0.010944022797048092\n",
      "Iteration: 8446/10000, Loss: 0.005783174652606249\n",
      "Iteration: 8447/10000, Loss: 0.00601604301482439\n",
      "Iteration: 8448/10000, Loss: 0.00458911107853055\n",
      "Iteration: 8449/10000, Loss: 0.004027492366731167\n",
      "Iteration: 8450/10000, Loss: 0.00946258008480072\n",
      "Iteration: 8451/10000, Loss: 0.008208009414374828\n",
      "Iteration: 8452/10000, Loss: 0.00914188101887703\n",
      "Iteration: 8453/10000, Loss: 0.009532792493700981\n",
      "Iteration: 8454/10000, Loss: 0.0075135729275643826\n",
      "Iteration: 8455/10000, Loss: 0.007212852593511343\n",
      "Iteration: 8456/10000, Loss: 0.008388623595237732\n",
      "Iteration: 8457/10000, Loss: 0.011742104776203632\n",
      "Iteration: 8458/10000, Loss: 0.011342152953147888\n",
      "Iteration: 8459/10000, Loss: 0.009632982313632965\n",
      "Iteration: 8460/10000, Loss: 0.013366231694817543\n",
      "Iteration: 8461/10000, Loss: 0.008580276742577553\n",
      "Iteration: 8462/10000, Loss: 0.009652606211602688\n",
      "Iteration: 8463/10000, Loss: 0.007712787017226219\n",
      "Iteration: 8464/10000, Loss: 0.012669479474425316\n",
      "Iteration: 8465/10000, Loss: 0.013479147106409073\n",
      "Iteration: 8466/10000, Loss: 0.008817839436233044\n",
      "Iteration: 8467/10000, Loss: 0.007755364291369915\n",
      "Iteration: 8468/10000, Loss: 0.010625398717820644\n",
      "Iteration: 8469/10000, Loss: 0.009004228748381138\n",
      "Iteration: 8470/10000, Loss: 0.00782922562211752\n",
      "Iteration: 8471/10000, Loss: 0.007802746258676052\n",
      "Iteration: 8472/10000, Loss: 0.007158251944929361\n",
      "Iteration: 8473/10000, Loss: 0.012112542055547237\n",
      "Iteration: 8474/10000, Loss: 0.007306169252842665\n",
      "Iteration: 8475/10000, Loss: 0.011953741312026978\n",
      "Iteration: 8476/10000, Loss: 0.007067530881613493\n",
      "Iteration: 8477/10000, Loss: 0.009680837392807007\n",
      "Iteration: 8478/10000, Loss: 0.009280182421207428\n",
      "Iteration: 8479/10000, Loss: 0.009220891632139683\n",
      "Iteration: 8480/10000, Loss: 0.006794613320380449\n",
      "Iteration: 8481/10000, Loss: 0.011371556669473648\n",
      "Iteration: 8482/10000, Loss: 0.006303119007498026\n",
      "Iteration: 8483/10000, Loss: 0.007542682345956564\n",
      "Iteration: 8484/10000, Loss: 0.008661128580570221\n",
      "Iteration: 8485/10000, Loss: 0.006933853030204773\n",
      "Iteration: 8486/10000, Loss: 0.009603948332369328\n",
      "Iteration: 8487/10000, Loss: 0.006540352012962103\n",
      "Iteration: 8488/10000, Loss: 0.010871713049709797\n",
      "Iteration: 8489/10000, Loss: 0.008569213561713696\n",
      "Iteration: 8490/10000, Loss: 0.009567667730152607\n",
      "Iteration: 8491/10000, Loss: 0.010813127271831036\n",
      "Iteration: 8492/10000, Loss: 0.009653707034885883\n",
      "Iteration: 8493/10000, Loss: 0.009672896936535835\n",
      "Iteration: 8494/10000, Loss: 0.0074513573199510574\n",
      "Iteration: 8495/10000, Loss: 0.006322653032839298\n",
      "Iteration: 8496/10000, Loss: 0.007901190780103207\n",
      "Iteration: 8497/10000, Loss: 0.006616019643843174\n",
      "Iteration: 8498/10000, Loss: 0.009489097632467747\n",
      "Iteration: 8499/10000, Loss: 0.011062977835536003\n",
      "Iteration: 8500/10000, Loss: 0.011445091105997562\n",
      "Average test loss:  0.0032\n",
      "Iteration: 8501/10000, Loss: 0.012279495596885681\n",
      "Iteration: 8502/10000, Loss: 0.007826260291039944\n",
      "Iteration: 8503/10000, Loss: 0.01421281322836876\n",
      "Iteration: 8504/10000, Loss: 0.006660761311650276\n",
      "Iteration: 8505/10000, Loss: 0.00849029142409563\n",
      "Iteration: 8506/10000, Loss: 0.008825773373246193\n",
      "Iteration: 8507/10000, Loss: 0.011087315157055855\n",
      "Iteration: 8508/10000, Loss: 0.0052954163402318954\n",
      "Iteration: 8509/10000, Loss: 0.006419721059501171\n",
      "Iteration: 8510/10000, Loss: 0.011238684877753258\n",
      "Iteration: 8511/10000, Loss: 0.007130513899028301\n",
      "Iteration: 8512/10000, Loss: 0.0077806031331419945\n",
      "Iteration: 8513/10000, Loss: 0.009841503575444221\n",
      "Iteration: 8514/10000, Loss: 0.009152846410870552\n",
      "Iteration: 8515/10000, Loss: 0.007487497292459011\n",
      "Iteration: 8516/10000, Loss: 0.009639464318752289\n",
      "Iteration: 8517/10000, Loss: 0.010706703178584576\n",
      "Iteration: 8518/10000, Loss: 0.01537252962589264\n",
      "Iteration: 8519/10000, Loss: 0.011523522436618805\n",
      "Iteration: 8520/10000, Loss: 0.010603140108287334\n",
      "Iteration: 8521/10000, Loss: 0.012179097160696983\n",
      "Iteration: 8522/10000, Loss: 0.007434449624270201\n",
      "Iteration: 8523/10000, Loss: 0.010409875772893429\n",
      "Iteration: 8524/10000, Loss: 0.008644051849842072\n",
      "Iteration: 8525/10000, Loss: 0.009470614604651928\n",
      "Iteration: 8526/10000, Loss: 0.007624364458024502\n",
      "Iteration: 8527/10000, Loss: 0.009638507850468159\n",
      "Iteration: 8528/10000, Loss: 0.009210708551108837\n",
      "Iteration: 8529/10000, Loss: 0.005113651510328054\n",
      "Iteration: 8530/10000, Loss: 0.010355185717344284\n",
      "Iteration: 8531/10000, Loss: 0.0058971671387553215\n",
      "Iteration: 8532/10000, Loss: 0.009448057040572166\n",
      "Iteration: 8533/10000, Loss: 0.008218953385949135\n",
      "Iteration: 8534/10000, Loss: 0.005831583868712187\n",
      "Iteration: 8535/10000, Loss: 0.009943709708750248\n",
      "Iteration: 8536/10000, Loss: 0.011685902252793312\n",
      "Iteration: 8537/10000, Loss: 0.00853031501173973\n",
      "Iteration: 8538/10000, Loss: 0.0051325843669474125\n",
      "Iteration: 8539/10000, Loss: 0.008321305736899376\n",
      "Iteration: 8540/10000, Loss: 0.009993227198719978\n",
      "Iteration: 8541/10000, Loss: 0.008220146410167217\n",
      "Iteration: 8542/10000, Loss: 0.00608988618478179\n",
      "Iteration: 8543/10000, Loss: 0.007135837804526091\n",
      "Iteration: 8544/10000, Loss: 0.010966213420033455\n",
      "Iteration: 8545/10000, Loss: 0.011821706779301167\n",
      "Iteration: 8546/10000, Loss: 0.01203703973442316\n",
      "Iteration: 8547/10000, Loss: 0.008721214719116688\n",
      "Iteration: 8548/10000, Loss: 0.0041871024295687675\n",
      "Iteration: 8549/10000, Loss: 0.0064444695599377155\n",
      "Iteration: 8550/10000, Loss: 0.0103466110303998\n",
      "Iteration: 8551/10000, Loss: 0.011623408645391464\n",
      "Iteration: 8552/10000, Loss: 0.008719728328287601\n",
      "Iteration: 8553/10000, Loss: 0.006282235961407423\n",
      "Iteration: 8554/10000, Loss: 0.006943205371499062\n",
      "Iteration: 8555/10000, Loss: 0.008599505759775639\n",
      "Iteration: 8556/10000, Loss: 0.006980761419981718\n",
      "Iteration: 8557/10000, Loss: 0.01138368621468544\n",
      "Iteration: 8558/10000, Loss: 0.007806321606040001\n",
      "Iteration: 8559/10000, Loss: 0.010426154360175133\n",
      "Iteration: 8560/10000, Loss: 0.007275912910699844\n",
      "Iteration: 8561/10000, Loss: 0.006815209984779358\n",
      "Iteration: 8562/10000, Loss: 0.008123350329697132\n",
      "Iteration: 8563/10000, Loss: 0.011456375941634178\n",
      "Iteration: 8564/10000, Loss: 0.010606695897877216\n",
      "Iteration: 8565/10000, Loss: 0.007617768831551075\n",
      "Iteration: 8566/10000, Loss: 0.00784566905349493\n",
      "Iteration: 8567/10000, Loss: 0.007740841247141361\n",
      "Iteration: 8568/10000, Loss: 0.010285756550729275\n",
      "Iteration: 8569/10000, Loss: 0.006159573793411255\n",
      "Iteration: 8570/10000, Loss: 0.0053382269106805325\n",
      "Iteration: 8571/10000, Loss: 0.013370543718338013\n",
      "Iteration: 8572/10000, Loss: 0.008279448375105858\n",
      "Iteration: 8573/10000, Loss: 0.01236514188349247\n",
      "Iteration: 8574/10000, Loss: 0.007318677380681038\n",
      "Iteration: 8575/10000, Loss: 0.007570261601358652\n",
      "Iteration: 8576/10000, Loss: 0.005796520970761776\n",
      "Iteration: 8577/10000, Loss: 0.008478210307657719\n",
      "Iteration: 8578/10000, Loss: 0.007018352393060923\n",
      "Iteration: 8579/10000, Loss: 0.009905206970870495\n",
      "Iteration: 8580/10000, Loss: 0.006356087978929281\n",
      "Iteration: 8581/10000, Loss: 0.003992381040006876\n",
      "Iteration: 8582/10000, Loss: 0.010308770462870598\n",
      "Iteration: 8583/10000, Loss: 0.0062781572341918945\n",
      "Iteration: 8584/10000, Loss: 0.007955506443977356\n",
      "Iteration: 8585/10000, Loss: 0.00957331620156765\n",
      "Iteration: 8586/10000, Loss: 0.008918164297938347\n",
      "Iteration: 8587/10000, Loss: 0.010050948709249496\n",
      "Iteration: 8588/10000, Loss: 0.008765527047216892\n",
      "Iteration: 8589/10000, Loss: 0.009599852375686169\n",
      "Iteration: 8590/10000, Loss: 0.010254638269543648\n",
      "Iteration: 8591/10000, Loss: 0.008560964837670326\n",
      "Iteration: 8592/10000, Loss: 0.008157482370734215\n",
      "Iteration: 8593/10000, Loss: 0.009787851013243198\n",
      "Iteration: 8594/10000, Loss: 0.006672779098153114\n",
      "Iteration: 8595/10000, Loss: 0.007008282467722893\n",
      "Iteration: 8596/10000, Loss: 0.009318096563220024\n",
      "Iteration: 8597/10000, Loss: 0.004661303013563156\n",
      "Iteration: 8598/10000, Loss: 0.011737748980522156\n",
      "Iteration: 8599/10000, Loss: 0.013920407742261887\n",
      "Iteration: 8600/10000, Loss: 0.010929567739367485\n",
      "Average test loss:  0.0030\n",
      "Iteration: 8601/10000, Loss: 0.00844621006399393\n",
      "Iteration: 8602/10000, Loss: 0.009551964700222015\n",
      "Iteration: 8603/10000, Loss: 0.01565355807542801\n",
      "Iteration: 8604/10000, Loss: 0.01087624579668045\n",
      "Iteration: 8605/10000, Loss: 0.009526057168841362\n",
      "Iteration: 8606/10000, Loss: 0.012768901884555817\n",
      "Iteration: 8607/10000, Loss: 0.008378083817660809\n",
      "Iteration: 8608/10000, Loss: 0.009498689323663712\n",
      "Iteration: 8609/10000, Loss: 0.008039946667850018\n",
      "Iteration: 8610/10000, Loss: 0.014247879385948181\n",
      "Iteration: 8611/10000, Loss: 0.009263289161026478\n",
      "Iteration: 8612/10000, Loss: 0.007896705530583858\n",
      "Iteration: 8613/10000, Loss: 0.009675327688455582\n",
      "Iteration: 8614/10000, Loss: 0.011611448600888252\n",
      "Iteration: 8615/10000, Loss: 0.015995096415281296\n",
      "Iteration: 8616/10000, Loss: 0.00989475753158331\n",
      "Iteration: 8617/10000, Loss: 0.007092438638210297\n",
      "Iteration: 8618/10000, Loss: 0.007403053808957338\n",
      "Iteration: 8619/10000, Loss: 0.00812307745218277\n",
      "Iteration: 8620/10000, Loss: 0.007932641543447971\n",
      "Iteration: 8621/10000, Loss: 0.011361668817698956\n",
      "Iteration: 8622/10000, Loss: 0.00765874283388257\n",
      "Iteration: 8623/10000, Loss: 0.00765827065333724\n",
      "Iteration: 8624/10000, Loss: 0.007842079736292362\n",
      "Iteration: 8625/10000, Loss: 0.01344656478613615\n",
      "Iteration: 8626/10000, Loss: 0.007498701103031635\n",
      "Iteration: 8627/10000, Loss: 0.008449114859104156\n",
      "Iteration: 8628/10000, Loss: 0.00472874753177166\n",
      "Iteration: 8629/10000, Loss: 0.006728023290634155\n",
      "Iteration: 8630/10000, Loss: 0.008135523647069931\n",
      "Iteration: 8631/10000, Loss: 0.008427713997662067\n",
      "Iteration: 8632/10000, Loss: 0.006919896230101585\n",
      "Iteration: 8633/10000, Loss: 0.007537738420069218\n",
      "Iteration: 8634/10000, Loss: 0.009297099895775318\n",
      "Iteration: 8635/10000, Loss: 0.005158929619938135\n",
      "Iteration: 8636/10000, Loss: 0.008564738556742668\n",
      "Iteration: 8637/10000, Loss: 0.009285643696784973\n",
      "Iteration: 8638/10000, Loss: 0.009443900547921658\n",
      "Iteration: 8639/10000, Loss: 0.007961621508002281\n",
      "Iteration: 8640/10000, Loss: 0.005745946429669857\n",
      "Iteration: 8641/10000, Loss: 0.007012892980128527\n",
      "Iteration: 8642/10000, Loss: 0.0076788426376879215\n",
      "Iteration: 8643/10000, Loss: 0.006503172218799591\n",
      "Iteration: 8644/10000, Loss: 0.005419625900685787\n",
      "Iteration: 8645/10000, Loss: 0.007910259999334812\n",
      "Iteration: 8646/10000, Loss: 0.008170782588422298\n",
      "Iteration: 8647/10000, Loss: 0.00741166528314352\n",
      "Iteration: 8648/10000, Loss: 0.014903973788022995\n",
      "Iteration: 8649/10000, Loss: 0.010309673845767975\n",
      "Iteration: 8650/10000, Loss: 0.0066462671384215355\n",
      "Iteration: 8651/10000, Loss: 0.009576876647770405\n",
      "Iteration: 8652/10000, Loss: 0.006448020227253437\n",
      "Iteration: 8653/10000, Loss: 0.010737603530287743\n",
      "Iteration: 8654/10000, Loss: 0.007723924703896046\n",
      "Iteration: 8655/10000, Loss: 0.00815095379948616\n",
      "Iteration: 8656/10000, Loss: 0.00824446976184845\n",
      "Iteration: 8657/10000, Loss: 0.006547282915562391\n",
      "Iteration: 8658/10000, Loss: 0.00822475366294384\n",
      "Iteration: 8659/10000, Loss: 0.008959326893091202\n",
      "Iteration: 8660/10000, Loss: 0.006493736989796162\n",
      "Iteration: 8661/10000, Loss: 0.01128789409995079\n",
      "Iteration: 8662/10000, Loss: 0.006861486006528139\n",
      "Iteration: 8663/10000, Loss: 0.0110598374158144\n",
      "Iteration: 8664/10000, Loss: 0.005147462245076895\n",
      "Iteration: 8665/10000, Loss: 0.009515156038105488\n",
      "Iteration: 8666/10000, Loss: 0.0065705254673957825\n",
      "Iteration: 8667/10000, Loss: 0.007539267186075449\n",
      "Iteration: 8668/10000, Loss: 0.010658493265509605\n",
      "Iteration: 8669/10000, Loss: 0.01031429972499609\n",
      "Iteration: 8670/10000, Loss: 0.012192687019705772\n",
      "Iteration: 8671/10000, Loss: 0.007471705321222544\n",
      "Iteration: 8672/10000, Loss: 0.007851557806134224\n",
      "Iteration: 8673/10000, Loss: 0.007674585562199354\n",
      "Iteration: 8674/10000, Loss: 0.010805729776620865\n",
      "Iteration: 8675/10000, Loss: 0.01285826601088047\n",
      "Iteration: 8676/10000, Loss: 0.006303646136075258\n",
      "Iteration: 8677/10000, Loss: 0.0063647120259702206\n",
      "Iteration: 8678/10000, Loss: 0.010318612679839134\n",
      "Iteration: 8679/10000, Loss: 0.005186094902455807\n",
      "Iteration: 8680/10000, Loss: 0.0062920525670051575\n",
      "Iteration: 8681/10000, Loss: 0.009594147093594074\n",
      "Iteration: 8682/10000, Loss: 0.006535481661558151\n",
      "Iteration: 8683/10000, Loss: 0.009416040033102036\n",
      "Iteration: 8684/10000, Loss: 0.009062874130904675\n",
      "Iteration: 8685/10000, Loss: 0.011494392529129982\n",
      "Iteration: 8686/10000, Loss: 0.007122987415641546\n",
      "Iteration: 8687/10000, Loss: 0.009124410338699818\n",
      "Iteration: 8688/10000, Loss: 0.007650080602616072\n",
      "Iteration: 8689/10000, Loss: 0.008805452845990658\n",
      "Iteration: 8690/10000, Loss: 0.006934504956007004\n",
      "Iteration: 8691/10000, Loss: 0.005234329029917717\n",
      "Iteration: 8692/10000, Loss: 0.008126558735966682\n",
      "Iteration: 8693/10000, Loss: 0.009129672311246395\n",
      "Iteration: 8694/10000, Loss: 0.009134129621088505\n",
      "Iteration: 8695/10000, Loss: 0.006539531983435154\n",
      "Iteration: 8696/10000, Loss: 0.008794203400611877\n",
      "Iteration: 8697/10000, Loss: 0.01102270558476448\n",
      "Iteration: 8698/10000, Loss: 0.008466433733701706\n",
      "Iteration: 8699/10000, Loss: 0.010225670412182808\n",
      "Iteration: 8700/10000, Loss: 0.01161620207130909\n",
      "Average test loss:  0.0017\n",
      "Iteration: 8701/10000, Loss: 0.007182095665484667\n",
      "Iteration: 8702/10000, Loss: 0.008716490119695663\n",
      "Iteration: 8703/10000, Loss: 0.006445883773267269\n",
      "Iteration: 8704/10000, Loss: 0.011822840198874474\n",
      "Iteration: 8705/10000, Loss: 0.010155684314668179\n",
      "Iteration: 8706/10000, Loss: 0.009773514233529568\n",
      "Iteration: 8707/10000, Loss: 0.011214840225875378\n",
      "Iteration: 8708/10000, Loss: 0.010578637011349201\n",
      "Iteration: 8709/10000, Loss: 0.00923150684684515\n",
      "Iteration: 8710/10000, Loss: 0.012035521678626537\n",
      "Iteration: 8711/10000, Loss: 0.007487789262086153\n",
      "Iteration: 8712/10000, Loss: 0.011015847325325012\n",
      "Iteration: 8713/10000, Loss: 0.007010624743998051\n",
      "Iteration: 8714/10000, Loss: 0.011380643583834171\n",
      "Iteration: 8715/10000, Loss: 0.008778125047683716\n",
      "Iteration: 8716/10000, Loss: 0.005111359525471926\n",
      "Iteration: 8717/10000, Loss: 0.005925604607909918\n",
      "Iteration: 8718/10000, Loss: 0.009860639460384846\n",
      "Iteration: 8719/10000, Loss: 0.015609846450388432\n",
      "Iteration: 8720/10000, Loss: 0.00782130379229784\n",
      "Iteration: 8721/10000, Loss: 0.006731102243065834\n",
      "Iteration: 8722/10000, Loss: 0.010400231927633286\n",
      "Iteration: 8723/10000, Loss: 0.006968994624912739\n",
      "Iteration: 8724/10000, Loss: 0.00574352964758873\n",
      "Iteration: 8725/10000, Loss: 0.009098101407289505\n",
      "Iteration: 8726/10000, Loss: 0.004392317030578852\n",
      "Iteration: 8727/10000, Loss: 0.012690014205873013\n",
      "Iteration: 8728/10000, Loss: 0.012685158289968967\n",
      "Iteration: 8729/10000, Loss: 0.00814723875373602\n",
      "Iteration: 8730/10000, Loss: 0.010462390258908272\n",
      "Iteration: 8731/10000, Loss: 0.009956941939890385\n",
      "Iteration: 8732/10000, Loss: 0.007322706747800112\n",
      "Iteration: 8733/10000, Loss: 0.004159607458859682\n",
      "Iteration: 8734/10000, Loss: 0.006758835166692734\n",
      "Iteration: 8735/10000, Loss: 0.0057359980419278145\n",
      "Iteration: 8736/10000, Loss: 0.006933518685400486\n",
      "Iteration: 8737/10000, Loss: 0.0075094131752848625\n",
      "Iteration: 8738/10000, Loss: 0.006325442343950272\n",
      "Iteration: 8739/10000, Loss: 0.007004389073699713\n",
      "Iteration: 8740/10000, Loss: 0.009130887687206268\n",
      "Iteration: 8741/10000, Loss: 0.010826715268194675\n",
      "Iteration: 8742/10000, Loss: 0.009808565489947796\n",
      "Iteration: 8743/10000, Loss: 0.008962088264524937\n",
      "Iteration: 8744/10000, Loss: 0.009314912371337414\n",
      "Iteration: 8745/10000, Loss: 0.009115870110690594\n",
      "Iteration: 8746/10000, Loss: 0.007477808743715286\n",
      "Iteration: 8747/10000, Loss: 0.008726580068469048\n",
      "Iteration: 8748/10000, Loss: 0.008749041706323624\n",
      "Iteration: 8749/10000, Loss: 0.012048384174704552\n",
      "Iteration: 8750/10000, Loss: 0.00946045946329832\n",
      "Iteration: 8751/10000, Loss: 0.01085631176829338\n",
      "Iteration: 8752/10000, Loss: 0.004185685887932777\n",
      "Iteration: 8753/10000, Loss: 0.0057531786151230335\n",
      "Iteration: 8754/10000, Loss: 0.00745077570900321\n",
      "Iteration: 8755/10000, Loss: 0.010753229260444641\n",
      "Iteration: 8756/10000, Loss: 0.009383263997733593\n",
      "Iteration: 8757/10000, Loss: 0.009370526298880577\n",
      "Iteration: 8758/10000, Loss: 0.009859347715973854\n",
      "Iteration: 8759/10000, Loss: 0.007689363323152065\n",
      "Iteration: 8760/10000, Loss: 0.009066963568329811\n",
      "Iteration: 8761/10000, Loss: 0.009465138427913189\n",
      "Iteration: 8762/10000, Loss: 0.012591206468641758\n",
      "Iteration: 8763/10000, Loss: 0.009667696431279182\n",
      "Iteration: 8764/10000, Loss: 0.0090703833848238\n",
      "Iteration: 8765/10000, Loss: 0.010583979077637196\n",
      "Iteration: 8766/10000, Loss: 0.008215896785259247\n",
      "Iteration: 8767/10000, Loss: 0.006431476213037968\n",
      "Iteration: 8768/10000, Loss: 0.010766151361167431\n",
      "Iteration: 8769/10000, Loss: 0.007890814915299416\n",
      "Iteration: 8770/10000, Loss: 0.006448936648666859\n",
      "Iteration: 8771/10000, Loss: 0.0077695343643426895\n",
      "Iteration: 8772/10000, Loss: 0.013790528289973736\n",
      "Iteration: 8773/10000, Loss: 0.009782090783119202\n",
      "Iteration: 8774/10000, Loss: 0.01095682755112648\n",
      "Iteration: 8775/10000, Loss: 0.014279698021709919\n",
      "Iteration: 8776/10000, Loss: 0.010483556427061558\n",
      "Iteration: 8777/10000, Loss: 0.009076572023332119\n",
      "Iteration: 8778/10000, Loss: 0.0074788471683859825\n",
      "Iteration: 8779/10000, Loss: 0.010619125328958035\n",
      "Iteration: 8780/10000, Loss: 0.010726414620876312\n",
      "Iteration: 8781/10000, Loss: 0.0071394676342606544\n",
      "Iteration: 8782/10000, Loss: 0.009996415115892887\n",
      "Iteration: 8783/10000, Loss: 0.005030021537095308\n",
      "Iteration: 8784/10000, Loss: 0.007822830229997635\n",
      "Iteration: 8785/10000, Loss: 0.007010466419160366\n",
      "Iteration: 8786/10000, Loss: 0.01144353672862053\n",
      "Iteration: 8787/10000, Loss: 0.010126905515789986\n",
      "Iteration: 8788/10000, Loss: 0.007674790918827057\n",
      "Iteration: 8789/10000, Loss: 0.006384067703038454\n",
      "Iteration: 8790/10000, Loss: 0.01156534068286419\n",
      "Iteration: 8791/10000, Loss: 0.010109918192029\n",
      "Iteration: 8792/10000, Loss: 0.009592494927346706\n",
      "Iteration: 8793/10000, Loss: 0.009114321321249008\n",
      "Iteration: 8794/10000, Loss: 0.009502436965703964\n",
      "Iteration: 8795/10000, Loss: 0.00535155413672328\n",
      "Iteration: 8796/10000, Loss: 0.010732436552643776\n",
      "Iteration: 8797/10000, Loss: 0.00992676056921482\n",
      "Iteration: 8798/10000, Loss: 0.008395585231482983\n",
      "Iteration: 8799/10000, Loss: 0.008927932009100914\n",
      "Iteration: 8800/10000, Loss: 0.00512928981333971\n",
      "Average test loss:  0.0032\n",
      "Iteration: 8801/10000, Loss: 0.005778863560408354\n",
      "Iteration: 8802/10000, Loss: 0.006720897741615772\n",
      "Iteration: 8803/10000, Loss: 0.007922296412289143\n",
      "Iteration: 8804/10000, Loss: 0.01107741892337799\n",
      "Iteration: 8805/10000, Loss: 0.007648092694580555\n",
      "Iteration: 8806/10000, Loss: 0.006956161931157112\n",
      "Iteration: 8807/10000, Loss: 0.009738163091242313\n",
      "Iteration: 8808/10000, Loss: 0.010201677680015564\n",
      "Iteration: 8809/10000, Loss: 0.00707977544516325\n",
      "Iteration: 8810/10000, Loss: 0.008815898559987545\n",
      "Iteration: 8811/10000, Loss: 0.007221668027341366\n",
      "Iteration: 8812/10000, Loss: 0.005544796586036682\n",
      "Iteration: 8813/10000, Loss: 0.010151412338018417\n",
      "Iteration: 8814/10000, Loss: 0.007614556234329939\n",
      "Iteration: 8815/10000, Loss: 0.010558882728219032\n",
      "Iteration: 8816/10000, Loss: 0.005353903863579035\n",
      "Iteration: 8817/10000, Loss: 0.010377119295299053\n",
      "Iteration: 8818/10000, Loss: 0.01145453006029129\n",
      "Iteration: 8819/10000, Loss: 0.007285464555025101\n",
      "Iteration: 8820/10000, Loss: 0.008406849578022957\n",
      "Iteration: 8821/10000, Loss: 0.009811032563447952\n",
      "Iteration: 8822/10000, Loss: 0.004943035542964935\n",
      "Iteration: 8823/10000, Loss: 0.007438333239406347\n",
      "Iteration: 8824/10000, Loss: 0.0105248112231493\n",
      "Iteration: 8825/10000, Loss: 0.006655637640506029\n",
      "Iteration: 8826/10000, Loss: 0.006987444125115871\n",
      "Iteration: 8827/10000, Loss: 0.012877939268946648\n",
      "Iteration: 8828/10000, Loss: 0.015455740503966808\n",
      "Iteration: 8829/10000, Loss: 0.011805232614278793\n",
      "Iteration: 8830/10000, Loss: 0.008489259518682957\n",
      "Iteration: 8831/10000, Loss: 0.005860823672264814\n",
      "Iteration: 8832/10000, Loss: 0.00930584967136383\n",
      "Iteration: 8833/10000, Loss: 0.011408030986785889\n",
      "Iteration: 8834/10000, Loss: 0.009112343192100525\n",
      "Iteration: 8835/10000, Loss: 0.010461847297847271\n",
      "Iteration: 8836/10000, Loss: 0.007362225092947483\n",
      "Iteration: 8837/10000, Loss: 0.006715727038681507\n",
      "Iteration: 8838/10000, Loss: 0.006768885534256697\n",
      "Iteration: 8839/10000, Loss: 0.00836927443742752\n",
      "Iteration: 8840/10000, Loss: 0.010109158232808113\n",
      "Iteration: 8841/10000, Loss: 0.009907839819788933\n",
      "Iteration: 8842/10000, Loss: 0.007845218293368816\n",
      "Iteration: 8843/10000, Loss: 0.009080534800887108\n",
      "Iteration: 8844/10000, Loss: 0.007534449454396963\n",
      "Iteration: 8845/10000, Loss: 0.010284078307449818\n",
      "Iteration: 8846/10000, Loss: 0.007644742727279663\n",
      "Iteration: 8847/10000, Loss: 0.0068503436632454395\n",
      "Iteration: 8848/10000, Loss: 0.008182118646800518\n",
      "Iteration: 8849/10000, Loss: 0.005839919205754995\n",
      "Iteration: 8850/10000, Loss: 0.009636289440095425\n",
      "Iteration: 8851/10000, Loss: 0.010078231804072857\n",
      "Iteration: 8852/10000, Loss: 0.009073108434677124\n",
      "Iteration: 8853/10000, Loss: 0.007524564396589994\n",
      "Iteration: 8854/10000, Loss: 0.007327984552830458\n",
      "Iteration: 8855/10000, Loss: 0.011566564440727234\n",
      "Iteration: 8856/10000, Loss: 0.005211027804762125\n",
      "Iteration: 8857/10000, Loss: 0.009478800930082798\n",
      "Iteration: 8858/10000, Loss: 0.009004607796669006\n",
      "Iteration: 8859/10000, Loss: 0.007935412228107452\n",
      "Iteration: 8860/10000, Loss: 0.008504931814968586\n",
      "Iteration: 8861/10000, Loss: 0.013517124578356743\n",
      "Iteration: 8862/10000, Loss: 0.009084111079573631\n",
      "Iteration: 8863/10000, Loss: 0.009028987027704716\n",
      "Iteration: 8864/10000, Loss: 0.007158314809203148\n",
      "Iteration: 8865/10000, Loss: 0.00980420783162117\n",
      "Iteration: 8866/10000, Loss: 0.008124815300107002\n",
      "Iteration: 8867/10000, Loss: 0.015429642051458359\n",
      "Iteration: 8868/10000, Loss: 0.00563540356233716\n",
      "Iteration: 8869/10000, Loss: 0.006233180407434702\n",
      "Iteration: 8870/10000, Loss: 0.010060418397188187\n",
      "Iteration: 8871/10000, Loss: 0.008148782886564732\n",
      "Iteration: 8872/10000, Loss: 0.008428863249719143\n",
      "Iteration: 8873/10000, Loss: 0.007718448527157307\n",
      "Iteration: 8874/10000, Loss: 0.009217748418450356\n",
      "Iteration: 8875/10000, Loss: 0.007526602130383253\n",
      "Iteration: 8876/10000, Loss: 0.008169957436621189\n",
      "Iteration: 8877/10000, Loss: 0.008383291773498058\n",
      "Iteration: 8878/10000, Loss: 0.008717583492398262\n",
      "Iteration: 8879/10000, Loss: 0.009066243655979633\n",
      "Iteration: 8880/10000, Loss: 0.011267948895692825\n",
      "Iteration: 8881/10000, Loss: 0.006873817648738623\n",
      "Iteration: 8882/10000, Loss: 0.010784987360239029\n",
      "Iteration: 8883/10000, Loss: 0.006792002357542515\n",
      "Iteration: 8884/10000, Loss: 0.011346869170665741\n",
      "Iteration: 8885/10000, Loss: 0.009093094617128372\n",
      "Iteration: 8886/10000, Loss: 0.0054771373979747295\n",
      "Iteration: 8887/10000, Loss: 0.009124665521085262\n",
      "Iteration: 8888/10000, Loss: 0.004662173800170422\n",
      "Iteration: 8889/10000, Loss: 0.009893432259559631\n",
      "Iteration: 8890/10000, Loss: 0.007905662059783936\n",
      "Iteration: 8891/10000, Loss: 0.00791673269122839\n",
      "Iteration: 8892/10000, Loss: 0.012873056344687939\n",
      "Iteration: 8893/10000, Loss: 0.008011034689843655\n",
      "Iteration: 8894/10000, Loss: 0.007045476697385311\n",
      "Iteration: 8895/10000, Loss: 0.007055498659610748\n",
      "Iteration: 8896/10000, Loss: 0.006510095205157995\n",
      "Iteration: 8897/10000, Loss: 0.009041199460625648\n",
      "Iteration: 8898/10000, Loss: 0.007902671582996845\n",
      "Iteration: 8899/10000, Loss: 0.008398585021495819\n",
      "Iteration: 8900/10000, Loss: 0.008129858411848545\n",
      "Average test loss:  0.0034\n",
      "Iteration: 8901/10000, Loss: 0.00880200881510973\n",
      "Iteration: 8902/10000, Loss: 0.008088510483503342\n",
      "Iteration: 8903/10000, Loss: 0.00732079241424799\n",
      "Iteration: 8904/10000, Loss: 0.007229819893836975\n",
      "Iteration: 8905/10000, Loss: 0.008129036985337734\n",
      "Iteration: 8906/10000, Loss: 0.00815653894096613\n",
      "Iteration: 8907/10000, Loss: 0.009867980144917965\n",
      "Iteration: 8908/10000, Loss: 0.009579765610396862\n",
      "Iteration: 8909/10000, Loss: 0.009252917021512985\n",
      "Iteration: 8910/10000, Loss: 0.009419218637049198\n",
      "Iteration: 8911/10000, Loss: 0.008129671216011047\n",
      "Iteration: 8912/10000, Loss: 0.0107937166467309\n",
      "Iteration: 8913/10000, Loss: 0.011627253144979477\n",
      "Iteration: 8914/10000, Loss: 0.007524463813751936\n",
      "Iteration: 8915/10000, Loss: 0.00993160530924797\n",
      "Iteration: 8916/10000, Loss: 0.014607035554945469\n",
      "Iteration: 8917/10000, Loss: 0.006604960188269615\n",
      "Iteration: 8918/10000, Loss: 0.007439997047185898\n",
      "Iteration: 8919/10000, Loss: 0.007619884796440601\n",
      "Iteration: 8920/10000, Loss: 0.008447928354144096\n",
      "Iteration: 8921/10000, Loss: 0.009456034749746323\n",
      "Iteration: 8922/10000, Loss: 0.009230490773916245\n",
      "Iteration: 8923/10000, Loss: 0.005863031838089228\n",
      "Iteration: 8924/10000, Loss: 0.00544147239997983\n",
      "Iteration: 8925/10000, Loss: 0.009544270113110542\n",
      "Iteration: 8926/10000, Loss: 0.008575198240578175\n",
      "Iteration: 8927/10000, Loss: 0.007537534460425377\n",
      "Iteration: 8928/10000, Loss: 0.00748441694304347\n",
      "Iteration: 8929/10000, Loss: 0.005804138723760843\n",
      "Iteration: 8930/10000, Loss: 0.011960303410887718\n",
      "Iteration: 8931/10000, Loss: 0.00890060979872942\n",
      "Iteration: 8932/10000, Loss: 0.005850858986377716\n",
      "Iteration: 8933/10000, Loss: 0.007452729158103466\n",
      "Iteration: 8934/10000, Loss: 0.005967655684798956\n",
      "Iteration: 8935/10000, Loss: 0.011715998873114586\n",
      "Iteration: 8936/10000, Loss: 0.007736732717603445\n",
      "Iteration: 8937/10000, Loss: 0.007916267961263657\n",
      "Iteration: 8938/10000, Loss: 0.008641020394861698\n",
      "Iteration: 8939/10000, Loss: 0.006883211433887482\n",
      "Iteration: 8940/10000, Loss: 0.00787055492401123\n",
      "Iteration: 8941/10000, Loss: 0.005918134469538927\n",
      "Iteration: 8942/10000, Loss: 0.008177155628800392\n",
      "Iteration: 8943/10000, Loss: 0.011671287938952446\n",
      "Iteration: 8944/10000, Loss: 0.009065319783985615\n",
      "Iteration: 8945/10000, Loss: 0.011012500151991844\n",
      "Iteration: 8946/10000, Loss: 0.009155074134469032\n",
      "Iteration: 8947/10000, Loss: 0.005874814465641975\n",
      "Iteration: 8948/10000, Loss: 0.01178524550050497\n",
      "Iteration: 8949/10000, Loss: 0.012665235437452793\n",
      "Iteration: 8950/10000, Loss: 0.015433023683726788\n",
      "Iteration: 8951/10000, Loss: 0.004780243616551161\n",
      "Iteration: 8952/10000, Loss: 0.009526743553578854\n",
      "Iteration: 8953/10000, Loss: 0.007989346981048584\n",
      "Iteration: 8954/10000, Loss: 0.01002741139382124\n",
      "Iteration: 8955/10000, Loss: 0.007015570532530546\n",
      "Iteration: 8956/10000, Loss: 0.009169241413474083\n",
      "Iteration: 8957/10000, Loss: 0.011035257950425148\n",
      "Iteration: 8958/10000, Loss: 0.01185258012264967\n",
      "Iteration: 8959/10000, Loss: 0.007369567174464464\n",
      "Iteration: 8960/10000, Loss: 0.007277139462530613\n",
      "Iteration: 8961/10000, Loss: 0.0064834230579435825\n",
      "Iteration: 8962/10000, Loss: 0.005181195680052042\n",
      "Iteration: 8963/10000, Loss: 0.005255723837763071\n",
      "Iteration: 8964/10000, Loss: 0.007411764468997717\n",
      "Iteration: 8965/10000, Loss: 0.00674988329410553\n",
      "Iteration: 8966/10000, Loss: 0.008077424019575119\n",
      "Iteration: 8967/10000, Loss: 0.012815720401704311\n",
      "Iteration: 8968/10000, Loss: 0.009462998248636723\n",
      "Iteration: 8969/10000, Loss: 0.00680841039866209\n",
      "Iteration: 8970/10000, Loss: 0.008484385907649994\n",
      "Iteration: 8971/10000, Loss: 0.009073524735867977\n",
      "Iteration: 8972/10000, Loss: 0.011148429475724697\n",
      "Iteration: 8973/10000, Loss: 0.007213663309812546\n",
      "Iteration: 8974/10000, Loss: 0.00535428524017334\n",
      "Iteration: 8975/10000, Loss: 0.010722682811319828\n",
      "Iteration: 8976/10000, Loss: 0.005349461454898119\n",
      "Iteration: 8977/10000, Loss: 0.010419516824185848\n",
      "Iteration: 8978/10000, Loss: 0.009370697662234306\n",
      "Iteration: 8979/10000, Loss: 0.0052419197745621204\n",
      "Iteration: 8980/10000, Loss: 0.006107557564973831\n",
      "Iteration: 8981/10000, Loss: 0.006039604544639587\n",
      "Iteration: 8982/10000, Loss: 0.007083932403475046\n",
      "Iteration: 8983/10000, Loss: 0.006026887334883213\n",
      "Iteration: 8984/10000, Loss: 0.00792666245251894\n",
      "Iteration: 8985/10000, Loss: 0.005834606941789389\n",
      "Iteration: 8986/10000, Loss: 0.008830121718347073\n",
      "Iteration: 8987/10000, Loss: 0.006637236103415489\n",
      "Iteration: 8988/10000, Loss: 0.011502393521368504\n",
      "Iteration: 8989/10000, Loss: 0.008579092100262642\n",
      "Iteration: 8990/10000, Loss: 0.013690518215298653\n",
      "Iteration: 8991/10000, Loss: 0.008930505253374577\n",
      "Iteration: 8992/10000, Loss: 0.010169781744480133\n",
      "Iteration: 8993/10000, Loss: 0.007461691740900278\n",
      "Iteration: 8994/10000, Loss: 0.008213071152567863\n",
      "Iteration: 8995/10000, Loss: 0.007343498524278402\n",
      "Iteration: 8996/10000, Loss: 0.009721686132252216\n",
      "Iteration: 8997/10000, Loss: 0.008623013272881508\n",
      "Iteration: 8998/10000, Loss: 0.006731962785124779\n",
      "Iteration: 8999/10000, Loss: 0.007802020758390427\n",
      "Iteration: 9000/10000, Loss: 0.004994405433535576\n",
      "Average test loss:  0.0034\n",
      "Iteration: 9001/10000, Loss: 0.008392167277634144\n",
      "Iteration: 9002/10000, Loss: 0.008597802370786667\n",
      "Iteration: 9003/10000, Loss: 0.006644339766353369\n",
      "Iteration: 9004/10000, Loss: 0.008860805071890354\n",
      "Iteration: 9005/10000, Loss: 0.007197448518127203\n",
      "Iteration: 9006/10000, Loss: 0.007757383398711681\n",
      "Iteration: 9007/10000, Loss: 0.0095468545332551\n",
      "Iteration: 9008/10000, Loss: 0.00780737679451704\n",
      "Iteration: 9009/10000, Loss: 0.008657384663820267\n",
      "Iteration: 9010/10000, Loss: 0.006022887770086527\n",
      "Iteration: 9011/10000, Loss: 0.008257207460701466\n",
      "Iteration: 9012/10000, Loss: 0.009234445169568062\n",
      "Iteration: 9013/10000, Loss: 0.011359008960425854\n",
      "Iteration: 9014/10000, Loss: 0.007739019580185413\n",
      "Iteration: 9015/10000, Loss: 0.008076910860836506\n",
      "Iteration: 9016/10000, Loss: 0.006159112323075533\n",
      "Iteration: 9017/10000, Loss: 0.010432083159685135\n",
      "Iteration: 9018/10000, Loss: 0.0068871150724589825\n",
      "Iteration: 9019/10000, Loss: 0.010445608757436275\n",
      "Iteration: 9020/10000, Loss: 0.007365277037024498\n",
      "Iteration: 9021/10000, Loss: 0.008183246478438377\n",
      "Iteration: 9022/10000, Loss: 0.0065144747495651245\n",
      "Iteration: 9023/10000, Loss: 0.010177879594266415\n",
      "Iteration: 9024/10000, Loss: 0.00828482210636139\n",
      "Iteration: 9025/10000, Loss: 0.006569371093064547\n",
      "Iteration: 9026/10000, Loss: 0.006514797918498516\n",
      "Iteration: 9027/10000, Loss: 0.009812487289309502\n",
      "Iteration: 9028/10000, Loss: 0.008680115453898907\n",
      "Iteration: 9029/10000, Loss: 0.006686370819807053\n",
      "Iteration: 9030/10000, Loss: 0.007252878043800592\n",
      "Iteration: 9031/10000, Loss: 0.008448372595012188\n",
      "Iteration: 9032/10000, Loss: 0.0076498896814882755\n",
      "Iteration: 9033/10000, Loss: 0.007942204363644123\n",
      "Iteration: 9034/10000, Loss: 0.007006173487752676\n",
      "Iteration: 9035/10000, Loss: 0.010694011114537716\n",
      "Iteration: 9036/10000, Loss: 0.010695700533688068\n",
      "Iteration: 9037/10000, Loss: 0.007148100063204765\n",
      "Iteration: 9038/10000, Loss: 0.010037717409431934\n",
      "Iteration: 9039/10000, Loss: 0.010070586577057838\n",
      "Iteration: 9040/10000, Loss: 0.011884225532412529\n",
      "Iteration: 9041/10000, Loss: 0.009324607439339161\n",
      "Iteration: 9042/10000, Loss: 0.008951684460043907\n",
      "Iteration: 9043/10000, Loss: 0.005099728237837553\n",
      "Iteration: 9044/10000, Loss: 0.006353119388222694\n",
      "Iteration: 9045/10000, Loss: 0.009492265060544014\n",
      "Iteration: 9046/10000, Loss: 0.012984770350158215\n",
      "Iteration: 9047/10000, Loss: 0.008562102913856506\n",
      "Iteration: 9048/10000, Loss: 0.008515901863574982\n",
      "Iteration: 9049/10000, Loss: 0.010238928720355034\n",
      "Iteration: 9050/10000, Loss: 0.00870248768478632\n",
      "Iteration: 9051/10000, Loss: 0.011901581659913063\n",
      "Iteration: 9052/10000, Loss: 0.006079254671931267\n",
      "Iteration: 9053/10000, Loss: 0.007376916706562042\n",
      "Iteration: 9054/10000, Loss: 0.007097295485436916\n",
      "Iteration: 9055/10000, Loss: 0.0072316876612603664\n",
      "Iteration: 9056/10000, Loss: 0.014771034009754658\n",
      "Iteration: 9057/10000, Loss: 0.008407068438827991\n",
      "Iteration: 9058/10000, Loss: 0.010477551259100437\n",
      "Iteration: 9059/10000, Loss: 0.006407961715012789\n",
      "Iteration: 9060/10000, Loss: 0.009103573858737946\n",
      "Iteration: 9061/10000, Loss: 0.007232089526951313\n",
      "Iteration: 9062/10000, Loss: 0.007996484637260437\n",
      "Iteration: 9063/10000, Loss: 0.009044748730957508\n",
      "Iteration: 9064/10000, Loss: 0.008816873654723167\n",
      "Iteration: 9065/10000, Loss: 0.008075250312685966\n",
      "Iteration: 9066/10000, Loss: 0.003811461618170142\n",
      "Iteration: 9067/10000, Loss: 0.007413035724312067\n",
      "Iteration: 9068/10000, Loss: 0.007728658150881529\n",
      "Iteration: 9069/10000, Loss: 0.008409499190747738\n",
      "Iteration: 9070/10000, Loss: 0.011374760419130325\n",
      "Iteration: 9071/10000, Loss: 0.007136446423828602\n",
      "Iteration: 9072/10000, Loss: 0.008157989010214806\n",
      "Iteration: 9073/10000, Loss: 0.00993247888982296\n",
      "Iteration: 9074/10000, Loss: 0.007972058840095997\n",
      "Iteration: 9075/10000, Loss: 0.009235096164047718\n",
      "Iteration: 9076/10000, Loss: 0.010424480773508549\n",
      "Iteration: 9077/10000, Loss: 0.006520013324916363\n",
      "Iteration: 9078/10000, Loss: 0.006436952389776707\n",
      "Iteration: 9079/10000, Loss: 0.007487916853278875\n",
      "Iteration: 9080/10000, Loss: 0.011145655997097492\n",
      "Iteration: 9081/10000, Loss: 0.008474076166749\n",
      "Iteration: 9082/10000, Loss: 0.007861261256039143\n",
      "Iteration: 9083/10000, Loss: 0.01003621518611908\n",
      "Iteration: 9084/10000, Loss: 0.005925619509071112\n",
      "Iteration: 9085/10000, Loss: 0.007548654917627573\n",
      "Iteration: 9086/10000, Loss: 0.010632876306772232\n",
      "Iteration: 9087/10000, Loss: 0.012277952395379543\n",
      "Iteration: 9088/10000, Loss: 0.009071478620171547\n",
      "Iteration: 9089/10000, Loss: 0.008912354707717896\n",
      "Iteration: 9090/10000, Loss: 0.008864632807672024\n",
      "Iteration: 9091/10000, Loss: 0.008903415873646736\n",
      "Iteration: 9092/10000, Loss: 0.005719670094549656\n",
      "Iteration: 9093/10000, Loss: 0.009790965355932713\n",
      "Iteration: 9094/10000, Loss: 0.009456799365580082\n",
      "Iteration: 9095/10000, Loss: 0.006398782134056091\n",
      "Iteration: 9096/10000, Loss: 0.008455478586256504\n",
      "Iteration: 9097/10000, Loss: 0.008435622788965702\n",
      "Iteration: 9098/10000, Loss: 0.007924739271402359\n",
      "Iteration: 9099/10000, Loss: 0.009969626553356647\n",
      "Iteration: 9100/10000, Loss: 0.011024774983525276\n",
      "Average test loss:  0.0028\n",
      "Iteration: 9101/10000, Loss: 0.008137762546539307\n",
      "Iteration: 9102/10000, Loss: 0.008079426363110542\n",
      "Iteration: 9103/10000, Loss: 0.0059213051572442055\n",
      "Iteration: 9104/10000, Loss: 0.011620267294347286\n",
      "Iteration: 9105/10000, Loss: 0.009532036259770393\n",
      "Iteration: 9106/10000, Loss: 0.009363376535475254\n",
      "Iteration: 9107/10000, Loss: 0.01347585953772068\n",
      "Iteration: 9108/10000, Loss: 0.009680019691586494\n",
      "Iteration: 9109/10000, Loss: 0.008350107818841934\n",
      "Iteration: 9110/10000, Loss: 0.008619123138487339\n",
      "Iteration: 9111/10000, Loss: 0.00884025078266859\n",
      "Iteration: 9112/10000, Loss: 0.00456597376614809\n",
      "Iteration: 9113/10000, Loss: 0.007916150614619255\n",
      "Iteration: 9114/10000, Loss: 0.007314502727240324\n",
      "Iteration: 9115/10000, Loss: 0.005067603196948767\n",
      "Iteration: 9116/10000, Loss: 0.011414149776101112\n",
      "Iteration: 9117/10000, Loss: 0.007722313515841961\n",
      "Iteration: 9118/10000, Loss: 0.009171228855848312\n",
      "Iteration: 9119/10000, Loss: 0.012305160984396935\n",
      "Iteration: 9120/10000, Loss: 0.011574875563383102\n",
      "Iteration: 9121/10000, Loss: 0.004838717635720968\n",
      "Iteration: 9122/10000, Loss: 0.005404775030910969\n",
      "Iteration: 9123/10000, Loss: 0.006818125024437904\n",
      "Iteration: 9124/10000, Loss: 0.006552547216415405\n",
      "Iteration: 9125/10000, Loss: 0.008775167167186737\n",
      "Iteration: 9126/10000, Loss: 0.009541026316583157\n",
      "Iteration: 9127/10000, Loss: 0.00742904981598258\n",
      "Iteration: 9128/10000, Loss: 0.00887316931039095\n",
      "Iteration: 9129/10000, Loss: 0.01192824449390173\n",
      "Iteration: 9130/10000, Loss: 0.010025424882769585\n",
      "Iteration: 9131/10000, Loss: 0.009867058135569096\n",
      "Iteration: 9132/10000, Loss: 0.010131346061825752\n",
      "Iteration: 9133/10000, Loss: 0.008153891190886497\n",
      "Iteration: 9134/10000, Loss: 0.0050245909951627254\n",
      "Iteration: 9135/10000, Loss: 0.010053888894617558\n",
      "Iteration: 9136/10000, Loss: 0.010306513868272305\n",
      "Iteration: 9137/10000, Loss: 0.005685817915946245\n",
      "Iteration: 9138/10000, Loss: 0.007164503913372755\n",
      "Iteration: 9139/10000, Loss: 0.009119318798184395\n",
      "Iteration: 9140/10000, Loss: 0.009256629273295403\n",
      "Iteration: 9141/10000, Loss: 0.006077300291508436\n",
      "Iteration: 9142/10000, Loss: 0.006054802797734737\n",
      "Iteration: 9143/10000, Loss: 0.008088287897408009\n",
      "Iteration: 9144/10000, Loss: 0.007071219850331545\n",
      "Iteration: 9145/10000, Loss: 0.006617214530706406\n",
      "Iteration: 9146/10000, Loss: 0.008630077354609966\n",
      "Iteration: 9147/10000, Loss: 0.005833299830555916\n",
      "Iteration: 9148/10000, Loss: 0.007033478002995253\n",
      "Iteration: 9149/10000, Loss: 0.006753585301339626\n",
      "Iteration: 9150/10000, Loss: 0.00622969027608633\n",
      "Iteration: 9151/10000, Loss: 0.00958921667188406\n",
      "Iteration: 9152/10000, Loss: 0.008348990231752396\n",
      "Iteration: 9153/10000, Loss: 0.008536107838153839\n",
      "Iteration: 9154/10000, Loss: 0.009818119928240776\n",
      "Iteration: 9155/10000, Loss: 0.007314083632081747\n",
      "Iteration: 9156/10000, Loss: 0.008165724575519562\n",
      "Iteration: 9157/10000, Loss: 0.009295902214944363\n",
      "Iteration: 9158/10000, Loss: 0.0071654049679636955\n",
      "Iteration: 9159/10000, Loss: 0.008263337425887585\n",
      "Iteration: 9160/10000, Loss: 0.007535973563790321\n",
      "Iteration: 9161/10000, Loss: 0.007133455481380224\n",
      "Iteration: 9162/10000, Loss: 0.010701724328100681\n",
      "Iteration: 9163/10000, Loss: 0.005892408080399036\n",
      "Iteration: 9164/10000, Loss: 0.005870264954864979\n",
      "Iteration: 9165/10000, Loss: 0.007285964209586382\n",
      "Iteration: 9166/10000, Loss: 0.009154622443020344\n",
      "Iteration: 9167/10000, Loss: 0.008920632302761078\n",
      "Iteration: 9168/10000, Loss: 0.007588728331029415\n",
      "Iteration: 9169/10000, Loss: 0.008906945586204529\n",
      "Iteration: 9170/10000, Loss: 0.006948170252144337\n",
      "Iteration: 9171/10000, Loss: 0.011375881731510162\n",
      "Iteration: 9172/10000, Loss: 0.005799429025501013\n",
      "Iteration: 9173/10000, Loss: 0.008777916431427002\n",
      "Iteration: 9174/10000, Loss: 0.008065733127295971\n",
      "Iteration: 9175/10000, Loss: 0.0072530475445091724\n",
      "Iteration: 9176/10000, Loss: 0.008297925814986229\n",
      "Iteration: 9177/10000, Loss: 0.005846076179295778\n",
      "Iteration: 9178/10000, Loss: 0.008917062543332577\n",
      "Iteration: 9179/10000, Loss: 0.008387764915823936\n",
      "Iteration: 9180/10000, Loss: 0.0062166862189769745\n",
      "Iteration: 9181/10000, Loss: 0.007548765745013952\n",
      "Iteration: 9182/10000, Loss: 0.00960774440318346\n",
      "Iteration: 9183/10000, Loss: 0.006275316700339317\n",
      "Iteration: 9184/10000, Loss: 0.0093260258436203\n",
      "Iteration: 9185/10000, Loss: 0.009185854345560074\n",
      "Iteration: 9186/10000, Loss: 0.009852278977632523\n",
      "Iteration: 9187/10000, Loss: 0.009021409787237644\n",
      "Iteration: 9188/10000, Loss: 0.011121579445898533\n",
      "Iteration: 9189/10000, Loss: 0.00760106835514307\n",
      "Iteration: 9190/10000, Loss: 0.008378861472010612\n",
      "Iteration: 9191/10000, Loss: 0.00511717377230525\n",
      "Iteration: 9192/10000, Loss: 0.008252238854765892\n",
      "Iteration: 9193/10000, Loss: 0.008091113530099392\n",
      "Iteration: 9194/10000, Loss: 0.00803405325859785\n",
      "Iteration: 9195/10000, Loss: 0.009441494010388851\n",
      "Iteration: 9196/10000, Loss: 0.014663501642644405\n",
      "Iteration: 9197/10000, Loss: 0.008598549291491508\n",
      "Iteration: 9198/10000, Loss: 0.00535461213439703\n",
      "Iteration: 9199/10000, Loss: 0.009658092632889748\n",
      "Iteration: 9200/10000, Loss: 0.011410793289542198\n",
      "Average test loss:  0.0028\n",
      "Iteration: 9201/10000, Loss: 0.0077375187538564205\n",
      "Iteration: 9202/10000, Loss: 0.010613271966576576\n",
      "Iteration: 9203/10000, Loss: 0.007105414755642414\n",
      "Iteration: 9204/10000, Loss: 0.008863965049386024\n",
      "Iteration: 9205/10000, Loss: 0.006534129846841097\n",
      "Iteration: 9206/10000, Loss: 0.005243473686277866\n",
      "Iteration: 9207/10000, Loss: 0.008397341705858707\n",
      "Iteration: 9208/10000, Loss: 0.011051305569708347\n",
      "Iteration: 9209/10000, Loss: 0.008254342712461948\n",
      "Iteration: 9210/10000, Loss: 0.005976881831884384\n",
      "Iteration: 9211/10000, Loss: 0.011585226282477379\n",
      "Iteration: 9212/10000, Loss: 0.007619293872267008\n",
      "Iteration: 9213/10000, Loss: 0.007610739208757877\n",
      "Iteration: 9214/10000, Loss: 0.00688541866838932\n",
      "Iteration: 9215/10000, Loss: 0.008649729192256927\n",
      "Iteration: 9216/10000, Loss: 0.0069786785170435905\n",
      "Iteration: 9217/10000, Loss: 0.005350092425942421\n",
      "Iteration: 9218/10000, Loss: 0.0071752555668354034\n",
      "Iteration: 9219/10000, Loss: 0.0036952425725758076\n",
      "Iteration: 9220/10000, Loss: 0.0070175169967114925\n",
      "Iteration: 9221/10000, Loss: 0.009479666128754616\n",
      "Iteration: 9222/10000, Loss: 0.007234176620841026\n",
      "Iteration: 9223/10000, Loss: 0.00952173676341772\n",
      "Iteration: 9224/10000, Loss: 0.012868508696556091\n",
      "Iteration: 9225/10000, Loss: 0.006776205264031887\n",
      "Iteration: 9226/10000, Loss: 0.00754593126475811\n",
      "Iteration: 9227/10000, Loss: 0.010461999103426933\n",
      "Iteration: 9228/10000, Loss: 0.0126463882625103\n",
      "Iteration: 9229/10000, Loss: 0.008797232061624527\n",
      "Iteration: 9230/10000, Loss: 0.005111929029226303\n",
      "Iteration: 9231/10000, Loss: 0.005935867317020893\n",
      "Iteration: 9232/10000, Loss: 0.005981926340609789\n",
      "Iteration: 9233/10000, Loss: 0.011387296952307224\n",
      "Iteration: 9234/10000, Loss: 0.009094253182411194\n",
      "Iteration: 9235/10000, Loss: 0.008206834085285664\n",
      "Iteration: 9236/10000, Loss: 0.005515307188034058\n",
      "Iteration: 9237/10000, Loss: 0.008069243282079697\n",
      "Iteration: 9238/10000, Loss: 0.006722516845911741\n",
      "Iteration: 9239/10000, Loss: 0.008557788096368313\n",
      "Iteration: 9240/10000, Loss: 0.008504251018166542\n",
      "Iteration: 9241/10000, Loss: 0.006865361705422401\n",
      "Iteration: 9242/10000, Loss: 0.00846385769546032\n",
      "Iteration: 9243/10000, Loss: 0.006575435865670443\n",
      "Iteration: 9244/10000, Loss: 0.005619287025183439\n",
      "Iteration: 9245/10000, Loss: 0.008158750832080841\n",
      "Iteration: 9246/10000, Loss: 0.00533487880602479\n",
      "Iteration: 9247/10000, Loss: 0.007283405400812626\n",
      "Iteration: 9248/10000, Loss: 0.00325020425952971\n",
      "Iteration: 9249/10000, Loss: 0.011114026419818401\n",
      "Iteration: 9250/10000, Loss: 0.009341176599264145\n",
      "Iteration: 9251/10000, Loss: 0.005035859066992998\n",
      "Iteration: 9252/10000, Loss: 0.009830346331000328\n",
      "Iteration: 9253/10000, Loss: 0.007020315621048212\n",
      "Iteration: 9254/10000, Loss: 0.01396707259118557\n",
      "Iteration: 9255/10000, Loss: 0.0072885132394731045\n",
      "Iteration: 9256/10000, Loss: 0.008950404822826385\n",
      "Iteration: 9257/10000, Loss: 0.00756637379527092\n",
      "Iteration: 9258/10000, Loss: 0.008130403235554695\n",
      "Iteration: 9259/10000, Loss: 0.006145834922790527\n",
      "Iteration: 9260/10000, Loss: 0.0089900316670537\n",
      "Iteration: 9261/10000, Loss: 0.008541326969861984\n",
      "Iteration: 9262/10000, Loss: 0.009583991020917892\n",
      "Iteration: 9263/10000, Loss: 0.006183016579598188\n",
      "Iteration: 9264/10000, Loss: 0.007641628384590149\n",
      "Iteration: 9265/10000, Loss: 0.009184954687952995\n",
      "Iteration: 9266/10000, Loss: 0.00929943472146988\n",
      "Iteration: 9267/10000, Loss: 0.006968105677515268\n",
      "Iteration: 9268/10000, Loss: 0.006564705166965723\n",
      "Iteration: 9269/10000, Loss: 0.005524007137864828\n",
      "Iteration: 9270/10000, Loss: 0.008416407741606236\n",
      "Iteration: 9271/10000, Loss: 0.007760966196656227\n",
      "Iteration: 9272/10000, Loss: 0.00820150040090084\n",
      "Iteration: 9273/10000, Loss: 0.01232820376753807\n",
      "Iteration: 9274/10000, Loss: 0.006622509565204382\n",
      "Iteration: 9275/10000, Loss: 0.009734557010233402\n",
      "Iteration: 9276/10000, Loss: 0.005008655600249767\n",
      "Iteration: 9277/10000, Loss: 0.010137233883142471\n",
      "Iteration: 9278/10000, Loss: 0.007700338028371334\n",
      "Iteration: 9279/10000, Loss: 0.0070313699543476105\n",
      "Iteration: 9280/10000, Loss: 0.006493535358458757\n",
      "Iteration: 9281/10000, Loss: 0.006028118077665567\n",
      "Iteration: 9282/10000, Loss: 0.005772974342107773\n",
      "Iteration: 9283/10000, Loss: 0.009458806365728378\n",
      "Iteration: 9284/10000, Loss: 0.008341221138834953\n",
      "Iteration: 9285/10000, Loss: 0.005734866484999657\n",
      "Iteration: 9286/10000, Loss: 0.004314064048230648\n",
      "Iteration: 9287/10000, Loss: 0.008666324429214\n",
      "Iteration: 9288/10000, Loss: 0.008928532712161541\n",
      "Iteration: 9289/10000, Loss: 0.0040575009770691395\n",
      "Iteration: 9290/10000, Loss: 0.007420235313475132\n",
      "Iteration: 9291/10000, Loss: 0.008964655920863152\n",
      "Iteration: 9292/10000, Loss: 0.009056891314685345\n",
      "Iteration: 9293/10000, Loss: 0.010487288236618042\n",
      "Iteration: 9294/10000, Loss: 0.0052758376114070415\n",
      "Iteration: 9295/10000, Loss: 0.007404750678688288\n",
      "Iteration: 9296/10000, Loss: 0.00901491567492485\n",
      "Iteration: 9297/10000, Loss: 0.010825739242136478\n",
      "Iteration: 9298/10000, Loss: 0.009757095947861671\n",
      "Iteration: 9299/10000, Loss: 0.009945588186383247\n",
      "Iteration: 9300/10000, Loss: 0.010077773593366146\n",
      "Average test loss:  0.0016\n",
      "Iteration: 9301/10000, Loss: 0.006617046892642975\n",
      "Iteration: 9302/10000, Loss: 0.007427460514008999\n",
      "Iteration: 9303/10000, Loss: 0.005850628018379211\n",
      "Iteration: 9304/10000, Loss: 0.013299098238348961\n",
      "Iteration: 9305/10000, Loss: 0.005879344418644905\n",
      "Iteration: 9306/10000, Loss: 0.011574484407901764\n",
      "Iteration: 9307/10000, Loss: 0.010184998624026775\n",
      "Iteration: 9308/10000, Loss: 0.009169057942926884\n",
      "Iteration: 9309/10000, Loss: 0.005492061376571655\n",
      "Iteration: 9310/10000, Loss: 0.009632415138185024\n",
      "Iteration: 9311/10000, Loss: 0.00938609428703785\n",
      "Iteration: 9312/10000, Loss: 0.010242525488138199\n",
      "Iteration: 9313/10000, Loss: 0.010505556128919125\n",
      "Iteration: 9314/10000, Loss: 0.010321573354303837\n",
      "Iteration: 9315/10000, Loss: 0.007381950505077839\n",
      "Iteration: 9316/10000, Loss: 0.005198042839765549\n",
      "Iteration: 9317/10000, Loss: 0.008143628016114235\n",
      "Iteration: 9318/10000, Loss: 0.009713484905660152\n",
      "Iteration: 9319/10000, Loss: 0.008007057942450047\n",
      "Iteration: 9320/10000, Loss: 0.009544847533106804\n",
      "Iteration: 9321/10000, Loss: 0.0077994754537940025\n",
      "Iteration: 9322/10000, Loss: 0.007626567967236042\n",
      "Iteration: 9323/10000, Loss: 0.006378802005201578\n",
      "Iteration: 9324/10000, Loss: 0.011886757798492908\n",
      "Iteration: 9325/10000, Loss: 0.010264641605317593\n",
      "Iteration: 9326/10000, Loss: 0.00869354885071516\n",
      "Iteration: 9327/10000, Loss: 0.007425874006003141\n",
      "Iteration: 9328/10000, Loss: 0.007297206670045853\n",
      "Iteration: 9329/10000, Loss: 0.008724527433514595\n",
      "Iteration: 9330/10000, Loss: 0.009733115322887897\n",
      "Iteration: 9331/10000, Loss: 0.007345573510974646\n",
      "Iteration: 9332/10000, Loss: 0.010940213687717915\n",
      "Iteration: 9333/10000, Loss: 0.008968545123934746\n",
      "Iteration: 9334/10000, Loss: 0.008516141213476658\n",
      "Iteration: 9335/10000, Loss: 0.007159731350839138\n",
      "Iteration: 9336/10000, Loss: 0.0124069694429636\n",
      "Iteration: 9337/10000, Loss: 0.008447187952697277\n",
      "Iteration: 9338/10000, Loss: 0.00695305410772562\n",
      "Iteration: 9339/10000, Loss: 0.008872023783624172\n",
      "Iteration: 9340/10000, Loss: 0.005383542738854885\n",
      "Iteration: 9341/10000, Loss: 0.009753493592143059\n",
      "Iteration: 9342/10000, Loss: 0.009718755260109901\n",
      "Iteration: 9343/10000, Loss: 0.006556100677698851\n",
      "Iteration: 9344/10000, Loss: 0.00839184783399105\n",
      "Iteration: 9345/10000, Loss: 0.008970336057245731\n",
      "Iteration: 9346/10000, Loss: 0.008916845545172691\n",
      "Iteration: 9347/10000, Loss: 0.005750279873609543\n",
      "Iteration: 9348/10000, Loss: 0.004954990930855274\n",
      "Iteration: 9349/10000, Loss: 0.0076973638497292995\n",
      "Iteration: 9350/10000, Loss: 0.009688880294561386\n",
      "Iteration: 9351/10000, Loss: 0.006682282779365778\n",
      "Iteration: 9352/10000, Loss: 0.007069868966937065\n",
      "Iteration: 9353/10000, Loss: 0.0061420416459441185\n",
      "Iteration: 9354/10000, Loss: 0.010334281250834465\n",
      "Iteration: 9355/10000, Loss: 0.007470493670552969\n",
      "Iteration: 9356/10000, Loss: 0.007223185617476702\n",
      "Iteration: 9357/10000, Loss: 0.008067674934864044\n",
      "Iteration: 9358/10000, Loss: 0.0078112478367984295\n",
      "Iteration: 9359/10000, Loss: 0.008269928395748138\n",
      "Iteration: 9360/10000, Loss: 0.0076636988669633865\n",
      "Iteration: 9361/10000, Loss: 0.008366174064576626\n",
      "Iteration: 9362/10000, Loss: 0.009061969816684723\n",
      "Iteration: 9363/10000, Loss: 0.007189711555838585\n",
      "Iteration: 9364/10000, Loss: 0.008075332269072533\n",
      "Iteration: 9365/10000, Loss: 0.008173639886081219\n",
      "Iteration: 9366/10000, Loss: 0.007928168401122093\n",
      "Iteration: 9367/10000, Loss: 0.006206775549799204\n",
      "Iteration: 9368/10000, Loss: 0.00732657965272665\n",
      "Iteration: 9369/10000, Loss: 0.0077379546128213406\n",
      "Iteration: 9370/10000, Loss: 0.005456198938190937\n",
      "Iteration: 9371/10000, Loss: 0.0065363734029233456\n",
      "Iteration: 9372/10000, Loss: 0.006346151698380709\n",
      "Iteration: 9373/10000, Loss: 0.01109080296009779\n",
      "Iteration: 9374/10000, Loss: 0.008422540500760078\n",
      "Iteration: 9375/10000, Loss: 0.011683233082294464\n",
      "Iteration: 9376/10000, Loss: 0.006511196494102478\n",
      "Iteration: 9377/10000, Loss: 0.007718943525105715\n",
      "Iteration: 9378/10000, Loss: 0.007111334707587957\n",
      "Iteration: 9379/10000, Loss: 0.009964997880160809\n",
      "Iteration: 9380/10000, Loss: 0.010145656764507294\n",
      "Iteration: 9381/10000, Loss: 0.009134399704635143\n",
      "Iteration: 9382/10000, Loss: 0.008605529554188251\n",
      "Iteration: 9383/10000, Loss: 0.004300576634705067\n",
      "Iteration: 9384/10000, Loss: 0.007949749939143658\n",
      "Iteration: 9385/10000, Loss: 0.0053985826671123505\n",
      "Iteration: 9386/10000, Loss: 0.01013824064284563\n",
      "Iteration: 9387/10000, Loss: 0.007643223740160465\n",
      "Iteration: 9388/10000, Loss: 0.006953066680580378\n",
      "Iteration: 9389/10000, Loss: 0.008435898460447788\n",
      "Iteration: 9390/10000, Loss: 0.007203605957329273\n",
      "Iteration: 9391/10000, Loss: 0.007427619304507971\n",
      "Iteration: 9392/10000, Loss: 0.010899416171014309\n",
      "Iteration: 9393/10000, Loss: 0.004414508119225502\n",
      "Iteration: 9394/10000, Loss: 0.01067162211984396\n",
      "Iteration: 9395/10000, Loss: 0.007711921352893114\n",
      "Iteration: 9396/10000, Loss: 0.009692351333796978\n",
      "Iteration: 9397/10000, Loss: 0.009319733828306198\n",
      "Iteration: 9398/10000, Loss: 0.00724218413233757\n",
      "Iteration: 9399/10000, Loss: 0.006236113607883453\n",
      "Iteration: 9400/10000, Loss: 0.006976745091378689\n",
      "Average test loss:  0.0025\n",
      "Iteration: 9401/10000, Loss: 0.009089243598282337\n",
      "Iteration: 9402/10000, Loss: 0.006643462926149368\n",
      "Iteration: 9403/10000, Loss: 0.007779835257679224\n",
      "Iteration: 9404/10000, Loss: 0.007045013830065727\n",
      "Iteration: 9405/10000, Loss: 0.00830403994768858\n",
      "Iteration: 9406/10000, Loss: 0.005985236261039972\n",
      "Iteration: 9407/10000, Loss: 0.008092200383543968\n",
      "Iteration: 9408/10000, Loss: 0.014413077384233475\n",
      "Iteration: 9409/10000, Loss: 0.010615586303174496\n",
      "Iteration: 9410/10000, Loss: 0.007550065405666828\n",
      "Iteration: 9411/10000, Loss: 0.011672047898173332\n",
      "Iteration: 9412/10000, Loss: 0.007506109774112701\n",
      "Iteration: 9413/10000, Loss: 0.010187226347625256\n",
      "Iteration: 9414/10000, Loss: 0.005720401648432016\n",
      "Iteration: 9415/10000, Loss: 0.008312545716762543\n",
      "Iteration: 9416/10000, Loss: 0.007185468450188637\n",
      "Iteration: 9417/10000, Loss: 0.010633077472448349\n",
      "Iteration: 9418/10000, Loss: 0.005993734113872051\n",
      "Iteration: 9419/10000, Loss: 0.006320944055914879\n",
      "Iteration: 9420/10000, Loss: 0.008153914473950863\n",
      "Iteration: 9421/10000, Loss: 0.006022315472364426\n",
      "Iteration: 9422/10000, Loss: 0.006041108630597591\n",
      "Iteration: 9423/10000, Loss: 0.006738417781889439\n",
      "Iteration: 9424/10000, Loss: 0.009666520170867443\n",
      "Iteration: 9425/10000, Loss: 0.008536729961633682\n",
      "Iteration: 9426/10000, Loss: 0.006119017954915762\n",
      "Iteration: 9427/10000, Loss: 0.00981614924967289\n",
      "Iteration: 9428/10000, Loss: 0.010176489129662514\n",
      "Iteration: 9429/10000, Loss: 0.009850279428064823\n",
      "Iteration: 9430/10000, Loss: 0.010078608058393002\n",
      "Iteration: 9431/10000, Loss: 0.0062870485708117485\n",
      "Iteration: 9432/10000, Loss: 0.00837630219757557\n",
      "Iteration: 9433/10000, Loss: 0.007716740481555462\n",
      "Iteration: 9434/10000, Loss: 0.00476424815133214\n",
      "Iteration: 9435/10000, Loss: 0.007237257435917854\n",
      "Iteration: 9436/10000, Loss: 0.007491566240787506\n",
      "Iteration: 9437/10000, Loss: 0.006676170509308577\n",
      "Iteration: 9438/10000, Loss: 0.00822252407670021\n",
      "Iteration: 9439/10000, Loss: 0.00675780838355422\n",
      "Iteration: 9440/10000, Loss: 0.008442911319434643\n",
      "Iteration: 9441/10000, Loss: 0.009882724843919277\n",
      "Iteration: 9442/10000, Loss: 0.007609205320477486\n",
      "Iteration: 9443/10000, Loss: 0.006465804763138294\n",
      "Iteration: 9444/10000, Loss: 0.008637773804366589\n",
      "Iteration: 9445/10000, Loss: 0.007958297617733479\n",
      "Iteration: 9446/10000, Loss: 0.005957304034382105\n",
      "Iteration: 9447/10000, Loss: 0.004959339741617441\n",
      "Iteration: 9448/10000, Loss: 0.006470826920121908\n",
      "Iteration: 9449/10000, Loss: 0.005752709228545427\n",
      "Iteration: 9450/10000, Loss: 0.005917479749768972\n",
      "Iteration: 9451/10000, Loss: 0.00883014127612114\n",
      "Iteration: 9452/10000, Loss: 0.009569013491272926\n",
      "Iteration: 9453/10000, Loss: 0.010099786333739758\n",
      "Iteration: 9454/10000, Loss: 0.009758942760527134\n",
      "Iteration: 9455/10000, Loss: 0.007923146709799767\n",
      "Iteration: 9456/10000, Loss: 0.009001684375107288\n",
      "Iteration: 9457/10000, Loss: 0.007589462213218212\n",
      "Iteration: 9458/10000, Loss: 0.011075613088905811\n",
      "Iteration: 9459/10000, Loss: 0.00900331512093544\n",
      "Iteration: 9460/10000, Loss: 0.0070176441222429276\n",
      "Iteration: 9461/10000, Loss: 0.007669929414987564\n",
      "Iteration: 9462/10000, Loss: 0.010860041715204716\n",
      "Iteration: 9463/10000, Loss: 0.006487288512289524\n",
      "Iteration: 9464/10000, Loss: 0.004832397680729628\n",
      "Iteration: 9465/10000, Loss: 0.006420950870960951\n",
      "Iteration: 9466/10000, Loss: 0.008170779794454575\n",
      "Iteration: 9467/10000, Loss: 0.006886041257530451\n",
      "Iteration: 9468/10000, Loss: 0.008864307776093483\n",
      "Iteration: 9469/10000, Loss: 0.00851425714790821\n",
      "Iteration: 9470/10000, Loss: 0.006386623252183199\n",
      "Iteration: 9471/10000, Loss: 0.009006410837173462\n",
      "Iteration: 9472/10000, Loss: 0.00921790860593319\n",
      "Iteration: 9473/10000, Loss: 0.007205146364867687\n",
      "Iteration: 9474/10000, Loss: 0.007124246098101139\n",
      "Iteration: 9475/10000, Loss: 0.008529706858098507\n",
      "Iteration: 9476/10000, Loss: 0.010451938025653362\n",
      "Iteration: 9477/10000, Loss: 0.0072684925980865955\n",
      "Iteration: 9478/10000, Loss: 0.007246262859553099\n",
      "Iteration: 9479/10000, Loss: 0.0074338726699352264\n",
      "Iteration: 9480/10000, Loss: 0.010605129413306713\n",
      "Iteration: 9481/10000, Loss: 0.014076851308345795\n",
      "Iteration: 9482/10000, Loss: 0.008786932565271854\n",
      "Iteration: 9483/10000, Loss: 0.005293802823871374\n",
      "Iteration: 9484/10000, Loss: 0.010249023325741291\n",
      "Iteration: 9485/10000, Loss: 0.006896050646901131\n",
      "Iteration: 9486/10000, Loss: 0.010674436576664448\n",
      "Iteration: 9487/10000, Loss: 0.008455331437289715\n",
      "Iteration: 9488/10000, Loss: 0.007829687558114529\n",
      "Iteration: 9489/10000, Loss: 0.009855067357420921\n",
      "Iteration: 9490/10000, Loss: 0.006384950131177902\n",
      "Iteration: 9491/10000, Loss: 0.008638156577944756\n",
      "Iteration: 9492/10000, Loss: 0.014425315894186497\n",
      "Iteration: 9493/10000, Loss: 0.009399523958563805\n",
      "Iteration: 9494/10000, Loss: 0.008342109620571136\n",
      "Iteration: 9495/10000, Loss: 0.0060306452214717865\n",
      "Iteration: 9496/10000, Loss: 0.005719164852052927\n",
      "Iteration: 9497/10000, Loss: 0.011606039479374886\n",
      "Iteration: 9498/10000, Loss: 0.008916727267205715\n",
      "Iteration: 9499/10000, Loss: 0.008520531468093395\n",
      "Iteration: 9500/10000, Loss: 0.006215898785740137\n",
      "Average test loss:  0.0030\n",
      "Iteration: 9501/10000, Loss: 0.006911109201610088\n",
      "Iteration: 9502/10000, Loss: 0.00957881286740303\n",
      "Iteration: 9503/10000, Loss: 0.008640551939606667\n",
      "Iteration: 9504/10000, Loss: 0.007027455605566502\n",
      "Iteration: 9505/10000, Loss: 0.0092361094430089\n",
      "Iteration: 9506/10000, Loss: 0.005934054497629404\n",
      "Iteration: 9507/10000, Loss: 0.00806794036179781\n",
      "Iteration: 9508/10000, Loss: 0.006180317606776953\n",
      "Iteration: 9509/10000, Loss: 0.006344967987388372\n",
      "Iteration: 9510/10000, Loss: 0.011699271388351917\n",
      "Iteration: 9511/10000, Loss: 0.0074712010100483894\n",
      "Iteration: 9512/10000, Loss: 0.010036184452474117\n",
      "Iteration: 9513/10000, Loss: 0.008585075847804546\n",
      "Iteration: 9514/10000, Loss: 0.009583364240825176\n",
      "Iteration: 9515/10000, Loss: 0.009690836071968079\n",
      "Iteration: 9516/10000, Loss: 0.013623344711959362\n",
      "Iteration: 9517/10000, Loss: 0.004388844594359398\n",
      "Iteration: 9518/10000, Loss: 0.010045265778899193\n",
      "Iteration: 9519/10000, Loss: 0.0069887032732367516\n",
      "Iteration: 9520/10000, Loss: 0.006508762948215008\n",
      "Iteration: 9521/10000, Loss: 0.009563736617565155\n",
      "Iteration: 9522/10000, Loss: 0.00853718537837267\n",
      "Iteration: 9523/10000, Loss: 0.009732072241604328\n",
      "Iteration: 9524/10000, Loss: 0.006594324018806219\n",
      "Iteration: 9525/10000, Loss: 0.009692813269793987\n",
      "Iteration: 9526/10000, Loss: 0.006740689277648926\n",
      "Iteration: 9527/10000, Loss: 0.006043675355613232\n",
      "Iteration: 9528/10000, Loss: 0.00996977835893631\n",
      "Iteration: 9529/10000, Loss: 0.011252409778535366\n",
      "Iteration: 9530/10000, Loss: 0.004885430913418531\n",
      "Iteration: 9531/10000, Loss: 0.007259245961904526\n",
      "Iteration: 9532/10000, Loss: 0.008710773661732674\n",
      "Iteration: 9533/10000, Loss: 0.007919957861304283\n",
      "Iteration: 9534/10000, Loss: 0.01023376639932394\n",
      "Iteration: 9535/10000, Loss: 0.007869977504014969\n",
      "Iteration: 9536/10000, Loss: 0.01350335031747818\n",
      "Iteration: 9537/10000, Loss: 0.009770609438419342\n",
      "Iteration: 9538/10000, Loss: 0.00843164324760437\n",
      "Iteration: 9539/10000, Loss: 0.009331493638455868\n",
      "Iteration: 9540/10000, Loss: 0.006112353410571814\n",
      "Iteration: 9541/10000, Loss: 0.0052405185997486115\n",
      "Iteration: 9542/10000, Loss: 0.007490255404263735\n",
      "Iteration: 9543/10000, Loss: 0.007051738444715738\n",
      "Iteration: 9544/10000, Loss: 0.009086634032428265\n",
      "Iteration: 9545/10000, Loss: 0.0053514111787080765\n",
      "Iteration: 9546/10000, Loss: 0.008063334040343761\n",
      "Iteration: 9547/10000, Loss: 0.009183566085994244\n",
      "Iteration: 9548/10000, Loss: 0.005562071688473225\n",
      "Iteration: 9549/10000, Loss: 0.009052005596458912\n",
      "Iteration: 9550/10000, Loss: 0.006430656183511019\n",
      "Iteration: 9551/10000, Loss: 0.005409196950495243\n",
      "Iteration: 9552/10000, Loss: 0.007087686099112034\n",
      "Iteration: 9553/10000, Loss: 0.011177466250956059\n",
      "Iteration: 9554/10000, Loss: 0.007844410836696625\n",
      "Iteration: 9555/10000, Loss: 0.009104050695896149\n",
      "Iteration: 9556/10000, Loss: 0.008091223426163197\n",
      "Iteration: 9557/10000, Loss: 0.00773846497759223\n",
      "Iteration: 9558/10000, Loss: 0.008922948502004147\n",
      "Iteration: 9559/10000, Loss: 0.008348247036337852\n",
      "Iteration: 9560/10000, Loss: 0.011455276049673557\n",
      "Iteration: 9561/10000, Loss: 0.007213159464299679\n",
      "Iteration: 9562/10000, Loss: 0.008847757242619991\n",
      "Iteration: 9563/10000, Loss: 0.007183270063251257\n",
      "Iteration: 9564/10000, Loss: 0.006082497537136078\n",
      "Iteration: 9565/10000, Loss: 0.012066088616847992\n",
      "Iteration: 9566/10000, Loss: 0.00661073811352253\n",
      "Iteration: 9567/10000, Loss: 0.008067882619798183\n",
      "Iteration: 9568/10000, Loss: 0.006846663076430559\n",
      "Iteration: 9569/10000, Loss: 0.006936093792319298\n",
      "Iteration: 9570/10000, Loss: 0.013965186662971973\n",
      "Iteration: 9571/10000, Loss: 0.008007550612092018\n",
      "Iteration: 9572/10000, Loss: 0.009630346670746803\n",
      "Iteration: 9573/10000, Loss: 0.006388974841684103\n",
      "Iteration: 9574/10000, Loss: 0.010043898597359657\n",
      "Iteration: 9575/10000, Loss: 0.007632671855390072\n",
      "Iteration: 9576/10000, Loss: 0.00866545271128416\n",
      "Iteration: 9577/10000, Loss: 0.007435866631567478\n",
      "Iteration: 9578/10000, Loss: 0.006960664410144091\n",
      "Iteration: 9579/10000, Loss: 0.011524345725774765\n",
      "Iteration: 9580/10000, Loss: 0.006529809441417456\n",
      "Iteration: 9581/10000, Loss: 0.005139810964465141\n",
      "Iteration: 9582/10000, Loss: 0.006602467969059944\n",
      "Iteration: 9583/10000, Loss: 0.009132626466453075\n",
      "Iteration: 9584/10000, Loss: 0.005800370126962662\n",
      "Iteration: 9585/10000, Loss: 0.012301132082939148\n",
      "Iteration: 9586/10000, Loss: 0.010653024539351463\n",
      "Iteration: 9587/10000, Loss: 0.007838261313736439\n",
      "Iteration: 9588/10000, Loss: 0.006482889410108328\n",
      "Iteration: 9589/10000, Loss: 0.005011313129216433\n",
      "Iteration: 9590/10000, Loss: 0.005699216853827238\n",
      "Iteration: 9591/10000, Loss: 0.005646036006510258\n",
      "Iteration: 9592/10000, Loss: 0.008039111271500587\n",
      "Iteration: 9593/10000, Loss: 0.012190106324851513\n",
      "Iteration: 9594/10000, Loss: 0.0038105868734419346\n",
      "Iteration: 9595/10000, Loss: 0.007256960496306419\n",
      "Iteration: 9596/10000, Loss: 0.0066185868345201015\n",
      "Iteration: 9597/10000, Loss: 0.008808302693068981\n",
      "Iteration: 9598/10000, Loss: 0.0035853858571499586\n",
      "Iteration: 9599/10000, Loss: 0.007905160076916218\n",
      "Iteration: 9600/10000, Loss: 0.011609124951064587\n",
      "Average test loss:  0.0026\n",
      "Iteration: 9601/10000, Loss: 0.0055456943809986115\n",
      "Iteration: 9602/10000, Loss: 0.010017258115112782\n",
      "Iteration: 9603/10000, Loss: 0.007112538442015648\n",
      "Iteration: 9604/10000, Loss: 0.0098642623052001\n",
      "Iteration: 9605/10000, Loss: 0.009242993779480457\n",
      "Iteration: 9606/10000, Loss: 0.008609854616224766\n",
      "Iteration: 9607/10000, Loss: 0.007197411265224218\n",
      "Iteration: 9608/10000, Loss: 0.010495485737919807\n",
      "Iteration: 9609/10000, Loss: 0.00880525354295969\n",
      "Iteration: 9610/10000, Loss: 0.009097290225327015\n",
      "Iteration: 9611/10000, Loss: 0.010485104285180569\n",
      "Iteration: 9612/10000, Loss: 0.009336855262517929\n",
      "Iteration: 9613/10000, Loss: 0.00879204086959362\n",
      "Iteration: 9614/10000, Loss: 0.009035911411046982\n",
      "Iteration: 9615/10000, Loss: 0.004350901115685701\n",
      "Iteration: 9616/10000, Loss: 0.0070567140355706215\n",
      "Iteration: 9617/10000, Loss: 0.006508578546345234\n",
      "Iteration: 9618/10000, Loss: 0.005218846723437309\n",
      "Iteration: 9619/10000, Loss: 0.011540713720023632\n",
      "Iteration: 9620/10000, Loss: 0.01175662875175476\n",
      "Iteration: 9621/10000, Loss: 0.008666068315505981\n",
      "Iteration: 9622/10000, Loss: 0.005414886865764856\n",
      "Iteration: 9623/10000, Loss: 0.0061133247800171375\n",
      "Iteration: 9624/10000, Loss: 0.0074091884307563305\n",
      "Iteration: 9625/10000, Loss: 0.010346856899559498\n",
      "Iteration: 9626/10000, Loss: 0.007283889222890139\n",
      "Iteration: 9627/10000, Loss: 0.0082530677318573\n",
      "Iteration: 9628/10000, Loss: 0.009410751983523369\n",
      "Iteration: 9629/10000, Loss: 0.00851931981742382\n",
      "Iteration: 9630/10000, Loss: 0.006609934847801924\n",
      "Iteration: 9631/10000, Loss: 0.01141244824975729\n",
      "Iteration: 9632/10000, Loss: 0.007033159025013447\n",
      "Iteration: 9633/10000, Loss: 0.007289948407560587\n",
      "Iteration: 9634/10000, Loss: 0.005146556533873081\n",
      "Iteration: 9635/10000, Loss: 0.0071098473854362965\n",
      "Iteration: 9636/10000, Loss: 0.009128018282353878\n",
      "Iteration: 9637/10000, Loss: 0.00674848910421133\n",
      "Iteration: 9638/10000, Loss: 0.007773152552545071\n",
      "Iteration: 9639/10000, Loss: 0.004913365002721548\n",
      "Iteration: 9640/10000, Loss: 0.01263930182904005\n",
      "Iteration: 9641/10000, Loss: 0.007096064276993275\n",
      "Iteration: 9642/10000, Loss: 0.009956080466508865\n",
      "Iteration: 9643/10000, Loss: 0.006752641871571541\n",
      "Iteration: 9644/10000, Loss: 0.006982569582760334\n",
      "Iteration: 9645/10000, Loss: 0.010450162924826145\n",
      "Iteration: 9646/10000, Loss: 0.01164031308144331\n",
      "Iteration: 9647/10000, Loss: 0.009190504439175129\n",
      "Iteration: 9648/10000, Loss: 0.00737538980320096\n",
      "Iteration: 9649/10000, Loss: 0.009603152982890606\n",
      "Iteration: 9650/10000, Loss: 0.007790545001626015\n",
      "Iteration: 9651/10000, Loss: 0.015103207901120186\n",
      "Iteration: 9652/10000, Loss: 0.011335058137774467\n",
      "Iteration: 9653/10000, Loss: 0.008385616354644299\n",
      "Iteration: 9654/10000, Loss: 0.00907498225569725\n",
      "Iteration: 9655/10000, Loss: 0.010845299810171127\n",
      "Iteration: 9656/10000, Loss: 0.00850022304803133\n",
      "Iteration: 9657/10000, Loss: 0.007846545428037643\n",
      "Iteration: 9658/10000, Loss: 0.013293773867189884\n",
      "Iteration: 9659/10000, Loss: 0.006013771053403616\n",
      "Iteration: 9660/10000, Loss: 0.007453487254679203\n",
      "Iteration: 9661/10000, Loss: 0.008794550783932209\n",
      "Iteration: 9662/10000, Loss: 0.004920473322272301\n",
      "Iteration: 9663/10000, Loss: 0.007605561055243015\n",
      "Iteration: 9664/10000, Loss: 0.008591439574956894\n",
      "Iteration: 9665/10000, Loss: 0.006618991494178772\n",
      "Iteration: 9666/10000, Loss: 0.009919482283294201\n",
      "Iteration: 9667/10000, Loss: 0.009807277470827103\n",
      "Iteration: 9668/10000, Loss: 0.010377299040555954\n",
      "Iteration: 9669/10000, Loss: 0.008931185118854046\n",
      "Iteration: 9670/10000, Loss: 0.00691307382658124\n",
      "Iteration: 9671/10000, Loss: 0.009642485529184341\n",
      "Iteration: 9672/10000, Loss: 0.010976506397128105\n",
      "Iteration: 9673/10000, Loss: 0.0061943745240569115\n",
      "Iteration: 9674/10000, Loss: 0.0050759403966367245\n",
      "Iteration: 9675/10000, Loss: 0.01281859539449215\n",
      "Iteration: 9676/10000, Loss: 0.00508399261161685\n",
      "Iteration: 9677/10000, Loss: 0.007137182168662548\n",
      "Iteration: 9678/10000, Loss: 0.009516783058643341\n",
      "Iteration: 9679/10000, Loss: 0.007457626983523369\n",
      "Iteration: 9680/10000, Loss: 0.008107012137770653\n",
      "Iteration: 9681/10000, Loss: 0.008257647044956684\n",
      "Iteration: 9682/10000, Loss: 0.007974677719175816\n",
      "Iteration: 9683/10000, Loss: 0.00556004885584116\n",
      "Iteration: 9684/10000, Loss: 0.00977489072829485\n",
      "Iteration: 9685/10000, Loss: 0.007876558229327202\n",
      "Iteration: 9686/10000, Loss: 0.010077332146465778\n",
      "Iteration: 9687/10000, Loss: 0.0038562905974686146\n",
      "Iteration: 9688/10000, Loss: 0.006904854904860258\n",
      "Iteration: 9689/10000, Loss: 0.007433007471263409\n",
      "Iteration: 9690/10000, Loss: 0.008635767735540867\n",
      "Iteration: 9691/10000, Loss: 0.005049592815339565\n",
      "Iteration: 9692/10000, Loss: 0.008070819079875946\n",
      "Iteration: 9693/10000, Loss: 0.009001316502690315\n",
      "Iteration: 9694/10000, Loss: 0.006210516672581434\n",
      "Iteration: 9695/10000, Loss: 0.006746890489012003\n",
      "Iteration: 9696/10000, Loss: 0.006011731456965208\n",
      "Iteration: 9697/10000, Loss: 0.01082505565136671\n",
      "Iteration: 9698/10000, Loss: 0.008409621194005013\n",
      "Iteration: 9699/10000, Loss: 0.005450161639600992\n",
      "Iteration: 9700/10000, Loss: 0.01118086464703083\n",
      "Average test loss:  0.0044\n",
      "Iteration: 9701/10000, Loss: 0.012501895427703857\n",
      "Iteration: 9702/10000, Loss: 0.007542890962213278\n",
      "Iteration: 9703/10000, Loss: 0.009760946966707706\n",
      "Iteration: 9704/10000, Loss: 0.00851894449442625\n",
      "Iteration: 9705/10000, Loss: 0.007207800634205341\n",
      "Iteration: 9706/10000, Loss: 0.007521970197558403\n",
      "Iteration: 9707/10000, Loss: 0.008932551369071007\n",
      "Iteration: 9708/10000, Loss: 0.006304878741502762\n",
      "Iteration: 9709/10000, Loss: 0.009271683171391487\n",
      "Iteration: 9710/10000, Loss: 0.008832690306007862\n",
      "Iteration: 9711/10000, Loss: 0.011163524352014065\n",
      "Iteration: 9712/10000, Loss: 0.008215795271098614\n",
      "Iteration: 9713/10000, Loss: 0.012516037560999393\n",
      "Iteration: 9714/10000, Loss: 0.00926565658301115\n",
      "Iteration: 9715/10000, Loss: 0.009738460183143616\n",
      "Iteration: 9716/10000, Loss: 0.009579847566783428\n",
      "Iteration: 9717/10000, Loss: 0.00638260692358017\n",
      "Iteration: 9718/10000, Loss: 0.010224496014416218\n",
      "Iteration: 9719/10000, Loss: 0.0070339106023311615\n",
      "Iteration: 9720/10000, Loss: 0.006732440087944269\n",
      "Iteration: 9721/10000, Loss: 0.009370348416268826\n",
      "Iteration: 9722/10000, Loss: 0.0047433762811124325\n",
      "Iteration: 9723/10000, Loss: 0.008648687042295933\n",
      "Iteration: 9724/10000, Loss: 0.007292582653462887\n",
      "Iteration: 9725/10000, Loss: 0.008157727308571339\n",
      "Iteration: 9726/10000, Loss: 0.01033120509237051\n",
      "Iteration: 9727/10000, Loss: 0.0059738438576459885\n",
      "Iteration: 9728/10000, Loss: 0.008815343491733074\n",
      "Iteration: 9729/10000, Loss: 0.006935741752386093\n",
      "Iteration: 9730/10000, Loss: 0.00680625019595027\n",
      "Iteration: 9731/10000, Loss: 0.01372439507395029\n",
      "Iteration: 9732/10000, Loss: 0.008555968292057514\n",
      "Iteration: 9733/10000, Loss: 0.009674793109297752\n",
      "Iteration: 9734/10000, Loss: 0.0075714546255767345\n",
      "Iteration: 9735/10000, Loss: 0.00820615328848362\n",
      "Iteration: 9736/10000, Loss: 0.010456661693751812\n",
      "Iteration: 9737/10000, Loss: 0.007045491598546505\n",
      "Iteration: 9738/10000, Loss: 0.007637606002390385\n",
      "Iteration: 9739/10000, Loss: 0.010508649982511997\n",
      "Iteration: 9740/10000, Loss: 0.009303269907832146\n",
      "Iteration: 9741/10000, Loss: 0.0078118485398590565\n",
      "Iteration: 9742/10000, Loss: 0.008318287320435047\n",
      "Iteration: 9743/10000, Loss: 0.00789361447095871\n",
      "Iteration: 9744/10000, Loss: 0.005806691013276577\n",
      "Iteration: 9745/10000, Loss: 0.008873440325260162\n",
      "Iteration: 9746/10000, Loss: 0.010847782716155052\n",
      "Iteration: 9747/10000, Loss: 0.007490877527743578\n",
      "Iteration: 9748/10000, Loss: 0.005669883452355862\n",
      "Iteration: 9749/10000, Loss: 0.004419706296175718\n",
      "Iteration: 9750/10000, Loss: 0.010126931592822075\n",
      "Iteration: 9751/10000, Loss: 0.009219512343406677\n",
      "Iteration: 9752/10000, Loss: 0.007084593642503023\n",
      "Iteration: 9753/10000, Loss: 0.009295310825109482\n",
      "Iteration: 9754/10000, Loss: 0.006693968083709478\n",
      "Iteration: 9755/10000, Loss: 0.007733124773949385\n",
      "Iteration: 9756/10000, Loss: 0.008751808665692806\n",
      "Iteration: 9757/10000, Loss: 0.007638385519385338\n",
      "Iteration: 9758/10000, Loss: 0.010980953462421894\n",
      "Iteration: 9759/10000, Loss: 0.00986474473029375\n",
      "Iteration: 9760/10000, Loss: 0.005850449204444885\n",
      "Iteration: 9761/10000, Loss: 0.008252209983766079\n",
      "Iteration: 9762/10000, Loss: 0.007146640680730343\n",
      "Iteration: 9763/10000, Loss: 0.010745727457106113\n",
      "Iteration: 9764/10000, Loss: 0.00927071925252676\n",
      "Iteration: 9765/10000, Loss: 0.009000223129987717\n",
      "Iteration: 9766/10000, Loss: 0.007878797128796577\n",
      "Iteration: 9767/10000, Loss: 0.006723245605826378\n",
      "Iteration: 9768/10000, Loss: 0.007889693602919579\n",
      "Iteration: 9769/10000, Loss: 0.0072694565169513226\n",
      "Iteration: 9770/10000, Loss: 0.010629885829985142\n",
      "Iteration: 9771/10000, Loss: 0.01016396377235651\n",
      "Iteration: 9772/10000, Loss: 0.010616758838295937\n",
      "Iteration: 9773/10000, Loss: 0.004980327095836401\n",
      "Iteration: 9774/10000, Loss: 0.010754842311143875\n",
      "Iteration: 9775/10000, Loss: 0.007085662800818682\n",
      "Iteration: 9776/10000, Loss: 0.0118833277374506\n",
      "Iteration: 9777/10000, Loss: 0.0073830438777804375\n",
      "Iteration: 9778/10000, Loss: 0.008194711059331894\n",
      "Iteration: 9779/10000, Loss: 0.008724361658096313\n",
      "Iteration: 9780/10000, Loss: 0.00872107781469822\n",
      "Iteration: 9781/10000, Loss: 0.005292931105941534\n",
      "Iteration: 9782/10000, Loss: 0.007420414127409458\n",
      "Iteration: 9783/10000, Loss: 0.011689825914800167\n",
      "Iteration: 9784/10000, Loss: 0.006284291390329599\n",
      "Iteration: 9785/10000, Loss: 0.011011268943548203\n",
      "Iteration: 9786/10000, Loss: 0.007650220766663551\n",
      "Iteration: 9787/10000, Loss: 0.0075008803978562355\n",
      "Iteration: 9788/10000, Loss: 0.008836531080305576\n",
      "Iteration: 9789/10000, Loss: 0.01080483291298151\n",
      "Iteration: 9790/10000, Loss: 0.00858386605978012\n",
      "Iteration: 9791/10000, Loss: 0.005037927068769932\n",
      "Iteration: 9792/10000, Loss: 0.010386179201304913\n",
      "Iteration: 9793/10000, Loss: 0.004426581785082817\n",
      "Iteration: 9794/10000, Loss: 0.010735905729234219\n",
      "Iteration: 9795/10000, Loss: 0.007749445736408234\n",
      "Iteration: 9796/10000, Loss: 0.006193879060447216\n",
      "Iteration: 9797/10000, Loss: 0.007167652249336243\n",
      "Iteration: 9798/10000, Loss: 0.006167842075228691\n",
      "Iteration: 9799/10000, Loss: 0.0075777447782456875\n",
      "Iteration: 9800/10000, Loss: 0.00947592779994011\n",
      "Average test loss:  0.0018\n",
      "Iteration: 9801/10000, Loss: 0.009248477406799793\n",
      "Iteration: 9802/10000, Loss: 0.005151216872036457\n",
      "Iteration: 9803/10000, Loss: 0.006584275979548693\n",
      "Iteration: 9804/10000, Loss: 0.008795970119535923\n",
      "Iteration: 9805/10000, Loss: 0.012893970124423504\n",
      "Iteration: 9806/10000, Loss: 0.01445559412240982\n",
      "Iteration: 9807/10000, Loss: 0.009104042313992977\n",
      "Iteration: 9808/10000, Loss: 0.011273265816271305\n",
      "Iteration: 9809/10000, Loss: 0.008123011328279972\n",
      "Iteration: 9810/10000, Loss: 0.010706507600843906\n",
      "Iteration: 9811/10000, Loss: 0.016683155670762062\n",
      "Iteration: 9812/10000, Loss: 0.0045482199639081955\n",
      "Iteration: 9813/10000, Loss: 0.005964068695902824\n",
      "Iteration: 9814/10000, Loss: 0.005818554665893316\n",
      "Iteration: 9815/10000, Loss: 0.007753334008157253\n",
      "Iteration: 9816/10000, Loss: 0.004415733739733696\n",
      "Iteration: 9817/10000, Loss: 0.010487274266779423\n",
      "Iteration: 9818/10000, Loss: 0.01433416549116373\n",
      "Iteration: 9819/10000, Loss: 0.012941518798470497\n",
      "Iteration: 9820/10000, Loss: 0.006769570987671614\n",
      "Iteration: 9821/10000, Loss: 0.00910732988268137\n",
      "Iteration: 9822/10000, Loss: 0.009291362948715687\n",
      "Iteration: 9823/10000, Loss: 0.00428814347833395\n",
      "Iteration: 9824/10000, Loss: 0.008494439534842968\n",
      "Iteration: 9825/10000, Loss: 0.007716324180364609\n",
      "Iteration: 9826/10000, Loss: 0.009536664932966232\n",
      "Iteration: 9827/10000, Loss: 0.00801296066492796\n",
      "Iteration: 9828/10000, Loss: 0.006485297344624996\n",
      "Iteration: 9829/10000, Loss: 0.00904407911002636\n",
      "Iteration: 9830/10000, Loss: 0.00837547704577446\n",
      "Iteration: 9831/10000, Loss: 0.005523311905562878\n",
      "Iteration: 9832/10000, Loss: 0.0077304113656282425\n",
      "Iteration: 9833/10000, Loss: 0.010784179903566837\n",
      "Iteration: 9834/10000, Loss: 0.007229149807244539\n",
      "Iteration: 9835/10000, Loss: 0.009562740102410316\n",
      "Iteration: 9836/10000, Loss: 0.00867440551519394\n",
      "Iteration: 9837/10000, Loss: 0.009017943404614925\n",
      "Iteration: 9838/10000, Loss: 0.007738377433270216\n",
      "Iteration: 9839/10000, Loss: 0.004966301377862692\n",
      "Iteration: 9840/10000, Loss: 0.006718273740261793\n",
      "Iteration: 9841/10000, Loss: 0.00695406598970294\n",
      "Iteration: 9842/10000, Loss: 0.00776932155713439\n",
      "Iteration: 9843/10000, Loss: 0.007657662499696016\n",
      "Iteration: 9844/10000, Loss: 0.011594734154641628\n",
      "Iteration: 9845/10000, Loss: 0.006393349263817072\n",
      "Iteration: 9846/10000, Loss: 0.007808574941009283\n",
      "Iteration: 9847/10000, Loss: 0.0077807107008993626\n",
      "Iteration: 9848/10000, Loss: 0.006155418232083321\n",
      "Iteration: 9849/10000, Loss: 0.009326232597231865\n",
      "Iteration: 9850/10000, Loss: 0.0116872014477849\n",
      "Iteration: 9851/10000, Loss: 0.008907577022910118\n",
      "Iteration: 9852/10000, Loss: 0.008428921923041344\n",
      "Iteration: 9853/10000, Loss: 0.009110587649047375\n",
      "Iteration: 9854/10000, Loss: 0.006793579552322626\n",
      "Iteration: 9855/10000, Loss: 0.007906210608780384\n",
      "Iteration: 9856/10000, Loss: 0.007776257582008839\n",
      "Iteration: 9857/10000, Loss: 0.00978784542530775\n",
      "Iteration: 9858/10000, Loss: 0.007668883539736271\n",
      "Iteration: 9859/10000, Loss: 0.005964357405900955\n",
      "Iteration: 9860/10000, Loss: 0.0083437105640769\n",
      "Iteration: 9861/10000, Loss: 0.00996194314211607\n",
      "Iteration: 9862/10000, Loss: 0.010475294664502144\n",
      "Iteration: 9863/10000, Loss: 0.007159056141972542\n",
      "Iteration: 9864/10000, Loss: 0.005520935170352459\n",
      "Iteration: 9865/10000, Loss: 0.0075256722047924995\n",
      "Iteration: 9866/10000, Loss: 0.007924143224954605\n",
      "Iteration: 9867/10000, Loss: 0.0054503800347447395\n",
      "Iteration: 9868/10000, Loss: 0.009957967326045036\n",
      "Iteration: 9869/10000, Loss: 0.009462888352572918\n",
      "Iteration: 9870/10000, Loss: 0.006429515779018402\n",
      "Iteration: 9871/10000, Loss: 0.008537487126886845\n",
      "Iteration: 9872/10000, Loss: 0.005132978316396475\n",
      "Iteration: 9873/10000, Loss: 0.007942584343254566\n",
      "Iteration: 9874/10000, Loss: 0.011113776825368404\n",
      "Iteration: 9875/10000, Loss: 0.00907588005065918\n",
      "Iteration: 9876/10000, Loss: 0.008918322622776031\n",
      "Iteration: 9877/10000, Loss: 0.009035203605890274\n",
      "Iteration: 9878/10000, Loss: 0.010465603321790695\n",
      "Iteration: 9879/10000, Loss: 0.006295778322964907\n",
      "Iteration: 9880/10000, Loss: 0.007840014062821865\n",
      "Iteration: 9881/10000, Loss: 0.011348523199558258\n",
      "Iteration: 9882/10000, Loss: 0.006887313909828663\n",
      "Iteration: 9883/10000, Loss: 0.008822946809232235\n",
      "Iteration: 9884/10000, Loss: 0.00561097776517272\n",
      "Iteration: 9885/10000, Loss: 0.01081911288201809\n",
      "Iteration: 9886/10000, Loss: 0.015696246176958084\n",
      "Iteration: 9887/10000, Loss: 0.008654037490487099\n",
      "Iteration: 9888/10000, Loss: 0.009154995903372765\n",
      "Iteration: 9889/10000, Loss: 0.009839622303843498\n",
      "Iteration: 9890/10000, Loss: 0.008938525803387165\n",
      "Iteration: 9891/10000, Loss: 0.0070001063868403435\n",
      "Iteration: 9892/10000, Loss: 0.007689941208809614\n",
      "Iteration: 9893/10000, Loss: 0.011007786728441715\n",
      "Iteration: 9894/10000, Loss: 0.006257812026888132\n",
      "Iteration: 9895/10000, Loss: 0.005644568242132664\n",
      "Iteration: 9896/10000, Loss: 0.008360755629837513\n",
      "Iteration: 9897/10000, Loss: 0.01106926891952753\n",
      "Iteration: 9898/10000, Loss: 0.008080665022134781\n",
      "Iteration: 9899/10000, Loss: 0.007967382669448853\n",
      "Iteration: 9900/10000, Loss: 0.008989977650344372\n",
      "Average test loss:  0.0038\n",
      "Iteration: 9901/10000, Loss: 0.014404237270355225\n",
      "Iteration: 9902/10000, Loss: 0.00645257905125618\n",
      "Iteration: 9903/10000, Loss: 0.008382090367376804\n",
      "Iteration: 9904/10000, Loss: 0.008147303946316242\n",
      "Iteration: 9905/10000, Loss: 0.009887856431305408\n",
      "Iteration: 9906/10000, Loss: 0.00802667997777462\n",
      "Iteration: 9907/10000, Loss: 0.009768239222466946\n",
      "Iteration: 9908/10000, Loss: 0.005135118495672941\n",
      "Iteration: 9909/10000, Loss: 0.011031132191419601\n",
      "Iteration: 9910/10000, Loss: 0.007933543063700199\n",
      "Iteration: 9911/10000, Loss: 0.009978637099266052\n",
      "Iteration: 9912/10000, Loss: 0.006605530623346567\n",
      "Iteration: 9913/10000, Loss: 0.0052513000555336475\n",
      "Iteration: 9914/10000, Loss: 0.012083228677511215\n",
      "Iteration: 9915/10000, Loss: 0.010075259953737259\n",
      "Iteration: 9916/10000, Loss: 0.00832967460155487\n",
      "Iteration: 9917/10000, Loss: 0.011435398831963539\n",
      "Iteration: 9918/10000, Loss: 0.007071570493280888\n",
      "Iteration: 9919/10000, Loss: 0.005432297941297293\n",
      "Iteration: 9920/10000, Loss: 0.013273493386805058\n",
      "Iteration: 9921/10000, Loss: 0.011245446279644966\n",
      "Iteration: 9922/10000, Loss: 0.012529072351753712\n",
      "Iteration: 9923/10000, Loss: 0.00880013220012188\n",
      "Iteration: 9924/10000, Loss: 0.006885289680212736\n",
      "Iteration: 9925/10000, Loss: 0.007274949923157692\n",
      "Iteration: 9926/10000, Loss: 0.0075932894833385944\n",
      "Iteration: 9927/10000, Loss: 0.006011105142533779\n",
      "Iteration: 9928/10000, Loss: 0.014285664074122906\n",
      "Iteration: 9929/10000, Loss: 0.009256765246391296\n",
      "Iteration: 9930/10000, Loss: 0.009606465697288513\n",
      "Iteration: 9931/10000, Loss: 0.010605929419398308\n",
      "Iteration: 9932/10000, Loss: 0.004859032575041056\n",
      "Iteration: 9933/10000, Loss: 0.006233991589397192\n",
      "Iteration: 9934/10000, Loss: 0.007653552107512951\n",
      "Iteration: 9935/10000, Loss: 0.0090138865634799\n",
      "Iteration: 9936/10000, Loss: 0.008835106156766415\n",
      "Iteration: 9937/10000, Loss: 0.009069840423762798\n",
      "Iteration: 9938/10000, Loss: 0.010750364512205124\n",
      "Iteration: 9939/10000, Loss: 0.006602256093174219\n",
      "Iteration: 9940/10000, Loss: 0.006537142675369978\n",
      "Iteration: 9941/10000, Loss: 0.00618395209312439\n",
      "Iteration: 9942/10000, Loss: 0.007769345305860043\n",
      "Iteration: 9943/10000, Loss: 0.006488213315606117\n",
      "Iteration: 9944/10000, Loss: 0.00879838690161705\n",
      "Iteration: 9945/10000, Loss: 0.007815191522240639\n",
      "Iteration: 9946/10000, Loss: 0.012758791446685791\n",
      "Iteration: 9947/10000, Loss: 0.011276867240667343\n",
      "Iteration: 9948/10000, Loss: 0.009919153526425362\n",
      "Iteration: 9949/10000, Loss: 0.005568686407059431\n",
      "Iteration: 9950/10000, Loss: 0.0077436137944459915\n",
      "Iteration: 9951/10000, Loss: 0.006725197192281485\n",
      "Iteration: 9952/10000, Loss: 0.00375819462351501\n",
      "Iteration: 9953/10000, Loss: 0.006285772193223238\n",
      "Iteration: 9954/10000, Loss: 0.006329224910587072\n",
      "Iteration: 9955/10000, Loss: 0.004125528037548065\n",
      "Iteration: 9956/10000, Loss: 0.005940347444266081\n",
      "Iteration: 9957/10000, Loss: 0.00815519504249096\n",
      "Iteration: 9958/10000, Loss: 0.008943252265453339\n",
      "Iteration: 9959/10000, Loss: 0.008473256602883339\n",
      "Iteration: 9960/10000, Loss: 0.007443984970450401\n",
      "Iteration: 9961/10000, Loss: 0.007367131300270557\n",
      "Iteration: 9962/10000, Loss: 0.00612059747800231\n",
      "Iteration: 9963/10000, Loss: 0.006576646119356155\n",
      "Iteration: 9964/10000, Loss: 0.010844328440725803\n",
      "Iteration: 9965/10000, Loss: 0.006369089242070913\n",
      "Iteration: 9966/10000, Loss: 0.008405881002545357\n",
      "Iteration: 9967/10000, Loss: 0.008563959039747715\n",
      "Iteration: 9968/10000, Loss: 0.005356288980692625\n",
      "Iteration: 9969/10000, Loss: 0.008255131542682648\n",
      "Iteration: 9970/10000, Loss: 0.006963470950722694\n",
      "Iteration: 9971/10000, Loss: 0.0053337146528065205\n",
      "Iteration: 9972/10000, Loss: 0.007316001690924168\n",
      "Iteration: 9973/10000, Loss: 0.008027582429349422\n",
      "Iteration: 9974/10000, Loss: 0.00903657078742981\n",
      "Iteration: 9975/10000, Loss: 0.004940061364322901\n",
      "Iteration: 9976/10000, Loss: 0.0071861292235553265\n",
      "Iteration: 9977/10000, Loss: 0.010545848868787289\n",
      "Iteration: 9978/10000, Loss: 0.009637797251343727\n",
      "Iteration: 9979/10000, Loss: 0.009957327507436275\n",
      "Iteration: 9980/10000, Loss: 0.008408952504396439\n",
      "Iteration: 9981/10000, Loss: 0.005989309400320053\n",
      "Iteration: 9982/10000, Loss: 0.009745149873197079\n",
      "Iteration: 9983/10000, Loss: 0.007211724761873484\n",
      "Iteration: 9984/10000, Loss: 0.01025096233934164\n",
      "Iteration: 9985/10000, Loss: 0.008194590918719769\n",
      "Iteration: 9986/10000, Loss: 0.011066238395869732\n",
      "Iteration: 9987/10000, Loss: 0.008930657058954239\n",
      "Iteration: 9988/10000, Loss: 0.008925865404307842\n",
      "Iteration: 9989/10000, Loss: 0.013966185972094536\n",
      "Iteration: 9990/10000, Loss: 0.008438018150627613\n",
      "Iteration: 9991/10000, Loss: 0.00728222168982029\n",
      "Iteration: 9992/10000, Loss: 0.008983314037322998\n",
      "Iteration: 9993/10000, Loss: 0.010875578969717026\n",
      "Iteration: 9994/10000, Loss: 0.008447638712823391\n",
      "Iteration: 9995/10000, Loss: 0.009092084132134914\n",
      "Iteration: 9996/10000, Loss: 0.006468649487942457\n",
      "Iteration: 9997/10000, Loss: 0.006979264318943024\n",
      "Iteration: 9998/10000, Loss: 0.00813213363289833\n",
      "Iteration: 9999/10000, Loss: 0.00872083380818367\n",
      "Iteration: 10000/10000, Loss: 0.008081414736807346\n",
      "Average test loss:  0.0031\n",
      "Training took 252.464s in total.\n"
     ]
    }
   ],
   "source": [
    "# CUDA device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {0}'.format(device))\n",
    "\n",
    "# Build the model\n",
    "num_class = 4\n",
    "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
    "model = model.to(device)\n",
    "params = list(model.parameters())\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "# Segmentation loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Datasets\n",
    "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
    "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
    "\n",
    "# Train the model\n",
    "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
    "num_iter = 10000\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "start = time.time()\n",
    "for it in range(1, 1 + num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = train_set.get_random_batch(train_batch_size)\n",
    "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    logits = model(images)\n",
    "\n",
    "\n",
    "    # Perform optimisation and print out the training loss\n",
    "    ### Insert your code ###\n",
    "    optimizer.zero_grad()  # Clear the gradients\n",
    "    loss = criterion(logits, labels)  # Calculate the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update the model parameters\n",
    "\n",
    "    print(f'Iteration: {it}/{num_iter}, Loss: {loss.item()}')\n",
    "    ### End of your code ###\n",
    "\n",
    "    # Evaluate\n",
    "    if it % 100 == 0:\n",
    "        model.eval()\n",
    "        # Disabling gradient calculation during reference to reduce memory consumption\n",
    "        with torch.no_grad():\n",
    "            # Evaluate on a batch of test images and print out the test loss\n",
    "            ### Insert your code ###\n",
    "            total_loss = 0\n",
    "            input_images, real_labels = test_set.get_random_batch(eval_batch_size)\n",
    "            input_images, real_labels = torch.from_numpy(input_images), torch.from_numpy(real_labels)\n",
    "            input_images, real_labels = input_images.to(device, dtype=torch.float32), real_labels.to(device, dtype=torch.long)\n",
    "            outputs = model(input_images)\n",
    "            \n",
    "            loss = criterion(outputs, real_labels)\n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / eval_batch_size\n",
    "            \n",
    "            print(f\"Average test loss: {avg_loss: .4f}\")\n",
    "            \n",
    "            \n",
    "            ### End of your code ###\n",
    "\n",
    "    # Save the model\n",
    "    if it % 5000 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yjxjGyb6yT"
   },
   "source": [
    "## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
    "\n",
    "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "wZeLE0qZjd2j"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "deploy_size = 4\n",
    "img_dim = (120, 120)\n",
    "\n",
    "model.eval()\n",
    "## Get a random set of 4 test images\n",
    "test_images, test_labels = test_set.get_random_batch(deploy_size)\n",
    "d_test_images = torch.from_numpy(test_images).to(device, dtype=torch.float32)\n",
    "\n",
    "## Perform inference on the test images\n",
    "with torch.no_grad():\n",
    "    outputs = model(d_test_images)\n",
    "    predicted_labels = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "## Visualize the test images, automated segmentation, and ground truth segmentation\n",
    "fig, grid = plt.subplots(deploy_size, 3, figsize=(10, 10))\n",
    "\n",
    "## Add titles\n",
    "titles = [\"Test Image\", \"Auto Segmentation\", \"Ground Truth Segmentation\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(grid[0], titles)]\n",
    "\n",
    "for i in range(deploy_size):\n",
    "    grid[i, 0].imshow(test_images[i, 0], cmap=cmap_image)\n",
    "    grid[i, 0].axis('off')\n",
    "\n",
    "    grid[i, 1].imshow(predicted_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 1].axis('off')\n",
    "\n",
    "    grid[i, 2].imshow(test_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "\n",
    "### End of your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj3Qusin_s_r"
   },
   "source": [
    "## 6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVwEtDKIdTRs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
