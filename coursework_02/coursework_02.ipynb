{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "# Coursework 2: Image segmentation\n",
    "\n",
    "In this coursework you will develop and train a convolutional neural network for brain tumour image segmentation. Please read both the text and the code in this notebook to get an idea what you are expected to implement. Pay attention to the missing code blocks that look like this:\n",
    "\n",
    "```\n",
    "### Insert your code ###\n",
    "...\n",
    "### End of your code ###\n",
    "```\n",
    "\n",
    "## What to do?\n",
    "\n",
    "* Complete and run the code using `jupyter-lab` or `jupyter-notebook` to get the results.\n",
    "\n",
    "* Export (File | S'ave and Export Notebook As...) the notebook as a PDF file, which contains your code, results and answers, and upload the PDF file onto [Scientia](https://scientia.doc.ic.ac.uk).\n",
    "\n",
    "* Instead of clicking the Export button, you can also run the following command instead: `jupyter nbconvert coursework.ipynb --to pdf`\n",
    "\n",
    "* If Jupyter complains about some problems in exporting, it is likely that pandoc (https://pandoc.org/installing.html) or latex is not installed, or their paths have not been included. You can install the relevant libraries and retry.\n",
    "\n",
    "* If Jupyter-lab does not work for you at the end, you can use Google Colab to write the code and export the PDF file.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "You need to install Jupyter-Lab (https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html) and other libraries used in this coursework, such as by running the command:\n",
    "`pip3 install [package_name]`\n",
    "\n",
    "## GPU resource\n",
    "\n",
    "The coursework is developed to be able to run on CPU, as all images have been pre-processed to be 2D and of a smaller size, compared to original 3D volumes.\n",
    "\n",
    "However, to save training time, you may want to use GPU. In that case, you can run this notebook on Google Colab. On Google Colab, go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware acceleartor. At the end, please still export everything and submit as a PDF file on Scientia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this tutorial.\n",
    "# However, if any other library is needed, please install by yourself.\n",
    "import tarfile\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## 1. Download and visualise the imaging dataset.\n",
    "\n",
    "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this tutorial, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
    "\n",
    "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
    "\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mt93oQ8xZkE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 16:39:34--  https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6020:18::a27d:4012\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz [following]\n",
      "--2024-02-26 16:39:35--  https://www.dropbox.com/s/raw/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com/cd/0/inline/COC14zLtEIhfC_I-HUua56-nhZvyOTK6Tvq85CfHJSLYPN9v4JSZ8-DsTXmIKBRItW5D8WyxeUer2n6XTQyqUgp7X9Dc0T3elJUB5QHkb5dNWtPhGNjiIzGSRayMX4qKFsk/file# [following]\n",
      "--2024-02-26 16:39:35--  https://uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com/cd/0/inline/COC14zLtEIhfC_I-HUua56-nhZvyOTK6Tvq85CfHJSLYPN9v4JSZ8-DsTXmIKBRItW5D8WyxeUer2n6XTQyqUgp7X9Dc0T3elJUB5QHkb5dNWtPhGNjiIzGSRayMX4qKFsk/file\n",
      "Resolving uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com (uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n",
      "Connecting to uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com (uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CODfRTE4SQJ9jzb6CEWZBCFE6bSVbAXb0PUc26ako3uQYOnDmOjLskUD_l381gKLCAPCKXfZEr3GFgwI7h9K6gjJkjBP3DGH7W77NTBLRXy6eEVpriBlwweY2nXFpQ5rY0Mm0hYWK1Avd5hfLEwqF80mOMrV1U0GnDlB-l7VVqoiKyom7KUBApHCVTT-XS8ZvK7eoXzCPH-biwNDwhbzoqmmnlNk3ufnF3zmo31aqFewTtCo-B9f5rqhjywlndOrNW6_IJo4yXcSRibMgu1R-EdTUP7MgMyYJ5DNAwaQZjkWSaFP3I4U87eDlZqTBp53dQsioptGucZXp5XRyYMwmI_zNjaCnJHm8NOWU1CRlPByFQ/file [following]\n",
      "--2024-02-26 16:39:36--  https://uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com/cd/0/inline2/CODfRTE4SQJ9jzb6CEWZBCFE6bSVbAXb0PUc26ako3uQYOnDmOjLskUD_l381gKLCAPCKXfZEr3GFgwI7h9K6gjJkjBP3DGH7W77NTBLRXy6eEVpriBlwweY2nXFpQ5rY0Mm0hYWK1Avd5hfLEwqF80mOMrV1U0GnDlB-l7VVqoiKyom7KUBApHCVTT-XS8ZvK7eoXzCPH-biwNDwhbzoqmmnlNk3ufnF3zmo31aqFewTtCo-B9f5rqhjywlndOrNW6_IJo4yXcSRibMgu1R-EdTUP7MgMyYJ5DNAwaQZjkWSaFP3I4U87eDlZqTBp53dQsioptGucZXp5XRyYMwmI_zNjaCnJHm8NOWU1CRlPByFQ/file\n",
      "Reusing existing connection to uc5c966918dbed04a903521315b0.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9251149 (8.8M) [application/octet-stream]\n",
      "Saving to: ‘Task01_BrainTumour_2D.tar.gz’\n",
      "\n",
      "Task01_BrainTumour_ 100%[===================>]   8.82M  23.4MB/s    in 0.4s    \n",
      "\n",
      "2024-02-26 16:39:37 (23.4 MB/s) - ‘Task01_BrainTumour_2D.tar.gz’ saved [9251149/9251149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://www.dropbox.com/s/zmytk2yu284af6t/Task01_BrainTumour_2D.tar.gz\n",
    "\n",
    "# Unzip the '.tar.gz' file to the current directory\n",
    "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
    "datafile.extractall()\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu_BTL0x6o5a"
   },
   "source": [
    "## Visualise a random set of 4 training images along with their label maps.\n",
    "\n",
    "Suggested colour map for brain MR image:\n",
    "```\n",
    "cmap = 'gray'\n",
    "```\n",
    "\n",
    "Suggested colour map for segmentation map:\n",
    "```\n",
    "cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3fgubCRC6m4k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16161/276553290.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(training_img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "cmap_image = \"gray\"\n",
    "cmap_segmentation = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
    "\n",
    "zs = [46, 62, 77, 93, 108, 124]\n",
    "IMAGES_FROM = 1\n",
    "IMAGES_TO = 483\n",
    "from random import randint\n",
    "from random import choice\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "\n",
    "# figure = plt.figure(figsize = (4, 2))\n",
    "# img_grid = ImageGrid(figure, 111, nrows_ncols = (4, 2), axes_pad =3)\n",
    "figure, img_grid = plt.subplots(nrows=4, ncols=2, figsize = (5, 10))\n",
    "\n",
    "titles = [\"Training Image\", \"Label\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(img_grid[0], titles)]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"./Task01_BrainTumour_2D/training_images/\", topdown = False):\n",
    "  chosen = []\n",
    "  for _ in range(4):\n",
    "    chosen.append(choice(files))\n",
    "\n",
    "path = \"Task01_BrainTumour_2D\"\n",
    "training_path = \"training_images\"\n",
    "label_path = \"training_labels\"\n",
    "\n",
    "for i, img_path in enumerate(chosen):\n",
    "  training_img_path = f\"{path}/{training_path}/{img_path}\"\n",
    "  label_img_path = f\"{path}/{label_path}/{img_path}\"\n",
    "  \n",
    "  ## Training Image\n",
    "  img = imageio.imread(training_img_path)\n",
    "  img_grid[i, 0].imshow(img, cmap = cmap_image)\n",
    "  img_grid[i, 0].axis(\"off\")\n",
    "  \n",
    "  ## Label Map\n",
    "  label_img= imageio.v3.imread(label_img_path)\n",
    "  \n",
    "  img_grid[i, 1].imshow(label_img, cmap = cmap_segmentation)\n",
    "  img_grid[i, 1].axis(\"off\")\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xWGT3KaML-D"
   },
   "source": [
    "## 2. Implement a dataset class.\n",
    "\n",
    "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6p6wFZ3na5z9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalise_intensity(image, thres_roi=1.0):\n",
    "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
    "    # ROI defines the image foreground\n",
    "    val_l = np.percentile(image, thres_roi)\n",
    "    roi = (image >= val_l)\n",
    "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
    "    eps = 1e-6\n",
    "    image2 = (image - mu) / (sigma + eps)\n",
    "    return image2\n",
    "\n",
    "\n",
    "class BrainImageSet(Dataset):\n",
    "    \"\"\" Brain image set \"\"\"\n",
    "    def __init__(self, image_path, label_path='', deploy=False):\n",
    "        self.image_path = image_path\n",
    "        self.deploy = deploy\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        image_names = sorted(os.listdir(image_path))\n",
    "        for image_name in image_names:\n",
    "            # Read the image\n",
    "            image = imageio.v3.imread(os.path.join(image_path, image_name))\n",
    "            self.images += [image]\n",
    "\n",
    "            # Read the label map\n",
    "            if not self.deploy:\n",
    "                label_name = os.path.join(label_path, image_name)\n",
    "                label = imageio.v3.imread(label_name)\n",
    "                self.labels += [label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get an image and perform intensity normalisation\n",
    "        # Dimension: XY\n",
    "        image = normalise_intensity(self.images[idx])\n",
    "\n",
    "        # Get its label map\n",
    "        # Dimension: XY\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_random_batch(self, batch_size):\n",
    "        # Get a batch of paired images and label maps\n",
    "        # Dimension of images: NCXY\n",
    "        # Dimension of labels: NXY\n",
    "        images, labels = [], []\n",
    "        \n",
    "        ### Insert your code ###\n",
    "        \n",
    "        # seed = np.random.default_rng().integers(low=0, high=2048) # arbitratry range can be changed\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "          i, l = random.choice(self)\n",
    "          images.append(i)\n",
    "          labels.append(l)\n",
    "        \n",
    "        \n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        ## add the greyscale colour channel so conv2d works correctly\n",
    "        images = np.reshape(images, (batch_size, 1, images.shape[1], images.shape[2])) \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "        ### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4ZpawDNmwu"
   },
   "source": [
    "## 3. Build a U-net architecture.\n",
    "\n",
    "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
    "\n",
    "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n",
    "\n",
    "For the first convolutional layer, you can start with 16 filters. We have implemented the encoder path. Please complete the decoder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IMPmBZVGb1aI"
   },
   "outputs": [],
   "source": [
    "\"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        ### Insert your code ###\n",
    "        n //= 2 # 64\n",
    "        self.upconv5 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 128 -> 64 ch (x2 dims)\n",
    "        self.conv5 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        n //= 2 # 32\n",
    "        self.upconv6 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2 ) # 64 -> 32 ch (x2 dims)\n",
    "        self.conv6 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2, n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        n //= 2 # 16\n",
    "        self.upconv7 = nn.ConvTranspose2d(n * 2, n, kernel_size=2, stride=2) # 32 -> 16 ch (x2 dims)\n",
    "        self.conv7 = nn.Sequential(\n",
    "          nn.Conv2d(n * 2 , n, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "          nn.BatchNorm2d(n),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(n, output_channel, kernel_size=1) ## final 1x1 conv\n",
    "        )\n",
    "        ### End of your code ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the convolutional operators defined above to build the U-net\n",
    "        # The encoder part is already done for you.\n",
    "        # You need to complete the decoder part.\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        conv1_skip = x\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        conv2_skip = x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        conv3_skip = x\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        # Decoder\n",
    "        ### Insert your code ###\n",
    "        x = self.conv5(torch.cat([self.upconv5(x), conv3_skip], dim=1))\n",
    "        \n",
    "        x = self.conv6(torch.cat([self.upconv6(x), conv2_skip], dim=1))\n",
    "        \n",
    "        x = self.conv7(torch.cat([self.upconv7(x), conv1_skip], dim=1))\n",
    "        \n",
    "        ### End of your code ###\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcNWZS08d47P"
   },
   "source": [
    "## 4. Train the segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xaGGkKQndIaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Iteration: 1/10000, Loss: 1.613095998764038\n",
      "Iteration: 2/10000, Loss: 1.541533350944519\n",
      "Iteration: 3/10000, Loss: 1.517272710800171\n",
      "Iteration: 4/10000, Loss: 1.4780787229537964\n",
      "Iteration: 5/10000, Loss: 1.4514315128326416\n",
      "Iteration: 6/10000, Loss: 1.4265904426574707\n",
      "Iteration: 7/10000, Loss: 1.3958195447921753\n",
      "Iteration: 8/10000, Loss: 1.3737926483154297\n",
      "Iteration: 9/10000, Loss: 1.3528491258621216\n",
      "Iteration: 10/10000, Loss: 1.332755208015442\n",
      "Iteration: 11/10000, Loss: 1.3080099821090698\n",
      "Iteration: 12/10000, Loss: 1.295964002609253\n",
      "Iteration: 13/10000, Loss: 1.2742458581924438\n",
      "Iteration: 14/10000, Loss: 1.245286226272583\n",
      "Iteration: 15/10000, Loss: 1.2301188707351685\n",
      "Iteration: 16/10000, Loss: 1.220606803894043\n",
      "Iteration: 17/10000, Loss: 1.2032194137573242\n",
      "Iteration: 18/10000, Loss: 1.1892707347869873\n",
      "Iteration: 19/10000, Loss: 1.1779255867004395\n",
      "Iteration: 20/10000, Loss: 1.15779447555542\n",
      "Iteration: 21/10000, Loss: 1.1496999263763428\n",
      "Iteration: 22/10000, Loss: 1.1456364393234253\n",
      "Iteration: 23/10000, Loss: 1.1318830251693726\n",
      "Iteration: 24/10000, Loss: 1.1417205333709717\n",
      "Iteration: 25/10000, Loss: 1.1161847114562988\n",
      "Iteration: 26/10000, Loss: 1.1062906980514526\n",
      "Iteration: 27/10000, Loss: 1.0875589847564697\n",
      "Iteration: 28/10000, Loss: 1.0746806859970093\n",
      "Iteration: 29/10000, Loss: 1.0771355628967285\n",
      "Iteration: 30/10000, Loss: 1.067725658416748\n",
      "Iteration: 31/10000, Loss: 1.0579839944839478\n",
      "Iteration: 32/10000, Loss: 1.042951226234436\n",
      "Iteration: 33/10000, Loss: 1.0412664413452148\n",
      "Iteration: 34/10000, Loss: 1.0239769220352173\n",
      "Iteration: 35/10000, Loss: 1.0230191946029663\n",
      "Iteration: 36/10000, Loss: 1.0096038579940796\n",
      "Iteration: 37/10000, Loss: 1.0022175312042236\n",
      "Iteration: 38/10000, Loss: 0.9920639395713806\n",
      "Iteration: 39/10000, Loss: 0.9901145696640015\n",
      "Iteration: 40/10000, Loss: 0.987026572227478\n",
      "Iteration: 41/10000, Loss: 0.9810642004013062\n",
      "Iteration: 42/10000, Loss: 0.975017786026001\n",
      "Iteration: 43/10000, Loss: 0.9640675783157349\n",
      "Iteration: 44/10000, Loss: 0.937600314617157\n",
      "Iteration: 45/10000, Loss: 0.9340705275535583\n",
      "Iteration: 46/10000, Loss: 0.9346098303794861\n",
      "Iteration: 47/10000, Loss: 0.9158453345298767\n",
      "Iteration: 48/10000, Loss: 0.9083226323127747\n",
      "Iteration: 49/10000, Loss: 0.8925066590309143\n",
      "Iteration: 50/10000, Loss: 0.8843282461166382\n",
      "Iteration: 51/10000, Loss: 0.8710014224052429\n",
      "Iteration: 52/10000, Loss: 0.8515900373458862\n",
      "Iteration: 53/10000, Loss: 0.8626856803894043\n",
      "Iteration: 54/10000, Loss: 0.8485632538795471\n",
      "Iteration: 55/10000, Loss: 0.8358228206634521\n",
      "Iteration: 56/10000, Loss: 0.8417569398880005\n",
      "Iteration: 57/10000, Loss: 0.8336920142173767\n",
      "Iteration: 58/10000, Loss: 0.8101171255111694\n",
      "Iteration: 59/10000, Loss: 0.8096299767494202\n",
      "Iteration: 60/10000, Loss: 0.7978982329368591\n",
      "Iteration: 61/10000, Loss: 0.7891250848770142\n",
      "Iteration: 62/10000, Loss: 0.809167742729187\n",
      "Iteration: 63/10000, Loss: 0.7852777242660522\n",
      "Iteration: 64/10000, Loss: 0.7871699929237366\n",
      "Iteration: 65/10000, Loss: 0.7720623016357422\n",
      "Iteration: 66/10000, Loss: 0.7636877298355103\n",
      "Iteration: 67/10000, Loss: 0.7765541672706604\n",
      "Iteration: 68/10000, Loss: 0.754626452922821\n",
      "Iteration: 69/10000, Loss: 0.7510120868682861\n",
      "Iteration: 70/10000, Loss: 0.7512483596801758\n",
      "Iteration: 71/10000, Loss: 0.723552405834198\n",
      "Iteration: 72/10000, Loss: 0.7420337200164795\n",
      "Iteration: 73/10000, Loss: 0.7327403426170349\n",
      "Iteration: 74/10000, Loss: 0.7101494073867798\n",
      "Iteration: 75/10000, Loss: 0.7035103440284729\n",
      "Iteration: 76/10000, Loss: 0.7001668810844421\n",
      "Iteration: 77/10000, Loss: 0.6874606609344482\n",
      "Iteration: 78/10000, Loss: 0.6769347190856934\n",
      "Iteration: 79/10000, Loss: 0.685278058052063\n",
      "Iteration: 80/10000, Loss: 0.6758785843849182\n",
      "Iteration: 81/10000, Loss: 0.6786800622940063\n",
      "Iteration: 82/10000, Loss: 0.6650751233100891\n",
      "Iteration: 83/10000, Loss: 0.6710220575332642\n",
      "Iteration: 84/10000, Loss: 0.6550936698913574\n",
      "Iteration: 85/10000, Loss: 0.6482952833175659\n",
      "Iteration: 86/10000, Loss: 0.6459763646125793\n",
      "Iteration: 87/10000, Loss: 0.6383563280105591\n",
      "Iteration: 88/10000, Loss: 0.6297200918197632\n",
      "Iteration: 89/10000, Loss: 0.6311225295066833\n",
      "Iteration: 90/10000, Loss: 0.6302164793014526\n",
      "Iteration: 91/10000, Loss: 0.6100698709487915\n",
      "Iteration: 92/10000, Loss: 0.6132103204727173\n",
      "Iteration: 93/10000, Loss: 0.5986067652702332\n",
      "Iteration: 94/10000, Loss: 0.603976309299469\n",
      "Iteration: 95/10000, Loss: 0.615869402885437\n",
      "Iteration: 96/10000, Loss: 0.5834730267524719\n",
      "Iteration: 97/10000, Loss: 0.5790730118751526\n",
      "Iteration: 98/10000, Loss: 0.5756707787513733\n",
      "Iteration: 99/10000, Loss: 0.5660086274147034\n",
      "Iteration: 100/10000, Loss: 0.5685879588127136\n",
      "Average test loss:  0.0381\n",
      "Iteration: 101/10000, Loss: 0.5646853446960449\n",
      "Iteration: 102/10000, Loss: 0.5468220114707947\n",
      "Iteration: 103/10000, Loss: 0.5382859110832214\n",
      "Iteration: 104/10000, Loss: 0.552919864654541\n",
      "Iteration: 105/10000, Loss: 0.5405882596969604\n",
      "Iteration: 106/10000, Loss: 0.5447190999984741\n",
      "Iteration: 107/10000, Loss: 0.5173321962356567\n",
      "Iteration: 108/10000, Loss: 0.5309586524963379\n",
      "Iteration: 109/10000, Loss: 0.5392853021621704\n",
      "Iteration: 110/10000, Loss: 0.5228539109230042\n",
      "Iteration: 111/10000, Loss: 0.5247655510902405\n",
      "Iteration: 112/10000, Loss: 0.5231344699859619\n",
      "Iteration: 113/10000, Loss: 0.5072612166404724\n",
      "Iteration: 114/10000, Loss: 0.5137925744056702\n",
      "Iteration: 115/10000, Loss: 0.4899102747440338\n",
      "Iteration: 116/10000, Loss: 0.4956716299057007\n",
      "Iteration: 117/10000, Loss: 0.5103923678398132\n",
      "Iteration: 118/10000, Loss: 0.47214972972869873\n",
      "Iteration: 119/10000, Loss: 0.48137375712394714\n",
      "Iteration: 120/10000, Loss: 0.4715561270713806\n",
      "Iteration: 121/10000, Loss: 0.4802579879760742\n",
      "Iteration: 122/10000, Loss: 0.46915075182914734\n",
      "Iteration: 123/10000, Loss: 0.4649945795536041\n",
      "Iteration: 124/10000, Loss: 0.43801048398017883\n",
      "Iteration: 125/10000, Loss: 0.46061351895332336\n",
      "Iteration: 126/10000, Loss: 0.4331625998020172\n",
      "Iteration: 127/10000, Loss: 0.4441675841808319\n",
      "Iteration: 128/10000, Loss: 0.44811439514160156\n",
      "Iteration: 129/10000, Loss: 0.44266459345817566\n",
      "Iteration: 130/10000, Loss: 0.46063297986984253\n",
      "Iteration: 131/10000, Loss: 0.4108726382255554\n",
      "Iteration: 132/10000, Loss: 0.4334244430065155\n",
      "Iteration: 133/10000, Loss: 0.41526687145233154\n",
      "Iteration: 134/10000, Loss: 0.432792991399765\n",
      "Iteration: 135/10000, Loss: 0.4323693811893463\n",
      "Iteration: 136/10000, Loss: 0.40279537439346313\n",
      "Iteration: 137/10000, Loss: 0.40216729044914246\n",
      "Iteration: 138/10000, Loss: 0.39791059494018555\n",
      "Iteration: 139/10000, Loss: 0.38811954855918884\n",
      "Iteration: 140/10000, Loss: 0.4074370265007019\n",
      "Iteration: 141/10000, Loss: 0.40439507365226746\n",
      "Iteration: 142/10000, Loss: 0.3874768018722534\n",
      "Iteration: 143/10000, Loss: 0.38764292001724243\n",
      "Iteration: 144/10000, Loss: 0.38869723677635193\n",
      "Iteration: 145/10000, Loss: 0.37163421511650085\n",
      "Iteration: 146/10000, Loss: 0.39850786328315735\n",
      "Iteration: 147/10000, Loss: 0.3668489456176758\n",
      "Iteration: 148/10000, Loss: 0.38829463720321655\n",
      "Iteration: 149/10000, Loss: 0.3618605434894562\n",
      "Iteration: 150/10000, Loss: 0.3910951316356659\n",
      "Iteration: 151/10000, Loss: 0.3493604063987732\n",
      "Iteration: 152/10000, Loss: 0.34087592363357544\n",
      "Iteration: 153/10000, Loss: 0.3277413249015808\n",
      "Iteration: 154/10000, Loss: 0.32905441522598267\n",
      "Iteration: 155/10000, Loss: 0.358573853969574\n",
      "Iteration: 156/10000, Loss: 0.3453211784362793\n",
      "Iteration: 157/10000, Loss: 0.3492644727230072\n",
      "Iteration: 158/10000, Loss: 0.3315028250217438\n",
      "Iteration: 159/10000, Loss: 0.3374042809009552\n",
      "Iteration: 160/10000, Loss: 0.3281935751438141\n",
      "Iteration: 161/10000, Loss: 0.3377814292907715\n",
      "Iteration: 162/10000, Loss: 0.31380078196525574\n",
      "Iteration: 163/10000, Loss: 0.3181696832180023\n",
      "Iteration: 164/10000, Loss: 0.3233630061149597\n",
      "Iteration: 165/10000, Loss: 0.3360871970653534\n",
      "Iteration: 166/10000, Loss: 0.3027660548686981\n",
      "Iteration: 167/10000, Loss: 0.3113868236541748\n",
      "Iteration: 168/10000, Loss: 0.31590065360069275\n",
      "Iteration: 169/10000, Loss: 0.3307490944862366\n",
      "Iteration: 170/10000, Loss: 0.3171551525592804\n",
      "Iteration: 171/10000, Loss: 0.3072621524333954\n",
      "Iteration: 172/10000, Loss: 0.29302117228507996\n",
      "Iteration: 173/10000, Loss: 0.3008366525173187\n",
      "Iteration: 174/10000, Loss: 0.3168497383594513\n",
      "Iteration: 175/10000, Loss: 0.28722038865089417\n",
      "Iteration: 176/10000, Loss: 0.2706313133239746\n",
      "Iteration: 177/10000, Loss: 0.3012753427028656\n",
      "Iteration: 178/10000, Loss: 0.2959843575954437\n",
      "Iteration: 179/10000, Loss: 0.2846205234527588\n",
      "Iteration: 180/10000, Loss: 0.27165254950523376\n",
      "Iteration: 181/10000, Loss: 0.2820282280445099\n",
      "Iteration: 182/10000, Loss: 0.27584999799728394\n",
      "Iteration: 183/10000, Loss: 0.2557566165924072\n",
      "Iteration: 184/10000, Loss: 0.27006831765174866\n",
      "Iteration: 185/10000, Loss: 0.26020845770835876\n",
      "Iteration: 186/10000, Loss: 0.26723891496658325\n",
      "Iteration: 187/10000, Loss: 0.2590795159339905\n",
      "Iteration: 188/10000, Loss: 0.2738191485404968\n",
      "Iteration: 189/10000, Loss: 0.25694191455841064\n",
      "Iteration: 190/10000, Loss: 0.25394952297210693\n",
      "Iteration: 191/10000, Loss: 0.255825400352478\n",
      "Iteration: 192/10000, Loss: 0.2727256119251251\n",
      "Iteration: 193/10000, Loss: 0.26709163188934326\n",
      "Iteration: 194/10000, Loss: 0.28873297572135925\n",
      "Iteration: 195/10000, Loss: 0.2559989094734192\n",
      "Iteration: 196/10000, Loss: 0.2369438111782074\n",
      "Iteration: 197/10000, Loss: 0.2733888626098633\n",
      "Iteration: 198/10000, Loss: 0.24196511507034302\n",
      "Iteration: 199/10000, Loss: 0.2353433519601822\n",
      "Iteration: 200/10000, Loss: 0.24324506521224976\n",
      "Average test loss:  0.0149\n",
      "Iteration: 201/10000, Loss: 0.2557636797428131\n",
      "Iteration: 202/10000, Loss: 0.244627445936203\n",
      "Iteration: 203/10000, Loss: 0.2528466582298279\n",
      "Iteration: 204/10000, Loss: 0.26640933752059937\n",
      "Iteration: 205/10000, Loss: 0.27867066860198975\n",
      "Iteration: 206/10000, Loss: 0.26058900356292725\n",
      "Iteration: 207/10000, Loss: 0.23385089635849\n",
      "Iteration: 208/10000, Loss: 0.23610925674438477\n",
      "Iteration: 209/10000, Loss: 0.2326829582452774\n",
      "Iteration: 210/10000, Loss: 0.2247910499572754\n",
      "Iteration: 211/10000, Loss: 0.23751100897789001\n",
      "Iteration: 212/10000, Loss: 0.25544121861457825\n",
      "Iteration: 213/10000, Loss: 0.24417869746685028\n",
      "Iteration: 214/10000, Loss: 0.2639666497707367\n",
      "Iteration: 215/10000, Loss: 0.2252548336982727\n",
      "Iteration: 216/10000, Loss: 0.23555923998355865\n",
      "Iteration: 217/10000, Loss: 0.2224707007408142\n",
      "Iteration: 218/10000, Loss: 0.22812217473983765\n",
      "Iteration: 219/10000, Loss: 0.2109500765800476\n",
      "Iteration: 220/10000, Loss: 0.21619370579719543\n",
      "Iteration: 221/10000, Loss: 0.2237674593925476\n",
      "Iteration: 222/10000, Loss: 0.21870045363903046\n",
      "Iteration: 223/10000, Loss: 0.21785041689872742\n",
      "Iteration: 224/10000, Loss: 0.1964331418275833\n",
      "Iteration: 225/10000, Loss: 0.2016409933567047\n",
      "Iteration: 226/10000, Loss: 0.19897082448005676\n",
      "Iteration: 227/10000, Loss: 0.22646810114383698\n",
      "Iteration: 228/10000, Loss: 0.22799520194530487\n",
      "Iteration: 229/10000, Loss: 0.18001987040042877\n",
      "Iteration: 230/10000, Loss: 0.19794344902038574\n",
      "Iteration: 231/10000, Loss: 0.19216328859329224\n",
      "Iteration: 232/10000, Loss: 0.19418266415596008\n",
      "Iteration: 233/10000, Loss: 0.20893973112106323\n",
      "Iteration: 234/10000, Loss: 0.2002037912607193\n",
      "Iteration: 235/10000, Loss: 0.18638238310813904\n",
      "Iteration: 236/10000, Loss: 0.18507055938243866\n",
      "Iteration: 237/10000, Loss: 0.1891401708126068\n",
      "Iteration: 238/10000, Loss: 0.18567295372486115\n",
      "Iteration: 239/10000, Loss: 0.19215518236160278\n",
      "Iteration: 240/10000, Loss: 0.21752464771270752\n",
      "Iteration: 241/10000, Loss: 0.17770066857337952\n",
      "Iteration: 242/10000, Loss: 0.1986643671989441\n",
      "Iteration: 243/10000, Loss: 0.17891840636730194\n",
      "Iteration: 244/10000, Loss: 0.1801079660654068\n",
      "Iteration: 245/10000, Loss: 0.17755958437919617\n",
      "Iteration: 246/10000, Loss: 0.17617714405059814\n",
      "Iteration: 247/10000, Loss: 0.17323902249336243\n",
      "Iteration: 248/10000, Loss: 0.17881262302398682\n",
      "Iteration: 249/10000, Loss: 0.16417136788368225\n",
      "Iteration: 250/10000, Loss: 0.1603240668773651\n",
      "Iteration: 251/10000, Loss: 0.18808810412883759\n",
      "Iteration: 252/10000, Loss: 0.17104022204875946\n",
      "Iteration: 253/10000, Loss: 0.20863229036331177\n",
      "Iteration: 254/10000, Loss: 0.16541531682014465\n",
      "Iteration: 255/10000, Loss: 0.17681162059307098\n",
      "Iteration: 256/10000, Loss: 0.1576509326696396\n",
      "Iteration: 257/10000, Loss: 0.1887184977531433\n",
      "Iteration: 258/10000, Loss: 0.18998049199581146\n",
      "Iteration: 259/10000, Loss: 0.18654510378837585\n",
      "Iteration: 260/10000, Loss: 0.18318894505500793\n",
      "Iteration: 261/10000, Loss: 0.16433405876159668\n",
      "Iteration: 262/10000, Loss: 0.17142927646636963\n",
      "Iteration: 263/10000, Loss: 0.15553870797157288\n",
      "Iteration: 264/10000, Loss: 0.1777980476617813\n",
      "Iteration: 265/10000, Loss: 0.1666964590549469\n",
      "Iteration: 266/10000, Loss: 0.17780743539333344\n",
      "Iteration: 267/10000, Loss: 0.16513831913471222\n",
      "Iteration: 268/10000, Loss: 0.16099436581134796\n",
      "Iteration: 269/10000, Loss: 0.1571415513753891\n",
      "Iteration: 270/10000, Loss: 0.17500755190849304\n",
      "Iteration: 271/10000, Loss: 0.15980257093906403\n",
      "Iteration: 272/10000, Loss: 0.14747098088264465\n",
      "Iteration: 273/10000, Loss: 0.1717720478773117\n",
      "Iteration: 274/10000, Loss: 0.16923844814300537\n",
      "Iteration: 275/10000, Loss: 0.16913677752017975\n",
      "Iteration: 276/10000, Loss: 0.15731914341449738\n",
      "Iteration: 277/10000, Loss: 0.1776888370513916\n",
      "Iteration: 278/10000, Loss: 0.16584691405296326\n",
      "Iteration: 279/10000, Loss: 0.15811291337013245\n",
      "Iteration: 280/10000, Loss: 0.15644359588623047\n",
      "Iteration: 281/10000, Loss: 0.14642614126205444\n",
      "Iteration: 282/10000, Loss: 0.15407143533229828\n",
      "Iteration: 283/10000, Loss: 0.1487760990858078\n",
      "Iteration: 284/10000, Loss: 0.14020222425460815\n",
      "Iteration: 285/10000, Loss: 0.15226957201957703\n",
      "Iteration: 286/10000, Loss: 0.14178192615509033\n",
      "Iteration: 287/10000, Loss: 0.17289084196090698\n",
      "Iteration: 288/10000, Loss: 0.15586823225021362\n",
      "Iteration: 289/10000, Loss: 0.14345096051692963\n",
      "Iteration: 290/10000, Loss: 0.14287015795707703\n",
      "Iteration: 291/10000, Loss: 0.14898602664470673\n",
      "Iteration: 292/10000, Loss: 0.16328759491443634\n",
      "Iteration: 293/10000, Loss: 0.1366511583328247\n",
      "Iteration: 294/10000, Loss: 0.16009044647216797\n",
      "Iteration: 295/10000, Loss: 0.13634343445301056\n",
      "Iteration: 296/10000, Loss: 0.1326272040605545\n",
      "Iteration: 297/10000, Loss: 0.1483045220375061\n",
      "Iteration: 298/10000, Loss: 0.14291612803936005\n",
      "Iteration: 299/10000, Loss: 0.11957953870296478\n",
      "Iteration: 300/10000, Loss: 0.14886681735515594\n",
      "Average test loss:  0.0078\n",
      "Iteration: 301/10000, Loss: 0.14728279411792755\n",
      "Iteration: 302/10000, Loss: 0.1502765715122223\n",
      "Iteration: 303/10000, Loss: 0.14147186279296875\n",
      "Iteration: 304/10000, Loss: 0.1527836173772812\n",
      "Iteration: 305/10000, Loss: 0.13760995864868164\n",
      "Iteration: 306/10000, Loss: 0.14788129925727844\n",
      "Iteration: 307/10000, Loss: 0.16142810881137848\n",
      "Iteration: 308/10000, Loss: 0.1548483818769455\n",
      "Iteration: 309/10000, Loss: 0.13342320919036865\n",
      "Iteration: 310/10000, Loss: 0.12787330150604248\n",
      "Iteration: 311/10000, Loss: 0.10913260281085968\n",
      "Iteration: 312/10000, Loss: 0.11943520605564117\n",
      "Iteration: 313/10000, Loss: 0.13787706196308136\n",
      "Iteration: 314/10000, Loss: 0.11551684141159058\n",
      "Iteration: 315/10000, Loss: 0.1437198668718338\n",
      "Iteration: 316/10000, Loss: 0.11850346624851227\n",
      "Iteration: 317/10000, Loss: 0.1518985480070114\n",
      "Iteration: 318/10000, Loss: 0.14418862760066986\n",
      "Iteration: 319/10000, Loss: 0.15208914875984192\n",
      "Iteration: 320/10000, Loss: 0.11536333709955215\n",
      "Iteration: 321/10000, Loss: 0.12828895449638367\n",
      "Iteration: 322/10000, Loss: 0.13896696269512177\n",
      "Iteration: 323/10000, Loss: 0.144849494099617\n",
      "Iteration: 324/10000, Loss: 0.14981397986412048\n",
      "Iteration: 325/10000, Loss: 0.13696084916591644\n",
      "Iteration: 326/10000, Loss: 0.11051853746175766\n",
      "Iteration: 327/10000, Loss: 0.12195694446563721\n",
      "Iteration: 328/10000, Loss: 0.13457196950912476\n",
      "Iteration: 329/10000, Loss: 0.12250539660453796\n",
      "Iteration: 330/10000, Loss: 0.12739554047584534\n",
      "Iteration: 331/10000, Loss: 0.12528009712696075\n",
      "Iteration: 332/10000, Loss: 0.12086989730596542\n",
      "Iteration: 333/10000, Loss: 0.1411658078432083\n",
      "Iteration: 334/10000, Loss: 0.130197212100029\n",
      "Iteration: 335/10000, Loss: 0.13095372915267944\n",
      "Iteration: 336/10000, Loss: 0.12855511903762817\n",
      "Iteration: 337/10000, Loss: 0.13848812878131866\n",
      "Iteration: 338/10000, Loss: 0.10758598148822784\n",
      "Iteration: 339/10000, Loss: 0.11126602441072464\n",
      "Iteration: 340/10000, Loss: 0.12747140228748322\n",
      "Iteration: 341/10000, Loss: 0.15229928493499756\n",
      "Iteration: 342/10000, Loss: 0.10494037717580795\n",
      "Iteration: 343/10000, Loss: 0.11234668642282486\n",
      "Iteration: 344/10000, Loss: 0.1110968366265297\n",
      "Iteration: 345/10000, Loss: 0.1470026671886444\n",
      "Iteration: 346/10000, Loss: 0.1302340179681778\n",
      "Iteration: 347/10000, Loss: 0.10578309744596481\n",
      "Iteration: 348/10000, Loss: 0.11477074027061462\n",
      "Iteration: 349/10000, Loss: 0.12083321809768677\n",
      "Iteration: 350/10000, Loss: 0.13283482193946838\n",
      "Iteration: 351/10000, Loss: 0.097301185131073\n",
      "Iteration: 352/10000, Loss: 0.11092644929885864\n",
      "Iteration: 353/10000, Loss: 0.11426637321710587\n",
      "Iteration: 354/10000, Loss: 0.11256342381238937\n",
      "Iteration: 355/10000, Loss: 0.13359041512012482\n",
      "Iteration: 356/10000, Loss: 0.10603870451450348\n",
      "Iteration: 357/10000, Loss: 0.10445981472730637\n",
      "Iteration: 358/10000, Loss: 0.11012015491724014\n",
      "Iteration: 359/10000, Loss: 0.10133592039346695\n",
      "Iteration: 360/10000, Loss: 0.10949196666479111\n",
      "Iteration: 361/10000, Loss: 0.11143077909946442\n",
      "Iteration: 362/10000, Loss: 0.11902592331171036\n",
      "Iteration: 363/10000, Loss: 0.12461822479963303\n",
      "Iteration: 364/10000, Loss: 0.09910553693771362\n",
      "Iteration: 365/10000, Loss: 0.0914604663848877\n",
      "Iteration: 366/10000, Loss: 0.12586583197116852\n",
      "Iteration: 367/10000, Loss: 0.10660413652658463\n",
      "Iteration: 368/10000, Loss: 0.10708774626255035\n",
      "Iteration: 369/10000, Loss: 0.13811126351356506\n",
      "Iteration: 370/10000, Loss: 0.12848986685276031\n",
      "Iteration: 371/10000, Loss: 0.13441473245620728\n",
      "Iteration: 372/10000, Loss: 0.12060526013374329\n",
      "Iteration: 373/10000, Loss: 0.10361012816429138\n",
      "Iteration: 374/10000, Loss: 0.12196995317935944\n",
      "Iteration: 375/10000, Loss: 0.115055613219738\n",
      "Iteration: 376/10000, Loss: 0.09567359834909439\n",
      "Iteration: 377/10000, Loss: 0.10438957810401917\n",
      "Iteration: 378/10000, Loss: 0.10131613910198212\n",
      "Iteration: 379/10000, Loss: 0.11344033479690552\n",
      "Iteration: 380/10000, Loss: 0.09042441844940186\n",
      "Iteration: 381/10000, Loss: 0.10157867521047592\n",
      "Iteration: 382/10000, Loss: 0.10916103422641754\n",
      "Iteration: 383/10000, Loss: 0.12034260481595993\n",
      "Iteration: 384/10000, Loss: 0.1007072776556015\n",
      "Iteration: 385/10000, Loss: 0.11173287034034729\n",
      "Iteration: 386/10000, Loss: 0.10930441319942474\n",
      "Iteration: 387/10000, Loss: 0.12126662582159042\n",
      "Iteration: 388/10000, Loss: 0.1354753077030182\n",
      "Iteration: 389/10000, Loss: 0.1118939220905304\n",
      "Iteration: 390/10000, Loss: 0.09411060065031052\n",
      "Iteration: 391/10000, Loss: 0.09999358654022217\n",
      "Iteration: 392/10000, Loss: 0.10458599776029587\n",
      "Iteration: 393/10000, Loss: 0.10158992558717728\n",
      "Iteration: 394/10000, Loss: 0.12173979729413986\n",
      "Iteration: 395/10000, Loss: 0.10230085253715515\n",
      "Iteration: 396/10000, Loss: 0.08761733770370483\n",
      "Iteration: 397/10000, Loss: 0.08029527962207794\n",
      "Iteration: 398/10000, Loss: 0.11520923674106598\n",
      "Iteration: 399/10000, Loss: 0.09182330965995789\n",
      "Iteration: 400/10000, Loss: 0.08699163049459457\n",
      "Average test loss:  0.0063\n",
      "Iteration: 401/10000, Loss: 0.07813140749931335\n",
      "Iteration: 402/10000, Loss: 0.08552736043930054\n",
      "Iteration: 403/10000, Loss: 0.11694754660129547\n",
      "Iteration: 404/10000, Loss: 0.11613130569458008\n",
      "Iteration: 405/10000, Loss: 0.11551353335380554\n",
      "Iteration: 406/10000, Loss: 0.09113683551549911\n",
      "Iteration: 407/10000, Loss: 0.09386638551950455\n",
      "Iteration: 408/10000, Loss: 0.08208445459604263\n",
      "Iteration: 409/10000, Loss: 0.11682026088237762\n",
      "Iteration: 410/10000, Loss: 0.1053093820810318\n",
      "Iteration: 411/10000, Loss: 0.116801418364048\n",
      "Iteration: 412/10000, Loss: 0.09147974848747253\n",
      "Iteration: 413/10000, Loss: 0.09685984253883362\n",
      "Iteration: 414/10000, Loss: 0.11881621181964874\n",
      "Iteration: 415/10000, Loss: 0.10869026184082031\n",
      "Iteration: 416/10000, Loss: 0.09254977852106094\n",
      "Iteration: 417/10000, Loss: 0.1426578164100647\n",
      "Iteration: 418/10000, Loss: 0.0801006406545639\n",
      "Iteration: 419/10000, Loss: 0.10503595322370529\n",
      "Iteration: 420/10000, Loss: 0.08883962035179138\n",
      "Iteration: 421/10000, Loss: 0.099866583943367\n",
      "Iteration: 422/10000, Loss: 0.09596825391054153\n",
      "Iteration: 423/10000, Loss: 0.08528129011392593\n",
      "Iteration: 424/10000, Loss: 0.11868561804294586\n",
      "Iteration: 425/10000, Loss: 0.09147995710372925\n",
      "Iteration: 426/10000, Loss: 0.10438213497400284\n",
      "Iteration: 427/10000, Loss: 0.08279955387115479\n",
      "Iteration: 428/10000, Loss: 0.09581689536571503\n",
      "Iteration: 429/10000, Loss: 0.10103394091129303\n",
      "Iteration: 430/10000, Loss: 0.1121746227145195\n",
      "Iteration: 431/10000, Loss: 0.10058914870023727\n",
      "Iteration: 432/10000, Loss: 0.08270493894815445\n",
      "Iteration: 433/10000, Loss: 0.10248703509569168\n",
      "Iteration: 434/10000, Loss: 0.1002727746963501\n",
      "Iteration: 435/10000, Loss: 0.11048728227615356\n",
      "Iteration: 436/10000, Loss: 0.09932737797498703\n",
      "Iteration: 437/10000, Loss: 0.07984552532434464\n",
      "Iteration: 438/10000, Loss: 0.0844905823469162\n",
      "Iteration: 439/10000, Loss: 0.08796888589859009\n",
      "Iteration: 440/10000, Loss: 0.07723873853683472\n",
      "Iteration: 441/10000, Loss: 0.10004419088363647\n",
      "Iteration: 442/10000, Loss: 0.0840640440583229\n",
      "Iteration: 443/10000, Loss: 0.09268176555633545\n",
      "Iteration: 444/10000, Loss: 0.09785576164722443\n",
      "Iteration: 445/10000, Loss: 0.11023237556219101\n",
      "Iteration: 446/10000, Loss: 0.09337453544139862\n",
      "Iteration: 447/10000, Loss: 0.1055343821644783\n",
      "Iteration: 448/10000, Loss: 0.08828823268413544\n",
      "Iteration: 449/10000, Loss: 0.12445080280303955\n",
      "Iteration: 450/10000, Loss: 0.0749073177576065\n",
      "Iteration: 451/10000, Loss: 0.0945035070180893\n",
      "Iteration: 452/10000, Loss: 0.10161585360765457\n",
      "Iteration: 453/10000, Loss: 0.0961654782295227\n",
      "Iteration: 454/10000, Loss: 0.10677715390920639\n",
      "Iteration: 455/10000, Loss: 0.09311141818761826\n",
      "Iteration: 456/10000, Loss: 0.09060002863407135\n",
      "Iteration: 457/10000, Loss: 0.0869998186826706\n",
      "Iteration: 458/10000, Loss: 0.09750969707965851\n",
      "Iteration: 459/10000, Loss: 0.08059549331665039\n",
      "Iteration: 460/10000, Loss: 0.10676531493663788\n",
      "Iteration: 461/10000, Loss: 0.11933590471744537\n",
      "Iteration: 462/10000, Loss: 0.07961424440145493\n",
      "Iteration: 463/10000, Loss: 0.09997426718473434\n",
      "Iteration: 464/10000, Loss: 0.08423314243555069\n",
      "Iteration: 465/10000, Loss: 0.07984752207994461\n",
      "Iteration: 466/10000, Loss: 0.08495546877384186\n",
      "Iteration: 467/10000, Loss: 0.07830066233873367\n",
      "Iteration: 468/10000, Loss: 0.07453608512878418\n",
      "Iteration: 469/10000, Loss: 0.07930802553892136\n",
      "Iteration: 470/10000, Loss: 0.12201228737831116\n",
      "Iteration: 471/10000, Loss: 0.08478269726037979\n",
      "Iteration: 472/10000, Loss: 0.09522105008363724\n",
      "Iteration: 473/10000, Loss: 0.07943179458379745\n",
      "Iteration: 474/10000, Loss: 0.10508511960506439\n",
      "Iteration: 475/10000, Loss: 0.08248667418956757\n",
      "Iteration: 476/10000, Loss: 0.08807305246591568\n",
      "Iteration: 477/10000, Loss: 0.06812358647584915\n",
      "Iteration: 478/10000, Loss: 0.08413045108318329\n",
      "Iteration: 479/10000, Loss: 0.08545231074094772\n",
      "Iteration: 480/10000, Loss: 0.08731268346309662\n",
      "Iteration: 481/10000, Loss: 0.07118754088878632\n",
      "Iteration: 482/10000, Loss: 0.09378065168857574\n",
      "Iteration: 483/10000, Loss: 0.12240808457136154\n",
      "Iteration: 484/10000, Loss: 0.10259480029344559\n",
      "Iteration: 485/10000, Loss: 0.07201454043388367\n",
      "Iteration: 486/10000, Loss: 0.07644710689783096\n",
      "Iteration: 487/10000, Loss: 0.0729963630437851\n",
      "Iteration: 488/10000, Loss: 0.07378328591585159\n",
      "Iteration: 489/10000, Loss: 0.08057018369436264\n",
      "Iteration: 490/10000, Loss: 0.084307000041008\n",
      "Iteration: 491/10000, Loss: 0.08303810656070709\n",
      "Iteration: 492/10000, Loss: 0.08189529925584793\n",
      "Iteration: 493/10000, Loss: 0.08542589098215103\n",
      "Iteration: 494/10000, Loss: 0.07783587276935577\n",
      "Iteration: 495/10000, Loss: 0.0928281620144844\n",
      "Iteration: 496/10000, Loss: 0.08859024196863174\n",
      "Iteration: 497/10000, Loss: 0.08845778554677963\n",
      "Iteration: 498/10000, Loss: 0.08036600798368454\n",
      "Iteration: 499/10000, Loss: 0.08151979744434357\n",
      "Iteration: 500/10000, Loss: 0.08374135941267014\n",
      "Average test loss:  0.0046\n",
      "Iteration: 501/10000, Loss: 0.08154978603124619\n",
      "Iteration: 502/10000, Loss: 0.08190086483955383\n",
      "Iteration: 503/10000, Loss: 0.09396042674779892\n",
      "Iteration: 504/10000, Loss: 0.07850965112447739\n",
      "Iteration: 505/10000, Loss: 0.11006603389978409\n",
      "Iteration: 506/10000, Loss: 0.09465348720550537\n",
      "Iteration: 507/10000, Loss: 0.06619980931282043\n",
      "Iteration: 508/10000, Loss: 0.06550928950309753\n",
      "Iteration: 509/10000, Loss: 0.08159429579973221\n",
      "Iteration: 510/10000, Loss: 0.08856526017189026\n",
      "Iteration: 511/10000, Loss: 0.06591496616601944\n",
      "Iteration: 512/10000, Loss: 0.07381795346736908\n",
      "Iteration: 513/10000, Loss: 0.06918194144964218\n",
      "Iteration: 514/10000, Loss: 0.05844513326883316\n",
      "Iteration: 515/10000, Loss: 0.07765985280275345\n",
      "Iteration: 516/10000, Loss: 0.07766210287809372\n",
      "Iteration: 517/10000, Loss: 0.08043166995048523\n",
      "Iteration: 518/10000, Loss: 0.07718851417303085\n",
      "Iteration: 519/10000, Loss: 0.06678661704063416\n",
      "Iteration: 520/10000, Loss: 0.10699421912431717\n",
      "Iteration: 521/10000, Loss: 0.07403749972581863\n",
      "Iteration: 522/10000, Loss: 0.07854034751653671\n",
      "Iteration: 523/10000, Loss: 0.0857834741473198\n",
      "Iteration: 524/10000, Loss: 0.09143800288438797\n",
      "Iteration: 525/10000, Loss: 0.07407964020967484\n",
      "Iteration: 526/10000, Loss: 0.06589100509881973\n",
      "Iteration: 527/10000, Loss: 0.11760617047548294\n",
      "Iteration: 528/10000, Loss: 0.07842021435499191\n",
      "Iteration: 529/10000, Loss: 0.0911157876253128\n",
      "Iteration: 530/10000, Loss: 0.0701717957854271\n",
      "Iteration: 531/10000, Loss: 0.07861015945672989\n",
      "Iteration: 532/10000, Loss: 0.07745015621185303\n",
      "Iteration: 533/10000, Loss: 0.0794847309589386\n",
      "Iteration: 534/10000, Loss: 0.06110676750540733\n",
      "Iteration: 535/10000, Loss: 0.0824638307094574\n",
      "Iteration: 536/10000, Loss: 0.10716427117586136\n",
      "Iteration: 537/10000, Loss: 0.07350879162549973\n",
      "Iteration: 538/10000, Loss: 0.07039035856723785\n",
      "Iteration: 539/10000, Loss: 0.11123893409967422\n",
      "Iteration: 540/10000, Loss: 0.0820017084479332\n",
      "Iteration: 541/10000, Loss: 0.07431258261203766\n",
      "Iteration: 542/10000, Loss: 0.07010301947593689\n",
      "Iteration: 543/10000, Loss: 0.09439368546009064\n",
      "Iteration: 544/10000, Loss: 0.08207977563142776\n",
      "Iteration: 545/10000, Loss: 0.09115473926067352\n",
      "Iteration: 546/10000, Loss: 0.06956354528665543\n",
      "Iteration: 547/10000, Loss: 0.07984162867069244\n",
      "Iteration: 548/10000, Loss: 0.08902836591005325\n",
      "Iteration: 549/10000, Loss: 0.08667058497667313\n",
      "Iteration: 550/10000, Loss: 0.07713931798934937\n",
      "Iteration: 551/10000, Loss: 0.06118307262659073\n",
      "Iteration: 552/10000, Loss: 0.08299696445465088\n",
      "Iteration: 553/10000, Loss: 0.08283167332410812\n",
      "Iteration: 554/10000, Loss: 0.07232474535703659\n",
      "Iteration: 555/10000, Loss: 0.07782267034053802\n",
      "Iteration: 556/10000, Loss: 0.06973320245742798\n",
      "Iteration: 557/10000, Loss: 0.0863717794418335\n",
      "Iteration: 558/10000, Loss: 0.06359779834747314\n",
      "Iteration: 559/10000, Loss: 0.0733797550201416\n",
      "Iteration: 560/10000, Loss: 0.08631691336631775\n",
      "Iteration: 561/10000, Loss: 0.06704069674015045\n",
      "Iteration: 562/10000, Loss: 0.07186038047075272\n",
      "Iteration: 563/10000, Loss: 0.08848056942224503\n",
      "Iteration: 564/10000, Loss: 0.05594688281416893\n",
      "Iteration: 565/10000, Loss: 0.06959577649831772\n",
      "Iteration: 566/10000, Loss: 0.09412398934364319\n",
      "Iteration: 567/10000, Loss: 0.06903930008411407\n",
      "Iteration: 568/10000, Loss: 0.06976582109928131\n",
      "Iteration: 569/10000, Loss: 0.06043904647231102\n",
      "Iteration: 570/10000, Loss: 0.06295160204172134\n",
      "Iteration: 571/10000, Loss: 0.07293639332056046\n",
      "Iteration: 572/10000, Loss: 0.07337232679128647\n",
      "Iteration: 573/10000, Loss: 0.06819868087768555\n",
      "Iteration: 574/10000, Loss: 0.06381119042634964\n",
      "Iteration: 575/10000, Loss: 0.08335717767477036\n",
      "Iteration: 576/10000, Loss: 0.06057163327932358\n",
      "Iteration: 577/10000, Loss: 0.06216048449277878\n",
      "Iteration: 578/10000, Loss: 0.07412419468164444\n",
      "Iteration: 579/10000, Loss: 0.08106087893247604\n",
      "Iteration: 580/10000, Loss: 0.07255518436431885\n",
      "Iteration: 581/10000, Loss: 0.0727912113070488\n",
      "Iteration: 582/10000, Loss: 0.06361552327871323\n",
      "Iteration: 583/10000, Loss: 0.06427261233329773\n",
      "Iteration: 584/10000, Loss: 0.08268529176712036\n",
      "Iteration: 585/10000, Loss: 0.06371789425611496\n",
      "Iteration: 586/10000, Loss: 0.07857358455657959\n",
      "Iteration: 587/10000, Loss: 0.06497371196746826\n",
      "Iteration: 588/10000, Loss: 0.0698511078953743\n",
      "Iteration: 589/10000, Loss: 0.07165246456861496\n",
      "Iteration: 590/10000, Loss: 0.08353868126869202\n",
      "Iteration: 591/10000, Loss: 0.05633711442351341\n",
      "Iteration: 592/10000, Loss: 0.06151958182454109\n",
      "Iteration: 593/10000, Loss: 0.07196485251188278\n",
      "Iteration: 594/10000, Loss: 0.09080439060926437\n",
      "Iteration: 595/10000, Loss: 0.08992420136928558\n",
      "Iteration: 596/10000, Loss: 0.07565176486968994\n",
      "Iteration: 597/10000, Loss: 0.08326610177755356\n",
      "Iteration: 598/10000, Loss: 0.07934410125017166\n",
      "Iteration: 599/10000, Loss: 0.07112440466880798\n",
      "Iteration: 600/10000, Loss: 0.07620768994092941\n",
      "Average test loss:  0.0044\n",
      "Iteration: 601/10000, Loss: 0.08232611417770386\n",
      "Iteration: 602/10000, Loss: 0.08992312848567963\n",
      "Iteration: 603/10000, Loss: 0.06877569109201431\n",
      "Iteration: 604/10000, Loss: 0.0698467567563057\n",
      "Iteration: 605/10000, Loss: 0.06744033843278885\n",
      "Iteration: 606/10000, Loss: 0.056863415986299515\n",
      "Iteration: 607/10000, Loss: 0.06405476480722427\n",
      "Iteration: 608/10000, Loss: 0.08968133479356766\n",
      "Iteration: 609/10000, Loss: 0.08768349885940552\n",
      "Iteration: 610/10000, Loss: 0.07641295343637466\n",
      "Iteration: 611/10000, Loss: 0.07219967246055603\n",
      "Iteration: 612/10000, Loss: 0.07744932919740677\n",
      "Iteration: 613/10000, Loss: 0.05916536599397659\n",
      "Iteration: 614/10000, Loss: 0.062138065695762634\n",
      "Iteration: 615/10000, Loss: 0.07583168148994446\n",
      "Iteration: 616/10000, Loss: 0.06217454746365547\n",
      "Iteration: 617/10000, Loss: 0.048660360276699066\n",
      "Iteration: 618/10000, Loss: 0.0528830885887146\n",
      "Iteration: 619/10000, Loss: 0.08083845674991608\n",
      "Iteration: 620/10000, Loss: 0.055967219173908234\n",
      "Iteration: 621/10000, Loss: 0.07493139803409576\n",
      "Iteration: 622/10000, Loss: 0.061001967638731\n",
      "Iteration: 623/10000, Loss: 0.07038161158561707\n",
      "Iteration: 624/10000, Loss: 0.055264662951231\n",
      "Iteration: 625/10000, Loss: 0.05636553466320038\n",
      "Iteration: 626/10000, Loss: 0.04466160386800766\n",
      "Iteration: 627/10000, Loss: 0.0522824190557003\n",
      "Iteration: 628/10000, Loss: 0.060366641730070114\n",
      "Iteration: 629/10000, Loss: 0.0623372346162796\n",
      "Iteration: 630/10000, Loss: 0.09125266224145889\n",
      "Iteration: 631/10000, Loss: 0.0626789852976799\n",
      "Iteration: 632/10000, Loss: 0.05123624578118324\n",
      "Iteration: 633/10000, Loss: 0.06350724399089813\n",
      "Iteration: 634/10000, Loss: 0.07822247594594955\n",
      "Iteration: 635/10000, Loss: 0.05830760672688484\n",
      "Iteration: 636/10000, Loss: 0.09953659027814865\n",
      "Iteration: 637/10000, Loss: 0.06682252138853073\n",
      "Iteration: 638/10000, Loss: 0.07529014348983765\n",
      "Iteration: 639/10000, Loss: 0.06678890436887741\n",
      "Iteration: 640/10000, Loss: 0.06392087787389755\n",
      "Iteration: 641/10000, Loss: 0.05812639743089676\n",
      "Iteration: 642/10000, Loss: 0.05994151905179024\n",
      "Iteration: 643/10000, Loss: 0.07141978293657303\n",
      "Iteration: 644/10000, Loss: 0.07875693589448929\n",
      "Iteration: 645/10000, Loss: 0.08464657515287399\n",
      "Iteration: 646/10000, Loss: 0.06452355533838272\n",
      "Iteration: 647/10000, Loss: 0.053840864449739456\n",
      "Iteration: 648/10000, Loss: 0.07331905514001846\n",
      "Iteration: 649/10000, Loss: 0.06862469762563705\n",
      "Iteration: 650/10000, Loss: 0.061153847724199295\n",
      "Iteration: 651/10000, Loss: 0.07155647873878479\n",
      "Iteration: 652/10000, Loss: 0.04675643518567085\n",
      "Iteration: 653/10000, Loss: 0.05974596366286278\n",
      "Iteration: 654/10000, Loss: 0.07073020190000534\n",
      "Iteration: 655/10000, Loss: 0.06241685524582863\n",
      "Iteration: 656/10000, Loss: 0.047474395483732224\n",
      "Iteration: 657/10000, Loss: 0.06681357324123383\n",
      "Iteration: 658/10000, Loss: 0.06393047422170639\n",
      "Iteration: 659/10000, Loss: 0.06414448469877243\n",
      "Iteration: 660/10000, Loss: 0.0628962591290474\n",
      "Iteration: 661/10000, Loss: 0.05064771696925163\n",
      "Iteration: 662/10000, Loss: 0.06728851050138474\n",
      "Iteration: 663/10000, Loss: 0.07226141542196274\n",
      "Iteration: 664/10000, Loss: 0.05129493772983551\n",
      "Iteration: 665/10000, Loss: 0.08995585888624191\n",
      "Iteration: 666/10000, Loss: 0.05403286963701248\n",
      "Iteration: 667/10000, Loss: 0.0758649930357933\n",
      "Iteration: 668/10000, Loss: 0.06639939546585083\n",
      "Iteration: 669/10000, Loss: 0.06921994686126709\n",
      "Iteration: 670/10000, Loss: 0.0669618621468544\n",
      "Iteration: 671/10000, Loss: 0.06461392343044281\n",
      "Iteration: 672/10000, Loss: 0.08592163026332855\n",
      "Iteration: 673/10000, Loss: 0.0718824714422226\n",
      "Iteration: 674/10000, Loss: 0.062119267880916595\n",
      "Iteration: 675/10000, Loss: 0.05810850113630295\n",
      "Iteration: 676/10000, Loss: 0.05793539434671402\n",
      "Iteration: 677/10000, Loss: 0.06699106097221375\n",
      "Iteration: 678/10000, Loss: 0.056624945253133774\n",
      "Iteration: 679/10000, Loss: 0.054155293852090836\n",
      "Iteration: 680/10000, Loss: 0.04933154582977295\n",
      "Iteration: 681/10000, Loss: 0.0652584433555603\n",
      "Iteration: 682/10000, Loss: 0.04393066093325615\n",
      "Iteration: 683/10000, Loss: 0.07441838085651398\n",
      "Iteration: 684/10000, Loss: 0.06859683990478516\n",
      "Iteration: 685/10000, Loss: 0.0632377341389656\n",
      "Iteration: 686/10000, Loss: 0.05367786064743996\n",
      "Iteration: 687/10000, Loss: 0.05946296453475952\n",
      "Iteration: 688/10000, Loss: 0.05115425959229469\n",
      "Iteration: 689/10000, Loss: 0.05128266289830208\n",
      "Iteration: 690/10000, Loss: 0.06749554723501205\n",
      "Iteration: 691/10000, Loss: 0.09325925260782242\n",
      "Iteration: 692/10000, Loss: 0.06436619907617569\n",
      "Iteration: 693/10000, Loss: 0.06724032014608383\n",
      "Iteration: 694/10000, Loss: 0.07046964019536972\n",
      "Iteration: 695/10000, Loss: 0.0653892382979393\n",
      "Iteration: 696/10000, Loss: 0.05731917917728424\n",
      "Iteration: 697/10000, Loss: 0.04572373628616333\n",
      "Iteration: 698/10000, Loss: 0.07777398824691772\n",
      "Iteration: 699/10000, Loss: 0.061907120048999786\n",
      "Iteration: 700/10000, Loss: 0.07596321403980255\n",
      "Average test loss:  0.0043\n",
      "Iteration: 701/10000, Loss: 0.08777111768722534\n",
      "Iteration: 702/10000, Loss: 0.049348898231983185\n",
      "Iteration: 703/10000, Loss: 0.048160478472709656\n",
      "Iteration: 704/10000, Loss: 0.0679321438074112\n",
      "Iteration: 705/10000, Loss: 0.057585716247558594\n",
      "Iteration: 706/10000, Loss: 0.060624636709690094\n",
      "Iteration: 707/10000, Loss: 0.037428732961416245\n",
      "Iteration: 708/10000, Loss: 0.07094409316778183\n",
      "Iteration: 709/10000, Loss: 0.05310201272368431\n",
      "Iteration: 710/10000, Loss: 0.06403010338544846\n",
      "Iteration: 711/10000, Loss: 0.049664128571748734\n",
      "Iteration: 712/10000, Loss: 0.07195208221673965\n",
      "Iteration: 713/10000, Loss: 0.051698099821805954\n",
      "Iteration: 714/10000, Loss: 0.0445735901594162\n",
      "Iteration: 715/10000, Loss: 0.05821148306131363\n",
      "Iteration: 716/10000, Loss: 0.06375603377819061\n",
      "Iteration: 717/10000, Loss: 0.05840716138482094\n",
      "Iteration: 718/10000, Loss: 0.08313094824552536\n",
      "Iteration: 719/10000, Loss: 0.058100320398807526\n",
      "Iteration: 720/10000, Loss: 0.05740483105182648\n",
      "Iteration: 721/10000, Loss: 0.06975089013576508\n",
      "Iteration: 722/10000, Loss: 0.06761301308870316\n",
      "Iteration: 723/10000, Loss: 0.052990738302469254\n",
      "Iteration: 724/10000, Loss: 0.05113757401704788\n",
      "Iteration: 725/10000, Loss: 0.06221039593219757\n",
      "Iteration: 726/10000, Loss: 0.07963024079799652\n",
      "Iteration: 727/10000, Loss: 0.06076684594154358\n",
      "Iteration: 728/10000, Loss: 0.055038392543792725\n",
      "Iteration: 729/10000, Loss: 0.04685445874929428\n",
      "Iteration: 730/10000, Loss: 0.07398584485054016\n",
      "Iteration: 731/10000, Loss: 0.03936531022191048\n",
      "Iteration: 732/10000, Loss: 0.052083514630794525\n",
      "Iteration: 733/10000, Loss: 0.06009649485349655\n",
      "Iteration: 734/10000, Loss: 0.061223942786455154\n",
      "Iteration: 735/10000, Loss: 0.04621337354183197\n",
      "Iteration: 736/10000, Loss: 0.04954472556710243\n",
      "Iteration: 737/10000, Loss: 0.05784692242741585\n",
      "Iteration: 738/10000, Loss: 0.05200368911027908\n",
      "Iteration: 739/10000, Loss: 0.05775681510567665\n",
      "Iteration: 740/10000, Loss: 0.05816120654344559\n",
      "Iteration: 741/10000, Loss: 0.04452207311987877\n",
      "Iteration: 742/10000, Loss: 0.05458037555217743\n",
      "Iteration: 743/10000, Loss: 0.05953672155737877\n",
      "Iteration: 744/10000, Loss: 0.07746021449565887\n",
      "Iteration: 745/10000, Loss: 0.04451054334640503\n",
      "Iteration: 746/10000, Loss: 0.04947544261813164\n",
      "Iteration: 747/10000, Loss: 0.06558097153902054\n",
      "Iteration: 748/10000, Loss: 0.08566632866859436\n",
      "Iteration: 749/10000, Loss: 0.06202350929379463\n",
      "Iteration: 750/10000, Loss: 0.051397040486335754\n",
      "Iteration: 751/10000, Loss: 0.0559069998562336\n",
      "Iteration: 752/10000, Loss: 0.05778583884239197\n",
      "Iteration: 753/10000, Loss: 0.07435669749975204\n",
      "Iteration: 754/10000, Loss: 0.05935757979750633\n",
      "Iteration: 755/10000, Loss: 0.06172414496541023\n",
      "Iteration: 756/10000, Loss: 0.06906062364578247\n",
      "Iteration: 757/10000, Loss: 0.04771376773715019\n",
      "Iteration: 758/10000, Loss: 0.0651320070028305\n",
      "Iteration: 759/10000, Loss: 0.05466519668698311\n",
      "Iteration: 760/10000, Loss: 0.06495842337608337\n",
      "Iteration: 761/10000, Loss: 0.06269124150276184\n",
      "Iteration: 762/10000, Loss: 0.04881231114268303\n",
      "Iteration: 763/10000, Loss: 0.07628411054611206\n",
      "Iteration: 764/10000, Loss: 0.05175111070275307\n",
      "Iteration: 765/10000, Loss: 0.04881032556295395\n",
      "Iteration: 766/10000, Loss: 0.051717136055231094\n",
      "Iteration: 767/10000, Loss: 0.04753434658050537\n",
      "Iteration: 768/10000, Loss: 0.07843620330095291\n",
      "Iteration: 769/10000, Loss: 0.044456277042627335\n",
      "Iteration: 770/10000, Loss: 0.05724531039595604\n",
      "Iteration: 771/10000, Loss: 0.043595410883426666\n",
      "Iteration: 772/10000, Loss: 0.07673525810241699\n",
      "Iteration: 773/10000, Loss: 0.11198669672012329\n",
      "Iteration: 774/10000, Loss: 0.05642348527908325\n",
      "Iteration: 775/10000, Loss: 0.050291866064071655\n",
      "Iteration: 776/10000, Loss: 0.06366441398859024\n",
      "Iteration: 777/10000, Loss: 0.06418942660093307\n",
      "Iteration: 778/10000, Loss: 0.06301494687795639\n",
      "Iteration: 779/10000, Loss: 0.05997014045715332\n",
      "Iteration: 780/10000, Loss: 0.0443209707736969\n",
      "Iteration: 781/10000, Loss: 0.04997079074382782\n",
      "Iteration: 782/10000, Loss: 0.06002184376120567\n",
      "Iteration: 783/10000, Loss: 0.06435667723417282\n",
      "Iteration: 784/10000, Loss: 0.045519810169935226\n",
      "Iteration: 785/10000, Loss: 0.05632702261209488\n",
      "Iteration: 786/10000, Loss: 0.05874940752983093\n",
      "Iteration: 787/10000, Loss: 0.07031076401472092\n",
      "Iteration: 788/10000, Loss: 0.05146525800228119\n",
      "Iteration: 789/10000, Loss: 0.05444159731268883\n",
      "Iteration: 790/10000, Loss: 0.0837278738617897\n",
      "Iteration: 791/10000, Loss: 0.06160477176308632\n",
      "Iteration: 792/10000, Loss: 0.05256529897451401\n",
      "Iteration: 793/10000, Loss: 0.0807533860206604\n",
      "Iteration: 794/10000, Loss: 0.05697878077626228\n",
      "Iteration: 795/10000, Loss: 0.05803542211651802\n",
      "Iteration: 796/10000, Loss: 0.07895556092262268\n",
      "Iteration: 797/10000, Loss: 0.06437797844409943\n",
      "Iteration: 798/10000, Loss: 0.06429716944694519\n",
      "Iteration: 799/10000, Loss: 0.0670669823884964\n",
      "Iteration: 800/10000, Loss: 0.05626495182514191\n",
      "Average test loss:  0.0028\n",
      "Iteration: 801/10000, Loss: 0.061883728951215744\n",
      "Iteration: 802/10000, Loss: 0.05598553642630577\n",
      "Iteration: 803/10000, Loss: 0.04699626937508583\n",
      "Iteration: 804/10000, Loss: 0.0453796312212944\n",
      "Iteration: 805/10000, Loss: 0.04813704267144203\n",
      "Iteration: 806/10000, Loss: 0.05919782072305679\n",
      "Iteration: 807/10000, Loss: 0.05466039106249809\n",
      "Iteration: 808/10000, Loss: 0.07622098177671432\n",
      "Iteration: 809/10000, Loss: 0.06587735563516617\n",
      "Iteration: 810/10000, Loss: 0.04545120149850845\n",
      "Iteration: 811/10000, Loss: 0.05136144906282425\n",
      "Iteration: 812/10000, Loss: 0.04866066947579384\n",
      "Iteration: 813/10000, Loss: 0.06112825497984886\n",
      "Iteration: 814/10000, Loss: 0.05419589579105377\n",
      "Iteration: 815/10000, Loss: 0.06091045215725899\n",
      "Iteration: 816/10000, Loss: 0.051405902951955795\n",
      "Iteration: 817/10000, Loss: 0.050231896340847015\n",
      "Iteration: 818/10000, Loss: 0.062311191111803055\n",
      "Iteration: 819/10000, Loss: 0.06477849185466766\n",
      "Iteration: 820/10000, Loss: 0.05153847113251686\n",
      "Iteration: 821/10000, Loss: 0.06570913642644882\n",
      "Iteration: 822/10000, Loss: 0.05037786439061165\n",
      "Iteration: 823/10000, Loss: 0.06137946993112564\n",
      "Iteration: 824/10000, Loss: 0.04871669411659241\n",
      "Iteration: 825/10000, Loss: 0.04693450406193733\n",
      "Iteration: 826/10000, Loss: 0.07364395260810852\n",
      "Iteration: 827/10000, Loss: 0.05440220236778259\n",
      "Iteration: 828/10000, Loss: 0.044565167278051376\n",
      "Iteration: 829/10000, Loss: 0.06508561223745346\n",
      "Iteration: 830/10000, Loss: 0.05222320929169655\n",
      "Iteration: 831/10000, Loss: 0.04809318482875824\n",
      "Iteration: 832/10000, Loss: 0.08053980022668839\n",
      "Iteration: 833/10000, Loss: 0.0471624955534935\n",
      "Iteration: 834/10000, Loss: 0.04521222412586212\n",
      "Iteration: 835/10000, Loss: 0.05227334052324295\n",
      "Iteration: 836/10000, Loss: 0.04471033439040184\n",
      "Iteration: 837/10000, Loss: 0.0626036524772644\n",
      "Iteration: 838/10000, Loss: 0.05160841718316078\n",
      "Iteration: 839/10000, Loss: 0.05492536723613739\n",
      "Iteration: 840/10000, Loss: 0.05232629179954529\n",
      "Iteration: 841/10000, Loss: 0.046643078327178955\n",
      "Iteration: 842/10000, Loss: 0.066770538687706\n",
      "Iteration: 843/10000, Loss: 0.05808521807193756\n",
      "Iteration: 844/10000, Loss: 0.06561015546321869\n",
      "Iteration: 845/10000, Loss: 0.0531609021127224\n",
      "Iteration: 846/10000, Loss: 0.05355053395032883\n",
      "Iteration: 847/10000, Loss: 0.042463261634111404\n",
      "Iteration: 848/10000, Loss: 0.051267169415950775\n",
      "Iteration: 849/10000, Loss: 0.04796120151877403\n",
      "Iteration: 850/10000, Loss: 0.035687826573848724\n",
      "Iteration: 851/10000, Loss: 0.06115081533789635\n",
      "Iteration: 852/10000, Loss: 0.06853487342596054\n",
      "Iteration: 853/10000, Loss: 0.05262887850403786\n",
      "Iteration: 854/10000, Loss: 0.044262830168008804\n",
      "Iteration: 855/10000, Loss: 0.0450492687523365\n",
      "Iteration: 856/10000, Loss: 0.06637465208768845\n",
      "Iteration: 857/10000, Loss: 0.05567058548331261\n",
      "Iteration: 858/10000, Loss: 0.06042945012450218\n",
      "Iteration: 859/10000, Loss: 0.04132276773452759\n",
      "Iteration: 860/10000, Loss: 0.05599184334278107\n",
      "Iteration: 861/10000, Loss: 0.05948146432638168\n",
      "Iteration: 862/10000, Loss: 0.05618669465184212\n",
      "Iteration: 863/10000, Loss: 0.06159175932407379\n",
      "Iteration: 864/10000, Loss: 0.0571950264275074\n",
      "Iteration: 865/10000, Loss: 0.08087504655122757\n",
      "Iteration: 866/10000, Loss: 0.05969631299376488\n",
      "Iteration: 867/10000, Loss: 0.09069915860891342\n",
      "Iteration: 868/10000, Loss: 0.055860791355371475\n",
      "Iteration: 869/10000, Loss: 0.044934745877981186\n",
      "Iteration: 870/10000, Loss: 0.060326673090457916\n",
      "Iteration: 871/10000, Loss: 0.03959035500884056\n",
      "Iteration: 872/10000, Loss: 0.06259186565876007\n",
      "Iteration: 873/10000, Loss: 0.04680482670664787\n",
      "Iteration: 874/10000, Loss: 0.06510975956916809\n",
      "Iteration: 875/10000, Loss: 0.06432092189788818\n",
      "Iteration: 876/10000, Loss: 0.033356472849845886\n",
      "Iteration: 877/10000, Loss: 0.0461219921708107\n",
      "Iteration: 878/10000, Loss: 0.06372878700494766\n",
      "Iteration: 879/10000, Loss: 0.04551026597619057\n",
      "Iteration: 880/10000, Loss: 0.05219185724854469\n",
      "Iteration: 881/10000, Loss: 0.07075615972280502\n",
      "Iteration: 882/10000, Loss: 0.06603372097015381\n",
      "Iteration: 883/10000, Loss: 0.04833332076668739\n",
      "Iteration: 884/10000, Loss: 0.05845097452402115\n",
      "Iteration: 885/10000, Loss: 0.0514078214764595\n",
      "Iteration: 886/10000, Loss: 0.05345463752746582\n",
      "Iteration: 887/10000, Loss: 0.04716086387634277\n",
      "Iteration: 888/10000, Loss: 0.05440213531255722\n",
      "Iteration: 889/10000, Loss: 0.050576552748680115\n",
      "Iteration: 890/10000, Loss: 0.05310840532183647\n",
      "Iteration: 891/10000, Loss: 0.06611783057451248\n",
      "Iteration: 892/10000, Loss: 0.04629041999578476\n",
      "Iteration: 893/10000, Loss: 0.03181080520153046\n",
      "Iteration: 894/10000, Loss: 0.06426290422677994\n",
      "Iteration: 895/10000, Loss: 0.07059404999017715\n",
      "Iteration: 896/10000, Loss: 0.05225510150194168\n",
      "Iteration: 897/10000, Loss: 0.05634519085288048\n",
      "Iteration: 898/10000, Loss: 0.0628063753247261\n",
      "Iteration: 899/10000, Loss: 0.04533473402261734\n",
      "Iteration: 900/10000, Loss: 0.04297108203172684\n",
      "Average test loss:  0.0047\n",
      "Iteration: 901/10000, Loss: 0.05261882022023201\n",
      "Iteration: 902/10000, Loss: 0.04503699764609337\n",
      "Iteration: 903/10000, Loss: 0.07222836464643478\n",
      "Iteration: 904/10000, Loss: 0.062216080725193024\n",
      "Iteration: 905/10000, Loss: 0.04400254040956497\n",
      "Iteration: 906/10000, Loss: 0.049911510199308395\n",
      "Iteration: 907/10000, Loss: 0.05568676441907883\n",
      "Iteration: 908/10000, Loss: 0.04084915295243263\n",
      "Iteration: 909/10000, Loss: 0.07262147963047028\n",
      "Iteration: 910/10000, Loss: 0.03867791220545769\n",
      "Iteration: 911/10000, Loss: 0.04261992871761322\n",
      "Iteration: 912/10000, Loss: 0.06067953258752823\n",
      "Iteration: 913/10000, Loss: 0.04450158029794693\n",
      "Iteration: 914/10000, Loss: 0.05952010303735733\n",
      "Iteration: 915/10000, Loss: 0.04953501373529434\n",
      "Iteration: 916/10000, Loss: 0.050550609827041626\n",
      "Iteration: 917/10000, Loss: 0.06172679364681244\n",
      "Iteration: 918/10000, Loss: 0.06468483060598373\n",
      "Iteration: 919/10000, Loss: 0.053916122764348984\n",
      "Iteration: 920/10000, Loss: 0.045990411192178726\n",
      "Iteration: 921/10000, Loss: 0.054116684943437576\n",
      "Iteration: 922/10000, Loss: 0.04830455034971237\n",
      "Iteration: 923/10000, Loss: 0.04029988497495651\n",
      "Iteration: 924/10000, Loss: 0.057401686906814575\n",
      "Iteration: 925/10000, Loss: 0.043247122317552567\n",
      "Iteration: 926/10000, Loss: 0.048340439796447754\n",
      "Iteration: 927/10000, Loss: 0.03728339821100235\n",
      "Iteration: 928/10000, Loss: 0.05125720053911209\n",
      "Iteration: 929/10000, Loss: 0.045207440853118896\n",
      "Iteration: 930/10000, Loss: 0.05286097154021263\n",
      "Iteration: 931/10000, Loss: 0.039537426084280014\n",
      "Iteration: 932/10000, Loss: 0.04040658846497536\n",
      "Iteration: 933/10000, Loss: 0.04370183125138283\n",
      "Iteration: 934/10000, Loss: 0.04965848848223686\n",
      "Iteration: 935/10000, Loss: 0.05814296752214432\n",
      "Iteration: 936/10000, Loss: 0.06230877712368965\n",
      "Iteration: 937/10000, Loss: 0.04840824007987976\n",
      "Iteration: 938/10000, Loss: 0.05048726499080658\n",
      "Iteration: 939/10000, Loss: 0.06449010968208313\n",
      "Iteration: 940/10000, Loss: 0.056845761835575104\n",
      "Iteration: 941/10000, Loss: 0.042544711381196976\n",
      "Iteration: 942/10000, Loss: 0.05573907494544983\n",
      "Iteration: 943/10000, Loss: 0.04295271262526512\n",
      "Iteration: 944/10000, Loss: 0.06963878124952316\n",
      "Iteration: 945/10000, Loss: 0.044487521052360535\n",
      "Iteration: 946/10000, Loss: 0.058923110365867615\n",
      "Iteration: 947/10000, Loss: 0.0633324608206749\n",
      "Iteration: 948/10000, Loss: 0.060119401663541794\n",
      "Iteration: 949/10000, Loss: 0.05806734412908554\n",
      "Iteration: 950/10000, Loss: 0.07281440496444702\n",
      "Iteration: 951/10000, Loss: 0.04881317913532257\n",
      "Iteration: 952/10000, Loss: 0.04822088032960892\n",
      "Iteration: 953/10000, Loss: 0.04358852654695511\n",
      "Iteration: 954/10000, Loss: 0.041358817368745804\n",
      "Iteration: 955/10000, Loss: 0.041437651962041855\n",
      "Iteration: 956/10000, Loss: 0.056139495223760605\n",
      "Iteration: 957/10000, Loss: 0.08301801979541779\n",
      "Iteration: 958/10000, Loss: 0.05066194757819176\n",
      "Iteration: 959/10000, Loss: 0.05736260488629341\n",
      "Iteration: 960/10000, Loss: 0.06698130071163177\n",
      "Iteration: 961/10000, Loss: 0.06977961212396622\n",
      "Iteration: 962/10000, Loss: 0.03855283930897713\n",
      "Iteration: 963/10000, Loss: 0.06017651781439781\n",
      "Iteration: 964/10000, Loss: 0.035958871245384216\n",
      "Iteration: 965/10000, Loss: 0.05914752185344696\n",
      "Iteration: 966/10000, Loss: 0.040534667670726776\n",
      "Iteration: 967/10000, Loss: 0.038390014320611954\n",
      "Iteration: 968/10000, Loss: 0.05272778868675232\n",
      "Iteration: 969/10000, Loss: 0.057785168290138245\n",
      "Iteration: 970/10000, Loss: 0.038255929946899414\n",
      "Iteration: 971/10000, Loss: 0.059193678200244904\n",
      "Iteration: 972/10000, Loss: 0.04766521975398064\n",
      "Iteration: 973/10000, Loss: 0.036954112350940704\n",
      "Iteration: 974/10000, Loss: 0.05307278037071228\n",
      "Iteration: 975/10000, Loss: 0.04405168816447258\n",
      "Iteration: 976/10000, Loss: 0.039395011961460114\n",
      "Iteration: 977/10000, Loss: 0.07162454724311829\n",
      "Iteration: 978/10000, Loss: 0.027061330154538155\n",
      "Iteration: 979/10000, Loss: 0.05280756205320358\n",
      "Iteration: 980/10000, Loss: 0.03653806075453758\n",
      "Iteration: 981/10000, Loss: 0.03309868648648262\n",
      "Iteration: 982/10000, Loss: 0.0503782220184803\n",
      "Iteration: 983/10000, Loss: 0.04273535683751106\n",
      "Iteration: 984/10000, Loss: 0.05373874679207802\n",
      "Iteration: 985/10000, Loss: 0.034304793924093246\n",
      "Iteration: 986/10000, Loss: 0.037588201463222504\n",
      "Iteration: 987/10000, Loss: 0.062238845974206924\n",
      "Iteration: 988/10000, Loss: 0.029802270233631134\n",
      "Iteration: 989/10000, Loss: 0.05502452328801155\n",
      "Iteration: 990/10000, Loss: 0.05123528093099594\n",
      "Iteration: 991/10000, Loss: 0.04505837708711624\n",
      "Iteration: 992/10000, Loss: 0.05229887366294861\n",
      "Iteration: 993/10000, Loss: 0.06001817807555199\n",
      "Iteration: 994/10000, Loss: 0.03871947526931763\n",
      "Iteration: 995/10000, Loss: 0.05206068977713585\n",
      "Iteration: 996/10000, Loss: 0.04230456054210663\n",
      "Iteration: 997/10000, Loss: 0.05216965451836586\n",
      "Iteration: 998/10000, Loss: 0.03787597268819809\n",
      "Iteration: 999/10000, Loss: 0.03301888704299927\n",
      "Iteration: 1000/10000, Loss: 0.04868089407682419\n",
      "Average test loss:  0.0039\n",
      "Iteration: 1001/10000, Loss: 0.04189864546060562\n",
      "Iteration: 1002/10000, Loss: 0.03695613518357277\n",
      "Iteration: 1003/10000, Loss: 0.03494285047054291\n",
      "Iteration: 1004/10000, Loss: 0.05467428267002106\n",
      "Iteration: 1005/10000, Loss: 0.029456045478582382\n",
      "Iteration: 1006/10000, Loss: 0.07141557335853577\n",
      "Iteration: 1007/10000, Loss: 0.035401880741119385\n",
      "Iteration: 1008/10000, Loss: 0.0488993376493454\n",
      "Iteration: 1009/10000, Loss: 0.037057064473629\n",
      "Iteration: 1010/10000, Loss: 0.04181230068206787\n",
      "Iteration: 1011/10000, Loss: 0.03948759287595749\n",
      "Iteration: 1012/10000, Loss: 0.05955461412668228\n",
      "Iteration: 1013/10000, Loss: 0.04293655976653099\n",
      "Iteration: 1014/10000, Loss: 0.04219716787338257\n",
      "Iteration: 1015/10000, Loss: 0.05502065271139145\n",
      "Iteration: 1016/10000, Loss: 0.04536689072847366\n",
      "Iteration: 1017/10000, Loss: 0.04974774271249771\n",
      "Iteration: 1018/10000, Loss: 0.045677635818719864\n",
      "Iteration: 1019/10000, Loss: 0.05637304484844208\n",
      "Iteration: 1020/10000, Loss: 0.053261224180459976\n",
      "Iteration: 1021/10000, Loss: 0.04439685121178627\n",
      "Iteration: 1022/10000, Loss: 0.05169900134205818\n",
      "Iteration: 1023/10000, Loss: 0.03250299021601677\n",
      "Iteration: 1024/10000, Loss: 0.07449798285961151\n",
      "Iteration: 1025/10000, Loss: 0.04737396165728569\n",
      "Iteration: 1026/10000, Loss: 0.049728114157915115\n",
      "Iteration: 1027/10000, Loss: 0.06268344074487686\n",
      "Iteration: 1028/10000, Loss: 0.041009604930877686\n",
      "Iteration: 1029/10000, Loss: 0.05669811740517616\n",
      "Iteration: 1030/10000, Loss: 0.04427193105220795\n",
      "Iteration: 1031/10000, Loss: 0.04369795322418213\n",
      "Iteration: 1032/10000, Loss: 0.05058866739273071\n",
      "Iteration: 1033/10000, Loss: 0.044714007526636124\n",
      "Iteration: 1034/10000, Loss: 0.047715045511722565\n",
      "Iteration: 1035/10000, Loss: 0.04968562349677086\n",
      "Iteration: 1036/10000, Loss: 0.033043839037418365\n",
      "Iteration: 1037/10000, Loss: 0.04043188691139221\n",
      "Iteration: 1038/10000, Loss: 0.038391947746276855\n",
      "Iteration: 1039/10000, Loss: 0.041705626994371414\n",
      "Iteration: 1040/10000, Loss: 0.05940903723239899\n",
      "Iteration: 1041/10000, Loss: 0.042971283197402954\n",
      "Iteration: 1042/10000, Loss: 0.04922864958643913\n",
      "Iteration: 1043/10000, Loss: 0.038722556084394455\n",
      "Iteration: 1044/10000, Loss: 0.0420277900993824\n",
      "Iteration: 1045/10000, Loss: 0.06849183887243271\n",
      "Iteration: 1046/10000, Loss: 0.04323568195104599\n",
      "Iteration: 1047/10000, Loss: 0.03246302157640457\n",
      "Iteration: 1048/10000, Loss: 0.055107250809669495\n",
      "Iteration: 1049/10000, Loss: 0.03548729047179222\n",
      "Iteration: 1050/10000, Loss: 0.06267286837100983\n",
      "Iteration: 1051/10000, Loss: 0.05400925502181053\n",
      "Iteration: 1052/10000, Loss: 0.05375014245510101\n",
      "Iteration: 1053/10000, Loss: 0.04743450507521629\n",
      "Iteration: 1054/10000, Loss: 0.04591096192598343\n",
      "Iteration: 1055/10000, Loss: 0.06602014601230621\n",
      "Iteration: 1056/10000, Loss: 0.05196216702461243\n",
      "Iteration: 1057/10000, Loss: 0.06045316159725189\n",
      "Iteration: 1058/10000, Loss: 0.039361417293548584\n",
      "Iteration: 1059/10000, Loss: 0.049186836928129196\n",
      "Iteration: 1060/10000, Loss: 0.03793448954820633\n",
      "Iteration: 1061/10000, Loss: 0.029071057215332985\n",
      "Iteration: 1062/10000, Loss: 0.050815217196941376\n",
      "Iteration: 1063/10000, Loss: 0.0401817187666893\n",
      "Iteration: 1064/10000, Loss: 0.09602512419223785\n",
      "Iteration: 1065/10000, Loss: 0.06872010231018066\n",
      "Iteration: 1066/10000, Loss: 0.07909522205591202\n",
      "Iteration: 1067/10000, Loss: 0.04163582995533943\n",
      "Iteration: 1068/10000, Loss: 0.05658509209752083\n",
      "Iteration: 1069/10000, Loss: 0.05862000212073326\n",
      "Iteration: 1070/10000, Loss: 0.03853180631995201\n",
      "Iteration: 1071/10000, Loss: 0.043059222400188446\n",
      "Iteration: 1072/10000, Loss: 0.05144646391272545\n",
      "Iteration: 1073/10000, Loss: 0.04220390319824219\n",
      "Iteration: 1074/10000, Loss: 0.046233881264925\n",
      "Iteration: 1075/10000, Loss: 0.043394021689891815\n",
      "Iteration: 1076/10000, Loss: 0.041868798434734344\n",
      "Iteration: 1077/10000, Loss: 0.059472642838954926\n",
      "Iteration: 1078/10000, Loss: 0.04411964863538742\n",
      "Iteration: 1079/10000, Loss: 0.030561769381165504\n",
      "Iteration: 1080/10000, Loss: 0.043441981077194214\n",
      "Iteration: 1081/10000, Loss: 0.04823850095272064\n",
      "Iteration: 1082/10000, Loss: 0.028799619525671005\n",
      "Iteration: 1083/10000, Loss: 0.0407257080078125\n",
      "Iteration: 1084/10000, Loss: 0.07015996426343918\n",
      "Iteration: 1085/10000, Loss: 0.028588104993104935\n",
      "Iteration: 1086/10000, Loss: 0.04133393615484238\n",
      "Iteration: 1087/10000, Loss: 0.03183572739362717\n",
      "Iteration: 1088/10000, Loss: 0.04067467525601387\n",
      "Iteration: 1089/10000, Loss: 0.053671061992645264\n",
      "Iteration: 1090/10000, Loss: 0.049872178584337234\n",
      "Iteration: 1091/10000, Loss: 0.043451983481645584\n",
      "Iteration: 1092/10000, Loss: 0.028340816497802734\n",
      "Iteration: 1093/10000, Loss: 0.073380246758461\n",
      "Iteration: 1094/10000, Loss: 0.030839748680591583\n",
      "Iteration: 1095/10000, Loss: 0.030359048396348953\n",
      "Iteration: 1096/10000, Loss: 0.03633280098438263\n",
      "Iteration: 1097/10000, Loss: 0.04008195549249649\n",
      "Iteration: 1098/10000, Loss: 0.04104842245578766\n",
      "Iteration: 1099/10000, Loss: 0.05205845460295677\n",
      "Iteration: 1100/10000, Loss: 0.05921652913093567\n",
      "Average test loss:  0.0022\n",
      "Iteration: 1101/10000, Loss: 0.038966406136751175\n",
      "Iteration: 1102/10000, Loss: 0.03586072102189064\n",
      "Iteration: 1103/10000, Loss: 0.03469061106443405\n",
      "Iteration: 1104/10000, Loss: 0.045733340084552765\n",
      "Iteration: 1105/10000, Loss: 0.052873171865940094\n",
      "Iteration: 1106/10000, Loss: 0.05645712837576866\n",
      "Iteration: 1107/10000, Loss: 0.0509302131831646\n",
      "Iteration: 1108/10000, Loss: 0.05391695350408554\n",
      "Iteration: 1109/10000, Loss: 0.046755217015743256\n",
      "Iteration: 1110/10000, Loss: 0.03701300173997879\n",
      "Iteration: 1111/10000, Loss: 0.04186692088842392\n",
      "Iteration: 1112/10000, Loss: 0.04644674435257912\n",
      "Iteration: 1113/10000, Loss: 0.0461604930460453\n",
      "Iteration: 1114/10000, Loss: 0.04866756498813629\n",
      "Iteration: 1115/10000, Loss: 0.04070017486810684\n",
      "Iteration: 1116/10000, Loss: 0.0520813949406147\n",
      "Iteration: 1117/10000, Loss: 0.056878071278333664\n",
      "Iteration: 1118/10000, Loss: 0.041243746876716614\n",
      "Iteration: 1119/10000, Loss: 0.04798944666981697\n",
      "Iteration: 1120/10000, Loss: 0.045987069606781006\n",
      "Iteration: 1121/10000, Loss: 0.040745608508586884\n",
      "Iteration: 1122/10000, Loss: 0.05588456988334656\n",
      "Iteration: 1123/10000, Loss: 0.046517711132764816\n",
      "Iteration: 1124/10000, Loss: 0.04180285707116127\n",
      "Iteration: 1125/10000, Loss: 0.07329495996236801\n",
      "Iteration: 1126/10000, Loss: 0.06436803936958313\n",
      "Iteration: 1127/10000, Loss: 0.04180397093296051\n",
      "Iteration: 1128/10000, Loss: 0.06689850240945816\n",
      "Iteration: 1129/10000, Loss: 0.038216978311538696\n",
      "Iteration: 1130/10000, Loss: 0.04753805696964264\n",
      "Iteration: 1131/10000, Loss: 0.04272359237074852\n",
      "Iteration: 1132/10000, Loss: 0.042777638882398605\n",
      "Iteration: 1133/10000, Loss: 0.04865948483347893\n",
      "Iteration: 1134/10000, Loss: 0.04186991974711418\n",
      "Iteration: 1135/10000, Loss: 0.04909077659249306\n",
      "Iteration: 1136/10000, Loss: 0.04808635637164116\n",
      "Iteration: 1137/10000, Loss: 0.04666519537568092\n",
      "Iteration: 1138/10000, Loss: 0.034073006361722946\n",
      "Iteration: 1139/10000, Loss: 0.03262979909777641\n",
      "Iteration: 1140/10000, Loss: 0.03649075701832771\n",
      "Iteration: 1141/10000, Loss: 0.039140284061431885\n",
      "Iteration: 1142/10000, Loss: 0.06751970946788788\n",
      "Iteration: 1143/10000, Loss: 0.0349753238260746\n",
      "Iteration: 1144/10000, Loss: 0.028697151690721512\n",
      "Iteration: 1145/10000, Loss: 0.03300867974758148\n",
      "Iteration: 1146/10000, Loss: 0.03318224474787712\n",
      "Iteration: 1147/10000, Loss: 0.03554758056998253\n",
      "Iteration: 1148/10000, Loss: 0.046213045716285706\n",
      "Iteration: 1149/10000, Loss: 0.05216153338551521\n",
      "Iteration: 1150/10000, Loss: 0.043253395706415176\n",
      "Iteration: 1151/10000, Loss: 0.046401288360357285\n",
      "Iteration: 1152/10000, Loss: 0.04096752032637596\n",
      "Iteration: 1153/10000, Loss: 0.03743671998381615\n",
      "Iteration: 1154/10000, Loss: 0.0317809134721756\n",
      "Iteration: 1155/10000, Loss: 0.04973560571670532\n",
      "Iteration: 1156/10000, Loss: 0.03492537885904312\n",
      "Iteration: 1157/10000, Loss: 0.04376647621393204\n",
      "Iteration: 1158/10000, Loss: 0.056986693292856216\n",
      "Iteration: 1159/10000, Loss: 0.04352286085486412\n",
      "Iteration: 1160/10000, Loss: 0.03801862895488739\n",
      "Iteration: 1161/10000, Loss: 0.05506294593214989\n",
      "Iteration: 1162/10000, Loss: 0.03420264273881912\n",
      "Iteration: 1163/10000, Loss: 0.05082337185740471\n",
      "Iteration: 1164/10000, Loss: 0.058150388300418854\n",
      "Iteration: 1165/10000, Loss: 0.037470847368240356\n",
      "Iteration: 1166/10000, Loss: 0.04516574740409851\n",
      "Iteration: 1167/10000, Loss: 0.03993119299411774\n",
      "Iteration: 1168/10000, Loss: 0.05081864818930626\n",
      "Iteration: 1169/10000, Loss: 0.06470971554517746\n",
      "Iteration: 1170/10000, Loss: 0.04096553474664688\n",
      "Iteration: 1171/10000, Loss: 0.03964998945593834\n",
      "Iteration: 1172/10000, Loss: 0.05180095508694649\n",
      "Iteration: 1173/10000, Loss: 0.03598872572183609\n",
      "Iteration: 1174/10000, Loss: 0.06943812966346741\n",
      "Iteration: 1175/10000, Loss: 0.04118574038147926\n",
      "Iteration: 1176/10000, Loss: 0.05587496981024742\n",
      "Iteration: 1177/10000, Loss: 0.046222515404224396\n",
      "Iteration: 1178/10000, Loss: 0.05182335898280144\n",
      "Iteration: 1179/10000, Loss: 0.03620489686727524\n",
      "Iteration: 1180/10000, Loss: 0.060120224952697754\n",
      "Iteration: 1181/10000, Loss: 0.03478022292256355\n",
      "Iteration: 1182/10000, Loss: 0.04497172310948372\n",
      "Iteration: 1183/10000, Loss: 0.03689956292510033\n",
      "Iteration: 1184/10000, Loss: 0.034270260483026505\n",
      "Iteration: 1185/10000, Loss: 0.03350711613893509\n",
      "Iteration: 1186/10000, Loss: 0.04275352135300636\n",
      "Iteration: 1187/10000, Loss: 0.03915751725435257\n",
      "Iteration: 1188/10000, Loss: 0.05447273328900337\n",
      "Iteration: 1189/10000, Loss: 0.04821547865867615\n",
      "Iteration: 1190/10000, Loss: 0.03647453337907791\n",
      "Iteration: 1191/10000, Loss: 0.038902346044778824\n",
      "Iteration: 1192/10000, Loss: 0.03744852542877197\n",
      "Iteration: 1193/10000, Loss: 0.03823186084628105\n",
      "Iteration: 1194/10000, Loss: 0.038254622370004654\n",
      "Iteration: 1195/10000, Loss: 0.052518803626298904\n",
      "Iteration: 1196/10000, Loss: 0.04192527011036873\n",
      "Iteration: 1197/10000, Loss: 0.04824821650981903\n",
      "Iteration: 1198/10000, Loss: 0.038161616772413254\n",
      "Iteration: 1199/10000, Loss: 0.044569067656993866\n",
      "Iteration: 1200/10000, Loss: 0.03119492717087269\n",
      "Average test loss:  0.0038\n",
      "Iteration: 1201/10000, Loss: 0.05403212830424309\n",
      "Iteration: 1202/10000, Loss: 0.030269047245383263\n",
      "Iteration: 1203/10000, Loss: 0.05149294063448906\n",
      "Iteration: 1204/10000, Loss: 0.03988664597272873\n",
      "Iteration: 1205/10000, Loss: 0.049345966428518295\n",
      "Iteration: 1206/10000, Loss: 0.035524047911167145\n",
      "Iteration: 1207/10000, Loss: 0.05619162321090698\n",
      "Iteration: 1208/10000, Loss: 0.056459929794073105\n",
      "Iteration: 1209/10000, Loss: 0.03360110521316528\n",
      "Iteration: 1210/10000, Loss: 0.03770769014954567\n",
      "Iteration: 1211/10000, Loss: 0.0417904295027256\n",
      "Iteration: 1212/10000, Loss: 0.04984333738684654\n",
      "Iteration: 1213/10000, Loss: 0.06635843962430954\n",
      "Iteration: 1214/10000, Loss: 0.03475097939372063\n",
      "Iteration: 1215/10000, Loss: 0.044779784977436066\n",
      "Iteration: 1216/10000, Loss: 0.03725406900048256\n",
      "Iteration: 1217/10000, Loss: 0.05717397853732109\n",
      "Iteration: 1218/10000, Loss: 0.03494774177670479\n",
      "Iteration: 1219/10000, Loss: 0.03815978020429611\n",
      "Iteration: 1220/10000, Loss: 0.03787487372756004\n",
      "Iteration: 1221/10000, Loss: 0.0329313799738884\n",
      "Iteration: 1222/10000, Loss: 0.03946603089570999\n",
      "Iteration: 1223/10000, Loss: 0.038295015692710876\n",
      "Iteration: 1224/10000, Loss: 0.03534636273980141\n",
      "Iteration: 1225/10000, Loss: 0.03488605469465256\n",
      "Iteration: 1226/10000, Loss: 0.053736645728349686\n",
      "Iteration: 1227/10000, Loss: 0.05399110168218613\n",
      "Iteration: 1228/10000, Loss: 0.04656573012471199\n",
      "Iteration: 1229/10000, Loss: 0.04662056639790535\n",
      "Iteration: 1230/10000, Loss: 0.03969917446374893\n",
      "Iteration: 1231/10000, Loss: 0.04352206364274025\n",
      "Iteration: 1232/10000, Loss: 0.04142296314239502\n",
      "Iteration: 1233/10000, Loss: 0.05402475968003273\n",
      "Iteration: 1234/10000, Loss: 0.04600520059466362\n",
      "Iteration: 1235/10000, Loss: 0.03903498500585556\n",
      "Iteration: 1236/10000, Loss: 0.04532524198293686\n",
      "Iteration: 1237/10000, Loss: 0.03180740028619766\n",
      "Iteration: 1238/10000, Loss: 0.05369032174348831\n",
      "Iteration: 1239/10000, Loss: 0.035589639097452164\n",
      "Iteration: 1240/10000, Loss: 0.0480208545923233\n",
      "Iteration: 1241/10000, Loss: 0.03265475109219551\n",
      "Iteration: 1242/10000, Loss: 0.0385698527097702\n",
      "Iteration: 1243/10000, Loss: 0.06068964675068855\n",
      "Iteration: 1244/10000, Loss: 0.03279072791337967\n",
      "Iteration: 1245/10000, Loss: 0.03908440098166466\n",
      "Iteration: 1246/10000, Loss: 0.03793296962976456\n",
      "Iteration: 1247/10000, Loss: 0.04468929395079613\n",
      "Iteration: 1248/10000, Loss: 0.03838207200169563\n",
      "Iteration: 1249/10000, Loss: 0.04625813663005829\n",
      "Iteration: 1250/10000, Loss: 0.050167396664619446\n",
      "Iteration: 1251/10000, Loss: 0.057012006640434265\n",
      "Iteration: 1252/10000, Loss: 0.04675935581326485\n",
      "Iteration: 1253/10000, Loss: 0.03628651425242424\n",
      "Iteration: 1254/10000, Loss: 0.04336581751704216\n",
      "Iteration: 1255/10000, Loss: 0.04889138787984848\n",
      "Iteration: 1256/10000, Loss: 0.039474740624427795\n",
      "Iteration: 1257/10000, Loss: 0.03258483111858368\n",
      "Iteration: 1258/10000, Loss: 0.0329473651945591\n",
      "Iteration: 1259/10000, Loss: 0.051429297775030136\n",
      "Iteration: 1260/10000, Loss: 0.04691395163536072\n",
      "Iteration: 1261/10000, Loss: 0.034406259655952454\n",
      "Iteration: 1262/10000, Loss: 0.04785565659403801\n",
      "Iteration: 1263/10000, Loss: 0.051254525780677795\n",
      "Iteration: 1264/10000, Loss: 0.026682494208216667\n",
      "Iteration: 1265/10000, Loss: 0.05504667013883591\n",
      "Iteration: 1266/10000, Loss: 0.042887669056653976\n",
      "Iteration: 1267/10000, Loss: 0.03446751832962036\n",
      "Iteration: 1268/10000, Loss: 0.03181060031056404\n",
      "Iteration: 1269/10000, Loss: 0.049461036920547485\n",
      "Iteration: 1270/10000, Loss: 0.0382087267935276\n",
      "Iteration: 1271/10000, Loss: 0.044732678681612015\n",
      "Iteration: 1272/10000, Loss: 0.0389343798160553\n",
      "Iteration: 1273/10000, Loss: 0.036797236651182175\n",
      "Iteration: 1274/10000, Loss: 0.05294285714626312\n",
      "Iteration: 1275/10000, Loss: 0.03554097190499306\n",
      "Iteration: 1276/10000, Loss: 0.04503421112895012\n",
      "Iteration: 1277/10000, Loss: 0.03837050497531891\n",
      "Iteration: 1278/10000, Loss: 0.035071101039648056\n",
      "Iteration: 1279/10000, Loss: 0.03663913160562515\n",
      "Iteration: 1280/10000, Loss: 0.03094342164695263\n",
      "Iteration: 1281/10000, Loss: 0.035986077040433884\n",
      "Iteration: 1282/10000, Loss: 0.033639583736658096\n",
      "Iteration: 1283/10000, Loss: 0.02872571535408497\n",
      "Iteration: 1284/10000, Loss: 0.06881087273359299\n",
      "Iteration: 1285/10000, Loss: 0.040946658700704575\n",
      "Iteration: 1286/10000, Loss: 0.03408239409327507\n",
      "Iteration: 1287/10000, Loss: 0.05108087882399559\n",
      "Iteration: 1288/10000, Loss: 0.05861096829175949\n",
      "Iteration: 1289/10000, Loss: 0.040429893881082535\n",
      "Iteration: 1290/10000, Loss: 0.03733937069773674\n",
      "Iteration: 1291/10000, Loss: 0.05580095946788788\n",
      "Iteration: 1292/10000, Loss: 0.040215421468019485\n",
      "Iteration: 1293/10000, Loss: 0.03522178903222084\n",
      "Iteration: 1294/10000, Loss: 0.03155098482966423\n",
      "Iteration: 1295/10000, Loss: 0.046721410006284714\n",
      "Iteration: 1296/10000, Loss: 0.04620235040783882\n",
      "Iteration: 1297/10000, Loss: 0.03895231708884239\n",
      "Iteration: 1298/10000, Loss: 0.04700923338532448\n",
      "Iteration: 1299/10000, Loss: 0.0383007638156414\n",
      "Iteration: 1300/10000, Loss: 0.037820279598236084\n",
      "Average test loss:  0.0034\n",
      "Iteration: 1301/10000, Loss: 0.03269420564174652\n",
      "Iteration: 1302/10000, Loss: 0.03950711712241173\n",
      "Iteration: 1303/10000, Loss: 0.028307443484663963\n",
      "Iteration: 1304/10000, Loss: 0.0402190275490284\n",
      "Iteration: 1305/10000, Loss: 0.04925890266895294\n",
      "Iteration: 1306/10000, Loss: 0.03967060148715973\n",
      "Iteration: 1307/10000, Loss: 0.036135122179985046\n",
      "Iteration: 1308/10000, Loss: 0.052494026720523834\n",
      "Iteration: 1309/10000, Loss: 0.04818003252148628\n",
      "Iteration: 1310/10000, Loss: 0.07173383235931396\n",
      "Iteration: 1311/10000, Loss: 0.03609427437186241\n",
      "Iteration: 1312/10000, Loss: 0.03262665867805481\n",
      "Iteration: 1313/10000, Loss: 0.041713617742061615\n",
      "Iteration: 1314/10000, Loss: 0.0381644144654274\n",
      "Iteration: 1315/10000, Loss: 0.028835143893957138\n",
      "Iteration: 1316/10000, Loss: 0.029630517587065697\n",
      "Iteration: 1317/10000, Loss: 0.059019774198532104\n",
      "Iteration: 1318/10000, Loss: 0.03162461519241333\n",
      "Iteration: 1319/10000, Loss: 0.04322393238544464\n",
      "Iteration: 1320/10000, Loss: 0.04307052865624428\n",
      "Iteration: 1321/10000, Loss: 0.053078435361385345\n",
      "Iteration: 1322/10000, Loss: 0.02734563872218132\n",
      "Iteration: 1323/10000, Loss: 0.037149637937545776\n",
      "Iteration: 1324/10000, Loss: 0.05468354374170303\n",
      "Iteration: 1325/10000, Loss: 0.039524875581264496\n",
      "Iteration: 1326/10000, Loss: 0.031385306268930435\n",
      "Iteration: 1327/10000, Loss: 0.04234522581100464\n",
      "Iteration: 1328/10000, Loss: 0.037346359342336655\n",
      "Iteration: 1329/10000, Loss: 0.03662082552909851\n",
      "Iteration: 1330/10000, Loss: 0.04959535226225853\n",
      "Iteration: 1331/10000, Loss: 0.03287670016288757\n",
      "Iteration: 1332/10000, Loss: 0.0453663170337677\n",
      "Iteration: 1333/10000, Loss: 0.061797887086868286\n",
      "Iteration: 1334/10000, Loss: 0.03488198667764664\n",
      "Iteration: 1335/10000, Loss: 0.03274689242243767\n",
      "Iteration: 1336/10000, Loss: 0.024493834003806114\n",
      "Iteration: 1337/10000, Loss: 0.03737172111868858\n",
      "Iteration: 1338/10000, Loss: 0.04372866451740265\n",
      "Iteration: 1339/10000, Loss: 0.03149604797363281\n",
      "Iteration: 1340/10000, Loss: 0.030233284458518028\n",
      "Iteration: 1341/10000, Loss: 0.043274104595184326\n",
      "Iteration: 1342/10000, Loss: 0.04183068126440048\n",
      "Iteration: 1343/10000, Loss: 0.04398242384195328\n",
      "Iteration: 1344/10000, Loss: 0.03998597711324692\n",
      "Iteration: 1345/10000, Loss: 0.035919517278671265\n",
      "Iteration: 1346/10000, Loss: 0.05650980770587921\n",
      "Iteration: 1347/10000, Loss: 0.03796961158514023\n",
      "Iteration: 1348/10000, Loss: 0.04265584424138069\n",
      "Iteration: 1349/10000, Loss: 0.0702625960111618\n",
      "Iteration: 1350/10000, Loss: 0.042322710156440735\n",
      "Iteration: 1351/10000, Loss: 0.03867478668689728\n",
      "Iteration: 1352/10000, Loss: 0.03376391530036926\n",
      "Iteration: 1353/10000, Loss: 0.031973570585250854\n",
      "Iteration: 1354/10000, Loss: 0.03016311675310135\n",
      "Iteration: 1355/10000, Loss: 0.03457663208246231\n",
      "Iteration: 1356/10000, Loss: 0.036296501755714417\n",
      "Iteration: 1357/10000, Loss: 0.04513583704829216\n",
      "Iteration: 1358/10000, Loss: 0.04247668758034706\n",
      "Iteration: 1359/10000, Loss: 0.025761624798178673\n",
      "Iteration: 1360/10000, Loss: 0.03593648225069046\n",
      "Iteration: 1361/10000, Loss: 0.035970840603113174\n",
      "Iteration: 1362/10000, Loss: 0.05194242298603058\n",
      "Iteration: 1363/10000, Loss: 0.04441762715578079\n",
      "Iteration: 1364/10000, Loss: 0.03045177459716797\n",
      "Iteration: 1365/10000, Loss: 0.051155395805835724\n",
      "Iteration: 1366/10000, Loss: 0.03575478866696358\n",
      "Iteration: 1367/10000, Loss: 0.03559645265340805\n",
      "Iteration: 1368/10000, Loss: 0.04544050991535187\n",
      "Iteration: 1369/10000, Loss: 0.025843339040875435\n",
      "Iteration: 1370/10000, Loss: 0.04468419775366783\n",
      "Iteration: 1371/10000, Loss: 0.04247259348630905\n",
      "Iteration: 1372/10000, Loss: 0.03962564840912819\n",
      "Iteration: 1373/10000, Loss: 0.03770669177174568\n",
      "Iteration: 1374/10000, Loss: 0.03612632304430008\n",
      "Iteration: 1375/10000, Loss: 0.03056449256837368\n",
      "Iteration: 1376/10000, Loss: 0.040455855429172516\n",
      "Iteration: 1377/10000, Loss: 0.04831743612885475\n",
      "Iteration: 1378/10000, Loss: 0.04916932433843613\n",
      "Iteration: 1379/10000, Loss: 0.02906699851155281\n",
      "Iteration: 1380/10000, Loss: 0.035990696400403976\n",
      "Iteration: 1381/10000, Loss: 0.029133368283510208\n",
      "Iteration: 1382/10000, Loss: 0.0452851764857769\n",
      "Iteration: 1383/10000, Loss: 0.032491534948349\n",
      "Iteration: 1384/10000, Loss: 0.03778752684593201\n",
      "Iteration: 1385/10000, Loss: 0.031620558351278305\n",
      "Iteration: 1386/10000, Loss: 0.0444449707865715\n",
      "Iteration: 1387/10000, Loss: 0.0412515290081501\n",
      "Iteration: 1388/10000, Loss: 0.030424267053604126\n",
      "Iteration: 1389/10000, Loss: 0.031838174909353256\n",
      "Iteration: 1390/10000, Loss: 0.03215813264250755\n",
      "Iteration: 1391/10000, Loss: 0.04771111533045769\n",
      "Iteration: 1392/10000, Loss: 0.04579127952456474\n",
      "Iteration: 1393/10000, Loss: 0.022427882999181747\n",
      "Iteration: 1394/10000, Loss: 0.03932564705610275\n",
      "Iteration: 1395/10000, Loss: 0.030027471482753754\n",
      "Iteration: 1396/10000, Loss: 0.03176584094762802\n",
      "Iteration: 1397/10000, Loss: 0.031207585707306862\n",
      "Iteration: 1398/10000, Loss: 0.05942005291581154\n",
      "Iteration: 1399/10000, Loss: 0.05384258180856705\n",
      "Iteration: 1400/10000, Loss: 0.031741175800561905\n",
      "Average test loss:  0.0030\n",
      "Iteration: 1401/10000, Loss: 0.061631374061107635\n",
      "Iteration: 1402/10000, Loss: 0.03147217631340027\n",
      "Iteration: 1403/10000, Loss: 0.029073664918541908\n",
      "Iteration: 1404/10000, Loss: 0.04390941932797432\n",
      "Iteration: 1405/10000, Loss: 0.043140798807144165\n",
      "Iteration: 1406/10000, Loss: 0.0333024263381958\n",
      "Iteration: 1407/10000, Loss: 0.02848830260336399\n",
      "Iteration: 1408/10000, Loss: 0.031926512718200684\n",
      "Iteration: 1409/10000, Loss: 0.042656369507312775\n",
      "Iteration: 1410/10000, Loss: 0.039375558495521545\n",
      "Iteration: 1411/10000, Loss: 0.033637747168540955\n",
      "Iteration: 1412/10000, Loss: 0.03551197052001953\n",
      "Iteration: 1413/10000, Loss: 0.029339373111724854\n",
      "Iteration: 1414/10000, Loss: 0.03023131936788559\n",
      "Iteration: 1415/10000, Loss: 0.039893947541713715\n",
      "Iteration: 1416/10000, Loss: 0.05626937001943588\n",
      "Iteration: 1417/10000, Loss: 0.03852623701095581\n",
      "Iteration: 1418/10000, Loss: 0.026844577863812447\n",
      "Iteration: 1419/10000, Loss: 0.04245971143245697\n",
      "Iteration: 1420/10000, Loss: 0.04556064307689667\n",
      "Iteration: 1421/10000, Loss: 0.045345425605773926\n",
      "Iteration: 1422/10000, Loss: 0.04676157236099243\n",
      "Iteration: 1423/10000, Loss: 0.040805134922266006\n",
      "Iteration: 1424/10000, Loss: 0.04352416470646858\n",
      "Iteration: 1425/10000, Loss: 0.047131698578596115\n",
      "Iteration: 1426/10000, Loss: 0.03492789715528488\n",
      "Iteration: 1427/10000, Loss: 0.04177479073405266\n",
      "Iteration: 1428/10000, Loss: 0.03843346983194351\n",
      "Iteration: 1429/10000, Loss: 0.05588794872164726\n",
      "Iteration: 1430/10000, Loss: 0.042686644941568375\n",
      "Iteration: 1431/10000, Loss: 0.06704196333885193\n",
      "Iteration: 1432/10000, Loss: 0.0401848703622818\n",
      "Iteration: 1433/10000, Loss: 0.0356927327811718\n",
      "Iteration: 1434/10000, Loss: 0.050575170665979385\n",
      "Iteration: 1435/10000, Loss: 0.061633624136447906\n",
      "Iteration: 1436/10000, Loss: 0.03164491057395935\n",
      "Iteration: 1437/10000, Loss: 0.04074649140238762\n",
      "Iteration: 1438/10000, Loss: 0.04339468479156494\n",
      "Iteration: 1439/10000, Loss: 0.05595622956752777\n",
      "Iteration: 1440/10000, Loss: 0.04064168781042099\n",
      "Iteration: 1441/10000, Loss: 0.056821759790182114\n",
      "Iteration: 1442/10000, Loss: 0.037219010293483734\n",
      "Iteration: 1443/10000, Loss: 0.036726295948028564\n",
      "Iteration: 1444/10000, Loss: 0.028821300715208054\n",
      "Iteration: 1445/10000, Loss: 0.03578100726008415\n",
      "Iteration: 1446/10000, Loss: 0.023927416652441025\n",
      "Iteration: 1447/10000, Loss: 0.039608102291822433\n",
      "Iteration: 1448/10000, Loss: 0.03547611087560654\n",
      "Iteration: 1449/10000, Loss: 0.02983156591653824\n",
      "Iteration: 1450/10000, Loss: 0.06514246761798859\n",
      "Iteration: 1451/10000, Loss: 0.03707413002848625\n",
      "Iteration: 1452/10000, Loss: 0.0322776734828949\n",
      "Iteration: 1453/10000, Loss: 0.04031900689005852\n",
      "Iteration: 1454/10000, Loss: 0.047495368868112564\n",
      "Iteration: 1455/10000, Loss: 0.053234122693538666\n",
      "Iteration: 1456/10000, Loss: 0.03998972848057747\n",
      "Iteration: 1457/10000, Loss: 0.0501350462436676\n",
      "Iteration: 1458/10000, Loss: 0.037593621760606766\n",
      "Iteration: 1459/10000, Loss: 0.03588802367448807\n",
      "Iteration: 1460/10000, Loss: 0.043391529470682144\n",
      "Iteration: 1461/10000, Loss: 0.03467594087123871\n",
      "Iteration: 1462/10000, Loss: 0.036820318549871445\n",
      "Iteration: 1463/10000, Loss: 0.04569263011217117\n",
      "Iteration: 1464/10000, Loss: 0.018679209053516388\n",
      "Iteration: 1465/10000, Loss: 0.039237525314092636\n",
      "Iteration: 1466/10000, Loss: 0.043010491877794266\n",
      "Iteration: 1467/10000, Loss: 0.04427853226661682\n",
      "Iteration: 1468/10000, Loss: 0.025269566103816032\n",
      "Iteration: 1469/10000, Loss: 0.029443904757499695\n",
      "Iteration: 1470/10000, Loss: 0.029079727828502655\n",
      "Iteration: 1471/10000, Loss: 0.03986566513776779\n",
      "Iteration: 1472/10000, Loss: 0.03919099643826485\n",
      "Iteration: 1473/10000, Loss: 0.029961038380861282\n",
      "Iteration: 1474/10000, Loss: 0.03707331418991089\n",
      "Iteration: 1475/10000, Loss: 0.04135248810052872\n",
      "Iteration: 1476/10000, Loss: 0.03585733473300934\n",
      "Iteration: 1477/10000, Loss: 0.045248325914144516\n",
      "Iteration: 1478/10000, Loss: 0.03973916545510292\n",
      "Iteration: 1479/10000, Loss: 0.04584386572241783\n",
      "Iteration: 1480/10000, Loss: 0.04094979912042618\n",
      "Iteration: 1481/10000, Loss: 0.02739592082798481\n",
      "Iteration: 1482/10000, Loss: 0.03529369831085205\n",
      "Iteration: 1483/10000, Loss: 0.025352459400892258\n",
      "Iteration: 1484/10000, Loss: 0.04104272648692131\n",
      "Iteration: 1485/10000, Loss: 0.04845289885997772\n",
      "Iteration: 1486/10000, Loss: 0.03772461414337158\n",
      "Iteration: 1487/10000, Loss: 0.03433633968234062\n",
      "Iteration: 1488/10000, Loss: 0.04383755847811699\n",
      "Iteration: 1489/10000, Loss: 0.04848426580429077\n",
      "Iteration: 1490/10000, Loss: 0.033501818776130676\n",
      "Iteration: 1491/10000, Loss: 0.04469210281968117\n",
      "Iteration: 1492/10000, Loss: 0.04314703494310379\n",
      "Iteration: 1493/10000, Loss: 0.04405136778950691\n",
      "Iteration: 1494/10000, Loss: 0.044708456844091415\n",
      "Iteration: 1495/10000, Loss: 0.049561042338609695\n",
      "Iteration: 1496/10000, Loss: 0.0324581004679203\n",
      "Iteration: 1497/10000, Loss: 0.0375271700322628\n",
      "Iteration: 1498/10000, Loss: 0.04387109726667404\n",
      "Iteration: 1499/10000, Loss: 0.030874473974108696\n",
      "Iteration: 1500/10000, Loss: 0.03250224143266678\n",
      "Average test loss:  0.0029\n",
      "Iteration: 1501/10000, Loss: 0.04969296231865883\n",
      "Iteration: 1502/10000, Loss: 0.021876487880945206\n",
      "Iteration: 1503/10000, Loss: 0.030867362394928932\n",
      "Iteration: 1504/10000, Loss: 0.04695947840809822\n",
      "Iteration: 1505/10000, Loss: 0.07004240155220032\n",
      "Iteration: 1506/10000, Loss: 0.025411512702703476\n",
      "Iteration: 1507/10000, Loss: 0.05838938429951668\n",
      "Iteration: 1508/10000, Loss: 0.028937075287103653\n",
      "Iteration: 1509/10000, Loss: 0.04529278352856636\n",
      "Iteration: 1510/10000, Loss: 0.04509282112121582\n",
      "Iteration: 1511/10000, Loss: 0.04045763984322548\n",
      "Iteration: 1512/10000, Loss: 0.035335723310709\n",
      "Iteration: 1513/10000, Loss: 0.04397495836019516\n",
      "Iteration: 1514/10000, Loss: 0.03909841924905777\n",
      "Iteration: 1515/10000, Loss: 0.04365890473127365\n",
      "Iteration: 1516/10000, Loss: 0.05159255117177963\n",
      "Iteration: 1517/10000, Loss: 0.038319412618875504\n",
      "Iteration: 1518/10000, Loss: 0.05097153037786484\n",
      "Iteration: 1519/10000, Loss: 0.04155571013689041\n",
      "Iteration: 1520/10000, Loss: 0.03570769727230072\n",
      "Iteration: 1521/10000, Loss: 0.03346174582839012\n",
      "Iteration: 1522/10000, Loss: 0.038314610719680786\n",
      "Iteration: 1523/10000, Loss: 0.02160647325217724\n",
      "Iteration: 1524/10000, Loss: 0.04444342851638794\n",
      "Iteration: 1525/10000, Loss: 0.05034917593002319\n",
      "Iteration: 1526/10000, Loss: 0.040756288915872574\n",
      "Iteration: 1527/10000, Loss: 0.036085695028305054\n",
      "Iteration: 1528/10000, Loss: 0.03041921555995941\n",
      "Iteration: 1529/10000, Loss: 0.028265465050935745\n",
      "Iteration: 1530/10000, Loss: 0.038891445845365524\n",
      "Iteration: 1531/10000, Loss: 0.031951453536748886\n",
      "Iteration: 1532/10000, Loss: 0.038081396371126175\n",
      "Iteration: 1533/10000, Loss: 0.0348343625664711\n",
      "Iteration: 1534/10000, Loss: 0.030339887365698814\n",
      "Iteration: 1535/10000, Loss: 0.032235950231552124\n",
      "Iteration: 1536/10000, Loss: 0.03411827236413956\n",
      "Iteration: 1537/10000, Loss: 0.02810349129140377\n",
      "Iteration: 1538/10000, Loss: 0.035938601940870285\n",
      "Iteration: 1539/10000, Loss: 0.02833375707268715\n",
      "Iteration: 1540/10000, Loss: 0.022795874625444412\n",
      "Iteration: 1541/10000, Loss: 0.03321213647723198\n",
      "Iteration: 1542/10000, Loss: 0.02949131466448307\n",
      "Iteration: 1543/10000, Loss: 0.03420126438140869\n",
      "Iteration: 1544/10000, Loss: 0.0453127957880497\n",
      "Iteration: 1545/10000, Loss: 0.028793515637516975\n",
      "Iteration: 1546/10000, Loss: 0.03881244733929634\n",
      "Iteration: 1547/10000, Loss: 0.018375366926193237\n",
      "Iteration: 1548/10000, Loss: 0.03742971271276474\n",
      "Iteration: 1549/10000, Loss: 0.022150933742523193\n",
      "Iteration: 1550/10000, Loss: 0.044608987867832184\n",
      "Iteration: 1551/10000, Loss: 0.03630127012729645\n",
      "Iteration: 1552/10000, Loss: 0.022947639226913452\n",
      "Iteration: 1553/10000, Loss: 0.048198699951171875\n",
      "Iteration: 1554/10000, Loss: 0.03275001794099808\n",
      "Iteration: 1555/10000, Loss: 0.03483588993549347\n",
      "Iteration: 1556/10000, Loss: 0.02767711691558361\n",
      "Iteration: 1557/10000, Loss: 0.036690354347229004\n",
      "Iteration: 1558/10000, Loss: 0.04158354178071022\n",
      "Iteration: 1559/10000, Loss: 0.03314226493239403\n",
      "Iteration: 1560/10000, Loss: 0.03844436630606651\n",
      "Iteration: 1561/10000, Loss: 0.04316207394003868\n",
      "Iteration: 1562/10000, Loss: 0.03451133146882057\n",
      "Iteration: 1563/10000, Loss: 0.03235447034239769\n",
      "Iteration: 1564/10000, Loss: 0.02706987038254738\n",
      "Iteration: 1565/10000, Loss: 0.029661886394023895\n",
      "Iteration: 1566/10000, Loss: 0.036418404430150986\n",
      "Iteration: 1567/10000, Loss: 0.032651226967573166\n",
      "Iteration: 1568/10000, Loss: 0.028257325291633606\n",
      "Iteration: 1569/10000, Loss: 0.05714363232254982\n",
      "Iteration: 1570/10000, Loss: 0.02948651649057865\n",
      "Iteration: 1571/10000, Loss: 0.045425500720739365\n",
      "Iteration: 1572/10000, Loss: 0.037577468901872635\n",
      "Iteration: 1573/10000, Loss: 0.033545009791851044\n",
      "Iteration: 1574/10000, Loss: 0.03362579271197319\n",
      "Iteration: 1575/10000, Loss: 0.022405872121453285\n",
      "Iteration: 1576/10000, Loss: 0.03337366506457329\n",
      "Iteration: 1577/10000, Loss: 0.04872472211718559\n",
      "Iteration: 1578/10000, Loss: 0.04206681251525879\n",
      "Iteration: 1579/10000, Loss: 0.04863038659095764\n",
      "Iteration: 1580/10000, Loss: 0.03612344712018967\n",
      "Iteration: 1581/10000, Loss: 0.0293683223426342\n",
      "Iteration: 1582/10000, Loss: 0.044468414038419724\n",
      "Iteration: 1583/10000, Loss: 0.052069950848817825\n",
      "Iteration: 1584/10000, Loss: 0.03589333966374397\n",
      "Iteration: 1585/10000, Loss: 0.03493507206439972\n",
      "Iteration: 1586/10000, Loss: 0.05890980735421181\n",
      "Iteration: 1587/10000, Loss: 0.03740280121564865\n",
      "Iteration: 1588/10000, Loss: 0.03765260800719261\n",
      "Iteration: 1589/10000, Loss: 0.03971872106194496\n",
      "Iteration: 1590/10000, Loss: 0.039441317319869995\n",
      "Iteration: 1591/10000, Loss: 0.0523705929517746\n",
      "Iteration: 1592/10000, Loss: 0.023611949756741524\n",
      "Iteration: 1593/10000, Loss: 0.02957383170723915\n",
      "Iteration: 1594/10000, Loss: 0.03913741931319237\n",
      "Iteration: 1595/10000, Loss: 0.03620364889502525\n",
      "Iteration: 1596/10000, Loss: 0.03547653555870056\n",
      "Iteration: 1597/10000, Loss: 0.028755437582731247\n",
      "Iteration: 1598/10000, Loss: 0.041633084416389465\n",
      "Iteration: 1599/10000, Loss: 0.02941886894404888\n",
      "Iteration: 1600/10000, Loss: 0.045740947127342224\n",
      "Average test loss:  0.0025\n",
      "Iteration: 1601/10000, Loss: 0.023536309599876404\n",
      "Iteration: 1602/10000, Loss: 0.06870140880346298\n",
      "Iteration: 1603/10000, Loss: 0.030850499868392944\n",
      "Iteration: 1604/10000, Loss: 0.03670068457722664\n",
      "Iteration: 1605/10000, Loss: 0.03472910448908806\n",
      "Iteration: 1606/10000, Loss: 0.03800666332244873\n",
      "Iteration: 1607/10000, Loss: 0.05259983614087105\n",
      "Iteration: 1608/10000, Loss: 0.04262764751911163\n",
      "Iteration: 1609/10000, Loss: 0.03748255968093872\n",
      "Iteration: 1610/10000, Loss: 0.041780807077884674\n",
      "Iteration: 1611/10000, Loss: 0.04073476046323776\n",
      "Iteration: 1612/10000, Loss: 0.027937278151512146\n",
      "Iteration: 1613/10000, Loss: 0.03862304612994194\n",
      "Iteration: 1614/10000, Loss: 0.03662257641553879\n",
      "Iteration: 1615/10000, Loss: 0.0636364221572876\n",
      "Iteration: 1616/10000, Loss: 0.02746369130909443\n",
      "Iteration: 1617/10000, Loss: 0.03996617719531059\n",
      "Iteration: 1618/10000, Loss: 0.03679780289530754\n",
      "Iteration: 1619/10000, Loss: 0.03857314959168434\n",
      "Iteration: 1620/10000, Loss: 0.04396090656518936\n",
      "Iteration: 1621/10000, Loss: 0.03001825511455536\n",
      "Iteration: 1622/10000, Loss: 0.032590195536613464\n",
      "Iteration: 1623/10000, Loss: 0.031726986169815063\n",
      "Iteration: 1624/10000, Loss: 0.05372193828225136\n",
      "Iteration: 1625/10000, Loss: 0.0428742840886116\n",
      "Iteration: 1626/10000, Loss: 0.03914393484592438\n",
      "Iteration: 1627/10000, Loss: 0.02513011172413826\n",
      "Iteration: 1628/10000, Loss: 0.03368726372718811\n",
      "Iteration: 1629/10000, Loss: 0.028894763439893723\n",
      "Iteration: 1630/10000, Loss: 0.03499117121100426\n",
      "Iteration: 1631/10000, Loss: 0.038042839616537094\n",
      "Iteration: 1632/10000, Loss: 0.041828494518995285\n",
      "Iteration: 1633/10000, Loss: 0.042127545922994614\n",
      "Iteration: 1634/10000, Loss: 0.03681216388940811\n",
      "Iteration: 1635/10000, Loss: 0.03343767672777176\n",
      "Iteration: 1636/10000, Loss: 0.029928186908364296\n",
      "Iteration: 1637/10000, Loss: 0.03897055611014366\n",
      "Iteration: 1638/10000, Loss: 0.046990830451250076\n",
      "Iteration: 1639/10000, Loss: 0.0317743681371212\n",
      "Iteration: 1640/10000, Loss: 0.03893524408340454\n",
      "Iteration: 1641/10000, Loss: 0.03494270518422127\n",
      "Iteration: 1642/10000, Loss: 0.030334103852510452\n",
      "Iteration: 1643/10000, Loss: 0.05472155287861824\n",
      "Iteration: 1644/10000, Loss: 0.03102828562259674\n",
      "Iteration: 1645/10000, Loss: 0.048362817615270615\n",
      "Iteration: 1646/10000, Loss: 0.037783775478601456\n",
      "Iteration: 1647/10000, Loss: 0.035136204212903976\n",
      "Iteration: 1648/10000, Loss: 0.04570811241865158\n",
      "Iteration: 1649/10000, Loss: 0.03476811200380325\n",
      "Iteration: 1650/10000, Loss: 0.032284338027238846\n",
      "Iteration: 1651/10000, Loss: 0.039003677666187286\n",
      "Iteration: 1652/10000, Loss: 0.04251224920153618\n",
      "Iteration: 1653/10000, Loss: 0.036543458700180054\n",
      "Iteration: 1654/10000, Loss: 0.031367406249046326\n",
      "Iteration: 1655/10000, Loss: 0.043256811797618866\n",
      "Iteration: 1656/10000, Loss: 0.030032804235816002\n",
      "Iteration: 1657/10000, Loss: 0.030645063146948814\n",
      "Iteration: 1658/10000, Loss: 0.032455362379550934\n",
      "Iteration: 1659/10000, Loss: 0.04000844433903694\n",
      "Iteration: 1660/10000, Loss: 0.03285885229706764\n",
      "Iteration: 1661/10000, Loss: 0.03801509365439415\n",
      "Iteration: 1662/10000, Loss: 0.024825509637594223\n",
      "Iteration: 1663/10000, Loss: 0.028089655563235283\n",
      "Iteration: 1664/10000, Loss: 0.027310950681567192\n",
      "Iteration: 1665/10000, Loss: 0.053335923701524734\n",
      "Iteration: 1666/10000, Loss: 0.03914375975728035\n",
      "Iteration: 1667/10000, Loss: 0.03221873193979263\n",
      "Iteration: 1668/10000, Loss: 0.04284274950623512\n",
      "Iteration: 1669/10000, Loss: 0.024709008634090424\n",
      "Iteration: 1670/10000, Loss: 0.029288703575730324\n",
      "Iteration: 1671/10000, Loss: 0.03172953799366951\n",
      "Iteration: 1672/10000, Loss: 0.042335204780101776\n",
      "Iteration: 1673/10000, Loss: 0.026538042351603508\n",
      "Iteration: 1674/10000, Loss: 0.03364163264632225\n",
      "Iteration: 1675/10000, Loss: 0.03039097599685192\n",
      "Iteration: 1676/10000, Loss: 0.03343215957283974\n",
      "Iteration: 1677/10000, Loss: 0.04782302677631378\n",
      "Iteration: 1678/10000, Loss: 0.030533449724316597\n",
      "Iteration: 1679/10000, Loss: 0.026659905910491943\n",
      "Iteration: 1680/10000, Loss: 0.042852114886045456\n",
      "Iteration: 1681/10000, Loss: 0.03950207307934761\n",
      "Iteration: 1682/10000, Loss: 0.03197025507688522\n",
      "Iteration: 1683/10000, Loss: 0.035892147570848465\n",
      "Iteration: 1684/10000, Loss: 0.03082270920276642\n",
      "Iteration: 1685/10000, Loss: 0.032280564308166504\n",
      "Iteration: 1686/10000, Loss: 0.030461356043815613\n",
      "Iteration: 1687/10000, Loss: 0.026498205959796906\n",
      "Iteration: 1688/10000, Loss: 0.034824345260858536\n",
      "Iteration: 1689/10000, Loss: 0.0627637580037117\n",
      "Iteration: 1690/10000, Loss: 0.03293659910559654\n",
      "Iteration: 1691/10000, Loss: 0.039144329726696014\n",
      "Iteration: 1692/10000, Loss: 0.024522485211491585\n",
      "Iteration: 1693/10000, Loss: 0.030805600807070732\n",
      "Iteration: 1694/10000, Loss: 0.03914811089634895\n",
      "Iteration: 1695/10000, Loss: 0.0499952957034111\n",
      "Iteration: 1696/10000, Loss: 0.03692193329334259\n",
      "Iteration: 1697/10000, Loss: 0.039019256830215454\n",
      "Iteration: 1698/10000, Loss: 0.040078066289424896\n",
      "Iteration: 1699/10000, Loss: 0.033572275191545486\n",
      "Iteration: 1700/10000, Loss: 0.036605823785066605\n",
      "Average test loss:  0.0021\n",
      "Iteration: 1701/10000, Loss: 0.05038256570696831\n",
      "Iteration: 1702/10000, Loss: 0.029306799173355103\n",
      "Iteration: 1703/10000, Loss: 0.039264801889657974\n",
      "Iteration: 1704/10000, Loss: 0.034142959862947464\n",
      "Iteration: 1705/10000, Loss: 0.03138970956206322\n",
      "Iteration: 1706/10000, Loss: 0.044466882944107056\n",
      "Iteration: 1707/10000, Loss: 0.0313502661883831\n",
      "Iteration: 1708/10000, Loss: 0.028969595208764076\n",
      "Iteration: 1709/10000, Loss: 0.028969744220376015\n",
      "Iteration: 1710/10000, Loss: 0.046555884182453156\n",
      "Iteration: 1711/10000, Loss: 0.03324113041162491\n",
      "Iteration: 1712/10000, Loss: 0.02925942651927471\n",
      "Iteration: 1713/10000, Loss: 0.029083166271448135\n",
      "Iteration: 1714/10000, Loss: 0.04523693397641182\n",
      "Iteration: 1715/10000, Loss: 0.03402271121740341\n",
      "Iteration: 1716/10000, Loss: 0.0346476286649704\n",
      "Iteration: 1717/10000, Loss: 0.048420049250125885\n",
      "Iteration: 1718/10000, Loss: 0.029984131455421448\n",
      "Iteration: 1719/10000, Loss: 0.03927161917090416\n",
      "Iteration: 1720/10000, Loss: 0.03948279097676277\n",
      "Iteration: 1721/10000, Loss: 0.02788596972823143\n",
      "Iteration: 1722/10000, Loss: 0.04574856907129288\n",
      "Iteration: 1723/10000, Loss: 0.03693762794137001\n",
      "Iteration: 1724/10000, Loss: 0.04120537266135216\n",
      "Iteration: 1725/10000, Loss: 0.029567653313279152\n",
      "Iteration: 1726/10000, Loss: 0.03073575720191002\n",
      "Iteration: 1727/10000, Loss: 0.04382910579442978\n",
      "Iteration: 1728/10000, Loss: 0.028434863314032555\n",
      "Iteration: 1729/10000, Loss: 0.04535279422998428\n",
      "Iteration: 1730/10000, Loss: 0.03808749467134476\n",
      "Iteration: 1731/10000, Loss: 0.029873184859752655\n",
      "Iteration: 1732/10000, Loss: 0.024794619530439377\n",
      "Iteration: 1733/10000, Loss: 0.027358297258615494\n",
      "Iteration: 1734/10000, Loss: 0.03915103152394295\n",
      "Iteration: 1735/10000, Loss: 0.016808567568659782\n",
      "Iteration: 1736/10000, Loss: 0.023938465863466263\n",
      "Iteration: 1737/10000, Loss: 0.047038089483976364\n",
      "Iteration: 1738/10000, Loss: 0.03853829577565193\n",
      "Iteration: 1739/10000, Loss: 0.05308070778846741\n",
      "Iteration: 1740/10000, Loss: 0.023406846448779106\n",
      "Iteration: 1741/10000, Loss: 0.037541043013334274\n",
      "Iteration: 1742/10000, Loss: 0.03264760598540306\n",
      "Iteration: 1743/10000, Loss: 0.04395719990134239\n",
      "Iteration: 1744/10000, Loss: 0.04549349844455719\n",
      "Iteration: 1745/10000, Loss: 0.0416208952665329\n",
      "Iteration: 1746/10000, Loss: 0.026405181735754013\n",
      "Iteration: 1747/10000, Loss: 0.04109876602888107\n",
      "Iteration: 1748/10000, Loss: 0.03753563389182091\n",
      "Iteration: 1749/10000, Loss: 0.029291588813066483\n",
      "Iteration: 1750/10000, Loss: 0.02468351274728775\n",
      "Iteration: 1751/10000, Loss: 0.03336145728826523\n",
      "Iteration: 1752/10000, Loss: 0.027086487039923668\n",
      "Iteration: 1753/10000, Loss: 0.04259370267391205\n",
      "Iteration: 1754/10000, Loss: 0.03209243714809418\n",
      "Iteration: 1755/10000, Loss: 0.029813505709171295\n",
      "Iteration: 1756/10000, Loss: 0.03898824006319046\n",
      "Iteration: 1757/10000, Loss: 0.042871855199337006\n",
      "Iteration: 1758/10000, Loss: 0.02712227590382099\n",
      "Iteration: 1759/10000, Loss: 0.02910260297358036\n",
      "Iteration: 1760/10000, Loss: 0.017233029007911682\n",
      "Iteration: 1761/10000, Loss: 0.019980166107416153\n",
      "Iteration: 1762/10000, Loss: 0.032977670431137085\n",
      "Iteration: 1763/10000, Loss: 0.03600164130330086\n",
      "Iteration: 1764/10000, Loss: 0.027776867151260376\n",
      "Iteration: 1765/10000, Loss: 0.04796672239899635\n",
      "Iteration: 1766/10000, Loss: 0.040576353669166565\n",
      "Iteration: 1767/10000, Loss: 0.0242699533700943\n",
      "Iteration: 1768/10000, Loss: 0.03621821850538254\n",
      "Iteration: 1769/10000, Loss: 0.035216741263866425\n",
      "Iteration: 1770/10000, Loss: 0.030085593461990356\n",
      "Iteration: 1771/10000, Loss: 0.03182622045278549\n",
      "Iteration: 1772/10000, Loss: 0.021277301013469696\n",
      "Iteration: 1773/10000, Loss: 0.03356577455997467\n",
      "Iteration: 1774/10000, Loss: 0.042624786496162415\n",
      "Iteration: 1775/10000, Loss: 0.041180457919836044\n",
      "Iteration: 1776/10000, Loss: 0.03133440390229225\n",
      "Iteration: 1777/10000, Loss: 0.03717004135251045\n",
      "Iteration: 1778/10000, Loss: 0.03000691346824169\n",
      "Iteration: 1779/10000, Loss: 0.02790304832160473\n",
      "Iteration: 1780/10000, Loss: 0.0513717345893383\n",
      "Iteration: 1781/10000, Loss: 0.027142977342009544\n",
      "Iteration: 1782/10000, Loss: 0.0533110648393631\n",
      "Iteration: 1783/10000, Loss: 0.03791090101003647\n",
      "Iteration: 1784/10000, Loss: 0.03561869636178017\n",
      "Iteration: 1785/10000, Loss: 0.031869880855083466\n",
      "Iteration: 1786/10000, Loss: 0.02283756621181965\n",
      "Iteration: 1787/10000, Loss: 0.03436161205172539\n",
      "Iteration: 1788/10000, Loss: 0.02767459861934185\n",
      "Iteration: 1789/10000, Loss: 0.03638355806469917\n",
      "Iteration: 1790/10000, Loss: 0.039616622030735016\n",
      "Iteration: 1791/10000, Loss: 0.026625923812389374\n",
      "Iteration: 1792/10000, Loss: 0.04659588634967804\n",
      "Iteration: 1793/10000, Loss: 0.05466842278838158\n",
      "Iteration: 1794/10000, Loss: 0.033635593950748444\n",
      "Iteration: 1795/10000, Loss: 0.031104588881134987\n",
      "Iteration: 1796/10000, Loss: 0.03532851114869118\n",
      "Iteration: 1797/10000, Loss: 0.036689963191747665\n",
      "Iteration: 1798/10000, Loss: 0.03594166040420532\n",
      "Iteration: 1799/10000, Loss: 0.044964153319597244\n",
      "Iteration: 1800/10000, Loss: 0.06285197287797928\n",
      "Average test loss:  0.0028\n",
      "Iteration: 1801/10000, Loss: 0.047749169170856476\n",
      "Iteration: 1802/10000, Loss: 0.029545802623033524\n",
      "Iteration: 1803/10000, Loss: 0.0383484847843647\n",
      "Iteration: 1804/10000, Loss: 0.03558425232768059\n",
      "Iteration: 1805/10000, Loss: 0.04037525877356529\n",
      "Iteration: 1806/10000, Loss: 0.031155554577708244\n",
      "Iteration: 1807/10000, Loss: 0.037582091987133026\n",
      "Iteration: 1808/10000, Loss: 0.029266225174069405\n",
      "Iteration: 1809/10000, Loss: 0.037519969046115875\n",
      "Iteration: 1810/10000, Loss: 0.033925265073776245\n",
      "Iteration: 1811/10000, Loss: 0.027432989329099655\n",
      "Iteration: 1812/10000, Loss: 0.049405381083488464\n",
      "Iteration: 1813/10000, Loss: 0.033195070922374725\n",
      "Iteration: 1814/10000, Loss: 0.0314210020005703\n",
      "Iteration: 1815/10000, Loss: 0.03954106569290161\n",
      "Iteration: 1816/10000, Loss: 0.026182064786553383\n",
      "Iteration: 1817/10000, Loss: 0.04400670900940895\n",
      "Iteration: 1818/10000, Loss: 0.035885561257600784\n",
      "Iteration: 1819/10000, Loss: 0.027325628325343132\n",
      "Iteration: 1820/10000, Loss: 0.03259885311126709\n",
      "Iteration: 1821/10000, Loss: 0.03306687995791435\n",
      "Iteration: 1822/10000, Loss: 0.031248129904270172\n",
      "Iteration: 1823/10000, Loss: 0.03395203873515129\n",
      "Iteration: 1824/10000, Loss: 0.02535463124513626\n",
      "Iteration: 1825/10000, Loss: 0.022827282547950745\n",
      "Iteration: 1826/10000, Loss: 0.029368629679083824\n",
      "Iteration: 1827/10000, Loss: 0.038422346115112305\n",
      "Iteration: 1828/10000, Loss: 0.027053112164139748\n",
      "Iteration: 1829/10000, Loss: 0.04671476408839226\n",
      "Iteration: 1830/10000, Loss: 0.04237538203597069\n",
      "Iteration: 1831/10000, Loss: 0.04424464330077171\n",
      "Iteration: 1832/10000, Loss: 0.021493352949619293\n",
      "Iteration: 1833/10000, Loss: 0.03003785014152527\n",
      "Iteration: 1834/10000, Loss: 0.03043069690465927\n",
      "Iteration: 1835/10000, Loss: 0.03237348049879074\n",
      "Iteration: 1836/10000, Loss: 0.03983069583773613\n",
      "Iteration: 1837/10000, Loss: 0.03869130089879036\n",
      "Iteration: 1838/10000, Loss: 0.023613912984728813\n",
      "Iteration: 1839/10000, Loss: 0.033007849007844925\n",
      "Iteration: 1840/10000, Loss: 0.03933410719037056\n",
      "Iteration: 1841/10000, Loss: 0.04369773715734482\n",
      "Iteration: 1842/10000, Loss: 0.021761422976851463\n",
      "Iteration: 1843/10000, Loss: 0.032956305891275406\n",
      "Iteration: 1844/10000, Loss: 0.04344775900244713\n",
      "Iteration: 1845/10000, Loss: 0.02967027574777603\n",
      "Iteration: 1846/10000, Loss: 0.04405152052640915\n",
      "Iteration: 1847/10000, Loss: 0.026074904948472977\n",
      "Iteration: 1848/10000, Loss: 0.037281207740306854\n",
      "Iteration: 1849/10000, Loss: 0.020846223458647728\n",
      "Iteration: 1850/10000, Loss: 0.040225449949502945\n",
      "Iteration: 1851/10000, Loss: 0.03017253242433071\n",
      "Iteration: 1852/10000, Loss: 0.03489622101187706\n",
      "Iteration: 1853/10000, Loss: 0.01786937564611435\n",
      "Iteration: 1854/10000, Loss: 0.04865265637636185\n",
      "Iteration: 1855/10000, Loss: 0.03887663409113884\n",
      "Iteration: 1856/10000, Loss: 0.03995223715901375\n",
      "Iteration: 1857/10000, Loss: 0.03145357593894005\n",
      "Iteration: 1858/10000, Loss: 0.02675657719373703\n",
      "Iteration: 1859/10000, Loss: 0.035428110510110855\n",
      "Iteration: 1860/10000, Loss: 0.03358366712927818\n",
      "Iteration: 1861/10000, Loss: 0.03509196639060974\n",
      "Iteration: 1862/10000, Loss: 0.04744453728199005\n",
      "Iteration: 1863/10000, Loss: 0.03182853013277054\n",
      "Iteration: 1864/10000, Loss: 0.027282606810331345\n",
      "Iteration: 1865/10000, Loss: 0.0269877128303051\n",
      "Iteration: 1866/10000, Loss: 0.03759278729557991\n",
      "Iteration: 1867/10000, Loss: 0.04157551750540733\n",
      "Iteration: 1868/10000, Loss: 0.02783339098095894\n",
      "Iteration: 1869/10000, Loss: 0.025044623762369156\n",
      "Iteration: 1870/10000, Loss: 0.03742257505655289\n",
      "Iteration: 1871/10000, Loss: 0.027898728847503662\n",
      "Iteration: 1872/10000, Loss: 0.043001025915145874\n",
      "Iteration: 1873/10000, Loss: 0.03832773491740227\n",
      "Iteration: 1874/10000, Loss: 0.02680906467139721\n",
      "Iteration: 1875/10000, Loss: 0.03810606896877289\n",
      "Iteration: 1876/10000, Loss: 0.03634229302406311\n",
      "Iteration: 1877/10000, Loss: 0.028627291321754456\n",
      "Iteration: 1878/10000, Loss: 0.04006657376885414\n",
      "Iteration: 1879/10000, Loss: 0.03428332135081291\n",
      "Iteration: 1880/10000, Loss: 0.029195014387369156\n",
      "Iteration: 1881/10000, Loss: 0.03228488191962242\n",
      "Iteration: 1882/10000, Loss: 0.03887972980737686\n",
      "Iteration: 1883/10000, Loss: 0.029612967744469643\n",
      "Iteration: 1884/10000, Loss: 0.03230711817741394\n",
      "Iteration: 1885/10000, Loss: 0.028672924265265465\n",
      "Iteration: 1886/10000, Loss: 0.03320475295186043\n",
      "Iteration: 1887/10000, Loss: 0.038735318928956985\n",
      "Iteration: 1888/10000, Loss: 0.024993712082505226\n",
      "Iteration: 1889/10000, Loss: 0.021895837038755417\n",
      "Iteration: 1890/10000, Loss: 0.03847137838602066\n",
      "Iteration: 1891/10000, Loss: 0.03782742843031883\n",
      "Iteration: 1892/10000, Loss: 0.030960189178586006\n",
      "Iteration: 1893/10000, Loss: 0.03249769285321236\n",
      "Iteration: 1894/10000, Loss: 0.025403939187526703\n",
      "Iteration: 1895/10000, Loss: 0.029521439224481583\n",
      "Iteration: 1896/10000, Loss: 0.023900646716356277\n",
      "Iteration: 1897/10000, Loss: 0.029519714415073395\n",
      "Iteration: 1898/10000, Loss: 0.03318054974079132\n",
      "Iteration: 1899/10000, Loss: 0.029190706089138985\n",
      "Iteration: 1900/10000, Loss: 0.041803307831287384\n",
      "Average test loss:  0.0041\n",
      "Iteration: 1901/10000, Loss: 0.04778922721743584\n",
      "Iteration: 1902/10000, Loss: 0.030848704278469086\n",
      "Iteration: 1903/10000, Loss: 0.02675795741379261\n",
      "Iteration: 1904/10000, Loss: 0.03596936911344528\n",
      "Iteration: 1905/10000, Loss: 0.023503106087446213\n",
      "Iteration: 1906/10000, Loss: 0.027581317350268364\n",
      "Iteration: 1907/10000, Loss: 0.03637174889445305\n",
      "Iteration: 1908/10000, Loss: 0.024617668241262436\n",
      "Iteration: 1909/10000, Loss: 0.03975486755371094\n",
      "Iteration: 1910/10000, Loss: 0.03377198427915573\n",
      "Iteration: 1911/10000, Loss: 0.03460429608821869\n",
      "Iteration: 1912/10000, Loss: 0.041929811239242554\n",
      "Iteration: 1913/10000, Loss: 0.02757139503955841\n",
      "Iteration: 1914/10000, Loss: 0.034491464495658875\n",
      "Iteration: 1915/10000, Loss: 0.03583890572190285\n",
      "Iteration: 1916/10000, Loss: 0.026945462450385094\n",
      "Iteration: 1917/10000, Loss: 0.026543227955698967\n",
      "Iteration: 1918/10000, Loss: 0.014822961762547493\n",
      "Iteration: 1919/10000, Loss: 0.030985603109002113\n",
      "Iteration: 1920/10000, Loss: 0.025398632511496544\n",
      "Iteration: 1921/10000, Loss: 0.03013448230922222\n",
      "Iteration: 1922/10000, Loss: 0.04925931245088577\n",
      "Iteration: 1923/10000, Loss: 0.03357279300689697\n",
      "Iteration: 1924/10000, Loss: 0.037942443042993546\n",
      "Iteration: 1925/10000, Loss: 0.027851903811097145\n",
      "Iteration: 1926/10000, Loss: 0.03816227987408638\n",
      "Iteration: 1927/10000, Loss: 0.029337678104639053\n",
      "Iteration: 1928/10000, Loss: 0.02925952896475792\n",
      "Iteration: 1929/10000, Loss: 0.03761029615998268\n",
      "Iteration: 1930/10000, Loss: 0.01973232813179493\n",
      "Iteration: 1931/10000, Loss: 0.03109973855316639\n",
      "Iteration: 1932/10000, Loss: 0.027150563895702362\n",
      "Iteration: 1933/10000, Loss: 0.027340088039636612\n",
      "Iteration: 1934/10000, Loss: 0.01924676075577736\n",
      "Iteration: 1935/10000, Loss: 0.025802578777074814\n",
      "Iteration: 1936/10000, Loss: 0.02999308705329895\n",
      "Iteration: 1937/10000, Loss: 0.022055238485336304\n",
      "Iteration: 1938/10000, Loss: 0.044730398803949356\n",
      "Iteration: 1939/10000, Loss: 0.03633936867117882\n",
      "Iteration: 1940/10000, Loss: 0.03171352669596672\n",
      "Iteration: 1941/10000, Loss: 0.027643166482448578\n",
      "Iteration: 1942/10000, Loss: 0.041238732635974884\n",
      "Iteration: 1943/10000, Loss: 0.03560728579759598\n",
      "Iteration: 1944/10000, Loss: 0.03010524995625019\n",
      "Iteration: 1945/10000, Loss: 0.026943573728203773\n",
      "Iteration: 1946/10000, Loss: 0.03323785215616226\n",
      "Iteration: 1947/10000, Loss: 0.027418076992034912\n",
      "Iteration: 1948/10000, Loss: 0.03199605271220207\n",
      "Iteration: 1949/10000, Loss: 0.03885878622531891\n",
      "Iteration: 1950/10000, Loss: 0.04474495351314545\n",
      "Iteration: 1951/10000, Loss: 0.030974162742495537\n",
      "Iteration: 1952/10000, Loss: 0.02240622788667679\n",
      "Iteration: 1953/10000, Loss: 0.028172845020890236\n",
      "Iteration: 1954/10000, Loss: 0.027604732662439346\n",
      "Iteration: 1955/10000, Loss: 0.0306714978069067\n",
      "Iteration: 1956/10000, Loss: 0.04050540179014206\n",
      "Iteration: 1957/10000, Loss: 0.04281686618924141\n",
      "Iteration: 1958/10000, Loss: 0.03776019811630249\n",
      "Iteration: 1959/10000, Loss: 0.022598855197429657\n",
      "Iteration: 1960/10000, Loss: 0.025793001055717468\n",
      "Iteration: 1961/10000, Loss: 0.030674584209918976\n",
      "Iteration: 1962/10000, Loss: 0.03323924541473389\n",
      "Iteration: 1963/10000, Loss: 0.03519380837678909\n",
      "Iteration: 1964/10000, Loss: 0.026131030172109604\n",
      "Iteration: 1965/10000, Loss: 0.04701744765043259\n",
      "Iteration: 1966/10000, Loss: 0.031632039695978165\n",
      "Iteration: 1967/10000, Loss: 0.020516201853752136\n",
      "Iteration: 1968/10000, Loss: 0.04058811441063881\n",
      "Iteration: 1969/10000, Loss: 0.036072105169296265\n",
      "Iteration: 1970/10000, Loss: 0.03002951107919216\n",
      "Iteration: 1971/10000, Loss: 0.025731096044182777\n",
      "Iteration: 1972/10000, Loss: 0.03841294348239899\n",
      "Iteration: 1973/10000, Loss: 0.020340891554951668\n",
      "Iteration: 1974/10000, Loss: 0.03998688608407974\n",
      "Iteration: 1975/10000, Loss: 0.03019714541733265\n",
      "Iteration: 1976/10000, Loss: 0.03182436525821686\n",
      "Iteration: 1977/10000, Loss: 0.041701540350914\n",
      "Iteration: 1978/10000, Loss: 0.03249688446521759\n",
      "Iteration: 1979/10000, Loss: 0.03208315744996071\n",
      "Iteration: 1980/10000, Loss: 0.03192674368619919\n",
      "Iteration: 1981/10000, Loss: 0.03599841892719269\n",
      "Iteration: 1982/10000, Loss: 0.023078305646777153\n",
      "Iteration: 1983/10000, Loss: 0.03841928392648697\n",
      "Iteration: 1984/10000, Loss: 0.03158588707447052\n",
      "Iteration: 1985/10000, Loss: 0.0383945107460022\n",
      "Iteration: 1986/10000, Loss: 0.032816894352436066\n",
      "Iteration: 1987/10000, Loss: 0.03141165152192116\n",
      "Iteration: 1988/10000, Loss: 0.03002220205962658\n",
      "Iteration: 1989/10000, Loss: 0.03582976385951042\n",
      "Iteration: 1990/10000, Loss: 0.03857888653874397\n",
      "Iteration: 1991/10000, Loss: 0.03031367063522339\n",
      "Iteration: 1992/10000, Loss: 0.031481657177209854\n",
      "Iteration: 1993/10000, Loss: 0.025022298097610474\n",
      "Iteration: 1994/10000, Loss: 0.03510277345776558\n",
      "Iteration: 1995/10000, Loss: 0.028610065579414368\n",
      "Iteration: 1996/10000, Loss: 0.025489376857876778\n",
      "Iteration: 1997/10000, Loss: 0.024542251601815224\n",
      "Iteration: 1998/10000, Loss: 0.031950097531080246\n",
      "Iteration: 1999/10000, Loss: 0.05594140291213989\n",
      "Iteration: 2000/10000, Loss: 0.037917107343673706\n",
      "Average test loss:  0.0026\n",
      "Iteration: 2001/10000, Loss: 0.030887113884091377\n",
      "Iteration: 2002/10000, Loss: 0.05403949320316315\n",
      "Iteration: 2003/10000, Loss: 0.029063565656542778\n",
      "Iteration: 2004/10000, Loss: 0.032609496265649796\n",
      "Iteration: 2005/10000, Loss: 0.033839527517557144\n",
      "Iteration: 2006/10000, Loss: 0.03431418910622597\n",
      "Iteration: 2007/10000, Loss: 0.02533154934644699\n",
      "Iteration: 2008/10000, Loss: 0.022124212235212326\n",
      "Iteration: 2009/10000, Loss: 0.025938648730516434\n",
      "Iteration: 2010/10000, Loss: 0.03428172320127487\n",
      "Iteration: 2011/10000, Loss: 0.04283280298113823\n",
      "Iteration: 2012/10000, Loss: 0.03733630105853081\n",
      "Iteration: 2013/10000, Loss: 0.03803747519850731\n",
      "Iteration: 2014/10000, Loss: 0.025609692558646202\n",
      "Iteration: 2015/10000, Loss: 0.020069774240255356\n",
      "Iteration: 2016/10000, Loss: 0.027578692883253098\n",
      "Iteration: 2017/10000, Loss: 0.02912248484790325\n",
      "Iteration: 2018/10000, Loss: 0.03726321831345558\n",
      "Iteration: 2019/10000, Loss: 0.029601749032735825\n",
      "Iteration: 2020/10000, Loss: 0.027487915009260178\n",
      "Iteration: 2021/10000, Loss: 0.027027057483792305\n",
      "Iteration: 2022/10000, Loss: 0.031128928065299988\n",
      "Iteration: 2023/10000, Loss: 0.04414253681898117\n",
      "Iteration: 2024/10000, Loss: 0.03255363926291466\n",
      "Iteration: 2025/10000, Loss: 0.04369392246007919\n",
      "Iteration: 2026/10000, Loss: 0.02424701116979122\n",
      "Iteration: 2027/10000, Loss: 0.036193687468767166\n",
      "Iteration: 2028/10000, Loss: 0.023607555776834488\n",
      "Iteration: 2029/10000, Loss: 0.026382921263575554\n",
      "Iteration: 2030/10000, Loss: 0.04238821566104889\n",
      "Iteration: 2031/10000, Loss: 0.029454082250595093\n",
      "Iteration: 2032/10000, Loss: 0.026690762490034103\n",
      "Iteration: 2033/10000, Loss: 0.032707035541534424\n",
      "Iteration: 2034/10000, Loss: 0.028469085693359375\n",
      "Iteration: 2035/10000, Loss: 0.028908682987093925\n",
      "Iteration: 2036/10000, Loss: 0.027034172788262367\n",
      "Iteration: 2037/10000, Loss: 0.025421082973480225\n",
      "Iteration: 2038/10000, Loss: 0.02153692953288555\n",
      "Iteration: 2039/10000, Loss: 0.02720957249403\n",
      "Iteration: 2040/10000, Loss: 0.02939237467944622\n",
      "Iteration: 2041/10000, Loss: 0.01821153238415718\n",
      "Iteration: 2042/10000, Loss: 0.020033976063132286\n",
      "Iteration: 2043/10000, Loss: 0.029596375301480293\n",
      "Iteration: 2044/10000, Loss: 0.027191204950213432\n",
      "Iteration: 2045/10000, Loss: 0.022578295320272446\n",
      "Iteration: 2046/10000, Loss: 0.03794101998209953\n",
      "Iteration: 2047/10000, Loss: 0.025420932099223137\n",
      "Iteration: 2048/10000, Loss: 0.030305733904242516\n",
      "Iteration: 2049/10000, Loss: 0.02449927292764187\n",
      "Iteration: 2050/10000, Loss: 0.04140102118253708\n",
      "Iteration: 2051/10000, Loss: 0.034985776990652084\n",
      "Iteration: 2052/10000, Loss: 0.04052145034074783\n",
      "Iteration: 2053/10000, Loss: 0.05118703097105026\n",
      "Iteration: 2054/10000, Loss: 0.022696413099765778\n",
      "Iteration: 2055/10000, Loss: 0.03152851387858391\n",
      "Iteration: 2056/10000, Loss: 0.03346436470746994\n",
      "Iteration: 2057/10000, Loss: 0.048444561660289764\n",
      "Iteration: 2058/10000, Loss: 0.051842719316482544\n",
      "Iteration: 2059/10000, Loss: 0.0260233785957098\n",
      "Iteration: 2060/10000, Loss: 0.03666835278272629\n",
      "Iteration: 2061/10000, Loss: 0.029111022129654884\n",
      "Iteration: 2062/10000, Loss: 0.03177152946591377\n",
      "Iteration: 2063/10000, Loss: 0.03380030393600464\n",
      "Iteration: 2064/10000, Loss: 0.025210343301296234\n",
      "Iteration: 2065/10000, Loss: 0.04199228808283806\n",
      "Iteration: 2066/10000, Loss: 0.023783639073371887\n",
      "Iteration: 2067/10000, Loss: 0.03865199163556099\n",
      "Iteration: 2068/10000, Loss: 0.034141767770051956\n",
      "Iteration: 2069/10000, Loss: 0.03287322074174881\n",
      "Iteration: 2070/10000, Loss: 0.022900447249412537\n",
      "Iteration: 2071/10000, Loss: 0.0384339801967144\n",
      "Iteration: 2072/10000, Loss: 0.023706573992967606\n",
      "Iteration: 2073/10000, Loss: 0.03286214917898178\n",
      "Iteration: 2074/10000, Loss: 0.019938789308071136\n",
      "Iteration: 2075/10000, Loss: 0.0351228229701519\n",
      "Iteration: 2076/10000, Loss: 0.036439135670661926\n",
      "Iteration: 2077/10000, Loss: 0.02960415743291378\n",
      "Iteration: 2078/10000, Loss: 0.02483907900750637\n",
      "Iteration: 2079/10000, Loss: 0.03302627429366112\n",
      "Iteration: 2080/10000, Loss: 0.023680010810494423\n",
      "Iteration: 2081/10000, Loss: 0.026238903403282166\n",
      "Iteration: 2082/10000, Loss: 0.04190366715192795\n",
      "Iteration: 2083/10000, Loss: 0.037526436150074005\n",
      "Iteration: 2084/10000, Loss: 0.02291894145309925\n",
      "Iteration: 2085/10000, Loss: 0.023960070684552193\n",
      "Iteration: 2086/10000, Loss: 0.01565983146429062\n",
      "Iteration: 2087/10000, Loss: 0.022143328562378883\n",
      "Iteration: 2088/10000, Loss: 0.02971680462360382\n",
      "Iteration: 2089/10000, Loss: 0.029824046418070793\n",
      "Iteration: 2090/10000, Loss: 0.028233421966433525\n",
      "Iteration: 2091/10000, Loss: 0.023922454565763474\n",
      "Iteration: 2092/10000, Loss: 0.027568483725190163\n",
      "Iteration: 2093/10000, Loss: 0.03306417167186737\n",
      "Iteration: 2094/10000, Loss: 0.019302168861031532\n",
      "Iteration: 2095/10000, Loss: 0.0317288339138031\n",
      "Iteration: 2096/10000, Loss: 0.02936575375497341\n",
      "Iteration: 2097/10000, Loss: 0.029039856046438217\n",
      "Iteration: 2098/10000, Loss: 0.036325834691524506\n",
      "Iteration: 2099/10000, Loss: 0.03698737546801567\n",
      "Iteration: 2100/10000, Loss: 0.0231632087379694\n",
      "Average test loss:  0.0023\n",
      "Iteration: 2101/10000, Loss: 0.037647612392902374\n",
      "Iteration: 2102/10000, Loss: 0.02912166528403759\n",
      "Iteration: 2103/10000, Loss: 0.021224236115813255\n",
      "Iteration: 2104/10000, Loss: 0.03628974407911301\n",
      "Iteration: 2105/10000, Loss: 0.026310564950108528\n",
      "Iteration: 2106/10000, Loss: 0.02307443879544735\n",
      "Iteration: 2107/10000, Loss: 0.02361341007053852\n",
      "Iteration: 2108/10000, Loss: 0.029411952942609787\n",
      "Iteration: 2109/10000, Loss: 0.04417245835065842\n",
      "Iteration: 2110/10000, Loss: 0.024365780875086784\n",
      "Iteration: 2111/10000, Loss: 0.026545463129878044\n",
      "Iteration: 2112/10000, Loss: 0.036810971796512604\n",
      "Iteration: 2113/10000, Loss: 0.025858890265226364\n",
      "Iteration: 2114/10000, Loss: 0.032568495720624924\n",
      "Iteration: 2115/10000, Loss: 0.027377989143133163\n",
      "Iteration: 2116/10000, Loss: 0.030130421742796898\n",
      "Iteration: 2117/10000, Loss: 0.02600480429828167\n",
      "Iteration: 2118/10000, Loss: 0.02177639864385128\n",
      "Iteration: 2119/10000, Loss: 0.027294199913740158\n",
      "Iteration: 2120/10000, Loss: 0.022804372012615204\n",
      "Iteration: 2121/10000, Loss: 0.030727766454219818\n",
      "Iteration: 2122/10000, Loss: 0.03471186384558678\n",
      "Iteration: 2123/10000, Loss: 0.01732349768280983\n",
      "Iteration: 2124/10000, Loss: 0.044294506311416626\n",
      "Iteration: 2125/10000, Loss: 0.02532510831952095\n",
      "Iteration: 2126/10000, Loss: 0.030573904514312744\n",
      "Iteration: 2127/10000, Loss: 0.022760316729545593\n",
      "Iteration: 2128/10000, Loss: 0.026997314766049385\n",
      "Iteration: 2129/10000, Loss: 0.02143057994544506\n",
      "Iteration: 2130/10000, Loss: 0.03186638653278351\n",
      "Iteration: 2131/10000, Loss: 0.032563429325819016\n",
      "Iteration: 2132/10000, Loss: 0.027133701369166374\n",
      "Iteration: 2133/10000, Loss: 0.023263685405254364\n",
      "Iteration: 2134/10000, Loss: 0.02179715223610401\n",
      "Iteration: 2135/10000, Loss: 0.026135092601180077\n",
      "Iteration: 2136/10000, Loss: 0.037422917783260345\n",
      "Iteration: 2137/10000, Loss: 0.04099804908037186\n",
      "Iteration: 2138/10000, Loss: 0.030574312433600426\n",
      "Iteration: 2139/10000, Loss: 0.024735983461141586\n",
      "Iteration: 2140/10000, Loss: 0.026807455345988274\n",
      "Iteration: 2141/10000, Loss: 0.032167524099349976\n",
      "Iteration: 2142/10000, Loss: 0.030336778610944748\n",
      "Iteration: 2143/10000, Loss: 0.02578895539045334\n",
      "Iteration: 2144/10000, Loss: 0.03046407364308834\n",
      "Iteration: 2145/10000, Loss: 0.025370996445417404\n",
      "Iteration: 2146/10000, Loss: 0.018868427723646164\n",
      "Iteration: 2147/10000, Loss: 0.0259499903768301\n",
      "Iteration: 2148/10000, Loss: 0.031354956328868866\n",
      "Iteration: 2149/10000, Loss: 0.015181311406195164\n",
      "Iteration: 2150/10000, Loss: 0.03120884858071804\n",
      "Iteration: 2151/10000, Loss: 0.03231242299079895\n",
      "Iteration: 2152/10000, Loss: 0.015350354835391045\n",
      "Iteration: 2153/10000, Loss: 0.02887735143303871\n",
      "Iteration: 2154/10000, Loss: 0.03048531338572502\n",
      "Iteration: 2155/10000, Loss: 0.02640148252248764\n",
      "Iteration: 2156/10000, Loss: 0.03028200753033161\n",
      "Iteration: 2157/10000, Loss: 0.025661200284957886\n",
      "Iteration: 2158/10000, Loss: 0.0265191663056612\n",
      "Iteration: 2159/10000, Loss: 0.025527190417051315\n",
      "Iteration: 2160/10000, Loss: 0.020324110984802246\n",
      "Iteration: 2161/10000, Loss: 0.04322867840528488\n",
      "Iteration: 2162/10000, Loss: 0.03776649385690689\n",
      "Iteration: 2163/10000, Loss: 0.028022591024637222\n",
      "Iteration: 2164/10000, Loss: 0.034922026097774506\n",
      "Iteration: 2165/10000, Loss: 0.030611028894782066\n",
      "Iteration: 2166/10000, Loss: 0.029663965106010437\n",
      "Iteration: 2167/10000, Loss: 0.028310269117355347\n",
      "Iteration: 2168/10000, Loss: 0.030563291162252426\n",
      "Iteration: 2169/10000, Loss: 0.02165958844125271\n",
      "Iteration: 2170/10000, Loss: 0.036086734384298325\n",
      "Iteration: 2171/10000, Loss: 0.02719244919717312\n",
      "Iteration: 2172/10000, Loss: 0.04557293653488159\n",
      "Iteration: 2173/10000, Loss: 0.0180211178958416\n",
      "Iteration: 2174/10000, Loss: 0.02411266788840294\n",
      "Iteration: 2175/10000, Loss: 0.025971800088882446\n",
      "Iteration: 2176/10000, Loss: 0.02344643883407116\n",
      "Iteration: 2177/10000, Loss: 0.021386850625276566\n",
      "Iteration: 2178/10000, Loss: 0.03513640910387039\n",
      "Iteration: 2179/10000, Loss: 0.026550011709332466\n",
      "Iteration: 2180/10000, Loss: 0.021831056103110313\n",
      "Iteration: 2181/10000, Loss: 0.022985434159636497\n",
      "Iteration: 2182/10000, Loss: 0.03352440148591995\n",
      "Iteration: 2183/10000, Loss: 0.03057360276579857\n",
      "Iteration: 2184/10000, Loss: 0.015426574274897575\n",
      "Iteration: 2185/10000, Loss: 0.028537550941109657\n",
      "Iteration: 2186/10000, Loss: 0.02203114703297615\n",
      "Iteration: 2187/10000, Loss: 0.03206230700016022\n",
      "Iteration: 2188/10000, Loss: 0.0328068844974041\n",
      "Iteration: 2189/10000, Loss: 0.03130950778722763\n",
      "Iteration: 2190/10000, Loss: 0.0365176759660244\n",
      "Iteration: 2191/10000, Loss: 0.03275131434202194\n",
      "Iteration: 2192/10000, Loss: 0.02760593220591545\n",
      "Iteration: 2193/10000, Loss: 0.026533478870987892\n",
      "Iteration: 2194/10000, Loss: 0.03231372311711311\n",
      "Iteration: 2195/10000, Loss: 0.023417538031935692\n",
      "Iteration: 2196/10000, Loss: 0.03245137259364128\n",
      "Iteration: 2197/10000, Loss: 0.03040776401758194\n",
      "Iteration: 2198/10000, Loss: 0.04329736903309822\n",
      "Iteration: 2199/10000, Loss: 0.02518942765891552\n",
      "Iteration: 2200/10000, Loss: 0.03266313299536705\n",
      "Average test loss:  0.0015\n",
      "Iteration: 2201/10000, Loss: 0.02244032360613346\n",
      "Iteration: 2202/10000, Loss: 0.022756043821573257\n",
      "Iteration: 2203/10000, Loss: 0.03014158084988594\n",
      "Iteration: 2204/10000, Loss: 0.021300850436091423\n",
      "Iteration: 2205/10000, Loss: 0.035266317427158356\n",
      "Iteration: 2206/10000, Loss: 0.02558305487036705\n",
      "Iteration: 2207/10000, Loss: 0.026196127757430077\n",
      "Iteration: 2208/10000, Loss: 0.02904433012008667\n",
      "Iteration: 2209/10000, Loss: 0.02850615233182907\n",
      "Iteration: 2210/10000, Loss: 0.01962975226342678\n",
      "Iteration: 2211/10000, Loss: 0.031061463057994843\n",
      "Iteration: 2212/10000, Loss: 0.015896005555987358\n",
      "Iteration: 2213/10000, Loss: 0.03140889108181\n",
      "Iteration: 2214/10000, Loss: 0.027426084503531456\n",
      "Iteration: 2215/10000, Loss: 0.01855223998427391\n",
      "Iteration: 2216/10000, Loss: 0.021535001695156097\n",
      "Iteration: 2217/10000, Loss: 0.0331132672727108\n",
      "Iteration: 2218/10000, Loss: 0.026717232540249825\n",
      "Iteration: 2219/10000, Loss: 0.02454511448740959\n",
      "Iteration: 2220/10000, Loss: 0.03524656966328621\n",
      "Iteration: 2221/10000, Loss: 0.03023139387369156\n",
      "Iteration: 2222/10000, Loss: 0.03198249638080597\n",
      "Iteration: 2223/10000, Loss: 0.02383633889257908\n",
      "Iteration: 2224/10000, Loss: 0.024416353553533554\n",
      "Iteration: 2225/10000, Loss: 0.0305766724050045\n",
      "Iteration: 2226/10000, Loss: 0.036492932587862015\n",
      "Iteration: 2227/10000, Loss: 0.015771491453051567\n",
      "Iteration: 2228/10000, Loss: 0.023401038721203804\n",
      "Iteration: 2229/10000, Loss: 0.0330377034842968\n",
      "Iteration: 2230/10000, Loss: 0.022920234128832817\n",
      "Iteration: 2231/10000, Loss: 0.014042092487215996\n",
      "Iteration: 2232/10000, Loss: 0.02547105774283409\n",
      "Iteration: 2233/10000, Loss: 0.0328342467546463\n",
      "Iteration: 2234/10000, Loss: 0.023730911314487457\n",
      "Iteration: 2235/10000, Loss: 0.03232510760426521\n",
      "Iteration: 2236/10000, Loss: 0.04284732788801193\n",
      "Iteration: 2237/10000, Loss: 0.033528637140989304\n",
      "Iteration: 2238/10000, Loss: 0.03829506039619446\n",
      "Iteration: 2239/10000, Loss: 0.029958682134747505\n",
      "Iteration: 2240/10000, Loss: 0.029728440567851067\n",
      "Iteration: 2241/10000, Loss: 0.030411016196012497\n",
      "Iteration: 2242/10000, Loss: 0.0336521752178669\n",
      "Iteration: 2243/10000, Loss: 0.03158276528120041\n",
      "Iteration: 2244/10000, Loss: 0.02380817010998726\n",
      "Iteration: 2245/10000, Loss: 0.047442078590393066\n",
      "Iteration: 2246/10000, Loss: 0.03133738413453102\n",
      "Iteration: 2247/10000, Loss: 0.03272106498479843\n",
      "Iteration: 2248/10000, Loss: 0.03097066842019558\n",
      "Iteration: 2249/10000, Loss: 0.021400118246674538\n",
      "Iteration: 2250/10000, Loss: 0.029190966859459877\n",
      "Iteration: 2251/10000, Loss: 0.034894730895757675\n",
      "Iteration: 2252/10000, Loss: 0.023868098855018616\n",
      "Iteration: 2253/10000, Loss: 0.026200950145721436\n",
      "Iteration: 2254/10000, Loss: 0.022921282798051834\n",
      "Iteration: 2255/10000, Loss: 0.0259864404797554\n",
      "Iteration: 2256/10000, Loss: 0.02783886529505253\n",
      "Iteration: 2257/10000, Loss: 0.02662530355155468\n",
      "Iteration: 2258/10000, Loss: 0.03404456749558449\n",
      "Iteration: 2259/10000, Loss: 0.019556904211640358\n",
      "Iteration: 2260/10000, Loss: 0.034051693975925446\n",
      "Iteration: 2261/10000, Loss: 0.02042568475008011\n",
      "Iteration: 2262/10000, Loss: 0.02070273645222187\n",
      "Iteration: 2263/10000, Loss: 0.029369596391916275\n",
      "Iteration: 2264/10000, Loss: 0.031165366992354393\n",
      "Iteration: 2265/10000, Loss: 0.023713568225502968\n",
      "Iteration: 2266/10000, Loss: 0.022409606724977493\n",
      "Iteration: 2267/10000, Loss: 0.023667385801672935\n",
      "Iteration: 2268/10000, Loss: 0.03186660259962082\n",
      "Iteration: 2269/10000, Loss: 0.034753940999507904\n",
      "Iteration: 2270/10000, Loss: 0.01952952705323696\n",
      "Iteration: 2271/10000, Loss: 0.02320738323032856\n",
      "Iteration: 2272/10000, Loss: 0.029555929824709892\n",
      "Iteration: 2273/10000, Loss: 0.026750314980745316\n",
      "Iteration: 2274/10000, Loss: 0.0247513335198164\n",
      "Iteration: 2275/10000, Loss: 0.03544372320175171\n",
      "Iteration: 2276/10000, Loss: 0.024489818140864372\n",
      "Iteration: 2277/10000, Loss: 0.032816722989082336\n",
      "Iteration: 2278/10000, Loss: 0.026260733604431152\n",
      "Iteration: 2279/10000, Loss: 0.022602219134569168\n",
      "Iteration: 2280/10000, Loss: 0.030373604968190193\n",
      "Iteration: 2281/10000, Loss: 0.030684322118759155\n",
      "Iteration: 2282/10000, Loss: 0.026737269014120102\n",
      "Iteration: 2283/10000, Loss: 0.023014485836029053\n",
      "Iteration: 2284/10000, Loss: 0.030342381447553635\n",
      "Iteration: 2285/10000, Loss: 0.02519921213388443\n",
      "Iteration: 2286/10000, Loss: 0.018106918781995773\n",
      "Iteration: 2287/10000, Loss: 0.021837987005710602\n",
      "Iteration: 2288/10000, Loss: 0.01555913407355547\n",
      "Iteration: 2289/10000, Loss: 0.02279483526945114\n",
      "Iteration: 2290/10000, Loss: 0.026484917849302292\n",
      "Iteration: 2291/10000, Loss: 0.027741428464651108\n",
      "Iteration: 2292/10000, Loss: 0.03728066012263298\n",
      "Iteration: 2293/10000, Loss: 0.01902691088616848\n",
      "Iteration: 2294/10000, Loss: 0.026494616642594337\n",
      "Iteration: 2295/10000, Loss: 0.03528330847620964\n",
      "Iteration: 2296/10000, Loss: 0.03686058148741722\n",
      "Iteration: 2297/10000, Loss: 0.03079991787672043\n",
      "Iteration: 2298/10000, Loss: 0.02400694228708744\n",
      "Iteration: 2299/10000, Loss: 0.02527032606303692\n",
      "Iteration: 2300/10000, Loss: 0.02233233116567135\n",
      "Average test loss:  0.0024\n",
      "Iteration: 2301/10000, Loss: 0.029836947098374367\n",
      "Iteration: 2302/10000, Loss: 0.036846406757831573\n",
      "Iteration: 2303/10000, Loss: 0.018803371116518974\n",
      "Iteration: 2304/10000, Loss: 0.03218459337949753\n",
      "Iteration: 2305/10000, Loss: 0.02584044076502323\n",
      "Iteration: 2306/10000, Loss: 0.015970764681696892\n",
      "Iteration: 2307/10000, Loss: 0.02758864127099514\n",
      "Iteration: 2308/10000, Loss: 0.02905626781284809\n",
      "Iteration: 2309/10000, Loss: 0.01902426779270172\n",
      "Iteration: 2310/10000, Loss: 0.02703247405588627\n",
      "Iteration: 2311/10000, Loss: 0.039105236530303955\n",
      "Iteration: 2312/10000, Loss: 0.022494656965136528\n",
      "Iteration: 2313/10000, Loss: 0.021343166008591652\n",
      "Iteration: 2314/10000, Loss: 0.025423269718885422\n",
      "Iteration: 2315/10000, Loss: 0.022603122517466545\n",
      "Iteration: 2316/10000, Loss: 0.0272145364433527\n",
      "Iteration: 2317/10000, Loss: 0.026493247598409653\n",
      "Iteration: 2318/10000, Loss: 0.025127118453383446\n",
      "Iteration: 2319/10000, Loss: 0.028303081169724464\n",
      "Iteration: 2320/10000, Loss: 0.02286076359450817\n",
      "Iteration: 2321/10000, Loss: 0.025372032076120377\n",
      "Iteration: 2322/10000, Loss: 0.03939136862754822\n",
      "Iteration: 2323/10000, Loss: 0.02604859694838524\n",
      "Iteration: 2324/10000, Loss: 0.028405286371707916\n",
      "Iteration: 2325/10000, Loss: 0.02396846003830433\n",
      "Iteration: 2326/10000, Loss: 0.03375862166285515\n",
      "Iteration: 2327/10000, Loss: 0.020787948742508888\n",
      "Iteration: 2328/10000, Loss: 0.022589124739170074\n",
      "Iteration: 2329/10000, Loss: 0.03342851251363754\n",
      "Iteration: 2330/10000, Loss: 0.029130440205335617\n",
      "Iteration: 2331/10000, Loss: 0.0348099060356617\n",
      "Iteration: 2332/10000, Loss: 0.02796877920627594\n",
      "Iteration: 2333/10000, Loss: 0.024168455973267555\n",
      "Iteration: 2334/10000, Loss: 0.032704778015613556\n",
      "Iteration: 2335/10000, Loss: 0.0330498069524765\n",
      "Iteration: 2336/10000, Loss: 0.0255294032394886\n",
      "Iteration: 2337/10000, Loss: 0.038563795387744904\n",
      "Iteration: 2338/10000, Loss: 0.025743694975972176\n",
      "Iteration: 2339/10000, Loss: 0.019473539665341377\n",
      "Iteration: 2340/10000, Loss: 0.02570142038166523\n",
      "Iteration: 2341/10000, Loss: 0.02511659823358059\n",
      "Iteration: 2342/10000, Loss: 0.03976229950785637\n",
      "Iteration: 2343/10000, Loss: 0.03399988263845444\n",
      "Iteration: 2344/10000, Loss: 0.04710960388183594\n",
      "Iteration: 2345/10000, Loss: 0.027173463255167007\n",
      "Iteration: 2346/10000, Loss: 0.0253425445407629\n",
      "Iteration: 2347/10000, Loss: 0.021262189373373985\n",
      "Iteration: 2348/10000, Loss: 0.02246786281466484\n",
      "Iteration: 2349/10000, Loss: 0.047057852149009705\n",
      "Iteration: 2350/10000, Loss: 0.039856113493442535\n",
      "Iteration: 2351/10000, Loss: 0.01987956091761589\n",
      "Iteration: 2352/10000, Loss: 0.027738429605960846\n",
      "Iteration: 2353/10000, Loss: 0.026670126244425774\n",
      "Iteration: 2354/10000, Loss: 0.03193271532654762\n",
      "Iteration: 2355/10000, Loss: 0.02983994223177433\n",
      "Iteration: 2356/10000, Loss: 0.02976374700665474\n",
      "Iteration: 2357/10000, Loss: 0.022605154663324356\n",
      "Iteration: 2358/10000, Loss: 0.021609023213386536\n",
      "Iteration: 2359/10000, Loss: 0.02325250580906868\n",
      "Iteration: 2360/10000, Loss: 0.025900578126311302\n",
      "Iteration: 2361/10000, Loss: 0.02951764687895775\n",
      "Iteration: 2362/10000, Loss: 0.02873021736741066\n",
      "Iteration: 2363/10000, Loss: 0.02047010138630867\n",
      "Iteration: 2364/10000, Loss: 0.032974641770124435\n",
      "Iteration: 2365/10000, Loss: 0.028480730950832367\n",
      "Iteration: 2366/10000, Loss: 0.03280457481741905\n",
      "Iteration: 2367/10000, Loss: 0.034595079720020294\n",
      "Iteration: 2368/10000, Loss: 0.03589935973286629\n",
      "Iteration: 2369/10000, Loss: 0.027812115848064423\n",
      "Iteration: 2370/10000, Loss: 0.038507647812366486\n",
      "Iteration: 2371/10000, Loss: 0.029641952365636826\n",
      "Iteration: 2372/10000, Loss: 0.024660682305693626\n",
      "Iteration: 2373/10000, Loss: 0.015495962463319302\n",
      "Iteration: 2374/10000, Loss: 0.027773329988121986\n",
      "Iteration: 2375/10000, Loss: 0.04165339469909668\n",
      "Iteration: 2376/10000, Loss: 0.02446897327899933\n",
      "Iteration: 2377/10000, Loss: 0.018126117065548897\n",
      "Iteration: 2378/10000, Loss: 0.021889135241508484\n",
      "Iteration: 2379/10000, Loss: 0.019557654857635498\n",
      "Iteration: 2380/10000, Loss: 0.025304824113845825\n",
      "Iteration: 2381/10000, Loss: 0.033723216503858566\n",
      "Iteration: 2382/10000, Loss: 0.024652378633618355\n",
      "Iteration: 2383/10000, Loss: 0.02354002185165882\n",
      "Iteration: 2384/10000, Loss: 0.02557801641523838\n",
      "Iteration: 2385/10000, Loss: 0.032761797308921814\n",
      "Iteration: 2386/10000, Loss: 0.020842889323830605\n",
      "Iteration: 2387/10000, Loss: 0.0232415609061718\n",
      "Iteration: 2388/10000, Loss: 0.027007704600691795\n",
      "Iteration: 2389/10000, Loss: 0.01579952798783779\n",
      "Iteration: 2390/10000, Loss: 0.052232977002859116\n",
      "Iteration: 2391/10000, Loss: 0.03128466010093689\n",
      "Iteration: 2392/10000, Loss: 0.03300059959292412\n",
      "Iteration: 2393/10000, Loss: 0.02600441314280033\n",
      "Iteration: 2394/10000, Loss: 0.029316524043679237\n",
      "Iteration: 2395/10000, Loss: 0.03185061365365982\n",
      "Iteration: 2396/10000, Loss: 0.023701943457126617\n",
      "Iteration: 2397/10000, Loss: 0.028769444674253464\n",
      "Iteration: 2398/10000, Loss: 0.024114690721035004\n",
      "Iteration: 2399/10000, Loss: 0.022002102807164192\n",
      "Iteration: 2400/10000, Loss: 0.022444775328040123\n",
      "Average test loss:  0.0018\n",
      "Iteration: 2401/10000, Loss: 0.03286079689860344\n",
      "Iteration: 2402/10000, Loss: 0.02108057215809822\n",
      "Iteration: 2403/10000, Loss: 0.0321161188185215\n",
      "Iteration: 2404/10000, Loss: 0.04065147414803505\n",
      "Iteration: 2405/10000, Loss: 0.02516299858689308\n",
      "Iteration: 2406/10000, Loss: 0.01793554425239563\n",
      "Iteration: 2407/10000, Loss: 0.03476628288626671\n",
      "Iteration: 2408/10000, Loss: 0.027100784704089165\n",
      "Iteration: 2409/10000, Loss: 0.025456592440605164\n",
      "Iteration: 2410/10000, Loss: 0.02683982066810131\n",
      "Iteration: 2411/10000, Loss: 0.03403494134545326\n",
      "Iteration: 2412/10000, Loss: 0.02686871588230133\n",
      "Iteration: 2413/10000, Loss: 0.025416018441319466\n",
      "Iteration: 2414/10000, Loss: 0.026372481137514114\n",
      "Iteration: 2415/10000, Loss: 0.02957618422806263\n",
      "Iteration: 2416/10000, Loss: 0.025617210194468498\n",
      "Iteration: 2417/10000, Loss: 0.01512763649225235\n",
      "Iteration: 2418/10000, Loss: 0.04430723562836647\n",
      "Iteration: 2419/10000, Loss: 0.028628332540392876\n",
      "Iteration: 2420/10000, Loss: 0.024432038888335228\n",
      "Iteration: 2421/10000, Loss: 0.019897378981113434\n",
      "Iteration: 2422/10000, Loss: 0.023583291098475456\n",
      "Iteration: 2423/10000, Loss: 0.027845384553074837\n",
      "Iteration: 2424/10000, Loss: 0.03448585793375969\n",
      "Iteration: 2425/10000, Loss: 0.03491179272532463\n",
      "Iteration: 2426/10000, Loss: 0.032423313707113266\n",
      "Iteration: 2427/10000, Loss: 0.017520539462566376\n",
      "Iteration: 2428/10000, Loss: 0.03157268464565277\n",
      "Iteration: 2429/10000, Loss: 0.03030114434659481\n",
      "Iteration: 2430/10000, Loss: 0.029583873227238655\n",
      "Iteration: 2431/10000, Loss: 0.02384296804666519\n",
      "Iteration: 2432/10000, Loss: 0.027206389233469963\n",
      "Iteration: 2433/10000, Loss: 0.0347592793405056\n",
      "Iteration: 2434/10000, Loss: 0.02517401985824108\n",
      "Iteration: 2435/10000, Loss: 0.024453485384583473\n",
      "Iteration: 2436/10000, Loss: 0.020433031022548676\n",
      "Iteration: 2437/10000, Loss: 0.02668306790292263\n",
      "Iteration: 2438/10000, Loss: 0.023572472855448723\n",
      "Iteration: 2439/10000, Loss: 0.020618818700313568\n",
      "Iteration: 2440/10000, Loss: 0.03712881729006767\n",
      "Iteration: 2441/10000, Loss: 0.0234301146119833\n",
      "Iteration: 2442/10000, Loss: 0.022981474176049232\n",
      "Iteration: 2443/10000, Loss: 0.022042179480195045\n",
      "Iteration: 2444/10000, Loss: 0.026929182931780815\n",
      "Iteration: 2445/10000, Loss: 0.03105706349015236\n",
      "Iteration: 2446/10000, Loss: 0.022953461855649948\n",
      "Iteration: 2447/10000, Loss: 0.03751625865697861\n",
      "Iteration: 2448/10000, Loss: 0.024858325719833374\n",
      "Iteration: 2449/10000, Loss: 0.028386671096086502\n",
      "Iteration: 2450/10000, Loss: 0.01986098103225231\n",
      "Iteration: 2451/10000, Loss: 0.022136783227324486\n",
      "Iteration: 2452/10000, Loss: 0.02725299447774887\n",
      "Iteration: 2453/10000, Loss: 0.035976704210042953\n",
      "Iteration: 2454/10000, Loss: 0.024123182520270348\n",
      "Iteration: 2455/10000, Loss: 0.02334696613252163\n",
      "Iteration: 2456/10000, Loss: 0.02976737543940544\n",
      "Iteration: 2457/10000, Loss: 0.031913578510284424\n",
      "Iteration: 2458/10000, Loss: 0.02843504399061203\n",
      "Iteration: 2459/10000, Loss: 0.02183718793094158\n",
      "Iteration: 2460/10000, Loss: 0.03702332451939583\n",
      "Iteration: 2461/10000, Loss: 0.025048475712537766\n",
      "Iteration: 2462/10000, Loss: 0.027467168867588043\n",
      "Iteration: 2463/10000, Loss: 0.0247383713722229\n",
      "Iteration: 2464/10000, Loss: 0.02706022560596466\n",
      "Iteration: 2465/10000, Loss: 0.01745876483619213\n",
      "Iteration: 2466/10000, Loss: 0.03230543062090874\n",
      "Iteration: 2467/10000, Loss: 0.014035326428711414\n",
      "Iteration: 2468/10000, Loss: 0.02716047130525112\n",
      "Iteration: 2469/10000, Loss: 0.025425691157579422\n",
      "Iteration: 2470/10000, Loss: 0.026122016832232475\n",
      "Iteration: 2471/10000, Loss: 0.03296069800853729\n",
      "Iteration: 2472/10000, Loss: 0.025526374578475952\n",
      "Iteration: 2473/10000, Loss: 0.019456034526228905\n",
      "Iteration: 2474/10000, Loss: 0.050631083548069\n",
      "Iteration: 2475/10000, Loss: 0.026382721960544586\n",
      "Iteration: 2476/10000, Loss: 0.029636908322572708\n",
      "Iteration: 2477/10000, Loss: 0.024616993963718414\n",
      "Iteration: 2478/10000, Loss: 0.0349060520529747\n",
      "Iteration: 2479/10000, Loss: 0.029360109940171242\n",
      "Iteration: 2480/10000, Loss: 0.022886304184794426\n",
      "Iteration: 2481/10000, Loss: 0.03926083818078041\n",
      "Iteration: 2482/10000, Loss: 0.028294261544942856\n",
      "Iteration: 2483/10000, Loss: 0.02055235207080841\n",
      "Iteration: 2484/10000, Loss: 0.029632726684212685\n",
      "Iteration: 2485/10000, Loss: 0.018157610669732094\n",
      "Iteration: 2486/10000, Loss: 0.018942011520266533\n",
      "Iteration: 2487/10000, Loss: 0.01881072111427784\n",
      "Iteration: 2488/10000, Loss: 0.01744857057929039\n",
      "Iteration: 2489/10000, Loss: 0.013675405643880367\n",
      "Iteration: 2490/10000, Loss: 0.019965345039963722\n",
      "Iteration: 2491/10000, Loss: 0.03416917845606804\n",
      "Iteration: 2492/10000, Loss: 0.025660889223217964\n",
      "Iteration: 2493/10000, Loss: 0.01563732698559761\n",
      "Iteration: 2494/10000, Loss: 0.01680101454257965\n",
      "Iteration: 2495/10000, Loss: 0.02300434373319149\n",
      "Iteration: 2496/10000, Loss: 0.03136716037988663\n",
      "Iteration: 2497/10000, Loss: 0.023989273235201836\n",
      "Iteration: 2498/10000, Loss: 0.021987974643707275\n",
      "Iteration: 2499/10000, Loss: 0.030788976699113846\n",
      "Iteration: 2500/10000, Loss: 0.027243496850132942\n",
      "Average test loss:  0.0033\n",
      "Iteration: 2501/10000, Loss: 0.02886096015572548\n",
      "Iteration: 2502/10000, Loss: 0.03141779825091362\n",
      "Iteration: 2503/10000, Loss: 0.029005123302340508\n",
      "Iteration: 2504/10000, Loss: 0.023557528853416443\n",
      "Iteration: 2505/10000, Loss: 0.0249620508402586\n",
      "Iteration: 2506/10000, Loss: 0.023359181359410286\n",
      "Iteration: 2507/10000, Loss: 0.02829430066049099\n",
      "Iteration: 2508/10000, Loss: 0.01807779259979725\n",
      "Iteration: 2509/10000, Loss: 0.03136604651808739\n",
      "Iteration: 2510/10000, Loss: 0.035878077149391174\n",
      "Iteration: 2511/10000, Loss: 0.01792006567120552\n",
      "Iteration: 2512/10000, Loss: 0.029954612255096436\n",
      "Iteration: 2513/10000, Loss: 0.042278409004211426\n",
      "Iteration: 2514/10000, Loss: 0.022209426388144493\n",
      "Iteration: 2515/10000, Loss: 0.022695673629641533\n",
      "Iteration: 2516/10000, Loss: 0.03743920475244522\n",
      "Iteration: 2517/10000, Loss: 0.02598372846841812\n",
      "Iteration: 2518/10000, Loss: 0.027366552501916885\n",
      "Iteration: 2519/10000, Loss: 0.02005010098218918\n",
      "Iteration: 2520/10000, Loss: 0.029424970969557762\n",
      "Iteration: 2521/10000, Loss: 0.02571837604045868\n",
      "Iteration: 2522/10000, Loss: 0.02175077423453331\n",
      "Iteration: 2523/10000, Loss: 0.028022760525345802\n",
      "Iteration: 2524/10000, Loss: 0.025738833472132683\n",
      "Iteration: 2525/10000, Loss: 0.032933399081230164\n",
      "Iteration: 2526/10000, Loss: 0.029413960874080658\n",
      "Iteration: 2527/10000, Loss: 0.02401244267821312\n",
      "Iteration: 2528/10000, Loss: 0.025638854131102562\n",
      "Iteration: 2529/10000, Loss: 0.024995453655719757\n",
      "Iteration: 2530/10000, Loss: 0.02645455114543438\n",
      "Iteration: 2531/10000, Loss: 0.023415513336658478\n",
      "Iteration: 2532/10000, Loss: 0.018363049253821373\n",
      "Iteration: 2533/10000, Loss: 0.021305186673998833\n",
      "Iteration: 2534/10000, Loss: 0.020064882934093475\n",
      "Iteration: 2535/10000, Loss: 0.025485310703516006\n",
      "Iteration: 2536/10000, Loss: 0.02467244863510132\n",
      "Iteration: 2537/10000, Loss: 0.023287497460842133\n",
      "Iteration: 2538/10000, Loss: 0.03425360098481178\n",
      "Iteration: 2539/10000, Loss: 0.032034046947956085\n",
      "Iteration: 2540/10000, Loss: 0.01502649113535881\n",
      "Iteration: 2541/10000, Loss: 0.020549271255731583\n",
      "Iteration: 2542/10000, Loss: 0.020258687436580658\n",
      "Iteration: 2543/10000, Loss: 0.026065947487950325\n",
      "Iteration: 2544/10000, Loss: 0.022411081939935684\n",
      "Iteration: 2545/10000, Loss: 0.0234761293977499\n",
      "Iteration: 2546/10000, Loss: 0.026733411476016045\n",
      "Iteration: 2547/10000, Loss: 0.0394866019487381\n",
      "Iteration: 2548/10000, Loss: 0.020638301968574524\n",
      "Iteration: 2549/10000, Loss: 0.032655492424964905\n",
      "Iteration: 2550/10000, Loss: 0.018835388123989105\n",
      "Iteration: 2551/10000, Loss: 0.023698411881923676\n",
      "Iteration: 2552/10000, Loss: 0.024620583280920982\n",
      "Iteration: 2553/10000, Loss: 0.014998403377830982\n",
      "Iteration: 2554/10000, Loss: 0.03203138709068298\n",
      "Iteration: 2555/10000, Loss: 0.0182209275662899\n",
      "Iteration: 2556/10000, Loss: 0.02049756981432438\n",
      "Iteration: 2557/10000, Loss: 0.02625700645148754\n",
      "Iteration: 2558/10000, Loss: 0.036521922796964645\n",
      "Iteration: 2559/10000, Loss: 0.02265900745987892\n",
      "Iteration: 2560/10000, Loss: 0.04234769940376282\n",
      "Iteration: 2561/10000, Loss: 0.023822106420993805\n",
      "Iteration: 2562/10000, Loss: 0.023325279355049133\n",
      "Iteration: 2563/10000, Loss: 0.03366716951131821\n",
      "Iteration: 2564/10000, Loss: 0.02813132107257843\n",
      "Iteration: 2565/10000, Loss: 0.028266552835702896\n",
      "Iteration: 2566/10000, Loss: 0.023262405768036842\n",
      "Iteration: 2567/10000, Loss: 0.030976230278611183\n",
      "Iteration: 2568/10000, Loss: 0.024352287873625755\n",
      "Iteration: 2569/10000, Loss: 0.02433316968381405\n",
      "Iteration: 2570/10000, Loss: 0.023385098204016685\n",
      "Iteration: 2571/10000, Loss: 0.02997319959104061\n",
      "Iteration: 2572/10000, Loss: 0.02399308793246746\n",
      "Iteration: 2573/10000, Loss: 0.02865908108651638\n",
      "Iteration: 2574/10000, Loss: 0.033914051949977875\n",
      "Iteration: 2575/10000, Loss: 0.01858028955757618\n",
      "Iteration: 2576/10000, Loss: 0.02160545065999031\n",
      "Iteration: 2577/10000, Loss: 0.029596691951155663\n",
      "Iteration: 2578/10000, Loss: 0.031511131674051285\n",
      "Iteration: 2579/10000, Loss: 0.02314000204205513\n",
      "Iteration: 2580/10000, Loss: 0.02244638465344906\n",
      "Iteration: 2581/10000, Loss: 0.03274180367588997\n",
      "Iteration: 2582/10000, Loss: 0.025168247520923615\n",
      "Iteration: 2583/10000, Loss: 0.01795297861099243\n",
      "Iteration: 2584/10000, Loss: 0.0163229089230299\n",
      "Iteration: 2585/10000, Loss: 0.01671735569834709\n",
      "Iteration: 2586/10000, Loss: 0.025954339653253555\n",
      "Iteration: 2587/10000, Loss: 0.03364340960979462\n",
      "Iteration: 2588/10000, Loss: 0.024559006094932556\n",
      "Iteration: 2589/10000, Loss: 0.03649584576487541\n",
      "Iteration: 2590/10000, Loss: 0.02183268405497074\n",
      "Iteration: 2591/10000, Loss: 0.029028020799160004\n",
      "Iteration: 2592/10000, Loss: 0.019664928317070007\n",
      "Iteration: 2593/10000, Loss: 0.023925917223095894\n",
      "Iteration: 2594/10000, Loss: 0.022207679226994514\n",
      "Iteration: 2595/10000, Loss: 0.01486275065690279\n",
      "Iteration: 2596/10000, Loss: 0.02891623042523861\n",
      "Iteration: 2597/10000, Loss: 0.028423108160495758\n",
      "Iteration: 2598/10000, Loss: 0.04240623116493225\n",
      "Iteration: 2599/10000, Loss: 0.018848981708288193\n",
      "Iteration: 2600/10000, Loss: 0.024443630129098892\n",
      "Average test loss:  0.0050\n",
      "Iteration: 2601/10000, Loss: 0.03040451742708683\n",
      "Iteration: 2602/10000, Loss: 0.027806557714939117\n",
      "Iteration: 2603/10000, Loss: 0.020919319242239\n",
      "Iteration: 2604/10000, Loss: 0.026453297585248947\n",
      "Iteration: 2605/10000, Loss: 0.01987117901444435\n",
      "Iteration: 2606/10000, Loss: 0.014026086777448654\n",
      "Iteration: 2607/10000, Loss: 0.041473936289548874\n",
      "Iteration: 2608/10000, Loss: 0.01893305592238903\n",
      "Iteration: 2609/10000, Loss: 0.028943872079253197\n",
      "Iteration: 2610/10000, Loss: 0.016664084047079086\n",
      "Iteration: 2611/10000, Loss: 0.02645949460566044\n",
      "Iteration: 2612/10000, Loss: 0.023758791387081146\n",
      "Iteration: 2613/10000, Loss: 0.02441326342523098\n",
      "Iteration: 2614/10000, Loss: 0.022297874093055725\n",
      "Iteration: 2615/10000, Loss: 0.029518742114305496\n",
      "Iteration: 2616/10000, Loss: 0.027777763083577156\n",
      "Iteration: 2617/10000, Loss: 0.033217187970876694\n",
      "Iteration: 2618/10000, Loss: 0.024915644899010658\n",
      "Iteration: 2619/10000, Loss: 0.023486793041229248\n",
      "Iteration: 2620/10000, Loss: 0.015745660290122032\n",
      "Iteration: 2621/10000, Loss: 0.017476776614785194\n",
      "Iteration: 2622/10000, Loss: 0.026676110923290253\n",
      "Iteration: 2623/10000, Loss: 0.02405763603746891\n",
      "Iteration: 2624/10000, Loss: 0.018347980454564095\n",
      "Iteration: 2625/10000, Loss: 0.01876084692776203\n",
      "Iteration: 2626/10000, Loss: 0.025125553831458092\n",
      "Iteration: 2627/10000, Loss: 0.025113271549344063\n",
      "Iteration: 2628/10000, Loss: 0.022866632789373398\n",
      "Iteration: 2629/10000, Loss: 0.018084388226270676\n",
      "Iteration: 2630/10000, Loss: 0.018406802788376808\n",
      "Iteration: 2631/10000, Loss: 0.017422683537006378\n",
      "Iteration: 2632/10000, Loss: 0.03329407796263695\n",
      "Iteration: 2633/10000, Loss: 0.028252597898244858\n",
      "Iteration: 2634/10000, Loss: 0.024487458169460297\n",
      "Iteration: 2635/10000, Loss: 0.023708973079919815\n",
      "Iteration: 2636/10000, Loss: 0.025147616863250732\n",
      "Iteration: 2637/10000, Loss: 0.030603749677538872\n",
      "Iteration: 2638/10000, Loss: 0.022328266873955727\n",
      "Iteration: 2639/10000, Loss: 0.019542422145605087\n",
      "Iteration: 2640/10000, Loss: 0.026008261367678642\n",
      "Iteration: 2641/10000, Loss: 0.03025832027196884\n",
      "Iteration: 2642/10000, Loss: 0.02627759426832199\n",
      "Iteration: 2643/10000, Loss: 0.02940981090068817\n",
      "Iteration: 2644/10000, Loss: 0.020934751257300377\n",
      "Iteration: 2645/10000, Loss: 0.018418943509459496\n",
      "Iteration: 2646/10000, Loss: 0.016139641404151917\n",
      "Iteration: 2647/10000, Loss: 0.01888810284435749\n",
      "Iteration: 2648/10000, Loss: 0.0207956675440073\n",
      "Iteration: 2649/10000, Loss: 0.027149464935064316\n",
      "Iteration: 2650/10000, Loss: 0.021836403757333755\n",
      "Iteration: 2651/10000, Loss: 0.023128321394324303\n",
      "Iteration: 2652/10000, Loss: 0.01884700544178486\n",
      "Iteration: 2653/10000, Loss: 0.029809603467583656\n",
      "Iteration: 2654/10000, Loss: 0.0302099771797657\n",
      "Iteration: 2655/10000, Loss: 0.03034246154129505\n",
      "Iteration: 2656/10000, Loss: 0.019889047369360924\n",
      "Iteration: 2657/10000, Loss: 0.023857053369283676\n",
      "Iteration: 2658/10000, Loss: 0.026088718324899673\n",
      "Iteration: 2659/10000, Loss: 0.02569146640598774\n",
      "Iteration: 2660/10000, Loss: 0.028653880581259727\n",
      "Iteration: 2661/10000, Loss: 0.019564572721719742\n",
      "Iteration: 2662/10000, Loss: 0.02152775600552559\n",
      "Iteration: 2663/10000, Loss: 0.02647438272833824\n",
      "Iteration: 2664/10000, Loss: 0.02763412334024906\n",
      "Iteration: 2665/10000, Loss: 0.016207199543714523\n",
      "Iteration: 2666/10000, Loss: 0.021213360130786896\n",
      "Iteration: 2667/10000, Loss: 0.020593691617250443\n",
      "Iteration: 2668/10000, Loss: 0.023817257955670357\n",
      "Iteration: 2669/10000, Loss: 0.01738712750375271\n",
      "Iteration: 2670/10000, Loss: 0.028350872918963432\n",
      "Iteration: 2671/10000, Loss: 0.027379870414733887\n",
      "Iteration: 2672/10000, Loss: 0.02438630908727646\n",
      "Iteration: 2673/10000, Loss: 0.020607732236385345\n",
      "Iteration: 2674/10000, Loss: 0.019388092681765556\n",
      "Iteration: 2675/10000, Loss: 0.021070171147584915\n",
      "Iteration: 2676/10000, Loss: 0.022833777591586113\n",
      "Iteration: 2677/10000, Loss: 0.02404114417731762\n",
      "Iteration: 2678/10000, Loss: 0.03253095597028732\n",
      "Iteration: 2679/10000, Loss: 0.022047720849514008\n",
      "Iteration: 2680/10000, Loss: 0.024869227781891823\n",
      "Iteration: 2681/10000, Loss: 0.021039217710494995\n",
      "Iteration: 2682/10000, Loss: 0.021826768293976784\n",
      "Iteration: 2683/10000, Loss: 0.026431100443005562\n",
      "Iteration: 2684/10000, Loss: 0.024598412215709686\n",
      "Iteration: 2685/10000, Loss: 0.023266496136784554\n",
      "Iteration: 2686/10000, Loss: 0.028391310945153236\n",
      "Iteration: 2687/10000, Loss: 0.02821902371942997\n",
      "Iteration: 2688/10000, Loss: 0.022566303610801697\n",
      "Iteration: 2689/10000, Loss: 0.014599010348320007\n",
      "Iteration: 2690/10000, Loss: 0.029836691915988922\n",
      "Iteration: 2691/10000, Loss: 0.04268909990787506\n",
      "Iteration: 2692/10000, Loss: 0.0223840419203043\n",
      "Iteration: 2693/10000, Loss: 0.026089083403348923\n",
      "Iteration: 2694/10000, Loss: 0.01994527131319046\n",
      "Iteration: 2695/10000, Loss: 0.023337511345744133\n",
      "Iteration: 2696/10000, Loss: 0.022711003199219704\n",
      "Iteration: 2697/10000, Loss: 0.016870085150003433\n",
      "Iteration: 2698/10000, Loss: 0.013682433404028416\n",
      "Iteration: 2699/10000, Loss: 0.017899679020047188\n",
      "Iteration: 2700/10000, Loss: 0.026658795773983\n",
      "Average test loss:  0.0037\n",
      "Iteration: 2701/10000, Loss: 0.023343006148934364\n",
      "Iteration: 2702/10000, Loss: 0.013217415660619736\n",
      "Iteration: 2703/10000, Loss: 0.023180224001407623\n",
      "Iteration: 2704/10000, Loss: 0.02144538424909115\n",
      "Iteration: 2705/10000, Loss: 0.018876170739531517\n",
      "Iteration: 2706/10000, Loss: 0.022928329184651375\n",
      "Iteration: 2707/10000, Loss: 0.03206712007522583\n",
      "Iteration: 2708/10000, Loss: 0.021421408280730247\n",
      "Iteration: 2709/10000, Loss: 0.03075539506971836\n",
      "Iteration: 2710/10000, Loss: 0.021754654124379158\n",
      "Iteration: 2711/10000, Loss: 0.017619824036955833\n",
      "Iteration: 2712/10000, Loss: 0.0220430176705122\n",
      "Iteration: 2713/10000, Loss: 0.025571340695023537\n",
      "Iteration: 2714/10000, Loss: 0.01766194961965084\n",
      "Iteration: 2715/10000, Loss: 0.02489444985985756\n",
      "Iteration: 2716/10000, Loss: 0.030907627195119858\n",
      "Iteration: 2717/10000, Loss: 0.01923559419810772\n",
      "Iteration: 2718/10000, Loss: 0.03603032976388931\n",
      "Iteration: 2719/10000, Loss: 0.02598509192466736\n",
      "Iteration: 2720/10000, Loss: 0.023345673456788063\n",
      "Iteration: 2721/10000, Loss: 0.022294919937849045\n",
      "Iteration: 2722/10000, Loss: 0.023746736347675323\n",
      "Iteration: 2723/10000, Loss: 0.031645506620407104\n",
      "Iteration: 2724/10000, Loss: 0.024806063622236252\n",
      "Iteration: 2725/10000, Loss: 0.02714930661022663\n",
      "Iteration: 2726/10000, Loss: 0.02616039291024208\n",
      "Iteration: 2727/10000, Loss: 0.011431537568569183\n",
      "Iteration: 2728/10000, Loss: 0.028805559501051903\n",
      "Iteration: 2729/10000, Loss: 0.02742808870971203\n",
      "Iteration: 2730/10000, Loss: 0.0180127564817667\n",
      "Iteration: 2731/10000, Loss: 0.024396896362304688\n",
      "Iteration: 2732/10000, Loss: 0.030521675944328308\n",
      "Iteration: 2733/10000, Loss: 0.02923455834388733\n",
      "Iteration: 2734/10000, Loss: 0.01657828874886036\n",
      "Iteration: 2735/10000, Loss: 0.02696753665804863\n",
      "Iteration: 2736/10000, Loss: 0.02181759849190712\n",
      "Iteration: 2737/10000, Loss: 0.03220801427960396\n",
      "Iteration: 2738/10000, Loss: 0.025490565225481987\n",
      "Iteration: 2739/10000, Loss: 0.030483428388834\n",
      "Iteration: 2740/10000, Loss: 0.02688582055270672\n",
      "Iteration: 2741/10000, Loss: 0.021519850939512253\n",
      "Iteration: 2742/10000, Loss: 0.02098853699862957\n",
      "Iteration: 2743/10000, Loss: 0.01940169371664524\n",
      "Iteration: 2744/10000, Loss: 0.02618280239403248\n",
      "Iteration: 2745/10000, Loss: 0.02644626796245575\n",
      "Iteration: 2746/10000, Loss: 0.024617576971650124\n",
      "Iteration: 2747/10000, Loss: 0.016508527100086212\n",
      "Iteration: 2748/10000, Loss: 0.03145180270075798\n",
      "Iteration: 2749/10000, Loss: 0.020494427531957626\n",
      "Iteration: 2750/10000, Loss: 0.01797247864305973\n",
      "Iteration: 2751/10000, Loss: 0.019955875352025032\n",
      "Iteration: 2752/10000, Loss: 0.027309918776154518\n",
      "Iteration: 2753/10000, Loss: 0.034755464643239975\n",
      "Iteration: 2754/10000, Loss: 0.038996316492557526\n",
      "Iteration: 2755/10000, Loss: 0.018999144434928894\n",
      "Iteration: 2756/10000, Loss: 0.03675749525427818\n",
      "Iteration: 2757/10000, Loss: 0.017343195155262947\n",
      "Iteration: 2758/10000, Loss: 0.0300619937479496\n",
      "Iteration: 2759/10000, Loss: 0.02175929956138134\n",
      "Iteration: 2760/10000, Loss: 0.016359055414795876\n",
      "Iteration: 2761/10000, Loss: 0.020489277318120003\n",
      "Iteration: 2762/10000, Loss: 0.020669111981987953\n",
      "Iteration: 2763/10000, Loss: 0.023337358608841896\n",
      "Iteration: 2764/10000, Loss: 0.02421489916741848\n",
      "Iteration: 2765/10000, Loss: 0.025296812877058983\n",
      "Iteration: 2766/10000, Loss: 0.021125223487615585\n",
      "Iteration: 2767/10000, Loss: 0.02385859563946724\n",
      "Iteration: 2768/10000, Loss: 0.026015302166342735\n",
      "Iteration: 2769/10000, Loss: 0.025013940408825874\n",
      "Iteration: 2770/10000, Loss: 0.02647215873003006\n",
      "Iteration: 2771/10000, Loss: 0.028947461396455765\n",
      "Iteration: 2772/10000, Loss: 0.02139727771282196\n",
      "Iteration: 2773/10000, Loss: 0.024376943707466125\n",
      "Iteration: 2774/10000, Loss: 0.026666788384318352\n",
      "Iteration: 2775/10000, Loss: 0.024872712790966034\n",
      "Iteration: 2776/10000, Loss: 0.016238044947385788\n",
      "Iteration: 2777/10000, Loss: 0.01999756135046482\n",
      "Iteration: 2778/10000, Loss: 0.01750907301902771\n",
      "Iteration: 2779/10000, Loss: 0.026252303272485733\n",
      "Iteration: 2780/10000, Loss: 0.01926211640238762\n",
      "Iteration: 2781/10000, Loss: 0.021096767857670784\n",
      "Iteration: 2782/10000, Loss: 0.025899654254317284\n",
      "Iteration: 2783/10000, Loss: 0.015937352553009987\n",
      "Iteration: 2784/10000, Loss: 0.02461470663547516\n",
      "Iteration: 2785/10000, Loss: 0.03303360939025879\n",
      "Iteration: 2786/10000, Loss: 0.024722851812839508\n",
      "Iteration: 2787/10000, Loss: 0.026615997776389122\n",
      "Iteration: 2788/10000, Loss: 0.01867806725203991\n",
      "Iteration: 2789/10000, Loss: 0.0191289484500885\n",
      "Iteration: 2790/10000, Loss: 0.026425397023558617\n",
      "Iteration: 2791/10000, Loss: 0.030642304569482803\n",
      "Iteration: 2792/10000, Loss: 0.016408709809184074\n",
      "Iteration: 2793/10000, Loss: 0.023867454379796982\n",
      "Iteration: 2794/10000, Loss: 0.01991189271211624\n",
      "Iteration: 2795/10000, Loss: 0.014811682514846325\n",
      "Iteration: 2796/10000, Loss: 0.02892954647541046\n",
      "Iteration: 2797/10000, Loss: 0.03109295479953289\n",
      "Iteration: 2798/10000, Loss: 0.022792305797338486\n",
      "Iteration: 2799/10000, Loss: 0.023388244211673737\n",
      "Iteration: 2800/10000, Loss: 0.01998218521475792\n",
      "Average test loss:  0.0019\n",
      "Iteration: 2801/10000, Loss: 0.023841215297579765\n",
      "Iteration: 2802/10000, Loss: 0.02798992581665516\n",
      "Iteration: 2803/10000, Loss: 0.01863580010831356\n",
      "Iteration: 2804/10000, Loss: 0.016375239938497543\n",
      "Iteration: 2805/10000, Loss: 0.020753640681505203\n",
      "Iteration: 2806/10000, Loss: 0.01843499206006527\n",
      "Iteration: 2807/10000, Loss: 0.015511928126215935\n",
      "Iteration: 2808/10000, Loss: 0.018503008410334587\n",
      "Iteration: 2809/10000, Loss: 0.026137059554457664\n",
      "Iteration: 2810/10000, Loss: 0.02768305502831936\n",
      "Iteration: 2811/10000, Loss: 0.017202800139784813\n",
      "Iteration: 2812/10000, Loss: 0.02509150095283985\n",
      "Iteration: 2813/10000, Loss: 0.011492831632494926\n",
      "Iteration: 2814/10000, Loss: 0.01913697086274624\n",
      "Iteration: 2815/10000, Loss: 0.016803324222564697\n",
      "Iteration: 2816/10000, Loss: 0.023184271529316902\n",
      "Iteration: 2817/10000, Loss: 0.01888762228190899\n",
      "Iteration: 2818/10000, Loss: 0.01770380139350891\n",
      "Iteration: 2819/10000, Loss: 0.01837330311536789\n",
      "Iteration: 2820/10000, Loss: 0.022656897082924843\n",
      "Iteration: 2821/10000, Loss: 0.016608409583568573\n",
      "Iteration: 2822/10000, Loss: 0.020424440503120422\n",
      "Iteration: 2823/10000, Loss: 0.023897921666502953\n",
      "Iteration: 2824/10000, Loss: 0.02829485945403576\n",
      "Iteration: 2825/10000, Loss: 0.01953868381679058\n",
      "Iteration: 2826/10000, Loss: 0.021028507500886917\n",
      "Iteration: 2827/10000, Loss: 0.025211738422513008\n",
      "Iteration: 2828/10000, Loss: 0.02993372082710266\n",
      "Iteration: 2829/10000, Loss: 0.02422788180410862\n",
      "Iteration: 2830/10000, Loss: 0.01963767036795616\n",
      "Iteration: 2831/10000, Loss: 0.02128569409251213\n",
      "Iteration: 2832/10000, Loss: 0.018087277188897133\n",
      "Iteration: 2833/10000, Loss: 0.0171178188174963\n",
      "Iteration: 2834/10000, Loss: 0.022283462807536125\n",
      "Iteration: 2835/10000, Loss: 0.03943449631333351\n",
      "Iteration: 2836/10000, Loss: 0.024510663002729416\n",
      "Iteration: 2837/10000, Loss: 0.013567762449383736\n",
      "Iteration: 2838/10000, Loss: 0.03398493304848671\n",
      "Iteration: 2839/10000, Loss: 0.015878213569521904\n",
      "Iteration: 2840/10000, Loss: 0.018203506246209145\n",
      "Iteration: 2841/10000, Loss: 0.017818354070186615\n",
      "Iteration: 2842/10000, Loss: 0.020531803369522095\n",
      "Iteration: 2843/10000, Loss: 0.02569260634481907\n",
      "Iteration: 2844/10000, Loss: 0.016697581857442856\n",
      "Iteration: 2845/10000, Loss: 0.01934671774506569\n",
      "Iteration: 2846/10000, Loss: 0.024829454720020294\n",
      "Iteration: 2847/10000, Loss: 0.0166836678981781\n",
      "Iteration: 2848/10000, Loss: 0.02469247207045555\n",
      "Iteration: 2849/10000, Loss: 0.021631252020597458\n",
      "Iteration: 2850/10000, Loss: 0.019703762605786324\n",
      "Iteration: 2851/10000, Loss: 0.027516838163137436\n",
      "Iteration: 2852/10000, Loss: 0.02347758039832115\n",
      "Iteration: 2853/10000, Loss: 0.019089670851826668\n",
      "Iteration: 2854/10000, Loss: 0.02225658856332302\n",
      "Iteration: 2855/10000, Loss: 0.02994156815111637\n",
      "Iteration: 2856/10000, Loss: 0.01292278803884983\n",
      "Iteration: 2857/10000, Loss: 0.02493184618651867\n",
      "Iteration: 2858/10000, Loss: 0.015825962647795677\n",
      "Iteration: 2859/10000, Loss: 0.012803315185010433\n",
      "Iteration: 2860/10000, Loss: 0.03043803572654724\n",
      "Iteration: 2861/10000, Loss: 0.01828262396156788\n",
      "Iteration: 2862/10000, Loss: 0.020851876586675644\n",
      "Iteration: 2863/10000, Loss: 0.027948103845119476\n",
      "Iteration: 2864/10000, Loss: 0.013440488837659359\n",
      "Iteration: 2865/10000, Loss: 0.025725368410348892\n",
      "Iteration: 2866/10000, Loss: 0.017450138926506042\n",
      "Iteration: 2867/10000, Loss: 0.021063175052404404\n",
      "Iteration: 2868/10000, Loss: 0.023675452917814255\n",
      "Iteration: 2869/10000, Loss: 0.01554910745471716\n",
      "Iteration: 2870/10000, Loss: 0.019678283482789993\n",
      "Iteration: 2871/10000, Loss: 0.03209563344717026\n",
      "Iteration: 2872/10000, Loss: 0.016024738550186157\n",
      "Iteration: 2873/10000, Loss: 0.019856248050928116\n",
      "Iteration: 2874/10000, Loss: 0.01933068409562111\n",
      "Iteration: 2875/10000, Loss: 0.02562788687646389\n",
      "Iteration: 2876/10000, Loss: 0.024442758411169052\n",
      "Iteration: 2877/10000, Loss: 0.02019686996936798\n",
      "Iteration: 2878/10000, Loss: 0.02069179154932499\n",
      "Iteration: 2879/10000, Loss: 0.024556973949074745\n",
      "Iteration: 2880/10000, Loss: 0.033441849052906036\n",
      "Iteration: 2881/10000, Loss: 0.04093693569302559\n",
      "Iteration: 2882/10000, Loss: 0.025865662842988968\n",
      "Iteration: 2883/10000, Loss: 0.023319510743021965\n",
      "Iteration: 2884/10000, Loss: 0.021334528923034668\n",
      "Iteration: 2885/10000, Loss: 0.021367786452174187\n",
      "Iteration: 2886/10000, Loss: 0.026974936947226524\n",
      "Iteration: 2887/10000, Loss: 0.02450176514685154\n",
      "Iteration: 2888/10000, Loss: 0.01612032949924469\n",
      "Iteration: 2889/10000, Loss: 0.025099320337176323\n",
      "Iteration: 2890/10000, Loss: 0.027394477277994156\n",
      "Iteration: 2891/10000, Loss: 0.032259292900562286\n",
      "Iteration: 2892/10000, Loss: 0.024026237428188324\n",
      "Iteration: 2893/10000, Loss: 0.01789850927889347\n",
      "Iteration: 2894/10000, Loss: 0.016839366406202316\n",
      "Iteration: 2895/10000, Loss: 0.023923087865114212\n",
      "Iteration: 2896/10000, Loss: 0.01867060549557209\n",
      "Iteration: 2897/10000, Loss: 0.02770679071545601\n",
      "Iteration: 2898/10000, Loss: 0.018268384039402008\n",
      "Iteration: 2899/10000, Loss: 0.019645346328616142\n",
      "Iteration: 2900/10000, Loss: 0.017485331743955612\n",
      "Average test loss:  0.0040\n",
      "Iteration: 2901/10000, Loss: 0.014495380222797394\n",
      "Iteration: 2902/10000, Loss: 0.02589266747236252\n",
      "Iteration: 2903/10000, Loss: 0.030863791704177856\n",
      "Iteration: 2904/10000, Loss: 0.013947137631475925\n",
      "Iteration: 2905/10000, Loss: 0.022451819851994514\n",
      "Iteration: 2906/10000, Loss: 0.023694736883044243\n",
      "Iteration: 2907/10000, Loss: 0.021706752479076385\n",
      "Iteration: 2908/10000, Loss: 0.014041787944734097\n",
      "Iteration: 2909/10000, Loss: 0.012878505513072014\n",
      "Iteration: 2910/10000, Loss: 0.029231194406747818\n",
      "Iteration: 2911/10000, Loss: 0.025220857933163643\n",
      "Iteration: 2912/10000, Loss: 0.01814492791891098\n",
      "Iteration: 2913/10000, Loss: 0.02889581024646759\n",
      "Iteration: 2914/10000, Loss: 0.017693547531962395\n",
      "Iteration: 2915/10000, Loss: 0.018149947747588158\n",
      "Iteration: 2916/10000, Loss: 0.015835074707865715\n",
      "Iteration: 2917/10000, Loss: 0.01919030025601387\n",
      "Iteration: 2918/10000, Loss: 0.02799047902226448\n",
      "Iteration: 2919/10000, Loss: 0.017310693860054016\n",
      "Iteration: 2920/10000, Loss: 0.017336295917630196\n",
      "Iteration: 2921/10000, Loss: 0.01517237164080143\n",
      "Iteration: 2922/10000, Loss: 0.014664504677057266\n",
      "Iteration: 2923/10000, Loss: 0.03561794012784958\n",
      "Iteration: 2924/10000, Loss: 0.013642934150993824\n",
      "Iteration: 2925/10000, Loss: 0.0077690728940069675\n",
      "Iteration: 2926/10000, Loss: 0.02205502800643444\n",
      "Iteration: 2927/10000, Loss: 0.027667677029967308\n",
      "Iteration: 2928/10000, Loss: 0.016341613605618477\n",
      "Iteration: 2929/10000, Loss: 0.02246992662549019\n",
      "Iteration: 2930/10000, Loss: 0.020822256803512573\n",
      "Iteration: 2931/10000, Loss: 0.024996742606163025\n",
      "Iteration: 2932/10000, Loss: 0.020752355456352234\n",
      "Iteration: 2933/10000, Loss: 0.01525370217859745\n",
      "Iteration: 2934/10000, Loss: 0.015546951442956924\n",
      "Iteration: 2935/10000, Loss: 0.014313466846942902\n",
      "Iteration: 2936/10000, Loss: 0.024580243974924088\n",
      "Iteration: 2937/10000, Loss: 0.02209220454096794\n",
      "Iteration: 2938/10000, Loss: 0.024732772260904312\n",
      "Iteration: 2939/10000, Loss: 0.03477450832724571\n",
      "Iteration: 2940/10000, Loss: 0.016825171187520027\n",
      "Iteration: 2941/10000, Loss: 0.022776320576667786\n",
      "Iteration: 2942/10000, Loss: 0.020395316183567047\n",
      "Iteration: 2943/10000, Loss: 0.024590281769633293\n",
      "Iteration: 2944/10000, Loss: 0.018436219543218613\n",
      "Iteration: 2945/10000, Loss: 0.024648437276482582\n",
      "Iteration: 2946/10000, Loss: 0.026098165661096573\n",
      "Iteration: 2947/10000, Loss: 0.02068333700299263\n",
      "Iteration: 2948/10000, Loss: 0.010861963033676147\n",
      "Iteration: 2949/10000, Loss: 0.01950404979288578\n",
      "Iteration: 2950/10000, Loss: 0.022865446284413338\n",
      "Iteration: 2951/10000, Loss: 0.019814295694231987\n",
      "Iteration: 2952/10000, Loss: 0.021901851519942284\n",
      "Iteration: 2953/10000, Loss: 0.02704768255352974\n",
      "Iteration: 2954/10000, Loss: 0.02862093597650528\n",
      "Iteration: 2955/10000, Loss: 0.01440222468227148\n",
      "Iteration: 2956/10000, Loss: 0.014918405562639236\n",
      "Iteration: 2957/10000, Loss: 0.01976962387561798\n",
      "Iteration: 2958/10000, Loss: 0.025084080174565315\n",
      "Iteration: 2959/10000, Loss: 0.021585341542959213\n",
      "Iteration: 2960/10000, Loss: 0.025162409991025925\n",
      "Iteration: 2961/10000, Loss: 0.022499119862914085\n",
      "Iteration: 2962/10000, Loss: 0.022442253306508064\n",
      "Iteration: 2963/10000, Loss: 0.017115294933319092\n",
      "Iteration: 2964/10000, Loss: 0.02644895389676094\n",
      "Iteration: 2965/10000, Loss: 0.02236936055123806\n",
      "Iteration: 2966/10000, Loss: 0.019457465037703514\n",
      "Iteration: 2967/10000, Loss: 0.02171315997838974\n",
      "Iteration: 2968/10000, Loss: 0.017688265070319176\n",
      "Iteration: 2969/10000, Loss: 0.023332390934228897\n",
      "Iteration: 2970/10000, Loss: 0.0177353136241436\n",
      "Iteration: 2971/10000, Loss: 0.013922237791121006\n",
      "Iteration: 2972/10000, Loss: 0.014793486334383488\n",
      "Iteration: 2973/10000, Loss: 0.019074369221925735\n",
      "Iteration: 2974/10000, Loss: 0.02710382267832756\n",
      "Iteration: 2975/10000, Loss: 0.023385338485240936\n",
      "Iteration: 2976/10000, Loss: 0.022881194949150085\n",
      "Iteration: 2977/10000, Loss: 0.023579910397529602\n",
      "Iteration: 2978/10000, Loss: 0.015160097740590572\n",
      "Iteration: 2979/10000, Loss: 0.02121000923216343\n",
      "Iteration: 2980/10000, Loss: 0.024571193382143974\n",
      "Iteration: 2981/10000, Loss: 0.023060446605086327\n",
      "Iteration: 2982/10000, Loss: 0.01563272997736931\n",
      "Iteration: 2983/10000, Loss: 0.019233694300055504\n",
      "Iteration: 2984/10000, Loss: 0.027904869988560677\n",
      "Iteration: 2985/10000, Loss: 0.025628946721553802\n",
      "Iteration: 2986/10000, Loss: 0.015566844493150711\n",
      "Iteration: 2987/10000, Loss: 0.018184252083301544\n",
      "Iteration: 2988/10000, Loss: 0.01779140904545784\n",
      "Iteration: 2989/10000, Loss: 0.0349700041115284\n",
      "Iteration: 2990/10000, Loss: 0.019660968333482742\n",
      "Iteration: 2991/10000, Loss: 0.017563097178936005\n",
      "Iteration: 2992/10000, Loss: 0.029371775686740875\n",
      "Iteration: 2993/10000, Loss: 0.019770216196775436\n",
      "Iteration: 2994/10000, Loss: 0.019713759422302246\n",
      "Iteration: 2995/10000, Loss: 0.014583218842744827\n",
      "Iteration: 2996/10000, Loss: 0.021193860098719597\n",
      "Iteration: 2997/10000, Loss: 0.021702855825424194\n",
      "Iteration: 2998/10000, Loss: 0.0171949602663517\n",
      "Iteration: 2999/10000, Loss: 0.029500775039196014\n",
      "Iteration: 3000/10000, Loss: 0.015745120123028755\n",
      "Average test loss:  0.0026\n",
      "Iteration: 3001/10000, Loss: 0.026088623329997063\n",
      "Iteration: 3002/10000, Loss: 0.021320439875125885\n",
      "Iteration: 3003/10000, Loss: 0.024650877341628075\n",
      "Iteration: 3004/10000, Loss: 0.011353667825460434\n",
      "Iteration: 3005/10000, Loss: 0.018998701125383377\n",
      "Iteration: 3006/10000, Loss: 0.018474426120519638\n",
      "Iteration: 3007/10000, Loss: 0.014823175966739655\n",
      "Iteration: 3008/10000, Loss: 0.029331034049391747\n",
      "Iteration: 3009/10000, Loss: 0.021257339045405388\n",
      "Iteration: 3010/10000, Loss: 0.01956799626350403\n",
      "Iteration: 3011/10000, Loss: 0.018346484750509262\n",
      "Iteration: 3012/10000, Loss: 0.01628255844116211\n",
      "Iteration: 3013/10000, Loss: 0.015027530491352081\n",
      "Iteration: 3014/10000, Loss: 0.020629363134503365\n",
      "Iteration: 3015/10000, Loss: 0.023184141144156456\n",
      "Iteration: 3016/10000, Loss: 0.018834559246897697\n",
      "Iteration: 3017/10000, Loss: 0.014968211762607098\n",
      "Iteration: 3018/10000, Loss: 0.027747994288802147\n",
      "Iteration: 3019/10000, Loss: 0.014103918336331844\n",
      "Iteration: 3020/10000, Loss: 0.015149946324527264\n",
      "Iteration: 3021/10000, Loss: 0.020022360607981682\n",
      "Iteration: 3022/10000, Loss: 0.022251315414905548\n",
      "Iteration: 3023/10000, Loss: 0.026005135849118233\n",
      "Iteration: 3024/10000, Loss: 0.027886899188160896\n",
      "Iteration: 3025/10000, Loss: 0.021106885746121407\n",
      "Iteration: 3026/10000, Loss: 0.01594576984643936\n",
      "Iteration: 3027/10000, Loss: 0.013864096254110336\n",
      "Iteration: 3028/10000, Loss: 0.0224712323397398\n",
      "Iteration: 3029/10000, Loss: 0.01713598147034645\n",
      "Iteration: 3030/10000, Loss: 0.01487280335277319\n",
      "Iteration: 3031/10000, Loss: 0.019394971430301666\n",
      "Iteration: 3032/10000, Loss: 0.026337526738643646\n",
      "Iteration: 3033/10000, Loss: 0.019545933231711388\n",
      "Iteration: 3034/10000, Loss: 0.01765044406056404\n",
      "Iteration: 3035/10000, Loss: 0.017938291653990746\n",
      "Iteration: 3036/10000, Loss: 0.04014112800359726\n",
      "Iteration: 3037/10000, Loss: 0.02749544195830822\n",
      "Iteration: 3038/10000, Loss: 0.023161953315138817\n",
      "Iteration: 3039/10000, Loss: 0.023452403023838997\n",
      "Iteration: 3040/10000, Loss: 0.027403071522712708\n",
      "Iteration: 3041/10000, Loss: 0.015234275721013546\n",
      "Iteration: 3042/10000, Loss: 0.019117623567581177\n",
      "Iteration: 3043/10000, Loss: 0.02430497482419014\n",
      "Iteration: 3044/10000, Loss: 0.01776079088449478\n",
      "Iteration: 3045/10000, Loss: 0.023457923904061317\n",
      "Iteration: 3046/10000, Loss: 0.019644249230623245\n",
      "Iteration: 3047/10000, Loss: 0.025187985971570015\n",
      "Iteration: 3048/10000, Loss: 0.019576260820031166\n",
      "Iteration: 3049/10000, Loss: 0.03208266571164131\n",
      "Iteration: 3050/10000, Loss: 0.02178986370563507\n",
      "Iteration: 3051/10000, Loss: 0.027900105342268944\n",
      "Iteration: 3052/10000, Loss: 0.021326275542378426\n",
      "Iteration: 3053/10000, Loss: 0.02992895245552063\n",
      "Iteration: 3054/10000, Loss: 0.01779075898230076\n",
      "Iteration: 3055/10000, Loss: 0.02342584729194641\n",
      "Iteration: 3056/10000, Loss: 0.017837699502706528\n",
      "Iteration: 3057/10000, Loss: 0.02889283560216427\n",
      "Iteration: 3058/10000, Loss: 0.01393919438123703\n",
      "Iteration: 3059/10000, Loss: 0.016828685998916626\n",
      "Iteration: 3060/10000, Loss: 0.020897390320897102\n",
      "Iteration: 3061/10000, Loss: 0.01951448619365692\n",
      "Iteration: 3062/10000, Loss: 0.028806723654270172\n",
      "Iteration: 3063/10000, Loss: 0.019040219485759735\n",
      "Iteration: 3064/10000, Loss: 0.026742778718471527\n",
      "Iteration: 3065/10000, Loss: 0.021389275789260864\n",
      "Iteration: 3066/10000, Loss: 0.018037308007478714\n",
      "Iteration: 3067/10000, Loss: 0.0184930507093668\n",
      "Iteration: 3068/10000, Loss: 0.013763489201664925\n",
      "Iteration: 3069/10000, Loss: 0.01492825336754322\n",
      "Iteration: 3070/10000, Loss: 0.018071573227643967\n",
      "Iteration: 3071/10000, Loss: 0.021406183019280434\n",
      "Iteration: 3072/10000, Loss: 0.020327284932136536\n",
      "Iteration: 3073/10000, Loss: 0.021749678999185562\n",
      "Iteration: 3074/10000, Loss: 0.0267853531986475\n",
      "Iteration: 3075/10000, Loss: 0.018532956019043922\n",
      "Iteration: 3076/10000, Loss: 0.02209123596549034\n",
      "Iteration: 3077/10000, Loss: 0.023683415725827217\n",
      "Iteration: 3078/10000, Loss: 0.019141361117362976\n",
      "Iteration: 3079/10000, Loss: 0.028469117358326912\n",
      "Iteration: 3080/10000, Loss: 0.027225390076637268\n",
      "Iteration: 3081/10000, Loss: 0.018214158713817596\n",
      "Iteration: 3082/10000, Loss: 0.023632945492863655\n",
      "Iteration: 3083/10000, Loss: 0.019545165821909904\n",
      "Iteration: 3084/10000, Loss: 0.02122034691274166\n",
      "Iteration: 3085/10000, Loss: 0.013911068439483643\n",
      "Iteration: 3086/10000, Loss: 0.021953409537672997\n",
      "Iteration: 3087/10000, Loss: 0.01632002554833889\n",
      "Iteration: 3088/10000, Loss: 0.0251468513160944\n",
      "Iteration: 3089/10000, Loss: 0.02703176625072956\n",
      "Iteration: 3090/10000, Loss: 0.021449357271194458\n",
      "Iteration: 3091/10000, Loss: 0.01878882572054863\n",
      "Iteration: 3092/10000, Loss: 0.015755895525217056\n",
      "Iteration: 3093/10000, Loss: 0.0221696887165308\n",
      "Iteration: 3094/10000, Loss: 0.023174241185188293\n",
      "Iteration: 3095/10000, Loss: 0.020926250144839287\n",
      "Iteration: 3096/10000, Loss: 0.02509896643459797\n",
      "Iteration: 3097/10000, Loss: 0.025310318917036057\n",
      "Iteration: 3098/10000, Loss: 0.022898616269230843\n",
      "Iteration: 3099/10000, Loss: 0.02695554681122303\n",
      "Iteration: 3100/10000, Loss: 0.019096272066235542\n",
      "Average test loss:  0.0029\n",
      "Iteration: 3101/10000, Loss: 0.02205536887049675\n",
      "Iteration: 3102/10000, Loss: 0.019219309091567993\n",
      "Iteration: 3103/10000, Loss: 0.013468868099153042\n",
      "Iteration: 3104/10000, Loss: 0.026007860898971558\n",
      "Iteration: 3105/10000, Loss: 0.019619034603238106\n",
      "Iteration: 3106/10000, Loss: 0.02479192614555359\n",
      "Iteration: 3107/10000, Loss: 0.019107913598418236\n",
      "Iteration: 3108/10000, Loss: 0.02061787061393261\n",
      "Iteration: 3109/10000, Loss: 0.012123636901378632\n",
      "Iteration: 3110/10000, Loss: 0.018756669014692307\n",
      "Iteration: 3111/10000, Loss: 0.01822790317237377\n",
      "Iteration: 3112/10000, Loss: 0.010606607422232628\n",
      "Iteration: 3113/10000, Loss: 0.02004259265959263\n",
      "Iteration: 3114/10000, Loss: 0.03343336284160614\n",
      "Iteration: 3115/10000, Loss: 0.020567048341035843\n",
      "Iteration: 3116/10000, Loss: 0.015806391835212708\n",
      "Iteration: 3117/10000, Loss: 0.03122003935277462\n",
      "Iteration: 3118/10000, Loss: 0.028472283855080605\n",
      "Iteration: 3119/10000, Loss: 0.01946525275707245\n",
      "Iteration: 3120/10000, Loss: 0.01472142431885004\n",
      "Iteration: 3121/10000, Loss: 0.015342973172664642\n",
      "Iteration: 3122/10000, Loss: 0.02524389885365963\n",
      "Iteration: 3123/10000, Loss: 0.021815961226820946\n",
      "Iteration: 3124/10000, Loss: 0.020000377669930458\n",
      "Iteration: 3125/10000, Loss: 0.020348751917481422\n",
      "Iteration: 3126/10000, Loss: 0.02028622478246689\n",
      "Iteration: 3127/10000, Loss: 0.02193545363843441\n",
      "Iteration: 3128/10000, Loss: 0.02633603662252426\n",
      "Iteration: 3129/10000, Loss: 0.01363145187497139\n",
      "Iteration: 3130/10000, Loss: 0.02030341885983944\n",
      "Iteration: 3131/10000, Loss: 0.02080797217786312\n",
      "Iteration: 3132/10000, Loss: 0.014662191271781921\n",
      "Iteration: 3133/10000, Loss: 0.016976945102214813\n",
      "Iteration: 3134/10000, Loss: 0.027112286537885666\n",
      "Iteration: 3135/10000, Loss: 0.01658669300377369\n",
      "Iteration: 3136/10000, Loss: 0.02347954735159874\n",
      "Iteration: 3137/10000, Loss: 0.020485861226916313\n",
      "Iteration: 3138/10000, Loss: 0.021955586969852448\n",
      "Iteration: 3139/10000, Loss: 0.025051655247807503\n",
      "Iteration: 3140/10000, Loss: 0.01901600882411003\n",
      "Iteration: 3141/10000, Loss: 0.018494464457035065\n",
      "Iteration: 3142/10000, Loss: 0.018080735579133034\n",
      "Iteration: 3143/10000, Loss: 0.02479315921664238\n",
      "Iteration: 3144/10000, Loss: 0.01860686205327511\n",
      "Iteration: 3145/10000, Loss: 0.02439803071320057\n",
      "Iteration: 3146/10000, Loss: 0.011343750171363354\n",
      "Iteration: 3147/10000, Loss: 0.03294691443443298\n",
      "Iteration: 3148/10000, Loss: 0.014330470934510231\n",
      "Iteration: 3149/10000, Loss: 0.029569169506430626\n",
      "Iteration: 3150/10000, Loss: 0.017121663317084312\n",
      "Iteration: 3151/10000, Loss: 0.02235480397939682\n",
      "Iteration: 3152/10000, Loss: 0.026669831946492195\n",
      "Iteration: 3153/10000, Loss: 0.025993214920163155\n",
      "Iteration: 3154/10000, Loss: 0.014746724627912045\n",
      "Iteration: 3155/10000, Loss: 0.019104009494185448\n",
      "Iteration: 3156/10000, Loss: 0.022006819024682045\n",
      "Iteration: 3157/10000, Loss: 0.017751071602106094\n",
      "Iteration: 3158/10000, Loss: 0.017513850703835487\n",
      "Iteration: 3159/10000, Loss: 0.02609279192984104\n",
      "Iteration: 3160/10000, Loss: 0.012016293592751026\n",
      "Iteration: 3161/10000, Loss: 0.022715386003255844\n",
      "Iteration: 3162/10000, Loss: 0.024539098143577576\n",
      "Iteration: 3163/10000, Loss: 0.018943145871162415\n",
      "Iteration: 3164/10000, Loss: 0.024950336664915085\n",
      "Iteration: 3165/10000, Loss: 0.024965396150946617\n",
      "Iteration: 3166/10000, Loss: 0.013874889351427555\n",
      "Iteration: 3167/10000, Loss: 0.017486214637756348\n",
      "Iteration: 3168/10000, Loss: 0.022658664733171463\n",
      "Iteration: 3169/10000, Loss: 0.021581755951046944\n",
      "Iteration: 3170/10000, Loss: 0.00809611938893795\n",
      "Iteration: 3171/10000, Loss: 0.02374604344367981\n",
      "Iteration: 3172/10000, Loss: 0.022671746090054512\n",
      "Iteration: 3173/10000, Loss: 0.017897725105285645\n",
      "Iteration: 3174/10000, Loss: 0.019910788163542747\n",
      "Iteration: 3175/10000, Loss: 0.01651596836745739\n",
      "Iteration: 3176/10000, Loss: 0.019208727404475212\n",
      "Iteration: 3177/10000, Loss: 0.02243892289698124\n",
      "Iteration: 3178/10000, Loss: 0.019445504993200302\n",
      "Iteration: 3179/10000, Loss: 0.01458508986979723\n",
      "Iteration: 3180/10000, Loss: 0.016400331631302834\n",
      "Iteration: 3181/10000, Loss: 0.01267541665583849\n",
      "Iteration: 3182/10000, Loss: 0.026099571958184242\n",
      "Iteration: 3183/10000, Loss: 0.012407904490828514\n",
      "Iteration: 3184/10000, Loss: 0.033448174595832825\n",
      "Iteration: 3185/10000, Loss: 0.02238859236240387\n",
      "Iteration: 3186/10000, Loss: 0.013427159748971462\n",
      "Iteration: 3187/10000, Loss: 0.025228211656212807\n",
      "Iteration: 3188/10000, Loss: 0.02450140006840229\n",
      "Iteration: 3189/10000, Loss: 0.024457771331071854\n",
      "Iteration: 3190/10000, Loss: 0.02728538028895855\n",
      "Iteration: 3191/10000, Loss: 0.01780448667705059\n",
      "Iteration: 3192/10000, Loss: 0.021524915471673012\n",
      "Iteration: 3193/10000, Loss: 0.021160034462809563\n",
      "Iteration: 3194/10000, Loss: 0.017909066751599312\n",
      "Iteration: 3195/10000, Loss: 0.02819129265844822\n",
      "Iteration: 3196/10000, Loss: 0.024014553055167198\n",
      "Iteration: 3197/10000, Loss: 0.02172021195292473\n",
      "Iteration: 3198/10000, Loss: 0.022290488705039024\n",
      "Iteration: 3199/10000, Loss: 0.025301126763224602\n",
      "Iteration: 3200/10000, Loss: 0.02828948199748993\n",
      "Average test loss:  0.0019\n",
      "Iteration: 3201/10000, Loss: 0.013709304854273796\n",
      "Iteration: 3202/10000, Loss: 0.018685562536120415\n",
      "Iteration: 3203/10000, Loss: 0.018190395087003708\n",
      "Iteration: 3204/10000, Loss: 0.02180088683962822\n",
      "Iteration: 3205/10000, Loss: 0.013841678388416767\n",
      "Iteration: 3206/10000, Loss: 0.018285445868968964\n",
      "Iteration: 3207/10000, Loss: 0.018982332199811935\n",
      "Iteration: 3208/10000, Loss: 0.021850181743502617\n",
      "Iteration: 3209/10000, Loss: 0.024232598021626472\n",
      "Iteration: 3210/10000, Loss: 0.025037147104740143\n",
      "Iteration: 3211/10000, Loss: 0.0153970867395401\n",
      "Iteration: 3212/10000, Loss: 0.02100047469139099\n",
      "Iteration: 3213/10000, Loss: 0.019294293597340584\n",
      "Iteration: 3214/10000, Loss: 0.015535702928900719\n",
      "Iteration: 3215/10000, Loss: 0.020952096208930016\n",
      "Iteration: 3216/10000, Loss: 0.01975690759718418\n",
      "Iteration: 3217/10000, Loss: 0.020891133695840836\n",
      "Iteration: 3218/10000, Loss: 0.02182699367403984\n",
      "Iteration: 3219/10000, Loss: 0.02616485208272934\n",
      "Iteration: 3220/10000, Loss: 0.020571313798427582\n",
      "Iteration: 3221/10000, Loss: 0.026320578530430794\n",
      "Iteration: 3222/10000, Loss: 0.01149959396570921\n",
      "Iteration: 3223/10000, Loss: 0.012973102740943432\n",
      "Iteration: 3224/10000, Loss: 0.0181628055870533\n",
      "Iteration: 3225/10000, Loss: 0.02071191929280758\n",
      "Iteration: 3226/10000, Loss: 0.01328155118972063\n",
      "Iteration: 3227/10000, Loss: 0.018538355827331543\n",
      "Iteration: 3228/10000, Loss: 0.015844587236642838\n",
      "Iteration: 3229/10000, Loss: 0.013276361860334873\n",
      "Iteration: 3230/10000, Loss: 0.015726778656244278\n",
      "Iteration: 3231/10000, Loss: 0.025255898013710976\n",
      "Iteration: 3232/10000, Loss: 0.023366406559944153\n",
      "Iteration: 3233/10000, Loss: 0.011938433162868023\n",
      "Iteration: 3234/10000, Loss: 0.013868269510567188\n",
      "Iteration: 3235/10000, Loss: 0.02565568871796131\n",
      "Iteration: 3236/10000, Loss: 0.00959484837949276\n",
      "Iteration: 3237/10000, Loss: 0.028344402089715004\n",
      "Iteration: 3238/10000, Loss: 0.012490836903452873\n",
      "Iteration: 3239/10000, Loss: 0.017308847978711128\n",
      "Iteration: 3240/10000, Loss: 0.018489671871066093\n",
      "Iteration: 3241/10000, Loss: 0.018261872231960297\n",
      "Iteration: 3242/10000, Loss: 0.019628556445240974\n",
      "Iteration: 3243/10000, Loss: 0.02396368235349655\n",
      "Iteration: 3244/10000, Loss: 0.017883751541376114\n",
      "Iteration: 3245/10000, Loss: 0.024110620841383934\n",
      "Iteration: 3246/10000, Loss: 0.019299795851111412\n",
      "Iteration: 3247/10000, Loss: 0.01874292641878128\n",
      "Iteration: 3248/10000, Loss: 0.013291853480041027\n",
      "Iteration: 3249/10000, Loss: 0.015712149441242218\n",
      "Iteration: 3250/10000, Loss: 0.027043690904974937\n",
      "Iteration: 3251/10000, Loss: 0.018870677798986435\n",
      "Iteration: 3252/10000, Loss: 0.011630167253315449\n",
      "Iteration: 3253/10000, Loss: 0.022869152948260307\n",
      "Iteration: 3254/10000, Loss: 0.018493786454200745\n",
      "Iteration: 3255/10000, Loss: 0.016362708061933517\n",
      "Iteration: 3256/10000, Loss: 0.018660344183444977\n",
      "Iteration: 3257/10000, Loss: 0.024594882503151894\n",
      "Iteration: 3258/10000, Loss: 0.016379885375499725\n",
      "Iteration: 3259/10000, Loss: 0.02060301974415779\n",
      "Iteration: 3260/10000, Loss: 0.028171464800834656\n",
      "Iteration: 3261/10000, Loss: 0.01676485501229763\n",
      "Iteration: 3262/10000, Loss: 0.025352930650115013\n",
      "Iteration: 3263/10000, Loss: 0.016322284936904907\n",
      "Iteration: 3264/10000, Loss: 0.02694932371377945\n",
      "Iteration: 3265/10000, Loss: 0.025764070451259613\n",
      "Iteration: 3266/10000, Loss: 0.020244799554347992\n",
      "Iteration: 3267/10000, Loss: 0.02047159895300865\n",
      "Iteration: 3268/10000, Loss: 0.013928218744695187\n",
      "Iteration: 3269/10000, Loss: 0.013077273964881897\n",
      "Iteration: 3270/10000, Loss: 0.016589704900979996\n",
      "Iteration: 3271/10000, Loss: 0.015393691137433052\n",
      "Iteration: 3272/10000, Loss: 0.01657058857381344\n",
      "Iteration: 3273/10000, Loss: 0.01666133850812912\n",
      "Iteration: 3274/10000, Loss: 0.018170757219195366\n",
      "Iteration: 3275/10000, Loss: 0.014798327349126339\n",
      "Iteration: 3276/10000, Loss: 0.026012200862169266\n",
      "Iteration: 3277/10000, Loss: 0.020555958151817322\n",
      "Iteration: 3278/10000, Loss: 0.013629114255309105\n",
      "Iteration: 3279/10000, Loss: 0.024203499779105186\n",
      "Iteration: 3280/10000, Loss: 0.01871398091316223\n",
      "Iteration: 3281/10000, Loss: 0.024263296276330948\n",
      "Iteration: 3282/10000, Loss: 0.022548222914338112\n",
      "Iteration: 3283/10000, Loss: 0.029140781611204147\n",
      "Iteration: 3284/10000, Loss: 0.01749991998076439\n",
      "Iteration: 3285/10000, Loss: 0.017206894233822823\n",
      "Iteration: 3286/10000, Loss: 0.029667414724826813\n",
      "Iteration: 3287/10000, Loss: 0.024964412674307823\n",
      "Iteration: 3288/10000, Loss: 0.018701275810599327\n",
      "Iteration: 3289/10000, Loss: 0.01619773358106613\n",
      "Iteration: 3290/10000, Loss: 0.018724998459219933\n",
      "Iteration: 3291/10000, Loss: 0.029097504913806915\n",
      "Iteration: 3292/10000, Loss: 0.009557639248669147\n",
      "Iteration: 3293/10000, Loss: 0.02037925086915493\n",
      "Iteration: 3294/10000, Loss: 0.015556146390736103\n",
      "Iteration: 3295/10000, Loss: 0.01671794056892395\n",
      "Iteration: 3296/10000, Loss: 0.015897711738944054\n",
      "Iteration: 3297/10000, Loss: 0.02169727347791195\n",
      "Iteration: 3298/10000, Loss: 0.0204695463180542\n",
      "Iteration: 3299/10000, Loss: 0.012574651278555393\n",
      "Iteration: 3300/10000, Loss: 0.03124219737946987\n",
      "Average test loss:  0.0014\n",
      "Iteration: 3301/10000, Loss: 0.012841930612921715\n",
      "Iteration: 3302/10000, Loss: 0.02096899226307869\n",
      "Iteration: 3303/10000, Loss: 0.01870640181005001\n",
      "Iteration: 3304/10000, Loss: 0.020378632470965385\n",
      "Iteration: 3305/10000, Loss: 0.016754504293203354\n",
      "Iteration: 3306/10000, Loss: 0.027981629595160484\n",
      "Iteration: 3307/10000, Loss: 0.030511273071169853\n",
      "Iteration: 3308/10000, Loss: 0.01933039166033268\n",
      "Iteration: 3309/10000, Loss: 0.029140090569853783\n",
      "Iteration: 3310/10000, Loss: 0.023468730971217155\n",
      "Iteration: 3311/10000, Loss: 0.0169952604919672\n",
      "Iteration: 3312/10000, Loss: 0.021978439763188362\n",
      "Iteration: 3313/10000, Loss: 0.015188487246632576\n",
      "Iteration: 3314/10000, Loss: 0.010000448673963547\n",
      "Iteration: 3315/10000, Loss: 0.026716308668255806\n",
      "Iteration: 3316/10000, Loss: 0.019006231799721718\n",
      "Iteration: 3317/10000, Loss: 0.022942231968045235\n",
      "Iteration: 3318/10000, Loss: 0.015964936465024948\n",
      "Iteration: 3319/10000, Loss: 0.020617742091417313\n",
      "Iteration: 3320/10000, Loss: 0.011459552682936192\n",
      "Iteration: 3321/10000, Loss: 0.02169916033744812\n",
      "Iteration: 3322/10000, Loss: 0.026690516620874405\n",
      "Iteration: 3323/10000, Loss: 0.016151970252394676\n",
      "Iteration: 3324/10000, Loss: 0.020325608551502228\n",
      "Iteration: 3325/10000, Loss: 0.02439807914197445\n",
      "Iteration: 3326/10000, Loss: 0.019741632044315338\n",
      "Iteration: 3327/10000, Loss: 0.015009257011115551\n",
      "Iteration: 3328/10000, Loss: 0.01823541522026062\n",
      "Iteration: 3329/10000, Loss: 0.011026161722838879\n",
      "Iteration: 3330/10000, Loss: 0.011103430762887001\n",
      "Iteration: 3331/10000, Loss: 0.023829260841012\n",
      "Iteration: 3332/10000, Loss: 0.02216111682355404\n",
      "Iteration: 3333/10000, Loss: 0.0133353965356946\n",
      "Iteration: 3334/10000, Loss: 0.02338075265288353\n",
      "Iteration: 3335/10000, Loss: 0.017505498602986336\n",
      "Iteration: 3336/10000, Loss: 0.026799708604812622\n",
      "Iteration: 3337/10000, Loss: 0.012568028643727303\n",
      "Iteration: 3338/10000, Loss: 0.024528399109840393\n",
      "Iteration: 3339/10000, Loss: 0.030049674212932587\n",
      "Iteration: 3340/10000, Loss: 0.02167525701224804\n",
      "Iteration: 3341/10000, Loss: 0.012412399984896183\n",
      "Iteration: 3342/10000, Loss: 0.02494088187813759\n",
      "Iteration: 3343/10000, Loss: 0.021065521985292435\n",
      "Iteration: 3344/10000, Loss: 0.020504336804151535\n",
      "Iteration: 3345/10000, Loss: 0.027518505230545998\n",
      "Iteration: 3346/10000, Loss: 0.016016673296689987\n",
      "Iteration: 3347/10000, Loss: 0.01334285270422697\n",
      "Iteration: 3348/10000, Loss: 0.02556450292468071\n",
      "Iteration: 3349/10000, Loss: 0.01968497596681118\n",
      "Iteration: 3350/10000, Loss: 0.02583431638777256\n",
      "Iteration: 3351/10000, Loss: 0.013568648137152195\n",
      "Iteration: 3352/10000, Loss: 0.014726932160556316\n",
      "Iteration: 3353/10000, Loss: 0.025356201454997063\n",
      "Iteration: 3354/10000, Loss: 0.019674014300107956\n",
      "Iteration: 3355/10000, Loss: 0.015929648652672768\n",
      "Iteration: 3356/10000, Loss: 0.018291732296347618\n",
      "Iteration: 3357/10000, Loss: 0.015515532344579697\n",
      "Iteration: 3358/10000, Loss: 0.01639878936111927\n",
      "Iteration: 3359/10000, Loss: 0.0223796758800745\n",
      "Iteration: 3360/10000, Loss: 0.016563598066568375\n",
      "Iteration: 3361/10000, Loss: 0.017914971336722374\n",
      "Iteration: 3362/10000, Loss: 0.013533428311347961\n",
      "Iteration: 3363/10000, Loss: 0.014573140069842339\n",
      "Iteration: 3364/10000, Loss: 0.01573099195957184\n",
      "Iteration: 3365/10000, Loss: 0.02288178540766239\n",
      "Iteration: 3366/10000, Loss: 0.02977345697581768\n",
      "Iteration: 3367/10000, Loss: 0.02220035530626774\n",
      "Iteration: 3368/10000, Loss: 0.0188722163438797\n",
      "Iteration: 3369/10000, Loss: 0.020665379241108894\n",
      "Iteration: 3370/10000, Loss: 0.018101762980222702\n",
      "Iteration: 3371/10000, Loss: 0.0145392045378685\n",
      "Iteration: 3372/10000, Loss: 0.017636720091104507\n",
      "Iteration: 3373/10000, Loss: 0.021482476964592934\n",
      "Iteration: 3374/10000, Loss: 0.020668480545282364\n",
      "Iteration: 3375/10000, Loss: 0.011108623817563057\n",
      "Iteration: 3376/10000, Loss: 0.02657601237297058\n",
      "Iteration: 3377/10000, Loss: 0.026722606271505356\n",
      "Iteration: 3378/10000, Loss: 0.01989332213997841\n",
      "Iteration: 3379/10000, Loss: 0.017845692113041878\n",
      "Iteration: 3380/10000, Loss: 0.016482150182127953\n",
      "Iteration: 3381/10000, Loss: 0.013800173997879028\n",
      "Iteration: 3382/10000, Loss: 0.021432140842080116\n",
      "Iteration: 3383/10000, Loss: 0.021814540028572083\n",
      "Iteration: 3384/10000, Loss: 0.027052905410528183\n",
      "Iteration: 3385/10000, Loss: 0.017313450574874878\n",
      "Iteration: 3386/10000, Loss: 0.012612988241016865\n",
      "Iteration: 3387/10000, Loss: 0.008582258597016335\n",
      "Iteration: 3388/10000, Loss: 0.015933042392134666\n",
      "Iteration: 3389/10000, Loss: 0.021523019298911095\n",
      "Iteration: 3390/10000, Loss: 0.01797780767083168\n",
      "Iteration: 3391/10000, Loss: 0.017736932262778282\n",
      "Iteration: 3392/10000, Loss: 0.015298621729016304\n",
      "Iteration: 3393/10000, Loss: 0.02021767757833004\n",
      "Iteration: 3394/10000, Loss: 0.019101498648524284\n",
      "Iteration: 3395/10000, Loss: 0.020011603832244873\n",
      "Iteration: 3396/10000, Loss: 0.016867583617568016\n",
      "Iteration: 3397/10000, Loss: 0.020589658990502357\n",
      "Iteration: 3398/10000, Loss: 0.017866823822259903\n",
      "Iteration: 3399/10000, Loss: 0.014743980951607227\n",
      "Iteration: 3400/10000, Loss: 0.023777134716510773\n",
      "Average test loss:  0.0020\n",
      "Iteration: 3401/10000, Loss: 0.014854623936116695\n",
      "Iteration: 3402/10000, Loss: 0.02245175652205944\n",
      "Iteration: 3403/10000, Loss: 0.02479603886604309\n",
      "Iteration: 3404/10000, Loss: 0.006032709032297134\n",
      "Iteration: 3405/10000, Loss: 0.011327223852276802\n",
      "Iteration: 3406/10000, Loss: 0.01613822765648365\n",
      "Iteration: 3407/10000, Loss: 0.018760351464152336\n",
      "Iteration: 3408/10000, Loss: 0.017709365114569664\n",
      "Iteration: 3409/10000, Loss: 0.012666061520576477\n",
      "Iteration: 3410/10000, Loss: 0.02101481519639492\n",
      "Iteration: 3411/10000, Loss: 0.019717155024409294\n",
      "Iteration: 3412/10000, Loss: 0.014414343051612377\n",
      "Iteration: 3413/10000, Loss: 0.017791058868169785\n",
      "Iteration: 3414/10000, Loss: 0.019259078428149223\n",
      "Iteration: 3415/10000, Loss: 0.01584620214998722\n",
      "Iteration: 3416/10000, Loss: 0.02176533453166485\n",
      "Iteration: 3417/10000, Loss: 0.020197708159685135\n",
      "Iteration: 3418/10000, Loss: 0.024659303948283195\n",
      "Iteration: 3419/10000, Loss: 0.016835860908031464\n",
      "Iteration: 3420/10000, Loss: 0.020763976499438286\n",
      "Iteration: 3421/10000, Loss: 0.014003465883433819\n",
      "Iteration: 3422/10000, Loss: 0.02488785609602928\n",
      "Iteration: 3423/10000, Loss: 0.017701491713523865\n",
      "Iteration: 3424/10000, Loss: 0.02187107503414154\n",
      "Iteration: 3425/10000, Loss: 0.025382105261087418\n",
      "Iteration: 3426/10000, Loss: 0.015833118930459023\n",
      "Iteration: 3427/10000, Loss: 0.022643228992819786\n",
      "Iteration: 3428/10000, Loss: 0.014836722053587437\n",
      "Iteration: 3429/10000, Loss: 0.02061762847006321\n",
      "Iteration: 3430/10000, Loss: 0.019773339852690697\n",
      "Iteration: 3431/10000, Loss: 0.013550903648138046\n",
      "Iteration: 3432/10000, Loss: 0.01559944823384285\n",
      "Iteration: 3433/10000, Loss: 0.013948850333690643\n",
      "Iteration: 3434/10000, Loss: 0.022294895723462105\n",
      "Iteration: 3435/10000, Loss: 0.027773991227149963\n",
      "Iteration: 3436/10000, Loss: 0.01586894318461418\n",
      "Iteration: 3437/10000, Loss: 0.018088053911924362\n",
      "Iteration: 3438/10000, Loss: 0.014481466263532639\n",
      "Iteration: 3439/10000, Loss: 0.011710422113537788\n",
      "Iteration: 3440/10000, Loss: 0.01368278544396162\n",
      "Iteration: 3441/10000, Loss: 0.018104486167430878\n",
      "Iteration: 3442/10000, Loss: 0.025682834908366203\n",
      "Iteration: 3443/10000, Loss: 0.020782150328159332\n",
      "Iteration: 3444/10000, Loss: 0.016086038202047348\n",
      "Iteration: 3445/10000, Loss: 0.016448883339762688\n",
      "Iteration: 3446/10000, Loss: 0.019250331446528435\n",
      "Iteration: 3447/10000, Loss: 0.0202772356569767\n",
      "Iteration: 3448/10000, Loss: 0.020422596484422684\n",
      "Iteration: 3449/10000, Loss: 0.02516118995845318\n",
      "Iteration: 3450/10000, Loss: 0.015164618380367756\n",
      "Iteration: 3451/10000, Loss: 0.023705260828137398\n",
      "Iteration: 3452/10000, Loss: 0.010250994004309177\n",
      "Iteration: 3453/10000, Loss: 0.02197449840605259\n",
      "Iteration: 3454/10000, Loss: 0.016052110120654106\n",
      "Iteration: 3455/10000, Loss: 0.02012292668223381\n",
      "Iteration: 3456/10000, Loss: 0.015503555536270142\n",
      "Iteration: 3457/10000, Loss: 0.014730358496308327\n",
      "Iteration: 3458/10000, Loss: 0.010773961432278156\n",
      "Iteration: 3459/10000, Loss: 0.011171272024512291\n",
      "Iteration: 3460/10000, Loss: 0.028059642761945724\n",
      "Iteration: 3461/10000, Loss: 0.013790089637041092\n",
      "Iteration: 3462/10000, Loss: 0.023914657533168793\n",
      "Iteration: 3463/10000, Loss: 0.011059191077947617\n",
      "Iteration: 3464/10000, Loss: 0.01813609153032303\n",
      "Iteration: 3465/10000, Loss: 0.019918547943234444\n",
      "Iteration: 3466/10000, Loss: 0.018536647781729698\n",
      "Iteration: 3467/10000, Loss: 0.01404516026377678\n",
      "Iteration: 3468/10000, Loss: 0.01249308418482542\n",
      "Iteration: 3469/10000, Loss: 0.016960956156253815\n",
      "Iteration: 3470/10000, Loss: 0.016821961849927902\n",
      "Iteration: 3471/10000, Loss: 0.025361817330121994\n",
      "Iteration: 3472/10000, Loss: 0.018114792183041573\n",
      "Iteration: 3473/10000, Loss: 0.018846090883016586\n",
      "Iteration: 3474/10000, Loss: 0.021115468814969063\n",
      "Iteration: 3475/10000, Loss: 0.017015989869832993\n",
      "Iteration: 3476/10000, Loss: 0.021816948428750038\n",
      "Iteration: 3477/10000, Loss: 0.019513839855790138\n",
      "Iteration: 3478/10000, Loss: 0.009911788627505302\n",
      "Iteration: 3479/10000, Loss: 0.017712194472551346\n",
      "Iteration: 3480/10000, Loss: 0.015437244437634945\n",
      "Iteration: 3481/10000, Loss: 0.013551764190196991\n",
      "Iteration: 3482/10000, Loss: 0.015651853755116463\n",
      "Iteration: 3483/10000, Loss: 0.021363599225878716\n",
      "Iteration: 3484/10000, Loss: 0.02044450119137764\n",
      "Iteration: 3485/10000, Loss: 0.014642544090747833\n",
      "Iteration: 3486/10000, Loss: 0.022586343809962273\n",
      "Iteration: 3487/10000, Loss: 0.017017774283885956\n",
      "Iteration: 3488/10000, Loss: 0.018005408346652985\n",
      "Iteration: 3489/10000, Loss: 0.022657686844468117\n",
      "Iteration: 3490/10000, Loss: 0.01713600754737854\n",
      "Iteration: 3491/10000, Loss: 0.02379097416996956\n",
      "Iteration: 3492/10000, Loss: 0.019583772867918015\n",
      "Iteration: 3493/10000, Loss: 0.016043176874518394\n",
      "Iteration: 3494/10000, Loss: 0.017267245799303055\n",
      "Iteration: 3495/10000, Loss: 0.015973053872585297\n",
      "Iteration: 3496/10000, Loss: 0.012365478090941906\n",
      "Iteration: 3497/10000, Loss: 0.01794813759624958\n",
      "Iteration: 3498/10000, Loss: 0.016845090314745903\n",
      "Iteration: 3499/10000, Loss: 0.02257508784532547\n",
      "Iteration: 3500/10000, Loss: 0.022124527022242546\n",
      "Average test loss:  0.0045\n",
      "Iteration: 3501/10000, Loss: 0.017566999420523643\n",
      "Iteration: 3502/10000, Loss: 0.027361717075109482\n",
      "Iteration: 3503/10000, Loss: 0.01062653586268425\n",
      "Iteration: 3504/10000, Loss: 0.024838803336024284\n",
      "Iteration: 3505/10000, Loss: 0.020513731986284256\n",
      "Iteration: 3506/10000, Loss: 0.02176392450928688\n",
      "Iteration: 3507/10000, Loss: 0.022386282682418823\n",
      "Iteration: 3508/10000, Loss: 0.01586453802883625\n",
      "Iteration: 3509/10000, Loss: 0.01573961414396763\n",
      "Iteration: 3510/10000, Loss: 0.018400005996227264\n",
      "Iteration: 3511/10000, Loss: 0.019746866077184677\n",
      "Iteration: 3512/10000, Loss: 0.018416985869407654\n",
      "Iteration: 3513/10000, Loss: 0.01723199523985386\n",
      "Iteration: 3514/10000, Loss: 0.01933380775153637\n",
      "Iteration: 3515/10000, Loss: 0.018410343676805496\n",
      "Iteration: 3516/10000, Loss: 0.022306552156805992\n",
      "Iteration: 3517/10000, Loss: 0.028407743200659752\n",
      "Iteration: 3518/10000, Loss: 0.01532733254134655\n",
      "Iteration: 3519/10000, Loss: 0.02889103814959526\n",
      "Iteration: 3520/10000, Loss: 0.019350852817296982\n",
      "Iteration: 3521/10000, Loss: 0.02802363783121109\n",
      "Iteration: 3522/10000, Loss: 0.021168220788240433\n",
      "Iteration: 3523/10000, Loss: 0.017576832324266434\n",
      "Iteration: 3524/10000, Loss: 0.01911178044974804\n",
      "Iteration: 3525/10000, Loss: 0.02097778022289276\n",
      "Iteration: 3526/10000, Loss: 0.02326139248907566\n",
      "Iteration: 3527/10000, Loss: 0.0177190899848938\n",
      "Iteration: 3528/10000, Loss: 0.016103481873869896\n",
      "Iteration: 3529/10000, Loss: 0.012113361619412899\n",
      "Iteration: 3530/10000, Loss: 0.02105613984167576\n",
      "Iteration: 3531/10000, Loss: 0.026209834963083267\n",
      "Iteration: 3532/10000, Loss: 0.01575971022248268\n",
      "Iteration: 3533/10000, Loss: 0.015267166309058666\n",
      "Iteration: 3534/10000, Loss: 0.017042052000761032\n",
      "Iteration: 3535/10000, Loss: 0.019762849435210228\n",
      "Iteration: 3536/10000, Loss: 0.017533697187900543\n",
      "Iteration: 3537/10000, Loss: 0.014271767809987068\n",
      "Iteration: 3538/10000, Loss: 0.013588984496891499\n",
      "Iteration: 3539/10000, Loss: 0.023978468030691147\n",
      "Iteration: 3540/10000, Loss: 0.01965382881462574\n",
      "Iteration: 3541/10000, Loss: 0.017905551940202713\n",
      "Iteration: 3542/10000, Loss: 0.01811613328754902\n",
      "Iteration: 3543/10000, Loss: 0.019925931468605995\n",
      "Iteration: 3544/10000, Loss: 0.015530552715063095\n",
      "Iteration: 3545/10000, Loss: 0.016428006812930107\n",
      "Iteration: 3546/10000, Loss: 0.02154642902314663\n",
      "Iteration: 3547/10000, Loss: 0.012149243615567684\n",
      "Iteration: 3548/10000, Loss: 0.020560266450047493\n",
      "Iteration: 3549/10000, Loss: 0.0310869999229908\n",
      "Iteration: 3550/10000, Loss: 0.015454916283488274\n",
      "Iteration: 3551/10000, Loss: 0.018669962882995605\n",
      "Iteration: 3552/10000, Loss: 0.014679592102766037\n",
      "Iteration: 3553/10000, Loss: 0.018069816753268242\n",
      "Iteration: 3554/10000, Loss: 0.025604726746678352\n",
      "Iteration: 3555/10000, Loss: 0.01856396347284317\n",
      "Iteration: 3556/10000, Loss: 0.020292818546295166\n",
      "Iteration: 3557/10000, Loss: 0.024370476603507996\n",
      "Iteration: 3558/10000, Loss: 0.02443515509366989\n",
      "Iteration: 3559/10000, Loss: 0.018960226327180862\n",
      "Iteration: 3560/10000, Loss: 0.025636745616793633\n",
      "Iteration: 3561/10000, Loss: 0.019618991762399673\n",
      "Iteration: 3562/10000, Loss: 0.019175808876752853\n",
      "Iteration: 3563/10000, Loss: 0.016119329258799553\n",
      "Iteration: 3564/10000, Loss: 0.019508052617311478\n",
      "Iteration: 3565/10000, Loss: 0.022463234141469002\n",
      "Iteration: 3566/10000, Loss: 0.015033331699669361\n",
      "Iteration: 3567/10000, Loss: 0.02874111942946911\n",
      "Iteration: 3568/10000, Loss: 0.024727826938033104\n",
      "Iteration: 3569/10000, Loss: 0.016172116622328758\n",
      "Iteration: 3570/10000, Loss: 0.02077293023467064\n",
      "Iteration: 3571/10000, Loss: 0.016849715262651443\n",
      "Iteration: 3572/10000, Loss: 0.019566239789128304\n",
      "Iteration: 3573/10000, Loss: 0.02756621316075325\n",
      "Iteration: 3574/10000, Loss: 0.025329185649752617\n",
      "Iteration: 3575/10000, Loss: 0.018709490075707436\n",
      "Iteration: 3576/10000, Loss: 0.02381810173392296\n",
      "Iteration: 3577/10000, Loss: 0.01635463908314705\n",
      "Iteration: 3578/10000, Loss: 0.019839312881231308\n",
      "Iteration: 3579/10000, Loss: 0.018945807591080666\n",
      "Iteration: 3580/10000, Loss: 0.028523176908493042\n",
      "Iteration: 3581/10000, Loss: 0.017324142158031464\n",
      "Iteration: 3582/10000, Loss: 0.020098218694329262\n",
      "Iteration: 3583/10000, Loss: 0.013818023726344109\n",
      "Iteration: 3584/10000, Loss: 0.01227193046361208\n",
      "Iteration: 3585/10000, Loss: 0.01454139780253172\n",
      "Iteration: 3586/10000, Loss: 0.02065826766192913\n",
      "Iteration: 3587/10000, Loss: 0.021736128255724907\n",
      "Iteration: 3588/10000, Loss: 0.013469190336763859\n",
      "Iteration: 3589/10000, Loss: 0.022335533052682877\n",
      "Iteration: 3590/10000, Loss: 0.02232924848794937\n",
      "Iteration: 3591/10000, Loss: 0.011094380170106888\n",
      "Iteration: 3592/10000, Loss: 0.01630806364119053\n",
      "Iteration: 3593/10000, Loss: 0.015844985842704773\n",
      "Iteration: 3594/10000, Loss: 0.024203132838010788\n",
      "Iteration: 3595/10000, Loss: 0.013880605809390545\n",
      "Iteration: 3596/10000, Loss: 0.012912812642753124\n",
      "Iteration: 3597/10000, Loss: 0.018047358840703964\n",
      "Iteration: 3598/10000, Loss: 0.01518938783556223\n",
      "Iteration: 3599/10000, Loss: 0.0232803076505661\n",
      "Iteration: 3600/10000, Loss: 0.01773894764482975\n",
      "Average test loss:  0.0021\n",
      "Iteration: 3601/10000, Loss: 0.01494323369115591\n",
      "Iteration: 3602/10000, Loss: 0.01920153573155403\n",
      "Iteration: 3603/10000, Loss: 0.017622709274291992\n",
      "Iteration: 3604/10000, Loss: 0.017838405445218086\n",
      "Iteration: 3605/10000, Loss: 0.028964750468730927\n",
      "Iteration: 3606/10000, Loss: 0.014657014980912209\n",
      "Iteration: 3607/10000, Loss: 0.023516181856393814\n",
      "Iteration: 3608/10000, Loss: 0.01910494454205036\n",
      "Iteration: 3609/10000, Loss: 0.016232704743742943\n",
      "Iteration: 3610/10000, Loss: 0.017080243676900864\n",
      "Iteration: 3611/10000, Loss: 0.018461037427186966\n",
      "Iteration: 3612/10000, Loss: 0.012884534895420074\n",
      "Iteration: 3613/10000, Loss: 0.01625688746571541\n",
      "Iteration: 3614/10000, Loss: 0.01841624453663826\n",
      "Iteration: 3615/10000, Loss: 0.025860637426376343\n",
      "Iteration: 3616/10000, Loss: 0.01498614251613617\n",
      "Iteration: 3617/10000, Loss: 0.012804741971194744\n",
      "Iteration: 3618/10000, Loss: 0.026166217401623726\n",
      "Iteration: 3619/10000, Loss: 0.014844327233731747\n",
      "Iteration: 3620/10000, Loss: 0.016219574958086014\n",
      "Iteration: 3621/10000, Loss: 0.019426021724939346\n",
      "Iteration: 3622/10000, Loss: 0.013535247184336185\n",
      "Iteration: 3623/10000, Loss: 0.01767255738377571\n",
      "Iteration: 3624/10000, Loss: 0.016755782067775726\n",
      "Iteration: 3625/10000, Loss: 0.024552084505558014\n",
      "Iteration: 3626/10000, Loss: 0.019848790019750595\n",
      "Iteration: 3627/10000, Loss: 0.019120190292596817\n",
      "Iteration: 3628/10000, Loss: 0.01951790228486061\n",
      "Iteration: 3629/10000, Loss: 0.018779728561639786\n",
      "Iteration: 3630/10000, Loss: 0.018027490004897118\n",
      "Iteration: 3631/10000, Loss: 0.018723830580711365\n",
      "Iteration: 3632/10000, Loss: 0.02044672518968582\n",
      "Iteration: 3633/10000, Loss: 0.018843786790966988\n",
      "Iteration: 3634/10000, Loss: 0.017485978081822395\n",
      "Iteration: 3635/10000, Loss: 0.013307212851941586\n",
      "Iteration: 3636/10000, Loss: 0.01695033349096775\n",
      "Iteration: 3637/10000, Loss: 0.018820948898792267\n",
      "Iteration: 3638/10000, Loss: 0.013632767833769321\n",
      "Iteration: 3639/10000, Loss: 0.01479306723922491\n",
      "Iteration: 3640/10000, Loss: 0.017298785969614983\n",
      "Iteration: 3641/10000, Loss: 0.02188660018146038\n",
      "Iteration: 3642/10000, Loss: 0.013003586791455746\n",
      "Iteration: 3643/10000, Loss: 0.015162751078605652\n",
      "Iteration: 3644/10000, Loss: 0.02282482571899891\n",
      "Iteration: 3645/10000, Loss: 0.01487753726541996\n",
      "Iteration: 3646/10000, Loss: 0.022367756813764572\n",
      "Iteration: 3647/10000, Loss: 0.02793283388018608\n",
      "Iteration: 3648/10000, Loss: 0.012953612022101879\n",
      "Iteration: 3649/10000, Loss: 0.01560642383992672\n",
      "Iteration: 3650/10000, Loss: 0.017644254490733147\n",
      "Iteration: 3651/10000, Loss: 0.012191250920295715\n",
      "Iteration: 3652/10000, Loss: 0.01076522283256054\n",
      "Iteration: 3653/10000, Loss: 0.01522932667285204\n",
      "Iteration: 3654/10000, Loss: 0.02547593228518963\n",
      "Iteration: 3655/10000, Loss: 0.011295115575194359\n",
      "Iteration: 3656/10000, Loss: 0.01699725165963173\n",
      "Iteration: 3657/10000, Loss: 0.01689109206199646\n",
      "Iteration: 3658/10000, Loss: 0.013415472581982613\n",
      "Iteration: 3659/10000, Loss: 0.017370684072375298\n",
      "Iteration: 3660/10000, Loss: 0.014958100393414497\n",
      "Iteration: 3661/10000, Loss: 0.017441757023334503\n",
      "Iteration: 3662/10000, Loss: 0.016976373270154\n",
      "Iteration: 3663/10000, Loss: 0.01715203747153282\n",
      "Iteration: 3664/10000, Loss: 0.015323230065405369\n",
      "Iteration: 3665/10000, Loss: 0.019527306780219078\n",
      "Iteration: 3666/10000, Loss: 0.014210131019353867\n",
      "Iteration: 3667/10000, Loss: 0.015422229655086994\n",
      "Iteration: 3668/10000, Loss: 0.018178783357143402\n",
      "Iteration: 3669/10000, Loss: 0.021611524745821953\n",
      "Iteration: 3670/10000, Loss: 0.014738204888999462\n",
      "Iteration: 3671/10000, Loss: 0.018394798040390015\n",
      "Iteration: 3672/10000, Loss: 0.018509864807128906\n",
      "Iteration: 3673/10000, Loss: 0.023014867678284645\n",
      "Iteration: 3674/10000, Loss: 0.010500282980501652\n",
      "Iteration: 3675/10000, Loss: 0.015467018820345402\n",
      "Iteration: 3676/10000, Loss: 0.02574365958571434\n",
      "Iteration: 3677/10000, Loss: 0.018241221085190773\n",
      "Iteration: 3678/10000, Loss: 0.013061393052339554\n",
      "Iteration: 3679/10000, Loss: 0.014488015323877335\n",
      "Iteration: 3680/10000, Loss: 0.023469775915145874\n",
      "Iteration: 3681/10000, Loss: 0.014338647946715355\n",
      "Iteration: 3682/10000, Loss: 0.01454546395689249\n",
      "Iteration: 3683/10000, Loss: 0.013746274635195732\n",
      "Iteration: 3684/10000, Loss: 0.02332458831369877\n",
      "Iteration: 3685/10000, Loss: 0.015707731246948242\n",
      "Iteration: 3686/10000, Loss: 0.01758596859872341\n",
      "Iteration: 3687/10000, Loss: 0.014524446800351143\n",
      "Iteration: 3688/10000, Loss: 0.012395071797072887\n",
      "Iteration: 3689/10000, Loss: 0.021767625585198402\n",
      "Iteration: 3690/10000, Loss: 0.015580281615257263\n",
      "Iteration: 3691/10000, Loss: 0.025824828073382378\n",
      "Iteration: 3692/10000, Loss: 0.014371709898114204\n",
      "Iteration: 3693/10000, Loss: 0.02082175202667713\n",
      "Iteration: 3694/10000, Loss: 0.022936783730983734\n",
      "Iteration: 3695/10000, Loss: 0.014151955023407936\n",
      "Iteration: 3696/10000, Loss: 0.01626899279654026\n",
      "Iteration: 3697/10000, Loss: 0.01328333467245102\n",
      "Iteration: 3698/10000, Loss: 0.014224722981452942\n",
      "Iteration: 3699/10000, Loss: 0.024692809209227562\n",
      "Iteration: 3700/10000, Loss: 0.016768785193562508\n",
      "Average test loss:  0.0028\n",
      "Iteration: 3701/10000, Loss: 0.010038342326879501\n",
      "Iteration: 3702/10000, Loss: 0.014831255190074444\n",
      "Iteration: 3703/10000, Loss: 0.026444947347044945\n",
      "Iteration: 3704/10000, Loss: 0.019858770072460175\n",
      "Iteration: 3705/10000, Loss: 0.018329722806811333\n",
      "Iteration: 3706/10000, Loss: 0.015054367482662201\n",
      "Iteration: 3707/10000, Loss: 0.013604619540274143\n",
      "Iteration: 3708/10000, Loss: 0.018543748185038567\n",
      "Iteration: 3709/10000, Loss: 0.018120642751455307\n",
      "Iteration: 3710/10000, Loss: 0.015290459617972374\n",
      "Iteration: 3711/10000, Loss: 0.018787896260619164\n",
      "Iteration: 3712/10000, Loss: 0.021946432068943977\n",
      "Iteration: 3713/10000, Loss: 0.020186204463243484\n",
      "Iteration: 3714/10000, Loss: 0.017979299649596214\n",
      "Iteration: 3715/10000, Loss: 0.013445502147078514\n",
      "Iteration: 3716/10000, Loss: 0.022994792088866234\n",
      "Iteration: 3717/10000, Loss: 0.022550411522388458\n",
      "Iteration: 3718/10000, Loss: 0.021202905103564262\n",
      "Iteration: 3719/10000, Loss: 0.017795223742723465\n",
      "Iteration: 3720/10000, Loss: 0.02313372865319252\n",
      "Iteration: 3721/10000, Loss: 0.021725866943597794\n",
      "Iteration: 3722/10000, Loss: 0.017389165237545967\n",
      "Iteration: 3723/10000, Loss: 0.014488914981484413\n",
      "Iteration: 3724/10000, Loss: 0.011440061032772064\n",
      "Iteration: 3725/10000, Loss: 0.021502092480659485\n",
      "Iteration: 3726/10000, Loss: 0.015564888715744019\n",
      "Iteration: 3727/10000, Loss: 0.016989633440971375\n",
      "Iteration: 3728/10000, Loss: 0.014967940747737885\n",
      "Iteration: 3729/10000, Loss: 0.016389090567827225\n",
      "Iteration: 3730/10000, Loss: 0.019127188250422478\n",
      "Iteration: 3731/10000, Loss: 0.01618790440261364\n",
      "Iteration: 3732/10000, Loss: 0.01725880429148674\n",
      "Iteration: 3733/10000, Loss: 0.010514938272535801\n",
      "Iteration: 3734/10000, Loss: 0.01739051192998886\n",
      "Iteration: 3735/10000, Loss: 0.014587001875042915\n",
      "Iteration: 3736/10000, Loss: 0.01692669279873371\n",
      "Iteration: 3737/10000, Loss: 0.014728367328643799\n",
      "Iteration: 3738/10000, Loss: 0.01670939102768898\n",
      "Iteration: 3739/10000, Loss: 0.016509370878338814\n",
      "Iteration: 3740/10000, Loss: 0.013773055747151375\n",
      "Iteration: 3741/10000, Loss: 0.027777675539255142\n",
      "Iteration: 3742/10000, Loss: 0.017614126205444336\n",
      "Iteration: 3743/10000, Loss: 0.03288819640874863\n",
      "Iteration: 3744/10000, Loss: 0.01842729188501835\n",
      "Iteration: 3745/10000, Loss: 0.017005376517772675\n",
      "Iteration: 3746/10000, Loss: 0.022862344980239868\n",
      "Iteration: 3747/10000, Loss: 0.0196614321321249\n",
      "Iteration: 3748/10000, Loss: 0.01410042867064476\n",
      "Iteration: 3749/10000, Loss: 0.015625732019543648\n",
      "Iteration: 3750/10000, Loss: 0.02119896188378334\n",
      "Iteration: 3751/10000, Loss: 0.025357916951179504\n",
      "Iteration: 3752/10000, Loss: 0.025465117767453194\n",
      "Iteration: 3753/10000, Loss: 0.015556159429252148\n",
      "Iteration: 3754/10000, Loss: 0.019900163635611534\n",
      "Iteration: 3755/10000, Loss: 0.012458361685276031\n",
      "Iteration: 3756/10000, Loss: 0.017803795635700226\n",
      "Iteration: 3757/10000, Loss: 0.01854541338980198\n",
      "Iteration: 3758/10000, Loss: 0.017668714746832848\n",
      "Iteration: 3759/10000, Loss: 0.01477021537721157\n",
      "Iteration: 3760/10000, Loss: 0.01898099109530449\n",
      "Iteration: 3761/10000, Loss: 0.014050946570932865\n",
      "Iteration: 3762/10000, Loss: 0.019122149795293808\n",
      "Iteration: 3763/10000, Loss: 0.015025587752461433\n",
      "Iteration: 3764/10000, Loss: 0.012248309329152107\n",
      "Iteration: 3765/10000, Loss: 0.015346832573413849\n",
      "Iteration: 3766/10000, Loss: 0.02721310779452324\n",
      "Iteration: 3767/10000, Loss: 0.013309299945831299\n",
      "Iteration: 3768/10000, Loss: 0.021175995469093323\n",
      "Iteration: 3769/10000, Loss: 0.017435889691114426\n",
      "Iteration: 3770/10000, Loss: 0.015630405396223068\n",
      "Iteration: 3771/10000, Loss: 0.02179313637316227\n",
      "Iteration: 3772/10000, Loss: 0.017177574336528778\n",
      "Iteration: 3773/10000, Loss: 0.01949349232017994\n",
      "Iteration: 3774/10000, Loss: 0.011524700559675694\n",
      "Iteration: 3775/10000, Loss: 0.017643099650740623\n",
      "Iteration: 3776/10000, Loss: 0.01861799880862236\n",
      "Iteration: 3777/10000, Loss: 0.014281181618571281\n",
      "Iteration: 3778/10000, Loss: 0.019053347408771515\n",
      "Iteration: 3779/10000, Loss: 0.02240431122481823\n",
      "Iteration: 3780/10000, Loss: 0.023371130228042603\n",
      "Iteration: 3781/10000, Loss: 0.019519023597240448\n",
      "Iteration: 3782/10000, Loss: 0.019897447898983955\n",
      "Iteration: 3783/10000, Loss: 0.01467994973063469\n",
      "Iteration: 3784/10000, Loss: 0.017128819599747658\n",
      "Iteration: 3785/10000, Loss: 0.01962156966328621\n",
      "Iteration: 3786/10000, Loss: 0.01021138858050108\n",
      "Iteration: 3787/10000, Loss: 0.01706354320049286\n",
      "Iteration: 3788/10000, Loss: 0.017268257215619087\n",
      "Iteration: 3789/10000, Loss: 0.01984228938817978\n",
      "Iteration: 3790/10000, Loss: 0.025102175772190094\n",
      "Iteration: 3791/10000, Loss: 0.01675768755376339\n",
      "Iteration: 3792/10000, Loss: 0.015597062185406685\n",
      "Iteration: 3793/10000, Loss: 0.013177384622395039\n",
      "Iteration: 3794/10000, Loss: 0.016933975741267204\n",
      "Iteration: 3795/10000, Loss: 0.018715232610702515\n",
      "Iteration: 3796/10000, Loss: 0.02457011491060257\n",
      "Iteration: 3797/10000, Loss: 0.019062254577875137\n",
      "Iteration: 3798/10000, Loss: 0.01468232274055481\n",
      "Iteration: 3799/10000, Loss: 0.018539072945713997\n",
      "Iteration: 3800/10000, Loss: 0.022640999406576157\n",
      "Average test loss:  0.0015\n",
      "Iteration: 3801/10000, Loss: 0.0186571404337883\n",
      "Iteration: 3802/10000, Loss: 0.014778893440961838\n",
      "Iteration: 3803/10000, Loss: 0.017348190769553185\n",
      "Iteration: 3804/10000, Loss: 0.024254431948065758\n",
      "Iteration: 3805/10000, Loss: 0.022835180163383484\n",
      "Iteration: 3806/10000, Loss: 0.01352731604129076\n",
      "Iteration: 3807/10000, Loss: 0.02091844379901886\n",
      "Iteration: 3808/10000, Loss: 0.012114533223211765\n",
      "Iteration: 3809/10000, Loss: 0.014098865911364555\n",
      "Iteration: 3810/10000, Loss: 0.013444023206830025\n",
      "Iteration: 3811/10000, Loss: 0.016530856490135193\n",
      "Iteration: 3812/10000, Loss: 0.016166802495718002\n",
      "Iteration: 3813/10000, Loss: 0.01826615072786808\n",
      "Iteration: 3814/10000, Loss: 0.02074335888028145\n",
      "Iteration: 3815/10000, Loss: 0.0182325579226017\n",
      "Iteration: 3816/10000, Loss: 0.016929954290390015\n",
      "Iteration: 3817/10000, Loss: 0.02259594202041626\n",
      "Iteration: 3818/10000, Loss: 0.02117323689162731\n",
      "Iteration: 3819/10000, Loss: 0.020953843370079994\n",
      "Iteration: 3820/10000, Loss: 0.014911387115716934\n",
      "Iteration: 3821/10000, Loss: 0.01923496648669243\n",
      "Iteration: 3822/10000, Loss: 0.0179784893989563\n",
      "Iteration: 3823/10000, Loss: 0.021560359746217728\n",
      "Iteration: 3824/10000, Loss: 0.018159685656428337\n",
      "Iteration: 3825/10000, Loss: 0.01582946442067623\n",
      "Iteration: 3826/10000, Loss: 0.020754890516400337\n",
      "Iteration: 3827/10000, Loss: 0.010331314988434315\n",
      "Iteration: 3828/10000, Loss: 0.020543038845062256\n",
      "Iteration: 3829/10000, Loss: 0.017153030261397362\n",
      "Iteration: 3830/10000, Loss: 0.011126257479190826\n",
      "Iteration: 3831/10000, Loss: 0.021806910634040833\n",
      "Iteration: 3832/10000, Loss: 0.02300194464623928\n",
      "Iteration: 3833/10000, Loss: 0.01815527305006981\n",
      "Iteration: 3834/10000, Loss: 0.016820579767227173\n",
      "Iteration: 3835/10000, Loss: 0.011391378939151764\n",
      "Iteration: 3836/10000, Loss: 0.010248135775327682\n",
      "Iteration: 3837/10000, Loss: 0.01606719382107258\n",
      "Iteration: 3838/10000, Loss: 0.01994570717215538\n",
      "Iteration: 3839/10000, Loss: 0.019997717812657356\n",
      "Iteration: 3840/10000, Loss: 0.011484464630484581\n",
      "Iteration: 3841/10000, Loss: 0.01630531996488571\n",
      "Iteration: 3842/10000, Loss: 0.010892759077250957\n",
      "Iteration: 3843/10000, Loss: 0.01414632610976696\n",
      "Iteration: 3844/10000, Loss: 0.020534005016088486\n",
      "Iteration: 3845/10000, Loss: 0.02253650687634945\n",
      "Iteration: 3846/10000, Loss: 0.008353546261787415\n",
      "Iteration: 3847/10000, Loss: 0.02258460409939289\n",
      "Iteration: 3848/10000, Loss: 0.018470032140612602\n",
      "Iteration: 3849/10000, Loss: 0.015612173825502396\n",
      "Iteration: 3850/10000, Loss: 0.015346134081482887\n",
      "Iteration: 3851/10000, Loss: 0.03052547015249729\n",
      "Iteration: 3852/10000, Loss: 0.013121917843818665\n",
      "Iteration: 3853/10000, Loss: 0.02558431774377823\n",
      "Iteration: 3854/10000, Loss: 0.022561799734830856\n",
      "Iteration: 3855/10000, Loss: 0.010467268526554108\n",
      "Iteration: 3856/10000, Loss: 0.01582053303718567\n",
      "Iteration: 3857/10000, Loss: 0.018579913303256035\n",
      "Iteration: 3858/10000, Loss: 0.018032796680927277\n",
      "Iteration: 3859/10000, Loss: 0.015966124832630157\n",
      "Iteration: 3860/10000, Loss: 0.016681961715221405\n",
      "Iteration: 3861/10000, Loss: 0.013261215761303902\n",
      "Iteration: 3862/10000, Loss: 0.0194675512611866\n",
      "Iteration: 3863/10000, Loss: 0.019198166206479073\n",
      "Iteration: 3864/10000, Loss: 0.018886705860495567\n",
      "Iteration: 3865/10000, Loss: 0.018874559551477432\n",
      "Iteration: 3866/10000, Loss: 0.011241277679800987\n",
      "Iteration: 3867/10000, Loss: 0.01826559752225876\n",
      "Iteration: 3868/10000, Loss: 0.014695611782371998\n",
      "Iteration: 3869/10000, Loss: 0.017076807096600533\n",
      "Iteration: 3870/10000, Loss: 0.023431815207004547\n",
      "Iteration: 3871/10000, Loss: 0.014737174846231937\n",
      "Iteration: 3872/10000, Loss: 0.018726877868175507\n",
      "Iteration: 3873/10000, Loss: 0.020957976579666138\n",
      "Iteration: 3874/10000, Loss: 0.018943672999739647\n",
      "Iteration: 3875/10000, Loss: 0.013629326596856117\n",
      "Iteration: 3876/10000, Loss: 0.012980235740542412\n",
      "Iteration: 3877/10000, Loss: 0.018750205636024475\n",
      "Iteration: 3878/10000, Loss: 0.018190018832683563\n",
      "Iteration: 3879/10000, Loss: 0.018361205235123634\n",
      "Iteration: 3880/10000, Loss: 0.0113863255828619\n",
      "Iteration: 3881/10000, Loss: 0.02351928874850273\n",
      "Iteration: 3882/10000, Loss: 0.022010821849107742\n",
      "Iteration: 3883/10000, Loss: 0.016780681908130646\n",
      "Iteration: 3884/10000, Loss: 0.020045772194862366\n",
      "Iteration: 3885/10000, Loss: 0.017122117802500725\n",
      "Iteration: 3886/10000, Loss: 0.01772092469036579\n",
      "Iteration: 3887/10000, Loss: 0.018867164850234985\n",
      "Iteration: 3888/10000, Loss: 0.014464139007031918\n",
      "Iteration: 3889/10000, Loss: 0.013132539577782154\n",
      "Iteration: 3890/10000, Loss: 0.019030798226594925\n",
      "Iteration: 3891/10000, Loss: 0.009738565422594547\n",
      "Iteration: 3892/10000, Loss: 0.014569333754479885\n",
      "Iteration: 3893/10000, Loss: 0.013915371149778366\n",
      "Iteration: 3894/10000, Loss: 0.021840732544660568\n",
      "Iteration: 3895/10000, Loss: 0.015085364691913128\n",
      "Iteration: 3896/10000, Loss: 0.013022337108850479\n",
      "Iteration: 3897/10000, Loss: 0.016094336286187172\n",
      "Iteration: 3898/10000, Loss: 0.01741873100399971\n",
      "Iteration: 3899/10000, Loss: 0.015175088308751583\n",
      "Iteration: 3900/10000, Loss: 0.015533612109720707\n",
      "Average test loss:  0.0024\n",
      "Iteration: 3901/10000, Loss: 0.01700536161661148\n",
      "Iteration: 3902/10000, Loss: 0.018485233187675476\n",
      "Iteration: 3903/10000, Loss: 0.019830411300063133\n",
      "Iteration: 3904/10000, Loss: 0.022197719663381577\n",
      "Iteration: 3905/10000, Loss: 0.01773764379322529\n",
      "Iteration: 3906/10000, Loss: 0.01921715773642063\n",
      "Iteration: 3907/10000, Loss: 0.014309328980743885\n",
      "Iteration: 3908/10000, Loss: 0.01679820753633976\n",
      "Iteration: 3909/10000, Loss: 0.016831573098897934\n",
      "Iteration: 3910/10000, Loss: 0.02036626636981964\n",
      "Iteration: 3911/10000, Loss: 0.02212630584836006\n",
      "Iteration: 3912/10000, Loss: 0.014471685513854027\n",
      "Iteration: 3913/10000, Loss: 0.01568111777305603\n",
      "Iteration: 3914/10000, Loss: 0.018258726224303246\n",
      "Iteration: 3915/10000, Loss: 0.017394205555319786\n",
      "Iteration: 3916/10000, Loss: 0.011375680565834045\n",
      "Iteration: 3917/10000, Loss: 0.00871453806757927\n",
      "Iteration: 3918/10000, Loss: 0.018197601661086082\n",
      "Iteration: 3919/10000, Loss: 0.01884591206908226\n",
      "Iteration: 3920/10000, Loss: 0.010813336819410324\n",
      "Iteration: 3921/10000, Loss: 0.014859498478472233\n",
      "Iteration: 3922/10000, Loss: 0.01509751658886671\n",
      "Iteration: 3923/10000, Loss: 0.022139351814985275\n",
      "Iteration: 3924/10000, Loss: 0.010896872729063034\n",
      "Iteration: 3925/10000, Loss: 0.01660759001970291\n",
      "Iteration: 3926/10000, Loss: 0.01725299283862114\n",
      "Iteration: 3927/10000, Loss: 0.01325975451618433\n",
      "Iteration: 3928/10000, Loss: 0.019831756129860878\n",
      "Iteration: 3929/10000, Loss: 0.008020611479878426\n",
      "Iteration: 3930/10000, Loss: 0.015697214752435684\n",
      "Iteration: 3931/10000, Loss: 0.014795465394854546\n",
      "Iteration: 3932/10000, Loss: 0.021991770714521408\n",
      "Iteration: 3933/10000, Loss: 0.01508156955242157\n",
      "Iteration: 3934/10000, Loss: 0.014165040105581284\n",
      "Iteration: 3935/10000, Loss: 0.01499676238745451\n",
      "Iteration: 3936/10000, Loss: 0.013701613061130047\n",
      "Iteration: 3937/10000, Loss: 0.01762741431593895\n",
      "Iteration: 3938/10000, Loss: 0.01348053477704525\n",
      "Iteration: 3939/10000, Loss: 0.01789570041000843\n",
      "Iteration: 3940/10000, Loss: 0.01509318221360445\n",
      "Iteration: 3941/10000, Loss: 0.017282042652368546\n",
      "Iteration: 3942/10000, Loss: 0.01751875877380371\n",
      "Iteration: 3943/10000, Loss: 0.017143264412879944\n",
      "Iteration: 3944/10000, Loss: 0.016810966655611992\n",
      "Iteration: 3945/10000, Loss: 0.016820581629872322\n",
      "Iteration: 3946/10000, Loss: 0.01922585628926754\n",
      "Iteration: 3947/10000, Loss: 0.012851918116211891\n",
      "Iteration: 3948/10000, Loss: 0.017364641651511192\n",
      "Iteration: 3949/10000, Loss: 0.016945384442806244\n",
      "Iteration: 3950/10000, Loss: 0.016267482191324234\n",
      "Iteration: 3951/10000, Loss: 0.01485473196953535\n",
      "Iteration: 3952/10000, Loss: 0.012786248698830605\n",
      "Iteration: 3953/10000, Loss: 0.01994389481842518\n",
      "Iteration: 3954/10000, Loss: 0.020391449332237244\n",
      "Iteration: 3955/10000, Loss: 0.01695106364786625\n",
      "Iteration: 3956/10000, Loss: 0.015594897791743279\n",
      "Iteration: 3957/10000, Loss: 0.027251247316598892\n",
      "Iteration: 3958/10000, Loss: 0.013947594910860062\n",
      "Iteration: 3959/10000, Loss: 0.016686653718352318\n",
      "Iteration: 3960/10000, Loss: 0.017336705699563026\n",
      "Iteration: 3961/10000, Loss: 0.01351501140743494\n",
      "Iteration: 3962/10000, Loss: 0.020333245396614075\n",
      "Iteration: 3963/10000, Loss: 0.013790225610136986\n",
      "Iteration: 3964/10000, Loss: 0.02941012568771839\n",
      "Iteration: 3965/10000, Loss: 0.014728723093867302\n",
      "Iteration: 3966/10000, Loss: 0.017435988411307335\n",
      "Iteration: 3967/10000, Loss: 0.013944870792329311\n",
      "Iteration: 3968/10000, Loss: 0.012982746586203575\n",
      "Iteration: 3969/10000, Loss: 0.011886128224432468\n",
      "Iteration: 3970/10000, Loss: 0.014667744748294353\n",
      "Iteration: 3971/10000, Loss: 0.013444656506180763\n",
      "Iteration: 3972/10000, Loss: 0.015094662085175514\n",
      "Iteration: 3973/10000, Loss: 0.011353113688528538\n",
      "Iteration: 3974/10000, Loss: 0.016457969322800636\n",
      "Iteration: 3975/10000, Loss: 0.013651050627231598\n",
      "Iteration: 3976/10000, Loss: 0.023006418719887733\n",
      "Iteration: 3977/10000, Loss: 0.019289344549179077\n",
      "Iteration: 3978/10000, Loss: 0.012360905297100544\n",
      "Iteration: 3979/10000, Loss: 0.0142211327329278\n",
      "Iteration: 3980/10000, Loss: 0.011350970715284348\n",
      "Iteration: 3981/10000, Loss: 0.02067800983786583\n",
      "Iteration: 3982/10000, Loss: 0.015750374644994736\n",
      "Iteration: 3983/10000, Loss: 0.016356656327843666\n",
      "Iteration: 3984/10000, Loss: 0.02205245941877365\n",
      "Iteration: 3985/10000, Loss: 0.011346984654664993\n",
      "Iteration: 3986/10000, Loss: 0.012112629599869251\n",
      "Iteration: 3987/10000, Loss: 0.01845172792673111\n",
      "Iteration: 3988/10000, Loss: 0.02114400640130043\n",
      "Iteration: 3989/10000, Loss: 0.017678910866379738\n",
      "Iteration: 3990/10000, Loss: 0.011970414780080318\n",
      "Iteration: 3991/10000, Loss: 0.024042535573244095\n",
      "Iteration: 3992/10000, Loss: 0.019409459084272385\n",
      "Iteration: 3993/10000, Loss: 0.01694479212164879\n",
      "Iteration: 3994/10000, Loss: 0.01534339226782322\n",
      "Iteration: 3995/10000, Loss: 0.01417536847293377\n",
      "Iteration: 3996/10000, Loss: 0.012589991092681885\n",
      "Iteration: 3997/10000, Loss: 0.014731369912624359\n",
      "Iteration: 3998/10000, Loss: 0.02359783835709095\n",
      "Iteration: 3999/10000, Loss: 0.03083300217986107\n",
      "Iteration: 4000/10000, Loss: 0.013836832717061043\n",
      "Average test loss:  0.0023\n",
      "Iteration: 4001/10000, Loss: 0.02081575244665146\n",
      "Iteration: 4002/10000, Loss: 0.017027586698532104\n",
      "Iteration: 4003/10000, Loss: 0.015131745487451553\n",
      "Iteration: 4004/10000, Loss: 0.01834108866751194\n",
      "Iteration: 4005/10000, Loss: 0.01907382532954216\n",
      "Iteration: 4006/10000, Loss: 0.016540784388780594\n",
      "Iteration: 4007/10000, Loss: 0.012055397033691406\n",
      "Iteration: 4008/10000, Loss: 0.015325875952839851\n",
      "Iteration: 4009/10000, Loss: 0.02021203376352787\n",
      "Iteration: 4010/10000, Loss: 0.017262114211916924\n",
      "Iteration: 4011/10000, Loss: 0.022971589118242264\n",
      "Iteration: 4012/10000, Loss: 0.01686171069741249\n",
      "Iteration: 4013/10000, Loss: 0.015072478912770748\n",
      "Iteration: 4014/10000, Loss: 0.01766752079129219\n",
      "Iteration: 4015/10000, Loss: 0.015229999087750912\n",
      "Iteration: 4016/10000, Loss: 0.022766971960663795\n",
      "Iteration: 4017/10000, Loss: 0.02458367496728897\n",
      "Iteration: 4018/10000, Loss: 0.016746094450354576\n",
      "Iteration: 4019/10000, Loss: 0.020270895212888718\n",
      "Iteration: 4020/10000, Loss: 0.013245620764791965\n",
      "Iteration: 4021/10000, Loss: 0.013637811876833439\n",
      "Iteration: 4022/10000, Loss: 0.016585422679781914\n",
      "Iteration: 4023/10000, Loss: 0.009992685168981552\n",
      "Iteration: 4024/10000, Loss: 0.010496293194591999\n",
      "Iteration: 4025/10000, Loss: 0.017795328050851822\n",
      "Iteration: 4026/10000, Loss: 0.020711984485387802\n",
      "Iteration: 4027/10000, Loss: 0.015315065160393715\n",
      "Iteration: 4028/10000, Loss: 0.0263348575681448\n",
      "Iteration: 4029/10000, Loss: 0.025090357288718224\n",
      "Iteration: 4030/10000, Loss: 0.012400380335748196\n",
      "Iteration: 4031/10000, Loss: 0.016177866607904434\n",
      "Iteration: 4032/10000, Loss: 0.017055470496416092\n",
      "Iteration: 4033/10000, Loss: 0.01311731617897749\n",
      "Iteration: 4034/10000, Loss: 0.016328873112797737\n",
      "Iteration: 4035/10000, Loss: 0.020468881353735924\n",
      "Iteration: 4036/10000, Loss: 0.010622567497193813\n",
      "Iteration: 4037/10000, Loss: 0.013853495940566063\n",
      "Iteration: 4038/10000, Loss: 0.018382558599114418\n",
      "Iteration: 4039/10000, Loss: 0.01945216953754425\n",
      "Iteration: 4040/10000, Loss: 0.018900059163570404\n",
      "Iteration: 4041/10000, Loss: 0.015665942803025246\n",
      "Iteration: 4042/10000, Loss: 0.028091292828321457\n",
      "Iteration: 4043/10000, Loss: 0.019125204533338547\n",
      "Iteration: 4044/10000, Loss: 0.01265376340597868\n",
      "Iteration: 4045/10000, Loss: 0.019601039588451385\n",
      "Iteration: 4046/10000, Loss: 0.017803657799959183\n",
      "Iteration: 4047/10000, Loss: 0.018307752907276154\n",
      "Iteration: 4048/10000, Loss: 0.016402944922447205\n",
      "Iteration: 4049/10000, Loss: 0.019896527752280235\n",
      "Iteration: 4050/10000, Loss: 0.019893383607268333\n",
      "Iteration: 4051/10000, Loss: 0.020859314128756523\n",
      "Iteration: 4052/10000, Loss: 0.012898636981844902\n",
      "Iteration: 4053/10000, Loss: 0.015691516920924187\n",
      "Iteration: 4054/10000, Loss: 0.01227748766541481\n",
      "Iteration: 4055/10000, Loss: 0.010765097104012966\n",
      "Iteration: 4056/10000, Loss: 0.016038913279771805\n",
      "Iteration: 4057/10000, Loss: 0.016678106039762497\n",
      "Iteration: 4058/10000, Loss: 0.011453105136752129\n",
      "Iteration: 4059/10000, Loss: 0.020159315317869186\n",
      "Iteration: 4060/10000, Loss: 0.02123783901333809\n",
      "Iteration: 4061/10000, Loss: 0.015593675896525383\n",
      "Iteration: 4062/10000, Loss: 0.012768682092428207\n",
      "Iteration: 4063/10000, Loss: 0.017950423061847687\n",
      "Iteration: 4064/10000, Loss: 0.01694830134510994\n",
      "Iteration: 4065/10000, Loss: 0.01891695149242878\n",
      "Iteration: 4066/10000, Loss: 0.021376851946115494\n",
      "Iteration: 4067/10000, Loss: 0.0169546976685524\n",
      "Iteration: 4068/10000, Loss: 0.0214118380099535\n",
      "Iteration: 4069/10000, Loss: 0.02268376015126705\n",
      "Iteration: 4070/10000, Loss: 0.014009370468556881\n",
      "Iteration: 4071/10000, Loss: 0.012540550902485847\n",
      "Iteration: 4072/10000, Loss: 0.014371959492564201\n",
      "Iteration: 4073/10000, Loss: 0.018293220549821854\n",
      "Iteration: 4074/10000, Loss: 0.014355350285768509\n",
      "Iteration: 4075/10000, Loss: 0.017621377483010292\n",
      "Iteration: 4076/10000, Loss: 0.021018579602241516\n",
      "Iteration: 4077/10000, Loss: 0.017169050872325897\n",
      "Iteration: 4078/10000, Loss: 0.019274994730949402\n",
      "Iteration: 4079/10000, Loss: 0.016826104372739792\n",
      "Iteration: 4080/10000, Loss: 0.009743218310177326\n",
      "Iteration: 4081/10000, Loss: 0.014771743677556515\n",
      "Iteration: 4082/10000, Loss: 0.015676366165280342\n",
      "Iteration: 4083/10000, Loss: 0.014978237450122833\n",
      "Iteration: 4084/10000, Loss: 0.011134411208331585\n",
      "Iteration: 4085/10000, Loss: 0.011998368427157402\n",
      "Iteration: 4086/10000, Loss: 0.01881362684071064\n",
      "Iteration: 4087/10000, Loss: 0.01568794809281826\n",
      "Iteration: 4088/10000, Loss: 0.011591491289436817\n",
      "Iteration: 4089/10000, Loss: 0.02446640655398369\n",
      "Iteration: 4090/10000, Loss: 0.016671666875481606\n",
      "Iteration: 4091/10000, Loss: 0.014420497231185436\n",
      "Iteration: 4092/10000, Loss: 0.016756335273385048\n",
      "Iteration: 4093/10000, Loss: 0.01491005439311266\n",
      "Iteration: 4094/10000, Loss: 0.018790723755955696\n",
      "Iteration: 4095/10000, Loss: 0.01708037033677101\n",
      "Iteration: 4096/10000, Loss: 0.01599646918475628\n",
      "Iteration: 4097/10000, Loss: 0.013636894524097443\n",
      "Iteration: 4098/10000, Loss: 0.0150937270373106\n",
      "Iteration: 4099/10000, Loss: 0.02114366553723812\n",
      "Iteration: 4100/10000, Loss: 0.018621673807501793\n",
      "Average test loss:  0.0026\n",
      "Iteration: 4101/10000, Loss: 0.01749260723590851\n",
      "Iteration: 4102/10000, Loss: 0.01804937981069088\n",
      "Iteration: 4103/10000, Loss: 0.013611980713903904\n",
      "Iteration: 4104/10000, Loss: 0.016259346157312393\n",
      "Iteration: 4105/10000, Loss: 0.013931052759289742\n",
      "Iteration: 4106/10000, Loss: 0.018208831548690796\n",
      "Iteration: 4107/10000, Loss: 0.022946776822209358\n",
      "Iteration: 4108/10000, Loss: 0.014794358052313328\n",
      "Iteration: 4109/10000, Loss: 0.02521899715065956\n",
      "Iteration: 4110/10000, Loss: 0.018916789442300797\n",
      "Iteration: 4111/10000, Loss: 0.009265994653105736\n",
      "Iteration: 4112/10000, Loss: 0.01517405267804861\n",
      "Iteration: 4113/10000, Loss: 0.012895098887383938\n",
      "Iteration: 4114/10000, Loss: 0.018716616556048393\n",
      "Iteration: 4115/10000, Loss: 0.016026413068175316\n",
      "Iteration: 4116/10000, Loss: 0.01441382896155119\n",
      "Iteration: 4117/10000, Loss: 0.016256658360362053\n",
      "Iteration: 4118/10000, Loss: 0.014193680137395859\n",
      "Iteration: 4119/10000, Loss: 0.01082985196262598\n",
      "Iteration: 4120/10000, Loss: 0.016237474977970123\n",
      "Iteration: 4121/10000, Loss: 0.020711220800876617\n",
      "Iteration: 4122/10000, Loss: 0.010718593373894691\n",
      "Iteration: 4123/10000, Loss: 0.012355737388134003\n",
      "Iteration: 4124/10000, Loss: 0.015600129961967468\n",
      "Iteration: 4125/10000, Loss: 0.01536870189011097\n",
      "Iteration: 4126/10000, Loss: 0.011786121875047684\n",
      "Iteration: 4127/10000, Loss: 0.021485235542058945\n",
      "Iteration: 4128/10000, Loss: 0.01170214731246233\n",
      "Iteration: 4129/10000, Loss: 0.015322414226830006\n",
      "Iteration: 4130/10000, Loss: 0.013287869282066822\n",
      "Iteration: 4131/10000, Loss: 0.011928980238735676\n",
      "Iteration: 4132/10000, Loss: 0.012883185409009457\n",
      "Iteration: 4133/10000, Loss: 0.019019752740859985\n",
      "Iteration: 4134/10000, Loss: 0.014158946461975574\n",
      "Iteration: 4135/10000, Loss: 0.014784648083150387\n",
      "Iteration: 4136/10000, Loss: 0.012979320250451565\n",
      "Iteration: 4137/10000, Loss: 0.024130312725901604\n",
      "Iteration: 4138/10000, Loss: 0.011960098519921303\n",
      "Iteration: 4139/10000, Loss: 0.01656273752450943\n",
      "Iteration: 4140/10000, Loss: 0.017343400046229362\n",
      "Iteration: 4141/10000, Loss: 0.01903543807566166\n",
      "Iteration: 4142/10000, Loss: 0.02014322578907013\n",
      "Iteration: 4143/10000, Loss: 0.014827653765678406\n",
      "Iteration: 4144/10000, Loss: 0.019672082737088203\n",
      "Iteration: 4145/10000, Loss: 0.01262340135872364\n",
      "Iteration: 4146/10000, Loss: 0.019329652190208435\n",
      "Iteration: 4147/10000, Loss: 0.022257115691900253\n",
      "Iteration: 4148/10000, Loss: 0.014037396758794785\n",
      "Iteration: 4149/10000, Loss: 0.012486576102674007\n",
      "Iteration: 4150/10000, Loss: 0.013925686478614807\n",
      "Iteration: 4151/10000, Loss: 0.022129571065306664\n",
      "Iteration: 4152/10000, Loss: 0.013686985708773136\n",
      "Iteration: 4153/10000, Loss: 0.0133722685277462\n",
      "Iteration: 4154/10000, Loss: 0.019394710659980774\n",
      "Iteration: 4155/10000, Loss: 0.014294890686869621\n",
      "Iteration: 4156/10000, Loss: 0.015104979276657104\n",
      "Iteration: 4157/10000, Loss: 0.02059062384068966\n",
      "Iteration: 4158/10000, Loss: 0.010883413255214691\n",
      "Iteration: 4159/10000, Loss: 0.010136358439922333\n",
      "Iteration: 4160/10000, Loss: 0.018205763772130013\n",
      "Iteration: 4161/10000, Loss: 0.028884436935186386\n",
      "Iteration: 4162/10000, Loss: 0.01608072966337204\n",
      "Iteration: 4163/10000, Loss: 0.019832473248243332\n",
      "Iteration: 4164/10000, Loss: 0.016729606315493584\n",
      "Iteration: 4165/10000, Loss: 0.013921544887125492\n",
      "Iteration: 4166/10000, Loss: 0.022506173700094223\n",
      "Iteration: 4167/10000, Loss: 0.016056932508945465\n",
      "Iteration: 4168/10000, Loss: 0.028605328872799873\n",
      "Iteration: 4169/10000, Loss: 0.018696492537856102\n",
      "Iteration: 4170/10000, Loss: 0.01660735160112381\n",
      "Iteration: 4171/10000, Loss: 0.010121735744178295\n",
      "Iteration: 4172/10000, Loss: 0.022042933851480484\n",
      "Iteration: 4173/10000, Loss: 0.0186812374740839\n",
      "Iteration: 4174/10000, Loss: 0.014591170474886894\n",
      "Iteration: 4175/10000, Loss: 0.01693836972117424\n",
      "Iteration: 4176/10000, Loss: 0.018099652603268623\n",
      "Iteration: 4177/10000, Loss: 0.015997981652617455\n",
      "Iteration: 4178/10000, Loss: 0.01835167407989502\n",
      "Iteration: 4179/10000, Loss: 0.018262643367052078\n",
      "Iteration: 4180/10000, Loss: 0.016492946073412895\n",
      "Iteration: 4181/10000, Loss: 0.014779618941247463\n",
      "Iteration: 4182/10000, Loss: 0.015073786489665508\n",
      "Iteration: 4183/10000, Loss: 0.011788444593548775\n",
      "Iteration: 4184/10000, Loss: 0.01596934348344803\n",
      "Iteration: 4185/10000, Loss: 0.015182742848992348\n",
      "Iteration: 4186/10000, Loss: 0.023193346336483955\n",
      "Iteration: 4187/10000, Loss: 0.012796192429959774\n",
      "Iteration: 4188/10000, Loss: 0.01697259023785591\n",
      "Iteration: 4189/10000, Loss: 0.020592566579580307\n",
      "Iteration: 4190/10000, Loss: 0.013925347477197647\n",
      "Iteration: 4191/10000, Loss: 0.01629732735455036\n",
      "Iteration: 4192/10000, Loss: 0.014583435840904713\n",
      "Iteration: 4193/10000, Loss: 0.014282814227044582\n",
      "Iteration: 4194/10000, Loss: 0.016723034903407097\n",
      "Iteration: 4195/10000, Loss: 0.011790458112955093\n",
      "Iteration: 4196/10000, Loss: 0.013302035629749298\n",
      "Iteration: 4197/10000, Loss: 0.018548792228102684\n",
      "Iteration: 4198/10000, Loss: 0.02324194461107254\n",
      "Iteration: 4199/10000, Loss: 0.01598537154495716\n",
      "Iteration: 4200/10000, Loss: 0.010312032885849476\n",
      "Average test loss:  0.0015\n",
      "Iteration: 4201/10000, Loss: 0.019311105832457542\n",
      "Iteration: 4202/10000, Loss: 0.016765106469392776\n",
      "Iteration: 4203/10000, Loss: 0.007822535000741482\n",
      "Iteration: 4204/10000, Loss: 0.014157627709209919\n",
      "Iteration: 4205/10000, Loss: 0.015034467913210392\n",
      "Iteration: 4206/10000, Loss: 0.01785939931869507\n",
      "Iteration: 4207/10000, Loss: 0.012854373082518578\n",
      "Iteration: 4208/10000, Loss: 0.013139800168573856\n",
      "Iteration: 4209/10000, Loss: 0.021145911887288094\n",
      "Iteration: 4210/10000, Loss: 0.017529163509607315\n",
      "Iteration: 4211/10000, Loss: 0.01753445714712143\n",
      "Iteration: 4212/10000, Loss: 0.016919991001486778\n",
      "Iteration: 4213/10000, Loss: 0.01399032212793827\n",
      "Iteration: 4214/10000, Loss: 0.015529988333582878\n",
      "Iteration: 4215/10000, Loss: 0.014189681969583035\n",
      "Iteration: 4216/10000, Loss: 0.020508361980319023\n",
      "Iteration: 4217/10000, Loss: 0.013197720050811768\n",
      "Iteration: 4218/10000, Loss: 0.012212109751999378\n",
      "Iteration: 4219/10000, Loss: 0.02713034115731716\n",
      "Iteration: 4220/10000, Loss: 0.018517347052693367\n",
      "Iteration: 4221/10000, Loss: 0.0177353136241436\n",
      "Iteration: 4222/10000, Loss: 0.019235750660300255\n",
      "Iteration: 4223/10000, Loss: 0.01397497858852148\n",
      "Iteration: 4224/10000, Loss: 0.010038684122264385\n",
      "Iteration: 4225/10000, Loss: 0.017389552667737007\n",
      "Iteration: 4226/10000, Loss: 0.01616513542830944\n",
      "Iteration: 4227/10000, Loss: 0.011766945943236351\n",
      "Iteration: 4228/10000, Loss: 0.01611539162695408\n",
      "Iteration: 4229/10000, Loss: 0.01967242732644081\n",
      "Iteration: 4230/10000, Loss: 0.023303614929318428\n",
      "Iteration: 4231/10000, Loss: 0.018376106396317482\n",
      "Iteration: 4232/10000, Loss: 0.015614748932421207\n",
      "Iteration: 4233/10000, Loss: 0.016362175345420837\n",
      "Iteration: 4234/10000, Loss: 0.023123279213905334\n",
      "Iteration: 4235/10000, Loss: 0.01192115992307663\n",
      "Iteration: 4236/10000, Loss: 0.023437703028321266\n",
      "Iteration: 4237/10000, Loss: 0.013220065273344517\n",
      "Iteration: 4238/10000, Loss: 0.02463877573609352\n",
      "Iteration: 4239/10000, Loss: 0.01631101593375206\n",
      "Iteration: 4240/10000, Loss: 0.01614476926624775\n",
      "Iteration: 4241/10000, Loss: 0.014783385209739208\n",
      "Iteration: 4242/10000, Loss: 0.01772031933069229\n",
      "Iteration: 4243/10000, Loss: 0.014435467310249805\n",
      "Iteration: 4244/10000, Loss: 0.01683664135634899\n",
      "Iteration: 4245/10000, Loss: 0.01134482491761446\n",
      "Iteration: 4246/10000, Loss: 0.016322162002325058\n",
      "Iteration: 4247/10000, Loss: 0.0156145840883255\n",
      "Iteration: 4248/10000, Loss: 0.018447842448949814\n",
      "Iteration: 4249/10000, Loss: 0.018225813284516335\n",
      "Iteration: 4250/10000, Loss: 0.01082520466297865\n",
      "Iteration: 4251/10000, Loss: 0.01673673838376999\n",
      "Iteration: 4252/10000, Loss: 0.015136796049773693\n",
      "Iteration: 4253/10000, Loss: 0.017965111881494522\n",
      "Iteration: 4254/10000, Loss: 0.017933331429958344\n",
      "Iteration: 4255/10000, Loss: 0.012481455691158772\n",
      "Iteration: 4256/10000, Loss: 0.01631859503686428\n",
      "Iteration: 4257/10000, Loss: 0.018724806606769562\n",
      "Iteration: 4258/10000, Loss: 0.019213872030377388\n",
      "Iteration: 4259/10000, Loss: 0.028615761548280716\n",
      "Iteration: 4260/10000, Loss: 0.014988934621214867\n",
      "Iteration: 4261/10000, Loss: 0.017538512125611305\n",
      "Iteration: 4262/10000, Loss: 0.019121438264846802\n",
      "Iteration: 4263/10000, Loss: 0.020230356603860855\n",
      "Iteration: 4264/10000, Loss: 0.013536212965846062\n",
      "Iteration: 4265/10000, Loss: 0.015203254297375679\n",
      "Iteration: 4266/10000, Loss: 0.01707434095442295\n",
      "Iteration: 4267/10000, Loss: 0.02301120199263096\n",
      "Iteration: 4268/10000, Loss: 0.011497723869979382\n",
      "Iteration: 4269/10000, Loss: 0.014050056226551533\n",
      "Iteration: 4270/10000, Loss: 0.010346120223402977\n",
      "Iteration: 4271/10000, Loss: 0.016774805262684822\n",
      "Iteration: 4272/10000, Loss: 0.015247408300638199\n",
      "Iteration: 4273/10000, Loss: 0.013698027469217777\n",
      "Iteration: 4274/10000, Loss: 0.017303748056292534\n",
      "Iteration: 4275/10000, Loss: 0.01731047034263611\n",
      "Iteration: 4276/10000, Loss: 0.012861820869147778\n",
      "Iteration: 4277/10000, Loss: 0.020420735701918602\n",
      "Iteration: 4278/10000, Loss: 0.014756238088011742\n",
      "Iteration: 4279/10000, Loss: 0.016971822828054428\n",
      "Iteration: 4280/10000, Loss: 0.009827851317822933\n",
      "Iteration: 4281/10000, Loss: 0.018276333808898926\n",
      "Iteration: 4282/10000, Loss: 0.01393831055611372\n",
      "Iteration: 4283/10000, Loss: 0.013848675414919853\n",
      "Iteration: 4284/10000, Loss: 0.016705645248293877\n",
      "Iteration: 4285/10000, Loss: 0.011372488923370838\n",
      "Iteration: 4286/10000, Loss: 0.027755500748753548\n",
      "Iteration: 4287/10000, Loss: 0.018804775550961494\n",
      "Iteration: 4288/10000, Loss: 0.013793766498565674\n",
      "Iteration: 4289/10000, Loss: 0.018820326775312424\n",
      "Iteration: 4290/10000, Loss: 0.016775591298937798\n",
      "Iteration: 4291/10000, Loss: 0.010887030512094498\n",
      "Iteration: 4292/10000, Loss: 0.01420279685407877\n",
      "Iteration: 4293/10000, Loss: 0.01549005601555109\n",
      "Iteration: 4294/10000, Loss: 0.026787905022501945\n",
      "Iteration: 4295/10000, Loss: 0.013852149248123169\n",
      "Iteration: 4296/10000, Loss: 0.013695995323359966\n",
      "Iteration: 4297/10000, Loss: 0.01602037250995636\n",
      "Iteration: 4298/10000, Loss: 0.010580184869468212\n",
      "Iteration: 4299/10000, Loss: 0.009191595017910004\n",
      "Iteration: 4300/10000, Loss: 0.013216547667980194\n",
      "Average test loss:  0.0036\n",
      "Iteration: 4301/10000, Loss: 0.013248361647129059\n",
      "Iteration: 4302/10000, Loss: 0.01468456257134676\n",
      "Iteration: 4303/10000, Loss: 0.021424010396003723\n",
      "Iteration: 4304/10000, Loss: 0.022810300812125206\n",
      "Iteration: 4305/10000, Loss: 0.014789494685828686\n",
      "Iteration: 4306/10000, Loss: 0.013967461884021759\n",
      "Iteration: 4307/10000, Loss: 0.009225498884916306\n",
      "Iteration: 4308/10000, Loss: 0.014011531136929989\n",
      "Iteration: 4309/10000, Loss: 0.020637067034840584\n",
      "Iteration: 4310/10000, Loss: 0.01172058004885912\n",
      "Iteration: 4311/10000, Loss: 0.011462853290140629\n",
      "Iteration: 4312/10000, Loss: 0.017341189086437225\n",
      "Iteration: 4313/10000, Loss: 0.011221349239349365\n",
      "Iteration: 4314/10000, Loss: 0.016165634617209435\n",
      "Iteration: 4315/10000, Loss: 0.013158397749066353\n",
      "Iteration: 4316/10000, Loss: 0.01470266841351986\n",
      "Iteration: 4317/10000, Loss: 0.012551404535770416\n",
      "Iteration: 4318/10000, Loss: 0.021204080432653427\n",
      "Iteration: 4319/10000, Loss: 0.020755739882588387\n",
      "Iteration: 4320/10000, Loss: 0.0102367689833045\n",
      "Iteration: 4321/10000, Loss: 0.01767794042825699\n",
      "Iteration: 4322/10000, Loss: 0.015983911231160164\n",
      "Iteration: 4323/10000, Loss: 0.01826826110482216\n",
      "Iteration: 4324/10000, Loss: 0.018075846135616302\n",
      "Iteration: 4325/10000, Loss: 0.01687460020184517\n",
      "Iteration: 4326/10000, Loss: 0.010730999521911144\n",
      "Iteration: 4327/10000, Loss: 0.017730554565787315\n",
      "Iteration: 4328/10000, Loss: 0.015983734279870987\n",
      "Iteration: 4329/10000, Loss: 0.010367317125201225\n",
      "Iteration: 4330/10000, Loss: 0.027065584436058998\n",
      "Iteration: 4331/10000, Loss: 0.01610957458615303\n",
      "Iteration: 4332/10000, Loss: 0.013836950995028019\n",
      "Iteration: 4333/10000, Loss: 0.022639833390712738\n",
      "Iteration: 4334/10000, Loss: 0.016877640038728714\n",
      "Iteration: 4335/10000, Loss: 0.014797220937907696\n",
      "Iteration: 4336/10000, Loss: 0.017929276451468468\n",
      "Iteration: 4337/10000, Loss: 0.013177442364394665\n",
      "Iteration: 4338/10000, Loss: 0.011744542047381401\n",
      "Iteration: 4339/10000, Loss: 0.028662988916039467\n",
      "Iteration: 4340/10000, Loss: 0.016386905685067177\n",
      "Iteration: 4341/10000, Loss: 0.013107563368976116\n",
      "Iteration: 4342/10000, Loss: 0.012480520643293858\n",
      "Iteration: 4343/10000, Loss: 0.019245468080043793\n",
      "Iteration: 4344/10000, Loss: 0.01575133018195629\n",
      "Iteration: 4345/10000, Loss: 0.018363628536462784\n",
      "Iteration: 4346/10000, Loss: 0.021442817524075508\n",
      "Iteration: 4347/10000, Loss: 0.017305977642536163\n",
      "Iteration: 4348/10000, Loss: 0.013755862601101398\n",
      "Iteration: 4349/10000, Loss: 0.012181876227259636\n",
      "Iteration: 4350/10000, Loss: 0.013312273658812046\n",
      "Iteration: 4351/10000, Loss: 0.01541206892579794\n",
      "Iteration: 4352/10000, Loss: 0.014452059753239155\n",
      "Iteration: 4353/10000, Loss: 0.02377989888191223\n",
      "Iteration: 4354/10000, Loss: 0.013159818015992641\n",
      "Iteration: 4355/10000, Loss: 0.016428301110863686\n",
      "Iteration: 4356/10000, Loss: 0.018303731456398964\n",
      "Iteration: 4357/10000, Loss: 0.019848456606268883\n",
      "Iteration: 4358/10000, Loss: 0.011707490310072899\n",
      "Iteration: 4359/10000, Loss: 0.016841350123286247\n",
      "Iteration: 4360/10000, Loss: 0.017306234687566757\n",
      "Iteration: 4361/10000, Loss: 0.02113906294107437\n",
      "Iteration: 4362/10000, Loss: 0.020244764164090157\n",
      "Iteration: 4363/10000, Loss: 0.006220488343387842\n",
      "Iteration: 4364/10000, Loss: 0.014408109709620476\n",
      "Iteration: 4365/10000, Loss: 0.011039904318749905\n",
      "Iteration: 4366/10000, Loss: 0.015684641897678375\n",
      "Iteration: 4367/10000, Loss: 0.013807267881929874\n",
      "Iteration: 4368/10000, Loss: 0.014799564145505428\n",
      "Iteration: 4369/10000, Loss: 0.009968504309654236\n",
      "Iteration: 4370/10000, Loss: 0.014552303589880466\n",
      "Iteration: 4371/10000, Loss: 0.013420640490949154\n",
      "Iteration: 4372/10000, Loss: 0.011426996439695358\n",
      "Iteration: 4373/10000, Loss: 0.020068461075425148\n",
      "Iteration: 4374/10000, Loss: 0.008844668976962566\n",
      "Iteration: 4375/10000, Loss: 0.01319837849587202\n",
      "Iteration: 4376/10000, Loss: 0.015837617218494415\n",
      "Iteration: 4377/10000, Loss: 0.015148603357374668\n",
      "Iteration: 4378/10000, Loss: 0.011862944811582565\n",
      "Iteration: 4379/10000, Loss: 0.013302872888743877\n",
      "Iteration: 4380/10000, Loss: 0.011668057180941105\n",
      "Iteration: 4381/10000, Loss: 0.012837366200983524\n",
      "Iteration: 4382/10000, Loss: 0.008458693511784077\n",
      "Iteration: 4383/10000, Loss: 0.014100114814937115\n",
      "Iteration: 4384/10000, Loss: 0.018880149349570274\n",
      "Iteration: 4385/10000, Loss: 0.01344557199627161\n",
      "Iteration: 4386/10000, Loss: 0.011988048441708088\n",
      "Iteration: 4387/10000, Loss: 0.015365172177553177\n",
      "Iteration: 4388/10000, Loss: 0.016593115404248238\n",
      "Iteration: 4389/10000, Loss: 0.017397120594978333\n",
      "Iteration: 4390/10000, Loss: 0.01215379498898983\n",
      "Iteration: 4391/10000, Loss: 0.014947265386581421\n",
      "Iteration: 4392/10000, Loss: 0.016330817714333534\n",
      "Iteration: 4393/10000, Loss: 0.015850039198994637\n",
      "Iteration: 4394/10000, Loss: 0.017478516325354576\n",
      "Iteration: 4395/10000, Loss: 0.01348838396370411\n",
      "Iteration: 4396/10000, Loss: 0.019410163164138794\n",
      "Iteration: 4397/10000, Loss: 0.02377135120332241\n",
      "Iteration: 4398/10000, Loss: 0.015889300033450127\n",
      "Iteration: 4399/10000, Loss: 0.01365460641682148\n",
      "Iteration: 4400/10000, Loss: 0.014261826872825623\n",
      "Average test loss:  0.0036\n",
      "Iteration: 4401/10000, Loss: 0.015142769552767277\n",
      "Iteration: 4402/10000, Loss: 0.02320927008986473\n",
      "Iteration: 4403/10000, Loss: 0.01443050429224968\n",
      "Iteration: 4404/10000, Loss: 0.02282813936471939\n",
      "Iteration: 4405/10000, Loss: 0.013169798068702221\n",
      "Iteration: 4406/10000, Loss: 0.013015306554734707\n",
      "Iteration: 4407/10000, Loss: 0.014908580109477043\n",
      "Iteration: 4408/10000, Loss: 0.020398087799549103\n",
      "Iteration: 4409/10000, Loss: 0.011895140632987022\n",
      "Iteration: 4410/10000, Loss: 0.017033128067851067\n",
      "Iteration: 4411/10000, Loss: 0.014428745023906231\n",
      "Iteration: 4412/10000, Loss: 0.012817658483982086\n",
      "Iteration: 4413/10000, Loss: 0.009791892021894455\n",
      "Iteration: 4414/10000, Loss: 0.018772829324007034\n",
      "Iteration: 4415/10000, Loss: 0.007188387215137482\n",
      "Iteration: 4416/10000, Loss: 0.01681181788444519\n",
      "Iteration: 4417/10000, Loss: 0.01124174240976572\n",
      "Iteration: 4418/10000, Loss: 0.014883533120155334\n",
      "Iteration: 4419/10000, Loss: 0.01842527650296688\n",
      "Iteration: 4420/10000, Loss: 0.023863660171628\n",
      "Iteration: 4421/10000, Loss: 0.007856661453843117\n",
      "Iteration: 4422/10000, Loss: 0.017482440918684006\n",
      "Iteration: 4423/10000, Loss: 0.013333454728126526\n",
      "Iteration: 4424/10000, Loss: 0.004873496014624834\n",
      "Iteration: 4425/10000, Loss: 0.012546888552606106\n",
      "Iteration: 4426/10000, Loss: 0.017653023824095726\n",
      "Iteration: 4427/10000, Loss: 0.01866881735622883\n",
      "Iteration: 4428/10000, Loss: 0.02264910377562046\n",
      "Iteration: 4429/10000, Loss: 0.016159046441316605\n",
      "Iteration: 4430/10000, Loss: 0.01698695681989193\n",
      "Iteration: 4431/10000, Loss: 0.013220188207924366\n",
      "Iteration: 4432/10000, Loss: 0.010729804635047913\n",
      "Iteration: 4433/10000, Loss: 0.016932014375925064\n",
      "Iteration: 4434/10000, Loss: 0.013037740252912045\n",
      "Iteration: 4435/10000, Loss: 0.013331221416592598\n",
      "Iteration: 4436/10000, Loss: 0.017007796093821526\n",
      "Iteration: 4437/10000, Loss: 0.009241480380296707\n",
      "Iteration: 4438/10000, Loss: 0.009973746724426746\n",
      "Iteration: 4439/10000, Loss: 0.02576417289674282\n",
      "Iteration: 4440/10000, Loss: 0.014661512337625027\n",
      "Iteration: 4441/10000, Loss: 0.01396031491458416\n",
      "Iteration: 4442/10000, Loss: 0.019533997401595116\n",
      "Iteration: 4443/10000, Loss: 0.014364051632583141\n",
      "Iteration: 4444/10000, Loss: 0.020013807341456413\n",
      "Iteration: 4445/10000, Loss: 0.015420272946357727\n",
      "Iteration: 4446/10000, Loss: 0.012636297382414341\n",
      "Iteration: 4447/10000, Loss: 0.016322938725352287\n",
      "Iteration: 4448/10000, Loss: 0.013728063553571701\n",
      "Iteration: 4449/10000, Loss: 0.015196451917290688\n",
      "Iteration: 4450/10000, Loss: 0.014256362803280354\n",
      "Iteration: 4451/10000, Loss: 0.014063545502722263\n",
      "Iteration: 4452/10000, Loss: 0.017275068908929825\n",
      "Iteration: 4453/10000, Loss: 0.021669762209057808\n",
      "Iteration: 4454/10000, Loss: 0.01449549663811922\n",
      "Iteration: 4455/10000, Loss: 0.012190270237624645\n",
      "Iteration: 4456/10000, Loss: 0.013364243321120739\n",
      "Iteration: 4457/10000, Loss: 0.01716664992272854\n",
      "Iteration: 4458/10000, Loss: 0.015414153225719929\n",
      "Iteration: 4459/10000, Loss: 0.013498266227543354\n",
      "Iteration: 4460/10000, Loss: 0.02037697844207287\n",
      "Iteration: 4461/10000, Loss: 0.013214698992669582\n",
      "Iteration: 4462/10000, Loss: 0.014857890084385872\n",
      "Iteration: 4463/10000, Loss: 0.017038535326719284\n",
      "Iteration: 4464/10000, Loss: 0.016244154423475266\n",
      "Iteration: 4465/10000, Loss: 0.012812932021915913\n",
      "Iteration: 4466/10000, Loss: 0.018029306083917618\n",
      "Iteration: 4467/10000, Loss: 0.016257334500551224\n",
      "Iteration: 4468/10000, Loss: 0.012039508670568466\n",
      "Iteration: 4469/10000, Loss: 0.014985543675720692\n",
      "Iteration: 4470/10000, Loss: 0.018935788422822952\n",
      "Iteration: 4471/10000, Loss: 0.014510435983538628\n",
      "Iteration: 4472/10000, Loss: 0.011979980394244194\n",
      "Iteration: 4473/10000, Loss: 0.016587989404797554\n",
      "Iteration: 4474/10000, Loss: 0.013738071545958519\n",
      "Iteration: 4475/10000, Loss: 0.015945948660373688\n",
      "Iteration: 4476/10000, Loss: 0.015519652515649796\n",
      "Iteration: 4477/10000, Loss: 0.01612856797873974\n",
      "Iteration: 4478/10000, Loss: 0.019661059603095055\n",
      "Iteration: 4479/10000, Loss: 0.014071062207221985\n",
      "Iteration: 4480/10000, Loss: 0.013357028365135193\n",
      "Iteration: 4481/10000, Loss: 0.015924321487545967\n",
      "Iteration: 4482/10000, Loss: 0.02312769554555416\n",
      "Iteration: 4483/10000, Loss: 0.01700592413544655\n",
      "Iteration: 4484/10000, Loss: 0.019000407308340073\n",
      "Iteration: 4485/10000, Loss: 0.013620616868138313\n",
      "Iteration: 4486/10000, Loss: 0.020451867952942848\n",
      "Iteration: 4487/10000, Loss: 0.009319636039435863\n",
      "Iteration: 4488/10000, Loss: 0.015122530981898308\n",
      "Iteration: 4489/10000, Loss: 0.013399988412857056\n",
      "Iteration: 4490/10000, Loss: 0.02577824331820011\n",
      "Iteration: 4491/10000, Loss: 0.00992489606142044\n",
      "Iteration: 4492/10000, Loss: 0.017993316054344177\n",
      "Iteration: 4493/10000, Loss: 0.018849588930606842\n",
      "Iteration: 4494/10000, Loss: 0.018506420776247978\n",
      "Iteration: 4495/10000, Loss: 0.014354219660162926\n",
      "Iteration: 4496/10000, Loss: 0.010244841687381268\n",
      "Iteration: 4497/10000, Loss: 0.02017396315932274\n",
      "Iteration: 4498/10000, Loss: 0.013030873611569405\n",
      "Iteration: 4499/10000, Loss: 0.01853175275027752\n",
      "Iteration: 4500/10000, Loss: 0.013224061578512192\n",
      "Average test loss:  0.0024\n",
      "Iteration: 4501/10000, Loss: 0.017320452257990837\n",
      "Iteration: 4502/10000, Loss: 0.011553771793842316\n",
      "Iteration: 4503/10000, Loss: 0.018521223217248917\n",
      "Iteration: 4504/10000, Loss: 0.010883014649152756\n",
      "Iteration: 4505/10000, Loss: 0.017006494104862213\n",
      "Iteration: 4506/10000, Loss: 0.015605499036610126\n",
      "Iteration: 4507/10000, Loss: 0.019991977140307426\n",
      "Iteration: 4508/10000, Loss: 0.01897958107292652\n",
      "Iteration: 4509/10000, Loss: 0.014854894950985909\n",
      "Iteration: 4510/10000, Loss: 0.017619896680116653\n",
      "Iteration: 4511/10000, Loss: 0.01651727966964245\n",
      "Iteration: 4512/10000, Loss: 0.02239319123327732\n",
      "Iteration: 4513/10000, Loss: 0.011324464343488216\n",
      "Iteration: 4514/10000, Loss: 0.011057158932089806\n",
      "Iteration: 4515/10000, Loss: 0.013101808726787567\n",
      "Iteration: 4516/10000, Loss: 0.00857979990541935\n",
      "Iteration: 4517/10000, Loss: 0.018041078001260757\n",
      "Iteration: 4518/10000, Loss: 0.010543513111770153\n",
      "Iteration: 4519/10000, Loss: 0.017609061673283577\n",
      "Iteration: 4520/10000, Loss: 0.017108989879488945\n",
      "Iteration: 4521/10000, Loss: 0.016486894339323044\n",
      "Iteration: 4522/10000, Loss: 0.011403913609683514\n",
      "Iteration: 4523/10000, Loss: 0.012795732356607914\n",
      "Iteration: 4524/10000, Loss: 0.015065286308526993\n",
      "Iteration: 4525/10000, Loss: 0.01595071516931057\n",
      "Iteration: 4526/10000, Loss: 0.016904911026358604\n",
      "Iteration: 4527/10000, Loss: 0.010726614855229855\n",
      "Iteration: 4528/10000, Loss: 0.014610925689339638\n",
      "Iteration: 4529/10000, Loss: 0.006334152538329363\n",
      "Iteration: 4530/10000, Loss: 0.010507620871067047\n",
      "Iteration: 4531/10000, Loss: 0.022507084533572197\n",
      "Iteration: 4532/10000, Loss: 0.013508484698832035\n",
      "Iteration: 4533/10000, Loss: 0.015525010414421558\n",
      "Iteration: 4534/10000, Loss: 0.01192173920571804\n",
      "Iteration: 4535/10000, Loss: 0.017628388479351997\n",
      "Iteration: 4536/10000, Loss: 0.018963048234581947\n",
      "Iteration: 4537/10000, Loss: 0.009721845388412476\n",
      "Iteration: 4538/10000, Loss: 0.012947166338562965\n",
      "Iteration: 4539/10000, Loss: 0.012953139841556549\n",
      "Iteration: 4540/10000, Loss: 0.011005248874425888\n",
      "Iteration: 4541/10000, Loss: 0.014061668887734413\n",
      "Iteration: 4542/10000, Loss: 0.010172422043979168\n",
      "Iteration: 4543/10000, Loss: 0.014551082625985146\n",
      "Iteration: 4544/10000, Loss: 0.02271737903356552\n",
      "Iteration: 4545/10000, Loss: 0.009305352345108986\n",
      "Iteration: 4546/10000, Loss: 0.011876819655299187\n",
      "Iteration: 4547/10000, Loss: 0.013512128964066505\n",
      "Iteration: 4548/10000, Loss: 0.022944921627640724\n",
      "Iteration: 4549/10000, Loss: 0.012990918010473251\n",
      "Iteration: 4550/10000, Loss: 0.011807475239038467\n",
      "Iteration: 4551/10000, Loss: 0.012886237353086472\n",
      "Iteration: 4552/10000, Loss: 0.019100286066532135\n",
      "Iteration: 4553/10000, Loss: 0.018819918856024742\n",
      "Iteration: 4554/10000, Loss: 0.01310797780752182\n",
      "Iteration: 4555/10000, Loss: 0.018009580671787262\n",
      "Iteration: 4556/10000, Loss: 0.012959024868905544\n",
      "Iteration: 4557/10000, Loss: 0.016425734385848045\n",
      "Iteration: 4558/10000, Loss: 0.012732992880046368\n",
      "Iteration: 4559/10000, Loss: 0.015006747096776962\n",
      "Iteration: 4560/10000, Loss: 0.011323553510010242\n",
      "Iteration: 4561/10000, Loss: 0.020606517791748047\n",
      "Iteration: 4562/10000, Loss: 0.021031226962804794\n",
      "Iteration: 4563/10000, Loss: 0.010374254547059536\n",
      "Iteration: 4564/10000, Loss: 0.012131298892199993\n",
      "Iteration: 4565/10000, Loss: 0.015641693025827408\n",
      "Iteration: 4566/10000, Loss: 0.014641724526882172\n",
      "Iteration: 4567/10000, Loss: 0.011021503247320652\n",
      "Iteration: 4568/10000, Loss: 0.01895158737897873\n",
      "Iteration: 4569/10000, Loss: 0.009345386177301407\n",
      "Iteration: 4570/10000, Loss: 0.013515619561076164\n",
      "Iteration: 4571/10000, Loss: 0.012958996929228306\n",
      "Iteration: 4572/10000, Loss: 0.01135692186653614\n",
      "Iteration: 4573/10000, Loss: 0.011532105505466461\n",
      "Iteration: 4574/10000, Loss: 0.014915421605110168\n",
      "Iteration: 4575/10000, Loss: 0.019633417949080467\n",
      "Iteration: 4576/10000, Loss: 0.014919441193342209\n",
      "Iteration: 4577/10000, Loss: 0.012817679904401302\n",
      "Iteration: 4578/10000, Loss: 0.014970563352108002\n",
      "Iteration: 4579/10000, Loss: 0.026669904589653015\n",
      "Iteration: 4580/10000, Loss: 0.01149298157542944\n",
      "Iteration: 4581/10000, Loss: 0.018816834315657616\n",
      "Iteration: 4582/10000, Loss: 0.0129685178399086\n",
      "Iteration: 4583/10000, Loss: 0.010726450011134148\n",
      "Iteration: 4584/10000, Loss: 0.011658431962132454\n",
      "Iteration: 4585/10000, Loss: 0.007364935707300901\n",
      "Iteration: 4586/10000, Loss: 0.010731963440775871\n",
      "Iteration: 4587/10000, Loss: 0.014121449552476406\n",
      "Iteration: 4588/10000, Loss: 0.016860779374837875\n",
      "Iteration: 4589/10000, Loss: 0.014190959744155407\n",
      "Iteration: 4590/10000, Loss: 0.018417757004499435\n",
      "Iteration: 4591/10000, Loss: 0.01585012674331665\n",
      "Iteration: 4592/10000, Loss: 0.013244756497442722\n",
      "Iteration: 4593/10000, Loss: 0.01509415078908205\n",
      "Iteration: 4594/10000, Loss: 0.01612008921802044\n",
      "Iteration: 4595/10000, Loss: 0.015143942087888718\n",
      "Iteration: 4596/10000, Loss: 0.012130613438785076\n",
      "Iteration: 4597/10000, Loss: 0.014605020172894001\n",
      "Iteration: 4598/10000, Loss: 0.016562972217798233\n",
      "Iteration: 4599/10000, Loss: 0.013176163658499718\n",
      "Iteration: 4600/10000, Loss: 0.0261672530323267\n",
      "Average test loss:  0.0024\n",
      "Iteration: 4601/10000, Loss: 0.013743149116635323\n",
      "Iteration: 4602/10000, Loss: 0.013012898154556751\n",
      "Iteration: 4603/10000, Loss: 0.01722576841711998\n",
      "Iteration: 4604/10000, Loss: 0.020346008241176605\n",
      "Iteration: 4605/10000, Loss: 0.008346213027834892\n",
      "Iteration: 4606/10000, Loss: 0.016843624413013458\n",
      "Iteration: 4607/10000, Loss: 0.015554573386907578\n",
      "Iteration: 4608/10000, Loss: 0.011221794411540031\n",
      "Iteration: 4609/10000, Loss: 0.009926043450832367\n",
      "Iteration: 4610/10000, Loss: 0.013273783959448338\n",
      "Iteration: 4611/10000, Loss: 0.016478344798088074\n",
      "Iteration: 4612/10000, Loss: 0.01987936720252037\n",
      "Iteration: 4613/10000, Loss: 0.014668067917227745\n",
      "Iteration: 4614/10000, Loss: 0.020165886729955673\n",
      "Iteration: 4615/10000, Loss: 0.01385494414716959\n",
      "Iteration: 4616/10000, Loss: 0.01637415401637554\n",
      "Iteration: 4617/10000, Loss: 0.01620360277593136\n",
      "Iteration: 4618/10000, Loss: 0.01747453212738037\n",
      "Iteration: 4619/10000, Loss: 0.012869797646999359\n",
      "Iteration: 4620/10000, Loss: 0.013927880674600601\n",
      "Iteration: 4621/10000, Loss: 0.013798355124890804\n",
      "Iteration: 4622/10000, Loss: 0.012365804985165596\n",
      "Iteration: 4623/10000, Loss: 0.020742667838931084\n",
      "Iteration: 4624/10000, Loss: 0.02529762126505375\n",
      "Iteration: 4625/10000, Loss: 0.012473232112824917\n",
      "Iteration: 4626/10000, Loss: 0.011430212296545506\n",
      "Iteration: 4627/10000, Loss: 0.01979888044297695\n",
      "Iteration: 4628/10000, Loss: 0.02032201550900936\n",
      "Iteration: 4629/10000, Loss: 0.015306401066482067\n",
      "Iteration: 4630/10000, Loss: 0.019883230328559875\n",
      "Iteration: 4631/10000, Loss: 0.015583853237330914\n",
      "Iteration: 4632/10000, Loss: 0.012355087324976921\n",
      "Iteration: 4633/10000, Loss: 0.012674533762037754\n",
      "Iteration: 4634/10000, Loss: 0.01701267994940281\n",
      "Iteration: 4635/10000, Loss: 0.012460876256227493\n",
      "Iteration: 4636/10000, Loss: 0.01991697959601879\n",
      "Iteration: 4637/10000, Loss: 0.008390270173549652\n",
      "Iteration: 4638/10000, Loss: 0.015660561621189117\n",
      "Iteration: 4639/10000, Loss: 0.01884368620812893\n",
      "Iteration: 4640/10000, Loss: 0.01980571262538433\n",
      "Iteration: 4641/10000, Loss: 0.01919454336166382\n",
      "Iteration: 4642/10000, Loss: 0.013695391826331615\n",
      "Iteration: 4643/10000, Loss: 0.014864260330796242\n",
      "Iteration: 4644/10000, Loss: 0.01491704024374485\n",
      "Iteration: 4645/10000, Loss: 0.017664704471826553\n",
      "Iteration: 4646/10000, Loss: 0.0106589887291193\n",
      "Iteration: 4647/10000, Loss: 0.02623908407986164\n",
      "Iteration: 4648/10000, Loss: 0.014789586886763573\n",
      "Iteration: 4649/10000, Loss: 0.009929018095135689\n",
      "Iteration: 4650/10000, Loss: 0.011135113425552845\n",
      "Iteration: 4651/10000, Loss: 0.01176072470843792\n",
      "Iteration: 4652/10000, Loss: 0.009878633543848991\n",
      "Iteration: 4653/10000, Loss: 0.00952273141592741\n",
      "Iteration: 4654/10000, Loss: 0.01079922541975975\n",
      "Iteration: 4655/10000, Loss: 0.012521444819867611\n",
      "Iteration: 4656/10000, Loss: 0.01427396759390831\n",
      "Iteration: 4657/10000, Loss: 0.015372847206890583\n",
      "Iteration: 4658/10000, Loss: 0.00842010136693716\n",
      "Iteration: 4659/10000, Loss: 0.014507925137877464\n",
      "Iteration: 4660/10000, Loss: 0.022071998566389084\n",
      "Iteration: 4661/10000, Loss: 0.014494622126221657\n",
      "Iteration: 4662/10000, Loss: 0.014756391756236553\n",
      "Iteration: 4663/10000, Loss: 0.010493144392967224\n",
      "Iteration: 4664/10000, Loss: 0.015692953020334244\n",
      "Iteration: 4665/10000, Loss: 0.02040824666619301\n",
      "Iteration: 4666/10000, Loss: 0.014490552246570587\n",
      "Iteration: 4667/10000, Loss: 0.016985246911644936\n",
      "Iteration: 4668/10000, Loss: 0.014956886880099773\n",
      "Iteration: 4669/10000, Loss: 0.012131906114518642\n",
      "Iteration: 4670/10000, Loss: 0.016740400344133377\n",
      "Iteration: 4671/10000, Loss: 0.02502470277249813\n",
      "Iteration: 4672/10000, Loss: 0.009311345405876637\n",
      "Iteration: 4673/10000, Loss: 0.015568488277494907\n",
      "Iteration: 4674/10000, Loss: 0.014402391389012337\n",
      "Iteration: 4675/10000, Loss: 0.02164788916707039\n",
      "Iteration: 4676/10000, Loss: 0.018189283087849617\n",
      "Iteration: 4677/10000, Loss: 0.01536568347364664\n",
      "Iteration: 4678/10000, Loss: 0.01537032425403595\n",
      "Iteration: 4679/10000, Loss: 0.011533954180777073\n",
      "Iteration: 4680/10000, Loss: 0.018246209248900414\n",
      "Iteration: 4681/10000, Loss: 0.01594504341483116\n",
      "Iteration: 4682/10000, Loss: 0.013106814585626125\n",
      "Iteration: 4683/10000, Loss: 0.01278334017843008\n",
      "Iteration: 4684/10000, Loss: 0.016789069399237633\n",
      "Iteration: 4685/10000, Loss: 0.007020957302302122\n",
      "Iteration: 4686/10000, Loss: 0.014710898511111736\n",
      "Iteration: 4687/10000, Loss: 0.017205234616994858\n",
      "Iteration: 4688/10000, Loss: 0.012774779461324215\n",
      "Iteration: 4689/10000, Loss: 0.012546117417514324\n",
      "Iteration: 4690/10000, Loss: 0.015377001836895943\n",
      "Iteration: 4691/10000, Loss: 0.008389244787395\n",
      "Iteration: 4692/10000, Loss: 0.013916263356804848\n",
      "Iteration: 4693/10000, Loss: 0.011321830563247204\n",
      "Iteration: 4694/10000, Loss: 0.014131305739283562\n",
      "Iteration: 4695/10000, Loss: 0.016678612679243088\n",
      "Iteration: 4696/10000, Loss: 0.009950532577931881\n",
      "Iteration: 4697/10000, Loss: 0.014615228399634361\n",
      "Iteration: 4698/10000, Loss: 0.014941588044166565\n",
      "Iteration: 4699/10000, Loss: 0.008962346240878105\n",
      "Iteration: 4700/10000, Loss: 0.011012556031346321\n",
      "Average test loss:  0.0032\n",
      "Iteration: 4701/10000, Loss: 0.017139755189418793\n",
      "Iteration: 4702/10000, Loss: 0.011120693758130074\n",
      "Iteration: 4703/10000, Loss: 0.010140201076865196\n",
      "Iteration: 4704/10000, Loss: 0.013517211191356182\n",
      "Iteration: 4705/10000, Loss: 0.016066083684563637\n",
      "Iteration: 4706/10000, Loss: 0.019082821905612946\n",
      "Iteration: 4707/10000, Loss: 0.009031550958752632\n",
      "Iteration: 4708/10000, Loss: 0.010058715008199215\n",
      "Iteration: 4709/10000, Loss: 0.01692367158830166\n",
      "Iteration: 4710/10000, Loss: 0.013111395761370659\n",
      "Iteration: 4711/10000, Loss: 0.011593366041779518\n",
      "Iteration: 4712/10000, Loss: 0.013662673532962799\n",
      "Iteration: 4713/10000, Loss: 0.01684318296611309\n",
      "Iteration: 4714/10000, Loss: 0.013498680666089058\n",
      "Iteration: 4715/10000, Loss: 0.01158296037465334\n",
      "Iteration: 4716/10000, Loss: 0.014541348442435265\n",
      "Iteration: 4717/10000, Loss: 0.022184204310178757\n",
      "Iteration: 4718/10000, Loss: 0.017786012962460518\n",
      "Iteration: 4719/10000, Loss: 0.016748154535889626\n",
      "Iteration: 4720/10000, Loss: 0.016597578302025795\n",
      "Iteration: 4721/10000, Loss: 0.008811329491436481\n",
      "Iteration: 4722/10000, Loss: 0.0155049879103899\n",
      "Iteration: 4723/10000, Loss: 0.012789062224328518\n",
      "Iteration: 4724/10000, Loss: 0.01410159282386303\n",
      "Iteration: 4725/10000, Loss: 0.011521199718117714\n",
      "Iteration: 4726/10000, Loss: 0.007901297882199287\n",
      "Iteration: 4727/10000, Loss: 0.015558567829430103\n",
      "Iteration: 4728/10000, Loss: 0.01032214518636465\n",
      "Iteration: 4729/10000, Loss: 0.011135208420455456\n",
      "Iteration: 4730/10000, Loss: 0.016286570578813553\n",
      "Iteration: 4731/10000, Loss: 0.014037326909601688\n",
      "Iteration: 4732/10000, Loss: 0.013286375440657139\n",
      "Iteration: 4733/10000, Loss: 0.014652404002845287\n",
      "Iteration: 4734/10000, Loss: 0.01573837362229824\n",
      "Iteration: 4735/10000, Loss: 0.013907583430409431\n",
      "Iteration: 4736/10000, Loss: 0.010658923536539078\n",
      "Iteration: 4737/10000, Loss: 0.017596036195755005\n",
      "Iteration: 4738/10000, Loss: 0.01650317758321762\n",
      "Iteration: 4739/10000, Loss: 0.008316751569509506\n",
      "Iteration: 4740/10000, Loss: 0.01971467211842537\n",
      "Iteration: 4741/10000, Loss: 0.014163612388074398\n",
      "Iteration: 4742/10000, Loss: 0.012976797297596931\n",
      "Iteration: 4743/10000, Loss: 0.014991319738328457\n",
      "Iteration: 4744/10000, Loss: 0.023302603513002396\n",
      "Iteration: 4745/10000, Loss: 0.014669147320091724\n",
      "Iteration: 4746/10000, Loss: 0.014066963456571102\n",
      "Iteration: 4747/10000, Loss: 0.010423876345157623\n",
      "Iteration: 4748/10000, Loss: 0.010661168955266476\n",
      "Iteration: 4749/10000, Loss: 0.008496543392539024\n",
      "Iteration: 4750/10000, Loss: 0.013247514143586159\n",
      "Iteration: 4751/10000, Loss: 0.01270463690161705\n",
      "Iteration: 4752/10000, Loss: 0.01689930260181427\n",
      "Iteration: 4753/10000, Loss: 0.014921634458005428\n",
      "Iteration: 4754/10000, Loss: 0.0174732469022274\n",
      "Iteration: 4755/10000, Loss: 0.01579582691192627\n",
      "Iteration: 4756/10000, Loss: 0.011335483752191067\n",
      "Iteration: 4757/10000, Loss: 0.014500643126666546\n",
      "Iteration: 4758/10000, Loss: 0.014860991388559341\n",
      "Iteration: 4759/10000, Loss: 0.018451524898409843\n",
      "Iteration: 4760/10000, Loss: 0.014744398184120655\n",
      "Iteration: 4761/10000, Loss: 0.012347553856670856\n",
      "Iteration: 4762/10000, Loss: 0.012017042376101017\n",
      "Iteration: 4763/10000, Loss: 0.014472407288849354\n",
      "Iteration: 4764/10000, Loss: 0.017256755381822586\n",
      "Iteration: 4765/10000, Loss: 0.014091821387410164\n",
      "Iteration: 4766/10000, Loss: 0.009475122205913067\n",
      "Iteration: 4767/10000, Loss: 0.011373721994459629\n",
      "Iteration: 4768/10000, Loss: 0.011046788655221462\n",
      "Iteration: 4769/10000, Loss: 0.011013956740498543\n",
      "Iteration: 4770/10000, Loss: 0.02324317954480648\n",
      "Iteration: 4771/10000, Loss: 0.012072061188519001\n",
      "Iteration: 4772/10000, Loss: 0.016013246029615402\n",
      "Iteration: 4773/10000, Loss: 0.009409230202436447\n",
      "Iteration: 4774/10000, Loss: 0.00952304806560278\n",
      "Iteration: 4775/10000, Loss: 0.015119077637791634\n",
      "Iteration: 4776/10000, Loss: 0.016665643081068993\n",
      "Iteration: 4777/10000, Loss: 0.01796901226043701\n",
      "Iteration: 4778/10000, Loss: 0.01568002812564373\n",
      "Iteration: 4779/10000, Loss: 0.014264347031712532\n",
      "Iteration: 4780/10000, Loss: 0.01301771029829979\n",
      "Iteration: 4781/10000, Loss: 0.01020110584795475\n",
      "Iteration: 4782/10000, Loss: 0.013696732930839062\n",
      "Iteration: 4783/10000, Loss: 0.009560639970004559\n",
      "Iteration: 4784/10000, Loss: 0.015662873163819313\n",
      "Iteration: 4785/10000, Loss: 0.01176869310438633\n",
      "Iteration: 4786/10000, Loss: 0.01658640243113041\n",
      "Iteration: 4787/10000, Loss: 0.016858089715242386\n",
      "Iteration: 4788/10000, Loss: 0.012036574073135853\n",
      "Iteration: 4789/10000, Loss: 0.01321813277900219\n",
      "Iteration: 4790/10000, Loss: 0.009049410000443459\n",
      "Iteration: 4791/10000, Loss: 0.01238608080893755\n",
      "Iteration: 4792/10000, Loss: 0.01244470663368702\n",
      "Iteration: 4793/10000, Loss: 0.01536033395677805\n",
      "Iteration: 4794/10000, Loss: 0.011640717275440693\n",
      "Iteration: 4795/10000, Loss: 0.01563221774995327\n",
      "Iteration: 4796/10000, Loss: 0.022691769525408745\n",
      "Iteration: 4797/10000, Loss: 0.012089981697499752\n",
      "Iteration: 4798/10000, Loss: 0.016605453565716743\n",
      "Iteration: 4799/10000, Loss: 0.01587369479238987\n",
      "Iteration: 4800/10000, Loss: 0.014294058084487915\n",
      "Average test loss:  0.0026\n",
      "Iteration: 4801/10000, Loss: 0.01958203688263893\n",
      "Iteration: 4802/10000, Loss: 0.016552239656448364\n",
      "Iteration: 4803/10000, Loss: 0.013368981890380383\n",
      "Iteration: 4804/10000, Loss: 0.013951674103736877\n",
      "Iteration: 4805/10000, Loss: 0.016118504106998444\n",
      "Iteration: 4806/10000, Loss: 0.01419813185930252\n",
      "Iteration: 4807/10000, Loss: 0.012929576449096203\n",
      "Iteration: 4808/10000, Loss: 0.016048898920416832\n",
      "Iteration: 4809/10000, Loss: 0.011176316998898983\n",
      "Iteration: 4810/10000, Loss: 0.014317553490400314\n",
      "Iteration: 4811/10000, Loss: 0.01616588421165943\n",
      "Iteration: 4812/10000, Loss: 0.015428009442985058\n",
      "Iteration: 4813/10000, Loss: 0.012231488712131977\n",
      "Iteration: 4814/10000, Loss: 0.009581834077835083\n",
      "Iteration: 4815/10000, Loss: 0.01605645939707756\n",
      "Iteration: 4816/10000, Loss: 0.01983955316245556\n",
      "Iteration: 4817/10000, Loss: 0.018289638683199883\n",
      "Iteration: 4818/10000, Loss: 0.015025479719042778\n",
      "Iteration: 4819/10000, Loss: 0.012140112929046154\n",
      "Iteration: 4820/10000, Loss: 0.020134516060352325\n",
      "Iteration: 4821/10000, Loss: 0.018482312560081482\n",
      "Iteration: 4822/10000, Loss: 0.012539828196167946\n",
      "Iteration: 4823/10000, Loss: 0.014546527527272701\n",
      "Iteration: 4824/10000, Loss: 0.016194049268960953\n",
      "Iteration: 4825/10000, Loss: 0.012813808396458626\n",
      "Iteration: 4826/10000, Loss: 0.014473890885710716\n",
      "Iteration: 4827/10000, Loss: 0.01863115094602108\n",
      "Iteration: 4828/10000, Loss: 0.011489542201161385\n",
      "Iteration: 4829/10000, Loss: 0.010661435313522816\n",
      "Iteration: 4830/10000, Loss: 0.01039913110435009\n",
      "Iteration: 4831/10000, Loss: 0.01066741906106472\n",
      "Iteration: 4832/10000, Loss: 0.01707199029624462\n",
      "Iteration: 4833/10000, Loss: 0.014012735337018967\n",
      "Iteration: 4834/10000, Loss: 0.010718119330704212\n",
      "Iteration: 4835/10000, Loss: 0.01563437096774578\n",
      "Iteration: 4836/10000, Loss: 0.012266838923096657\n",
      "Iteration: 4837/10000, Loss: 0.009705464355647564\n",
      "Iteration: 4838/10000, Loss: 0.010908832773566246\n",
      "Iteration: 4839/10000, Loss: 0.011724678799510002\n",
      "Iteration: 4840/10000, Loss: 0.012707935646176338\n",
      "Iteration: 4841/10000, Loss: 0.01608310639858246\n",
      "Iteration: 4842/10000, Loss: 0.011090382933616638\n",
      "Iteration: 4843/10000, Loss: 0.019215933978557587\n",
      "Iteration: 4844/10000, Loss: 0.016630012542009354\n",
      "Iteration: 4845/10000, Loss: 0.012595217674970627\n",
      "Iteration: 4846/10000, Loss: 0.017544738948345184\n",
      "Iteration: 4847/10000, Loss: 0.012142937630414963\n",
      "Iteration: 4848/10000, Loss: 0.016585690900683403\n",
      "Iteration: 4849/10000, Loss: 0.018217718228697777\n",
      "Iteration: 4850/10000, Loss: 0.010754340328276157\n",
      "Iteration: 4851/10000, Loss: 0.013921168632805347\n",
      "Iteration: 4852/10000, Loss: 0.016658607870340347\n",
      "Iteration: 4853/10000, Loss: 0.012073268182575703\n",
      "Iteration: 4854/10000, Loss: 0.01567753031849861\n",
      "Iteration: 4855/10000, Loss: 0.015573396347463131\n",
      "Iteration: 4856/10000, Loss: 0.017367135733366013\n",
      "Iteration: 4857/10000, Loss: 0.0172880869358778\n",
      "Iteration: 4858/10000, Loss: 0.008341369219124317\n",
      "Iteration: 4859/10000, Loss: 0.012518780305981636\n",
      "Iteration: 4860/10000, Loss: 0.016975698992609978\n",
      "Iteration: 4861/10000, Loss: 0.01254271250218153\n",
      "Iteration: 4862/10000, Loss: 0.009033793583512306\n",
      "Iteration: 4863/10000, Loss: 0.008520863018929958\n",
      "Iteration: 4864/10000, Loss: 0.014645651914179325\n",
      "Iteration: 4865/10000, Loss: 0.012610388919711113\n",
      "Iteration: 4866/10000, Loss: 0.016951104626059532\n",
      "Iteration: 4867/10000, Loss: 0.014286505058407784\n",
      "Iteration: 4868/10000, Loss: 0.014959292486310005\n",
      "Iteration: 4869/10000, Loss: 0.018135080114006996\n",
      "Iteration: 4870/10000, Loss: 0.007968515157699585\n",
      "Iteration: 4871/10000, Loss: 0.01747998222708702\n",
      "Iteration: 4872/10000, Loss: 0.01244537252932787\n",
      "Iteration: 4873/10000, Loss: 0.019287321716547012\n",
      "Iteration: 4874/10000, Loss: 0.01157414261251688\n",
      "Iteration: 4875/10000, Loss: 0.009694061242043972\n",
      "Iteration: 4876/10000, Loss: 0.018016383051872253\n",
      "Iteration: 4877/10000, Loss: 0.014138874597847462\n",
      "Iteration: 4878/10000, Loss: 0.013856800273060799\n",
      "Iteration: 4879/10000, Loss: 0.014350897632539272\n",
      "Iteration: 4880/10000, Loss: 0.017586514353752136\n",
      "Iteration: 4881/10000, Loss: 0.01171022653579712\n",
      "Iteration: 4882/10000, Loss: 0.012694074772298336\n",
      "Iteration: 4883/10000, Loss: 0.014577588066458702\n",
      "Iteration: 4884/10000, Loss: 0.017734026536345482\n",
      "Iteration: 4885/10000, Loss: 0.01296086423099041\n",
      "Iteration: 4886/10000, Loss: 0.013750635087490082\n",
      "Iteration: 4887/10000, Loss: 0.010237234644591808\n",
      "Iteration: 4888/10000, Loss: 0.012935898266732693\n",
      "Iteration: 4889/10000, Loss: 0.013844307512044907\n",
      "Iteration: 4890/10000, Loss: 0.02051636576652527\n",
      "Iteration: 4891/10000, Loss: 0.013761620037257671\n",
      "Iteration: 4892/10000, Loss: 0.024793483316898346\n",
      "Iteration: 4893/10000, Loss: 0.0116726728156209\n",
      "Iteration: 4894/10000, Loss: 0.015866989269852638\n",
      "Iteration: 4895/10000, Loss: 0.011772274039685726\n",
      "Iteration: 4896/10000, Loss: 0.013168759644031525\n",
      "Iteration: 4897/10000, Loss: 0.010269160382449627\n",
      "Iteration: 4898/10000, Loss: 0.012033328413963318\n",
      "Iteration: 4899/10000, Loss: 0.013398248702287674\n",
      "Iteration: 4900/10000, Loss: 0.015250831842422485\n",
      "Average test loss:  0.0012\n",
      "Iteration: 4901/10000, Loss: 0.012853030115365982\n",
      "Iteration: 4902/10000, Loss: 0.015505731105804443\n",
      "Iteration: 4903/10000, Loss: 0.018187785521149635\n",
      "Iteration: 4904/10000, Loss: 0.012908048927783966\n",
      "Iteration: 4905/10000, Loss: 0.011984250508248806\n",
      "Iteration: 4906/10000, Loss: 0.018777018412947655\n",
      "Iteration: 4907/10000, Loss: 0.009505382739007473\n",
      "Iteration: 4908/10000, Loss: 0.008765753358602524\n",
      "Iteration: 4909/10000, Loss: 0.020584776997566223\n",
      "Iteration: 4910/10000, Loss: 0.013687925413250923\n",
      "Iteration: 4911/10000, Loss: 0.01164508517831564\n",
      "Iteration: 4912/10000, Loss: 0.006715747062116861\n",
      "Iteration: 4913/10000, Loss: 0.012395071797072887\n",
      "Iteration: 4914/10000, Loss: 0.011613313108682632\n",
      "Iteration: 4915/10000, Loss: 0.012739419005811214\n",
      "Iteration: 4916/10000, Loss: 0.018277054652571678\n",
      "Iteration: 4917/10000, Loss: 0.012725002132356167\n",
      "Iteration: 4918/10000, Loss: 0.025205109268426895\n",
      "Iteration: 4919/10000, Loss: 0.01548145990818739\n",
      "Iteration: 4920/10000, Loss: 0.017712559551000595\n",
      "Iteration: 4921/10000, Loss: 0.014661439694464207\n",
      "Iteration: 4922/10000, Loss: 0.009770801290869713\n",
      "Iteration: 4923/10000, Loss: 0.007921110838651657\n",
      "Iteration: 4924/10000, Loss: 0.017751233652234077\n",
      "Iteration: 4925/10000, Loss: 0.01162880752235651\n",
      "Iteration: 4926/10000, Loss: 0.01381737645715475\n",
      "Iteration: 4927/10000, Loss: 0.012083044275641441\n",
      "Iteration: 4928/10000, Loss: 0.009351973421871662\n",
      "Iteration: 4929/10000, Loss: 0.00911079440265894\n",
      "Iteration: 4930/10000, Loss: 0.011477191001176834\n",
      "Iteration: 4931/10000, Loss: 0.022186405956745148\n",
      "Iteration: 4932/10000, Loss: 0.013121705502271652\n",
      "Iteration: 4933/10000, Loss: 0.020838996395468712\n",
      "Iteration: 4934/10000, Loss: 0.009935131296515465\n",
      "Iteration: 4935/10000, Loss: 0.015813538804650307\n",
      "Iteration: 4936/10000, Loss: 0.02014961838722229\n",
      "Iteration: 4937/10000, Loss: 0.013410358689725399\n",
      "Iteration: 4938/10000, Loss: 0.014134570956230164\n",
      "Iteration: 4939/10000, Loss: 0.018676260486245155\n",
      "Iteration: 4940/10000, Loss: 0.015684261918067932\n",
      "Iteration: 4941/10000, Loss: 0.014269220642745495\n",
      "Iteration: 4942/10000, Loss: 0.014660317450761795\n",
      "Iteration: 4943/10000, Loss: 0.016242293640971184\n",
      "Iteration: 4944/10000, Loss: 0.01477434579282999\n",
      "Iteration: 4945/10000, Loss: 0.012902346439659595\n",
      "Iteration: 4946/10000, Loss: 0.013590466231107712\n",
      "Iteration: 4947/10000, Loss: 0.017309272661805153\n",
      "Iteration: 4948/10000, Loss: 0.013696652837097645\n",
      "Iteration: 4949/10000, Loss: 0.01661982387304306\n",
      "Iteration: 4950/10000, Loss: 0.013600344769656658\n",
      "Iteration: 4951/10000, Loss: 0.01170650776475668\n",
      "Iteration: 4952/10000, Loss: 0.010024046525359154\n",
      "Iteration: 4953/10000, Loss: 0.014530972577631474\n",
      "Iteration: 4954/10000, Loss: 0.011345967650413513\n",
      "Iteration: 4955/10000, Loss: 0.012172441929578781\n",
      "Iteration: 4956/10000, Loss: 0.01780305989086628\n",
      "Iteration: 4957/10000, Loss: 0.013612386770546436\n",
      "Iteration: 4958/10000, Loss: 0.011123591102659702\n",
      "Iteration: 4959/10000, Loss: 0.012555651366710663\n",
      "Iteration: 4960/10000, Loss: 0.018303172662854195\n",
      "Iteration: 4961/10000, Loss: 0.012476668693125248\n",
      "Iteration: 4962/10000, Loss: 0.012190673500299454\n",
      "Iteration: 4963/10000, Loss: 0.019400043413043022\n",
      "Iteration: 4964/10000, Loss: 0.0160968117415905\n",
      "Iteration: 4965/10000, Loss: 0.014411569572985172\n",
      "Iteration: 4966/10000, Loss: 0.017680073156952858\n",
      "Iteration: 4967/10000, Loss: 0.01942913420498371\n",
      "Iteration: 4968/10000, Loss: 0.019624998793005943\n",
      "Iteration: 4969/10000, Loss: 0.013754126615822315\n",
      "Iteration: 4970/10000, Loss: 0.020407378673553467\n",
      "Iteration: 4971/10000, Loss: 0.014348977245390415\n",
      "Iteration: 4972/10000, Loss: 0.015841836109757423\n",
      "Iteration: 4973/10000, Loss: 0.017534250393509865\n",
      "Iteration: 4974/10000, Loss: 0.013197146356105804\n",
      "Iteration: 4975/10000, Loss: 0.012078285217285156\n",
      "Iteration: 4976/10000, Loss: 0.016270611435174942\n",
      "Iteration: 4977/10000, Loss: 0.014385722577571869\n",
      "Iteration: 4978/10000, Loss: 0.019206058233976364\n",
      "Iteration: 4979/10000, Loss: 0.018631698563694954\n",
      "Iteration: 4980/10000, Loss: 0.010935639962553978\n",
      "Iteration: 4981/10000, Loss: 0.016546450555324554\n",
      "Iteration: 4982/10000, Loss: 0.012898803688585758\n",
      "Iteration: 4983/10000, Loss: 0.013041614554822445\n",
      "Iteration: 4984/10000, Loss: 0.009883931837975979\n",
      "Iteration: 4985/10000, Loss: 0.014631850644946098\n",
      "Iteration: 4986/10000, Loss: 0.014263486489653587\n",
      "Iteration: 4987/10000, Loss: 0.008197535760700703\n",
      "Iteration: 4988/10000, Loss: 0.010822897776961327\n",
      "Iteration: 4989/10000, Loss: 0.010643566027283669\n",
      "Iteration: 4990/10000, Loss: 0.013341711834073067\n",
      "Iteration: 4991/10000, Loss: 0.011752476915717125\n",
      "Iteration: 4992/10000, Loss: 0.01339581236243248\n",
      "Iteration: 4993/10000, Loss: 0.01564045622944832\n",
      "Iteration: 4994/10000, Loss: 0.008737703785300255\n",
      "Iteration: 4995/10000, Loss: 0.014280375093221664\n",
      "Iteration: 4996/10000, Loss: 0.010980293154716492\n",
      "Iteration: 4997/10000, Loss: 0.01430271565914154\n",
      "Iteration: 4998/10000, Loss: 0.014416216872632504\n",
      "Iteration: 4999/10000, Loss: 0.017479030415415764\n",
      "Iteration: 5000/10000, Loss: 0.014294684864580631\n",
      "Average test loss:  0.0037\n",
      "Iteration: 5001/10000, Loss: 0.013592688366770744\n",
      "Iteration: 5002/10000, Loss: 0.013971582986414433\n",
      "Iteration: 5003/10000, Loss: 0.017620857805013657\n",
      "Iteration: 5004/10000, Loss: 0.009515303187072277\n",
      "Iteration: 5005/10000, Loss: 0.011243684217333794\n",
      "Iteration: 5006/10000, Loss: 0.01139887236058712\n",
      "Iteration: 5007/10000, Loss: 0.019377371296286583\n",
      "Iteration: 5008/10000, Loss: 0.010945099405944347\n",
      "Iteration: 5009/10000, Loss: 0.015865430235862732\n",
      "Iteration: 5010/10000, Loss: 0.01267073955386877\n",
      "Iteration: 5011/10000, Loss: 0.01684531755745411\n",
      "Iteration: 5012/10000, Loss: 0.013879233039915562\n",
      "Iteration: 5013/10000, Loss: 0.009133424609899521\n",
      "Iteration: 5014/10000, Loss: 0.010883062146604061\n",
      "Iteration: 5015/10000, Loss: 0.009030070155858994\n",
      "Iteration: 5016/10000, Loss: 0.016822123900055885\n",
      "Iteration: 5017/10000, Loss: 0.014218820258975029\n",
      "Iteration: 5018/10000, Loss: 0.01382470689713955\n",
      "Iteration: 5019/10000, Loss: 0.0121905617415905\n",
      "Iteration: 5020/10000, Loss: 0.016596341505646706\n",
      "Iteration: 5021/10000, Loss: 0.009752882644534111\n",
      "Iteration: 5022/10000, Loss: 0.01188275869935751\n",
      "Iteration: 5023/10000, Loss: 0.015202687121927738\n",
      "Iteration: 5024/10000, Loss: 0.015059031546115875\n",
      "Iteration: 5025/10000, Loss: 0.014266304671764374\n",
      "Iteration: 5026/10000, Loss: 0.016483331099152565\n",
      "Iteration: 5027/10000, Loss: 0.015221425332129002\n",
      "Iteration: 5028/10000, Loss: 0.013154433108866215\n",
      "Iteration: 5029/10000, Loss: 0.02082342840731144\n",
      "Iteration: 5030/10000, Loss: 0.015608026646077633\n",
      "Iteration: 5031/10000, Loss: 0.01660199463367462\n",
      "Iteration: 5032/10000, Loss: 0.014363333582878113\n",
      "Iteration: 5033/10000, Loss: 0.009728910401463509\n",
      "Iteration: 5034/10000, Loss: 0.015261529944837093\n",
      "Iteration: 5035/10000, Loss: 0.01129655446857214\n",
      "Iteration: 5036/10000, Loss: 0.00764293409883976\n",
      "Iteration: 5037/10000, Loss: 0.01157889049500227\n",
      "Iteration: 5038/10000, Loss: 0.014385168440639973\n",
      "Iteration: 5039/10000, Loss: 0.012429906986653805\n",
      "Iteration: 5040/10000, Loss: 0.01635645143687725\n",
      "Iteration: 5041/10000, Loss: 0.012538679875433445\n",
      "Iteration: 5042/10000, Loss: 0.012090270407497883\n",
      "Iteration: 5043/10000, Loss: 0.013834022916853428\n",
      "Iteration: 5044/10000, Loss: 0.016550077125430107\n",
      "Iteration: 5045/10000, Loss: 0.012230731546878815\n",
      "Iteration: 5046/10000, Loss: 0.01052803173661232\n",
      "Iteration: 5047/10000, Loss: 0.01092593651264906\n",
      "Iteration: 5048/10000, Loss: 0.013529223389923573\n",
      "Iteration: 5049/10000, Loss: 0.019421106204390526\n",
      "Iteration: 5050/10000, Loss: 0.021524813026189804\n",
      "Iteration: 5051/10000, Loss: 0.012074803002178669\n",
      "Iteration: 5052/10000, Loss: 0.017149757593870163\n",
      "Iteration: 5053/10000, Loss: 0.01181974820792675\n",
      "Iteration: 5054/10000, Loss: 0.011454188264906406\n",
      "Iteration: 5055/10000, Loss: 0.019895466044545174\n",
      "Iteration: 5056/10000, Loss: 0.01095852255821228\n",
      "Iteration: 5057/10000, Loss: 0.015301837585866451\n",
      "Iteration: 5058/10000, Loss: 0.01545424573123455\n",
      "Iteration: 5059/10000, Loss: 0.014401941560208797\n",
      "Iteration: 5060/10000, Loss: 0.012629021890461445\n",
      "Iteration: 5061/10000, Loss: 0.014250573702156544\n",
      "Iteration: 5062/10000, Loss: 0.013822019100189209\n",
      "Iteration: 5063/10000, Loss: 0.015327421016991138\n",
      "Iteration: 5064/10000, Loss: 0.012899977155029774\n",
      "Iteration: 5065/10000, Loss: 0.012125421315431595\n",
      "Iteration: 5066/10000, Loss: 0.011365456506609917\n",
      "Iteration: 5067/10000, Loss: 0.013855031691491604\n",
      "Iteration: 5068/10000, Loss: 0.01679833233356476\n",
      "Iteration: 5069/10000, Loss: 0.009362933225929737\n",
      "Iteration: 5070/10000, Loss: 0.011309863068163395\n",
      "Iteration: 5071/10000, Loss: 0.01254693791270256\n",
      "Iteration: 5072/10000, Loss: 0.011372127570211887\n",
      "Iteration: 5073/10000, Loss: 0.010313732549548149\n",
      "Iteration: 5074/10000, Loss: 0.011463889852166176\n",
      "Iteration: 5075/10000, Loss: 0.015110578387975693\n",
      "Iteration: 5076/10000, Loss: 0.0162807684391737\n",
      "Iteration: 5077/10000, Loss: 0.01304975338280201\n",
      "Iteration: 5078/10000, Loss: 0.021262044087052345\n",
      "Iteration: 5079/10000, Loss: 0.013298352248966694\n",
      "Iteration: 5080/10000, Loss: 0.01278938539326191\n",
      "Iteration: 5081/10000, Loss: 0.014454915188252926\n",
      "Iteration: 5082/10000, Loss: 0.012813792563974857\n",
      "Iteration: 5083/10000, Loss: 0.023716548457741737\n",
      "Iteration: 5084/10000, Loss: 0.014532637782394886\n",
      "Iteration: 5085/10000, Loss: 0.007433140184730291\n",
      "Iteration: 5086/10000, Loss: 0.012195231392979622\n",
      "Iteration: 5087/10000, Loss: 0.013291559182107449\n",
      "Iteration: 5088/10000, Loss: 0.014297831803560257\n",
      "Iteration: 5089/10000, Loss: 0.011418139562010765\n",
      "Iteration: 5090/10000, Loss: 0.017203284427523613\n",
      "Iteration: 5091/10000, Loss: 0.013325836509466171\n",
      "Iteration: 5092/10000, Loss: 0.006897846702486277\n",
      "Iteration: 5093/10000, Loss: 0.019190970808267593\n",
      "Iteration: 5094/10000, Loss: 0.013092588633298874\n",
      "Iteration: 5095/10000, Loss: 0.008379868231713772\n",
      "Iteration: 5096/10000, Loss: 0.014555691741406918\n",
      "Iteration: 5097/10000, Loss: 0.018210839480161667\n",
      "Iteration: 5098/10000, Loss: 0.01840837113559246\n",
      "Iteration: 5099/10000, Loss: 0.015799660235643387\n",
      "Iteration: 5100/10000, Loss: 0.014039311558008194\n",
      "Average test loss:  0.0032\n",
      "Iteration: 5101/10000, Loss: 0.01535850204527378\n",
      "Iteration: 5102/10000, Loss: 0.011103148572146893\n",
      "Iteration: 5103/10000, Loss: 0.01085690502077341\n",
      "Iteration: 5104/10000, Loss: 0.009902101010084152\n",
      "Iteration: 5105/10000, Loss: 0.015327767468988895\n",
      "Iteration: 5106/10000, Loss: 0.019958755001425743\n",
      "Iteration: 5107/10000, Loss: 0.01660565286874771\n",
      "Iteration: 5108/10000, Loss: 0.01041981391608715\n",
      "Iteration: 5109/10000, Loss: 0.008035775274038315\n",
      "Iteration: 5110/10000, Loss: 0.011433468200266361\n",
      "Iteration: 5111/10000, Loss: 0.013039038516581059\n",
      "Iteration: 5112/10000, Loss: 0.015571747906506062\n",
      "Iteration: 5113/10000, Loss: 0.009422719478607178\n",
      "Iteration: 5114/10000, Loss: 0.02091962844133377\n",
      "Iteration: 5115/10000, Loss: 0.00812606792896986\n",
      "Iteration: 5116/10000, Loss: 0.010650101117789745\n",
      "Iteration: 5117/10000, Loss: 0.019159119576215744\n",
      "Iteration: 5118/10000, Loss: 0.012546534650027752\n",
      "Iteration: 5119/10000, Loss: 0.009664323180913925\n",
      "Iteration: 5120/10000, Loss: 0.01096891425549984\n",
      "Iteration: 5121/10000, Loss: 0.015529803931713104\n",
      "Iteration: 5122/10000, Loss: 0.012889675796031952\n",
      "Iteration: 5123/10000, Loss: 0.01059135515242815\n",
      "Iteration: 5124/10000, Loss: 0.013368544168770313\n",
      "Iteration: 5125/10000, Loss: 0.013508557341992855\n",
      "Iteration: 5126/10000, Loss: 0.008004543371498585\n",
      "Iteration: 5127/10000, Loss: 0.009936300106346607\n",
      "Iteration: 5128/10000, Loss: 0.013812354765832424\n",
      "Iteration: 5129/10000, Loss: 0.015775855630636215\n",
      "Iteration: 5130/10000, Loss: 0.01015143096446991\n",
      "Iteration: 5131/10000, Loss: 0.012107293121516705\n",
      "Iteration: 5132/10000, Loss: 0.011399170383810997\n",
      "Iteration: 5133/10000, Loss: 0.011668020859360695\n",
      "Iteration: 5134/10000, Loss: 0.014420827850699425\n",
      "Iteration: 5135/10000, Loss: 0.017995420843362808\n",
      "Iteration: 5136/10000, Loss: 0.02137303538620472\n",
      "Iteration: 5137/10000, Loss: 0.009397616609930992\n",
      "Iteration: 5138/10000, Loss: 0.010181001387536526\n",
      "Iteration: 5139/10000, Loss: 0.011985807679593563\n",
      "Iteration: 5140/10000, Loss: 0.01265739742666483\n",
      "Iteration: 5141/10000, Loss: 0.014210893772542477\n",
      "Iteration: 5142/10000, Loss: 0.010595210827887058\n",
      "Iteration: 5143/10000, Loss: 0.01523797120898962\n",
      "Iteration: 5144/10000, Loss: 0.012904807925224304\n",
      "Iteration: 5145/10000, Loss: 0.021897152066230774\n",
      "Iteration: 5146/10000, Loss: 0.01953829452395439\n",
      "Iteration: 5147/10000, Loss: 0.0085302060469985\n",
      "Iteration: 5148/10000, Loss: 0.014814374037086964\n",
      "Iteration: 5149/10000, Loss: 0.014925102703273296\n",
      "Iteration: 5150/10000, Loss: 0.011922343634068966\n",
      "Iteration: 5151/10000, Loss: 0.016238108277320862\n",
      "Iteration: 5152/10000, Loss: 0.01247649546712637\n",
      "Iteration: 5153/10000, Loss: 0.01297434139996767\n",
      "Iteration: 5154/10000, Loss: 0.008629266172647476\n",
      "Iteration: 5155/10000, Loss: 0.021769694983959198\n",
      "Iteration: 5156/10000, Loss: 0.0129330363124609\n",
      "Iteration: 5157/10000, Loss: 0.011362960562109947\n",
      "Iteration: 5158/10000, Loss: 0.018321549519896507\n",
      "Iteration: 5159/10000, Loss: 0.010431211441755295\n",
      "Iteration: 5160/10000, Loss: 0.014917274005711079\n",
      "Iteration: 5161/10000, Loss: 0.01567789725959301\n",
      "Iteration: 5162/10000, Loss: 0.016691943630576134\n",
      "Iteration: 5163/10000, Loss: 0.015590955503284931\n",
      "Iteration: 5164/10000, Loss: 0.014044246636331081\n",
      "Iteration: 5165/10000, Loss: 0.015401509590446949\n",
      "Iteration: 5166/10000, Loss: 0.01685882918536663\n",
      "Iteration: 5167/10000, Loss: 0.01323237456381321\n",
      "Iteration: 5168/10000, Loss: 0.00816372036933899\n",
      "Iteration: 5169/10000, Loss: 0.011879741214215755\n",
      "Iteration: 5170/10000, Loss: 0.009529021568596363\n",
      "Iteration: 5171/10000, Loss: 0.014431112445890903\n",
      "Iteration: 5172/10000, Loss: 0.011627488769590855\n",
      "Iteration: 5173/10000, Loss: 0.01090194284915924\n",
      "Iteration: 5174/10000, Loss: 0.015812033787369728\n",
      "Iteration: 5175/10000, Loss: 0.017601879313588142\n",
      "Iteration: 5176/10000, Loss: 0.012824728153645992\n",
      "Iteration: 5177/10000, Loss: 0.006298915017396212\n",
      "Iteration: 5178/10000, Loss: 0.018001960590481758\n",
      "Iteration: 5179/10000, Loss: 0.015383364632725716\n",
      "Iteration: 5180/10000, Loss: 0.011923536658287048\n",
      "Iteration: 5181/10000, Loss: 0.01458191592246294\n",
      "Iteration: 5182/10000, Loss: 0.011691157706081867\n",
      "Iteration: 5183/10000, Loss: 0.009720946662127972\n",
      "Iteration: 5184/10000, Loss: 0.013393357396125793\n",
      "Iteration: 5185/10000, Loss: 0.011126580648124218\n",
      "Iteration: 5186/10000, Loss: 0.016681475564837456\n",
      "Iteration: 5187/10000, Loss: 0.011426974087953568\n",
      "Iteration: 5188/10000, Loss: 0.008930577896535397\n",
      "Iteration: 5189/10000, Loss: 0.013654949143528938\n",
      "Iteration: 5190/10000, Loss: 0.018593499436974525\n",
      "Iteration: 5191/10000, Loss: 0.00837900023907423\n",
      "Iteration: 5192/10000, Loss: 0.008497141301631927\n",
      "Iteration: 5193/10000, Loss: 0.012530386447906494\n",
      "Iteration: 5194/10000, Loss: 0.007678528316318989\n",
      "Iteration: 5195/10000, Loss: 0.017441218718886375\n",
      "Iteration: 5196/10000, Loss: 0.011089596897363663\n",
      "Iteration: 5197/10000, Loss: 0.012130791321396828\n",
      "Iteration: 5198/10000, Loss: 0.01740674488246441\n",
      "Iteration: 5199/10000, Loss: 0.014752651564776897\n",
      "Iteration: 5200/10000, Loss: 0.014700023457407951\n",
      "Average test loss:  0.0014\n",
      "Iteration: 5201/10000, Loss: 0.011153641156852245\n",
      "Iteration: 5202/10000, Loss: 0.019535109400749207\n",
      "Iteration: 5203/10000, Loss: 0.019703799858689308\n",
      "Iteration: 5204/10000, Loss: 0.008309027180075645\n",
      "Iteration: 5205/10000, Loss: 0.018710032105445862\n",
      "Iteration: 5206/10000, Loss: 0.01372102927416563\n",
      "Iteration: 5207/10000, Loss: 0.013100086711347103\n",
      "Iteration: 5208/10000, Loss: 0.014746940694749355\n",
      "Iteration: 5209/10000, Loss: 0.010989020578563213\n",
      "Iteration: 5210/10000, Loss: 0.009694951586425304\n",
      "Iteration: 5211/10000, Loss: 0.0187703687697649\n",
      "Iteration: 5212/10000, Loss: 0.016028355807065964\n",
      "Iteration: 5213/10000, Loss: 0.018350869417190552\n",
      "Iteration: 5214/10000, Loss: 0.0171187911182642\n",
      "Iteration: 5215/10000, Loss: 0.012401212006807327\n",
      "Iteration: 5216/10000, Loss: 0.012097025290131569\n",
      "Iteration: 5217/10000, Loss: 0.014198767021298409\n",
      "Iteration: 5218/10000, Loss: 0.011552020907402039\n",
      "Iteration: 5219/10000, Loss: 0.020172933116555214\n",
      "Iteration: 5220/10000, Loss: 0.014323168434202671\n",
      "Iteration: 5221/10000, Loss: 0.013188086450099945\n",
      "Iteration: 5222/10000, Loss: 0.010872257873415947\n",
      "Iteration: 5223/10000, Loss: 0.014038505963981152\n",
      "Iteration: 5224/10000, Loss: 0.014518997631967068\n",
      "Iteration: 5225/10000, Loss: 0.010927603580057621\n",
      "Iteration: 5226/10000, Loss: 0.010975020006299019\n",
      "Iteration: 5227/10000, Loss: 0.02091500163078308\n",
      "Iteration: 5228/10000, Loss: 0.012269175611436367\n",
      "Iteration: 5229/10000, Loss: 0.011876976117491722\n",
      "Iteration: 5230/10000, Loss: 0.012452191673219204\n",
      "Iteration: 5231/10000, Loss: 0.018583832308650017\n",
      "Iteration: 5232/10000, Loss: 0.010793522000312805\n",
      "Iteration: 5233/10000, Loss: 0.01972881145775318\n",
      "Iteration: 5234/10000, Loss: 0.014060094021260738\n",
      "Iteration: 5235/10000, Loss: 0.015505789779126644\n",
      "Iteration: 5236/10000, Loss: 0.015581185929477215\n",
      "Iteration: 5237/10000, Loss: 0.013612354174256325\n",
      "Iteration: 5238/10000, Loss: 0.012653100304305553\n",
      "Iteration: 5239/10000, Loss: 0.013286760076880455\n",
      "Iteration: 5240/10000, Loss: 0.012007338926196098\n",
      "Iteration: 5241/10000, Loss: 0.015856768935918808\n",
      "Iteration: 5242/10000, Loss: 0.009436005726456642\n",
      "Iteration: 5243/10000, Loss: 0.012637699022889137\n",
      "Iteration: 5244/10000, Loss: 0.00975011382251978\n",
      "Iteration: 5245/10000, Loss: 0.012755610048770905\n",
      "Iteration: 5246/10000, Loss: 0.02314862608909607\n",
      "Iteration: 5247/10000, Loss: 0.011127814650535583\n",
      "Iteration: 5248/10000, Loss: 0.009702793322503567\n",
      "Iteration: 5249/10000, Loss: 0.009638144634664059\n",
      "Iteration: 5250/10000, Loss: 0.008401436731219292\n",
      "Iteration: 5251/10000, Loss: 0.012795363552868366\n",
      "Iteration: 5252/10000, Loss: 0.01727660372853279\n",
      "Iteration: 5253/10000, Loss: 0.015629688277840614\n",
      "Iteration: 5254/10000, Loss: 0.017914628610014915\n",
      "Iteration: 5255/10000, Loss: 0.016324736177921295\n",
      "Iteration: 5256/10000, Loss: 0.013745955191552639\n",
      "Iteration: 5257/10000, Loss: 0.01850050315260887\n",
      "Iteration: 5258/10000, Loss: 0.01381114311516285\n",
      "Iteration: 5259/10000, Loss: 0.009296348318457603\n",
      "Iteration: 5260/10000, Loss: 0.012491188012063503\n",
      "Iteration: 5261/10000, Loss: 0.010084595531225204\n",
      "Iteration: 5262/10000, Loss: 0.0075224218890070915\n",
      "Iteration: 5263/10000, Loss: 0.0178768839687109\n",
      "Iteration: 5264/10000, Loss: 0.012883695773780346\n",
      "Iteration: 5265/10000, Loss: 0.013579756021499634\n",
      "Iteration: 5266/10000, Loss: 0.015528169460594654\n",
      "Iteration: 5267/10000, Loss: 0.01710989885032177\n",
      "Iteration: 5268/10000, Loss: 0.012373607605695724\n",
      "Iteration: 5269/10000, Loss: 0.014745642431080341\n",
      "Iteration: 5270/10000, Loss: 0.011092983186244965\n",
      "Iteration: 5271/10000, Loss: 0.008137953467667103\n",
      "Iteration: 5272/10000, Loss: 0.01422362495213747\n",
      "Iteration: 5273/10000, Loss: 0.0073434580117464066\n",
      "Iteration: 5274/10000, Loss: 0.012365205213427544\n",
      "Iteration: 5275/10000, Loss: 0.013717359863221645\n",
      "Iteration: 5276/10000, Loss: 0.012034367769956589\n",
      "Iteration: 5277/10000, Loss: 0.01083232183009386\n",
      "Iteration: 5278/10000, Loss: 0.018141532316803932\n",
      "Iteration: 5279/10000, Loss: 0.010318390093743801\n",
      "Iteration: 5280/10000, Loss: 0.012944160960614681\n",
      "Iteration: 5281/10000, Loss: 0.016771409660577774\n",
      "Iteration: 5282/10000, Loss: 0.009008062072098255\n",
      "Iteration: 5283/10000, Loss: 0.013036626391112804\n",
      "Iteration: 5284/10000, Loss: 0.014213060028851032\n",
      "Iteration: 5285/10000, Loss: 0.016242146492004395\n",
      "Iteration: 5286/10000, Loss: 0.01878195069730282\n",
      "Iteration: 5287/10000, Loss: 0.019872494041919708\n",
      "Iteration: 5288/10000, Loss: 0.013928382657468319\n",
      "Iteration: 5289/10000, Loss: 0.017286010086536407\n",
      "Iteration: 5290/10000, Loss: 0.008484242483973503\n",
      "Iteration: 5291/10000, Loss: 0.01007478404790163\n",
      "Iteration: 5292/10000, Loss: 0.014174935407936573\n",
      "Iteration: 5293/10000, Loss: 0.011628495529294014\n",
      "Iteration: 5294/10000, Loss: 0.019062012434005737\n",
      "Iteration: 5295/10000, Loss: 0.006913476157933474\n",
      "Iteration: 5296/10000, Loss: 0.015466611832380295\n",
      "Iteration: 5297/10000, Loss: 0.012514542788267136\n",
      "Iteration: 5298/10000, Loss: 0.01132359728217125\n",
      "Iteration: 5299/10000, Loss: 0.019503602758049965\n",
      "Iteration: 5300/10000, Loss: 0.007441909052431583\n",
      "Average test loss:  0.0039\n",
      "Iteration: 5301/10000, Loss: 0.018966995179653168\n",
      "Iteration: 5302/10000, Loss: 0.01174201350659132\n",
      "Iteration: 5303/10000, Loss: 0.0158688984811306\n",
      "Iteration: 5304/10000, Loss: 0.013376102782785892\n",
      "Iteration: 5305/10000, Loss: 0.010975437238812447\n",
      "Iteration: 5306/10000, Loss: 0.015464660711586475\n",
      "Iteration: 5307/10000, Loss: 0.017831427976489067\n",
      "Iteration: 5308/10000, Loss: 0.01209296751767397\n",
      "Iteration: 5309/10000, Loss: 0.014887082390487194\n",
      "Iteration: 5310/10000, Loss: 0.011800152249634266\n",
      "Iteration: 5311/10000, Loss: 0.013150151818990707\n",
      "Iteration: 5312/10000, Loss: 0.014108906500041485\n",
      "Iteration: 5313/10000, Loss: 0.005939476657658815\n",
      "Iteration: 5314/10000, Loss: 0.01221082266420126\n",
      "Iteration: 5315/10000, Loss: 0.014863152988255024\n",
      "Iteration: 5316/10000, Loss: 0.015598282217979431\n",
      "Iteration: 5317/10000, Loss: 0.018348902463912964\n",
      "Iteration: 5318/10000, Loss: 0.010366429574787617\n",
      "Iteration: 5319/10000, Loss: 0.01531201507896185\n",
      "Iteration: 5320/10000, Loss: 0.018399883061647415\n",
      "Iteration: 5321/10000, Loss: 0.010948771610856056\n",
      "Iteration: 5322/10000, Loss: 0.012778013944625854\n",
      "Iteration: 5323/10000, Loss: 0.014469671063125134\n",
      "Iteration: 5324/10000, Loss: 0.011120248585939407\n",
      "Iteration: 5325/10000, Loss: 0.0120153296738863\n",
      "Iteration: 5326/10000, Loss: 0.01136273518204689\n",
      "Iteration: 5327/10000, Loss: 0.015447556972503662\n",
      "Iteration: 5328/10000, Loss: 0.01868976093828678\n",
      "Iteration: 5329/10000, Loss: 0.009146449156105518\n",
      "Iteration: 5330/10000, Loss: 0.011937794275581837\n",
      "Iteration: 5331/10000, Loss: 0.0121544124558568\n",
      "Iteration: 5332/10000, Loss: 0.016992351040244102\n",
      "Iteration: 5333/10000, Loss: 0.006774991750717163\n",
      "Iteration: 5334/10000, Loss: 0.011673643253743649\n",
      "Iteration: 5335/10000, Loss: 0.01887940801680088\n",
      "Iteration: 5336/10000, Loss: 0.019001401960849762\n",
      "Iteration: 5337/10000, Loss: 0.010095445439219475\n",
      "Iteration: 5338/10000, Loss: 0.012112653814256191\n",
      "Iteration: 5339/10000, Loss: 0.01612919010221958\n",
      "Iteration: 5340/10000, Loss: 0.015241029672324657\n",
      "Iteration: 5341/10000, Loss: 0.014290085062384605\n",
      "Iteration: 5342/10000, Loss: 0.01310012862086296\n",
      "Iteration: 5343/10000, Loss: 0.010105581022799015\n",
      "Iteration: 5344/10000, Loss: 0.019929327070713043\n",
      "Iteration: 5345/10000, Loss: 0.009175746701657772\n",
      "Iteration: 5346/10000, Loss: 0.009385938756167889\n",
      "Iteration: 5347/10000, Loss: 0.009981658309698105\n",
      "Iteration: 5348/10000, Loss: 0.016099724918603897\n",
      "Iteration: 5349/10000, Loss: 0.010952592827379704\n",
      "Iteration: 5350/10000, Loss: 0.02330469712615013\n",
      "Iteration: 5351/10000, Loss: 0.01588273048400879\n",
      "Iteration: 5352/10000, Loss: 0.014133613556623459\n",
      "Iteration: 5353/10000, Loss: 0.019141843542456627\n",
      "Iteration: 5354/10000, Loss: 0.015000540763139725\n",
      "Iteration: 5355/10000, Loss: 0.014315717853605747\n",
      "Iteration: 5356/10000, Loss: 0.013957223854959011\n",
      "Iteration: 5357/10000, Loss: 0.017738794907927513\n",
      "Iteration: 5358/10000, Loss: 0.01496932003647089\n",
      "Iteration: 5359/10000, Loss: 0.017368804663419724\n",
      "Iteration: 5360/10000, Loss: 0.01008203811943531\n",
      "Iteration: 5361/10000, Loss: 0.014288408681750298\n",
      "Iteration: 5362/10000, Loss: 0.014037215150892735\n",
      "Iteration: 5363/10000, Loss: 0.013718651607632637\n",
      "Iteration: 5364/10000, Loss: 0.02046983130276203\n",
      "Iteration: 5365/10000, Loss: 0.019526949152350426\n",
      "Iteration: 5366/10000, Loss: 0.01435182336717844\n",
      "Iteration: 5367/10000, Loss: 0.00977443065494299\n",
      "Iteration: 5368/10000, Loss: 0.017067207023501396\n",
      "Iteration: 5369/10000, Loss: 0.015601320192217827\n",
      "Iteration: 5370/10000, Loss: 0.013650626875460148\n",
      "Iteration: 5371/10000, Loss: 0.019801510497927666\n",
      "Iteration: 5372/10000, Loss: 0.014916650019586086\n",
      "Iteration: 5373/10000, Loss: 0.012668272480368614\n",
      "Iteration: 5374/10000, Loss: 0.010740036144852638\n",
      "Iteration: 5375/10000, Loss: 0.00810141023248434\n",
      "Iteration: 5376/10000, Loss: 0.01525301393121481\n",
      "Iteration: 5377/10000, Loss: 0.011739375069737434\n",
      "Iteration: 5378/10000, Loss: 0.01095357071608305\n",
      "Iteration: 5379/10000, Loss: 0.010529912076890469\n",
      "Iteration: 5380/10000, Loss: 0.009702906012535095\n",
      "Iteration: 5381/10000, Loss: 0.02055511623620987\n",
      "Iteration: 5382/10000, Loss: 0.007250671740621328\n",
      "Iteration: 5383/10000, Loss: 0.009111901745200157\n",
      "Iteration: 5384/10000, Loss: 0.019324926659464836\n",
      "Iteration: 5385/10000, Loss: 0.015107085928320885\n",
      "Iteration: 5386/10000, Loss: 0.014952515251934528\n",
      "Iteration: 5387/10000, Loss: 0.01422059629112482\n",
      "Iteration: 5388/10000, Loss: 0.019854318350553513\n",
      "Iteration: 5389/10000, Loss: 0.008760777302086353\n",
      "Iteration: 5390/10000, Loss: 0.010985661298036575\n",
      "Iteration: 5391/10000, Loss: 0.027053389698266983\n",
      "Iteration: 5392/10000, Loss: 0.012920591980218887\n",
      "Iteration: 5393/10000, Loss: 0.012701318599283695\n",
      "Iteration: 5394/10000, Loss: 0.012058736756443977\n",
      "Iteration: 5395/10000, Loss: 0.02098730206489563\n",
      "Iteration: 5396/10000, Loss: 0.01001979224383831\n",
      "Iteration: 5397/10000, Loss: 0.012793883681297302\n",
      "Iteration: 5398/10000, Loss: 0.008893542923033237\n",
      "Iteration: 5399/10000, Loss: 0.01786179654300213\n",
      "Iteration: 5400/10000, Loss: 0.017581382766366005\n",
      "Average test loss:  0.0021\n",
      "Iteration: 5401/10000, Loss: 0.013509510084986687\n",
      "Iteration: 5402/10000, Loss: 0.011768367141485214\n",
      "Iteration: 5403/10000, Loss: 0.00877376738935709\n",
      "Iteration: 5404/10000, Loss: 0.010922761633992195\n",
      "Iteration: 5405/10000, Loss: 0.012921161949634552\n",
      "Iteration: 5406/10000, Loss: 0.010943450033664703\n",
      "Iteration: 5407/10000, Loss: 0.018224887549877167\n",
      "Iteration: 5408/10000, Loss: 0.01082237996160984\n",
      "Iteration: 5409/10000, Loss: 0.014416296035051346\n",
      "Iteration: 5410/10000, Loss: 0.013304241932928562\n",
      "Iteration: 5411/10000, Loss: 0.016912216320633888\n",
      "Iteration: 5412/10000, Loss: 0.018340246751904488\n",
      "Iteration: 5413/10000, Loss: 0.010573161765933037\n",
      "Iteration: 5414/10000, Loss: 0.01403916347771883\n",
      "Iteration: 5415/10000, Loss: 0.01900610141456127\n",
      "Iteration: 5416/10000, Loss: 0.012092875316739082\n",
      "Iteration: 5417/10000, Loss: 0.01876881904900074\n",
      "Iteration: 5418/10000, Loss: 0.009610568173229694\n",
      "Iteration: 5419/10000, Loss: 0.009102264419198036\n",
      "Iteration: 5420/10000, Loss: 0.018063386902213097\n",
      "Iteration: 5421/10000, Loss: 0.013520261272788048\n",
      "Iteration: 5422/10000, Loss: 0.011274842545390129\n",
      "Iteration: 5423/10000, Loss: 0.012302094139158726\n",
      "Iteration: 5424/10000, Loss: 0.014293265528976917\n",
      "Iteration: 5425/10000, Loss: 0.014390071853995323\n",
      "Iteration: 5426/10000, Loss: 0.013656278140842915\n",
      "Iteration: 5427/10000, Loss: 0.015108184888958931\n",
      "Iteration: 5428/10000, Loss: 0.01173720508813858\n",
      "Iteration: 5429/10000, Loss: 0.014741805382072926\n",
      "Iteration: 5430/10000, Loss: 0.01204961258918047\n",
      "Iteration: 5431/10000, Loss: 0.016930827870965004\n",
      "Iteration: 5432/10000, Loss: 0.009700505994260311\n",
      "Iteration: 5433/10000, Loss: 0.015100415796041489\n",
      "Iteration: 5434/10000, Loss: 0.018491286784410477\n",
      "Iteration: 5435/10000, Loss: 0.01179888192564249\n",
      "Iteration: 5436/10000, Loss: 0.02055211365222931\n",
      "Iteration: 5437/10000, Loss: 0.015643799677491188\n",
      "Iteration: 5438/10000, Loss: 0.010077047161757946\n",
      "Iteration: 5439/10000, Loss: 0.011505542322993279\n",
      "Iteration: 5440/10000, Loss: 0.011853022500872612\n",
      "Iteration: 5441/10000, Loss: 0.01745637319982052\n",
      "Iteration: 5442/10000, Loss: 0.01833486743271351\n",
      "Iteration: 5443/10000, Loss: 0.012065046466886997\n",
      "Iteration: 5444/10000, Loss: 0.012759734876453876\n",
      "Iteration: 5445/10000, Loss: 0.0138454744592309\n",
      "Iteration: 5446/10000, Loss: 0.014754393137991428\n",
      "Iteration: 5447/10000, Loss: 0.0049565983936190605\n",
      "Iteration: 5448/10000, Loss: 0.00769122876226902\n",
      "Iteration: 5449/10000, Loss: 0.013452650047838688\n",
      "Iteration: 5450/10000, Loss: 0.011314143426716328\n",
      "Iteration: 5451/10000, Loss: 0.013521700166165829\n",
      "Iteration: 5452/10000, Loss: 0.012573162093758583\n",
      "Iteration: 5453/10000, Loss: 0.01256511826068163\n",
      "Iteration: 5454/10000, Loss: 0.010951351374387741\n",
      "Iteration: 5455/10000, Loss: 0.007217953447252512\n",
      "Iteration: 5456/10000, Loss: 0.013790671713650227\n",
      "Iteration: 5457/10000, Loss: 0.008046618662774563\n",
      "Iteration: 5458/10000, Loss: 0.007313261739909649\n",
      "Iteration: 5459/10000, Loss: 0.010572315193712711\n",
      "Iteration: 5460/10000, Loss: 0.017828863114118576\n",
      "Iteration: 5461/10000, Loss: 0.009121978655457497\n",
      "Iteration: 5462/10000, Loss: 0.006745935883373022\n",
      "Iteration: 5463/10000, Loss: 0.013263294473290443\n",
      "Iteration: 5464/10000, Loss: 0.019095933064818382\n",
      "Iteration: 5465/10000, Loss: 0.014316977001726627\n",
      "Iteration: 5466/10000, Loss: 0.012175142765045166\n",
      "Iteration: 5467/10000, Loss: 0.018017128109931946\n",
      "Iteration: 5468/10000, Loss: 0.012931430712342262\n",
      "Iteration: 5469/10000, Loss: 0.010041918605566025\n",
      "Iteration: 5470/10000, Loss: 0.011799666099250317\n",
      "Iteration: 5471/10000, Loss: 0.014403034001588821\n",
      "Iteration: 5472/10000, Loss: 0.011399982497096062\n",
      "Iteration: 5473/10000, Loss: 0.009495537728071213\n",
      "Iteration: 5474/10000, Loss: 0.010998988524079323\n",
      "Iteration: 5475/10000, Loss: 0.018675079569220543\n",
      "Iteration: 5476/10000, Loss: 0.01423008181154728\n",
      "Iteration: 5477/10000, Loss: 0.013477478176355362\n",
      "Iteration: 5478/10000, Loss: 0.011292533949017525\n",
      "Iteration: 5479/10000, Loss: 0.01897074468433857\n",
      "Iteration: 5480/10000, Loss: 0.014869634993374348\n",
      "Iteration: 5481/10000, Loss: 0.01649687997996807\n",
      "Iteration: 5482/10000, Loss: 0.00922542717307806\n",
      "Iteration: 5483/10000, Loss: 0.0062402221374213696\n",
      "Iteration: 5484/10000, Loss: 0.024675317108631134\n",
      "Iteration: 5485/10000, Loss: 0.011188659816980362\n",
      "Iteration: 5486/10000, Loss: 0.014778191223740578\n",
      "Iteration: 5487/10000, Loss: 0.016891350969672203\n",
      "Iteration: 5488/10000, Loss: 0.012431150302290916\n",
      "Iteration: 5489/10000, Loss: 0.00898177083581686\n",
      "Iteration: 5490/10000, Loss: 0.018455740064382553\n",
      "Iteration: 5491/10000, Loss: 0.020486678928136826\n",
      "Iteration: 5492/10000, Loss: 0.00707521615549922\n",
      "Iteration: 5493/10000, Loss: 0.013964409939944744\n",
      "Iteration: 5494/10000, Loss: 0.013457407243549824\n",
      "Iteration: 5495/10000, Loss: 0.013593674637377262\n",
      "Iteration: 5496/10000, Loss: 0.008951764553785324\n",
      "Iteration: 5497/10000, Loss: 0.02068350464105606\n",
      "Iteration: 5498/10000, Loss: 0.011277083307504654\n",
      "Iteration: 5499/10000, Loss: 0.016481813043355942\n",
      "Iteration: 5500/10000, Loss: 0.012153617106378078\n",
      "Average test loss:  0.0026\n",
      "Iteration: 5501/10000, Loss: 0.015334293246269226\n",
      "Iteration: 5502/10000, Loss: 0.010103757493197918\n",
      "Iteration: 5503/10000, Loss: 0.009713838808238506\n",
      "Iteration: 5504/10000, Loss: 0.01645496115088463\n",
      "Iteration: 5505/10000, Loss: 0.019806720316410065\n",
      "Iteration: 5506/10000, Loss: 0.012679370120167732\n",
      "Iteration: 5507/10000, Loss: 0.014584911055862904\n",
      "Iteration: 5508/10000, Loss: 0.014500831253826618\n",
      "Iteration: 5509/10000, Loss: 0.017679749056696892\n",
      "Iteration: 5510/10000, Loss: 0.012277408502995968\n",
      "Iteration: 5511/10000, Loss: 0.010310889221727848\n",
      "Iteration: 5512/10000, Loss: 0.012605208903551102\n",
      "Iteration: 5513/10000, Loss: 0.01675255596637726\n",
      "Iteration: 5514/10000, Loss: 0.017062246799468994\n",
      "Iteration: 5515/10000, Loss: 0.008558196015655994\n",
      "Iteration: 5516/10000, Loss: 0.009078307077288628\n",
      "Iteration: 5517/10000, Loss: 0.013011772185564041\n",
      "Iteration: 5518/10000, Loss: 0.012650761753320694\n",
      "Iteration: 5519/10000, Loss: 0.012569136917591095\n",
      "Iteration: 5520/10000, Loss: 0.009046409279108047\n",
      "Iteration: 5521/10000, Loss: 0.006656956858932972\n",
      "Iteration: 5522/10000, Loss: 0.012035087682306767\n",
      "Iteration: 5523/10000, Loss: 0.009370786137878895\n",
      "Iteration: 5524/10000, Loss: 0.021558521315455437\n",
      "Iteration: 5525/10000, Loss: 0.010801714845001698\n",
      "Iteration: 5526/10000, Loss: 0.008679618127644062\n",
      "Iteration: 5527/10000, Loss: 0.011194152757525444\n",
      "Iteration: 5528/10000, Loss: 0.02302788756787777\n",
      "Iteration: 5529/10000, Loss: 0.011428926140069962\n",
      "Iteration: 5530/10000, Loss: 0.009868627414107323\n",
      "Iteration: 5531/10000, Loss: 0.009489373303949833\n",
      "Iteration: 5532/10000, Loss: 0.010426239110529423\n",
      "Iteration: 5533/10000, Loss: 0.01754017360508442\n",
      "Iteration: 5534/10000, Loss: 0.01134366262704134\n",
      "Iteration: 5535/10000, Loss: 0.012153505347669125\n",
      "Iteration: 5536/10000, Loss: 0.014400869607925415\n",
      "Iteration: 5537/10000, Loss: 0.01168372668325901\n",
      "Iteration: 5538/10000, Loss: 0.018466807901859283\n",
      "Iteration: 5539/10000, Loss: 0.008243315853178501\n",
      "Iteration: 5540/10000, Loss: 0.012451295740902424\n",
      "Iteration: 5541/10000, Loss: 0.016324304044246674\n",
      "Iteration: 5542/10000, Loss: 0.01632366143167019\n",
      "Iteration: 5543/10000, Loss: 0.01357815507799387\n",
      "Iteration: 5544/10000, Loss: 0.014381032437086105\n",
      "Iteration: 5545/10000, Loss: 0.014074034057557583\n",
      "Iteration: 5546/10000, Loss: 0.0059843785129487514\n",
      "Iteration: 5547/10000, Loss: 0.01367358397692442\n",
      "Iteration: 5548/10000, Loss: 0.010385760106146336\n",
      "Iteration: 5549/10000, Loss: 0.01415256317704916\n",
      "Iteration: 5550/10000, Loss: 0.007586554624140263\n",
      "Iteration: 5551/10000, Loss: 0.010193371213972569\n",
      "Iteration: 5552/10000, Loss: 0.01298446860164404\n",
      "Iteration: 5553/10000, Loss: 0.019084295257925987\n",
      "Iteration: 5554/10000, Loss: 0.015467384830117226\n",
      "Iteration: 5555/10000, Loss: 0.012895327061414719\n",
      "Iteration: 5556/10000, Loss: 0.013417479582130909\n",
      "Iteration: 5557/10000, Loss: 0.015745798125863075\n",
      "Iteration: 5558/10000, Loss: 0.011022418737411499\n",
      "Iteration: 5559/10000, Loss: 0.013276508077979088\n",
      "Iteration: 5560/10000, Loss: 0.015441308729350567\n",
      "Iteration: 5561/10000, Loss: 0.009803862310945988\n",
      "Iteration: 5562/10000, Loss: 0.013028744608163834\n",
      "Iteration: 5563/10000, Loss: 0.009537889622151852\n",
      "Iteration: 5564/10000, Loss: 0.014630105346441269\n",
      "Iteration: 5565/10000, Loss: 0.014546078629791737\n",
      "Iteration: 5566/10000, Loss: 0.012960397638380527\n",
      "Iteration: 5567/10000, Loss: 0.011475360952317715\n",
      "Iteration: 5568/10000, Loss: 0.013260496780276299\n",
      "Iteration: 5569/10000, Loss: 0.015807317569851875\n",
      "Iteration: 5570/10000, Loss: 0.008286934345960617\n",
      "Iteration: 5571/10000, Loss: 0.014880050905048847\n",
      "Iteration: 5572/10000, Loss: 0.010776476003229618\n",
      "Iteration: 5573/10000, Loss: 0.009937381371855736\n",
      "Iteration: 5574/10000, Loss: 0.016025232151150703\n",
      "Iteration: 5575/10000, Loss: 0.009171285666525364\n",
      "Iteration: 5576/10000, Loss: 0.018060950562357903\n",
      "Iteration: 5577/10000, Loss: 0.01033598929643631\n",
      "Iteration: 5578/10000, Loss: 0.014689584262669086\n",
      "Iteration: 5579/10000, Loss: 0.013907711952924728\n",
      "Iteration: 5580/10000, Loss: 0.014045100659132004\n",
      "Iteration: 5581/10000, Loss: 0.011832712218165398\n",
      "Iteration: 5582/10000, Loss: 0.01190478540956974\n",
      "Iteration: 5583/10000, Loss: 0.011274175718426704\n",
      "Iteration: 5584/10000, Loss: 0.014188576489686966\n",
      "Iteration: 5585/10000, Loss: 0.016653236001729965\n",
      "Iteration: 5586/10000, Loss: 0.02296205796301365\n",
      "Iteration: 5587/10000, Loss: 0.010069780051708221\n",
      "Iteration: 5588/10000, Loss: 0.013368844985961914\n",
      "Iteration: 5589/10000, Loss: 0.01723393239080906\n",
      "Iteration: 5590/10000, Loss: 0.011844360269606113\n",
      "Iteration: 5591/10000, Loss: 0.008511017076671124\n",
      "Iteration: 5592/10000, Loss: 0.0073875002562999725\n",
      "Iteration: 5593/10000, Loss: 0.010015116073191166\n",
      "Iteration: 5594/10000, Loss: 0.00767656322568655\n",
      "Iteration: 5595/10000, Loss: 0.013021053746342659\n",
      "Iteration: 5596/10000, Loss: 0.010920058004558086\n",
      "Iteration: 5597/10000, Loss: 0.013240654952824116\n",
      "Iteration: 5598/10000, Loss: 0.013132835738360882\n",
      "Iteration: 5599/10000, Loss: 0.014764790423214436\n",
      "Iteration: 5600/10000, Loss: 0.016160327941179276\n",
      "Average test loss:  0.0027\n",
      "Iteration: 5601/10000, Loss: 0.014139764942228794\n",
      "Iteration: 5602/10000, Loss: 0.009628716856241226\n",
      "Iteration: 5603/10000, Loss: 0.014112002216279507\n",
      "Iteration: 5604/10000, Loss: 0.012563138268887997\n",
      "Iteration: 5605/10000, Loss: 0.009447654709219933\n",
      "Iteration: 5606/10000, Loss: 0.017235275357961655\n",
      "Iteration: 5607/10000, Loss: 0.014286322519183159\n",
      "Iteration: 5608/10000, Loss: 0.013866576366126537\n",
      "Iteration: 5609/10000, Loss: 0.01159654837101698\n",
      "Iteration: 5610/10000, Loss: 0.00986796896904707\n",
      "Iteration: 5611/10000, Loss: 0.019503561779856682\n",
      "Iteration: 5612/10000, Loss: 0.012980911880731583\n",
      "Iteration: 5613/10000, Loss: 0.012373441830277443\n",
      "Iteration: 5614/10000, Loss: 0.010387714020907879\n",
      "Iteration: 5615/10000, Loss: 0.011271936818957329\n",
      "Iteration: 5616/10000, Loss: 0.013556990772485733\n",
      "Iteration: 5617/10000, Loss: 0.013441956602036953\n",
      "Iteration: 5618/10000, Loss: 0.011669465340673923\n",
      "Iteration: 5619/10000, Loss: 0.013802526518702507\n",
      "Iteration: 5620/10000, Loss: 0.015107309445738792\n",
      "Iteration: 5621/10000, Loss: 0.010282376781105995\n",
      "Iteration: 5622/10000, Loss: 0.015007912181317806\n",
      "Iteration: 5623/10000, Loss: 0.01361796073615551\n",
      "Iteration: 5624/10000, Loss: 0.014926550909876823\n",
      "Iteration: 5625/10000, Loss: 0.015315122902393341\n",
      "Iteration: 5626/10000, Loss: 0.01263248361647129\n",
      "Iteration: 5627/10000, Loss: 0.021119413897395134\n",
      "Iteration: 5628/10000, Loss: 0.013343844562768936\n",
      "Iteration: 5629/10000, Loss: 0.01494377851486206\n",
      "Iteration: 5630/10000, Loss: 0.01371078286319971\n",
      "Iteration: 5631/10000, Loss: 0.011041248217225075\n",
      "Iteration: 5632/10000, Loss: 0.019942454993724823\n",
      "Iteration: 5633/10000, Loss: 0.013179448433220387\n",
      "Iteration: 5634/10000, Loss: 0.008639782667160034\n",
      "Iteration: 5635/10000, Loss: 0.009354044683277607\n",
      "Iteration: 5636/10000, Loss: 0.014378824271261692\n",
      "Iteration: 5637/10000, Loss: 0.011251965537667274\n",
      "Iteration: 5638/10000, Loss: 0.008506109938025475\n",
      "Iteration: 5639/10000, Loss: 0.008776417002081871\n",
      "Iteration: 5640/10000, Loss: 0.012550289742648602\n",
      "Iteration: 5641/10000, Loss: 0.012447647750377655\n",
      "Iteration: 5642/10000, Loss: 0.011280685663223267\n",
      "Iteration: 5643/10000, Loss: 0.012546541169285774\n",
      "Iteration: 5644/10000, Loss: 0.009099215269088745\n",
      "Iteration: 5645/10000, Loss: 0.010201673954725266\n",
      "Iteration: 5646/10000, Loss: 0.015269359573721886\n",
      "Iteration: 5647/10000, Loss: 0.01318711880594492\n",
      "Iteration: 5648/10000, Loss: 0.013991639949381351\n",
      "Iteration: 5649/10000, Loss: 0.014308212324976921\n",
      "Iteration: 5650/10000, Loss: 0.016204901039600372\n",
      "Iteration: 5651/10000, Loss: 0.0151266073808074\n",
      "Iteration: 5652/10000, Loss: 0.012057237327098846\n",
      "Iteration: 5653/10000, Loss: 0.014499669894576073\n",
      "Iteration: 5654/10000, Loss: 0.010292375460267067\n",
      "Iteration: 5655/10000, Loss: 0.012357493862509727\n",
      "Iteration: 5656/10000, Loss: 0.013223854824900627\n",
      "Iteration: 5657/10000, Loss: 0.01365597639232874\n",
      "Iteration: 5658/10000, Loss: 0.012037131935358047\n",
      "Iteration: 5659/10000, Loss: 0.012479259632527828\n",
      "Iteration: 5660/10000, Loss: 0.01651914045214653\n",
      "Iteration: 5661/10000, Loss: 0.019099825993180275\n",
      "Iteration: 5662/10000, Loss: 0.014141668565571308\n",
      "Iteration: 5663/10000, Loss: 0.01380240824073553\n",
      "Iteration: 5664/10000, Loss: 0.016820795834064484\n",
      "Iteration: 5665/10000, Loss: 0.013927167281508446\n",
      "Iteration: 5666/10000, Loss: 0.008942007087171078\n",
      "Iteration: 5667/10000, Loss: 0.00768453860655427\n",
      "Iteration: 5668/10000, Loss: 0.014440526254475117\n",
      "Iteration: 5669/10000, Loss: 0.011753363534808159\n",
      "Iteration: 5670/10000, Loss: 0.01620909944176674\n",
      "Iteration: 5671/10000, Loss: 0.017569031566381454\n",
      "Iteration: 5672/10000, Loss: 0.01176372915506363\n",
      "Iteration: 5673/10000, Loss: 0.010604890063405037\n",
      "Iteration: 5674/10000, Loss: 0.01538912020623684\n",
      "Iteration: 5675/10000, Loss: 0.015507334843277931\n",
      "Iteration: 5676/10000, Loss: 0.01595132425427437\n",
      "Iteration: 5677/10000, Loss: 0.009440496563911438\n",
      "Iteration: 5678/10000, Loss: 0.01616598106920719\n",
      "Iteration: 5679/10000, Loss: 0.01205797865986824\n",
      "Iteration: 5680/10000, Loss: 0.013319623656570911\n",
      "Iteration: 5681/10000, Loss: 0.011252528056502342\n",
      "Iteration: 5682/10000, Loss: 0.006441601552069187\n",
      "Iteration: 5683/10000, Loss: 0.009261878207325935\n",
      "Iteration: 5684/10000, Loss: 0.012485780753195286\n",
      "Iteration: 5685/10000, Loss: 0.017159784212708473\n",
      "Iteration: 5686/10000, Loss: 0.010219170711934566\n",
      "Iteration: 5687/10000, Loss: 0.01334446668624878\n",
      "Iteration: 5688/10000, Loss: 0.010686041787266731\n",
      "Iteration: 5689/10000, Loss: 0.016049183905124664\n",
      "Iteration: 5690/10000, Loss: 0.012810483574867249\n",
      "Iteration: 5691/10000, Loss: 0.01156484242528677\n",
      "Iteration: 5692/10000, Loss: 0.011708353646099567\n",
      "Iteration: 5693/10000, Loss: 0.01759984716773033\n",
      "Iteration: 5694/10000, Loss: 0.01675945334136486\n",
      "Iteration: 5695/10000, Loss: 0.011548565700650215\n",
      "Iteration: 5696/10000, Loss: 0.015025002881884575\n",
      "Iteration: 5697/10000, Loss: 0.014485321938991547\n",
      "Iteration: 5698/10000, Loss: 0.014641247689723969\n",
      "Iteration: 5699/10000, Loss: 0.013760975562036037\n",
      "Iteration: 5700/10000, Loss: 0.016094639897346497\n",
      "Average test loss:  0.0040\n",
      "Iteration: 5701/10000, Loss: 0.015235166996717453\n",
      "Iteration: 5702/10000, Loss: 0.01241341233253479\n",
      "Iteration: 5703/10000, Loss: 0.010965523310005665\n",
      "Iteration: 5704/10000, Loss: 0.018427450209856033\n",
      "Iteration: 5705/10000, Loss: 0.008070135489106178\n",
      "Iteration: 5706/10000, Loss: 0.015052820555865765\n",
      "Iteration: 5707/10000, Loss: 0.01236641127616167\n",
      "Iteration: 5708/10000, Loss: 0.010115939192473888\n",
      "Iteration: 5709/10000, Loss: 0.016242992132902145\n",
      "Iteration: 5710/10000, Loss: 0.011037963442504406\n",
      "Iteration: 5711/10000, Loss: 0.017262423411011696\n",
      "Iteration: 5712/10000, Loss: 0.011275430209934711\n",
      "Iteration: 5713/10000, Loss: 0.013419527560472488\n",
      "Iteration: 5714/10000, Loss: 0.010549112223088741\n",
      "Iteration: 5715/10000, Loss: 0.012564340606331825\n",
      "Iteration: 5716/10000, Loss: 0.006458768621087074\n",
      "Iteration: 5717/10000, Loss: 0.011847401969134808\n",
      "Iteration: 5718/10000, Loss: 0.009300190955400467\n",
      "Iteration: 5719/10000, Loss: 0.013284781016409397\n",
      "Iteration: 5720/10000, Loss: 0.007868276908993721\n",
      "Iteration: 5721/10000, Loss: 0.012260234914720058\n",
      "Iteration: 5722/10000, Loss: 0.012186366133391857\n",
      "Iteration: 5723/10000, Loss: 0.015534603036940098\n",
      "Iteration: 5724/10000, Loss: 0.011106545105576515\n",
      "Iteration: 5725/10000, Loss: 0.02137123979628086\n",
      "Iteration: 5726/10000, Loss: 0.011356917209923267\n",
      "Iteration: 5727/10000, Loss: 0.014960095286369324\n",
      "Iteration: 5728/10000, Loss: 0.014549019746482372\n",
      "Iteration: 5729/10000, Loss: 0.011710711754858494\n",
      "Iteration: 5730/10000, Loss: 0.011635921895503998\n",
      "Iteration: 5731/10000, Loss: 0.018780365586280823\n",
      "Iteration: 5732/10000, Loss: 0.007195997983217239\n",
      "Iteration: 5733/10000, Loss: 0.013689827173948288\n",
      "Iteration: 5734/10000, Loss: 0.015226319432258606\n",
      "Iteration: 5735/10000, Loss: 0.013183186762034893\n",
      "Iteration: 5736/10000, Loss: 0.010009082034230232\n",
      "Iteration: 5737/10000, Loss: 0.005628775805234909\n",
      "Iteration: 5738/10000, Loss: 0.020526466891169548\n",
      "Iteration: 5739/10000, Loss: 0.009379414841532707\n",
      "Iteration: 5740/10000, Loss: 0.013271165080368519\n",
      "Iteration: 5741/10000, Loss: 0.016070017591118813\n",
      "Iteration: 5742/10000, Loss: 0.01597079448401928\n",
      "Iteration: 5743/10000, Loss: 0.019449247047305107\n",
      "Iteration: 5744/10000, Loss: 0.01258860807865858\n",
      "Iteration: 5745/10000, Loss: 0.016302945092320442\n",
      "Iteration: 5746/10000, Loss: 0.010428642854094505\n",
      "Iteration: 5747/10000, Loss: 0.010303197428584099\n",
      "Iteration: 5748/10000, Loss: 0.011531670577824116\n",
      "Iteration: 5749/10000, Loss: 0.011933762580156326\n",
      "Iteration: 5750/10000, Loss: 0.013136361725628376\n",
      "Iteration: 5751/10000, Loss: 0.014222358353435993\n",
      "Iteration: 5752/10000, Loss: 0.01964414305984974\n",
      "Iteration: 5753/10000, Loss: 0.007947487756609917\n",
      "Iteration: 5754/10000, Loss: 0.012435092590749264\n",
      "Iteration: 5755/10000, Loss: 0.01566348783671856\n",
      "Iteration: 5756/10000, Loss: 0.0063199857249855995\n",
      "Iteration: 5757/10000, Loss: 0.014668877236545086\n",
      "Iteration: 5758/10000, Loss: 0.014204715378582478\n",
      "Iteration: 5759/10000, Loss: 0.015998730435967445\n",
      "Iteration: 5760/10000, Loss: 0.010698998346924782\n",
      "Iteration: 5761/10000, Loss: 0.009627674706280231\n",
      "Iteration: 5762/10000, Loss: 0.0054510897025465965\n",
      "Iteration: 5763/10000, Loss: 0.007912411354482174\n",
      "Iteration: 5764/10000, Loss: 0.011840267106890678\n",
      "Iteration: 5765/10000, Loss: 0.008941144682466984\n",
      "Iteration: 5766/10000, Loss: 0.01569889485836029\n",
      "Iteration: 5767/10000, Loss: 0.013158092275261879\n",
      "Iteration: 5768/10000, Loss: 0.010788765735924244\n",
      "Iteration: 5769/10000, Loss: 0.01875426433980465\n",
      "Iteration: 5770/10000, Loss: 0.014831114560365677\n",
      "Iteration: 5771/10000, Loss: 0.012985446490347385\n",
      "Iteration: 5772/10000, Loss: 0.016073863953351974\n",
      "Iteration: 5773/10000, Loss: 0.016899384558200836\n",
      "Iteration: 5774/10000, Loss: 0.013515662401914597\n",
      "Iteration: 5775/10000, Loss: 0.016108624637126923\n",
      "Iteration: 5776/10000, Loss: 0.014767833054065704\n",
      "Iteration: 5777/10000, Loss: 0.0077106230892241\n",
      "Iteration: 5778/10000, Loss: 0.011904621496796608\n",
      "Iteration: 5779/10000, Loss: 0.011655090376734734\n",
      "Iteration: 5780/10000, Loss: 0.012469063512980938\n",
      "Iteration: 5781/10000, Loss: 0.01185007207095623\n",
      "Iteration: 5782/10000, Loss: 0.014852349646389484\n",
      "Iteration: 5783/10000, Loss: 0.01102599035948515\n",
      "Iteration: 5784/10000, Loss: 0.012098157778382301\n",
      "Iteration: 5785/10000, Loss: 0.014434006996452808\n",
      "Iteration: 5786/10000, Loss: 0.010849995538592339\n",
      "Iteration: 5787/10000, Loss: 0.01311754435300827\n",
      "Iteration: 5788/10000, Loss: 0.015063080005347729\n",
      "Iteration: 5789/10000, Loss: 0.012136438861489296\n",
      "Iteration: 5790/10000, Loss: 0.013681991025805473\n",
      "Iteration: 5791/10000, Loss: 0.0097059840336442\n",
      "Iteration: 5792/10000, Loss: 0.01154913380742073\n",
      "Iteration: 5793/10000, Loss: 0.012157910503447056\n",
      "Iteration: 5794/10000, Loss: 0.010757443495094776\n",
      "Iteration: 5795/10000, Loss: 0.014672738499939442\n",
      "Iteration: 5796/10000, Loss: 0.016422811895608902\n",
      "Iteration: 5797/10000, Loss: 0.008763855323195457\n",
      "Iteration: 5798/10000, Loss: 0.013619779609143734\n",
      "Iteration: 5799/10000, Loss: 0.01105023454874754\n",
      "Iteration: 5800/10000, Loss: 0.018352219834923744\n",
      "Average test loss:  0.0025\n",
      "Iteration: 5801/10000, Loss: 0.013626213185489178\n",
      "Iteration: 5802/10000, Loss: 0.012959601357579231\n",
      "Iteration: 5803/10000, Loss: 0.005444800015538931\n",
      "Iteration: 5804/10000, Loss: 0.01302262395620346\n",
      "Iteration: 5805/10000, Loss: 0.017862703651189804\n",
      "Iteration: 5806/10000, Loss: 0.013280817307531834\n",
      "Iteration: 5807/10000, Loss: 0.00868990272283554\n",
      "Iteration: 5808/10000, Loss: 0.0166619960218668\n",
      "Iteration: 5809/10000, Loss: 0.01109116431325674\n",
      "Iteration: 5810/10000, Loss: 0.016995521262288094\n",
      "Iteration: 5811/10000, Loss: 0.012347708456218243\n",
      "Iteration: 5812/10000, Loss: 0.02203572727739811\n",
      "Iteration: 5813/10000, Loss: 0.009445547126233578\n",
      "Iteration: 5814/10000, Loss: 0.012349989265203476\n",
      "Iteration: 5815/10000, Loss: 0.005844909697771072\n",
      "Iteration: 5816/10000, Loss: 0.01414312794804573\n",
      "Iteration: 5817/10000, Loss: 0.008714742958545685\n",
      "Iteration: 5818/10000, Loss: 0.01042809709906578\n",
      "Iteration: 5819/10000, Loss: 0.007623647805303335\n",
      "Iteration: 5820/10000, Loss: 0.011361793614923954\n",
      "Iteration: 5821/10000, Loss: 0.009829412214457989\n",
      "Iteration: 5822/10000, Loss: 0.0062376768328249454\n",
      "Iteration: 5823/10000, Loss: 0.010431473143398762\n",
      "Iteration: 5824/10000, Loss: 0.012474664486944675\n",
      "Iteration: 5825/10000, Loss: 0.01589922048151493\n",
      "Iteration: 5826/10000, Loss: 0.014583738520741463\n",
      "Iteration: 5827/10000, Loss: 0.011152121238410473\n",
      "Iteration: 5828/10000, Loss: 0.013701493851840496\n",
      "Iteration: 5829/10000, Loss: 0.014622974209487438\n",
      "Iteration: 5830/10000, Loss: 0.016820622608065605\n",
      "Iteration: 5831/10000, Loss: 0.011547626927495003\n",
      "Iteration: 5832/10000, Loss: 0.008409231901168823\n",
      "Iteration: 5833/10000, Loss: 0.020823361352086067\n",
      "Iteration: 5834/10000, Loss: 0.011791015043854713\n",
      "Iteration: 5835/10000, Loss: 0.012948432937264442\n",
      "Iteration: 5836/10000, Loss: 0.01152866892516613\n",
      "Iteration: 5837/10000, Loss: 0.011989603750407696\n",
      "Iteration: 5838/10000, Loss: 0.016230767592787743\n",
      "Iteration: 5839/10000, Loss: 0.013838398270308971\n",
      "Iteration: 5840/10000, Loss: 0.016154760494828224\n",
      "Iteration: 5841/10000, Loss: 0.007890451699495316\n",
      "Iteration: 5842/10000, Loss: 0.014786035753786564\n",
      "Iteration: 5843/10000, Loss: 0.01446295715868473\n",
      "Iteration: 5844/10000, Loss: 0.011632976122200489\n",
      "Iteration: 5845/10000, Loss: 0.012172522023320198\n",
      "Iteration: 5846/10000, Loss: 0.01815118081867695\n",
      "Iteration: 5847/10000, Loss: 0.01415870152413845\n",
      "Iteration: 5848/10000, Loss: 0.012498823925852776\n",
      "Iteration: 5849/10000, Loss: 0.013512385077774525\n",
      "Iteration: 5850/10000, Loss: 0.02179156243801117\n",
      "Iteration: 5851/10000, Loss: 0.011630814522504807\n",
      "Iteration: 5852/10000, Loss: 0.008387118577957153\n",
      "Iteration: 5853/10000, Loss: 0.012017996050417423\n",
      "Iteration: 5854/10000, Loss: 0.014707968570291996\n",
      "Iteration: 5855/10000, Loss: 0.016488511115312576\n",
      "Iteration: 5856/10000, Loss: 0.010315635241568089\n",
      "Iteration: 5857/10000, Loss: 0.00881221890449524\n",
      "Iteration: 5858/10000, Loss: 0.010060307569801807\n",
      "Iteration: 5859/10000, Loss: 0.007788534741848707\n",
      "Iteration: 5860/10000, Loss: 0.014347335323691368\n",
      "Iteration: 5861/10000, Loss: 0.00736467307433486\n",
      "Iteration: 5862/10000, Loss: 0.017247717827558517\n",
      "Iteration: 5863/10000, Loss: 0.014029198326170444\n",
      "Iteration: 5864/10000, Loss: 0.013844017870724201\n",
      "Iteration: 5865/10000, Loss: 0.017091000452637672\n",
      "Iteration: 5866/10000, Loss: 0.010412048548460007\n",
      "Iteration: 5867/10000, Loss: 0.01593785174190998\n",
      "Iteration: 5868/10000, Loss: 0.01749737374484539\n",
      "Iteration: 5869/10000, Loss: 0.012493520975112915\n",
      "Iteration: 5870/10000, Loss: 0.008865287527441978\n",
      "Iteration: 5871/10000, Loss: 0.013577871955931187\n",
      "Iteration: 5872/10000, Loss: 0.012756702490150928\n",
      "Iteration: 5873/10000, Loss: 0.017272774130105972\n",
      "Iteration: 5874/10000, Loss: 0.010383713990449905\n",
      "Iteration: 5875/10000, Loss: 0.011115595698356628\n",
      "Iteration: 5876/10000, Loss: 0.009873530827462673\n",
      "Iteration: 5877/10000, Loss: 0.009818990714848042\n",
      "Iteration: 5878/10000, Loss: 0.015745602548122406\n",
      "Iteration: 5879/10000, Loss: 0.015675654634833336\n",
      "Iteration: 5880/10000, Loss: 0.01199580729007721\n",
      "Iteration: 5881/10000, Loss: 0.007644340395927429\n",
      "Iteration: 5882/10000, Loss: 0.015114112757146358\n",
      "Iteration: 5883/10000, Loss: 0.012998893857002258\n",
      "Iteration: 5884/10000, Loss: 0.012050246819853783\n",
      "Iteration: 5885/10000, Loss: 0.014455104246735573\n",
      "Iteration: 5886/10000, Loss: 0.020247649401426315\n",
      "Iteration: 5887/10000, Loss: 0.008897488005459309\n",
      "Iteration: 5888/10000, Loss: 0.013128013350069523\n",
      "Iteration: 5889/10000, Loss: 0.01449719537049532\n",
      "Iteration: 5890/10000, Loss: 0.011156251654028893\n",
      "Iteration: 5891/10000, Loss: 0.004998612217605114\n",
      "Iteration: 5892/10000, Loss: 0.0077690971083939075\n",
      "Iteration: 5893/10000, Loss: 0.013493924401700497\n",
      "Iteration: 5894/10000, Loss: 0.011315143667161465\n",
      "Iteration: 5895/10000, Loss: 0.011315746232867241\n",
      "Iteration: 5896/10000, Loss: 0.01177122537046671\n",
      "Iteration: 5897/10000, Loss: 0.013624467886984348\n",
      "Iteration: 5898/10000, Loss: 0.013190841302275658\n",
      "Iteration: 5899/10000, Loss: 0.009864074178040028\n",
      "Iteration: 5900/10000, Loss: 0.009465634822845459\n",
      "Average test loss:  0.0030\n",
      "Iteration: 5901/10000, Loss: 0.011582879349589348\n",
      "Iteration: 5902/10000, Loss: 0.01190682128071785\n",
      "Iteration: 5903/10000, Loss: 0.01299747172743082\n",
      "Iteration: 5904/10000, Loss: 0.018643483519554138\n",
      "Iteration: 5905/10000, Loss: 0.010071367025375366\n",
      "Iteration: 5906/10000, Loss: 0.01368663553148508\n",
      "Iteration: 5907/10000, Loss: 0.014745228923857212\n",
      "Iteration: 5908/10000, Loss: 0.012591236270964146\n",
      "Iteration: 5909/10000, Loss: 0.015446681529283524\n",
      "Iteration: 5910/10000, Loss: 0.011360829696059227\n",
      "Iteration: 5911/10000, Loss: 0.016353515908122063\n",
      "Iteration: 5912/10000, Loss: 0.01235098298639059\n",
      "Iteration: 5913/10000, Loss: 0.014782313257455826\n",
      "Iteration: 5914/10000, Loss: 0.009328208863735199\n",
      "Iteration: 5915/10000, Loss: 0.011460495181381702\n",
      "Iteration: 5916/10000, Loss: 0.00797310657799244\n",
      "Iteration: 5917/10000, Loss: 0.01263286080211401\n",
      "Iteration: 5918/10000, Loss: 0.009808262810111046\n",
      "Iteration: 5919/10000, Loss: 0.01441057026386261\n",
      "Iteration: 5920/10000, Loss: 0.008171770721673965\n",
      "Iteration: 5921/10000, Loss: 0.017423439770936966\n",
      "Iteration: 5922/10000, Loss: 0.011111777275800705\n",
      "Iteration: 5923/10000, Loss: 0.013778994791209698\n",
      "Iteration: 5924/10000, Loss: 0.012622011825442314\n",
      "Iteration: 5925/10000, Loss: 0.016475366428494453\n",
      "Iteration: 5926/10000, Loss: 0.007299233693629503\n",
      "Iteration: 5927/10000, Loss: 0.012338204309344292\n",
      "Iteration: 5928/10000, Loss: 0.010720417834818363\n",
      "Iteration: 5929/10000, Loss: 0.012428115122020245\n",
      "Iteration: 5930/10000, Loss: 0.01200807187706232\n",
      "Iteration: 5931/10000, Loss: 0.009601939469575882\n",
      "Iteration: 5932/10000, Loss: 0.01462961733341217\n",
      "Iteration: 5933/10000, Loss: 0.019857488572597504\n",
      "Iteration: 5934/10000, Loss: 0.009638538584113121\n",
      "Iteration: 5935/10000, Loss: 0.009539227932691574\n",
      "Iteration: 5936/10000, Loss: 0.014925843104720116\n",
      "Iteration: 5937/10000, Loss: 0.005939078982919455\n",
      "Iteration: 5938/10000, Loss: 0.010924999602138996\n",
      "Iteration: 5939/10000, Loss: 0.009967997670173645\n",
      "Iteration: 5940/10000, Loss: 0.014739020727574825\n",
      "Iteration: 5941/10000, Loss: 0.012491919100284576\n",
      "Iteration: 5942/10000, Loss: 0.0136334877461195\n",
      "Iteration: 5943/10000, Loss: 0.008997539058327675\n",
      "Iteration: 5944/10000, Loss: 0.02022244967520237\n",
      "Iteration: 5945/10000, Loss: 0.009205974638462067\n",
      "Iteration: 5946/10000, Loss: 0.009646294638514519\n",
      "Iteration: 5947/10000, Loss: 0.007609060034155846\n",
      "Iteration: 5948/10000, Loss: 0.014288840815424919\n",
      "Iteration: 5949/10000, Loss: 0.015671242028474808\n",
      "Iteration: 5950/10000, Loss: 0.010333121754229069\n",
      "Iteration: 5951/10000, Loss: 0.008920036256313324\n",
      "Iteration: 5952/10000, Loss: 0.009925885125994682\n",
      "Iteration: 5953/10000, Loss: 0.013684957288205624\n",
      "Iteration: 5954/10000, Loss: 0.01439844910055399\n",
      "Iteration: 5955/10000, Loss: 0.010481291450560093\n",
      "Iteration: 5956/10000, Loss: 0.014655670151114464\n",
      "Iteration: 5957/10000, Loss: 0.012209402397274971\n",
      "Iteration: 5958/10000, Loss: 0.006173974368721247\n",
      "Iteration: 5959/10000, Loss: 0.015748323872685432\n",
      "Iteration: 5960/10000, Loss: 0.009104290045797825\n",
      "Iteration: 5961/10000, Loss: 0.01420237310230732\n",
      "Iteration: 5962/10000, Loss: 0.006775974296033382\n",
      "Iteration: 5963/10000, Loss: 0.011211289092898369\n",
      "Iteration: 5964/10000, Loss: 0.01581813208758831\n",
      "Iteration: 5965/10000, Loss: 0.009615360759198666\n",
      "Iteration: 5966/10000, Loss: 0.008146820589900017\n",
      "Iteration: 5967/10000, Loss: 0.011518115177750587\n",
      "Iteration: 5968/10000, Loss: 0.016061626374721527\n",
      "Iteration: 5969/10000, Loss: 0.010444830171763897\n",
      "Iteration: 5970/10000, Loss: 0.008001361042261124\n",
      "Iteration: 5971/10000, Loss: 0.015115384943783283\n",
      "Iteration: 5972/10000, Loss: 0.01203907746821642\n",
      "Iteration: 5973/10000, Loss: 0.005859878845512867\n",
      "Iteration: 5974/10000, Loss: 0.012417695485055447\n",
      "Iteration: 5975/10000, Loss: 0.010834979824721813\n",
      "Iteration: 5976/10000, Loss: 0.01318058930337429\n",
      "Iteration: 5977/10000, Loss: 0.014286966994404793\n",
      "Iteration: 5978/10000, Loss: 0.014824497513473034\n",
      "Iteration: 5979/10000, Loss: 0.017360705882310867\n",
      "Iteration: 5980/10000, Loss: 0.011954640969634056\n",
      "Iteration: 5981/10000, Loss: 0.012563095428049564\n",
      "Iteration: 5982/10000, Loss: 0.012103462591767311\n",
      "Iteration: 5983/10000, Loss: 0.01450718380510807\n",
      "Iteration: 5984/10000, Loss: 0.012615055777132511\n",
      "Iteration: 5985/10000, Loss: 0.011642302386462688\n",
      "Iteration: 5986/10000, Loss: 0.018226241692900658\n",
      "Iteration: 5987/10000, Loss: 0.011464856564998627\n",
      "Iteration: 5988/10000, Loss: 0.01232776790857315\n",
      "Iteration: 5989/10000, Loss: 0.013500232249498367\n",
      "Iteration: 5990/10000, Loss: 0.014414255507290363\n",
      "Iteration: 5991/10000, Loss: 0.009204450063407421\n",
      "Iteration: 5992/10000, Loss: 0.011761131696403027\n",
      "Iteration: 5993/10000, Loss: 0.01711256243288517\n",
      "Iteration: 5994/10000, Loss: 0.01653900556266308\n",
      "Iteration: 5995/10000, Loss: 0.00993674248456955\n",
      "Iteration: 5996/10000, Loss: 0.010416707955300808\n",
      "Iteration: 5997/10000, Loss: 0.014425703324377537\n",
      "Iteration: 5998/10000, Loss: 0.011105497367680073\n",
      "Iteration: 5999/10000, Loss: 0.013021863996982574\n",
      "Iteration: 6000/10000, Loss: 0.011373410001397133\n",
      "Average test loss:  0.0047\n",
      "Iteration: 6001/10000, Loss: 0.01136897411197424\n",
      "Iteration: 6002/10000, Loss: 0.013982472009956837\n",
      "Iteration: 6003/10000, Loss: 0.0134668480604887\n",
      "Iteration: 6004/10000, Loss: 0.012256793677806854\n",
      "Iteration: 6005/10000, Loss: 0.00650441600009799\n",
      "Iteration: 6006/10000, Loss: 0.012510300613939762\n",
      "Iteration: 6007/10000, Loss: 0.009759858250617981\n",
      "Iteration: 6008/10000, Loss: 0.011242414824664593\n",
      "Iteration: 6009/10000, Loss: 0.01091147679835558\n",
      "Iteration: 6010/10000, Loss: 0.015954837203025818\n",
      "Iteration: 6011/10000, Loss: 0.00884560402482748\n",
      "Iteration: 6012/10000, Loss: 0.00902782566845417\n",
      "Iteration: 6013/10000, Loss: 0.01449314784258604\n",
      "Iteration: 6014/10000, Loss: 0.011774602346122265\n",
      "Iteration: 6015/10000, Loss: 0.01262692455202341\n",
      "Iteration: 6016/10000, Loss: 0.012384304776787758\n",
      "Iteration: 6017/10000, Loss: 0.011845959350466728\n",
      "Iteration: 6018/10000, Loss: 0.006006726995110512\n",
      "Iteration: 6019/10000, Loss: 0.010854206047952175\n",
      "Iteration: 6020/10000, Loss: 0.011664549820125103\n",
      "Iteration: 6021/10000, Loss: 0.013462102971971035\n",
      "Iteration: 6022/10000, Loss: 0.009038787335157394\n",
      "Iteration: 6023/10000, Loss: 0.010150573216378689\n",
      "Iteration: 6024/10000, Loss: 0.013659871183335781\n",
      "Iteration: 6025/10000, Loss: 0.009071918204426765\n",
      "Iteration: 6026/10000, Loss: 0.007363839074969292\n",
      "Iteration: 6027/10000, Loss: 0.008350508287549019\n",
      "Iteration: 6028/10000, Loss: 0.01142942812293768\n",
      "Iteration: 6029/10000, Loss: 0.01380970235913992\n",
      "Iteration: 6030/10000, Loss: 0.015313315205276012\n",
      "Iteration: 6031/10000, Loss: 0.013457633554935455\n",
      "Iteration: 6032/10000, Loss: 0.013100618496537209\n",
      "Iteration: 6033/10000, Loss: 0.013203196227550507\n",
      "Iteration: 6034/10000, Loss: 0.014676075428724289\n",
      "Iteration: 6035/10000, Loss: 0.018765240907669067\n",
      "Iteration: 6036/10000, Loss: 0.012538199312984943\n",
      "Iteration: 6037/10000, Loss: 0.011336157098412514\n",
      "Iteration: 6038/10000, Loss: 0.013077275827527046\n",
      "Iteration: 6039/10000, Loss: 0.013225418515503407\n",
      "Iteration: 6040/10000, Loss: 0.011119305156171322\n",
      "Iteration: 6041/10000, Loss: 0.01674683205783367\n",
      "Iteration: 6042/10000, Loss: 0.014805048704147339\n",
      "Iteration: 6043/10000, Loss: 0.009974970482289791\n",
      "Iteration: 6044/10000, Loss: 0.012268955819308758\n",
      "Iteration: 6045/10000, Loss: 0.013615311123430729\n",
      "Iteration: 6046/10000, Loss: 0.012926665134727955\n",
      "Iteration: 6047/10000, Loss: 0.011429553851485252\n",
      "Iteration: 6048/10000, Loss: 0.016868477687239647\n",
      "Iteration: 6049/10000, Loss: 0.010408404283225536\n",
      "Iteration: 6050/10000, Loss: 0.011185620911419392\n",
      "Iteration: 6051/10000, Loss: 0.0067313299514353275\n",
      "Iteration: 6052/10000, Loss: 0.015446886420249939\n",
      "Iteration: 6053/10000, Loss: 0.008262163028120995\n",
      "Iteration: 6054/10000, Loss: 0.011286983266472816\n",
      "Iteration: 6055/10000, Loss: 0.012118197977542877\n",
      "Iteration: 6056/10000, Loss: 0.008104238659143448\n",
      "Iteration: 6057/10000, Loss: 0.010650500655174255\n",
      "Iteration: 6058/10000, Loss: 0.013771283440291882\n",
      "Iteration: 6059/10000, Loss: 0.0125495670363307\n",
      "Iteration: 6060/10000, Loss: 0.01206297054886818\n",
      "Iteration: 6061/10000, Loss: 0.01182676013559103\n",
      "Iteration: 6062/10000, Loss: 0.015896571800112724\n",
      "Iteration: 6063/10000, Loss: 0.01034882664680481\n",
      "Iteration: 6064/10000, Loss: 0.014321759343147278\n",
      "Iteration: 6065/10000, Loss: 0.009405451826751232\n",
      "Iteration: 6066/10000, Loss: 0.013933952897787094\n",
      "Iteration: 6067/10000, Loss: 0.008361788466572762\n",
      "Iteration: 6068/10000, Loss: 0.012746165506541729\n",
      "Iteration: 6069/10000, Loss: 0.011142229661345482\n",
      "Iteration: 6070/10000, Loss: 0.013101303949952126\n",
      "Iteration: 6071/10000, Loss: 0.015180317685008049\n",
      "Iteration: 6072/10000, Loss: 0.01040242426097393\n",
      "Iteration: 6073/10000, Loss: 0.013910925947129726\n",
      "Iteration: 6074/10000, Loss: 0.009908299893140793\n",
      "Iteration: 6075/10000, Loss: 0.008809384889900684\n",
      "Iteration: 6076/10000, Loss: 0.0129542276263237\n",
      "Iteration: 6077/10000, Loss: 0.013276933692395687\n",
      "Iteration: 6078/10000, Loss: 0.0071738772094249725\n",
      "Iteration: 6079/10000, Loss: 0.008376562967896461\n",
      "Iteration: 6080/10000, Loss: 0.019218167290091515\n",
      "Iteration: 6081/10000, Loss: 0.015941236168146133\n",
      "Iteration: 6082/10000, Loss: 0.009312697686254978\n",
      "Iteration: 6083/10000, Loss: 0.017530499026179314\n",
      "Iteration: 6084/10000, Loss: 0.013568833470344543\n",
      "Iteration: 6085/10000, Loss: 0.012352646328508854\n",
      "Iteration: 6086/10000, Loss: 0.01546698808670044\n",
      "Iteration: 6087/10000, Loss: 0.014363627880811691\n",
      "Iteration: 6088/10000, Loss: 0.013929050415754318\n",
      "Iteration: 6089/10000, Loss: 0.013974348083138466\n",
      "Iteration: 6090/10000, Loss: 0.011340674944221973\n",
      "Iteration: 6091/10000, Loss: 0.013030151836574078\n",
      "Iteration: 6092/10000, Loss: 0.00805218331515789\n",
      "Iteration: 6093/10000, Loss: 0.010403893887996674\n",
      "Iteration: 6094/10000, Loss: 0.015641413629055023\n",
      "Iteration: 6095/10000, Loss: 0.010041330009698868\n",
      "Iteration: 6096/10000, Loss: 0.016897078603506088\n",
      "Iteration: 6097/10000, Loss: 0.010084318928420544\n",
      "Iteration: 6098/10000, Loss: 0.012822090648114681\n",
      "Iteration: 6099/10000, Loss: 0.01387737412005663\n",
      "Iteration: 6100/10000, Loss: 0.008506691083312035\n",
      "Average test loss:  0.0024\n",
      "Iteration: 6101/10000, Loss: 0.00897073931992054\n",
      "Iteration: 6102/10000, Loss: 0.018150001764297485\n",
      "Iteration: 6103/10000, Loss: 0.0162245724350214\n",
      "Iteration: 6104/10000, Loss: 0.01023764256387949\n",
      "Iteration: 6105/10000, Loss: 0.00881674513220787\n",
      "Iteration: 6106/10000, Loss: 0.01505336444824934\n",
      "Iteration: 6107/10000, Loss: 0.01217934675514698\n",
      "Iteration: 6108/10000, Loss: 0.0073679424822330475\n",
      "Iteration: 6109/10000, Loss: 0.015279067680239677\n",
      "Iteration: 6110/10000, Loss: 0.013489587232470512\n",
      "Iteration: 6111/10000, Loss: 0.014205176383256912\n",
      "Iteration: 6112/10000, Loss: 0.012232271954417229\n",
      "Iteration: 6113/10000, Loss: 0.006159950513392687\n",
      "Iteration: 6114/10000, Loss: 0.012271057814359665\n",
      "Iteration: 6115/10000, Loss: 0.01491561345756054\n",
      "Iteration: 6116/10000, Loss: 0.01058296300470829\n",
      "Iteration: 6117/10000, Loss: 0.009851768612861633\n",
      "Iteration: 6118/10000, Loss: 0.012686998583376408\n",
      "Iteration: 6119/10000, Loss: 0.012989599257707596\n",
      "Iteration: 6120/10000, Loss: 0.011229936964809895\n",
      "Iteration: 6121/10000, Loss: 0.010419122874736786\n",
      "Iteration: 6122/10000, Loss: 0.010577544569969177\n",
      "Iteration: 6123/10000, Loss: 0.007010126020759344\n",
      "Iteration: 6124/10000, Loss: 0.0077832043170928955\n",
      "Iteration: 6125/10000, Loss: 0.00820186734199524\n",
      "Iteration: 6126/10000, Loss: 0.013019976206123829\n",
      "Iteration: 6127/10000, Loss: 0.010523389093577862\n",
      "Iteration: 6128/10000, Loss: 0.012241749092936516\n",
      "Iteration: 6129/10000, Loss: 0.0052098557353019714\n",
      "Iteration: 6130/10000, Loss: 0.015180994756519794\n",
      "Iteration: 6131/10000, Loss: 0.012651192955672741\n",
      "Iteration: 6132/10000, Loss: 0.012716727331280708\n",
      "Iteration: 6133/10000, Loss: 0.012539227493107319\n",
      "Iteration: 6134/10000, Loss: 0.011445248499512672\n",
      "Iteration: 6135/10000, Loss: 0.018921418115496635\n",
      "Iteration: 6136/10000, Loss: 0.015326682478189468\n",
      "Iteration: 6137/10000, Loss: 0.019022390246391296\n",
      "Iteration: 6138/10000, Loss: 0.015714852139353752\n",
      "Iteration: 6139/10000, Loss: 0.010120046325027943\n",
      "Iteration: 6140/10000, Loss: 0.010916649363934994\n",
      "Iteration: 6141/10000, Loss: 0.011067157611250877\n",
      "Iteration: 6142/10000, Loss: 0.008794429711997509\n",
      "Iteration: 6143/10000, Loss: 0.007383923977613449\n",
      "Iteration: 6144/10000, Loss: 0.01151474192738533\n",
      "Iteration: 6145/10000, Loss: 0.011065642349421978\n",
      "Iteration: 6146/10000, Loss: 0.01644221693277359\n",
      "Iteration: 6147/10000, Loss: 0.009303641505539417\n",
      "Iteration: 6148/10000, Loss: 0.014385256916284561\n",
      "Iteration: 6149/10000, Loss: 0.015546395443379879\n",
      "Iteration: 6150/10000, Loss: 0.0111837862059474\n",
      "Iteration: 6151/10000, Loss: 0.012976420111954212\n",
      "Iteration: 6152/10000, Loss: 0.01273401640355587\n",
      "Iteration: 6153/10000, Loss: 0.01006715651601553\n",
      "Iteration: 6154/10000, Loss: 0.011907657608389854\n",
      "Iteration: 6155/10000, Loss: 0.015063480474054813\n",
      "Iteration: 6156/10000, Loss: 0.01015989575535059\n",
      "Iteration: 6157/10000, Loss: 0.00911326240748167\n",
      "Iteration: 6158/10000, Loss: 0.014173856005072594\n",
      "Iteration: 6159/10000, Loss: 0.010001637041568756\n",
      "Iteration: 6160/10000, Loss: 0.014824280515313148\n",
      "Iteration: 6161/10000, Loss: 0.01808204874396324\n",
      "Iteration: 6162/10000, Loss: 0.011280396021902561\n",
      "Iteration: 6163/10000, Loss: 0.018244275823235512\n",
      "Iteration: 6164/10000, Loss: 0.009513430297374725\n",
      "Iteration: 6165/10000, Loss: 0.008218158967792988\n",
      "Iteration: 6166/10000, Loss: 0.015565261244773865\n",
      "Iteration: 6167/10000, Loss: 0.012368201278150082\n",
      "Iteration: 6168/10000, Loss: 0.009790029376745224\n",
      "Iteration: 6169/10000, Loss: 0.018200689926743507\n",
      "Iteration: 6170/10000, Loss: 0.011125106364488602\n",
      "Iteration: 6171/10000, Loss: 0.01725127547979355\n",
      "Iteration: 6172/10000, Loss: 0.012936976738274097\n",
      "Iteration: 6173/10000, Loss: 0.012281396426260471\n",
      "Iteration: 6174/10000, Loss: 0.016042394563555717\n",
      "Iteration: 6175/10000, Loss: 0.007929888553917408\n",
      "Iteration: 6176/10000, Loss: 0.008730068802833557\n",
      "Iteration: 6177/10000, Loss: 0.012040575966238976\n",
      "Iteration: 6178/10000, Loss: 0.009105406701564789\n",
      "Iteration: 6179/10000, Loss: 0.011195404455065727\n",
      "Iteration: 6180/10000, Loss: 0.016992803663015366\n",
      "Iteration: 6181/10000, Loss: 0.014104640111327171\n",
      "Iteration: 6182/10000, Loss: 0.00424383208155632\n",
      "Iteration: 6183/10000, Loss: 0.010392094030976295\n",
      "Iteration: 6184/10000, Loss: 0.01201622560620308\n",
      "Iteration: 6185/10000, Loss: 0.01605953834950924\n",
      "Iteration: 6186/10000, Loss: 0.0098419189453125\n",
      "Iteration: 6187/10000, Loss: 0.013288822025060654\n",
      "Iteration: 6188/10000, Loss: 0.008657767437398434\n",
      "Iteration: 6189/10000, Loss: 0.014669121243059635\n",
      "Iteration: 6190/10000, Loss: 0.014462406747043133\n",
      "Iteration: 6191/10000, Loss: 0.015237855724990368\n",
      "Iteration: 6192/10000, Loss: 0.013197229243814945\n",
      "Iteration: 6193/10000, Loss: 0.015120281837880611\n",
      "Iteration: 6194/10000, Loss: 0.009621180593967438\n",
      "Iteration: 6195/10000, Loss: 0.00991975236684084\n",
      "Iteration: 6196/10000, Loss: 0.014525041915476322\n",
      "Iteration: 6197/10000, Loss: 0.011707764118909836\n",
      "Iteration: 6198/10000, Loss: 0.01786472462117672\n",
      "Iteration: 6199/10000, Loss: 0.014459569938480854\n",
      "Iteration: 6200/10000, Loss: 0.013452308252453804\n",
      "Average test loss:  0.0019\n",
      "Iteration: 6201/10000, Loss: 0.011586609296500683\n",
      "Iteration: 6202/10000, Loss: 0.016306662932038307\n",
      "Iteration: 6203/10000, Loss: 0.009619073942303658\n",
      "Iteration: 6204/10000, Loss: 0.010811428539454937\n",
      "Iteration: 6205/10000, Loss: 0.012190739624202251\n",
      "Iteration: 6206/10000, Loss: 0.01582830399274826\n",
      "Iteration: 6207/10000, Loss: 0.011366942897439003\n",
      "Iteration: 6208/10000, Loss: 0.00865307729691267\n",
      "Iteration: 6209/10000, Loss: 0.016397826373577118\n",
      "Iteration: 6210/10000, Loss: 0.014353500679135323\n",
      "Iteration: 6211/10000, Loss: 0.01672116108238697\n",
      "Iteration: 6212/10000, Loss: 0.014695997349917889\n",
      "Iteration: 6213/10000, Loss: 0.007611447013914585\n",
      "Iteration: 6214/10000, Loss: 0.011403404176235199\n",
      "Iteration: 6215/10000, Loss: 0.013299978338181973\n",
      "Iteration: 6216/10000, Loss: 0.015520397573709488\n",
      "Iteration: 6217/10000, Loss: 0.011159124784171581\n",
      "Iteration: 6218/10000, Loss: 0.012214639224112034\n",
      "Iteration: 6219/10000, Loss: 0.008784356527030468\n",
      "Iteration: 6220/10000, Loss: 0.016070887446403503\n",
      "Iteration: 6221/10000, Loss: 0.01706511899828911\n",
      "Iteration: 6222/10000, Loss: 0.00951134692877531\n",
      "Iteration: 6223/10000, Loss: 0.018249137327075005\n",
      "Iteration: 6224/10000, Loss: 0.012380250729620457\n",
      "Iteration: 6225/10000, Loss: 0.009165622293949127\n",
      "Iteration: 6226/10000, Loss: 0.011293449439108372\n",
      "Iteration: 6227/10000, Loss: 0.016852103173732758\n",
      "Iteration: 6228/10000, Loss: 0.011018174700438976\n",
      "Iteration: 6229/10000, Loss: 0.00924874097108841\n",
      "Iteration: 6230/10000, Loss: 0.009470292367041111\n",
      "Iteration: 6231/10000, Loss: 0.005947427358478308\n",
      "Iteration: 6232/10000, Loss: 0.017599143087863922\n",
      "Iteration: 6233/10000, Loss: 0.009107052348554134\n",
      "Iteration: 6234/10000, Loss: 0.016278300434350967\n",
      "Iteration: 6235/10000, Loss: 0.015270592644810677\n",
      "Iteration: 6236/10000, Loss: 0.010234970599412918\n",
      "Iteration: 6237/10000, Loss: 0.007846579886972904\n",
      "Iteration: 6238/10000, Loss: 0.013570464216172695\n",
      "Iteration: 6239/10000, Loss: 0.008223969489336014\n",
      "Iteration: 6240/10000, Loss: 0.006506634410470724\n",
      "Iteration: 6241/10000, Loss: 0.012974685057997704\n",
      "Iteration: 6242/10000, Loss: 0.015164479613304138\n",
      "Iteration: 6243/10000, Loss: 0.015464754775166512\n",
      "Iteration: 6244/10000, Loss: 0.01067068986594677\n",
      "Iteration: 6245/10000, Loss: 0.010839554481208324\n",
      "Iteration: 6246/10000, Loss: 0.014014558866620064\n",
      "Iteration: 6247/10000, Loss: 0.012238295748829842\n",
      "Iteration: 6248/10000, Loss: 0.012380938045680523\n",
      "Iteration: 6249/10000, Loss: 0.01510806567966938\n",
      "Iteration: 6250/10000, Loss: 0.01149225514382124\n",
      "Iteration: 6251/10000, Loss: 0.01219849195331335\n",
      "Iteration: 6252/10000, Loss: 0.011468613520264626\n",
      "Iteration: 6253/10000, Loss: 0.01618105173110962\n",
      "Iteration: 6254/10000, Loss: 0.011368753388524055\n",
      "Iteration: 6255/10000, Loss: 0.015222365967929363\n",
      "Iteration: 6256/10000, Loss: 0.013108029030263424\n",
      "Iteration: 6257/10000, Loss: 0.012603195384144783\n",
      "Iteration: 6258/10000, Loss: 0.012633460573852062\n",
      "Iteration: 6259/10000, Loss: 0.014496205374598503\n",
      "Iteration: 6260/10000, Loss: 0.009139131754636765\n",
      "Iteration: 6261/10000, Loss: 0.010653592646121979\n",
      "Iteration: 6262/10000, Loss: 0.012907668948173523\n",
      "Iteration: 6263/10000, Loss: 0.0145269725471735\n",
      "Iteration: 6264/10000, Loss: 0.012180395424365997\n",
      "Iteration: 6265/10000, Loss: 0.011621839366853237\n",
      "Iteration: 6266/10000, Loss: 0.008841211907565594\n",
      "Iteration: 6267/10000, Loss: 0.011568460613489151\n",
      "Iteration: 6268/10000, Loss: 0.007011867128312588\n",
      "Iteration: 6269/10000, Loss: 0.012169424444437027\n",
      "Iteration: 6270/10000, Loss: 0.015171026811003685\n",
      "Iteration: 6271/10000, Loss: 0.013272805139422417\n",
      "Iteration: 6272/10000, Loss: 0.01077826227992773\n",
      "Iteration: 6273/10000, Loss: 0.013165099546313286\n",
      "Iteration: 6274/10000, Loss: 0.006433529779314995\n",
      "Iteration: 6275/10000, Loss: 0.01798134855926037\n",
      "Iteration: 6276/10000, Loss: 0.01305844634771347\n",
      "Iteration: 6277/10000, Loss: 0.010385328903794289\n",
      "Iteration: 6278/10000, Loss: 0.017657214775681496\n",
      "Iteration: 6279/10000, Loss: 0.011338462121784687\n",
      "Iteration: 6280/10000, Loss: 0.008739855140447617\n",
      "Iteration: 6281/10000, Loss: 0.009428533725440502\n",
      "Iteration: 6282/10000, Loss: 0.007397398352622986\n",
      "Iteration: 6283/10000, Loss: 0.010021449998021126\n",
      "Iteration: 6284/10000, Loss: 0.007806327659636736\n",
      "Iteration: 6285/10000, Loss: 0.014750655740499496\n",
      "Iteration: 6286/10000, Loss: 0.011679318733513355\n",
      "Iteration: 6287/10000, Loss: 0.00912410020828247\n",
      "Iteration: 6288/10000, Loss: 0.010939931496977806\n",
      "Iteration: 6289/10000, Loss: 0.010805939324200153\n",
      "Iteration: 6290/10000, Loss: 0.010110678151249886\n",
      "Iteration: 6291/10000, Loss: 0.013094944879412651\n",
      "Iteration: 6292/10000, Loss: 0.012927954085171223\n",
      "Iteration: 6293/10000, Loss: 0.010846896097064018\n",
      "Iteration: 6294/10000, Loss: 0.01763952523469925\n",
      "Iteration: 6295/10000, Loss: 0.015004465356469154\n",
      "Iteration: 6296/10000, Loss: 0.013821533881127834\n",
      "Iteration: 6297/10000, Loss: 0.008738658390939236\n",
      "Iteration: 6298/10000, Loss: 0.01256515458226204\n",
      "Iteration: 6299/10000, Loss: 0.009362281300127506\n",
      "Iteration: 6300/10000, Loss: 0.006958405487239361\n",
      "Average test loss:  0.0014\n",
      "Iteration: 6301/10000, Loss: 0.014086293987929821\n",
      "Iteration: 6302/10000, Loss: 0.014164380729198456\n",
      "Iteration: 6303/10000, Loss: 0.01427325326949358\n",
      "Iteration: 6304/10000, Loss: 0.012253904715180397\n",
      "Iteration: 6305/10000, Loss: 0.01878359541296959\n",
      "Iteration: 6306/10000, Loss: 0.01314749475568533\n",
      "Iteration: 6307/10000, Loss: 0.007883706130087376\n",
      "Iteration: 6308/10000, Loss: 0.01384170912206173\n",
      "Iteration: 6309/10000, Loss: 0.00797215010970831\n",
      "Iteration: 6310/10000, Loss: 0.007343900855630636\n",
      "Iteration: 6311/10000, Loss: 0.010822310112416744\n",
      "Iteration: 6312/10000, Loss: 0.014323349110782146\n",
      "Iteration: 6313/10000, Loss: 0.010794403962790966\n",
      "Iteration: 6314/10000, Loss: 0.015369277447462082\n",
      "Iteration: 6315/10000, Loss: 0.013280108571052551\n",
      "Iteration: 6316/10000, Loss: 0.009417248889803886\n",
      "Iteration: 6317/10000, Loss: 0.013617162592709064\n",
      "Iteration: 6318/10000, Loss: 0.008544990792870522\n",
      "Iteration: 6319/10000, Loss: 0.010462604463100433\n",
      "Iteration: 6320/10000, Loss: 0.007462432142347097\n",
      "Iteration: 6321/10000, Loss: 0.01672760769724846\n",
      "Iteration: 6322/10000, Loss: 0.0101520586758852\n",
      "Iteration: 6323/10000, Loss: 0.008119726553559303\n",
      "Iteration: 6324/10000, Loss: 0.011516268365085125\n",
      "Iteration: 6325/10000, Loss: 0.005802032072097063\n",
      "Iteration: 6326/10000, Loss: 0.012006568722426891\n",
      "Iteration: 6327/10000, Loss: 0.011095917783677578\n",
      "Iteration: 6328/10000, Loss: 0.0113825099542737\n",
      "Iteration: 6329/10000, Loss: 0.015219279564917088\n",
      "Iteration: 6330/10000, Loss: 0.009343747980892658\n",
      "Iteration: 6331/10000, Loss: 0.00813870970159769\n",
      "Iteration: 6332/10000, Loss: 0.009095381014049053\n",
      "Iteration: 6333/10000, Loss: 0.011434938758611679\n",
      "Iteration: 6334/10000, Loss: 0.013828763738274574\n",
      "Iteration: 6335/10000, Loss: 0.011287965811789036\n",
      "Iteration: 6336/10000, Loss: 0.011534232646226883\n",
      "Iteration: 6337/10000, Loss: 0.011163380928337574\n",
      "Iteration: 6338/10000, Loss: 0.013224855996668339\n",
      "Iteration: 6339/10000, Loss: 0.012285499833524227\n",
      "Iteration: 6340/10000, Loss: 0.01463341061025858\n",
      "Iteration: 6341/10000, Loss: 0.013545617461204529\n",
      "Iteration: 6342/10000, Loss: 0.013836074620485306\n",
      "Iteration: 6343/10000, Loss: 0.01277745421975851\n",
      "Iteration: 6344/10000, Loss: 0.010482135228812695\n",
      "Iteration: 6345/10000, Loss: 0.01217839028686285\n",
      "Iteration: 6346/10000, Loss: 0.013293364085257053\n",
      "Iteration: 6347/10000, Loss: 0.015366721898317337\n",
      "Iteration: 6348/10000, Loss: 0.00801633857190609\n",
      "Iteration: 6349/10000, Loss: 0.010397501289844513\n",
      "Iteration: 6350/10000, Loss: 0.014211715199053288\n",
      "Iteration: 6351/10000, Loss: 0.006065090652555227\n",
      "Iteration: 6352/10000, Loss: 0.009239712730050087\n",
      "Iteration: 6353/10000, Loss: 0.013122660107910633\n",
      "Iteration: 6354/10000, Loss: 0.0146713275462389\n",
      "Iteration: 6355/10000, Loss: 0.00811457633972168\n",
      "Iteration: 6356/10000, Loss: 0.009898253716528416\n",
      "Iteration: 6357/10000, Loss: 0.010921177454292774\n",
      "Iteration: 6358/10000, Loss: 0.009671863168478012\n",
      "Iteration: 6359/10000, Loss: 0.00840647891163826\n",
      "Iteration: 6360/10000, Loss: 0.01063389703631401\n",
      "Iteration: 6361/10000, Loss: 0.009991493076086044\n",
      "Iteration: 6362/10000, Loss: 0.017249055206775665\n",
      "Iteration: 6363/10000, Loss: 0.010787934064865112\n",
      "Iteration: 6364/10000, Loss: 0.010488338768482208\n",
      "Iteration: 6365/10000, Loss: 0.007927162572741508\n",
      "Iteration: 6366/10000, Loss: 0.01487390510737896\n",
      "Iteration: 6367/10000, Loss: 0.010730918496847153\n",
      "Iteration: 6368/10000, Loss: 0.014183604158461094\n",
      "Iteration: 6369/10000, Loss: 0.009223747998476028\n",
      "Iteration: 6370/10000, Loss: 0.009376589208841324\n",
      "Iteration: 6371/10000, Loss: 0.015114877372980118\n",
      "Iteration: 6372/10000, Loss: 0.008758689276874065\n",
      "Iteration: 6373/10000, Loss: 0.01278206892311573\n",
      "Iteration: 6374/10000, Loss: 0.011683980002999306\n",
      "Iteration: 6375/10000, Loss: 0.010442530736327171\n",
      "Iteration: 6376/10000, Loss: 0.01903689280152321\n",
      "Iteration: 6377/10000, Loss: 0.012150385417044163\n",
      "Iteration: 6378/10000, Loss: 0.010959201492369175\n",
      "Iteration: 6379/10000, Loss: 0.011443579569458961\n",
      "Iteration: 6380/10000, Loss: 0.01466461643576622\n",
      "Iteration: 6381/10000, Loss: 0.015112970024347305\n",
      "Iteration: 6382/10000, Loss: 0.013517163693904877\n",
      "Iteration: 6383/10000, Loss: 0.011419914662837982\n",
      "Iteration: 6384/10000, Loss: 0.011737236753106117\n",
      "Iteration: 6385/10000, Loss: 0.008792486041784286\n",
      "Iteration: 6386/10000, Loss: 0.010341710411012173\n",
      "Iteration: 6387/10000, Loss: 0.012302501127123833\n",
      "Iteration: 6388/10000, Loss: 0.014188522472977638\n",
      "Iteration: 6389/10000, Loss: 0.012720164842903614\n",
      "Iteration: 6390/10000, Loss: 0.015391446650028229\n",
      "Iteration: 6391/10000, Loss: 0.011613125912845135\n",
      "Iteration: 6392/10000, Loss: 0.016037989407777786\n",
      "Iteration: 6393/10000, Loss: 0.012868848629295826\n",
      "Iteration: 6394/10000, Loss: 0.010403728112578392\n",
      "Iteration: 6395/10000, Loss: 0.01315777562558651\n",
      "Iteration: 6396/10000, Loss: 0.005831460002809763\n",
      "Iteration: 6397/10000, Loss: 0.015260658226907253\n",
      "Iteration: 6398/10000, Loss: 0.012600500136613846\n",
      "Iteration: 6399/10000, Loss: 0.011416628956794739\n",
      "Iteration: 6400/10000, Loss: 0.006841394118964672\n",
      "Average test loss:  0.0032\n",
      "Iteration: 6401/10000, Loss: 0.011779043823480606\n",
      "Iteration: 6402/10000, Loss: 0.011705158278346062\n",
      "Iteration: 6403/10000, Loss: 0.01044800691306591\n",
      "Iteration: 6404/10000, Loss: 0.014579609036445618\n",
      "Iteration: 6405/10000, Loss: 0.014294357970356941\n",
      "Iteration: 6406/10000, Loss: 0.021317901089787483\n",
      "Iteration: 6407/10000, Loss: 0.009097715839743614\n",
      "Iteration: 6408/10000, Loss: 0.009249935857951641\n",
      "Iteration: 6409/10000, Loss: 0.009054398164153099\n",
      "Iteration: 6410/10000, Loss: 0.01839062198996544\n",
      "Iteration: 6411/10000, Loss: 0.01318996213376522\n",
      "Iteration: 6412/10000, Loss: 0.006599721033126116\n",
      "Iteration: 6413/10000, Loss: 0.019091365858912468\n",
      "Iteration: 6414/10000, Loss: 0.0073462664149701595\n",
      "Iteration: 6415/10000, Loss: 0.012245407328009605\n",
      "Iteration: 6416/10000, Loss: 0.012738305144011974\n",
      "Iteration: 6417/10000, Loss: 0.01232568733394146\n",
      "Iteration: 6418/10000, Loss: 0.011626615189015865\n",
      "Iteration: 6419/10000, Loss: 0.010657334700226784\n",
      "Iteration: 6420/10000, Loss: 0.009821212850511074\n",
      "Iteration: 6421/10000, Loss: 0.019086703658103943\n",
      "Iteration: 6422/10000, Loss: 0.010252581909298897\n",
      "Iteration: 6423/10000, Loss: 0.013571438379585743\n",
      "Iteration: 6424/10000, Loss: 0.017843225970864296\n",
      "Iteration: 6425/10000, Loss: 0.012374815531075\n",
      "Iteration: 6426/10000, Loss: 0.01301520224660635\n",
      "Iteration: 6427/10000, Loss: 0.01153825968503952\n",
      "Iteration: 6428/10000, Loss: 0.017318278551101685\n",
      "Iteration: 6429/10000, Loss: 0.0149019630625844\n",
      "Iteration: 6430/10000, Loss: 0.003995105624198914\n",
      "Iteration: 6431/10000, Loss: 0.0126852011308074\n",
      "Iteration: 6432/10000, Loss: 0.011314010247588158\n",
      "Iteration: 6433/10000, Loss: 0.016649367287755013\n",
      "Iteration: 6434/10000, Loss: 0.015706077218055725\n",
      "Iteration: 6435/10000, Loss: 0.015778735280036926\n",
      "Iteration: 6436/10000, Loss: 0.015338451601564884\n",
      "Iteration: 6437/10000, Loss: 0.010633508674800396\n",
      "Iteration: 6438/10000, Loss: 0.009970758110284805\n",
      "Iteration: 6439/10000, Loss: 0.007931241765618324\n",
      "Iteration: 6440/10000, Loss: 0.012318400666117668\n",
      "Iteration: 6441/10000, Loss: 0.013281459920108318\n",
      "Iteration: 6442/10000, Loss: 0.010898621752858162\n",
      "Iteration: 6443/10000, Loss: 0.011575755663216114\n",
      "Iteration: 6444/10000, Loss: 0.0146767757833004\n",
      "Iteration: 6445/10000, Loss: 0.012383697554469109\n",
      "Iteration: 6446/10000, Loss: 0.008888090960681438\n",
      "Iteration: 6447/10000, Loss: 0.009932899847626686\n",
      "Iteration: 6448/10000, Loss: 0.011009487323462963\n",
      "Iteration: 6449/10000, Loss: 0.01507512666285038\n",
      "Iteration: 6450/10000, Loss: 0.013453250750899315\n",
      "Iteration: 6451/10000, Loss: 0.014327154494822025\n",
      "Iteration: 6452/10000, Loss: 0.01836898736655712\n",
      "Iteration: 6453/10000, Loss: 0.014333854429423809\n",
      "Iteration: 6454/10000, Loss: 0.015043695457279682\n",
      "Iteration: 6455/10000, Loss: 0.010912027209997177\n",
      "Iteration: 6456/10000, Loss: 0.00913205649703741\n",
      "Iteration: 6457/10000, Loss: 0.007656590081751347\n",
      "Iteration: 6458/10000, Loss: 0.013065574690699577\n",
      "Iteration: 6459/10000, Loss: 0.012942507863044739\n",
      "Iteration: 6460/10000, Loss: 0.010813761502504349\n",
      "Iteration: 6461/10000, Loss: 0.004383869469165802\n",
      "Iteration: 6462/10000, Loss: 0.011680240742862225\n",
      "Iteration: 6463/10000, Loss: 0.008841967210173607\n",
      "Iteration: 6464/10000, Loss: 0.015579448081552982\n",
      "Iteration: 6465/10000, Loss: 0.01429479569196701\n",
      "Iteration: 6466/10000, Loss: 0.01415139902383089\n",
      "Iteration: 6467/10000, Loss: 0.013772757723927498\n",
      "Iteration: 6468/10000, Loss: 0.006272119469940662\n",
      "Iteration: 6469/10000, Loss: 0.013751354068517685\n",
      "Iteration: 6470/10000, Loss: 0.013406882993876934\n",
      "Iteration: 6471/10000, Loss: 0.012099174782633781\n",
      "Iteration: 6472/10000, Loss: 0.017111804336309433\n",
      "Iteration: 6473/10000, Loss: 0.008829201571643353\n",
      "Iteration: 6474/10000, Loss: 0.014129015617072582\n",
      "Iteration: 6475/10000, Loss: 0.006083998829126358\n",
      "Iteration: 6476/10000, Loss: 0.01286791730672121\n",
      "Iteration: 6477/10000, Loss: 0.013661488890647888\n",
      "Iteration: 6478/10000, Loss: 0.005819751415401697\n",
      "Iteration: 6479/10000, Loss: 0.013119577430188656\n",
      "Iteration: 6480/10000, Loss: 0.012411732226610184\n",
      "Iteration: 6481/10000, Loss: 0.009641156531870365\n",
      "Iteration: 6482/10000, Loss: 0.011280074715614319\n",
      "Iteration: 6483/10000, Loss: 0.016071798279881477\n",
      "Iteration: 6484/10000, Loss: 0.013644931837916374\n",
      "Iteration: 6485/10000, Loss: 0.013846767134964466\n",
      "Iteration: 6486/10000, Loss: 0.01381270308047533\n",
      "Iteration: 6487/10000, Loss: 0.013289649970829487\n",
      "Iteration: 6488/10000, Loss: 0.012949928641319275\n",
      "Iteration: 6489/10000, Loss: 0.01298308465629816\n",
      "Iteration: 6490/10000, Loss: 0.012602697126567364\n",
      "Iteration: 6491/10000, Loss: 0.012212429195642471\n",
      "Iteration: 6492/10000, Loss: 0.013295036740601063\n",
      "Iteration: 6493/10000, Loss: 0.009779538959264755\n",
      "Iteration: 6494/10000, Loss: 0.011623437516391277\n",
      "Iteration: 6495/10000, Loss: 0.015947366133332253\n",
      "Iteration: 6496/10000, Loss: 0.007618993986397982\n",
      "Iteration: 6497/10000, Loss: 0.014151523821055889\n",
      "Iteration: 6498/10000, Loss: 0.008788318373262882\n",
      "Iteration: 6499/10000, Loss: 0.009364821948111057\n",
      "Iteration: 6500/10000, Loss: 0.014827952720224857\n",
      "Average test loss:  0.0018\n",
      "Iteration: 6501/10000, Loss: 0.009195484220981598\n",
      "Iteration: 6502/10000, Loss: 0.011703803203999996\n",
      "Iteration: 6503/10000, Loss: 0.010915754362940788\n",
      "Iteration: 6504/10000, Loss: 0.007992026396095753\n",
      "Iteration: 6505/10000, Loss: 0.018481530249118805\n",
      "Iteration: 6506/10000, Loss: 0.01733713038265705\n",
      "Iteration: 6507/10000, Loss: 0.00973957497626543\n",
      "Iteration: 6508/10000, Loss: 0.010261713527143002\n",
      "Iteration: 6509/10000, Loss: 0.006069709546864033\n",
      "Iteration: 6510/10000, Loss: 0.010569254867732525\n",
      "Iteration: 6511/10000, Loss: 0.013641380704939365\n",
      "Iteration: 6512/10000, Loss: 0.00929055642336607\n",
      "Iteration: 6513/10000, Loss: 0.013799900189042091\n",
      "Iteration: 6514/10000, Loss: 0.010984773747622967\n",
      "Iteration: 6515/10000, Loss: 0.012762336060404778\n",
      "Iteration: 6516/10000, Loss: 0.01435208972543478\n",
      "Iteration: 6517/10000, Loss: 0.010198591277003288\n",
      "Iteration: 6518/10000, Loss: 0.013211201876401901\n",
      "Iteration: 6519/10000, Loss: 0.010844889096915722\n",
      "Iteration: 6520/10000, Loss: 0.010885192081332207\n",
      "Iteration: 6521/10000, Loss: 0.012203417718410492\n",
      "Iteration: 6522/10000, Loss: 0.013648508116602898\n",
      "Iteration: 6523/10000, Loss: 0.01245688647031784\n",
      "Iteration: 6524/10000, Loss: 0.015258205123245716\n",
      "Iteration: 6525/10000, Loss: 0.007918066345155239\n",
      "Iteration: 6526/10000, Loss: 0.012504431419074535\n",
      "Iteration: 6527/10000, Loss: 0.011574058793485165\n",
      "Iteration: 6528/10000, Loss: 0.013591201975941658\n",
      "Iteration: 6529/10000, Loss: 0.01509131956845522\n",
      "Iteration: 6530/10000, Loss: 0.01262778602540493\n",
      "Iteration: 6531/10000, Loss: 0.009347512386739254\n",
      "Iteration: 6532/10000, Loss: 0.010222773998975754\n",
      "Iteration: 6533/10000, Loss: 0.012788801454007626\n",
      "Iteration: 6534/10000, Loss: 0.009908655658364296\n",
      "Iteration: 6535/10000, Loss: 0.012973988428711891\n",
      "Iteration: 6536/10000, Loss: 0.01252097450196743\n",
      "Iteration: 6537/10000, Loss: 0.010785815306007862\n",
      "Iteration: 6538/10000, Loss: 0.009965135715901852\n",
      "Iteration: 6539/10000, Loss: 0.015009504742920399\n",
      "Iteration: 6540/10000, Loss: 0.012365749105811119\n",
      "Iteration: 6541/10000, Loss: 0.01367934513837099\n",
      "Iteration: 6542/10000, Loss: 0.007786781061440706\n",
      "Iteration: 6543/10000, Loss: 0.012484588660299778\n",
      "Iteration: 6544/10000, Loss: 0.01150580309331417\n",
      "Iteration: 6545/10000, Loss: 0.013768593780696392\n",
      "Iteration: 6546/10000, Loss: 0.009677518159151077\n",
      "Iteration: 6547/10000, Loss: 0.013244188390672207\n",
      "Iteration: 6548/10000, Loss: 0.008735117502510548\n",
      "Iteration: 6549/10000, Loss: 0.01111885067075491\n",
      "Iteration: 6550/10000, Loss: 0.010605229996144772\n",
      "Iteration: 6551/10000, Loss: 0.0075118280947208405\n",
      "Iteration: 6552/10000, Loss: 0.008208993822336197\n",
      "Iteration: 6553/10000, Loss: 0.01239603292196989\n",
      "Iteration: 6554/10000, Loss: 0.009053491055965424\n",
      "Iteration: 6555/10000, Loss: 0.00904433336108923\n",
      "Iteration: 6556/10000, Loss: 0.009829353541135788\n",
      "Iteration: 6557/10000, Loss: 0.011329147964715958\n",
      "Iteration: 6558/10000, Loss: 0.01169177982956171\n",
      "Iteration: 6559/10000, Loss: 0.010994739830493927\n",
      "Iteration: 6560/10000, Loss: 0.00912344641983509\n",
      "Iteration: 6561/10000, Loss: 0.017045464366674423\n",
      "Iteration: 6562/10000, Loss: 0.014040118083357811\n",
      "Iteration: 6563/10000, Loss: 0.010339992120862007\n",
      "Iteration: 6564/10000, Loss: 0.014578328467905521\n",
      "Iteration: 6565/10000, Loss: 0.011443927884101868\n",
      "Iteration: 6566/10000, Loss: 0.012551610358059406\n",
      "Iteration: 6567/10000, Loss: 0.011739793233573437\n",
      "Iteration: 6568/10000, Loss: 0.011680688709020615\n",
      "Iteration: 6569/10000, Loss: 0.012763343751430511\n",
      "Iteration: 6570/10000, Loss: 0.00963900052011013\n",
      "Iteration: 6571/10000, Loss: 0.012366156093776226\n",
      "Iteration: 6572/10000, Loss: 0.014571172185242176\n",
      "Iteration: 6573/10000, Loss: 0.01401145476847887\n",
      "Iteration: 6574/10000, Loss: 0.012369945645332336\n",
      "Iteration: 6575/10000, Loss: 0.010070733726024628\n",
      "Iteration: 6576/10000, Loss: 0.014470201916992664\n",
      "Iteration: 6577/10000, Loss: 0.012320161797106266\n",
      "Iteration: 6578/10000, Loss: 0.012195617891848087\n",
      "Iteration: 6579/10000, Loss: 0.013043105602264404\n",
      "Iteration: 6580/10000, Loss: 0.018375257030129433\n",
      "Iteration: 6581/10000, Loss: 0.015556344762444496\n",
      "Iteration: 6582/10000, Loss: 0.009173018857836723\n",
      "Iteration: 6583/10000, Loss: 0.007860079407691956\n",
      "Iteration: 6584/10000, Loss: 0.014746515080332756\n",
      "Iteration: 6585/10000, Loss: 0.008578815497457981\n",
      "Iteration: 6586/10000, Loss: 0.010072434321045876\n",
      "Iteration: 6587/10000, Loss: 0.007055336609482765\n",
      "Iteration: 6588/10000, Loss: 0.01806947961449623\n",
      "Iteration: 6589/10000, Loss: 0.016116350889205933\n",
      "Iteration: 6590/10000, Loss: 0.016178073361516\n",
      "Iteration: 6591/10000, Loss: 0.011386902071535587\n",
      "Iteration: 6592/10000, Loss: 0.01081844512373209\n",
      "Iteration: 6593/10000, Loss: 0.008728411979973316\n",
      "Iteration: 6594/10000, Loss: 0.014017502777278423\n",
      "Iteration: 6595/10000, Loss: 0.013855266384780407\n",
      "Iteration: 6596/10000, Loss: 0.012487383559346199\n",
      "Iteration: 6597/10000, Loss: 0.015831006690859795\n",
      "Iteration: 6598/10000, Loss: 0.007151926402002573\n",
      "Iteration: 6599/10000, Loss: 0.012268383987247944\n",
      "Iteration: 6600/10000, Loss: 0.009650817140936852\n",
      "Average test loss:  0.0052\n",
      "Iteration: 6601/10000, Loss: 0.011022660881280899\n",
      "Iteration: 6602/10000, Loss: 0.010707600973546505\n",
      "Iteration: 6603/10000, Loss: 0.007268834859132767\n",
      "Iteration: 6604/10000, Loss: 0.01212838664650917\n",
      "Iteration: 6605/10000, Loss: 0.012387051247060299\n",
      "Iteration: 6606/10000, Loss: 0.015355347655713558\n",
      "Iteration: 6607/10000, Loss: 0.0090269073843956\n",
      "Iteration: 6608/10000, Loss: 0.013127410784363747\n",
      "Iteration: 6609/10000, Loss: 0.011306495405733585\n",
      "Iteration: 6610/10000, Loss: 0.01780608668923378\n",
      "Iteration: 6611/10000, Loss: 0.009048542007803917\n",
      "Iteration: 6612/10000, Loss: 0.016452336683869362\n",
      "Iteration: 6613/10000, Loss: 0.006674503907561302\n",
      "Iteration: 6614/10000, Loss: 0.014875956811010838\n",
      "Iteration: 6615/10000, Loss: 0.009366536512970924\n",
      "Iteration: 6616/10000, Loss: 0.008644339628517628\n",
      "Iteration: 6617/10000, Loss: 0.011299923062324524\n",
      "Iteration: 6618/10000, Loss: 0.009632943198084831\n",
      "Iteration: 6619/10000, Loss: 0.011450866237282753\n",
      "Iteration: 6620/10000, Loss: 0.012192096561193466\n",
      "Iteration: 6621/10000, Loss: 0.009966184385120869\n",
      "Iteration: 6622/10000, Loss: 0.010204321704804897\n",
      "Iteration: 6623/10000, Loss: 0.00836638268083334\n",
      "Iteration: 6624/10000, Loss: 0.013066655956208706\n",
      "Iteration: 6625/10000, Loss: 0.00955220963805914\n",
      "Iteration: 6626/10000, Loss: 0.008886805735528469\n",
      "Iteration: 6627/10000, Loss: 0.015079070813953876\n",
      "Iteration: 6628/10000, Loss: 0.008935804478824139\n",
      "Iteration: 6629/10000, Loss: 0.009653575718402863\n",
      "Iteration: 6630/10000, Loss: 0.009555983357131481\n",
      "Iteration: 6631/10000, Loss: 0.011181407608091831\n",
      "Iteration: 6632/10000, Loss: 0.01256899069994688\n",
      "Iteration: 6633/10000, Loss: 0.013854477554559708\n",
      "Iteration: 6634/10000, Loss: 0.010608180426061153\n",
      "Iteration: 6635/10000, Loss: 0.014412188902497292\n",
      "Iteration: 6636/10000, Loss: 0.01266627386212349\n",
      "Iteration: 6637/10000, Loss: 0.014744436368346214\n",
      "Iteration: 6638/10000, Loss: 0.013953834772109985\n",
      "Iteration: 6639/10000, Loss: 0.008269179612398148\n",
      "Iteration: 6640/10000, Loss: 0.011621021665632725\n",
      "Iteration: 6641/10000, Loss: 0.00902768038213253\n",
      "Iteration: 6642/10000, Loss: 0.008861435577273369\n",
      "Iteration: 6643/10000, Loss: 0.014529815874993801\n",
      "Iteration: 6644/10000, Loss: 0.012862658128142357\n",
      "Iteration: 6645/10000, Loss: 0.011513006873428822\n",
      "Iteration: 6646/10000, Loss: 0.008429579436779022\n",
      "Iteration: 6647/10000, Loss: 0.010109983384609222\n",
      "Iteration: 6648/10000, Loss: 0.009975474327802658\n",
      "Iteration: 6649/10000, Loss: 0.009885893203318119\n",
      "Iteration: 6650/10000, Loss: 0.008669786155223846\n",
      "Iteration: 6651/10000, Loss: 0.010512782260775566\n",
      "Iteration: 6652/10000, Loss: 0.011984078213572502\n",
      "Iteration: 6653/10000, Loss: 0.01176956482231617\n",
      "Iteration: 6654/10000, Loss: 0.009366145357489586\n",
      "Iteration: 6655/10000, Loss: 0.016055326908826828\n",
      "Iteration: 6656/10000, Loss: 0.011526480317115784\n",
      "Iteration: 6657/10000, Loss: 0.013222889043390751\n",
      "Iteration: 6658/10000, Loss: 0.01456379983574152\n",
      "Iteration: 6659/10000, Loss: 0.012492126785218716\n",
      "Iteration: 6660/10000, Loss: 0.01391482912003994\n",
      "Iteration: 6661/10000, Loss: 0.008915631100535393\n",
      "Iteration: 6662/10000, Loss: 0.015483389608561993\n",
      "Iteration: 6663/10000, Loss: 0.008458313532173634\n",
      "Iteration: 6664/10000, Loss: 0.010675479657948017\n",
      "Iteration: 6665/10000, Loss: 0.013949944637715816\n",
      "Iteration: 6666/10000, Loss: 0.010761554352939129\n",
      "Iteration: 6667/10000, Loss: 0.012452316470444202\n",
      "Iteration: 6668/10000, Loss: 0.010195054113864899\n",
      "Iteration: 6669/10000, Loss: 0.011171652935445309\n",
      "Iteration: 6670/10000, Loss: 0.014477401971817017\n",
      "Iteration: 6671/10000, Loss: 0.009682844392955303\n",
      "Iteration: 6672/10000, Loss: 0.011633872985839844\n",
      "Iteration: 6673/10000, Loss: 0.009001651778817177\n",
      "Iteration: 6674/10000, Loss: 0.012521995231509209\n",
      "Iteration: 6675/10000, Loss: 0.007503707893192768\n",
      "Iteration: 6676/10000, Loss: 0.013960761949419975\n",
      "Iteration: 6677/10000, Loss: 0.007312912493944168\n",
      "Iteration: 6678/10000, Loss: 0.010824421420693398\n",
      "Iteration: 6679/10000, Loss: 0.011641754768788815\n",
      "Iteration: 6680/10000, Loss: 0.013090165331959724\n",
      "Iteration: 6681/10000, Loss: 0.014123654924333096\n",
      "Iteration: 6682/10000, Loss: 0.016351616010069847\n",
      "Iteration: 6683/10000, Loss: 0.011322155594825745\n",
      "Iteration: 6684/10000, Loss: 0.018085073679685593\n",
      "Iteration: 6685/10000, Loss: 0.010455864481627941\n",
      "Iteration: 6686/10000, Loss: 0.015261395834386349\n",
      "Iteration: 6687/10000, Loss: 0.0076587307266891\n",
      "Iteration: 6688/10000, Loss: 0.011592782102525234\n",
      "Iteration: 6689/10000, Loss: 0.01686231978237629\n",
      "Iteration: 6690/10000, Loss: 0.012608488090336323\n",
      "Iteration: 6691/10000, Loss: 0.012790482491254807\n",
      "Iteration: 6692/10000, Loss: 0.02256850153207779\n",
      "Iteration: 6693/10000, Loss: 0.011553111486136913\n",
      "Iteration: 6694/10000, Loss: 0.007457138504832983\n",
      "Iteration: 6695/10000, Loss: 0.0077606746926903725\n",
      "Iteration: 6696/10000, Loss: 0.020987067371606827\n",
      "Iteration: 6697/10000, Loss: 0.013433747924864292\n",
      "Iteration: 6698/10000, Loss: 0.010857222601771355\n",
      "Iteration: 6699/10000, Loss: 0.015383494086563587\n",
      "Iteration: 6700/10000, Loss: 0.01677055098116398\n",
      "Average test loss:  0.0039\n",
      "Iteration: 6701/10000, Loss: 0.012086465954780579\n",
      "Iteration: 6702/10000, Loss: 0.011980989016592503\n",
      "Iteration: 6703/10000, Loss: 0.010809192433953285\n",
      "Iteration: 6704/10000, Loss: 0.009492157027125359\n",
      "Iteration: 6705/10000, Loss: 0.010577128268778324\n",
      "Iteration: 6706/10000, Loss: 0.0110265351831913\n",
      "Iteration: 6707/10000, Loss: 0.010766549035906792\n",
      "Iteration: 6708/10000, Loss: 0.010403113439679146\n",
      "Iteration: 6709/10000, Loss: 0.010794484056532383\n",
      "Iteration: 6710/10000, Loss: 0.013280568644404411\n",
      "Iteration: 6711/10000, Loss: 0.012372476980090141\n",
      "Iteration: 6712/10000, Loss: 0.012052240781486034\n",
      "Iteration: 6713/10000, Loss: 0.016044575721025467\n",
      "Iteration: 6714/10000, Loss: 0.018063001334667206\n",
      "Iteration: 6715/10000, Loss: 0.013326526619493961\n",
      "Iteration: 6716/10000, Loss: 0.010875402018427849\n",
      "Iteration: 6717/10000, Loss: 0.006944776512682438\n",
      "Iteration: 6718/10000, Loss: 0.015183703042566776\n",
      "Iteration: 6719/10000, Loss: 0.010844811797142029\n",
      "Iteration: 6720/10000, Loss: 0.015372694469988346\n",
      "Iteration: 6721/10000, Loss: 0.013663606718182564\n",
      "Iteration: 6722/10000, Loss: 0.010647907853126526\n",
      "Iteration: 6723/10000, Loss: 0.017996927723288536\n",
      "Iteration: 6724/10000, Loss: 0.008830620907247066\n",
      "Iteration: 6725/10000, Loss: 0.01085270382463932\n",
      "Iteration: 6726/10000, Loss: 0.01242564432322979\n",
      "Iteration: 6727/10000, Loss: 0.008883094415068626\n",
      "Iteration: 6728/10000, Loss: 0.006399382837116718\n",
      "Iteration: 6729/10000, Loss: 0.01295657642185688\n",
      "Iteration: 6730/10000, Loss: 0.010056689381599426\n",
      "Iteration: 6731/10000, Loss: 0.007350710686296225\n",
      "Iteration: 6732/10000, Loss: 0.010729105211794376\n",
      "Iteration: 6733/10000, Loss: 0.013922109268605709\n",
      "Iteration: 6734/10000, Loss: 0.009792963042855263\n",
      "Iteration: 6735/10000, Loss: 0.009255081415176392\n",
      "Iteration: 6736/10000, Loss: 0.012777191586792469\n",
      "Iteration: 6737/10000, Loss: 0.011790549382567406\n",
      "Iteration: 6738/10000, Loss: 0.01115802675485611\n",
      "Iteration: 6739/10000, Loss: 0.012964299879968166\n",
      "Iteration: 6740/10000, Loss: 0.013963327743113041\n",
      "Iteration: 6741/10000, Loss: 0.01137254573404789\n",
      "Iteration: 6742/10000, Loss: 0.006791107356548309\n",
      "Iteration: 6743/10000, Loss: 0.010608985088765621\n",
      "Iteration: 6744/10000, Loss: 0.011159693822264671\n",
      "Iteration: 6745/10000, Loss: 0.010328955017030239\n",
      "Iteration: 6746/10000, Loss: 0.01259651593863964\n",
      "Iteration: 6747/10000, Loss: 0.01517415139824152\n",
      "Iteration: 6748/10000, Loss: 0.009916303679347038\n",
      "Iteration: 6749/10000, Loss: 0.01682414673268795\n",
      "Iteration: 6750/10000, Loss: 0.01010455098003149\n",
      "Iteration: 6751/10000, Loss: 0.00926157459616661\n",
      "Iteration: 6752/10000, Loss: 0.011720848269760609\n",
      "Iteration: 6753/10000, Loss: 0.014781821519136429\n",
      "Iteration: 6754/10000, Loss: 0.010538837872445583\n",
      "Iteration: 6755/10000, Loss: 0.01606897823512554\n",
      "Iteration: 6756/10000, Loss: 0.01501395646482706\n",
      "Iteration: 6757/10000, Loss: 0.007055062800645828\n",
      "Iteration: 6758/10000, Loss: 0.008921734057366848\n",
      "Iteration: 6759/10000, Loss: 0.012941236607730389\n",
      "Iteration: 6760/10000, Loss: 0.010481218807399273\n",
      "Iteration: 6761/10000, Loss: 0.011654145084321499\n",
      "Iteration: 6762/10000, Loss: 0.012156723067164421\n",
      "Iteration: 6763/10000, Loss: 0.006876921281218529\n",
      "Iteration: 6764/10000, Loss: 0.017386768013238907\n",
      "Iteration: 6765/10000, Loss: 0.01368054747581482\n",
      "Iteration: 6766/10000, Loss: 0.011479715816676617\n",
      "Iteration: 6767/10000, Loss: 0.011133456602692604\n",
      "Iteration: 6768/10000, Loss: 0.009076305665075779\n",
      "Iteration: 6769/10000, Loss: 0.01403709128499031\n",
      "Iteration: 6770/10000, Loss: 0.01436292752623558\n",
      "Iteration: 6771/10000, Loss: 0.00716428505256772\n",
      "Iteration: 6772/10000, Loss: 0.011946044862270355\n",
      "Iteration: 6773/10000, Loss: 0.010183527134358883\n",
      "Iteration: 6774/10000, Loss: 0.015472212806344032\n",
      "Iteration: 6775/10000, Loss: 0.009123209863901138\n",
      "Iteration: 6776/10000, Loss: 0.01262732595205307\n",
      "Iteration: 6777/10000, Loss: 0.0150447404012084\n",
      "Iteration: 6778/10000, Loss: 0.011334325186908245\n",
      "Iteration: 6779/10000, Loss: 0.012763964012265205\n",
      "Iteration: 6780/10000, Loss: 0.010973578318953514\n",
      "Iteration: 6781/10000, Loss: 0.010824302211403847\n",
      "Iteration: 6782/10000, Loss: 0.010587210766971111\n",
      "Iteration: 6783/10000, Loss: 0.010903578251600266\n",
      "Iteration: 6784/10000, Loss: 0.008720096200704575\n",
      "Iteration: 6785/10000, Loss: 0.010278087109327316\n",
      "Iteration: 6786/10000, Loss: 0.013349385932087898\n",
      "Iteration: 6787/10000, Loss: 0.01069000456482172\n",
      "Iteration: 6788/10000, Loss: 0.00859229825437069\n",
      "Iteration: 6789/10000, Loss: 0.008131926879286766\n",
      "Iteration: 6790/10000, Loss: 0.008303963579237461\n",
      "Iteration: 6791/10000, Loss: 0.008505009114742279\n",
      "Iteration: 6792/10000, Loss: 0.0069711050018668175\n",
      "Iteration: 6793/10000, Loss: 0.01280804444104433\n",
      "Iteration: 6794/10000, Loss: 0.010587691329419613\n",
      "Iteration: 6795/10000, Loss: 0.005660450551658869\n",
      "Iteration: 6796/10000, Loss: 0.009327133186161518\n",
      "Iteration: 6797/10000, Loss: 0.013827484101057053\n",
      "Iteration: 6798/10000, Loss: 0.014021636918187141\n",
      "Iteration: 6799/10000, Loss: 0.013426210731267929\n",
      "Iteration: 6800/10000, Loss: 0.012882708571851254\n",
      "Average test loss:  0.0019\n",
      "Iteration: 6801/10000, Loss: 0.013933172449469566\n",
      "Iteration: 6802/10000, Loss: 0.010030658915638924\n",
      "Iteration: 6803/10000, Loss: 0.01161712221801281\n",
      "Iteration: 6804/10000, Loss: 0.008577105589210987\n",
      "Iteration: 6805/10000, Loss: 0.011148243211209774\n",
      "Iteration: 6806/10000, Loss: 0.006821578834205866\n",
      "Iteration: 6807/10000, Loss: 0.008970402181148529\n",
      "Iteration: 6808/10000, Loss: 0.01081917341798544\n",
      "Iteration: 6809/10000, Loss: 0.01467203814536333\n",
      "Iteration: 6810/10000, Loss: 0.01084846630692482\n",
      "Iteration: 6811/10000, Loss: 0.012281502597033978\n",
      "Iteration: 6812/10000, Loss: 0.009961872361600399\n",
      "Iteration: 6813/10000, Loss: 0.011494711972773075\n",
      "Iteration: 6814/10000, Loss: 0.016841353848576546\n",
      "Iteration: 6815/10000, Loss: 0.010165532119572163\n",
      "Iteration: 6816/10000, Loss: 0.01362726092338562\n",
      "Iteration: 6817/10000, Loss: 0.011196430772542953\n",
      "Iteration: 6818/10000, Loss: 0.012737586162984371\n",
      "Iteration: 6819/10000, Loss: 0.008894763886928558\n",
      "Iteration: 6820/10000, Loss: 0.01655721105635166\n",
      "Iteration: 6821/10000, Loss: 0.02135700359940529\n",
      "Iteration: 6822/10000, Loss: 0.013673985376954079\n",
      "Iteration: 6823/10000, Loss: 0.010154698975384235\n",
      "Iteration: 6824/10000, Loss: 0.009155941195786\n",
      "Iteration: 6825/10000, Loss: 0.010054081678390503\n",
      "Iteration: 6826/10000, Loss: 0.011605667881667614\n",
      "Iteration: 6827/10000, Loss: 0.015714462846517563\n",
      "Iteration: 6828/10000, Loss: 0.007876229472458363\n",
      "Iteration: 6829/10000, Loss: 0.014071864075958729\n",
      "Iteration: 6830/10000, Loss: 0.006258834153413773\n",
      "Iteration: 6831/10000, Loss: 0.00932379998266697\n",
      "Iteration: 6832/10000, Loss: 0.016560377553105354\n",
      "Iteration: 6833/10000, Loss: 0.01438617892563343\n",
      "Iteration: 6834/10000, Loss: 0.011708819307386875\n",
      "Iteration: 6835/10000, Loss: 0.009867276065051556\n",
      "Iteration: 6836/10000, Loss: 0.013478442095220089\n",
      "Iteration: 6837/10000, Loss: 0.013781808316707611\n",
      "Iteration: 6838/10000, Loss: 0.00750053720548749\n",
      "Iteration: 6839/10000, Loss: 0.013952121138572693\n",
      "Iteration: 6840/10000, Loss: 0.011985701508820057\n",
      "Iteration: 6841/10000, Loss: 0.017016148194670677\n",
      "Iteration: 6842/10000, Loss: 0.006951102986931801\n",
      "Iteration: 6843/10000, Loss: 0.01034784596413374\n",
      "Iteration: 6844/10000, Loss: 0.009525708854198456\n",
      "Iteration: 6845/10000, Loss: 0.011332361027598381\n",
      "Iteration: 6846/10000, Loss: 0.015048249624669552\n",
      "Iteration: 6847/10000, Loss: 0.014529694803059101\n",
      "Iteration: 6848/10000, Loss: 0.009277313016355038\n",
      "Iteration: 6849/10000, Loss: 0.012047260999679565\n",
      "Iteration: 6850/10000, Loss: 0.011639797128736973\n",
      "Iteration: 6851/10000, Loss: 0.011254518292844296\n",
      "Iteration: 6852/10000, Loss: 0.010605860501527786\n",
      "Iteration: 6853/10000, Loss: 0.006752575282007456\n",
      "Iteration: 6854/10000, Loss: 0.01303047314286232\n",
      "Iteration: 6855/10000, Loss: 0.015182812698185444\n",
      "Iteration: 6856/10000, Loss: 0.0077073839493095875\n",
      "Iteration: 6857/10000, Loss: 0.010948962531983852\n",
      "Iteration: 6858/10000, Loss: 0.013213551603257656\n",
      "Iteration: 6859/10000, Loss: 0.010482712648808956\n",
      "Iteration: 6860/10000, Loss: 0.01413759309798479\n",
      "Iteration: 6861/10000, Loss: 0.014093616046011448\n",
      "Iteration: 6862/10000, Loss: 0.016954787075519562\n",
      "Iteration: 6863/10000, Loss: 0.009134314954280853\n",
      "Iteration: 6864/10000, Loss: 0.007620129734277725\n",
      "Iteration: 6865/10000, Loss: 0.008587547577917576\n",
      "Iteration: 6866/10000, Loss: 0.016446450725197792\n",
      "Iteration: 6867/10000, Loss: 0.014192897826433182\n",
      "Iteration: 6868/10000, Loss: 0.01272346917539835\n",
      "Iteration: 6869/10000, Loss: 0.012385901995003223\n",
      "Iteration: 6870/10000, Loss: 0.007169787771999836\n",
      "Iteration: 6871/10000, Loss: 0.011266753077507019\n",
      "Iteration: 6872/10000, Loss: 0.009370344690978527\n",
      "Iteration: 6873/10000, Loss: 0.0111111830919981\n",
      "Iteration: 6874/10000, Loss: 0.014470132999122143\n",
      "Iteration: 6875/10000, Loss: 0.009469477459788322\n",
      "Iteration: 6876/10000, Loss: 0.011863959021866322\n",
      "Iteration: 6877/10000, Loss: 0.007824700325727463\n",
      "Iteration: 6878/10000, Loss: 0.015349326655268669\n",
      "Iteration: 6879/10000, Loss: 0.013951701112091541\n",
      "Iteration: 6880/10000, Loss: 0.009478776715695858\n",
      "Iteration: 6881/10000, Loss: 0.017420094460248947\n",
      "Iteration: 6882/10000, Loss: 0.013856911100447178\n",
      "Iteration: 6883/10000, Loss: 0.006161619443446398\n",
      "Iteration: 6884/10000, Loss: 0.012401175685226917\n",
      "Iteration: 6885/10000, Loss: 0.008236686699092388\n",
      "Iteration: 6886/10000, Loss: 0.01184447668492794\n",
      "Iteration: 6887/10000, Loss: 0.007858427241444588\n",
      "Iteration: 6888/10000, Loss: 0.014617149718105793\n",
      "Iteration: 6889/10000, Loss: 0.01029204297810793\n",
      "Iteration: 6890/10000, Loss: 0.009435856714844704\n",
      "Iteration: 6891/10000, Loss: 0.01071078423410654\n",
      "Iteration: 6892/10000, Loss: 0.009255042299628258\n",
      "Iteration: 6893/10000, Loss: 0.015159707516431808\n",
      "Iteration: 6894/10000, Loss: 0.008054142817854881\n",
      "Iteration: 6895/10000, Loss: 0.017176106572151184\n",
      "Iteration: 6896/10000, Loss: 0.011815437115728855\n",
      "Iteration: 6897/10000, Loss: 0.012883025221526623\n",
      "Iteration: 6898/10000, Loss: 0.015252596698701382\n",
      "Iteration: 6899/10000, Loss: 0.0129553759470582\n",
      "Iteration: 6900/10000, Loss: 0.014633040875196457\n",
      "Average test loss:  0.0035\n",
      "Iteration: 6901/10000, Loss: 0.011684916913509369\n",
      "Iteration: 6902/10000, Loss: 0.011656247079372406\n",
      "Iteration: 6903/10000, Loss: 0.009080834686756134\n",
      "Iteration: 6904/10000, Loss: 0.009119782596826553\n",
      "Iteration: 6905/10000, Loss: 0.011783863417804241\n",
      "Iteration: 6906/10000, Loss: 0.009356336668133736\n",
      "Iteration: 6907/10000, Loss: 0.012197589501738548\n",
      "Iteration: 6908/10000, Loss: 0.01932002790272236\n",
      "Iteration: 6909/10000, Loss: 0.006150510627776384\n",
      "Iteration: 6910/10000, Loss: 0.011190788820385933\n",
      "Iteration: 6911/10000, Loss: 0.009299235418438911\n",
      "Iteration: 6912/10000, Loss: 0.010055659338831902\n",
      "Iteration: 6913/10000, Loss: 0.02054421603679657\n",
      "Iteration: 6914/10000, Loss: 0.009990478865802288\n",
      "Iteration: 6915/10000, Loss: 0.017603730782866478\n",
      "Iteration: 6916/10000, Loss: 0.010396376252174377\n",
      "Iteration: 6917/10000, Loss: 0.007664298173040152\n",
      "Iteration: 6918/10000, Loss: 0.011123613454401493\n",
      "Iteration: 6919/10000, Loss: 0.006690134294331074\n",
      "Iteration: 6920/10000, Loss: 0.012045522220432758\n",
      "Iteration: 6921/10000, Loss: 0.01076464168727398\n",
      "Iteration: 6922/10000, Loss: 0.009423532523214817\n",
      "Iteration: 6923/10000, Loss: 0.012565490789711475\n",
      "Iteration: 6924/10000, Loss: 0.007040876895189285\n",
      "Iteration: 6925/10000, Loss: 0.013037287630140781\n",
      "Iteration: 6926/10000, Loss: 0.007872390560805798\n",
      "Iteration: 6927/10000, Loss: 0.00984642282128334\n",
      "Iteration: 6928/10000, Loss: 0.011461573652923107\n",
      "Iteration: 6929/10000, Loss: 0.00718033267185092\n",
      "Iteration: 6930/10000, Loss: 0.011406435631215572\n",
      "Iteration: 6931/10000, Loss: 0.009413952939212322\n",
      "Iteration: 6932/10000, Loss: 0.01367238163948059\n",
      "Iteration: 6933/10000, Loss: 0.007920589298009872\n",
      "Iteration: 6934/10000, Loss: 0.011300473473966122\n",
      "Iteration: 6935/10000, Loss: 0.0097439493983984\n",
      "Iteration: 6936/10000, Loss: 0.007905666716396809\n",
      "Iteration: 6937/10000, Loss: 0.007743912283331156\n",
      "Iteration: 6938/10000, Loss: 0.007834385149180889\n",
      "Iteration: 6939/10000, Loss: 0.009061172604560852\n",
      "Iteration: 6940/10000, Loss: 0.011558208614587784\n",
      "Iteration: 6941/10000, Loss: 0.016731513664126396\n",
      "Iteration: 6942/10000, Loss: 0.014463922940194607\n",
      "Iteration: 6943/10000, Loss: 0.011842642910778522\n",
      "Iteration: 6944/10000, Loss: 0.013870844617486\n",
      "Iteration: 6945/10000, Loss: 0.009959281422197819\n",
      "Iteration: 6946/10000, Loss: 0.011376865208148956\n",
      "Iteration: 6947/10000, Loss: 0.010458515956997871\n",
      "Iteration: 6948/10000, Loss: 0.011220598593354225\n",
      "Iteration: 6949/10000, Loss: 0.017335759475827217\n",
      "Iteration: 6950/10000, Loss: 0.017974404618144035\n",
      "Iteration: 6951/10000, Loss: 0.011480680666863918\n",
      "Iteration: 6952/10000, Loss: 0.014298297464847565\n",
      "Iteration: 6953/10000, Loss: 0.009915836155414581\n",
      "Iteration: 6954/10000, Loss: 0.015604998916387558\n",
      "Iteration: 6955/10000, Loss: 0.011950748972594738\n",
      "Iteration: 6956/10000, Loss: 0.00892497505992651\n",
      "Iteration: 6957/10000, Loss: 0.0062002274207770824\n",
      "Iteration: 6958/10000, Loss: 0.011723020114004612\n",
      "Iteration: 6959/10000, Loss: 0.008395863696932793\n",
      "Iteration: 6960/10000, Loss: 0.011852259747684002\n",
      "Iteration: 6961/10000, Loss: 0.014369902200996876\n",
      "Iteration: 6962/10000, Loss: 0.012701933272182941\n",
      "Iteration: 6963/10000, Loss: 0.011815972626209259\n",
      "Iteration: 6964/10000, Loss: 0.010331869125366211\n",
      "Iteration: 6965/10000, Loss: 0.007293834816664457\n",
      "Iteration: 6966/10000, Loss: 0.008147087879478931\n",
      "Iteration: 6967/10000, Loss: 0.015731878578662872\n",
      "Iteration: 6968/10000, Loss: 0.010333690792322159\n",
      "Iteration: 6969/10000, Loss: 0.011214958503842354\n",
      "Iteration: 6970/10000, Loss: 0.01451063808053732\n",
      "Iteration: 6971/10000, Loss: 0.01316158752888441\n",
      "Iteration: 6972/10000, Loss: 0.007006966043263674\n",
      "Iteration: 6973/10000, Loss: 0.011319851502776146\n",
      "Iteration: 6974/10000, Loss: 0.008966743014752865\n",
      "Iteration: 6975/10000, Loss: 0.014122136868536472\n",
      "Iteration: 6976/10000, Loss: 0.013416700065135956\n",
      "Iteration: 6977/10000, Loss: 0.0125619200989604\n",
      "Iteration: 6978/10000, Loss: 0.012534725479781628\n",
      "Iteration: 6979/10000, Loss: 0.0056954859755933285\n",
      "Iteration: 6980/10000, Loss: 0.019150732085108757\n",
      "Iteration: 6981/10000, Loss: 0.009172710590064526\n",
      "Iteration: 6982/10000, Loss: 0.010928272269666195\n",
      "Iteration: 6983/10000, Loss: 0.007029245607554913\n",
      "Iteration: 6984/10000, Loss: 0.009637251496315002\n",
      "Iteration: 6985/10000, Loss: 0.015081350691616535\n",
      "Iteration: 6986/10000, Loss: 0.011234058067202568\n",
      "Iteration: 6987/10000, Loss: 0.014925369992852211\n",
      "Iteration: 6988/10000, Loss: 0.01296615693718195\n",
      "Iteration: 6989/10000, Loss: 0.006828527897596359\n",
      "Iteration: 6990/10000, Loss: 0.010592634789645672\n",
      "Iteration: 6991/10000, Loss: 0.006133748684078455\n",
      "Iteration: 6992/10000, Loss: 0.014565478079020977\n",
      "Iteration: 6993/10000, Loss: 0.00937576312571764\n",
      "Iteration: 6994/10000, Loss: 0.009177456609904766\n",
      "Iteration: 6995/10000, Loss: 0.009270546026527882\n",
      "Iteration: 6996/10000, Loss: 0.014291086234152317\n",
      "Iteration: 6997/10000, Loss: 0.014324626885354519\n",
      "Iteration: 6998/10000, Loss: 0.008965620771050453\n",
      "Iteration: 6999/10000, Loss: 0.01496069971472025\n",
      "Iteration: 7000/10000, Loss: 0.009982663206756115\n",
      "Average test loss:  0.0030\n",
      "Iteration: 7001/10000, Loss: 0.009471871890127659\n",
      "Iteration: 7002/10000, Loss: 0.007800797000527382\n",
      "Iteration: 7003/10000, Loss: 0.01573229767382145\n",
      "Iteration: 7004/10000, Loss: 0.012978855520486832\n",
      "Iteration: 7005/10000, Loss: 0.010031875222921371\n",
      "Iteration: 7006/10000, Loss: 0.015389440581202507\n",
      "Iteration: 7007/10000, Loss: 0.005936070345342159\n",
      "Iteration: 7008/10000, Loss: 0.010365341790020466\n",
      "Iteration: 7009/10000, Loss: 0.010915158316493034\n",
      "Iteration: 7010/10000, Loss: 0.012469109147787094\n",
      "Iteration: 7011/10000, Loss: 0.011297172866761684\n",
      "Iteration: 7012/10000, Loss: 0.009188074618577957\n",
      "Iteration: 7013/10000, Loss: 0.00961567647755146\n",
      "Iteration: 7014/10000, Loss: 0.008622969500720501\n",
      "Iteration: 7015/10000, Loss: 0.01584487035870552\n",
      "Iteration: 7016/10000, Loss: 0.00912146270275116\n",
      "Iteration: 7017/10000, Loss: 0.009438575245440006\n",
      "Iteration: 7018/10000, Loss: 0.005885147489607334\n",
      "Iteration: 7019/10000, Loss: 0.011894802562892437\n",
      "Iteration: 7020/10000, Loss: 0.016014112159609795\n",
      "Iteration: 7021/10000, Loss: 0.013620128855109215\n",
      "Iteration: 7022/10000, Loss: 0.010221146047115326\n",
      "Iteration: 7023/10000, Loss: 0.01348192524164915\n",
      "Iteration: 7024/10000, Loss: 0.012761803343892097\n",
      "Iteration: 7025/10000, Loss: 0.012492090463638306\n",
      "Iteration: 7026/10000, Loss: 0.013635621406137943\n",
      "Iteration: 7027/10000, Loss: 0.01136690005660057\n",
      "Iteration: 7028/10000, Loss: 0.012696143239736557\n",
      "Iteration: 7029/10000, Loss: 0.013898740522563457\n",
      "Iteration: 7030/10000, Loss: 0.010011887177824974\n",
      "Iteration: 7031/10000, Loss: 0.011666848324239254\n",
      "Iteration: 7032/10000, Loss: 0.010552582331001759\n",
      "Iteration: 7033/10000, Loss: 0.00997911673039198\n",
      "Iteration: 7034/10000, Loss: 0.011866617016494274\n",
      "Iteration: 7035/10000, Loss: 0.014424281194806099\n",
      "Iteration: 7036/10000, Loss: 0.008878692053258419\n",
      "Iteration: 7037/10000, Loss: 0.0097488509491086\n",
      "Iteration: 7038/10000, Loss: 0.010784127749502659\n",
      "Iteration: 7039/10000, Loss: 0.008246833458542824\n",
      "Iteration: 7040/10000, Loss: 0.01649247482419014\n",
      "Iteration: 7041/10000, Loss: 0.00845216866582632\n",
      "Iteration: 7042/10000, Loss: 0.011828304268419743\n",
      "Iteration: 7043/10000, Loss: 0.011889111250638962\n",
      "Iteration: 7044/10000, Loss: 0.007073120679706335\n",
      "Iteration: 7045/10000, Loss: 0.015907470136880875\n",
      "Iteration: 7046/10000, Loss: 0.012547928839921951\n",
      "Iteration: 7047/10000, Loss: 0.008297907188534737\n",
      "Iteration: 7048/10000, Loss: 0.010461313650012016\n",
      "Iteration: 7049/10000, Loss: 0.011217399500310421\n",
      "Iteration: 7050/10000, Loss: 0.007685462944209576\n",
      "Iteration: 7051/10000, Loss: 0.007232481148093939\n",
      "Iteration: 7052/10000, Loss: 0.009262578561902046\n",
      "Iteration: 7053/10000, Loss: 0.008957610465586185\n",
      "Iteration: 7054/10000, Loss: 0.006602469366043806\n",
      "Iteration: 7055/10000, Loss: 0.01000579446554184\n",
      "Iteration: 7056/10000, Loss: 0.011718214489519596\n",
      "Iteration: 7057/10000, Loss: 0.011618062853813171\n",
      "Iteration: 7058/10000, Loss: 0.014446647837758064\n",
      "Iteration: 7059/10000, Loss: 0.013886782340705395\n",
      "Iteration: 7060/10000, Loss: 0.01274035219103098\n",
      "Iteration: 7061/10000, Loss: 0.013099316507577896\n",
      "Iteration: 7062/10000, Loss: 0.015684429556131363\n",
      "Iteration: 7063/10000, Loss: 0.011065398342907429\n",
      "Iteration: 7064/10000, Loss: 0.014931632205843925\n",
      "Iteration: 7065/10000, Loss: 0.009988694451749325\n",
      "Iteration: 7066/10000, Loss: 0.011476225219666958\n",
      "Iteration: 7067/10000, Loss: 0.016810275614261627\n",
      "Iteration: 7068/10000, Loss: 0.007528791204094887\n",
      "Iteration: 7069/10000, Loss: 0.013837598264217377\n",
      "Iteration: 7070/10000, Loss: 0.010242446325719357\n",
      "Iteration: 7071/10000, Loss: 0.010474334470927715\n",
      "Iteration: 7072/10000, Loss: 0.014747988432645798\n",
      "Iteration: 7073/10000, Loss: 0.011415241286158562\n",
      "Iteration: 7074/10000, Loss: 0.018423233181238174\n",
      "Iteration: 7075/10000, Loss: 0.010426352731883526\n",
      "Iteration: 7076/10000, Loss: 0.010750413872301579\n",
      "Iteration: 7077/10000, Loss: 0.012282264418900013\n",
      "Iteration: 7078/10000, Loss: 0.012140007689595222\n",
      "Iteration: 7079/10000, Loss: 0.01226957980543375\n",
      "Iteration: 7080/10000, Loss: 0.014197759330272675\n",
      "Iteration: 7081/10000, Loss: 0.015385757200419903\n",
      "Iteration: 7082/10000, Loss: 0.00962856411933899\n",
      "Iteration: 7083/10000, Loss: 0.0053405254147946835\n",
      "Iteration: 7084/10000, Loss: 0.011751938611268997\n",
      "Iteration: 7085/10000, Loss: 0.007909010164439678\n",
      "Iteration: 7086/10000, Loss: 0.01216548215597868\n",
      "Iteration: 7087/10000, Loss: 0.01386712584644556\n",
      "Iteration: 7088/10000, Loss: 0.009564807638525963\n",
      "Iteration: 7089/10000, Loss: 0.010041491128504276\n",
      "Iteration: 7090/10000, Loss: 0.010326661169528961\n",
      "Iteration: 7091/10000, Loss: 0.012670946307480335\n",
      "Iteration: 7092/10000, Loss: 0.010369601659476757\n",
      "Iteration: 7093/10000, Loss: 0.01312581729143858\n",
      "Iteration: 7094/10000, Loss: 0.008380492217838764\n",
      "Iteration: 7095/10000, Loss: 0.011008941568434238\n",
      "Iteration: 7096/10000, Loss: 0.016064973548054695\n",
      "Iteration: 7097/10000, Loss: 0.008632318116724491\n",
      "Iteration: 7098/10000, Loss: 0.00845647044479847\n",
      "Iteration: 7099/10000, Loss: 0.012405012734234333\n",
      "Iteration: 7100/10000, Loss: 0.015967272222042084\n",
      "Average test loss:  0.0015\n",
      "Iteration: 7101/10000, Loss: 0.009475251659750938\n",
      "Iteration: 7102/10000, Loss: 0.008440577425062656\n",
      "Iteration: 7103/10000, Loss: 0.00726887583732605\n",
      "Iteration: 7104/10000, Loss: 0.01285819336771965\n",
      "Iteration: 7105/10000, Loss: 0.012734896503388882\n",
      "Iteration: 7106/10000, Loss: 0.013781469315290451\n",
      "Iteration: 7107/10000, Loss: 0.01411855686455965\n",
      "Iteration: 7108/10000, Loss: 0.0076723103411495686\n",
      "Iteration: 7109/10000, Loss: 0.01799079403281212\n",
      "Iteration: 7110/10000, Loss: 0.007659929804503918\n",
      "Iteration: 7111/10000, Loss: 0.011158857494592667\n",
      "Iteration: 7112/10000, Loss: 0.017483893781900406\n",
      "Iteration: 7113/10000, Loss: 0.012837755493819714\n",
      "Iteration: 7114/10000, Loss: 0.014895832166075706\n",
      "Iteration: 7115/10000, Loss: 0.011920245364308357\n",
      "Iteration: 7116/10000, Loss: 0.011482838541269302\n",
      "Iteration: 7117/10000, Loss: 0.011807664297521114\n",
      "Iteration: 7118/10000, Loss: 0.0094749229028821\n",
      "Iteration: 7119/10000, Loss: 0.016749683767557144\n",
      "Iteration: 7120/10000, Loss: 0.016504177823662758\n",
      "Iteration: 7121/10000, Loss: 0.01089039072394371\n",
      "Iteration: 7122/10000, Loss: 0.014734026975929737\n",
      "Iteration: 7123/10000, Loss: 0.013068560510873795\n",
      "Iteration: 7124/10000, Loss: 0.01188575942069292\n",
      "Iteration: 7125/10000, Loss: 0.01073563564568758\n",
      "Iteration: 7126/10000, Loss: 0.00808459147810936\n",
      "Iteration: 7127/10000, Loss: 0.014454756863415241\n",
      "Iteration: 7128/10000, Loss: 0.01255436148494482\n",
      "Iteration: 7129/10000, Loss: 0.00856021884828806\n",
      "Iteration: 7130/10000, Loss: 0.010514473542571068\n",
      "Iteration: 7131/10000, Loss: 0.011311105452477932\n",
      "Iteration: 7132/10000, Loss: 0.009737106040120125\n",
      "Iteration: 7133/10000, Loss: 0.010958584025502205\n",
      "Iteration: 7134/10000, Loss: 0.011650322005152702\n",
      "Iteration: 7135/10000, Loss: 0.010070571675896645\n",
      "Iteration: 7136/10000, Loss: 0.015145904384553432\n",
      "Iteration: 7137/10000, Loss: 0.020299354568123817\n",
      "Iteration: 7138/10000, Loss: 0.009530358947813511\n",
      "Iteration: 7139/10000, Loss: 0.009509077295660973\n",
      "Iteration: 7140/10000, Loss: 0.013298731297254562\n",
      "Iteration: 7141/10000, Loss: 0.01172289066016674\n",
      "Iteration: 7142/10000, Loss: 0.009430348873138428\n",
      "Iteration: 7143/10000, Loss: 0.013229742646217346\n",
      "Iteration: 7144/10000, Loss: 0.012898145243525505\n",
      "Iteration: 7145/10000, Loss: 0.014939546585083008\n",
      "Iteration: 7146/10000, Loss: 0.009433978237211704\n",
      "Iteration: 7147/10000, Loss: 0.012326212599873543\n",
      "Iteration: 7148/10000, Loss: 0.010774430818855762\n",
      "Iteration: 7149/10000, Loss: 0.014363333582878113\n",
      "Iteration: 7150/10000, Loss: 0.01429473701864481\n",
      "Iteration: 7151/10000, Loss: 0.011553372256457806\n",
      "Iteration: 7152/10000, Loss: 0.01050983089953661\n",
      "Iteration: 7153/10000, Loss: 0.013185244053602219\n",
      "Iteration: 7154/10000, Loss: 0.010647321119904518\n",
      "Iteration: 7155/10000, Loss: 0.006437400355935097\n",
      "Iteration: 7156/10000, Loss: 0.0059417178854346275\n",
      "Iteration: 7157/10000, Loss: 0.01535205077379942\n",
      "Iteration: 7158/10000, Loss: 0.01420594286173582\n",
      "Iteration: 7159/10000, Loss: 0.008289224468171597\n",
      "Iteration: 7160/10000, Loss: 0.008943187072873116\n",
      "Iteration: 7161/10000, Loss: 0.009491209872066975\n",
      "Iteration: 7162/10000, Loss: 0.008200270123779774\n",
      "Iteration: 7163/10000, Loss: 0.010125672444701195\n",
      "Iteration: 7164/10000, Loss: 0.013444764539599419\n",
      "Iteration: 7165/10000, Loss: 0.010950393974781036\n",
      "Iteration: 7166/10000, Loss: 0.015378965996205807\n",
      "Iteration: 7167/10000, Loss: 0.014266128651797771\n",
      "Iteration: 7168/10000, Loss: 0.011768692173063755\n",
      "Iteration: 7169/10000, Loss: 0.012318812310695648\n",
      "Iteration: 7170/10000, Loss: 0.008664334192872047\n",
      "Iteration: 7171/10000, Loss: 0.011809497140347958\n",
      "Iteration: 7172/10000, Loss: 0.009021935053169727\n",
      "Iteration: 7173/10000, Loss: 0.01159642357379198\n",
      "Iteration: 7174/10000, Loss: 0.010556327179074287\n",
      "Iteration: 7175/10000, Loss: 0.012705977074801922\n",
      "Iteration: 7176/10000, Loss: 0.008360294625163078\n",
      "Iteration: 7177/10000, Loss: 0.005865858402103186\n",
      "Iteration: 7178/10000, Loss: 0.009695841930806637\n",
      "Iteration: 7179/10000, Loss: 0.00902747455984354\n",
      "Iteration: 7180/10000, Loss: 0.013371252454817295\n",
      "Iteration: 7181/10000, Loss: 0.011546389199793339\n",
      "Iteration: 7182/10000, Loss: 0.009262552484869957\n",
      "Iteration: 7183/10000, Loss: 0.011231740936636925\n",
      "Iteration: 7184/10000, Loss: 0.011836083605885506\n",
      "Iteration: 7185/10000, Loss: 0.014034051448106766\n",
      "Iteration: 7186/10000, Loss: 0.012216865085065365\n",
      "Iteration: 7187/10000, Loss: 0.01672918163239956\n",
      "Iteration: 7188/10000, Loss: 0.015477098524570465\n",
      "Iteration: 7189/10000, Loss: 0.014111362397670746\n",
      "Iteration: 7190/10000, Loss: 0.015213128179311752\n",
      "Iteration: 7191/10000, Loss: 0.012385168112814426\n",
      "Iteration: 7192/10000, Loss: 0.01125871017575264\n",
      "Iteration: 7193/10000, Loss: 0.01358881313353777\n",
      "Iteration: 7194/10000, Loss: 0.015965702012181282\n",
      "Iteration: 7195/10000, Loss: 0.01415193546563387\n",
      "Iteration: 7196/10000, Loss: 0.013792392797768116\n",
      "Iteration: 7197/10000, Loss: 0.007861819118261337\n",
      "Iteration: 7198/10000, Loss: 0.00725917425006628\n",
      "Iteration: 7199/10000, Loss: 0.011314461939036846\n",
      "Iteration: 7200/10000, Loss: 0.00958559475839138\n",
      "Average test loss:  0.0039\n",
      "Iteration: 7201/10000, Loss: 0.01229018997400999\n",
      "Iteration: 7202/10000, Loss: 0.00616452656686306\n",
      "Iteration: 7203/10000, Loss: 0.010287090204656124\n",
      "Iteration: 7204/10000, Loss: 0.009356900118291378\n",
      "Iteration: 7205/10000, Loss: 0.011619922704994678\n",
      "Iteration: 7206/10000, Loss: 0.010444186627864838\n",
      "Iteration: 7207/10000, Loss: 0.00973869115114212\n",
      "Iteration: 7208/10000, Loss: 0.013304654508829117\n",
      "Iteration: 7209/10000, Loss: 0.009291697293519974\n",
      "Iteration: 7210/10000, Loss: 0.015351178124547005\n",
      "Iteration: 7211/10000, Loss: 0.016804836690425873\n",
      "Iteration: 7212/10000, Loss: 0.012860191985964775\n",
      "Iteration: 7213/10000, Loss: 0.010738550685346127\n",
      "Iteration: 7214/10000, Loss: 0.008729971945285797\n",
      "Iteration: 7215/10000, Loss: 0.00875606294721365\n",
      "Iteration: 7216/10000, Loss: 0.009074725210666656\n",
      "Iteration: 7217/10000, Loss: 0.011435569263994694\n",
      "Iteration: 7218/10000, Loss: 0.005472751799970865\n",
      "Iteration: 7219/10000, Loss: 0.005373626481741667\n",
      "Iteration: 7220/10000, Loss: 0.009976181201636791\n",
      "Iteration: 7221/10000, Loss: 0.011150391772389412\n",
      "Iteration: 7222/10000, Loss: 0.011251687072217464\n",
      "Iteration: 7223/10000, Loss: 0.011477215215563774\n",
      "Iteration: 7224/10000, Loss: 0.010509842075407505\n",
      "Iteration: 7225/10000, Loss: 0.007713183294981718\n",
      "Iteration: 7226/10000, Loss: 0.007487519644200802\n",
      "Iteration: 7227/10000, Loss: 0.012231020256876945\n",
      "Iteration: 7228/10000, Loss: 0.013390502892434597\n",
      "Iteration: 7229/10000, Loss: 0.013847226276993752\n",
      "Iteration: 7230/10000, Loss: 0.01047959178686142\n",
      "Iteration: 7231/10000, Loss: 0.01130576990544796\n",
      "Iteration: 7232/10000, Loss: 0.011102923192083836\n",
      "Iteration: 7233/10000, Loss: 0.011160610243678093\n",
      "Iteration: 7234/10000, Loss: 0.008252481929957867\n",
      "Iteration: 7235/10000, Loss: 0.014312866143882275\n",
      "Iteration: 7236/10000, Loss: 0.007756625767797232\n",
      "Iteration: 7237/10000, Loss: 0.008331085555255413\n",
      "Iteration: 7238/10000, Loss: 0.014355799183249474\n",
      "Iteration: 7239/10000, Loss: 0.016238601878285408\n",
      "Iteration: 7240/10000, Loss: 0.005050342995673418\n",
      "Iteration: 7241/10000, Loss: 0.011224465444684029\n",
      "Iteration: 7242/10000, Loss: 0.007200261577963829\n",
      "Iteration: 7243/10000, Loss: 0.014847107231616974\n",
      "Iteration: 7244/10000, Loss: 0.008270995691418648\n",
      "Iteration: 7245/10000, Loss: 0.01380476076155901\n",
      "Iteration: 7246/10000, Loss: 0.014732644893229008\n",
      "Iteration: 7247/10000, Loss: 0.01152037363499403\n",
      "Iteration: 7248/10000, Loss: 0.012269821017980576\n",
      "Iteration: 7249/10000, Loss: 0.01515448559075594\n",
      "Iteration: 7250/10000, Loss: 0.007917603477835655\n",
      "Iteration: 7251/10000, Loss: 0.011737918481230736\n",
      "Iteration: 7252/10000, Loss: 0.008078687824308872\n",
      "Iteration: 7253/10000, Loss: 0.014138109050691128\n",
      "Iteration: 7254/10000, Loss: 0.01018430944532156\n",
      "Iteration: 7255/10000, Loss: 0.013205188326537609\n",
      "Iteration: 7256/10000, Loss: 0.011365316808223724\n",
      "Iteration: 7257/10000, Loss: 0.009600170888006687\n",
      "Iteration: 7258/10000, Loss: 0.008870929479598999\n",
      "Iteration: 7259/10000, Loss: 0.007211457006633282\n",
      "Iteration: 7260/10000, Loss: 0.006872938014566898\n",
      "Iteration: 7261/10000, Loss: 0.010882491245865822\n",
      "Iteration: 7262/10000, Loss: 0.010502303019165993\n",
      "Iteration: 7263/10000, Loss: 0.012020771391689777\n",
      "Iteration: 7264/10000, Loss: 0.010581888258457184\n",
      "Iteration: 7265/10000, Loss: 0.013796726241707802\n",
      "Iteration: 7266/10000, Loss: 0.018424563109874725\n",
      "Iteration: 7267/10000, Loss: 0.012267453595995903\n",
      "Iteration: 7268/10000, Loss: 0.009893210604786873\n",
      "Iteration: 7269/10000, Loss: 0.009831344708800316\n",
      "Iteration: 7270/10000, Loss: 0.00977899506688118\n",
      "Iteration: 7271/10000, Loss: 0.008179730735719204\n",
      "Iteration: 7272/10000, Loss: 0.009817160665988922\n",
      "Iteration: 7273/10000, Loss: 0.008652926422655582\n",
      "Iteration: 7274/10000, Loss: 0.010124762542545795\n",
      "Iteration: 7275/10000, Loss: 0.012868048623204231\n",
      "Iteration: 7276/10000, Loss: 0.012612557969987392\n",
      "Iteration: 7277/10000, Loss: 0.012527418322861195\n",
      "Iteration: 7278/10000, Loss: 0.012398826889693737\n",
      "Iteration: 7279/10000, Loss: 0.007615440990775824\n",
      "Iteration: 7280/10000, Loss: 0.008848711848258972\n",
      "Iteration: 7281/10000, Loss: 0.01176227442920208\n",
      "Iteration: 7282/10000, Loss: 0.011973979882895947\n",
      "Iteration: 7283/10000, Loss: 0.008348902687430382\n",
      "Iteration: 7284/10000, Loss: 0.010991237126290798\n",
      "Iteration: 7285/10000, Loss: 0.014520383439958096\n",
      "Iteration: 7286/10000, Loss: 0.010858332738280296\n",
      "Iteration: 7287/10000, Loss: 0.008506573736667633\n",
      "Iteration: 7288/10000, Loss: 0.010852429084479809\n",
      "Iteration: 7289/10000, Loss: 0.01218142919242382\n",
      "Iteration: 7290/10000, Loss: 0.011084601283073425\n",
      "Iteration: 7291/10000, Loss: 0.012045674957334995\n",
      "Iteration: 7292/10000, Loss: 0.016540799289941788\n",
      "Iteration: 7293/10000, Loss: 0.009710659272968769\n",
      "Iteration: 7294/10000, Loss: 0.0073070344515144825\n",
      "Iteration: 7295/10000, Loss: 0.011995303444564342\n",
      "Iteration: 7296/10000, Loss: 0.007287861313670874\n",
      "Iteration: 7297/10000, Loss: 0.008928251452744007\n",
      "Iteration: 7298/10000, Loss: 0.0062682656571269035\n",
      "Iteration: 7299/10000, Loss: 0.013864177279174328\n",
      "Iteration: 7300/10000, Loss: 0.003987712785601616\n",
      "Average test loss:  0.0030\n",
      "Iteration: 7301/10000, Loss: 0.0073418268002569675\n",
      "Iteration: 7302/10000, Loss: 0.009561531245708466\n",
      "Iteration: 7303/10000, Loss: 0.01377567183226347\n",
      "Iteration: 7304/10000, Loss: 0.009706182405352592\n",
      "Iteration: 7305/10000, Loss: 0.010541022755205631\n",
      "Iteration: 7306/10000, Loss: 0.009137068875133991\n",
      "Iteration: 7307/10000, Loss: 0.009571860544383526\n",
      "Iteration: 7308/10000, Loss: 0.004161753226071596\n",
      "Iteration: 7309/10000, Loss: 0.005173444747924805\n",
      "Iteration: 7310/10000, Loss: 0.010973642580211163\n",
      "Iteration: 7311/10000, Loss: 0.009407726116478443\n",
      "Iteration: 7312/10000, Loss: 0.013961385004222393\n",
      "Iteration: 7313/10000, Loss: 0.01605926640331745\n",
      "Iteration: 7314/10000, Loss: 0.013062484562397003\n",
      "Iteration: 7315/10000, Loss: 0.010594193823635578\n",
      "Iteration: 7316/10000, Loss: 0.009522552601993084\n",
      "Iteration: 7317/10000, Loss: 0.011150520294904709\n",
      "Iteration: 7318/10000, Loss: 0.008400916121900082\n",
      "Iteration: 7319/10000, Loss: 0.009316609241068363\n",
      "Iteration: 7320/10000, Loss: 0.010898562148213387\n",
      "Iteration: 7321/10000, Loss: 0.01238514855504036\n",
      "Iteration: 7322/10000, Loss: 0.009821535088121891\n",
      "Iteration: 7323/10000, Loss: 0.011537866666913033\n",
      "Iteration: 7324/10000, Loss: 0.016049256548285484\n",
      "Iteration: 7325/10000, Loss: 0.009727123193442822\n",
      "Iteration: 7326/10000, Loss: 0.007700812537223101\n",
      "Iteration: 7327/10000, Loss: 0.010482186451554298\n",
      "Iteration: 7328/10000, Loss: 0.01022647600620985\n",
      "Iteration: 7329/10000, Loss: 0.013444210402667522\n",
      "Iteration: 7330/10000, Loss: 0.008495116606354713\n",
      "Iteration: 7331/10000, Loss: 0.014149378053843975\n",
      "Iteration: 7332/10000, Loss: 0.010318970307707787\n",
      "Iteration: 7333/10000, Loss: 0.012709512375295162\n",
      "Iteration: 7334/10000, Loss: 0.015843775123357773\n",
      "Iteration: 7335/10000, Loss: 0.012495302595198154\n",
      "Iteration: 7336/10000, Loss: 0.008959672413766384\n",
      "Iteration: 7337/10000, Loss: 0.007533000782132149\n",
      "Iteration: 7338/10000, Loss: 0.0137166827917099\n",
      "Iteration: 7339/10000, Loss: 0.008186273276805878\n",
      "Iteration: 7340/10000, Loss: 0.01258889026939869\n",
      "Iteration: 7341/10000, Loss: 0.008321953937411308\n",
      "Iteration: 7342/10000, Loss: 0.012026042677462101\n",
      "Iteration: 7343/10000, Loss: 0.010540246963500977\n",
      "Iteration: 7344/10000, Loss: 0.0137644587084651\n",
      "Iteration: 7345/10000, Loss: 0.017044972628355026\n",
      "Iteration: 7346/10000, Loss: 0.011592903174459934\n",
      "Iteration: 7347/10000, Loss: 0.010126316919922829\n",
      "Iteration: 7348/10000, Loss: 0.013678344897925854\n",
      "Iteration: 7349/10000, Loss: 0.005326181650161743\n",
      "Iteration: 7350/10000, Loss: 0.010666255839169025\n",
      "Iteration: 7351/10000, Loss: 0.013513389974832535\n",
      "Iteration: 7352/10000, Loss: 0.007460180204361677\n",
      "Iteration: 7353/10000, Loss: 0.015249035321176052\n",
      "Iteration: 7354/10000, Loss: 0.010235265828669071\n",
      "Iteration: 7355/10000, Loss: 0.008728088811039925\n",
      "Iteration: 7356/10000, Loss: 0.01196554210036993\n",
      "Iteration: 7357/10000, Loss: 0.008760225959122181\n",
      "Iteration: 7358/10000, Loss: 0.01383897289633751\n",
      "Iteration: 7359/10000, Loss: 0.012125085107982159\n",
      "Iteration: 7360/10000, Loss: 0.012898609973490238\n",
      "Iteration: 7361/10000, Loss: 0.009652658365666866\n",
      "Iteration: 7362/10000, Loss: 0.014585248194634914\n",
      "Iteration: 7363/10000, Loss: 0.011059693992137909\n",
      "Iteration: 7364/10000, Loss: 0.01349093671888113\n",
      "Iteration: 7365/10000, Loss: 0.009702792391180992\n",
      "Iteration: 7366/10000, Loss: 0.007557656150311232\n",
      "Iteration: 7367/10000, Loss: 0.012835090048611164\n",
      "Iteration: 7368/10000, Loss: 0.009220224805176258\n",
      "Iteration: 7369/10000, Loss: 0.007652929984033108\n",
      "Iteration: 7370/10000, Loss: 0.015342353843152523\n",
      "Iteration: 7371/10000, Loss: 0.011849102564156055\n",
      "Iteration: 7372/10000, Loss: 0.0077114710584282875\n",
      "Iteration: 7373/10000, Loss: 0.008847997523844242\n",
      "Iteration: 7374/10000, Loss: 0.01082620956003666\n",
      "Iteration: 7375/10000, Loss: 0.01696120947599411\n",
      "Iteration: 7376/10000, Loss: 0.005755786783993244\n",
      "Iteration: 7377/10000, Loss: 0.011052766814827919\n",
      "Iteration: 7378/10000, Loss: 0.009577315300703049\n",
      "Iteration: 7379/10000, Loss: 0.018999379128217697\n",
      "Iteration: 7380/10000, Loss: 0.010386294685304165\n",
      "Iteration: 7381/10000, Loss: 0.01094003114849329\n",
      "Iteration: 7382/10000, Loss: 0.010371989570558071\n",
      "Iteration: 7383/10000, Loss: 0.008892486803233624\n",
      "Iteration: 7384/10000, Loss: 0.009641041047871113\n",
      "Iteration: 7385/10000, Loss: 0.013161818496882915\n",
      "Iteration: 7386/10000, Loss: 0.009247755631804466\n",
      "Iteration: 7387/10000, Loss: 0.009771130979061127\n",
      "Iteration: 7388/10000, Loss: 0.011718100868165493\n",
      "Iteration: 7389/10000, Loss: 0.012742391787469387\n",
      "Iteration: 7390/10000, Loss: 0.013746598735451698\n",
      "Iteration: 7391/10000, Loss: 0.011139992624521255\n",
      "Iteration: 7392/10000, Loss: 0.008596891537308693\n",
      "Iteration: 7393/10000, Loss: 0.006395838689059019\n",
      "Iteration: 7394/10000, Loss: 0.00868169404566288\n",
      "Iteration: 7395/10000, Loss: 0.011519781313836575\n",
      "Iteration: 7396/10000, Loss: 0.010807976126670837\n",
      "Iteration: 7397/10000, Loss: 0.011680605821311474\n",
      "Iteration: 7398/10000, Loss: 0.012361169792711735\n",
      "Iteration: 7399/10000, Loss: 0.00994311086833477\n",
      "Iteration: 7400/10000, Loss: 0.007554047740995884\n",
      "Average test loss:  0.0016\n",
      "Iteration: 7401/10000, Loss: 0.009790515527129173\n",
      "Iteration: 7402/10000, Loss: 0.010206746868789196\n",
      "Iteration: 7403/10000, Loss: 0.008733831346035004\n",
      "Iteration: 7404/10000, Loss: 0.007763431407511234\n",
      "Iteration: 7405/10000, Loss: 0.008783564902842045\n",
      "Iteration: 7406/10000, Loss: 0.007882085628807545\n",
      "Iteration: 7407/10000, Loss: 0.008047562092542648\n",
      "Iteration: 7408/10000, Loss: 0.01156954001635313\n",
      "Iteration: 7409/10000, Loss: 0.012005462311208248\n",
      "Iteration: 7410/10000, Loss: 0.016124531626701355\n",
      "Iteration: 7411/10000, Loss: 0.012379745952785015\n",
      "Iteration: 7412/10000, Loss: 0.011129430495202541\n",
      "Iteration: 7413/10000, Loss: 0.004795676562935114\n",
      "Iteration: 7414/10000, Loss: 0.006370536983013153\n",
      "Iteration: 7415/10000, Loss: 0.008930210955440998\n",
      "Iteration: 7416/10000, Loss: 0.014079623855650425\n",
      "Iteration: 7417/10000, Loss: 0.009506931528449059\n",
      "Iteration: 7418/10000, Loss: 0.014596860855817795\n",
      "Iteration: 7419/10000, Loss: 0.011636498384177685\n",
      "Iteration: 7420/10000, Loss: 0.012771605513989925\n",
      "Iteration: 7421/10000, Loss: 0.01157713495194912\n",
      "Iteration: 7422/10000, Loss: 0.007535161916166544\n",
      "Iteration: 7423/10000, Loss: 0.00919102132320404\n",
      "Iteration: 7424/10000, Loss: 0.013148617930710316\n",
      "Iteration: 7425/10000, Loss: 0.011753342114388943\n",
      "Iteration: 7426/10000, Loss: 0.008542562834918499\n",
      "Iteration: 7427/10000, Loss: 0.00827079638838768\n",
      "Iteration: 7428/10000, Loss: 0.01618320494890213\n",
      "Iteration: 7429/10000, Loss: 0.0103445528075099\n",
      "Iteration: 7430/10000, Loss: 0.01090923696756363\n",
      "Iteration: 7431/10000, Loss: 0.010116487741470337\n",
      "Iteration: 7432/10000, Loss: 0.006970714312046766\n",
      "Iteration: 7433/10000, Loss: 0.008205180987715721\n",
      "Iteration: 7434/10000, Loss: 0.012776129879057407\n",
      "Iteration: 7435/10000, Loss: 0.011132699437439442\n",
      "Iteration: 7436/10000, Loss: 0.009195606224238873\n",
      "Iteration: 7437/10000, Loss: 0.01011046301573515\n",
      "Iteration: 7438/10000, Loss: 0.01570836454629898\n",
      "Iteration: 7439/10000, Loss: 0.020189760252833366\n",
      "Iteration: 7440/10000, Loss: 0.006393220275640488\n",
      "Iteration: 7441/10000, Loss: 0.008957725018262863\n",
      "Iteration: 7442/10000, Loss: 0.00984888430684805\n",
      "Iteration: 7443/10000, Loss: 0.012896612286567688\n",
      "Iteration: 7444/10000, Loss: 0.014616943895816803\n",
      "Iteration: 7445/10000, Loss: 0.01335220132023096\n",
      "Iteration: 7446/10000, Loss: 0.010345865041017532\n",
      "Iteration: 7447/10000, Loss: 0.01182528305798769\n",
      "Iteration: 7448/10000, Loss: 0.007699138019233942\n",
      "Iteration: 7449/10000, Loss: 0.01475589256733656\n",
      "Iteration: 7450/10000, Loss: 0.016094043850898743\n",
      "Iteration: 7451/10000, Loss: 0.009107910096645355\n",
      "Iteration: 7452/10000, Loss: 0.010089308023452759\n",
      "Iteration: 7453/10000, Loss: 0.009740659035742283\n",
      "Iteration: 7454/10000, Loss: 0.010022496804594994\n",
      "Iteration: 7455/10000, Loss: 0.011027834378182888\n",
      "Iteration: 7456/10000, Loss: 0.015074096620082855\n",
      "Iteration: 7457/10000, Loss: 0.016186440363526344\n",
      "Iteration: 7458/10000, Loss: 0.006862853188067675\n",
      "Iteration: 7459/10000, Loss: 0.009648305363953114\n",
      "Iteration: 7460/10000, Loss: 0.013340936042368412\n",
      "Iteration: 7461/10000, Loss: 0.011669420637190342\n",
      "Iteration: 7462/10000, Loss: 0.0077088577672839165\n",
      "Iteration: 7463/10000, Loss: 0.008693457581102848\n",
      "Iteration: 7464/10000, Loss: 0.009265569970011711\n",
      "Iteration: 7465/10000, Loss: 0.007197018712759018\n",
      "Iteration: 7466/10000, Loss: 0.010649421252310276\n",
      "Iteration: 7467/10000, Loss: 0.012820258736610413\n",
      "Iteration: 7468/10000, Loss: 0.009649524465203285\n",
      "Iteration: 7469/10000, Loss: 0.00984468124806881\n",
      "Iteration: 7470/10000, Loss: 0.015114552341401577\n",
      "Iteration: 7471/10000, Loss: 0.007211773190647364\n",
      "Iteration: 7472/10000, Loss: 0.006098290905356407\n",
      "Iteration: 7473/10000, Loss: 0.010614992119371891\n",
      "Iteration: 7474/10000, Loss: 0.00833924114704132\n",
      "Iteration: 7475/10000, Loss: 0.009532077237963676\n",
      "Iteration: 7476/10000, Loss: 0.007994725368916988\n",
      "Iteration: 7477/10000, Loss: 0.01701546460390091\n",
      "Iteration: 7478/10000, Loss: 0.011541197076439857\n",
      "Iteration: 7479/10000, Loss: 0.012517287395894527\n",
      "Iteration: 7480/10000, Loss: 0.009801849722862244\n",
      "Iteration: 7481/10000, Loss: 0.01105071697384119\n",
      "Iteration: 7482/10000, Loss: 0.01274843979626894\n",
      "Iteration: 7483/10000, Loss: 0.012817434035241604\n",
      "Iteration: 7484/10000, Loss: 0.013510297983884811\n",
      "Iteration: 7485/10000, Loss: 0.005959609989076853\n",
      "Iteration: 7486/10000, Loss: 0.010621882975101471\n",
      "Iteration: 7487/10000, Loss: 0.007071614731103182\n",
      "Iteration: 7488/10000, Loss: 0.01174956001341343\n",
      "Iteration: 7489/10000, Loss: 0.007597143296152353\n",
      "Iteration: 7490/10000, Loss: 0.012204396538436413\n",
      "Iteration: 7491/10000, Loss: 0.008083072490990162\n",
      "Iteration: 7492/10000, Loss: 0.005177340470254421\n",
      "Iteration: 7493/10000, Loss: 0.012073955498635769\n",
      "Iteration: 7494/10000, Loss: 0.011114290915429592\n",
      "Iteration: 7495/10000, Loss: 0.008722302503883839\n",
      "Iteration: 7496/10000, Loss: 0.008812845684587955\n",
      "Iteration: 7497/10000, Loss: 0.015769964084029198\n",
      "Iteration: 7498/10000, Loss: 0.005298741161823273\n",
      "Iteration: 7499/10000, Loss: 0.010459118522703648\n",
      "Iteration: 7500/10000, Loss: 0.010272948071360588\n",
      "Average test loss:  0.0050\n",
      "Iteration: 7501/10000, Loss: 0.011295300908386707\n",
      "Iteration: 7502/10000, Loss: 0.00968066044151783\n",
      "Iteration: 7503/10000, Loss: 0.00801197811961174\n",
      "Iteration: 7504/10000, Loss: 0.009295370429754257\n",
      "Iteration: 7505/10000, Loss: 0.007958214730024338\n",
      "Iteration: 7506/10000, Loss: 0.013257709331810474\n",
      "Iteration: 7507/10000, Loss: 0.009761916473507881\n",
      "Iteration: 7508/10000, Loss: 0.008682171814143658\n",
      "Iteration: 7509/10000, Loss: 0.011018508113920689\n",
      "Iteration: 7510/10000, Loss: 0.009144837036728859\n",
      "Iteration: 7511/10000, Loss: 0.010970120318233967\n",
      "Iteration: 7512/10000, Loss: 0.010577776469290257\n",
      "Iteration: 7513/10000, Loss: 0.010659988969564438\n",
      "Iteration: 7514/10000, Loss: 0.008092759177088737\n",
      "Iteration: 7515/10000, Loss: 0.009714669547975063\n",
      "Iteration: 7516/10000, Loss: 0.010438673198223114\n",
      "Iteration: 7517/10000, Loss: 0.008259022608399391\n",
      "Iteration: 7518/10000, Loss: 0.013255950063467026\n",
      "Iteration: 7519/10000, Loss: 0.015022655948996544\n",
      "Iteration: 7520/10000, Loss: 0.01289464719593525\n",
      "Iteration: 7521/10000, Loss: 0.013227913528680801\n",
      "Iteration: 7522/10000, Loss: 0.01437725592404604\n",
      "Iteration: 7523/10000, Loss: 0.010734403505921364\n",
      "Iteration: 7524/10000, Loss: 0.011185109615325928\n",
      "Iteration: 7525/10000, Loss: 0.011960728093981743\n",
      "Iteration: 7526/10000, Loss: 0.01542225293815136\n",
      "Iteration: 7527/10000, Loss: 0.013490400277078152\n",
      "Iteration: 7528/10000, Loss: 0.009174368344247341\n",
      "Iteration: 7529/10000, Loss: 0.011066826991736889\n",
      "Iteration: 7530/10000, Loss: 0.008102833293378353\n",
      "Iteration: 7531/10000, Loss: 0.018037064000964165\n",
      "Iteration: 7532/10000, Loss: 0.006482281256467104\n",
      "Iteration: 7533/10000, Loss: 0.01052851602435112\n",
      "Iteration: 7534/10000, Loss: 0.01539450790733099\n",
      "Iteration: 7535/10000, Loss: 0.011537615209817886\n",
      "Iteration: 7536/10000, Loss: 0.008597616106271744\n",
      "Iteration: 7537/10000, Loss: 0.012448756024241447\n",
      "Iteration: 7538/10000, Loss: 0.01523399818688631\n",
      "Iteration: 7539/10000, Loss: 0.010302091017365456\n",
      "Iteration: 7540/10000, Loss: 0.010248960927128792\n",
      "Iteration: 7541/10000, Loss: 0.012655570171773434\n",
      "Iteration: 7542/10000, Loss: 0.013932447880506516\n",
      "Iteration: 7543/10000, Loss: 0.009926562197506428\n",
      "Iteration: 7544/10000, Loss: 0.015429490245878696\n",
      "Iteration: 7545/10000, Loss: 0.013527214527130127\n",
      "Iteration: 7546/10000, Loss: 0.008723422884941101\n",
      "Iteration: 7547/10000, Loss: 0.013624640181660652\n",
      "Iteration: 7548/10000, Loss: 0.010626982897520065\n",
      "Iteration: 7549/10000, Loss: 0.01204048190265894\n",
      "Iteration: 7550/10000, Loss: 0.01000150665640831\n",
      "Iteration: 7551/10000, Loss: 0.012728823348879814\n",
      "Iteration: 7552/10000, Loss: 0.010291661135852337\n",
      "Iteration: 7553/10000, Loss: 0.010427277535200119\n",
      "Iteration: 7554/10000, Loss: 0.0093296580016613\n",
      "Iteration: 7555/10000, Loss: 0.012835889123380184\n",
      "Iteration: 7556/10000, Loss: 0.008010812103748322\n",
      "Iteration: 7557/10000, Loss: 0.014785141684114933\n",
      "Iteration: 7558/10000, Loss: 0.013365453109145164\n",
      "Iteration: 7559/10000, Loss: 0.008329103700816631\n",
      "Iteration: 7560/10000, Loss: 0.008152336813509464\n",
      "Iteration: 7561/10000, Loss: 0.010167461819946766\n",
      "Iteration: 7562/10000, Loss: 0.010888989083468914\n",
      "Iteration: 7563/10000, Loss: 0.011928806081414223\n",
      "Iteration: 7564/10000, Loss: 0.012434128671884537\n",
      "Iteration: 7565/10000, Loss: 0.0070570046082139015\n",
      "Iteration: 7566/10000, Loss: 0.013454058207571507\n",
      "Iteration: 7567/10000, Loss: 0.009564504958689213\n",
      "Iteration: 7568/10000, Loss: 0.010842077434062958\n",
      "Iteration: 7569/10000, Loss: 0.015415937639772892\n",
      "Iteration: 7570/10000, Loss: 0.012004283256828785\n",
      "Iteration: 7571/10000, Loss: 0.007305622566491365\n",
      "Iteration: 7572/10000, Loss: 0.010839131660759449\n",
      "Iteration: 7573/10000, Loss: 0.009194865822792053\n",
      "Iteration: 7574/10000, Loss: 0.009755073115229607\n",
      "Iteration: 7575/10000, Loss: 0.012884455733001232\n",
      "Iteration: 7576/10000, Loss: 0.009887252002954483\n",
      "Iteration: 7577/10000, Loss: 0.012894476763904095\n",
      "Iteration: 7578/10000, Loss: 0.008535553701221943\n",
      "Iteration: 7579/10000, Loss: 0.011343719437718391\n",
      "Iteration: 7580/10000, Loss: 0.010531463660299778\n",
      "Iteration: 7581/10000, Loss: 0.012182792648673058\n",
      "Iteration: 7582/10000, Loss: 0.010572714731097221\n",
      "Iteration: 7583/10000, Loss: 0.006886550225317478\n",
      "Iteration: 7584/10000, Loss: 0.010174702852964401\n",
      "Iteration: 7585/10000, Loss: 0.013325761072337627\n",
      "Iteration: 7586/10000, Loss: 0.008664910681545734\n",
      "Iteration: 7587/10000, Loss: 0.009918981231749058\n",
      "Iteration: 7588/10000, Loss: 0.009189982898533344\n",
      "Iteration: 7589/10000, Loss: 0.011431669816374779\n",
      "Iteration: 7590/10000, Loss: 0.010611464269459248\n",
      "Iteration: 7591/10000, Loss: 0.010285756550729275\n",
      "Iteration: 7592/10000, Loss: 0.014270327053964138\n",
      "Iteration: 7593/10000, Loss: 0.011489816941320896\n",
      "Iteration: 7594/10000, Loss: 0.009111222811043262\n",
      "Iteration: 7595/10000, Loss: 0.013142604380846024\n",
      "Iteration: 7596/10000, Loss: 0.012516566552221775\n",
      "Iteration: 7597/10000, Loss: 0.008221641182899475\n",
      "Iteration: 7598/10000, Loss: 0.012765700928866863\n",
      "Iteration: 7599/10000, Loss: 0.012987306341528893\n",
      "Iteration: 7600/10000, Loss: 0.01114259660243988\n",
      "Average test loss:  0.0034\n",
      "Iteration: 7601/10000, Loss: 0.006909691262990236\n",
      "Iteration: 7602/10000, Loss: 0.013914804905653\n",
      "Iteration: 7603/10000, Loss: 0.014506311155855656\n",
      "Iteration: 7604/10000, Loss: 0.00875944085419178\n",
      "Iteration: 7605/10000, Loss: 0.008936943486332893\n",
      "Iteration: 7606/10000, Loss: 0.009536704048514366\n",
      "Iteration: 7607/10000, Loss: 0.011823146604001522\n",
      "Iteration: 7608/10000, Loss: 0.009019594639539719\n",
      "Iteration: 7609/10000, Loss: 0.009017053991556168\n",
      "Iteration: 7610/10000, Loss: 0.013686343096196651\n",
      "Iteration: 7611/10000, Loss: 0.012149902060627937\n",
      "Iteration: 7612/10000, Loss: 0.007765308953821659\n",
      "Iteration: 7613/10000, Loss: 0.012400020845234394\n",
      "Iteration: 7614/10000, Loss: 0.011489824391901493\n",
      "Iteration: 7615/10000, Loss: 0.01138291321694851\n",
      "Iteration: 7616/10000, Loss: 0.009224982932209969\n",
      "Iteration: 7617/10000, Loss: 0.011368650011718273\n",
      "Iteration: 7618/10000, Loss: 0.006961692124605179\n",
      "Iteration: 7619/10000, Loss: 0.013378243893384933\n",
      "Iteration: 7620/10000, Loss: 0.011359293945133686\n",
      "Iteration: 7621/10000, Loss: 0.011138208210468292\n",
      "Iteration: 7622/10000, Loss: 0.008866319432854652\n",
      "Iteration: 7623/10000, Loss: 0.011259971186518669\n",
      "Iteration: 7624/10000, Loss: 0.00962106417864561\n",
      "Iteration: 7625/10000, Loss: 0.008593468926846981\n",
      "Iteration: 7626/10000, Loss: 0.012702708132565022\n",
      "Iteration: 7627/10000, Loss: 0.010392219759523869\n",
      "Iteration: 7628/10000, Loss: 0.008690856397151947\n",
      "Iteration: 7629/10000, Loss: 0.009072436951100826\n",
      "Iteration: 7630/10000, Loss: 0.014447018504142761\n",
      "Iteration: 7631/10000, Loss: 0.012526772916316986\n",
      "Iteration: 7632/10000, Loss: 0.011125115677714348\n",
      "Iteration: 7633/10000, Loss: 0.011480230838060379\n",
      "Iteration: 7634/10000, Loss: 0.010653366334736347\n",
      "Iteration: 7635/10000, Loss: 0.010567568242549896\n",
      "Iteration: 7636/10000, Loss: 0.009196683764457703\n",
      "Iteration: 7637/10000, Loss: 0.011747286655008793\n",
      "Iteration: 7638/10000, Loss: 0.007550454698503017\n",
      "Iteration: 7639/10000, Loss: 0.01561654545366764\n",
      "Iteration: 7640/10000, Loss: 0.009490090422332287\n",
      "Iteration: 7641/10000, Loss: 0.01317132730036974\n",
      "Iteration: 7642/10000, Loss: 0.007873875088989735\n",
      "Iteration: 7643/10000, Loss: 0.012704204767942429\n",
      "Iteration: 7644/10000, Loss: 0.009168095886707306\n",
      "Iteration: 7645/10000, Loss: 0.007901440374553204\n",
      "Iteration: 7646/10000, Loss: 0.011131802573800087\n",
      "Iteration: 7647/10000, Loss: 0.008116273209452629\n",
      "Iteration: 7648/10000, Loss: 0.008698740974068642\n",
      "Iteration: 7649/10000, Loss: 0.007280806079506874\n",
      "Iteration: 7650/10000, Loss: 0.010885055176913738\n",
      "Iteration: 7651/10000, Loss: 0.010749442502856255\n",
      "Iteration: 7652/10000, Loss: 0.01276839803904295\n",
      "Iteration: 7653/10000, Loss: 0.012175053358078003\n",
      "Iteration: 7654/10000, Loss: 0.010762116871774197\n",
      "Iteration: 7655/10000, Loss: 0.00990716926753521\n",
      "Iteration: 7656/10000, Loss: 0.00989866815507412\n",
      "Iteration: 7657/10000, Loss: 0.01254231110215187\n",
      "Iteration: 7658/10000, Loss: 0.012290905229747295\n",
      "Iteration: 7659/10000, Loss: 0.01255288626998663\n",
      "Iteration: 7660/10000, Loss: 0.011685888282954693\n",
      "Iteration: 7661/10000, Loss: 0.011935590766370296\n",
      "Iteration: 7662/10000, Loss: 0.014796346426010132\n",
      "Iteration: 7663/10000, Loss: 0.01207556389272213\n",
      "Iteration: 7664/10000, Loss: 0.01300826109945774\n",
      "Iteration: 7665/10000, Loss: 0.007523303385823965\n",
      "Iteration: 7666/10000, Loss: 0.010163620114326477\n",
      "Iteration: 7667/10000, Loss: 0.011650223284959793\n",
      "Iteration: 7668/10000, Loss: 0.013162974268198013\n",
      "Iteration: 7669/10000, Loss: 0.009359732270240784\n",
      "Iteration: 7670/10000, Loss: 0.007272316608577967\n",
      "Iteration: 7671/10000, Loss: 0.005110790021717548\n",
      "Iteration: 7672/10000, Loss: 0.011986506171524525\n",
      "Iteration: 7673/10000, Loss: 0.010370987467467785\n",
      "Iteration: 7674/10000, Loss: 0.012663832865655422\n",
      "Iteration: 7675/10000, Loss: 0.014281090348958969\n",
      "Iteration: 7676/10000, Loss: 0.01811273768544197\n",
      "Iteration: 7677/10000, Loss: 0.007239850237965584\n",
      "Iteration: 7678/10000, Loss: 0.011756864376366138\n",
      "Iteration: 7679/10000, Loss: 0.012538649141788483\n",
      "Iteration: 7680/10000, Loss: 0.010998556390404701\n",
      "Iteration: 7681/10000, Loss: 0.007153745740652084\n",
      "Iteration: 7682/10000, Loss: 0.009775040671229362\n",
      "Iteration: 7683/10000, Loss: 0.011385481804609299\n",
      "Iteration: 7684/10000, Loss: 0.013447137549519539\n",
      "Iteration: 7685/10000, Loss: 0.009555702097713947\n",
      "Iteration: 7686/10000, Loss: 0.013562335632741451\n",
      "Iteration: 7687/10000, Loss: 0.01209585927426815\n",
      "Iteration: 7688/10000, Loss: 0.013555155135691166\n",
      "Iteration: 7689/10000, Loss: 0.014690488576889038\n",
      "Iteration: 7690/10000, Loss: 0.009713888168334961\n",
      "Iteration: 7691/10000, Loss: 0.01217355951666832\n",
      "Iteration: 7692/10000, Loss: 0.01488298550248146\n",
      "Iteration: 7693/10000, Loss: 0.00986400805413723\n",
      "Iteration: 7694/10000, Loss: 0.01260446198284626\n",
      "Iteration: 7695/10000, Loss: 0.013388966210186481\n",
      "Iteration: 7696/10000, Loss: 0.009739432483911514\n",
      "Iteration: 7697/10000, Loss: 0.013161752372980118\n",
      "Iteration: 7698/10000, Loss: 0.009485783986747265\n",
      "Iteration: 7699/10000, Loss: 0.007524901535362005\n",
      "Iteration: 7700/10000, Loss: 0.007941527292132378\n",
      "Average test loss:  0.0034\n",
      "Iteration: 7701/10000, Loss: 0.010570639744400978\n",
      "Iteration: 7702/10000, Loss: 0.012360640801489353\n",
      "Iteration: 7703/10000, Loss: 0.015147688798606396\n",
      "Iteration: 7704/10000, Loss: 0.016933217644691467\n",
      "Iteration: 7705/10000, Loss: 0.010831904597580433\n",
      "Iteration: 7706/10000, Loss: 0.013701354153454304\n",
      "Iteration: 7707/10000, Loss: 0.008202750235795975\n",
      "Iteration: 7708/10000, Loss: 0.00779439602047205\n",
      "Iteration: 7709/10000, Loss: 0.017495250329375267\n",
      "Iteration: 7710/10000, Loss: 0.013346794992685318\n",
      "Iteration: 7711/10000, Loss: 0.009933409281075\n",
      "Iteration: 7712/10000, Loss: 0.011535262688994408\n",
      "Iteration: 7713/10000, Loss: 0.010600840672850609\n",
      "Iteration: 7714/10000, Loss: 0.00908572506159544\n",
      "Iteration: 7715/10000, Loss: 0.009804826229810715\n",
      "Iteration: 7716/10000, Loss: 0.010263560339808464\n",
      "Iteration: 7717/10000, Loss: 0.016254568472504616\n",
      "Iteration: 7718/10000, Loss: 0.008231020532548428\n",
      "Iteration: 7719/10000, Loss: 0.012487726286053658\n",
      "Iteration: 7720/10000, Loss: 0.01191667653620243\n",
      "Iteration: 7721/10000, Loss: 0.010108249261975288\n",
      "Iteration: 7722/10000, Loss: 0.008711932227015495\n",
      "Iteration: 7723/10000, Loss: 0.011624643579125404\n",
      "Iteration: 7724/10000, Loss: 0.013454378582537174\n",
      "Iteration: 7725/10000, Loss: 0.0067609334364533424\n",
      "Iteration: 7726/10000, Loss: 0.0072809550911188126\n",
      "Iteration: 7727/10000, Loss: 0.007981309667229652\n",
      "Iteration: 7728/10000, Loss: 0.008085938170552254\n",
      "Iteration: 7729/10000, Loss: 0.012802831828594208\n",
      "Iteration: 7730/10000, Loss: 0.005706758704036474\n",
      "Iteration: 7731/10000, Loss: 0.006333460099995136\n",
      "Iteration: 7732/10000, Loss: 0.00421407725661993\n",
      "Iteration: 7733/10000, Loss: 0.009388741105794907\n",
      "Iteration: 7734/10000, Loss: 0.014672495424747467\n",
      "Iteration: 7735/10000, Loss: 0.011009723879396915\n",
      "Iteration: 7736/10000, Loss: 0.008743966929614544\n",
      "Iteration: 7737/10000, Loss: 0.009724426083266735\n",
      "Iteration: 7738/10000, Loss: 0.010328015312552452\n",
      "Iteration: 7739/10000, Loss: 0.00818052887916565\n",
      "Iteration: 7740/10000, Loss: 0.004917279351502657\n",
      "Iteration: 7741/10000, Loss: 0.011965659447014332\n",
      "Iteration: 7742/10000, Loss: 0.009418400004506111\n",
      "Iteration: 7743/10000, Loss: 0.0070398165844380856\n",
      "Iteration: 7744/10000, Loss: 0.014046620577573776\n",
      "Iteration: 7745/10000, Loss: 0.015424494631588459\n",
      "Iteration: 7746/10000, Loss: 0.010108131915330887\n",
      "Iteration: 7747/10000, Loss: 0.009290128014981747\n",
      "Iteration: 7748/10000, Loss: 0.01004849188029766\n",
      "Iteration: 7749/10000, Loss: 0.009290499612689018\n",
      "Iteration: 7750/10000, Loss: 0.004434786271303892\n",
      "Iteration: 7751/10000, Loss: 0.010575464926660061\n",
      "Iteration: 7752/10000, Loss: 0.00925727840512991\n",
      "Iteration: 7753/10000, Loss: 0.007328602485358715\n",
      "Iteration: 7754/10000, Loss: 0.009097365662455559\n",
      "Iteration: 7755/10000, Loss: 0.004142242018133402\n",
      "Iteration: 7756/10000, Loss: 0.01192936860024929\n",
      "Iteration: 7757/10000, Loss: 0.008830567821860313\n",
      "Iteration: 7758/10000, Loss: 0.013248372822999954\n",
      "Iteration: 7759/10000, Loss: 0.01064221654087305\n",
      "Iteration: 7760/10000, Loss: 0.010792967863380909\n",
      "Iteration: 7761/10000, Loss: 0.008629233576357365\n",
      "Iteration: 7762/10000, Loss: 0.011924130842089653\n",
      "Iteration: 7763/10000, Loss: 0.010866228491067886\n",
      "Iteration: 7764/10000, Loss: 0.013272701762616634\n",
      "Iteration: 7765/10000, Loss: 0.011679965071380138\n",
      "Iteration: 7766/10000, Loss: 0.01007117610424757\n",
      "Iteration: 7767/10000, Loss: 0.012754577212035656\n",
      "Iteration: 7768/10000, Loss: 0.010659851133823395\n",
      "Iteration: 7769/10000, Loss: 0.007607531733810902\n",
      "Iteration: 7770/10000, Loss: 0.00719240540638566\n",
      "Iteration: 7771/10000, Loss: 0.011382417753338814\n",
      "Iteration: 7772/10000, Loss: 0.012486347928643227\n",
      "Iteration: 7773/10000, Loss: 0.009657828137278557\n",
      "Iteration: 7774/10000, Loss: 0.01059429720044136\n",
      "Iteration: 7775/10000, Loss: 0.00756206875666976\n",
      "Iteration: 7776/10000, Loss: 0.008381077088415623\n",
      "Iteration: 7777/10000, Loss: 0.011745346710085869\n",
      "Iteration: 7778/10000, Loss: 0.013295742683112621\n",
      "Iteration: 7779/10000, Loss: 0.017133790999650955\n",
      "Iteration: 7780/10000, Loss: 0.014515729621052742\n",
      "Iteration: 7781/10000, Loss: 0.00971195288002491\n",
      "Iteration: 7782/10000, Loss: 0.01500899251550436\n",
      "Iteration: 7783/10000, Loss: 0.008353779092431068\n",
      "Iteration: 7784/10000, Loss: 0.009369760751724243\n",
      "Iteration: 7785/10000, Loss: 0.006871818099170923\n",
      "Iteration: 7786/10000, Loss: 0.014000747352838516\n",
      "Iteration: 7787/10000, Loss: 0.01000978983938694\n",
      "Iteration: 7788/10000, Loss: 0.011351672001183033\n",
      "Iteration: 7789/10000, Loss: 0.011402659118175507\n",
      "Iteration: 7790/10000, Loss: 0.006812982726842165\n",
      "Iteration: 7791/10000, Loss: 0.006269967649132013\n",
      "Iteration: 7792/10000, Loss: 0.011011583730578423\n",
      "Iteration: 7793/10000, Loss: 0.0144877377897501\n",
      "Iteration: 7794/10000, Loss: 0.009821193292737007\n",
      "Iteration: 7795/10000, Loss: 0.015516920946538448\n",
      "Iteration: 7796/10000, Loss: 0.011768799275159836\n",
      "Iteration: 7797/10000, Loss: 0.008911501616239548\n",
      "Iteration: 7798/10000, Loss: 0.010339449159801006\n",
      "Iteration: 7799/10000, Loss: 0.004809560254216194\n",
      "Iteration: 7800/10000, Loss: 0.013029673136770725\n",
      "Average test loss:  0.0034\n",
      "Iteration: 7801/10000, Loss: 0.014261108823120594\n",
      "Iteration: 7802/10000, Loss: 0.012551428750157356\n",
      "Iteration: 7803/10000, Loss: 0.011340617202222347\n",
      "Iteration: 7804/10000, Loss: 0.008686098270118237\n",
      "Iteration: 7805/10000, Loss: 0.006172445137053728\n",
      "Iteration: 7806/10000, Loss: 0.010165093466639519\n",
      "Iteration: 7807/10000, Loss: 0.018113259226083755\n",
      "Iteration: 7808/10000, Loss: 0.006711948662996292\n",
      "Iteration: 7809/10000, Loss: 0.012642357498407364\n",
      "Iteration: 7810/10000, Loss: 0.012835884466767311\n",
      "Iteration: 7811/10000, Loss: 0.008048413321375847\n",
      "Iteration: 7812/10000, Loss: 0.00511972839012742\n",
      "Iteration: 7813/10000, Loss: 0.011662431992590427\n",
      "Iteration: 7814/10000, Loss: 0.008160654455423355\n",
      "Iteration: 7815/10000, Loss: 0.008011805824935436\n",
      "Iteration: 7816/10000, Loss: 0.010505051352083683\n",
      "Iteration: 7817/10000, Loss: 0.007561840582638979\n",
      "Iteration: 7818/10000, Loss: 0.01594354398548603\n",
      "Iteration: 7819/10000, Loss: 0.010483567602932453\n",
      "Iteration: 7820/10000, Loss: 0.009032700210809708\n",
      "Iteration: 7821/10000, Loss: 0.012192039750516415\n",
      "Iteration: 7822/10000, Loss: 0.01100650243461132\n",
      "Iteration: 7823/10000, Loss: 0.009714778512716293\n",
      "Iteration: 7824/10000, Loss: 0.011521213687956333\n",
      "Iteration: 7825/10000, Loss: 0.01236281730234623\n",
      "Iteration: 7826/10000, Loss: 0.009268693625926971\n",
      "Iteration: 7827/10000, Loss: 0.007293474394828081\n",
      "Iteration: 7828/10000, Loss: 0.00721061322838068\n",
      "Iteration: 7829/10000, Loss: 0.007991692051291466\n",
      "Iteration: 7830/10000, Loss: 0.012571219354867935\n",
      "Iteration: 7831/10000, Loss: 0.011583702638745308\n",
      "Iteration: 7832/10000, Loss: 0.00972077064216137\n",
      "Iteration: 7833/10000, Loss: 0.004911481402814388\n",
      "Iteration: 7834/10000, Loss: 0.01007428765296936\n",
      "Iteration: 7835/10000, Loss: 0.006276880856603384\n",
      "Iteration: 7836/10000, Loss: 0.011614450253546238\n",
      "Iteration: 7837/10000, Loss: 0.0124235013499856\n",
      "Iteration: 7838/10000, Loss: 0.009143669158220291\n",
      "Iteration: 7839/10000, Loss: 0.01654883474111557\n",
      "Iteration: 7840/10000, Loss: 0.01108664833009243\n",
      "Iteration: 7841/10000, Loss: 0.012222431600093842\n",
      "Iteration: 7842/10000, Loss: 0.008868365548551083\n",
      "Iteration: 7843/10000, Loss: 0.010014906525611877\n",
      "Iteration: 7844/10000, Loss: 0.011699183844029903\n",
      "Iteration: 7845/10000, Loss: 0.010543272830545902\n",
      "Iteration: 7846/10000, Loss: 0.017722226679325104\n",
      "Iteration: 7847/10000, Loss: 0.008421849459409714\n",
      "Iteration: 7848/10000, Loss: 0.009480897337198257\n",
      "Iteration: 7849/10000, Loss: 0.010652966797351837\n",
      "Iteration: 7850/10000, Loss: 0.014262152835726738\n",
      "Iteration: 7851/10000, Loss: 0.011848362162709236\n",
      "Iteration: 7852/10000, Loss: 0.017703069373965263\n",
      "Iteration: 7853/10000, Loss: 0.009578702040016651\n",
      "Iteration: 7854/10000, Loss: 0.0067933909595012665\n",
      "Iteration: 7855/10000, Loss: 0.009678097441792488\n",
      "Iteration: 7856/10000, Loss: 0.010453591123223305\n",
      "Iteration: 7857/10000, Loss: 0.013006109744310379\n",
      "Iteration: 7858/10000, Loss: 0.009293309412896633\n",
      "Iteration: 7859/10000, Loss: 0.012500896118581295\n",
      "Iteration: 7860/10000, Loss: 0.010014962404966354\n",
      "Iteration: 7861/10000, Loss: 0.01197073608636856\n",
      "Iteration: 7862/10000, Loss: 0.009765135124325752\n",
      "Iteration: 7863/10000, Loss: 0.009080403484404087\n",
      "Iteration: 7864/10000, Loss: 0.009284290485084057\n",
      "Iteration: 7865/10000, Loss: 0.012653475627303123\n",
      "Iteration: 7866/10000, Loss: 0.013840926811099052\n",
      "Iteration: 7867/10000, Loss: 0.01312317606061697\n",
      "Iteration: 7868/10000, Loss: 0.012580410577356815\n",
      "Iteration: 7869/10000, Loss: 0.011393832042813301\n",
      "Iteration: 7870/10000, Loss: 0.0106045575812459\n",
      "Iteration: 7871/10000, Loss: 0.008383205160498619\n",
      "Iteration: 7872/10000, Loss: 0.007415954954922199\n",
      "Iteration: 7873/10000, Loss: 0.013987256214022636\n",
      "Iteration: 7874/10000, Loss: 0.013388901017606258\n",
      "Iteration: 7875/10000, Loss: 0.010321891866624355\n",
      "Iteration: 7876/10000, Loss: 0.008567018434405327\n",
      "Iteration: 7877/10000, Loss: 0.008860182948410511\n",
      "Iteration: 7878/10000, Loss: 0.008825824595987797\n",
      "Iteration: 7879/10000, Loss: 0.01155590545386076\n",
      "Iteration: 7880/10000, Loss: 0.008676192723214626\n",
      "Iteration: 7881/10000, Loss: 0.010541808791458607\n",
      "Iteration: 7882/10000, Loss: 0.006987118627876043\n",
      "Iteration: 7883/10000, Loss: 0.016082482412457466\n",
      "Iteration: 7884/10000, Loss: 0.01153595745563507\n",
      "Iteration: 7885/10000, Loss: 0.012616481631994247\n",
      "Iteration: 7886/10000, Loss: 0.011084982194006443\n",
      "Iteration: 7887/10000, Loss: 0.015326553955674171\n",
      "Iteration: 7888/10000, Loss: 0.012729192152619362\n",
      "Iteration: 7889/10000, Loss: 0.012909572571516037\n",
      "Iteration: 7890/10000, Loss: 0.01343747042119503\n",
      "Iteration: 7891/10000, Loss: 0.010744941420853138\n",
      "Iteration: 7892/10000, Loss: 0.012271509505808353\n",
      "Iteration: 7893/10000, Loss: 0.011844191700220108\n",
      "Iteration: 7894/10000, Loss: 0.00656572449952364\n",
      "Iteration: 7895/10000, Loss: 0.01081602182239294\n",
      "Iteration: 7896/10000, Loss: 0.01170928031206131\n",
      "Iteration: 7897/10000, Loss: 0.014829471707344055\n",
      "Iteration: 7898/10000, Loss: 0.012725862674415112\n",
      "Iteration: 7899/10000, Loss: 0.006646528374403715\n",
      "Iteration: 7900/10000, Loss: 0.011354828253388405\n",
      "Average test loss:  0.0026\n",
      "Iteration: 7901/10000, Loss: 0.01211176160722971\n",
      "Iteration: 7902/10000, Loss: 0.01037460658699274\n",
      "Iteration: 7903/10000, Loss: 0.008984782733023167\n",
      "Iteration: 7904/10000, Loss: 0.009204437024891376\n",
      "Iteration: 7905/10000, Loss: 0.009482848457992077\n",
      "Iteration: 7906/10000, Loss: 0.010697297751903534\n",
      "Iteration: 7907/10000, Loss: 0.00990039948374033\n",
      "Iteration: 7908/10000, Loss: 0.01110612042248249\n",
      "Iteration: 7909/10000, Loss: 0.006651223637163639\n",
      "Iteration: 7910/10000, Loss: 0.00879371352493763\n",
      "Iteration: 7911/10000, Loss: 0.006840187590569258\n",
      "Iteration: 7912/10000, Loss: 0.012171045877039433\n",
      "Iteration: 7913/10000, Loss: 0.009314659982919693\n",
      "Iteration: 7914/10000, Loss: 0.010815596207976341\n",
      "Iteration: 7915/10000, Loss: 0.010811246931552887\n",
      "Iteration: 7916/10000, Loss: 0.008750347420573235\n",
      "Iteration: 7917/10000, Loss: 0.008854411542415619\n",
      "Iteration: 7918/10000, Loss: 0.01203156728297472\n",
      "Iteration: 7919/10000, Loss: 0.008670693263411522\n",
      "Iteration: 7920/10000, Loss: 0.00771742220968008\n",
      "Iteration: 7921/10000, Loss: 0.011865292675793171\n",
      "Iteration: 7922/10000, Loss: 0.007735346909612417\n",
      "Iteration: 7923/10000, Loss: 0.012368611991405487\n",
      "Iteration: 7924/10000, Loss: 0.011840105056762695\n",
      "Iteration: 7925/10000, Loss: 0.007646485231816769\n",
      "Iteration: 7926/10000, Loss: 0.012546244077384472\n",
      "Iteration: 7927/10000, Loss: 0.014951358549296856\n",
      "Iteration: 7928/10000, Loss: 0.009410718455910683\n",
      "Iteration: 7929/10000, Loss: 0.009551241993904114\n",
      "Iteration: 7930/10000, Loss: 0.011078034527599812\n",
      "Iteration: 7931/10000, Loss: 0.011346942745149136\n",
      "Iteration: 7932/10000, Loss: 0.00982974749058485\n",
      "Iteration: 7933/10000, Loss: 0.006568060256540775\n",
      "Iteration: 7934/10000, Loss: 0.012545914389193058\n",
      "Iteration: 7935/10000, Loss: 0.013417677022516727\n",
      "Iteration: 7936/10000, Loss: 0.010948280803859234\n",
      "Iteration: 7937/10000, Loss: 0.007034198846668005\n",
      "Iteration: 7938/10000, Loss: 0.008718610741198063\n",
      "Iteration: 7939/10000, Loss: 0.010018877685070038\n",
      "Iteration: 7940/10000, Loss: 0.009593181312084198\n",
      "Iteration: 7941/10000, Loss: 0.008327356539666653\n",
      "Iteration: 7942/10000, Loss: 0.01205113623291254\n",
      "Iteration: 7943/10000, Loss: 0.008899694308638573\n",
      "Iteration: 7944/10000, Loss: 0.01676977425813675\n",
      "Iteration: 7945/10000, Loss: 0.007868975400924683\n",
      "Iteration: 7946/10000, Loss: 0.013005336746573448\n",
      "Iteration: 7947/10000, Loss: 0.0041976929642260075\n",
      "Iteration: 7948/10000, Loss: 0.010173405520617962\n",
      "Iteration: 7949/10000, Loss: 0.007143512833863497\n",
      "Iteration: 7950/10000, Loss: 0.009263679385185242\n",
      "Iteration: 7951/10000, Loss: 0.007966196164488792\n",
      "Iteration: 7952/10000, Loss: 0.008061596192419529\n",
      "Iteration: 7953/10000, Loss: 0.008653195574879646\n",
      "Iteration: 7954/10000, Loss: 0.008471321314573288\n",
      "Iteration: 7955/10000, Loss: 0.006174719426780939\n",
      "Iteration: 7956/10000, Loss: 0.007533310446888208\n",
      "Iteration: 7957/10000, Loss: 0.013842098414897919\n",
      "Iteration: 7958/10000, Loss: 0.012163516134023666\n",
      "Iteration: 7959/10000, Loss: 0.010259225964546204\n",
      "Iteration: 7960/10000, Loss: 0.011397878639400005\n",
      "Iteration: 7961/10000, Loss: 0.009124403819441795\n",
      "Iteration: 7962/10000, Loss: 0.013434438966214657\n",
      "Iteration: 7963/10000, Loss: 0.008747023530304432\n",
      "Iteration: 7964/10000, Loss: 0.00805042963474989\n",
      "Iteration: 7965/10000, Loss: 0.01031833328306675\n",
      "Iteration: 7966/10000, Loss: 0.008206217549741268\n",
      "Iteration: 7967/10000, Loss: 0.010000549256801605\n",
      "Iteration: 7968/10000, Loss: 0.0063761575147509575\n",
      "Iteration: 7969/10000, Loss: 0.008548986166715622\n",
      "Iteration: 7970/10000, Loss: 0.011215515434741974\n",
      "Iteration: 7971/10000, Loss: 0.008502278476953506\n",
      "Iteration: 7972/10000, Loss: 0.011823901906609535\n",
      "Iteration: 7973/10000, Loss: 0.008495095185935497\n",
      "Iteration: 7974/10000, Loss: 0.01286241039633751\n",
      "Iteration: 7975/10000, Loss: 0.015023261308670044\n",
      "Iteration: 7976/10000, Loss: 0.013689780607819557\n",
      "Iteration: 7977/10000, Loss: 0.009929603897035122\n",
      "Iteration: 7978/10000, Loss: 0.010178595781326294\n",
      "Iteration: 7979/10000, Loss: 0.011527524329721928\n",
      "Iteration: 7980/10000, Loss: 0.008304602466523647\n",
      "Iteration: 7981/10000, Loss: 0.008988634683191776\n",
      "Iteration: 7982/10000, Loss: 0.011649427004158497\n",
      "Iteration: 7983/10000, Loss: 0.00995399709790945\n",
      "Iteration: 7984/10000, Loss: 0.01330509502440691\n",
      "Iteration: 7985/10000, Loss: 0.009793928824365139\n",
      "Iteration: 7986/10000, Loss: 0.00668256776407361\n",
      "Iteration: 7987/10000, Loss: 0.008121046237647533\n",
      "Iteration: 7988/10000, Loss: 0.009290055371820927\n",
      "Iteration: 7989/10000, Loss: 0.011693436652421951\n",
      "Iteration: 7990/10000, Loss: 0.012550046667456627\n",
      "Iteration: 7991/10000, Loss: 0.009069610387086868\n",
      "Iteration: 7992/10000, Loss: 0.009618180803954601\n",
      "Iteration: 7993/10000, Loss: 0.007354412227869034\n",
      "Iteration: 7994/10000, Loss: 0.009250069968402386\n",
      "Iteration: 7995/10000, Loss: 0.01669248938560486\n",
      "Iteration: 7996/10000, Loss: 0.013474203646183014\n",
      "Iteration: 7997/10000, Loss: 0.007824791595339775\n",
      "Iteration: 7998/10000, Loss: 0.008142441511154175\n",
      "Iteration: 7999/10000, Loss: 0.00900701992213726\n",
      "Iteration: 8000/10000, Loss: 0.011322691105306149\n",
      "Average test loss:  0.0033\n",
      "Iteration: 8001/10000, Loss: 0.01933443360030651\n",
      "Iteration: 8002/10000, Loss: 0.009602725505828857\n",
      "Iteration: 8003/10000, Loss: 0.009847357869148254\n",
      "Iteration: 8004/10000, Loss: 0.008303920738399029\n",
      "Iteration: 8005/10000, Loss: 0.013618086464703083\n",
      "Iteration: 8006/10000, Loss: 0.011314410716295242\n",
      "Iteration: 8007/10000, Loss: 0.014325538650155067\n",
      "Iteration: 8008/10000, Loss: 0.01715528778731823\n",
      "Iteration: 8009/10000, Loss: 0.0077615100890398026\n",
      "Iteration: 8010/10000, Loss: 0.012024962343275547\n",
      "Iteration: 8011/10000, Loss: 0.008738134056329727\n",
      "Iteration: 8012/10000, Loss: 0.012139483354985714\n",
      "Iteration: 8013/10000, Loss: 0.011800802312791348\n",
      "Iteration: 8014/10000, Loss: 0.006477645132690668\n",
      "Iteration: 8015/10000, Loss: 0.007065266370773315\n",
      "Iteration: 8016/10000, Loss: 0.006245464086532593\n",
      "Iteration: 8017/10000, Loss: 0.007526485715061426\n",
      "Iteration: 8018/10000, Loss: 0.012987574562430382\n",
      "Iteration: 8019/10000, Loss: 0.011434979736804962\n",
      "Iteration: 8020/10000, Loss: 0.011611885391175747\n",
      "Iteration: 8021/10000, Loss: 0.008589466102421284\n",
      "Iteration: 8022/10000, Loss: 0.008515769615769386\n",
      "Iteration: 8023/10000, Loss: 0.009441493079066277\n",
      "Iteration: 8024/10000, Loss: 0.011601956561207771\n",
      "Iteration: 8025/10000, Loss: 0.009136470034718513\n",
      "Iteration: 8026/10000, Loss: 0.012623858638107777\n",
      "Iteration: 8027/10000, Loss: 0.008813331834971905\n",
      "Iteration: 8028/10000, Loss: 0.008865601383149624\n",
      "Iteration: 8029/10000, Loss: 0.010553782805800438\n",
      "Iteration: 8030/10000, Loss: 0.013354381546378136\n",
      "Iteration: 8031/10000, Loss: 0.004763995297253132\n",
      "Iteration: 8032/10000, Loss: 0.010562322102487087\n",
      "Iteration: 8033/10000, Loss: 0.008446300402283669\n",
      "Iteration: 8034/10000, Loss: 0.012993467040359974\n",
      "Iteration: 8035/10000, Loss: 0.008848410099744797\n",
      "Iteration: 8036/10000, Loss: 0.0070310854353010654\n",
      "Iteration: 8037/10000, Loss: 0.012957234866917133\n",
      "Iteration: 8038/10000, Loss: 0.011884493753314018\n",
      "Iteration: 8039/10000, Loss: 0.009742435067892075\n",
      "Iteration: 8040/10000, Loss: 0.012417753227055073\n",
      "Iteration: 8041/10000, Loss: 0.011999284848570824\n",
      "Iteration: 8042/10000, Loss: 0.0060151852667331696\n",
      "Iteration: 8043/10000, Loss: 0.008610757999122143\n",
      "Iteration: 8044/10000, Loss: 0.009527084417641163\n",
      "Iteration: 8045/10000, Loss: 0.012245488353073597\n",
      "Iteration: 8046/10000, Loss: 0.0064321234822273254\n",
      "Iteration: 8047/10000, Loss: 0.009361425414681435\n",
      "Iteration: 8048/10000, Loss: 0.008750495500862598\n",
      "Iteration: 8049/10000, Loss: 0.008216611109673977\n",
      "Iteration: 8050/10000, Loss: 0.010425232350826263\n",
      "Iteration: 8051/10000, Loss: 0.009179172106087208\n",
      "Iteration: 8052/10000, Loss: 0.011594593524932861\n",
      "Iteration: 8053/10000, Loss: 0.011366487480700016\n",
      "Iteration: 8054/10000, Loss: 0.009115403518080711\n",
      "Iteration: 8055/10000, Loss: 0.009123294614255428\n",
      "Iteration: 8056/10000, Loss: 0.010889923200011253\n",
      "Iteration: 8057/10000, Loss: 0.009937223047018051\n",
      "Iteration: 8058/10000, Loss: 0.008623207919299603\n",
      "Iteration: 8059/10000, Loss: 0.008903239853680134\n",
      "Iteration: 8060/10000, Loss: 0.008886019699275494\n",
      "Iteration: 8061/10000, Loss: 0.011450269259512424\n",
      "Iteration: 8062/10000, Loss: 0.009741558693349361\n",
      "Iteration: 8063/10000, Loss: 0.006295923143625259\n",
      "Iteration: 8064/10000, Loss: 0.00902830995619297\n",
      "Iteration: 8065/10000, Loss: 0.01274268701672554\n",
      "Iteration: 8066/10000, Loss: 0.011173457838594913\n",
      "Iteration: 8067/10000, Loss: 0.007542275357991457\n",
      "Iteration: 8068/10000, Loss: 0.00858250167220831\n",
      "Iteration: 8069/10000, Loss: 0.009061896242201328\n",
      "Iteration: 8070/10000, Loss: 0.009078677743673325\n",
      "Iteration: 8071/10000, Loss: 0.009255769662559032\n",
      "Iteration: 8072/10000, Loss: 0.013649833388626575\n",
      "Iteration: 8073/10000, Loss: 0.010346846655011177\n",
      "Iteration: 8074/10000, Loss: 0.009946055710315704\n",
      "Iteration: 8075/10000, Loss: 0.005938292946666479\n",
      "Iteration: 8076/10000, Loss: 0.008964822627604008\n",
      "Iteration: 8077/10000, Loss: 0.006386201828718185\n",
      "Iteration: 8078/10000, Loss: 0.00790497101843357\n",
      "Iteration: 8079/10000, Loss: 0.008068314753472805\n",
      "Iteration: 8080/10000, Loss: 0.012696552090346813\n",
      "Iteration: 8081/10000, Loss: 0.010989916510879993\n",
      "Iteration: 8082/10000, Loss: 0.013365612365305424\n",
      "Iteration: 8083/10000, Loss: 0.009081649594008923\n",
      "Iteration: 8084/10000, Loss: 0.010405714623630047\n",
      "Iteration: 8085/10000, Loss: 0.008975930511951447\n",
      "Iteration: 8086/10000, Loss: 0.011553897522389889\n",
      "Iteration: 8087/10000, Loss: 0.010081295855343342\n",
      "Iteration: 8088/10000, Loss: 0.012638522312045097\n",
      "Iteration: 8089/10000, Loss: 0.009334363974630833\n",
      "Iteration: 8090/10000, Loss: 0.008185016922652721\n",
      "Iteration: 8091/10000, Loss: 0.00833079032599926\n",
      "Iteration: 8092/10000, Loss: 0.013251210562884808\n",
      "Iteration: 8093/10000, Loss: 0.010341271758079529\n",
      "Iteration: 8094/10000, Loss: 0.010051078163087368\n",
      "Iteration: 8095/10000, Loss: 0.010508892126381397\n",
      "Iteration: 8096/10000, Loss: 0.010390863753855228\n",
      "Iteration: 8097/10000, Loss: 0.008210567757487297\n",
      "Iteration: 8098/10000, Loss: 0.014112154953181744\n",
      "Iteration: 8099/10000, Loss: 0.01214671041816473\n",
      "Iteration: 8100/10000, Loss: 0.007306602317839861\n",
      "Average test loss:  0.0041\n",
      "Iteration: 8101/10000, Loss: 0.012266656383872032\n",
      "Iteration: 8102/10000, Loss: 0.007533683907240629\n",
      "Iteration: 8103/10000, Loss: 0.008892268873751163\n",
      "Iteration: 8104/10000, Loss: 0.010580145753920078\n",
      "Iteration: 8105/10000, Loss: 0.008026694878935814\n",
      "Iteration: 8106/10000, Loss: 0.008647087961435318\n",
      "Iteration: 8107/10000, Loss: 0.008589969016611576\n",
      "Iteration: 8108/10000, Loss: 0.004142898600548506\n",
      "Iteration: 8109/10000, Loss: 0.010682320222258568\n",
      "Iteration: 8110/10000, Loss: 0.014810098335146904\n",
      "Iteration: 8111/10000, Loss: 0.010493400506675243\n",
      "Iteration: 8112/10000, Loss: 0.012181325815618038\n",
      "Iteration: 8113/10000, Loss: 0.009422051720321178\n",
      "Iteration: 8114/10000, Loss: 0.006805508863180876\n",
      "Iteration: 8115/10000, Loss: 0.012455048970878124\n",
      "Iteration: 8116/10000, Loss: 0.00919432658702135\n",
      "Iteration: 8117/10000, Loss: 0.01151802483946085\n",
      "Iteration: 8118/10000, Loss: 0.007410414516925812\n",
      "Iteration: 8119/10000, Loss: 0.009616212919354439\n",
      "Iteration: 8120/10000, Loss: 0.011808064766228199\n",
      "Iteration: 8121/10000, Loss: 0.0063630943186581135\n",
      "Iteration: 8122/10000, Loss: 0.010565928183495998\n",
      "Iteration: 8123/10000, Loss: 0.009243086911737919\n",
      "Iteration: 8124/10000, Loss: 0.0042238421738147736\n",
      "Iteration: 8125/10000, Loss: 0.014773577451705933\n",
      "Iteration: 8126/10000, Loss: 0.009827741421759129\n",
      "Iteration: 8127/10000, Loss: 0.011949746869504452\n",
      "Iteration: 8128/10000, Loss: 0.010012888349592686\n",
      "Iteration: 8129/10000, Loss: 0.00737359095364809\n",
      "Iteration: 8130/10000, Loss: 0.012698622420430183\n",
      "Iteration: 8131/10000, Loss: 0.0095109473913908\n",
      "Iteration: 8132/10000, Loss: 0.010501612909138203\n",
      "Iteration: 8133/10000, Loss: 0.010413730517029762\n",
      "Iteration: 8134/10000, Loss: 0.011303579434752464\n",
      "Iteration: 8135/10000, Loss: 0.005883934907615185\n",
      "Iteration: 8136/10000, Loss: 0.006673686672002077\n",
      "Iteration: 8137/10000, Loss: 0.014985132031142712\n",
      "Iteration: 8138/10000, Loss: 0.0026685651391744614\n",
      "Iteration: 8139/10000, Loss: 0.008631791919469833\n",
      "Iteration: 8140/10000, Loss: 0.010387717746198177\n",
      "Iteration: 8141/10000, Loss: 0.010699864476919174\n",
      "Iteration: 8142/10000, Loss: 0.008896095678210258\n",
      "Iteration: 8143/10000, Loss: 0.007664750795811415\n",
      "Iteration: 8144/10000, Loss: 0.0059793549589812756\n",
      "Iteration: 8145/10000, Loss: 0.011934756301343441\n",
      "Iteration: 8146/10000, Loss: 0.010736197233200073\n",
      "Iteration: 8147/10000, Loss: 0.011272836476564407\n",
      "Iteration: 8148/10000, Loss: 0.011971223168075085\n",
      "Iteration: 8149/10000, Loss: 0.008253145031630993\n",
      "Iteration: 8150/10000, Loss: 0.006821842398494482\n",
      "Iteration: 8151/10000, Loss: 0.008819421753287315\n",
      "Iteration: 8152/10000, Loss: 0.008453541435301304\n",
      "Iteration: 8153/10000, Loss: 0.010602894239127636\n",
      "Iteration: 8154/10000, Loss: 0.011942188255488873\n",
      "Iteration: 8155/10000, Loss: 0.00928622018545866\n",
      "Iteration: 8156/10000, Loss: 0.01120352279394865\n",
      "Iteration: 8157/10000, Loss: 0.010219146497547626\n",
      "Iteration: 8158/10000, Loss: 0.010593499056994915\n",
      "Iteration: 8159/10000, Loss: 0.009654420427978039\n",
      "Iteration: 8160/10000, Loss: 0.008240685798227787\n",
      "Iteration: 8161/10000, Loss: 0.007641670294106007\n",
      "Iteration: 8162/10000, Loss: 0.007818820886313915\n",
      "Iteration: 8163/10000, Loss: 0.014440190978348255\n",
      "Iteration: 8164/10000, Loss: 0.008939237333834171\n",
      "Iteration: 8165/10000, Loss: 0.005831469781696796\n",
      "Iteration: 8166/10000, Loss: 0.003648590063676238\n",
      "Iteration: 8167/10000, Loss: 0.009635720402002335\n",
      "Iteration: 8168/10000, Loss: 0.006893893238157034\n",
      "Iteration: 8169/10000, Loss: 0.011042248457670212\n",
      "Iteration: 8170/10000, Loss: 0.008820446208119392\n",
      "Iteration: 8171/10000, Loss: 0.008624742738902569\n",
      "Iteration: 8172/10000, Loss: 0.011673052795231342\n",
      "Iteration: 8173/10000, Loss: 0.013555934652686119\n",
      "Iteration: 8174/10000, Loss: 0.011705294251441956\n",
      "Iteration: 8175/10000, Loss: 0.009312647394835949\n",
      "Iteration: 8176/10000, Loss: 0.010583344846963882\n",
      "Iteration: 8177/10000, Loss: 0.006215187255293131\n",
      "Iteration: 8178/10000, Loss: 0.01280870009213686\n",
      "Iteration: 8179/10000, Loss: 0.011765818111598492\n",
      "Iteration: 8180/10000, Loss: 0.006398690398782492\n",
      "Iteration: 8181/10000, Loss: 0.00807767640799284\n",
      "Iteration: 8182/10000, Loss: 0.010787692852318287\n",
      "Iteration: 8183/10000, Loss: 0.009876210242509842\n",
      "Iteration: 8184/10000, Loss: 0.010027552954852581\n",
      "Iteration: 8185/10000, Loss: 0.0082249129191041\n",
      "Iteration: 8186/10000, Loss: 0.00986548513174057\n",
      "Iteration: 8187/10000, Loss: 0.011443983763456345\n",
      "Iteration: 8188/10000, Loss: 0.008375733159482479\n",
      "Iteration: 8189/10000, Loss: 0.007821346633136272\n",
      "Iteration: 8190/10000, Loss: 0.00959381926804781\n",
      "Iteration: 8191/10000, Loss: 0.008878294378519058\n",
      "Iteration: 8192/10000, Loss: 0.010951321572065353\n",
      "Iteration: 8193/10000, Loss: 0.009689366444945335\n",
      "Iteration: 8194/10000, Loss: 0.005991360172629356\n",
      "Iteration: 8195/10000, Loss: 0.011601877398788929\n",
      "Iteration: 8196/10000, Loss: 0.010198528878390789\n",
      "Iteration: 8197/10000, Loss: 0.008951181545853615\n",
      "Iteration: 8198/10000, Loss: 0.01009747851639986\n",
      "Iteration: 8199/10000, Loss: 0.009935150854289532\n",
      "Iteration: 8200/10000, Loss: 0.011080926284193993\n",
      "Average test loss:  0.0018\n",
      "Iteration: 8201/10000, Loss: 0.00905374251306057\n",
      "Iteration: 8202/10000, Loss: 0.0093084666877985\n",
      "Iteration: 8203/10000, Loss: 0.010282400995492935\n",
      "Iteration: 8204/10000, Loss: 0.010854971595108509\n",
      "Iteration: 8205/10000, Loss: 0.010571856983006\n",
      "Iteration: 8206/10000, Loss: 0.011516403406858444\n",
      "Iteration: 8207/10000, Loss: 0.006731276400387287\n",
      "Iteration: 8208/10000, Loss: 0.009166606701910496\n",
      "Iteration: 8209/10000, Loss: 0.010646488517522812\n",
      "Iteration: 8210/10000, Loss: 0.012294490821659565\n",
      "Iteration: 8211/10000, Loss: 0.01524601224809885\n",
      "Iteration: 8212/10000, Loss: 0.005324029829353094\n",
      "Iteration: 8213/10000, Loss: 0.011226684786379337\n",
      "Iteration: 8214/10000, Loss: 0.004256281536072493\n",
      "Iteration: 8215/10000, Loss: 0.012196254916489124\n",
      "Iteration: 8216/10000, Loss: 0.010153587907552719\n",
      "Iteration: 8217/10000, Loss: 0.01074342429637909\n",
      "Iteration: 8218/10000, Loss: 0.015787266194820404\n",
      "Iteration: 8219/10000, Loss: 0.006364723201841116\n",
      "Iteration: 8220/10000, Loss: 0.008128252811729908\n",
      "Iteration: 8221/10000, Loss: 0.008811683394014835\n",
      "Iteration: 8222/10000, Loss: 0.011029222048819065\n",
      "Iteration: 8223/10000, Loss: 0.01340633537620306\n",
      "Iteration: 8224/10000, Loss: 0.012940958142280579\n",
      "Iteration: 8225/10000, Loss: 0.009377147071063519\n",
      "Iteration: 8226/10000, Loss: 0.012463654391467571\n",
      "Iteration: 8227/10000, Loss: 0.010460576973855495\n",
      "Iteration: 8228/10000, Loss: 0.007638505194336176\n",
      "Iteration: 8229/10000, Loss: 0.01322485227137804\n",
      "Iteration: 8230/10000, Loss: 0.01120054256170988\n",
      "Iteration: 8231/10000, Loss: 0.014004690572619438\n",
      "Iteration: 8232/10000, Loss: 0.008027723990380764\n",
      "Iteration: 8233/10000, Loss: 0.008830782026052475\n",
      "Iteration: 8234/10000, Loss: 0.006171535700559616\n",
      "Iteration: 8235/10000, Loss: 0.006685113068670034\n",
      "Iteration: 8236/10000, Loss: 0.006259969435632229\n",
      "Iteration: 8237/10000, Loss: 0.008512546308338642\n",
      "Iteration: 8238/10000, Loss: 0.012214481830596924\n",
      "Iteration: 8239/10000, Loss: 0.014131319709122181\n",
      "Iteration: 8240/10000, Loss: 0.010945302434265614\n",
      "Iteration: 8241/10000, Loss: 0.011696171015501022\n",
      "Iteration: 8242/10000, Loss: 0.008820842951536179\n",
      "Iteration: 8243/10000, Loss: 0.010842840187251568\n",
      "Iteration: 8244/10000, Loss: 0.011417278088629246\n",
      "Iteration: 8245/10000, Loss: 0.012873871251940727\n",
      "Iteration: 8246/10000, Loss: 0.010043858550488949\n",
      "Iteration: 8247/10000, Loss: 0.010580490343272686\n",
      "Iteration: 8248/10000, Loss: 0.013366509228944778\n",
      "Iteration: 8249/10000, Loss: 0.010775563307106495\n",
      "Iteration: 8250/10000, Loss: 0.009705792181193829\n",
      "Iteration: 8251/10000, Loss: 0.008514486253261566\n",
      "Iteration: 8252/10000, Loss: 0.014042978174984455\n",
      "Iteration: 8253/10000, Loss: 0.00898738019168377\n",
      "Iteration: 8254/10000, Loss: 0.009894207119941711\n",
      "Iteration: 8255/10000, Loss: 0.009908952750265598\n",
      "Iteration: 8256/10000, Loss: 0.003124764421954751\n",
      "Iteration: 8257/10000, Loss: 0.010389680042862892\n",
      "Iteration: 8258/10000, Loss: 0.010786562226712704\n",
      "Iteration: 8259/10000, Loss: 0.00750965578481555\n",
      "Iteration: 8260/10000, Loss: 0.007727509830147028\n",
      "Iteration: 8261/10000, Loss: 0.00954513531178236\n",
      "Iteration: 8262/10000, Loss: 0.007881883531808853\n",
      "Iteration: 8263/10000, Loss: 0.012082379311323166\n",
      "Iteration: 8264/10000, Loss: 0.00950124952942133\n",
      "Iteration: 8265/10000, Loss: 0.013034496456384659\n",
      "Iteration: 8266/10000, Loss: 0.0070372894406318665\n",
      "Iteration: 8267/10000, Loss: 0.013096310198307037\n",
      "Iteration: 8268/10000, Loss: 0.009912037290632725\n",
      "Iteration: 8269/10000, Loss: 0.010039503686130047\n",
      "Iteration: 8270/10000, Loss: 0.012263664044439793\n",
      "Iteration: 8271/10000, Loss: 0.0069606793113052845\n",
      "Iteration: 8272/10000, Loss: 0.011085525155067444\n",
      "Iteration: 8273/10000, Loss: 0.010018168948590755\n",
      "Iteration: 8274/10000, Loss: 0.01064825989305973\n",
      "Iteration: 8275/10000, Loss: 0.00857593771070242\n",
      "Iteration: 8276/10000, Loss: 0.006903812289237976\n",
      "Iteration: 8277/10000, Loss: 0.009086263366043568\n",
      "Iteration: 8278/10000, Loss: 0.008990523405373096\n",
      "Iteration: 8279/10000, Loss: 0.005452844314277172\n",
      "Iteration: 8280/10000, Loss: 0.010906527750194073\n",
      "Iteration: 8281/10000, Loss: 0.011885126121342182\n",
      "Iteration: 8282/10000, Loss: 0.007829423062503338\n",
      "Iteration: 8283/10000, Loss: 0.013552081771194935\n",
      "Iteration: 8284/10000, Loss: 0.010108407586812973\n",
      "Iteration: 8285/10000, Loss: 0.004991608671844006\n",
      "Iteration: 8286/10000, Loss: 0.01204715296626091\n",
      "Iteration: 8287/10000, Loss: 0.012321225367486477\n",
      "Iteration: 8288/10000, Loss: 0.010778653435409069\n",
      "Iteration: 8289/10000, Loss: 0.009977377951145172\n",
      "Iteration: 8290/10000, Loss: 0.008907904848456383\n",
      "Iteration: 8291/10000, Loss: 0.008586691692471504\n",
      "Iteration: 8292/10000, Loss: 0.007463348098099232\n",
      "Iteration: 8293/10000, Loss: 0.007198791019618511\n",
      "Iteration: 8294/10000, Loss: 0.012012913823127747\n",
      "Iteration: 8295/10000, Loss: 0.009280888363718987\n",
      "Iteration: 8296/10000, Loss: 0.008595249615609646\n",
      "Iteration: 8297/10000, Loss: 0.010909894481301308\n",
      "Iteration: 8298/10000, Loss: 0.010392741300165653\n",
      "Iteration: 8299/10000, Loss: 0.007990162819623947\n",
      "Iteration: 8300/10000, Loss: 0.007816365920007229\n",
      "Average test loss:  0.0033\n",
      "Iteration: 8301/10000, Loss: 0.006494533270597458\n",
      "Iteration: 8302/10000, Loss: 0.0130296116694808\n",
      "Iteration: 8303/10000, Loss: 0.010127569548785686\n",
      "Iteration: 8304/10000, Loss: 0.007910067215561867\n",
      "Iteration: 8305/10000, Loss: 0.012021149508655071\n",
      "Iteration: 8306/10000, Loss: 0.010342820547521114\n",
      "Iteration: 8307/10000, Loss: 0.00562296062707901\n",
      "Iteration: 8308/10000, Loss: 0.014750862494111061\n",
      "Iteration: 8309/10000, Loss: 0.010114763863384724\n",
      "Iteration: 8310/10000, Loss: 0.010086881928145885\n",
      "Iteration: 8311/10000, Loss: 0.012479225173592567\n",
      "Iteration: 8312/10000, Loss: 0.008002226240932941\n",
      "Iteration: 8313/10000, Loss: 0.008022249676287174\n",
      "Iteration: 8314/10000, Loss: 0.010988950729370117\n",
      "Iteration: 8315/10000, Loss: 0.009213784709572792\n",
      "Iteration: 8316/10000, Loss: 0.007428822573274374\n",
      "Iteration: 8317/10000, Loss: 0.008157525211572647\n",
      "Iteration: 8318/10000, Loss: 0.011787657625973225\n",
      "Iteration: 8319/10000, Loss: 0.008355014957487583\n",
      "Iteration: 8320/10000, Loss: 0.0052963425405323505\n",
      "Iteration: 8321/10000, Loss: 0.007993320003151894\n",
      "Iteration: 8322/10000, Loss: 0.008869223296642303\n",
      "Iteration: 8323/10000, Loss: 0.011009222827851772\n",
      "Iteration: 8324/10000, Loss: 0.008723919279873371\n",
      "Iteration: 8325/10000, Loss: 0.009266379289329052\n",
      "Iteration: 8326/10000, Loss: 0.009803585708141327\n",
      "Iteration: 8327/10000, Loss: 0.007415234576910734\n",
      "Iteration: 8328/10000, Loss: 0.004169468302279711\n",
      "Iteration: 8329/10000, Loss: 0.008262325078248978\n",
      "Iteration: 8330/10000, Loss: 0.013295875862240791\n",
      "Iteration: 8331/10000, Loss: 0.007431352976709604\n",
      "Iteration: 8332/10000, Loss: 0.010130072943866253\n",
      "Iteration: 8333/10000, Loss: 0.008806577883660793\n",
      "Iteration: 8334/10000, Loss: 0.0063204276375472546\n",
      "Iteration: 8335/10000, Loss: 0.007504391483962536\n",
      "Iteration: 8336/10000, Loss: 0.005902097560465336\n",
      "Iteration: 8337/10000, Loss: 0.0086403489112854\n",
      "Iteration: 8338/10000, Loss: 0.010183827951550484\n",
      "Iteration: 8339/10000, Loss: 0.010091235861182213\n",
      "Iteration: 8340/10000, Loss: 0.008503980003297329\n",
      "Iteration: 8341/10000, Loss: 0.007474880199879408\n",
      "Iteration: 8342/10000, Loss: 0.008816871792078018\n",
      "Iteration: 8343/10000, Loss: 0.011107000522315502\n",
      "Iteration: 8344/10000, Loss: 0.011462750844657421\n",
      "Iteration: 8345/10000, Loss: 0.004774316679686308\n",
      "Iteration: 8346/10000, Loss: 0.011209854856133461\n",
      "Iteration: 8347/10000, Loss: 0.005394128151237965\n",
      "Iteration: 8348/10000, Loss: 0.009967783465981483\n",
      "Iteration: 8349/10000, Loss: 0.008266743272542953\n",
      "Iteration: 8350/10000, Loss: 0.012025461532175541\n",
      "Iteration: 8351/10000, Loss: 0.008437355048954487\n",
      "Iteration: 8352/10000, Loss: 0.00865227822214365\n",
      "Iteration: 8353/10000, Loss: 0.008938421495258808\n",
      "Iteration: 8354/10000, Loss: 0.008407455869019032\n",
      "Iteration: 8355/10000, Loss: 0.009177989326417446\n",
      "Iteration: 8356/10000, Loss: 0.007143217138946056\n",
      "Iteration: 8357/10000, Loss: 0.009394346736371517\n",
      "Iteration: 8358/10000, Loss: 0.009651943109929562\n",
      "Iteration: 8359/10000, Loss: 0.012431508861482143\n",
      "Iteration: 8360/10000, Loss: 0.007266518659889698\n",
      "Iteration: 8361/10000, Loss: 0.008171754889190197\n",
      "Iteration: 8362/10000, Loss: 0.011392149142920971\n",
      "Iteration: 8363/10000, Loss: 0.010538632050156593\n",
      "Iteration: 8364/10000, Loss: 0.013333571143448353\n",
      "Iteration: 8365/10000, Loss: 0.0067621441558003426\n",
      "Iteration: 8366/10000, Loss: 0.007886338979005814\n",
      "Iteration: 8367/10000, Loss: 0.009164472110569477\n",
      "Iteration: 8368/10000, Loss: 0.008982961066067219\n",
      "Iteration: 8369/10000, Loss: 0.013166301883757114\n",
      "Iteration: 8370/10000, Loss: 0.005259934347122908\n",
      "Iteration: 8371/10000, Loss: 0.009284371510148048\n",
      "Iteration: 8372/10000, Loss: 0.011640463024377823\n",
      "Iteration: 8373/10000, Loss: 0.01110871136188507\n",
      "Iteration: 8374/10000, Loss: 0.011623595841228962\n",
      "Iteration: 8375/10000, Loss: 0.008991093374788761\n",
      "Iteration: 8376/10000, Loss: 0.00897396169602871\n",
      "Iteration: 8377/10000, Loss: 0.007460581138730049\n",
      "Iteration: 8378/10000, Loss: 0.007207745220512152\n",
      "Iteration: 8379/10000, Loss: 0.009207004681229591\n",
      "Iteration: 8380/10000, Loss: 0.00861373357474804\n",
      "Iteration: 8381/10000, Loss: 0.008004122413694859\n",
      "Iteration: 8382/10000, Loss: 0.009711249731481075\n",
      "Iteration: 8383/10000, Loss: 0.007468243129551411\n",
      "Iteration: 8384/10000, Loss: 0.013639785349369049\n",
      "Iteration: 8385/10000, Loss: 0.007516576908528805\n",
      "Iteration: 8386/10000, Loss: 0.01327067892998457\n",
      "Iteration: 8387/10000, Loss: 0.0061410642229020596\n",
      "Iteration: 8388/10000, Loss: 0.011440329253673553\n",
      "Iteration: 8389/10000, Loss: 0.010846876539289951\n",
      "Iteration: 8390/10000, Loss: 0.010390753857791424\n",
      "Iteration: 8391/10000, Loss: 0.009708144702017307\n",
      "Iteration: 8392/10000, Loss: 0.0069802189245820045\n",
      "Iteration: 8393/10000, Loss: 0.011118956841528416\n",
      "Iteration: 8394/10000, Loss: 0.008062019944190979\n",
      "Iteration: 8395/10000, Loss: 0.011831996962428093\n",
      "Iteration: 8396/10000, Loss: 0.011967859230935574\n",
      "Iteration: 8397/10000, Loss: 0.0056033688597381115\n",
      "Iteration: 8398/10000, Loss: 0.007656763773411512\n",
      "Iteration: 8399/10000, Loss: 0.005405532196164131\n",
      "Iteration: 8400/10000, Loss: 0.00746317021548748\n",
      "Average test loss:  0.0041\n",
      "Iteration: 8401/10000, Loss: 0.0095016835257411\n",
      "Iteration: 8402/10000, Loss: 0.0103817880153656\n",
      "Iteration: 8403/10000, Loss: 0.009344587102532387\n",
      "Iteration: 8404/10000, Loss: 0.012387405149638653\n",
      "Iteration: 8405/10000, Loss: 0.008322106674313545\n",
      "Iteration: 8406/10000, Loss: 0.009401412680745125\n",
      "Iteration: 8407/10000, Loss: 0.010014563798904419\n",
      "Iteration: 8408/10000, Loss: 0.007317223120480776\n",
      "Iteration: 8409/10000, Loss: 0.004840126261115074\n",
      "Iteration: 8410/10000, Loss: 0.010460862889885902\n",
      "Iteration: 8411/10000, Loss: 0.011306395754218102\n",
      "Iteration: 8412/10000, Loss: 0.00519784539937973\n",
      "Iteration: 8413/10000, Loss: 0.010472261346876621\n",
      "Iteration: 8414/10000, Loss: 0.010030140168964863\n",
      "Iteration: 8415/10000, Loss: 0.010491756722331047\n",
      "Iteration: 8416/10000, Loss: 0.008110420778393745\n",
      "Iteration: 8417/10000, Loss: 0.006845456548035145\n",
      "Iteration: 8418/10000, Loss: 0.01448490098118782\n",
      "Iteration: 8419/10000, Loss: 0.01326561439782381\n",
      "Iteration: 8420/10000, Loss: 0.017140870913863182\n",
      "Iteration: 8421/10000, Loss: 0.008906293660402298\n",
      "Iteration: 8422/10000, Loss: 0.008367587812244892\n",
      "Iteration: 8423/10000, Loss: 0.010122337378561497\n",
      "Iteration: 8424/10000, Loss: 0.00795538630336523\n",
      "Iteration: 8425/10000, Loss: 0.011002674698829651\n",
      "Iteration: 8426/10000, Loss: 0.01368689350783825\n",
      "Iteration: 8427/10000, Loss: 0.012120746076107025\n",
      "Iteration: 8428/10000, Loss: 0.008248593658208847\n",
      "Iteration: 8429/10000, Loss: 0.008639559149742126\n",
      "Iteration: 8430/10000, Loss: 0.006020197179168463\n",
      "Iteration: 8431/10000, Loss: 0.006610096897929907\n",
      "Iteration: 8432/10000, Loss: 0.013460777699947357\n",
      "Iteration: 8433/10000, Loss: 0.010498723946511745\n",
      "Iteration: 8434/10000, Loss: 0.012658750638365746\n",
      "Iteration: 8435/10000, Loss: 0.009718211367726326\n",
      "Iteration: 8436/10000, Loss: 0.007216812577098608\n",
      "Iteration: 8437/10000, Loss: 0.01056759338825941\n",
      "Iteration: 8438/10000, Loss: 0.01097133383154869\n",
      "Iteration: 8439/10000, Loss: 0.007932675071060658\n",
      "Iteration: 8440/10000, Loss: 0.005304343067109585\n",
      "Iteration: 8441/10000, Loss: 0.00855262205004692\n",
      "Iteration: 8442/10000, Loss: 0.005323783494532108\n",
      "Iteration: 8443/10000, Loss: 0.008985372260212898\n",
      "Iteration: 8444/10000, Loss: 0.013600789941847324\n",
      "Iteration: 8445/10000, Loss: 0.008753899484872818\n",
      "Iteration: 8446/10000, Loss: 0.02070760168135166\n",
      "Iteration: 8447/10000, Loss: 0.010888920165598392\n",
      "Iteration: 8448/10000, Loss: 0.009345692582428455\n",
      "Iteration: 8449/10000, Loss: 0.013028020970523357\n",
      "Iteration: 8450/10000, Loss: 0.00762792956084013\n",
      "Iteration: 8451/10000, Loss: 0.00866742618381977\n",
      "Iteration: 8452/10000, Loss: 0.01418327447026968\n",
      "Iteration: 8453/10000, Loss: 0.011649053543806076\n",
      "Iteration: 8454/10000, Loss: 0.008682823739945889\n",
      "Iteration: 8455/10000, Loss: 0.010075495578348637\n",
      "Iteration: 8456/10000, Loss: 0.008857354521751404\n",
      "Iteration: 8457/10000, Loss: 0.011869803071022034\n",
      "Iteration: 8458/10000, Loss: 0.01089589111506939\n",
      "Iteration: 8459/10000, Loss: 0.011591103859245777\n",
      "Iteration: 8460/10000, Loss: 0.010267502628266811\n",
      "Iteration: 8461/10000, Loss: 0.012545496225357056\n",
      "Iteration: 8462/10000, Loss: 0.00888875126838684\n",
      "Iteration: 8463/10000, Loss: 0.008846619166433811\n",
      "Iteration: 8464/10000, Loss: 0.008904232643544674\n",
      "Iteration: 8465/10000, Loss: 0.009967144578695297\n",
      "Iteration: 8466/10000, Loss: 0.013070820830762386\n",
      "Iteration: 8467/10000, Loss: 0.011731710284948349\n",
      "Iteration: 8468/10000, Loss: 0.012799869291484356\n",
      "Iteration: 8469/10000, Loss: 0.013025861233472824\n",
      "Iteration: 8470/10000, Loss: 0.01307549886405468\n",
      "Iteration: 8471/10000, Loss: 0.011203265748918056\n",
      "Iteration: 8472/10000, Loss: 0.01196923479437828\n",
      "Iteration: 8473/10000, Loss: 0.007084243930876255\n",
      "Iteration: 8474/10000, Loss: 0.008380663581192493\n",
      "Iteration: 8475/10000, Loss: 0.011718794703483582\n",
      "Iteration: 8476/10000, Loss: 0.007669844198971987\n",
      "Iteration: 8477/10000, Loss: 0.01348039135336876\n",
      "Iteration: 8478/10000, Loss: 0.008589822798967361\n",
      "Iteration: 8479/10000, Loss: 0.005554265342652798\n",
      "Iteration: 8480/10000, Loss: 0.01147089246660471\n",
      "Iteration: 8481/10000, Loss: 0.012555968016386032\n",
      "Iteration: 8482/10000, Loss: 0.015051090158522129\n",
      "Iteration: 8483/10000, Loss: 0.009002971462905407\n",
      "Iteration: 8484/10000, Loss: 0.010426037013530731\n",
      "Iteration: 8485/10000, Loss: 0.010642753913998604\n",
      "Iteration: 8486/10000, Loss: 0.008295910432934761\n",
      "Iteration: 8487/10000, Loss: 0.008586186915636063\n",
      "Iteration: 8488/10000, Loss: 0.011778464540839195\n",
      "Iteration: 8489/10000, Loss: 0.010213857516646385\n",
      "Iteration: 8490/10000, Loss: 0.0059576742351055145\n",
      "Iteration: 8491/10000, Loss: 0.008980073034763336\n",
      "Iteration: 8492/10000, Loss: 0.008933943696320057\n",
      "Iteration: 8493/10000, Loss: 0.00819286610931158\n",
      "Iteration: 8494/10000, Loss: 0.007220942061394453\n",
      "Iteration: 8495/10000, Loss: 0.01117351558059454\n",
      "Iteration: 8496/10000, Loss: 0.014044348150491714\n",
      "Iteration: 8497/10000, Loss: 0.009697649627923965\n",
      "Iteration: 8498/10000, Loss: 0.008394254371523857\n",
      "Iteration: 8499/10000, Loss: 0.019223332405090332\n",
      "Iteration: 8500/10000, Loss: 0.012263716198503971\n",
      "Average test loss:  0.0040\n",
      "Iteration: 8501/10000, Loss: 0.012173646129667759\n",
      "Iteration: 8502/10000, Loss: 0.011425763368606567\n",
      "Iteration: 8503/10000, Loss: 0.011370878666639328\n",
      "Iteration: 8504/10000, Loss: 0.008196653798222542\n",
      "Iteration: 8505/10000, Loss: 0.011784681119024754\n",
      "Iteration: 8506/10000, Loss: 0.011211126111447811\n",
      "Iteration: 8507/10000, Loss: 0.013948909007012844\n",
      "Iteration: 8508/10000, Loss: 0.008580978028476238\n",
      "Iteration: 8509/10000, Loss: 0.012029241770505905\n",
      "Iteration: 8510/10000, Loss: 0.010311190038919449\n",
      "Iteration: 8511/10000, Loss: 0.006540297996252775\n",
      "Iteration: 8512/10000, Loss: 0.011178653687238693\n",
      "Iteration: 8513/10000, Loss: 0.00897718034684658\n",
      "Iteration: 8514/10000, Loss: 0.009319826029241085\n",
      "Iteration: 8515/10000, Loss: 0.00894614402204752\n",
      "Iteration: 8516/10000, Loss: 0.012610561214387417\n",
      "Iteration: 8517/10000, Loss: 0.0072920192033052444\n",
      "Iteration: 8518/10000, Loss: 0.006140431389212608\n",
      "Iteration: 8519/10000, Loss: 0.010103407315909863\n",
      "Iteration: 8520/10000, Loss: 0.007560155354440212\n",
      "Iteration: 8521/10000, Loss: 0.011879229918122292\n",
      "Iteration: 8522/10000, Loss: 0.01141800545156002\n",
      "Iteration: 8523/10000, Loss: 0.008549291640520096\n",
      "Iteration: 8524/10000, Loss: 0.010937702842056751\n",
      "Iteration: 8525/10000, Loss: 0.011010429821908474\n",
      "Iteration: 8526/10000, Loss: 0.012103158980607986\n",
      "Iteration: 8527/10000, Loss: 0.015129979699850082\n",
      "Iteration: 8528/10000, Loss: 0.013018338941037655\n",
      "Iteration: 8529/10000, Loss: 0.014131478033959866\n",
      "Iteration: 8530/10000, Loss: 0.011274394579231739\n",
      "Iteration: 8531/10000, Loss: 0.0053318096324801445\n",
      "Iteration: 8532/10000, Loss: 0.006727171596139669\n",
      "Iteration: 8533/10000, Loss: 0.010931055061519146\n",
      "Iteration: 8534/10000, Loss: 0.012473883107304573\n",
      "Iteration: 8535/10000, Loss: 0.00882780272513628\n",
      "Iteration: 8536/10000, Loss: 0.009615661576390266\n",
      "Iteration: 8537/10000, Loss: 0.003755298675969243\n",
      "Iteration: 8538/10000, Loss: 0.007271359208971262\n",
      "Iteration: 8539/10000, Loss: 0.007325731683522463\n",
      "Iteration: 8540/10000, Loss: 0.006856294348835945\n",
      "Iteration: 8541/10000, Loss: 0.006991264875978231\n",
      "Iteration: 8542/10000, Loss: 0.007762148976325989\n",
      "Iteration: 8543/10000, Loss: 0.015143909491598606\n",
      "Iteration: 8544/10000, Loss: 0.007591476663947105\n",
      "Iteration: 8545/10000, Loss: 0.00901369284838438\n",
      "Iteration: 8546/10000, Loss: 0.009102738462388515\n",
      "Iteration: 8547/10000, Loss: 0.012420146726071835\n",
      "Iteration: 8548/10000, Loss: 0.011644312180578709\n",
      "Iteration: 8549/10000, Loss: 0.007846293039619923\n",
      "Iteration: 8550/10000, Loss: 0.008610664866864681\n",
      "Iteration: 8551/10000, Loss: 0.0074776532128453255\n",
      "Iteration: 8552/10000, Loss: 0.011453394778072834\n",
      "Iteration: 8553/10000, Loss: 0.009316925890743732\n",
      "Iteration: 8554/10000, Loss: 0.013910219073295593\n",
      "Iteration: 8555/10000, Loss: 0.007294513285160065\n",
      "Iteration: 8556/10000, Loss: 0.007760063745081425\n",
      "Iteration: 8557/10000, Loss: 0.011551626957952976\n",
      "Iteration: 8558/10000, Loss: 0.01278463564813137\n",
      "Iteration: 8559/10000, Loss: 0.011811807751655579\n",
      "Iteration: 8560/10000, Loss: 0.013324747793376446\n",
      "Iteration: 8561/10000, Loss: 0.011392585001885891\n",
      "Iteration: 8562/10000, Loss: 0.009180654771625996\n",
      "Iteration: 8563/10000, Loss: 0.012630091980099678\n",
      "Iteration: 8564/10000, Loss: 0.011686957441270351\n",
      "Iteration: 8565/10000, Loss: 0.01217549666762352\n",
      "Iteration: 8566/10000, Loss: 0.0069448072463274\n",
      "Iteration: 8567/10000, Loss: 0.012205018661916256\n",
      "Iteration: 8568/10000, Loss: 0.0070530688390135765\n",
      "Iteration: 8569/10000, Loss: 0.010210243985056877\n",
      "Iteration: 8570/10000, Loss: 0.00822246354073286\n",
      "Iteration: 8571/10000, Loss: 0.01657291315495968\n",
      "Iteration: 8572/10000, Loss: 0.008566794916987419\n",
      "Iteration: 8573/10000, Loss: 0.009708897210657597\n",
      "Iteration: 8574/10000, Loss: 0.008518710732460022\n",
      "Iteration: 8575/10000, Loss: 0.008607651107013226\n",
      "Iteration: 8576/10000, Loss: 0.010763213038444519\n",
      "Iteration: 8577/10000, Loss: 0.011276539415121078\n",
      "Iteration: 8578/10000, Loss: 0.0055810133926570415\n",
      "Iteration: 8579/10000, Loss: 0.009048056788742542\n",
      "Iteration: 8580/10000, Loss: 0.007298511918634176\n",
      "Iteration: 8581/10000, Loss: 0.0037889638915657997\n",
      "Iteration: 8582/10000, Loss: 0.006414678879082203\n",
      "Iteration: 8583/10000, Loss: 0.006240620743483305\n",
      "Iteration: 8584/10000, Loss: 0.010730847716331482\n",
      "Iteration: 8585/10000, Loss: 0.005994290579110384\n",
      "Iteration: 8586/10000, Loss: 0.009660487994551659\n",
      "Iteration: 8587/10000, Loss: 0.009161812253296375\n",
      "Iteration: 8588/10000, Loss: 0.011004384607076645\n",
      "Iteration: 8589/10000, Loss: 0.0051801749505102634\n",
      "Iteration: 8590/10000, Loss: 0.012471813708543777\n",
      "Iteration: 8591/10000, Loss: 0.009329748339951038\n",
      "Iteration: 8592/10000, Loss: 0.011797519400715828\n",
      "Iteration: 8593/10000, Loss: 0.004677928984165192\n",
      "Iteration: 8594/10000, Loss: 0.012907009571790695\n",
      "Iteration: 8595/10000, Loss: 0.013522925786674023\n",
      "Iteration: 8596/10000, Loss: 0.009367885999381542\n",
      "Iteration: 8597/10000, Loss: 0.008125802502036095\n",
      "Iteration: 8598/10000, Loss: 0.00953124649822712\n",
      "Iteration: 8599/10000, Loss: 0.007761097047477961\n",
      "Iteration: 8600/10000, Loss: 0.013697137124836445\n",
      "Average test loss:  0.0033\n",
      "Iteration: 8601/10000, Loss: 0.011356187053024769\n",
      "Iteration: 8602/10000, Loss: 0.006915700621902943\n",
      "Iteration: 8603/10000, Loss: 0.010035477578639984\n",
      "Iteration: 8604/10000, Loss: 0.011078555136919022\n",
      "Iteration: 8605/10000, Loss: 0.008895508013665676\n",
      "Iteration: 8606/10000, Loss: 0.007993470877408981\n",
      "Iteration: 8607/10000, Loss: 0.01420386042445898\n",
      "Iteration: 8608/10000, Loss: 0.010786399245262146\n",
      "Iteration: 8609/10000, Loss: 0.011443760246038437\n",
      "Iteration: 8610/10000, Loss: 0.009863292798399925\n",
      "Iteration: 8611/10000, Loss: 0.011868130415678024\n",
      "Iteration: 8612/10000, Loss: 0.009947543032467365\n",
      "Iteration: 8613/10000, Loss: 0.008593342266976833\n",
      "Iteration: 8614/10000, Loss: 0.011142418719828129\n",
      "Iteration: 8615/10000, Loss: 0.010434936732053757\n",
      "Iteration: 8616/10000, Loss: 0.007114695850759745\n",
      "Iteration: 8617/10000, Loss: 0.0086442856118083\n",
      "Iteration: 8618/10000, Loss: 0.005518702790141106\n",
      "Iteration: 8619/10000, Loss: 0.009380107745528221\n",
      "Iteration: 8620/10000, Loss: 0.010826189070940018\n",
      "Iteration: 8621/10000, Loss: 0.010640135034918785\n",
      "Iteration: 8622/10000, Loss: 0.006442542653530836\n",
      "Iteration: 8623/10000, Loss: 0.010674845427274704\n",
      "Iteration: 8624/10000, Loss: 0.008614852093160152\n",
      "Iteration: 8625/10000, Loss: 0.007749876473098993\n",
      "Iteration: 8626/10000, Loss: 0.011482040397822857\n",
      "Iteration: 8627/10000, Loss: 0.014783351682126522\n",
      "Iteration: 8628/10000, Loss: 0.01215381920337677\n",
      "Iteration: 8629/10000, Loss: 0.007199455518275499\n",
      "Iteration: 8630/10000, Loss: 0.011711746454238892\n",
      "Iteration: 8631/10000, Loss: 0.006472641136497259\n",
      "Iteration: 8632/10000, Loss: 0.012809010222554207\n",
      "Iteration: 8633/10000, Loss: 0.009540070779621601\n",
      "Iteration: 8634/10000, Loss: 0.006379177328199148\n",
      "Iteration: 8635/10000, Loss: 0.007542222272604704\n",
      "Iteration: 8636/10000, Loss: 0.009073072113096714\n",
      "Iteration: 8637/10000, Loss: 0.007627564016729593\n",
      "Iteration: 8638/10000, Loss: 0.008631446398794651\n",
      "Iteration: 8639/10000, Loss: 0.011497042141854763\n",
      "Iteration: 8640/10000, Loss: 0.013381644152104855\n",
      "Iteration: 8641/10000, Loss: 0.00890806969255209\n",
      "Iteration: 8642/10000, Loss: 0.009178712032735348\n",
      "Iteration: 8643/10000, Loss: 0.01195977907627821\n",
      "Iteration: 8644/10000, Loss: 0.004356781020760536\n",
      "Iteration: 8645/10000, Loss: 0.005854692775756121\n",
      "Iteration: 8646/10000, Loss: 0.007801087107509375\n",
      "Iteration: 8647/10000, Loss: 0.010341520421206951\n",
      "Iteration: 8648/10000, Loss: 0.009757439605891705\n",
      "Iteration: 8649/10000, Loss: 0.004926692228764296\n",
      "Iteration: 8650/10000, Loss: 0.01090365368872881\n",
      "Iteration: 8651/10000, Loss: 0.011635770089924335\n",
      "Iteration: 8652/10000, Loss: 0.007310810964554548\n",
      "Iteration: 8653/10000, Loss: 0.011691992171108723\n",
      "Iteration: 8654/10000, Loss: 0.0060198185965418816\n",
      "Iteration: 8655/10000, Loss: 0.009982259944081306\n",
      "Iteration: 8656/10000, Loss: 0.00748003413900733\n",
      "Iteration: 8657/10000, Loss: 0.010790567845106125\n",
      "Iteration: 8658/10000, Loss: 0.010591493919491768\n",
      "Iteration: 8659/10000, Loss: 0.008298675529658794\n",
      "Iteration: 8660/10000, Loss: 0.008211676962673664\n",
      "Iteration: 8661/10000, Loss: 0.009958340786397457\n",
      "Iteration: 8662/10000, Loss: 0.007767010945826769\n",
      "Iteration: 8663/10000, Loss: 0.008020044304430485\n",
      "Iteration: 8664/10000, Loss: 0.011260433122515678\n",
      "Iteration: 8665/10000, Loss: 0.009546782821416855\n",
      "Iteration: 8666/10000, Loss: 0.0106644993647933\n",
      "Iteration: 8667/10000, Loss: 0.009167453274130821\n",
      "Iteration: 8668/10000, Loss: 0.007661386393010616\n",
      "Iteration: 8669/10000, Loss: 0.00805816799402237\n",
      "Iteration: 8670/10000, Loss: 0.010507768020033836\n",
      "Iteration: 8671/10000, Loss: 0.008440854027867317\n",
      "Iteration: 8672/10000, Loss: 0.012779196724295616\n",
      "Iteration: 8673/10000, Loss: 0.010996934026479721\n",
      "Iteration: 8674/10000, Loss: 0.004704250954091549\n",
      "Iteration: 8675/10000, Loss: 0.0064619057811796665\n",
      "Iteration: 8676/10000, Loss: 0.004578263033181429\n",
      "Iteration: 8677/10000, Loss: 0.010140343569219112\n",
      "Iteration: 8678/10000, Loss: 0.010020047426223755\n",
      "Iteration: 8679/10000, Loss: 0.0073888530023396015\n",
      "Iteration: 8680/10000, Loss: 0.009537912905216217\n",
      "Iteration: 8681/10000, Loss: 0.008194709196686745\n",
      "Iteration: 8682/10000, Loss: 0.007041292730718851\n",
      "Iteration: 8683/10000, Loss: 0.010592029429972172\n",
      "Iteration: 8684/10000, Loss: 0.015897445380687714\n",
      "Iteration: 8685/10000, Loss: 0.006143589504063129\n",
      "Iteration: 8686/10000, Loss: 0.008585180155932903\n",
      "Iteration: 8687/10000, Loss: 0.008194695226848125\n",
      "Iteration: 8688/10000, Loss: 0.008249773643910885\n",
      "Iteration: 8689/10000, Loss: 0.012536630034446716\n",
      "Iteration: 8690/10000, Loss: 0.009852109476923943\n",
      "Iteration: 8691/10000, Loss: 0.00653334055095911\n",
      "Iteration: 8692/10000, Loss: 0.008934502489864826\n",
      "Iteration: 8693/10000, Loss: 0.009127442725002766\n",
      "Iteration: 8694/10000, Loss: 0.009609171189367771\n",
      "Iteration: 8695/10000, Loss: 0.007782241329550743\n",
      "Iteration: 8696/10000, Loss: 0.008945097215473652\n",
      "Iteration: 8697/10000, Loss: 0.01029979158192873\n",
      "Iteration: 8698/10000, Loss: 0.008985225111246109\n",
      "Iteration: 8699/10000, Loss: 0.00852824654430151\n",
      "Iteration: 8700/10000, Loss: 0.01564270816743374\n",
      "Average test loss:  0.0044\n",
      "Iteration: 8701/10000, Loss: 0.009741175919771194\n",
      "Iteration: 8702/10000, Loss: 0.00958668626844883\n",
      "Iteration: 8703/10000, Loss: 0.008053782396018505\n",
      "Iteration: 8704/10000, Loss: 0.006627896800637245\n",
      "Iteration: 8705/10000, Loss: 0.008839831687510014\n",
      "Iteration: 8706/10000, Loss: 0.011179698631167412\n",
      "Iteration: 8707/10000, Loss: 0.009822377003729343\n",
      "Iteration: 8708/10000, Loss: 0.009656626731157303\n",
      "Iteration: 8709/10000, Loss: 0.009395496919751167\n",
      "Iteration: 8710/10000, Loss: 0.013137566857039928\n",
      "Iteration: 8711/10000, Loss: 0.014068798162043095\n",
      "Iteration: 8712/10000, Loss: 0.013086041435599327\n",
      "Iteration: 8713/10000, Loss: 0.01039119902998209\n",
      "Iteration: 8714/10000, Loss: 0.007615351118147373\n",
      "Iteration: 8715/10000, Loss: 0.014277956448495388\n",
      "Iteration: 8716/10000, Loss: 0.008223391138017178\n",
      "Iteration: 8717/10000, Loss: 0.014404506422579288\n",
      "Iteration: 8718/10000, Loss: 0.0078081111423671246\n",
      "Iteration: 8719/10000, Loss: 0.008816726505756378\n",
      "Iteration: 8720/10000, Loss: 0.012306992895901203\n",
      "Iteration: 8721/10000, Loss: 0.008704664185643196\n",
      "Iteration: 8722/10000, Loss: 0.014779026620090008\n",
      "Iteration: 8723/10000, Loss: 0.012049713172018528\n",
      "Iteration: 8724/10000, Loss: 0.010952908545732498\n",
      "Iteration: 8725/10000, Loss: 0.007839815691113472\n",
      "Iteration: 8726/10000, Loss: 0.008795392699539661\n",
      "Iteration: 8727/10000, Loss: 0.012018277309834957\n",
      "Iteration: 8728/10000, Loss: 0.006557500455528498\n",
      "Iteration: 8729/10000, Loss: 0.008008906617760658\n",
      "Iteration: 8730/10000, Loss: 0.013794338330626488\n",
      "Iteration: 8731/10000, Loss: 0.009355703368782997\n",
      "Iteration: 8732/10000, Loss: 0.010931611992418766\n",
      "Iteration: 8733/10000, Loss: 0.014322914183139801\n",
      "Iteration: 8734/10000, Loss: 0.0075843133963644505\n",
      "Iteration: 8735/10000, Loss: 0.009916329756379128\n",
      "Iteration: 8736/10000, Loss: 0.008308186195790768\n",
      "Iteration: 8737/10000, Loss: 0.006423912476748228\n",
      "Iteration: 8738/10000, Loss: 0.00898156687617302\n",
      "Iteration: 8739/10000, Loss: 0.008284470997750759\n",
      "Iteration: 8740/10000, Loss: 0.010401132516562939\n",
      "Iteration: 8741/10000, Loss: 0.019745899364352226\n",
      "Iteration: 8742/10000, Loss: 0.011414590291678905\n",
      "Iteration: 8743/10000, Loss: 0.00909354817122221\n",
      "Iteration: 8744/10000, Loss: 0.009126940742135048\n",
      "Iteration: 8745/10000, Loss: 0.010311098769307137\n",
      "Iteration: 8746/10000, Loss: 0.008306635543704033\n",
      "Iteration: 8747/10000, Loss: 0.008851250633597374\n",
      "Iteration: 8748/10000, Loss: 0.009204105474054813\n",
      "Iteration: 8749/10000, Loss: 0.010768793523311615\n",
      "Iteration: 8750/10000, Loss: 0.015741320326924324\n",
      "Iteration: 8751/10000, Loss: 0.007916863076388836\n",
      "Iteration: 8752/10000, Loss: 0.011437686160206795\n",
      "Iteration: 8753/10000, Loss: 0.01595408096909523\n",
      "Iteration: 8754/10000, Loss: 0.007942122407257557\n",
      "Iteration: 8755/10000, Loss: 0.011413763277232647\n",
      "Iteration: 8756/10000, Loss: 0.009752032347023487\n",
      "Iteration: 8757/10000, Loss: 0.008965728804469109\n",
      "Iteration: 8758/10000, Loss: 0.011681266129016876\n",
      "Iteration: 8759/10000, Loss: 0.009798946790397167\n",
      "Iteration: 8760/10000, Loss: 0.011791504919528961\n",
      "Iteration: 8761/10000, Loss: 0.010690735653042793\n",
      "Iteration: 8762/10000, Loss: 0.011398940347135067\n",
      "Iteration: 8763/10000, Loss: 0.006752047222107649\n",
      "Iteration: 8764/10000, Loss: 0.0118316151201725\n",
      "Iteration: 8765/10000, Loss: 0.007819580845534801\n",
      "Iteration: 8766/10000, Loss: 0.014825362712144852\n",
      "Iteration: 8767/10000, Loss: 0.011618680320680141\n",
      "Iteration: 8768/10000, Loss: 0.00982387363910675\n",
      "Iteration: 8769/10000, Loss: 0.013231155462563038\n",
      "Iteration: 8770/10000, Loss: 0.009556070901453495\n",
      "Iteration: 8771/10000, Loss: 0.012319967150688171\n",
      "Iteration: 8772/10000, Loss: 0.009057017043232918\n",
      "Iteration: 8773/10000, Loss: 0.005040470976382494\n",
      "Iteration: 8774/10000, Loss: 0.007678513880819082\n",
      "Iteration: 8775/10000, Loss: 0.013460983522236347\n",
      "Iteration: 8776/10000, Loss: 0.009918669238686562\n",
      "Iteration: 8777/10000, Loss: 0.009085523895919323\n",
      "Iteration: 8778/10000, Loss: 0.010630018077790737\n",
      "Iteration: 8779/10000, Loss: 0.006790739484131336\n",
      "Iteration: 8780/10000, Loss: 0.0097648361697793\n",
      "Iteration: 8781/10000, Loss: 0.009277267381548882\n",
      "Iteration: 8782/10000, Loss: 0.007774229161441326\n",
      "Iteration: 8783/10000, Loss: 0.012733696959912777\n",
      "Iteration: 8784/10000, Loss: 0.007914887741208076\n",
      "Iteration: 8785/10000, Loss: 0.008156432770192623\n",
      "Iteration: 8786/10000, Loss: 0.014013177715241909\n",
      "Iteration: 8787/10000, Loss: 0.008261127397418022\n",
      "Iteration: 8788/10000, Loss: 0.009979729540646076\n",
      "Iteration: 8789/10000, Loss: 0.013754039071500301\n",
      "Iteration: 8790/10000, Loss: 0.006739479023963213\n",
      "Iteration: 8791/10000, Loss: 0.010601328685879707\n",
      "Iteration: 8792/10000, Loss: 0.00942188873887062\n",
      "Iteration: 8793/10000, Loss: 0.0060301488265395164\n",
      "Iteration: 8794/10000, Loss: 0.010901957750320435\n",
      "Iteration: 8795/10000, Loss: 0.009831910952925682\n",
      "Iteration: 8796/10000, Loss: 0.009557715617120266\n",
      "Iteration: 8797/10000, Loss: 0.009527145884931087\n",
      "Iteration: 8798/10000, Loss: 0.008391239680349827\n",
      "Iteration: 8799/10000, Loss: 0.0064927381463348866\n",
      "Iteration: 8800/10000, Loss: 0.006882254499942064\n",
      "Average test loss:  0.0030\n",
      "Iteration: 8801/10000, Loss: 0.006034525111317635\n",
      "Iteration: 8802/10000, Loss: 0.007054619491100311\n",
      "Iteration: 8803/10000, Loss: 0.013316407799720764\n",
      "Iteration: 8804/10000, Loss: 0.006465859245508909\n",
      "Iteration: 8805/10000, Loss: 0.00869984645396471\n",
      "Iteration: 8806/10000, Loss: 0.013962247408926487\n",
      "Iteration: 8807/10000, Loss: 0.0089937848970294\n",
      "Iteration: 8808/10000, Loss: 0.008536803536117077\n",
      "Iteration: 8809/10000, Loss: 0.00665340106934309\n",
      "Iteration: 8810/10000, Loss: 0.010134720243513584\n",
      "Iteration: 8811/10000, Loss: 0.007942022755742073\n",
      "Iteration: 8812/10000, Loss: 0.00981426052749157\n",
      "Iteration: 8813/10000, Loss: 0.007228550035506487\n",
      "Iteration: 8814/10000, Loss: 0.007668428588658571\n",
      "Iteration: 8815/10000, Loss: 0.009624157100915909\n",
      "Iteration: 8816/10000, Loss: 0.009456594474613667\n",
      "Iteration: 8817/10000, Loss: 0.010006559081375599\n",
      "Iteration: 8818/10000, Loss: 0.0118781179189682\n",
      "Iteration: 8819/10000, Loss: 0.009636846370995045\n",
      "Iteration: 8820/10000, Loss: 0.010816913098096848\n",
      "Iteration: 8821/10000, Loss: 0.006038991268724203\n",
      "Iteration: 8822/10000, Loss: 0.008871177211403847\n",
      "Iteration: 8823/10000, Loss: 0.010583519004285336\n",
      "Iteration: 8824/10000, Loss: 0.007960964925587177\n",
      "Iteration: 8825/10000, Loss: 0.008097981102764606\n",
      "Iteration: 8826/10000, Loss: 0.013638036325573921\n",
      "Iteration: 8827/10000, Loss: 0.01567762717604637\n",
      "Iteration: 8828/10000, Loss: 0.008238897658884525\n",
      "Iteration: 8829/10000, Loss: 0.003147024428471923\n",
      "Iteration: 8830/10000, Loss: 0.007911339402198792\n",
      "Iteration: 8831/10000, Loss: 0.009867893531918526\n",
      "Iteration: 8832/10000, Loss: 0.010518721304833889\n",
      "Iteration: 8833/10000, Loss: 0.013561082072556019\n",
      "Iteration: 8834/10000, Loss: 0.010313560254871845\n",
      "Iteration: 8835/10000, Loss: 0.007810188457369804\n",
      "Iteration: 8836/10000, Loss: 0.010931547731161118\n",
      "Iteration: 8837/10000, Loss: 0.006561517249792814\n",
      "Iteration: 8838/10000, Loss: 0.012806099839508533\n",
      "Iteration: 8839/10000, Loss: 0.011083562858402729\n",
      "Iteration: 8840/10000, Loss: 0.011690262705087662\n",
      "Iteration: 8841/10000, Loss: 0.013383572921156883\n",
      "Iteration: 8842/10000, Loss: 0.009052288718521595\n",
      "Iteration: 8843/10000, Loss: 0.013277172110974789\n",
      "Iteration: 8844/10000, Loss: 0.008548621088266373\n",
      "Iteration: 8845/10000, Loss: 0.007783819921314716\n",
      "Iteration: 8846/10000, Loss: 0.00833963043987751\n",
      "Iteration: 8847/10000, Loss: 0.014945712871849537\n",
      "Iteration: 8848/10000, Loss: 0.007385424338281155\n",
      "Iteration: 8849/10000, Loss: 0.010986309498548508\n",
      "Iteration: 8850/10000, Loss: 0.0047418177127838135\n",
      "Iteration: 8851/10000, Loss: 0.01204206794500351\n",
      "Iteration: 8852/10000, Loss: 0.008980411104857922\n",
      "Iteration: 8853/10000, Loss: 0.008316284976899624\n",
      "Iteration: 8854/10000, Loss: 0.008957380428910255\n",
      "Iteration: 8855/10000, Loss: 0.009662557393312454\n",
      "Iteration: 8856/10000, Loss: 0.011617223732173443\n",
      "Iteration: 8857/10000, Loss: 0.012027907185256481\n",
      "Iteration: 8858/10000, Loss: 0.00791708193719387\n",
      "Iteration: 8859/10000, Loss: 0.006472548004239798\n",
      "Iteration: 8860/10000, Loss: 0.009256604127585888\n",
      "Iteration: 8861/10000, Loss: 0.009460062719881535\n",
      "Iteration: 8862/10000, Loss: 0.011850928887724876\n",
      "Iteration: 8863/10000, Loss: 0.011101840063929558\n",
      "Iteration: 8864/10000, Loss: 0.00894807931035757\n",
      "Iteration: 8865/10000, Loss: 0.008549995720386505\n",
      "Iteration: 8866/10000, Loss: 0.009267437271773815\n",
      "Iteration: 8867/10000, Loss: 0.011929181404411793\n",
      "Iteration: 8868/10000, Loss: 0.008444187231361866\n",
      "Iteration: 8869/10000, Loss: 0.009640848264098167\n",
      "Iteration: 8870/10000, Loss: 0.008097534999251366\n",
      "Iteration: 8871/10000, Loss: 0.010236377827823162\n",
      "Iteration: 8872/10000, Loss: 0.011770695447921753\n",
      "Iteration: 8873/10000, Loss: 0.01113227941095829\n",
      "Iteration: 8874/10000, Loss: 0.008716681972146034\n",
      "Iteration: 8875/10000, Loss: 0.00816990528255701\n",
      "Iteration: 8876/10000, Loss: 0.008859953843057156\n",
      "Iteration: 8877/10000, Loss: 0.007217041682451963\n",
      "Iteration: 8878/10000, Loss: 0.010649551637470722\n",
      "Iteration: 8879/10000, Loss: 0.011020501144230366\n",
      "Iteration: 8880/10000, Loss: 0.007588356267660856\n",
      "Iteration: 8881/10000, Loss: 0.009951579384505749\n",
      "Iteration: 8882/10000, Loss: 0.007124557625502348\n",
      "Iteration: 8883/10000, Loss: 0.007422817405313253\n",
      "Iteration: 8884/10000, Loss: 0.0089559406042099\n",
      "Iteration: 8885/10000, Loss: 0.014142953790724277\n",
      "Iteration: 8886/10000, Loss: 0.011941584758460522\n",
      "Iteration: 8887/10000, Loss: 0.007552113849669695\n",
      "Iteration: 8888/10000, Loss: 0.011899294331669807\n",
      "Iteration: 8889/10000, Loss: 0.013769732788205147\n",
      "Iteration: 8890/10000, Loss: 0.008743123151361942\n",
      "Iteration: 8891/10000, Loss: 0.01420227438211441\n",
      "Iteration: 8892/10000, Loss: 0.010031607002019882\n",
      "Iteration: 8893/10000, Loss: 0.010628607124090195\n",
      "Iteration: 8894/10000, Loss: 0.00949870329350233\n",
      "Iteration: 8895/10000, Loss: 0.010190999135375023\n",
      "Iteration: 8896/10000, Loss: 0.010991099290549755\n",
      "Iteration: 8897/10000, Loss: 0.006764835678040981\n",
      "Iteration: 8898/10000, Loss: 0.004842085763812065\n",
      "Iteration: 8899/10000, Loss: 0.007861185818910599\n",
      "Iteration: 8900/10000, Loss: 0.005027810111641884\n",
      "Average test loss:  0.0029\n",
      "Iteration: 8901/10000, Loss: 0.008926920592784882\n",
      "Iteration: 8902/10000, Loss: 0.008587170392274857\n",
      "Iteration: 8903/10000, Loss: 0.012785843573510647\n",
      "Iteration: 8904/10000, Loss: 0.010100344195961952\n",
      "Iteration: 8905/10000, Loss: 0.006298823747783899\n",
      "Iteration: 8906/10000, Loss: 0.010812411084771156\n",
      "Iteration: 8907/10000, Loss: 0.008566316217184067\n",
      "Iteration: 8908/10000, Loss: 0.012983933091163635\n",
      "Iteration: 8909/10000, Loss: 0.013243122026324272\n",
      "Iteration: 8910/10000, Loss: 0.011463262140750885\n",
      "Iteration: 8911/10000, Loss: 0.009681821800768375\n",
      "Iteration: 8912/10000, Loss: 0.012523464858531952\n",
      "Iteration: 8913/10000, Loss: 0.00929850060492754\n",
      "Iteration: 8914/10000, Loss: 0.008576837368309498\n",
      "Iteration: 8915/10000, Loss: 0.007959291338920593\n",
      "Iteration: 8916/10000, Loss: 0.010081824846565723\n",
      "Iteration: 8917/10000, Loss: 0.008234775625169277\n",
      "Iteration: 8918/10000, Loss: 0.011223364621400833\n",
      "Iteration: 8919/10000, Loss: 0.008470925502479076\n",
      "Iteration: 8920/10000, Loss: 0.007307589519768953\n",
      "Iteration: 8921/10000, Loss: 0.012227792292833328\n",
      "Iteration: 8922/10000, Loss: 0.005051987245678902\n",
      "Iteration: 8923/10000, Loss: 0.01283852756023407\n",
      "Iteration: 8924/10000, Loss: 0.0061918096616864204\n",
      "Iteration: 8925/10000, Loss: 0.008574511855840683\n",
      "Iteration: 8926/10000, Loss: 0.008770703338086605\n",
      "Iteration: 8927/10000, Loss: 0.0077843815088272095\n",
      "Iteration: 8928/10000, Loss: 0.011353923007845879\n",
      "Iteration: 8929/10000, Loss: 0.007203348912298679\n",
      "Iteration: 8930/10000, Loss: 0.009453974664211273\n",
      "Iteration: 8931/10000, Loss: 0.006039407104253769\n",
      "Iteration: 8932/10000, Loss: 0.006461120676249266\n",
      "Iteration: 8933/10000, Loss: 0.008345764130353928\n",
      "Iteration: 8934/10000, Loss: 0.009499847888946533\n",
      "Iteration: 8935/10000, Loss: 0.009554707445204258\n",
      "Iteration: 8936/10000, Loss: 0.006822369527071714\n",
      "Iteration: 8937/10000, Loss: 0.011708211153745651\n",
      "Iteration: 8938/10000, Loss: 0.012924792245030403\n",
      "Iteration: 8939/10000, Loss: 0.012172536924481392\n",
      "Iteration: 8940/10000, Loss: 0.011297025717794895\n",
      "Iteration: 8941/10000, Loss: 0.010839086957275867\n",
      "Iteration: 8942/10000, Loss: 0.013596832752227783\n",
      "Iteration: 8943/10000, Loss: 0.010086814872920513\n",
      "Iteration: 8944/10000, Loss: 0.006333810277283192\n",
      "Iteration: 8945/10000, Loss: 0.013881362974643707\n",
      "Iteration: 8946/10000, Loss: 0.007821861654520035\n",
      "Iteration: 8947/10000, Loss: 0.010862126015126705\n",
      "Iteration: 8948/10000, Loss: 0.008965685963630676\n",
      "Iteration: 8949/10000, Loss: 0.014916063286364079\n",
      "Iteration: 8950/10000, Loss: 0.006090438459068537\n",
      "Iteration: 8951/10000, Loss: 0.011261653155088425\n",
      "Iteration: 8952/10000, Loss: 0.008823292329907417\n",
      "Iteration: 8953/10000, Loss: 0.00855408888310194\n",
      "Iteration: 8954/10000, Loss: 0.006149114575237036\n",
      "Iteration: 8955/10000, Loss: 0.006241162773221731\n",
      "Iteration: 8956/10000, Loss: 0.006514496635645628\n",
      "Iteration: 8957/10000, Loss: 0.008645248599350452\n",
      "Iteration: 8958/10000, Loss: 0.010848743841052055\n",
      "Iteration: 8959/10000, Loss: 0.0072317649610340595\n",
      "Iteration: 8960/10000, Loss: 0.009455529972910881\n",
      "Iteration: 8961/10000, Loss: 0.01056592632085085\n",
      "Iteration: 8962/10000, Loss: 0.011331501416862011\n",
      "Iteration: 8963/10000, Loss: 0.007155014667659998\n",
      "Iteration: 8964/10000, Loss: 0.006749468855559826\n",
      "Iteration: 8965/10000, Loss: 0.012253839522600174\n",
      "Iteration: 8966/10000, Loss: 0.0100689847022295\n",
      "Iteration: 8967/10000, Loss: 0.008621863089501858\n",
      "Iteration: 8968/10000, Loss: 0.013227739371359348\n",
      "Iteration: 8969/10000, Loss: 0.011828877963125706\n",
      "Iteration: 8970/10000, Loss: 0.008492848835885525\n",
      "Iteration: 8971/10000, Loss: 0.007982643321156502\n",
      "Iteration: 8972/10000, Loss: 0.013240722008049488\n",
      "Iteration: 8973/10000, Loss: 0.0075906794518232346\n",
      "Iteration: 8974/10000, Loss: 0.006761717144399881\n",
      "Iteration: 8975/10000, Loss: 0.008851151913404465\n",
      "Iteration: 8976/10000, Loss: 0.00936630368232727\n",
      "Iteration: 8977/10000, Loss: 0.011805451475083828\n",
      "Iteration: 8978/10000, Loss: 0.012952551245689392\n",
      "Iteration: 8979/10000, Loss: 0.007137105334550142\n",
      "Iteration: 8980/10000, Loss: 0.009477686136960983\n",
      "Iteration: 8981/10000, Loss: 0.009288662113249302\n",
      "Iteration: 8982/10000, Loss: 0.009303986094892025\n",
      "Iteration: 8983/10000, Loss: 0.008846460841596127\n",
      "Iteration: 8984/10000, Loss: 0.005686536431312561\n",
      "Iteration: 8985/10000, Loss: 0.010268126614391804\n",
      "Iteration: 8986/10000, Loss: 0.005719414446502924\n",
      "Iteration: 8987/10000, Loss: 0.009385179728269577\n",
      "Iteration: 8988/10000, Loss: 0.0053002298809587955\n",
      "Iteration: 8989/10000, Loss: 0.006574308965355158\n",
      "Iteration: 8990/10000, Loss: 0.007451309822499752\n",
      "Iteration: 8991/10000, Loss: 0.008745433762669563\n",
      "Iteration: 8992/10000, Loss: 0.008429266512393951\n",
      "Iteration: 8993/10000, Loss: 0.007573413196951151\n",
      "Iteration: 8994/10000, Loss: 0.011969461105763912\n",
      "Iteration: 8995/10000, Loss: 0.01024024561047554\n",
      "Iteration: 8996/10000, Loss: 0.00743073271587491\n",
      "Iteration: 8997/10000, Loss: 0.008455946110188961\n",
      "Iteration: 8998/10000, Loss: 0.004623901564627886\n",
      "Iteration: 8999/10000, Loss: 0.00680700084194541\n",
      "Iteration: 9000/10000, Loss: 0.0068152910098433495\n",
      "Average test loss:  0.0024\n",
      "Iteration: 9001/10000, Loss: 0.010946661233901978\n",
      "Iteration: 9002/10000, Loss: 0.007773355580866337\n",
      "Iteration: 9003/10000, Loss: 0.009819777682423592\n",
      "Iteration: 9004/10000, Loss: 0.008808600716292858\n",
      "Iteration: 9005/10000, Loss: 0.009930835105478764\n",
      "Iteration: 9006/10000, Loss: 0.013624593615531921\n",
      "Iteration: 9007/10000, Loss: 0.0036196457222104073\n",
      "Iteration: 9008/10000, Loss: 0.007031203247606754\n",
      "Iteration: 9009/10000, Loss: 0.005702231079339981\n",
      "Iteration: 9010/10000, Loss: 0.012220315635204315\n",
      "Iteration: 9011/10000, Loss: 0.009357534348964691\n",
      "Iteration: 9012/10000, Loss: 0.012010625563561916\n",
      "Iteration: 9013/10000, Loss: 0.007247893139719963\n",
      "Iteration: 9014/10000, Loss: 0.010050617158412933\n",
      "Iteration: 9015/10000, Loss: 0.004544438328593969\n",
      "Iteration: 9016/10000, Loss: 0.01327901054173708\n",
      "Iteration: 9017/10000, Loss: 0.007008256856352091\n",
      "Iteration: 9018/10000, Loss: 0.00683633191511035\n",
      "Iteration: 9019/10000, Loss: 0.010021107271313667\n",
      "Iteration: 9020/10000, Loss: 0.010707918554544449\n",
      "Iteration: 9021/10000, Loss: 0.009268182329833508\n",
      "Iteration: 9022/10000, Loss: 0.011555341072380543\n",
      "Iteration: 9023/10000, Loss: 0.006802716758102179\n",
      "Iteration: 9024/10000, Loss: 0.011136344633996487\n",
      "Iteration: 9025/10000, Loss: 0.01171830203384161\n",
      "Iteration: 9026/10000, Loss: 0.005924126133322716\n",
      "Iteration: 9027/10000, Loss: 0.010205414146184921\n",
      "Iteration: 9028/10000, Loss: 0.011532293632626534\n",
      "Iteration: 9029/10000, Loss: 0.007623623590916395\n",
      "Iteration: 9030/10000, Loss: 0.009146393276751041\n",
      "Iteration: 9031/10000, Loss: 0.009661443531513214\n",
      "Iteration: 9032/10000, Loss: 0.008849084377288818\n",
      "Iteration: 9033/10000, Loss: 0.011179325170814991\n",
      "Iteration: 9034/10000, Loss: 0.0075869024731218815\n",
      "Iteration: 9035/10000, Loss: 0.013564062304794788\n",
      "Iteration: 9036/10000, Loss: 0.00725357374176383\n",
      "Iteration: 9037/10000, Loss: 0.007491250056773424\n",
      "Iteration: 9038/10000, Loss: 0.010323002003133297\n",
      "Iteration: 9039/10000, Loss: 0.009791018441319466\n",
      "Iteration: 9040/10000, Loss: 0.0072613675147295\n",
      "Iteration: 9041/10000, Loss: 0.013931573368608952\n",
      "Iteration: 9042/10000, Loss: 0.01297205500304699\n",
      "Iteration: 9043/10000, Loss: 0.008295390754938126\n",
      "Iteration: 9044/10000, Loss: 0.011385412886738777\n",
      "Iteration: 9045/10000, Loss: 0.009315136820077896\n",
      "Iteration: 9046/10000, Loss: 0.008531196974217892\n",
      "Iteration: 9047/10000, Loss: 0.009520490653812885\n",
      "Iteration: 9048/10000, Loss: 0.007402438670396805\n",
      "Iteration: 9049/10000, Loss: 0.006327325943857431\n",
      "Iteration: 9050/10000, Loss: 0.009185463190078735\n",
      "Iteration: 9051/10000, Loss: 0.006210335996001959\n",
      "Iteration: 9052/10000, Loss: 0.010033216327428818\n",
      "Iteration: 9053/10000, Loss: 0.010849900543689728\n",
      "Iteration: 9054/10000, Loss: 0.0064237345941364765\n",
      "Iteration: 9055/10000, Loss: 0.009212826378643513\n",
      "Iteration: 9056/10000, Loss: 0.009768161922693253\n",
      "Iteration: 9057/10000, Loss: 0.010178775526583195\n",
      "Iteration: 9058/10000, Loss: 0.009719199500977993\n",
      "Iteration: 9059/10000, Loss: 0.01120325829833746\n",
      "Iteration: 9060/10000, Loss: 0.005288208369165659\n",
      "Iteration: 9061/10000, Loss: 0.008854207582771778\n",
      "Iteration: 9062/10000, Loss: 0.009931916370987892\n",
      "Iteration: 9063/10000, Loss: 0.009755282662808895\n",
      "Iteration: 9064/10000, Loss: 0.011245019733905792\n",
      "Iteration: 9065/10000, Loss: 0.006640537176281214\n",
      "Iteration: 9066/10000, Loss: 0.01139670517295599\n",
      "Iteration: 9067/10000, Loss: 0.016196051612496376\n",
      "Iteration: 9068/10000, Loss: 0.008826419711112976\n",
      "Iteration: 9069/10000, Loss: 0.0063027129508554935\n",
      "Iteration: 9070/10000, Loss: 0.006406968925148249\n",
      "Iteration: 9071/10000, Loss: 0.011081758886575699\n",
      "Iteration: 9072/10000, Loss: 0.01004752330482006\n",
      "Iteration: 9073/10000, Loss: 0.016226336359977722\n",
      "Iteration: 9074/10000, Loss: 0.00672707986086607\n",
      "Iteration: 9075/10000, Loss: 0.007266984321177006\n",
      "Iteration: 9076/10000, Loss: 0.008182177320122719\n",
      "Iteration: 9077/10000, Loss: 0.006707041524350643\n",
      "Iteration: 9078/10000, Loss: 0.008897444233298302\n",
      "Iteration: 9079/10000, Loss: 0.01461461465805769\n",
      "Iteration: 9080/10000, Loss: 0.010694380849599838\n",
      "Iteration: 9081/10000, Loss: 0.011109876446425915\n",
      "Iteration: 9082/10000, Loss: 0.011205394752323627\n",
      "Iteration: 9083/10000, Loss: 0.005445168819278479\n",
      "Iteration: 9084/10000, Loss: 0.009029017761349678\n",
      "Iteration: 9085/10000, Loss: 0.006799540016800165\n",
      "Iteration: 9086/10000, Loss: 0.00735043827444315\n",
      "Iteration: 9087/10000, Loss: 0.006382263731211424\n",
      "Iteration: 9088/10000, Loss: 0.009871366433799267\n",
      "Iteration: 9089/10000, Loss: 0.00904170423746109\n",
      "Iteration: 9090/10000, Loss: 0.010353143326938152\n",
      "Iteration: 9091/10000, Loss: 0.006046646740287542\n",
      "Iteration: 9092/10000, Loss: 0.0091264508664608\n",
      "Iteration: 9093/10000, Loss: 0.008237224072217941\n",
      "Iteration: 9094/10000, Loss: 0.005749636795371771\n",
      "Iteration: 9095/10000, Loss: 0.010914783924818039\n",
      "Iteration: 9096/10000, Loss: 0.008613692596554756\n",
      "Iteration: 9097/10000, Loss: 0.008899787440896034\n",
      "Iteration: 9098/10000, Loss: 0.008613686077296734\n",
      "Iteration: 9099/10000, Loss: 0.009758535772562027\n",
      "Iteration: 9100/10000, Loss: 0.011287963949143887\n",
      "Average test loss:  0.0030\n",
      "Iteration: 9101/10000, Loss: 0.008825386874377728\n",
      "Iteration: 9102/10000, Loss: 0.012246315367519855\n",
      "Iteration: 9103/10000, Loss: 0.009762374684214592\n",
      "Iteration: 9104/10000, Loss: 0.011628318578004837\n",
      "Iteration: 9105/10000, Loss: 0.007139339577406645\n",
      "Iteration: 9106/10000, Loss: 0.008953695185482502\n",
      "Iteration: 9107/10000, Loss: 0.007627416867762804\n",
      "Iteration: 9108/10000, Loss: 0.007814120501279831\n",
      "Iteration: 9109/10000, Loss: 0.0054958174005150795\n",
      "Iteration: 9110/10000, Loss: 0.00877959281206131\n",
      "Iteration: 9111/10000, Loss: 0.013717972673475742\n",
      "Iteration: 9112/10000, Loss: 0.006385669577866793\n",
      "Iteration: 9113/10000, Loss: 0.01650088280439377\n",
      "Iteration: 9114/10000, Loss: 0.009249726310372353\n",
      "Iteration: 9115/10000, Loss: 0.0075307684019207954\n",
      "Iteration: 9116/10000, Loss: 0.008094286546111107\n",
      "Iteration: 9117/10000, Loss: 0.009206142276525497\n",
      "Iteration: 9118/10000, Loss: 0.017138224095106125\n",
      "Iteration: 9119/10000, Loss: 0.008656911551952362\n",
      "Iteration: 9120/10000, Loss: 0.007479963358491659\n",
      "Iteration: 9121/10000, Loss: 0.008626803755760193\n",
      "Iteration: 9122/10000, Loss: 0.009866511449217796\n",
      "Iteration: 9123/10000, Loss: 0.00832314882427454\n",
      "Iteration: 9124/10000, Loss: 0.010795695707201958\n",
      "Iteration: 9125/10000, Loss: 0.005538928788155317\n",
      "Iteration: 9126/10000, Loss: 0.01137557253241539\n",
      "Iteration: 9127/10000, Loss: 0.015641463920474052\n",
      "Iteration: 9128/10000, Loss: 0.007895498536527157\n",
      "Iteration: 9129/10000, Loss: 0.007381042931228876\n",
      "Iteration: 9130/10000, Loss: 0.009327971376478672\n",
      "Iteration: 9131/10000, Loss: 0.012245936319231987\n",
      "Iteration: 9132/10000, Loss: 0.012303645722568035\n",
      "Iteration: 9133/10000, Loss: 0.007689906284213066\n",
      "Iteration: 9134/10000, Loss: 0.011376230046153069\n",
      "Iteration: 9135/10000, Loss: 0.0076298960484564304\n",
      "Iteration: 9136/10000, Loss: 0.00826684944331646\n",
      "Iteration: 9137/10000, Loss: 0.007587655447423458\n",
      "Iteration: 9138/10000, Loss: 0.010304812341928482\n",
      "Iteration: 9139/10000, Loss: 0.009860356338322163\n",
      "Iteration: 9140/10000, Loss: 0.007472590543329716\n",
      "Iteration: 9141/10000, Loss: 0.006576745770871639\n",
      "Iteration: 9142/10000, Loss: 0.011498812586069107\n",
      "Iteration: 9143/10000, Loss: 0.008350600488483906\n",
      "Iteration: 9144/10000, Loss: 0.008462552912533283\n",
      "Iteration: 9145/10000, Loss: 0.01008782722055912\n",
      "Iteration: 9146/10000, Loss: 0.008040957152843475\n",
      "Iteration: 9147/10000, Loss: 0.011438638903200626\n",
      "Iteration: 9148/10000, Loss: 0.010009855031967163\n",
      "Iteration: 9149/10000, Loss: 0.010672037489712238\n",
      "Iteration: 9150/10000, Loss: 0.013734019361436367\n",
      "Iteration: 9151/10000, Loss: 0.008375093340873718\n",
      "Iteration: 9152/10000, Loss: 0.005846347194164991\n",
      "Iteration: 9153/10000, Loss: 0.002982754958793521\n",
      "Iteration: 9154/10000, Loss: 0.013840220868587494\n",
      "Iteration: 9155/10000, Loss: 0.01075010746717453\n",
      "Iteration: 9156/10000, Loss: 0.01055784709751606\n",
      "Iteration: 9157/10000, Loss: 0.009119701571762562\n",
      "Iteration: 9158/10000, Loss: 0.009703169576823711\n",
      "Iteration: 9159/10000, Loss: 0.007637949660420418\n",
      "Iteration: 9160/10000, Loss: 0.010434486903250217\n",
      "Iteration: 9161/10000, Loss: 0.013380458578467369\n",
      "Iteration: 9162/10000, Loss: 0.013308506458997726\n",
      "Iteration: 9163/10000, Loss: 0.009891597554087639\n",
      "Iteration: 9164/10000, Loss: 0.008708522655069828\n",
      "Iteration: 9165/10000, Loss: 0.009817834012210369\n",
      "Iteration: 9166/10000, Loss: 0.00828674528747797\n",
      "Iteration: 9167/10000, Loss: 0.010647498071193695\n",
      "Iteration: 9168/10000, Loss: 0.010188761167228222\n",
      "Iteration: 9169/10000, Loss: 0.010450112633407116\n",
      "Iteration: 9170/10000, Loss: 0.009765266440808773\n",
      "Iteration: 9171/10000, Loss: 0.010682031512260437\n",
      "Iteration: 9172/10000, Loss: 0.010336087085306644\n",
      "Iteration: 9173/10000, Loss: 0.010811992920935154\n",
      "Iteration: 9174/10000, Loss: 0.007625252474099398\n",
      "Iteration: 9175/10000, Loss: 0.01298527792096138\n",
      "Iteration: 9176/10000, Loss: 0.007761786691844463\n",
      "Iteration: 9177/10000, Loss: 0.01352944876998663\n",
      "Iteration: 9178/10000, Loss: 0.010382253676652908\n",
      "Iteration: 9179/10000, Loss: 0.00964762270450592\n",
      "Iteration: 9180/10000, Loss: 0.012881886214017868\n",
      "Iteration: 9181/10000, Loss: 0.007585082668811083\n",
      "Iteration: 9182/10000, Loss: 0.006116504780948162\n",
      "Iteration: 9183/10000, Loss: 0.00842268019914627\n",
      "Iteration: 9184/10000, Loss: 0.009824132546782494\n",
      "Iteration: 9185/10000, Loss: 0.004184965044260025\n",
      "Iteration: 9186/10000, Loss: 0.012656518258154392\n",
      "Iteration: 9187/10000, Loss: 0.00968583207577467\n",
      "Iteration: 9188/10000, Loss: 0.009199309162795544\n",
      "Iteration: 9189/10000, Loss: 0.006951525807380676\n",
      "Iteration: 9190/10000, Loss: 0.005169369280338287\n",
      "Iteration: 9191/10000, Loss: 0.01130606047809124\n",
      "Iteration: 9192/10000, Loss: 0.009362696669995785\n",
      "Iteration: 9193/10000, Loss: 0.007841624319553375\n",
      "Iteration: 9194/10000, Loss: 0.008179759606719017\n",
      "Iteration: 9195/10000, Loss: 0.007693443447351456\n",
      "Iteration: 9196/10000, Loss: 0.005371022038161755\n",
      "Iteration: 9197/10000, Loss: 0.008923990651965141\n",
      "Iteration: 9198/10000, Loss: 0.005804821848869324\n",
      "Iteration: 9199/10000, Loss: 0.007092674262821674\n",
      "Iteration: 9200/10000, Loss: 0.007287578657269478\n",
      "Average test loss:  0.0029\n",
      "Iteration: 9201/10000, Loss: 0.016798848286271095\n",
      "Iteration: 9202/10000, Loss: 0.007696090266108513\n",
      "Iteration: 9203/10000, Loss: 0.007288995664566755\n",
      "Iteration: 9204/10000, Loss: 0.00922547560185194\n",
      "Iteration: 9205/10000, Loss: 0.011807904578745365\n",
      "Iteration: 9206/10000, Loss: 0.005247908644378185\n",
      "Iteration: 9207/10000, Loss: 0.006087261717766523\n",
      "Iteration: 9208/10000, Loss: 0.004113403148949146\n",
      "Iteration: 9209/10000, Loss: 0.010433866642415524\n",
      "Iteration: 9210/10000, Loss: 0.010765155777335167\n",
      "Iteration: 9211/10000, Loss: 0.008295395411550999\n",
      "Iteration: 9212/10000, Loss: 0.008614307269454002\n",
      "Iteration: 9213/10000, Loss: 0.007107410114258528\n",
      "Iteration: 9214/10000, Loss: 0.006629070732742548\n",
      "Iteration: 9215/10000, Loss: 0.006216848269104958\n",
      "Iteration: 9216/10000, Loss: 0.008085303008556366\n",
      "Iteration: 9217/10000, Loss: 0.011811565607786179\n",
      "Iteration: 9218/10000, Loss: 0.011593352071940899\n",
      "Iteration: 9219/10000, Loss: 0.007699698209762573\n",
      "Iteration: 9220/10000, Loss: 0.0029471595771610737\n",
      "Iteration: 9221/10000, Loss: 0.009320029988884926\n",
      "Iteration: 9222/10000, Loss: 0.007565665990114212\n",
      "Iteration: 9223/10000, Loss: 0.009616498835384846\n",
      "Iteration: 9224/10000, Loss: 0.010279994457960129\n",
      "Iteration: 9225/10000, Loss: 0.006839863955974579\n",
      "Iteration: 9226/10000, Loss: 0.008493260480463505\n",
      "Iteration: 9227/10000, Loss: 0.008779285475611687\n",
      "Iteration: 9228/10000, Loss: 0.007274481002241373\n",
      "Iteration: 9229/10000, Loss: 0.01724502630531788\n",
      "Iteration: 9230/10000, Loss: 0.009301734156906605\n",
      "Iteration: 9231/10000, Loss: 0.011077698320150375\n",
      "Iteration: 9232/10000, Loss: 0.00685097835958004\n",
      "Iteration: 9233/10000, Loss: 0.009161596186459064\n",
      "Iteration: 9234/10000, Loss: 0.012057974003255367\n",
      "Iteration: 9235/10000, Loss: 0.01708524487912655\n",
      "Iteration: 9236/10000, Loss: 0.012855619192123413\n",
      "Iteration: 9237/10000, Loss: 0.00981871783733368\n",
      "Iteration: 9238/10000, Loss: 0.006959003396332264\n",
      "Iteration: 9239/10000, Loss: 0.007587629836052656\n",
      "Iteration: 9240/10000, Loss: 0.006430686451494694\n",
      "Iteration: 9241/10000, Loss: 0.007891081273555756\n",
      "Iteration: 9242/10000, Loss: 0.006921857595443726\n",
      "Iteration: 9243/10000, Loss: 0.009673099964857101\n",
      "Iteration: 9244/10000, Loss: 0.0074468147940933704\n",
      "Iteration: 9245/10000, Loss: 0.0123161431401968\n",
      "Iteration: 9246/10000, Loss: 0.005345633253455162\n",
      "Iteration: 9247/10000, Loss: 0.009303074330091476\n",
      "Iteration: 9248/10000, Loss: 0.008707876317203045\n",
      "Iteration: 9249/10000, Loss: 0.008089077658951283\n",
      "Iteration: 9250/10000, Loss: 0.007668633479624987\n",
      "Iteration: 9251/10000, Loss: 0.00832789670675993\n",
      "Iteration: 9252/10000, Loss: 0.008650470525026321\n",
      "Iteration: 9253/10000, Loss: 0.00854342058300972\n",
      "Iteration: 9254/10000, Loss: 0.009127926081418991\n",
      "Iteration: 9255/10000, Loss: 0.007160996552556753\n",
      "Iteration: 9256/10000, Loss: 0.01242117676883936\n",
      "Iteration: 9257/10000, Loss: 0.008900424465537071\n",
      "Iteration: 9258/10000, Loss: 0.00898316316306591\n",
      "Iteration: 9259/10000, Loss: 0.008598560467362404\n",
      "Iteration: 9260/10000, Loss: 0.009017033502459526\n",
      "Iteration: 9261/10000, Loss: 0.010653434321284294\n",
      "Iteration: 9262/10000, Loss: 0.009548569098114967\n",
      "Iteration: 9263/10000, Loss: 0.011755305342376232\n",
      "Iteration: 9264/10000, Loss: 0.006061170715838671\n",
      "Iteration: 9265/10000, Loss: 0.0071822660975158215\n",
      "Iteration: 9266/10000, Loss: 0.010044042952358723\n",
      "Iteration: 9267/10000, Loss: 0.011176318861544132\n",
      "Iteration: 9268/10000, Loss: 0.007712847087532282\n",
      "Iteration: 9269/10000, Loss: 0.00581833953037858\n",
      "Iteration: 9270/10000, Loss: 0.008915402926504612\n",
      "Iteration: 9271/10000, Loss: 0.010315944440662861\n",
      "Iteration: 9272/10000, Loss: 0.008891107514500618\n",
      "Iteration: 9273/10000, Loss: 0.009219148196280003\n",
      "Iteration: 9274/10000, Loss: 0.014164108783006668\n",
      "Iteration: 9275/10000, Loss: 0.007561225909739733\n",
      "Iteration: 9276/10000, Loss: 0.011513518169522285\n",
      "Iteration: 9277/10000, Loss: 0.008619153872132301\n",
      "Iteration: 9278/10000, Loss: 0.007361116819083691\n",
      "Iteration: 9279/10000, Loss: 0.010019289329648018\n",
      "Iteration: 9280/10000, Loss: 0.010807137005031109\n",
      "Iteration: 9281/10000, Loss: 0.009290266782045364\n",
      "Iteration: 9282/10000, Loss: 0.009781408123672009\n",
      "Iteration: 9283/10000, Loss: 0.011408992111682892\n",
      "Iteration: 9284/10000, Loss: 0.005677295383065939\n",
      "Iteration: 9285/10000, Loss: 0.009817291051149368\n",
      "Iteration: 9286/10000, Loss: 0.011994617059826851\n",
      "Iteration: 9287/10000, Loss: 0.00989471934735775\n",
      "Iteration: 9288/10000, Loss: 0.00829501636326313\n",
      "Iteration: 9289/10000, Loss: 0.00721238786354661\n",
      "Iteration: 9290/10000, Loss: 0.006557136308401823\n",
      "Iteration: 9291/10000, Loss: 0.008919897489249706\n",
      "Iteration: 9292/10000, Loss: 0.01306822244077921\n",
      "Iteration: 9293/10000, Loss: 0.007756651844829321\n",
      "Iteration: 9294/10000, Loss: 0.01027190312743187\n",
      "Iteration: 9295/10000, Loss: 0.011397087015211582\n",
      "Iteration: 9296/10000, Loss: 0.009442697279155254\n",
      "Iteration: 9297/10000, Loss: 0.010439114645123482\n",
      "Iteration: 9298/10000, Loss: 0.012297864072024822\n",
      "Iteration: 9299/10000, Loss: 0.010097768157720566\n",
      "Iteration: 9300/10000, Loss: 0.008410154841840267\n",
      "Average test loss:  0.0029\n",
      "Iteration: 9301/10000, Loss: 0.009490295313298702\n",
      "Iteration: 9302/10000, Loss: 0.007025842554867268\n",
      "Iteration: 9303/10000, Loss: 0.009721500799059868\n",
      "Iteration: 9304/10000, Loss: 0.007116876542568207\n",
      "Iteration: 9305/10000, Loss: 0.009879833087325096\n",
      "Iteration: 9306/10000, Loss: 0.010940766893327236\n",
      "Iteration: 9307/10000, Loss: 0.010056569240987301\n",
      "Iteration: 9308/10000, Loss: 0.010900341905653477\n",
      "Iteration: 9309/10000, Loss: 0.010661187581717968\n",
      "Iteration: 9310/10000, Loss: 0.006897510960698128\n",
      "Iteration: 9311/10000, Loss: 0.00896886084228754\n",
      "Iteration: 9312/10000, Loss: 0.009287123568356037\n",
      "Iteration: 9313/10000, Loss: 0.005532840266823769\n",
      "Iteration: 9314/10000, Loss: 0.008875138126313686\n",
      "Iteration: 9315/10000, Loss: 0.012942024506628513\n",
      "Iteration: 9316/10000, Loss: 0.0073542543686926365\n",
      "Iteration: 9317/10000, Loss: 0.009480820968747139\n",
      "Iteration: 9318/10000, Loss: 0.008791289292275906\n",
      "Iteration: 9319/10000, Loss: 0.01079875510185957\n",
      "Iteration: 9320/10000, Loss: 0.010254736989736557\n",
      "Iteration: 9321/10000, Loss: 0.009627689607441425\n",
      "Iteration: 9322/10000, Loss: 0.00710476515814662\n",
      "Iteration: 9323/10000, Loss: 0.013221634551882744\n",
      "Iteration: 9324/10000, Loss: 0.006712640635669231\n",
      "Iteration: 9325/10000, Loss: 0.011785140261054039\n",
      "Iteration: 9326/10000, Loss: 0.007472136989235878\n",
      "Iteration: 9327/10000, Loss: 0.005115931387990713\n",
      "Iteration: 9328/10000, Loss: 0.012044173665344715\n",
      "Iteration: 9329/10000, Loss: 0.005911351181566715\n",
      "Iteration: 9330/10000, Loss: 0.006632096599787474\n",
      "Iteration: 9331/10000, Loss: 0.010850934311747551\n",
      "Iteration: 9332/10000, Loss: 0.013189494609832764\n",
      "Iteration: 9333/10000, Loss: 0.013658571988344193\n",
      "Iteration: 9334/10000, Loss: 0.008009732700884342\n",
      "Iteration: 9335/10000, Loss: 0.01121911033987999\n",
      "Iteration: 9336/10000, Loss: 0.008616091683506966\n",
      "Iteration: 9337/10000, Loss: 0.006781063042581081\n",
      "Iteration: 9338/10000, Loss: 0.005136857740581036\n",
      "Iteration: 9339/10000, Loss: 0.007493757177144289\n",
      "Iteration: 9340/10000, Loss: 0.013801784254610538\n",
      "Iteration: 9341/10000, Loss: 0.010455709882080555\n",
      "Iteration: 9342/10000, Loss: 0.008945382200181484\n",
      "Iteration: 9343/10000, Loss: 0.01069674827158451\n",
      "Iteration: 9344/10000, Loss: 0.010682309046387672\n",
      "Iteration: 9345/10000, Loss: 0.0110640749335289\n",
      "Iteration: 9346/10000, Loss: 0.00913270190358162\n",
      "Iteration: 9347/10000, Loss: 0.00801524706184864\n",
      "Iteration: 9348/10000, Loss: 0.011732378974556923\n",
      "Iteration: 9349/10000, Loss: 0.010284108109772205\n",
      "Iteration: 9350/10000, Loss: 0.0070098163560032845\n",
      "Iteration: 9351/10000, Loss: 0.006720483768731356\n",
      "Iteration: 9352/10000, Loss: 0.010387592017650604\n",
      "Iteration: 9353/10000, Loss: 0.009664352983236313\n",
      "Iteration: 9354/10000, Loss: 0.007593719754368067\n",
      "Iteration: 9355/10000, Loss: 0.0104666817933321\n",
      "Iteration: 9356/10000, Loss: 0.008818274363875389\n",
      "Iteration: 9357/10000, Loss: 0.013424181379377842\n",
      "Iteration: 9358/10000, Loss: 0.009249668568372726\n",
      "Iteration: 9359/10000, Loss: 0.007788015995174646\n",
      "Iteration: 9360/10000, Loss: 0.00814967043697834\n",
      "Iteration: 9361/10000, Loss: 0.009360135532915592\n",
      "Iteration: 9362/10000, Loss: 0.011711559258401394\n",
      "Iteration: 9363/10000, Loss: 0.01032786164432764\n",
      "Iteration: 9364/10000, Loss: 0.012574711814522743\n",
      "Iteration: 9365/10000, Loss: 0.009584993124008179\n",
      "Iteration: 9366/10000, Loss: 0.011120875366032124\n",
      "Iteration: 9367/10000, Loss: 0.008884335868060589\n",
      "Iteration: 9368/10000, Loss: 0.008094193413853645\n",
      "Iteration: 9369/10000, Loss: 0.007714670617133379\n",
      "Iteration: 9370/10000, Loss: 0.006280109751969576\n",
      "Iteration: 9371/10000, Loss: 0.007016401272267103\n",
      "Iteration: 9372/10000, Loss: 0.0074585191905498505\n",
      "Iteration: 9373/10000, Loss: 0.006922236178070307\n",
      "Iteration: 9374/10000, Loss: 0.009322001598775387\n",
      "Iteration: 9375/10000, Loss: 0.012596704997122288\n",
      "Iteration: 9376/10000, Loss: 0.011342615820467472\n",
      "Iteration: 9377/10000, Loss: 0.008291645906865597\n",
      "Iteration: 9378/10000, Loss: 0.013234981335699558\n",
      "Iteration: 9379/10000, Loss: 0.007819384336471558\n",
      "Iteration: 9380/10000, Loss: 0.009611592628061771\n",
      "Iteration: 9381/10000, Loss: 0.007611340377479792\n",
      "Iteration: 9382/10000, Loss: 0.006128132808953524\n",
      "Iteration: 9383/10000, Loss: 0.004708939231932163\n",
      "Iteration: 9384/10000, Loss: 0.005853462032973766\n",
      "Iteration: 9385/10000, Loss: 0.012202893383800983\n",
      "Iteration: 9386/10000, Loss: 0.0030826525762677193\n",
      "Iteration: 9387/10000, Loss: 0.006794116459786892\n",
      "Iteration: 9388/10000, Loss: 0.010026699863374233\n",
      "Iteration: 9389/10000, Loss: 0.008703207597136497\n",
      "Iteration: 9390/10000, Loss: 0.011829989030957222\n",
      "Iteration: 9391/10000, Loss: 0.009485429152846336\n",
      "Iteration: 9392/10000, Loss: 0.006725692190229893\n",
      "Iteration: 9393/10000, Loss: 0.009929818101227283\n",
      "Iteration: 9394/10000, Loss: 0.014597932808101177\n",
      "Iteration: 9395/10000, Loss: 0.00863055419176817\n",
      "Iteration: 9396/10000, Loss: 0.00495253037661314\n",
      "Iteration: 9397/10000, Loss: 0.009512561373412609\n",
      "Iteration: 9398/10000, Loss: 0.008575345389544964\n",
      "Iteration: 9399/10000, Loss: 0.008233561180531979\n",
      "Iteration: 9400/10000, Loss: 0.005070260725915432\n",
      "Average test loss:  0.0024\n",
      "Iteration: 9401/10000, Loss: 0.005458569619804621\n",
      "Iteration: 9402/10000, Loss: 0.006292174104601145\n",
      "Iteration: 9403/10000, Loss: 0.007252905983477831\n",
      "Iteration: 9404/10000, Loss: 0.010925505310297012\n",
      "Iteration: 9405/10000, Loss: 0.009540385566651821\n",
      "Iteration: 9406/10000, Loss: 0.009425527416169643\n",
      "Iteration: 9407/10000, Loss: 0.007828332483768463\n",
      "Iteration: 9408/10000, Loss: 0.0060858638025820255\n",
      "Iteration: 9409/10000, Loss: 0.007405415177345276\n",
      "Iteration: 9410/10000, Loss: 0.008140765130519867\n",
      "Iteration: 9411/10000, Loss: 0.011625573970377445\n",
      "Iteration: 9412/10000, Loss: 0.004142099525779486\n",
      "Iteration: 9413/10000, Loss: 0.013455311767756939\n",
      "Iteration: 9414/10000, Loss: 0.00635839719325304\n",
      "Iteration: 9415/10000, Loss: 0.009665127843618393\n",
      "Iteration: 9416/10000, Loss: 0.005901127588003874\n",
      "Iteration: 9417/10000, Loss: 0.004701982717961073\n",
      "Iteration: 9418/10000, Loss: 0.00823925156146288\n",
      "Iteration: 9419/10000, Loss: 0.009716889820992947\n",
      "Iteration: 9420/10000, Loss: 0.007571985479444265\n",
      "Iteration: 9421/10000, Loss: 0.009365490637719631\n",
      "Iteration: 9422/10000, Loss: 0.003924759570509195\n",
      "Iteration: 9423/10000, Loss: 0.006678805220872164\n",
      "Iteration: 9424/10000, Loss: 0.005702602211385965\n",
      "Iteration: 9425/10000, Loss: 0.0078877629712224\n",
      "Iteration: 9426/10000, Loss: 0.0053982846438884735\n",
      "Iteration: 9427/10000, Loss: 0.010409101843833923\n",
      "Iteration: 9428/10000, Loss: 0.013278717175126076\n",
      "Iteration: 9429/10000, Loss: 0.01220216415822506\n",
      "Iteration: 9430/10000, Loss: 0.005594900343567133\n",
      "Iteration: 9431/10000, Loss: 0.006463035009801388\n",
      "Iteration: 9432/10000, Loss: 0.011359344236552715\n",
      "Iteration: 9433/10000, Loss: 0.008615736849606037\n",
      "Iteration: 9434/10000, Loss: 0.007682858034968376\n",
      "Iteration: 9435/10000, Loss: 0.010177398100495338\n",
      "Iteration: 9436/10000, Loss: 0.007023684214800596\n",
      "Iteration: 9437/10000, Loss: 0.011513752862811089\n",
      "Iteration: 9438/10000, Loss: 0.012427831999957561\n",
      "Iteration: 9439/10000, Loss: 0.008065263740718365\n",
      "Iteration: 9440/10000, Loss: 0.009085407480597496\n",
      "Iteration: 9441/10000, Loss: 0.00850862730294466\n",
      "Iteration: 9442/10000, Loss: 0.0070352936163544655\n",
      "Iteration: 9443/10000, Loss: 0.009665713645517826\n",
      "Iteration: 9444/10000, Loss: 0.012290597893297672\n",
      "Iteration: 9445/10000, Loss: 0.009540841914713383\n",
      "Iteration: 9446/10000, Loss: 0.009417576715350151\n",
      "Iteration: 9447/10000, Loss: 0.009641803801059723\n",
      "Iteration: 9448/10000, Loss: 0.009663482196629047\n",
      "Iteration: 9449/10000, Loss: 0.007650781888514757\n",
      "Iteration: 9450/10000, Loss: 0.006964114960283041\n",
      "Iteration: 9451/10000, Loss: 0.007722774986177683\n",
      "Iteration: 9452/10000, Loss: 0.012242625467479229\n",
      "Iteration: 9453/10000, Loss: 0.007575822528451681\n",
      "Iteration: 9454/10000, Loss: 0.009447014890611172\n",
      "Iteration: 9455/10000, Loss: 0.005705568939447403\n",
      "Iteration: 9456/10000, Loss: 0.00872361846268177\n",
      "Iteration: 9457/10000, Loss: 0.006523140240460634\n",
      "Iteration: 9458/10000, Loss: 0.013329328037798405\n",
      "Iteration: 9459/10000, Loss: 0.009823317639529705\n",
      "Iteration: 9460/10000, Loss: 0.010302522219717503\n",
      "Iteration: 9461/10000, Loss: 0.005825869273394346\n",
      "Iteration: 9462/10000, Loss: 0.01250898465514183\n",
      "Iteration: 9463/10000, Loss: 0.011758360080420971\n",
      "Iteration: 9464/10000, Loss: 0.008499518036842346\n",
      "Iteration: 9465/10000, Loss: 0.008056807331740856\n",
      "Iteration: 9466/10000, Loss: 0.009982654824852943\n",
      "Iteration: 9467/10000, Loss: 0.007319399621337652\n",
      "Iteration: 9468/10000, Loss: 0.010672314092516899\n",
      "Iteration: 9469/10000, Loss: 0.007894625887274742\n",
      "Iteration: 9470/10000, Loss: 0.008628849871456623\n",
      "Iteration: 9471/10000, Loss: 0.01164689939469099\n",
      "Iteration: 9472/10000, Loss: 0.00796511210501194\n",
      "Iteration: 9473/10000, Loss: 0.009665724821388721\n",
      "Iteration: 9474/10000, Loss: 0.010995516553521156\n",
      "Iteration: 9475/10000, Loss: 0.012291102670133114\n",
      "Iteration: 9476/10000, Loss: 0.006982611026614904\n",
      "Iteration: 9477/10000, Loss: 0.009981654584407806\n",
      "Iteration: 9478/10000, Loss: 0.005581213161349297\n",
      "Iteration: 9479/10000, Loss: 0.010654912330210209\n",
      "Iteration: 9480/10000, Loss: 0.007778458762913942\n",
      "Iteration: 9481/10000, Loss: 0.0060052149929106236\n",
      "Iteration: 9482/10000, Loss: 0.008623495697975159\n",
      "Iteration: 9483/10000, Loss: 0.007630017586052418\n",
      "Iteration: 9484/10000, Loss: 0.011300010606646538\n",
      "Iteration: 9485/10000, Loss: 0.008785998448729515\n",
      "Iteration: 9486/10000, Loss: 0.008652856573462486\n",
      "Iteration: 9487/10000, Loss: 0.011391577310860157\n",
      "Iteration: 9488/10000, Loss: 0.007487223483622074\n",
      "Iteration: 9489/10000, Loss: 0.00806691125035286\n",
      "Iteration: 9490/10000, Loss: 0.007066154852509499\n",
      "Iteration: 9491/10000, Loss: 0.009290206246078014\n",
      "Iteration: 9492/10000, Loss: 0.012929248623549938\n",
      "Iteration: 9493/10000, Loss: 0.014376617036759853\n",
      "Iteration: 9494/10000, Loss: 0.009939165785908699\n",
      "Iteration: 9495/10000, Loss: 0.010456359013915062\n",
      "Iteration: 9496/10000, Loss: 0.008203372359275818\n",
      "Iteration: 9497/10000, Loss: 0.009083995595574379\n",
      "Iteration: 9498/10000, Loss: 0.01119065098464489\n",
      "Iteration: 9499/10000, Loss: 0.009023063816130161\n",
      "Iteration: 9500/10000, Loss: 0.006651621311903\n",
      "Average test loss:  0.0030\n",
      "Iteration: 9501/10000, Loss: 0.013781948946416378\n",
      "Iteration: 9502/10000, Loss: 0.012913122773170471\n",
      "Iteration: 9503/10000, Loss: 0.013683563098311424\n",
      "Iteration: 9504/10000, Loss: 0.009868640452623367\n",
      "Iteration: 9505/10000, Loss: 0.00532777002081275\n",
      "Iteration: 9506/10000, Loss: 0.007616791408509016\n",
      "Iteration: 9507/10000, Loss: 0.004582448396831751\n",
      "Iteration: 9508/10000, Loss: 0.005971292033791542\n",
      "Iteration: 9509/10000, Loss: 0.0070953345857560635\n",
      "Iteration: 9510/10000, Loss: 0.013417273759841919\n",
      "Iteration: 9511/10000, Loss: 0.005825684871524572\n",
      "Iteration: 9512/10000, Loss: 0.009158233180642128\n",
      "Iteration: 9513/10000, Loss: 0.00910261645913124\n",
      "Iteration: 9514/10000, Loss: 0.012023448944091797\n",
      "Iteration: 9515/10000, Loss: 0.01163538172841072\n",
      "Iteration: 9516/10000, Loss: 0.007264602929353714\n",
      "Iteration: 9517/10000, Loss: 0.011990495026111603\n",
      "Iteration: 9518/10000, Loss: 0.011728892102837563\n",
      "Iteration: 9519/10000, Loss: 0.006965963169932365\n",
      "Iteration: 9520/10000, Loss: 0.010344616137444973\n",
      "Iteration: 9521/10000, Loss: 0.013052115216851234\n",
      "Iteration: 9522/10000, Loss: 0.010775878094136715\n",
      "Iteration: 9523/10000, Loss: 0.009082525037229061\n",
      "Iteration: 9524/10000, Loss: 0.00803147628903389\n",
      "Iteration: 9525/10000, Loss: 0.009928521700203419\n",
      "Iteration: 9526/10000, Loss: 0.010522527620196342\n",
      "Iteration: 9527/10000, Loss: 0.008178171701729298\n",
      "Iteration: 9528/10000, Loss: 0.006641923915594816\n",
      "Iteration: 9529/10000, Loss: 0.013513959012925625\n",
      "Iteration: 9530/10000, Loss: 0.008358185179531574\n",
      "Iteration: 9531/10000, Loss: 0.008875134401023388\n",
      "Iteration: 9532/10000, Loss: 0.009580302983522415\n",
      "Iteration: 9533/10000, Loss: 0.009957991540431976\n",
      "Iteration: 9534/10000, Loss: 0.012327316217124462\n",
      "Iteration: 9535/10000, Loss: 0.0059427679516375065\n",
      "Iteration: 9536/10000, Loss: 0.0072369566187262535\n",
      "Iteration: 9537/10000, Loss: 0.01033996231853962\n",
      "Iteration: 9538/10000, Loss: 0.006087199319154024\n",
      "Iteration: 9539/10000, Loss: 0.0125397564843297\n",
      "Iteration: 9540/10000, Loss: 0.01044037938117981\n",
      "Iteration: 9541/10000, Loss: 0.011882676742970943\n",
      "Iteration: 9542/10000, Loss: 0.006810142192989588\n",
      "Iteration: 9543/10000, Loss: 0.0065455869771540165\n",
      "Iteration: 9544/10000, Loss: 0.006638700142502785\n",
      "Iteration: 9545/10000, Loss: 0.007848197594285011\n",
      "Iteration: 9546/10000, Loss: 0.011970757506787777\n",
      "Iteration: 9547/10000, Loss: 0.011788927949965\n",
      "Iteration: 9548/10000, Loss: 0.007312021683901548\n",
      "Iteration: 9549/10000, Loss: 0.01337867695838213\n",
      "Iteration: 9550/10000, Loss: 0.00512353889644146\n",
      "Iteration: 9551/10000, Loss: 0.011288587935268879\n",
      "Iteration: 9552/10000, Loss: 0.008704056032001972\n",
      "Iteration: 9553/10000, Loss: 0.00910411961376667\n",
      "Iteration: 9554/10000, Loss: 0.010686797089874744\n",
      "Iteration: 9555/10000, Loss: 0.007336551323533058\n",
      "Iteration: 9556/10000, Loss: 0.0030636293813586235\n",
      "Iteration: 9557/10000, Loss: 0.008492512628436089\n",
      "Iteration: 9558/10000, Loss: 0.013355502858757973\n",
      "Iteration: 9559/10000, Loss: 0.007314393296837807\n",
      "Iteration: 9560/10000, Loss: 0.011251975782215595\n",
      "Iteration: 9561/10000, Loss: 0.012961712665855885\n",
      "Iteration: 9562/10000, Loss: 0.007340137381106615\n",
      "Iteration: 9563/10000, Loss: 0.0073189386166632175\n",
      "Iteration: 9564/10000, Loss: 0.014684440568089485\n",
      "Iteration: 9565/10000, Loss: 0.010377220809459686\n",
      "Iteration: 9566/10000, Loss: 0.009963330812752247\n",
      "Iteration: 9567/10000, Loss: 0.010072080418467522\n",
      "Iteration: 9568/10000, Loss: 0.009952208027243614\n",
      "Iteration: 9569/10000, Loss: 0.008018826134502888\n",
      "Iteration: 9570/10000, Loss: 0.0070144194178283215\n",
      "Iteration: 9571/10000, Loss: 0.011867301538586617\n",
      "Iteration: 9572/10000, Loss: 0.008532823994755745\n",
      "Iteration: 9573/10000, Loss: 0.014237944036722183\n",
      "Iteration: 9574/10000, Loss: 0.009414578787982464\n",
      "Iteration: 9575/10000, Loss: 0.005248027853667736\n",
      "Iteration: 9576/10000, Loss: 0.010218935087323189\n",
      "Iteration: 9577/10000, Loss: 0.009829183109104633\n",
      "Iteration: 9578/10000, Loss: 0.007989888079464436\n",
      "Iteration: 9579/10000, Loss: 0.010437524877488613\n",
      "Iteration: 9580/10000, Loss: 0.012351695448160172\n",
      "Iteration: 9581/10000, Loss: 0.008394143544137478\n",
      "Iteration: 9582/10000, Loss: 0.00612318841740489\n",
      "Iteration: 9583/10000, Loss: 0.009168029762804508\n",
      "Iteration: 9584/10000, Loss: 0.007649865001440048\n",
      "Iteration: 9585/10000, Loss: 0.009909207932651043\n",
      "Iteration: 9586/10000, Loss: 0.008329171687364578\n",
      "Iteration: 9587/10000, Loss: 0.010181541554629803\n",
      "Iteration: 9588/10000, Loss: 0.007339492440223694\n",
      "Iteration: 9589/10000, Loss: 0.010176034644246101\n",
      "Iteration: 9590/10000, Loss: 0.007186721079051495\n",
      "Iteration: 9591/10000, Loss: 0.005491224583238363\n",
      "Iteration: 9592/10000, Loss: 0.00667898403480649\n",
      "Iteration: 9593/10000, Loss: 0.010676448233425617\n",
      "Iteration: 9594/10000, Loss: 0.009065810590982437\n",
      "Iteration: 9595/10000, Loss: 0.007220116909593344\n",
      "Iteration: 9596/10000, Loss: 0.00795739609748125\n",
      "Iteration: 9597/10000, Loss: 0.00808775331825018\n",
      "Iteration: 9598/10000, Loss: 0.011913677677512169\n",
      "Iteration: 9599/10000, Loss: 0.01002377551048994\n",
      "Iteration: 9600/10000, Loss: 0.00893053226172924\n",
      "Average test loss:  0.0041\n",
      "Iteration: 9601/10000, Loss: 0.011953855864703655\n",
      "Iteration: 9602/10000, Loss: 0.013157411478459835\n",
      "Iteration: 9603/10000, Loss: 0.0086490074172616\n",
      "Iteration: 9604/10000, Loss: 0.007921501062810421\n",
      "Iteration: 9605/10000, Loss: 0.009408608078956604\n",
      "Iteration: 9606/10000, Loss: 0.01089392602443695\n",
      "Iteration: 9607/10000, Loss: 0.006853346712887287\n",
      "Iteration: 9608/10000, Loss: 0.01292936410754919\n",
      "Iteration: 9609/10000, Loss: 0.009706709533929825\n",
      "Iteration: 9610/10000, Loss: 0.0064691705629229546\n",
      "Iteration: 9611/10000, Loss: 0.007687726989388466\n",
      "Iteration: 9612/10000, Loss: 0.012617044150829315\n",
      "Iteration: 9613/10000, Loss: 0.008375314064323902\n",
      "Iteration: 9614/10000, Loss: 0.013190394267439842\n",
      "Iteration: 9615/10000, Loss: 0.012007154524326324\n",
      "Iteration: 9616/10000, Loss: 0.01037614420056343\n",
      "Iteration: 9617/10000, Loss: 0.007774474564939737\n",
      "Iteration: 9618/10000, Loss: 0.00922202318906784\n",
      "Iteration: 9619/10000, Loss: 0.003399503417313099\n",
      "Iteration: 9620/10000, Loss: 0.009395440109074116\n",
      "Iteration: 9621/10000, Loss: 0.010601487010717392\n",
      "Iteration: 9622/10000, Loss: 0.01015285961329937\n",
      "Iteration: 9623/10000, Loss: 0.009882563725113869\n",
      "Iteration: 9624/10000, Loss: 0.007493294775485992\n",
      "Iteration: 9625/10000, Loss: 0.010729230009019375\n",
      "Iteration: 9626/10000, Loss: 0.009593317285180092\n",
      "Iteration: 9627/10000, Loss: 0.008247564546763897\n",
      "Iteration: 9628/10000, Loss: 0.010503966361284256\n",
      "Iteration: 9629/10000, Loss: 0.011973456479609013\n",
      "Iteration: 9630/10000, Loss: 0.008234306238591671\n",
      "Iteration: 9631/10000, Loss: 0.009761545807123184\n",
      "Iteration: 9632/10000, Loss: 0.00659400736913085\n",
      "Iteration: 9633/10000, Loss: 0.008994857780635357\n",
      "Iteration: 9634/10000, Loss: 0.011380426585674286\n",
      "Iteration: 9635/10000, Loss: 0.008266103453934193\n",
      "Iteration: 9636/10000, Loss: 0.008963363245129585\n",
      "Iteration: 9637/10000, Loss: 0.004309153184294701\n",
      "Iteration: 9638/10000, Loss: 0.007614664733409882\n",
      "Iteration: 9639/10000, Loss: 0.01086503453552723\n",
      "Iteration: 9640/10000, Loss: 0.008418362587690353\n",
      "Iteration: 9641/10000, Loss: 0.010169308632612228\n",
      "Iteration: 9642/10000, Loss: 0.006196592468768358\n",
      "Iteration: 9643/10000, Loss: 0.006548350676894188\n",
      "Iteration: 9644/10000, Loss: 0.006079607177525759\n",
      "Iteration: 9645/10000, Loss: 0.010711831972002983\n",
      "Iteration: 9646/10000, Loss: 0.007942760363221169\n",
      "Iteration: 9647/10000, Loss: 0.008546598255634308\n",
      "Iteration: 9648/10000, Loss: 0.010364987887442112\n",
      "Iteration: 9649/10000, Loss: 0.00862835068255663\n",
      "Iteration: 9650/10000, Loss: 0.0056302351877093315\n",
      "Iteration: 9651/10000, Loss: 0.009288412518799305\n",
      "Iteration: 9652/10000, Loss: 0.011441702023148537\n",
      "Iteration: 9653/10000, Loss: 0.010045686736702919\n",
      "Iteration: 9654/10000, Loss: 0.008949674665927887\n",
      "Iteration: 9655/10000, Loss: 0.013450496830046177\n",
      "Iteration: 9656/10000, Loss: 0.009081443771719933\n",
      "Iteration: 9657/10000, Loss: 0.009976154193282127\n",
      "Iteration: 9658/10000, Loss: 0.012472229078412056\n",
      "Iteration: 9659/10000, Loss: 0.00794903188943863\n",
      "Iteration: 9660/10000, Loss: 0.008118470199406147\n",
      "Iteration: 9661/10000, Loss: 0.009936228394508362\n",
      "Iteration: 9662/10000, Loss: 0.01132342591881752\n",
      "Iteration: 9663/10000, Loss: 0.007306972984224558\n",
      "Iteration: 9664/10000, Loss: 0.010540966875851154\n",
      "Iteration: 9665/10000, Loss: 0.010081939399242401\n",
      "Iteration: 9666/10000, Loss: 0.008838056586682796\n",
      "Iteration: 9667/10000, Loss: 0.008747597225010395\n",
      "Iteration: 9668/10000, Loss: 0.012868565507233143\n",
      "Iteration: 9669/10000, Loss: 0.008315211161971092\n",
      "Iteration: 9670/10000, Loss: 0.010459239594638348\n",
      "Iteration: 9671/10000, Loss: 0.009956808760762215\n",
      "Iteration: 9672/10000, Loss: 0.008848896250128746\n",
      "Iteration: 9673/10000, Loss: 0.011161712929606438\n",
      "Iteration: 9674/10000, Loss: 0.010224828496575356\n",
      "Iteration: 9675/10000, Loss: 0.009187989868223667\n",
      "Iteration: 9676/10000, Loss: 0.008739651180803776\n",
      "Iteration: 9677/10000, Loss: 0.009065174497663975\n",
      "Iteration: 9678/10000, Loss: 0.011810862459242344\n",
      "Iteration: 9679/10000, Loss: 0.005928977392613888\n",
      "Iteration: 9680/10000, Loss: 0.012497033923864365\n",
      "Iteration: 9681/10000, Loss: 0.0087977210059762\n",
      "Iteration: 9682/10000, Loss: 0.0083101661875844\n",
      "Iteration: 9683/10000, Loss: 0.009556824341416359\n",
      "Iteration: 9684/10000, Loss: 0.005550631787627935\n",
      "Iteration: 9685/10000, Loss: 0.010267042554914951\n",
      "Iteration: 9686/10000, Loss: 0.010694918222725391\n",
      "Iteration: 9687/10000, Loss: 0.010907018557190895\n",
      "Iteration: 9688/10000, Loss: 0.007204482331871986\n",
      "Iteration: 9689/10000, Loss: 0.006294890306890011\n",
      "Iteration: 9690/10000, Loss: 0.006492602173238993\n",
      "Iteration: 9691/10000, Loss: 0.008076504804193974\n",
      "Iteration: 9692/10000, Loss: 0.008375928737223148\n",
      "Iteration: 9693/10000, Loss: 0.007149104028940201\n",
      "Iteration: 9694/10000, Loss: 0.00714314728975296\n",
      "Iteration: 9695/10000, Loss: 0.006784344092011452\n",
      "Iteration: 9696/10000, Loss: 0.006402030121535063\n",
      "Iteration: 9697/10000, Loss: 0.009381726384162903\n",
      "Iteration: 9698/10000, Loss: 0.008320617489516735\n",
      "Iteration: 9699/10000, Loss: 0.00947515293955803\n",
      "Iteration: 9700/10000, Loss: 0.008935411460697651\n",
      "Average test loss:  0.0039\n",
      "Iteration: 9701/10000, Loss: 0.006183109246194363\n",
      "Iteration: 9702/10000, Loss: 0.007533630356192589\n",
      "Iteration: 9703/10000, Loss: 0.007179543375968933\n",
      "Iteration: 9704/10000, Loss: 0.010784261859953403\n",
      "Iteration: 9705/10000, Loss: 0.009263958781957626\n",
      "Iteration: 9706/10000, Loss: 0.0070559000596404076\n",
      "Iteration: 9707/10000, Loss: 0.011446742340922356\n",
      "Iteration: 9708/10000, Loss: 0.01061952579766512\n",
      "Iteration: 9709/10000, Loss: 0.007091959472745657\n",
      "Iteration: 9710/10000, Loss: 0.012552712112665176\n",
      "Iteration: 9711/10000, Loss: 0.008579487912356853\n",
      "Iteration: 9712/10000, Loss: 0.009274723008275032\n",
      "Iteration: 9713/10000, Loss: 0.00601568166166544\n",
      "Iteration: 9714/10000, Loss: 0.00865399744361639\n",
      "Iteration: 9715/10000, Loss: 0.009829778224229813\n",
      "Iteration: 9716/10000, Loss: 0.005140980705618858\n",
      "Iteration: 9717/10000, Loss: 0.012559403665363789\n",
      "Iteration: 9718/10000, Loss: 0.0075212460942566395\n",
      "Iteration: 9719/10000, Loss: 0.007134571205824614\n",
      "Iteration: 9720/10000, Loss: 0.006324382498860359\n",
      "Iteration: 9721/10000, Loss: 0.007666658144444227\n",
      "Iteration: 9722/10000, Loss: 0.011076940223574638\n",
      "Iteration: 9723/10000, Loss: 0.007368868216872215\n",
      "Iteration: 9724/10000, Loss: 0.01006612554192543\n",
      "Iteration: 9725/10000, Loss: 0.0065872082486748695\n",
      "Iteration: 9726/10000, Loss: 0.008616955019533634\n",
      "Iteration: 9727/10000, Loss: 0.008350363001227379\n",
      "Iteration: 9728/10000, Loss: 0.007098286412656307\n",
      "Iteration: 9729/10000, Loss: 0.011770186014473438\n",
      "Iteration: 9730/10000, Loss: 0.007840155623853207\n",
      "Iteration: 9731/10000, Loss: 0.010832495987415314\n",
      "Iteration: 9732/10000, Loss: 0.00878001656383276\n",
      "Iteration: 9733/10000, Loss: 0.009874637238681316\n",
      "Iteration: 9734/10000, Loss: 0.007821176201105118\n",
      "Iteration: 9735/10000, Loss: 0.010748221538960934\n",
      "Iteration: 9736/10000, Loss: 0.009297921322286129\n",
      "Iteration: 9737/10000, Loss: 0.012869729660451412\n",
      "Iteration: 9738/10000, Loss: 0.0066496841609478\n",
      "Iteration: 9739/10000, Loss: 0.009893708862364292\n",
      "Iteration: 9740/10000, Loss: 0.009595261886715889\n",
      "Iteration: 9741/10000, Loss: 0.01049837563186884\n",
      "Iteration: 9742/10000, Loss: 0.0061373938806355\n",
      "Iteration: 9743/10000, Loss: 0.011985734105110168\n",
      "Iteration: 9744/10000, Loss: 0.005769217852503061\n",
      "Iteration: 9745/10000, Loss: 0.011769323609769344\n",
      "Iteration: 9746/10000, Loss: 0.008986072614789009\n",
      "Iteration: 9747/10000, Loss: 0.012017977423965931\n",
      "Iteration: 9748/10000, Loss: 0.009130571037530899\n",
      "Iteration: 9749/10000, Loss: 0.008570433594286442\n",
      "Iteration: 9750/10000, Loss: 0.006706397980451584\n",
      "Iteration: 9751/10000, Loss: 0.007909726351499557\n",
      "Iteration: 9752/10000, Loss: 0.01293458603322506\n",
      "Iteration: 9753/10000, Loss: 0.007061408367007971\n",
      "Iteration: 9754/10000, Loss: 0.013162451796233654\n",
      "Iteration: 9755/10000, Loss: 0.01025816798210144\n",
      "Iteration: 9756/10000, Loss: 0.006783626973628998\n",
      "Iteration: 9757/10000, Loss: 0.005813009105622768\n",
      "Iteration: 9758/10000, Loss: 0.011175155639648438\n",
      "Iteration: 9759/10000, Loss: 0.010859409347176552\n",
      "Iteration: 9760/10000, Loss: 0.005924091208726168\n",
      "Iteration: 9761/10000, Loss: 0.010340927168726921\n",
      "Iteration: 9762/10000, Loss: 0.005816471762955189\n",
      "Iteration: 9763/10000, Loss: 0.010113130323588848\n",
      "Iteration: 9764/10000, Loss: 0.00467957928776741\n",
      "Iteration: 9765/10000, Loss: 0.007204153575003147\n",
      "Iteration: 9766/10000, Loss: 0.01468843873590231\n",
      "Iteration: 9767/10000, Loss: 0.01101683173328638\n",
      "Iteration: 9768/10000, Loss: 0.010561165399849415\n",
      "Iteration: 9769/10000, Loss: 0.00850547756999731\n",
      "Iteration: 9770/10000, Loss: 0.008992898277938366\n",
      "Iteration: 9771/10000, Loss: 0.01296489592641592\n",
      "Iteration: 9772/10000, Loss: 0.0075021833181381226\n",
      "Iteration: 9773/10000, Loss: 0.00869052391499281\n",
      "Iteration: 9774/10000, Loss: 0.006678928155452013\n",
      "Iteration: 9775/10000, Loss: 0.010755909606814384\n",
      "Iteration: 9776/10000, Loss: 0.006137351971119642\n",
      "Iteration: 9777/10000, Loss: 0.014016851782798767\n",
      "Iteration: 9778/10000, Loss: 0.010587493889033794\n",
      "Iteration: 9779/10000, Loss: 0.00767818558961153\n",
      "Iteration: 9780/10000, Loss: 0.006078965496271849\n",
      "Iteration: 9781/10000, Loss: 0.008919906802475452\n",
      "Iteration: 9782/10000, Loss: 0.011115956120193005\n",
      "Iteration: 9783/10000, Loss: 0.007044519763439894\n",
      "Iteration: 9784/10000, Loss: 0.00833834521472454\n",
      "Iteration: 9785/10000, Loss: 0.010403523221611977\n",
      "Iteration: 9786/10000, Loss: 0.007488558534532785\n",
      "Iteration: 9787/10000, Loss: 0.008196237497031689\n",
      "Iteration: 9788/10000, Loss: 0.008211858570575714\n",
      "Iteration: 9789/10000, Loss: 0.012233708053827286\n",
      "Iteration: 9790/10000, Loss: 0.006830973085016012\n",
      "Iteration: 9791/10000, Loss: 0.003844098187983036\n",
      "Iteration: 9792/10000, Loss: 0.011993253603577614\n",
      "Iteration: 9793/10000, Loss: 0.006384216248989105\n",
      "Iteration: 9794/10000, Loss: 0.010476071387529373\n",
      "Iteration: 9795/10000, Loss: 0.006273314356803894\n",
      "Iteration: 9796/10000, Loss: 0.008179457858204842\n",
      "Iteration: 9797/10000, Loss: 0.009339642710983753\n",
      "Iteration: 9798/10000, Loss: 0.009056405164301395\n",
      "Iteration: 9799/10000, Loss: 0.008792567998170853\n",
      "Iteration: 9800/10000, Loss: 0.006095268297940493\n",
      "Average test loss:  0.0021\n",
      "Iteration: 9801/10000, Loss: 0.004557779524475336\n",
      "Iteration: 9802/10000, Loss: 0.00700337952002883\n",
      "Iteration: 9803/10000, Loss: 0.006465411279350519\n",
      "Iteration: 9804/10000, Loss: 0.00681384839117527\n",
      "Iteration: 9805/10000, Loss: 0.008290965110063553\n",
      "Iteration: 9806/10000, Loss: 0.008716144599020481\n",
      "Iteration: 9807/10000, Loss: 0.01160412933677435\n",
      "Iteration: 9808/10000, Loss: 0.007841398008167744\n",
      "Iteration: 9809/10000, Loss: 0.009875268675386906\n",
      "Iteration: 9810/10000, Loss: 0.006540483329445124\n",
      "Iteration: 9811/10000, Loss: 0.006766033358871937\n",
      "Iteration: 9812/10000, Loss: 0.009147673845291138\n",
      "Iteration: 9813/10000, Loss: 0.00966352317482233\n",
      "Iteration: 9814/10000, Loss: 0.010398244485259056\n",
      "Iteration: 9815/10000, Loss: 0.011705256998538971\n",
      "Iteration: 9816/10000, Loss: 0.006309976801276207\n",
      "Iteration: 9817/10000, Loss: 0.006609401199966669\n",
      "Iteration: 9818/10000, Loss: 0.0102997412905097\n",
      "Iteration: 9819/10000, Loss: 0.009219735860824585\n",
      "Iteration: 9820/10000, Loss: 0.010311872698366642\n",
      "Iteration: 9821/10000, Loss: 0.010123729705810547\n",
      "Iteration: 9822/10000, Loss: 0.010088199749588966\n",
      "Iteration: 9823/10000, Loss: 0.01412825658917427\n",
      "Iteration: 9824/10000, Loss: 0.015011264011263847\n",
      "Iteration: 9825/10000, Loss: 0.013182627968490124\n",
      "Iteration: 9826/10000, Loss: 0.010570943355560303\n",
      "Iteration: 9827/10000, Loss: 0.013119129464030266\n",
      "Iteration: 9828/10000, Loss: 0.007764441892504692\n",
      "Iteration: 9829/10000, Loss: 0.012038123793900013\n",
      "Iteration: 9830/10000, Loss: 0.007341316435486078\n",
      "Iteration: 9831/10000, Loss: 0.008239585906267166\n",
      "Iteration: 9832/10000, Loss: 0.012177176773548126\n",
      "Iteration: 9833/10000, Loss: 0.015116584487259388\n",
      "Iteration: 9834/10000, Loss: 0.008264683187007904\n",
      "Iteration: 9835/10000, Loss: 0.007083833683282137\n",
      "Iteration: 9836/10000, Loss: 0.009611185640096664\n",
      "Iteration: 9837/10000, Loss: 0.011322841979563236\n",
      "Iteration: 9838/10000, Loss: 0.01104818843305111\n",
      "Iteration: 9839/10000, Loss: 0.009272683411836624\n",
      "Iteration: 9840/10000, Loss: 0.011394920758903027\n",
      "Iteration: 9841/10000, Loss: 0.010243942029774189\n",
      "Iteration: 9842/10000, Loss: 0.00838382076472044\n",
      "Iteration: 9843/10000, Loss: 0.015021284110844135\n",
      "Iteration: 9844/10000, Loss: 0.00846171099692583\n",
      "Iteration: 9845/10000, Loss: 0.012006056495010853\n",
      "Iteration: 9846/10000, Loss: 0.009982113726437092\n",
      "Iteration: 9847/10000, Loss: 0.007315543480217457\n",
      "Iteration: 9848/10000, Loss: 0.015010819770395756\n",
      "Iteration: 9849/10000, Loss: 0.011812634766101837\n",
      "Iteration: 9850/10000, Loss: 0.008452813141047955\n",
      "Iteration: 9851/10000, Loss: 0.0070472885854542255\n",
      "Iteration: 9852/10000, Loss: 0.009343431331217289\n",
      "Iteration: 9853/10000, Loss: 0.010104536078870296\n",
      "Iteration: 9854/10000, Loss: 0.014460255391895771\n",
      "Iteration: 9855/10000, Loss: 0.01012876071035862\n",
      "Iteration: 9856/10000, Loss: 0.009725837968289852\n",
      "Iteration: 9857/10000, Loss: 0.007474314421415329\n",
      "Iteration: 9858/10000, Loss: 0.008412377908825874\n",
      "Iteration: 9859/10000, Loss: 0.011280912905931473\n",
      "Iteration: 9860/10000, Loss: 0.004235333763062954\n",
      "Iteration: 9861/10000, Loss: 0.004664806183427572\n",
      "Iteration: 9862/10000, Loss: 0.008598314598202705\n",
      "Iteration: 9863/10000, Loss: 0.011078436858952045\n",
      "Iteration: 9864/10000, Loss: 0.009015836752951145\n",
      "Iteration: 9865/10000, Loss: 0.0061280569061636925\n",
      "Iteration: 9866/10000, Loss: 0.009517832659184933\n",
      "Iteration: 9867/10000, Loss: 0.007512500975281\n",
      "Iteration: 9868/10000, Loss: 0.00784335471689701\n",
      "Iteration: 9869/10000, Loss: 0.008283820003271103\n",
      "Iteration: 9870/10000, Loss: 0.010089772753417492\n",
      "Iteration: 9871/10000, Loss: 0.006187782622873783\n",
      "Iteration: 9872/10000, Loss: 0.00906772818416357\n",
      "Iteration: 9873/10000, Loss: 0.0077223279513418674\n",
      "Iteration: 9874/10000, Loss: 0.011014863848686218\n",
      "Iteration: 9875/10000, Loss: 0.005917205475270748\n",
      "Iteration: 9876/10000, Loss: 0.008571876212954521\n",
      "Iteration: 9877/10000, Loss: 0.011119742877781391\n",
      "Iteration: 9878/10000, Loss: 0.00758447265252471\n",
      "Iteration: 9879/10000, Loss: 0.011486769653856754\n",
      "Iteration: 9880/10000, Loss: 0.010990935377776623\n",
      "Iteration: 9881/10000, Loss: 0.008759749121963978\n",
      "Iteration: 9882/10000, Loss: 0.01069239154458046\n",
      "Iteration: 9883/10000, Loss: 0.005320160649716854\n",
      "Iteration: 9884/10000, Loss: 0.008028842508792877\n",
      "Iteration: 9885/10000, Loss: 0.00974804162979126\n",
      "Iteration: 9886/10000, Loss: 0.014370026998221874\n",
      "Iteration: 9887/10000, Loss: 0.012126955203711987\n",
      "Iteration: 9888/10000, Loss: 0.004310294054448605\n",
      "Iteration: 9889/10000, Loss: 0.011571619659662247\n",
      "Iteration: 9890/10000, Loss: 0.004547653719782829\n",
      "Iteration: 9891/10000, Loss: 0.013218880631029606\n",
      "Iteration: 9892/10000, Loss: 0.010870764963328838\n",
      "Iteration: 9893/10000, Loss: 0.007635380607098341\n",
      "Iteration: 9894/10000, Loss: 0.008567255921661854\n",
      "Iteration: 9895/10000, Loss: 0.011406690813601017\n",
      "Iteration: 9896/10000, Loss: 0.011388960294425488\n",
      "Iteration: 9897/10000, Loss: 0.0091591477394104\n",
      "Iteration: 9898/10000, Loss: 0.009264898486435413\n",
      "Iteration: 9899/10000, Loss: 0.006637764163315296\n",
      "Iteration: 9900/10000, Loss: 0.009024371393024921\n",
      "Average test loss:  0.0042\n",
      "Iteration: 9901/10000, Loss: 0.0073470622301101685\n",
      "Iteration: 9902/10000, Loss: 0.009680277667939663\n",
      "Iteration: 9903/10000, Loss: 0.007326103281229734\n",
      "Iteration: 9904/10000, Loss: 0.014516712166368961\n",
      "Iteration: 9905/10000, Loss: 0.01002707052975893\n",
      "Iteration: 9906/10000, Loss: 0.008472098968923092\n",
      "Iteration: 9907/10000, Loss: 0.00991752091795206\n",
      "Iteration: 9908/10000, Loss: 0.011543210595846176\n",
      "Iteration: 9909/10000, Loss: 0.010636411607265472\n",
      "Iteration: 9910/10000, Loss: 0.01287882775068283\n",
      "Iteration: 9911/10000, Loss: 0.010841069743037224\n",
      "Iteration: 9912/10000, Loss: 0.00797141995280981\n",
      "Iteration: 9913/10000, Loss: 0.007572143338620663\n",
      "Iteration: 9914/10000, Loss: 0.01038800273090601\n",
      "Iteration: 9915/10000, Loss: 0.009346352890133858\n",
      "Iteration: 9916/10000, Loss: 0.010382427833974361\n",
      "Iteration: 9917/10000, Loss: 0.009383101016283035\n",
      "Iteration: 9918/10000, Loss: 0.010770074091851711\n",
      "Iteration: 9919/10000, Loss: 0.008089154027402401\n",
      "Iteration: 9920/10000, Loss: 0.010322104208171368\n",
      "Iteration: 9921/10000, Loss: 0.008638596162199974\n",
      "Iteration: 9922/10000, Loss: 0.014583554118871689\n",
      "Iteration: 9923/10000, Loss: 0.011012570932507515\n",
      "Iteration: 9924/10000, Loss: 0.008029535412788391\n",
      "Iteration: 9925/10000, Loss: 0.009573083370923996\n",
      "Iteration: 9926/10000, Loss: 0.008756331168115139\n",
      "Iteration: 9927/10000, Loss: 0.0075869327411055565\n",
      "Iteration: 9928/10000, Loss: 0.0093659907579422\n",
      "Iteration: 9929/10000, Loss: 0.009817303158342838\n",
      "Iteration: 9930/10000, Loss: 0.008628612384200096\n",
      "Iteration: 9931/10000, Loss: 0.0034712336491793394\n",
      "Iteration: 9932/10000, Loss: 0.01348971389234066\n",
      "Iteration: 9933/10000, Loss: 0.010929133743047714\n",
      "Iteration: 9934/10000, Loss: 0.01023074146360159\n",
      "Iteration: 9935/10000, Loss: 0.0059126028791069984\n",
      "Iteration: 9936/10000, Loss: 0.014755062758922577\n",
      "Iteration: 9937/10000, Loss: 0.01156677957624197\n",
      "Iteration: 9938/10000, Loss: 0.007996971718966961\n",
      "Iteration: 9939/10000, Loss: 0.009323110803961754\n",
      "Iteration: 9940/10000, Loss: 0.011862870305776596\n",
      "Iteration: 9941/10000, Loss: 0.0072822365909814835\n",
      "Iteration: 9942/10000, Loss: 0.010076881386339664\n",
      "Iteration: 9943/10000, Loss: 0.008009727112948895\n",
      "Iteration: 9944/10000, Loss: 0.006198840215802193\n",
      "Iteration: 9945/10000, Loss: 0.009144559502601624\n",
      "Iteration: 9946/10000, Loss: 0.009977510198950768\n",
      "Iteration: 9947/10000, Loss: 0.010173937305808067\n",
      "Iteration: 9948/10000, Loss: 0.013144322670996189\n",
      "Iteration: 9949/10000, Loss: 0.01000966690480709\n",
      "Iteration: 9950/10000, Loss: 0.006926597561687231\n",
      "Iteration: 9951/10000, Loss: 0.007801374886184931\n",
      "Iteration: 9952/10000, Loss: 0.008416512981057167\n",
      "Iteration: 9953/10000, Loss: 0.008475158363580704\n",
      "Iteration: 9954/10000, Loss: 0.007009553723037243\n",
      "Iteration: 9955/10000, Loss: 0.006359855178743601\n",
      "Iteration: 9956/10000, Loss: 0.01030896045267582\n",
      "Iteration: 9957/10000, Loss: 0.009636301547288895\n",
      "Iteration: 9958/10000, Loss: 0.005944433622062206\n",
      "Iteration: 9959/10000, Loss: 0.007633615750819445\n",
      "Iteration: 9960/10000, Loss: 0.0086996303871274\n",
      "Iteration: 9961/10000, Loss: 0.008067358285188675\n",
      "Iteration: 9962/10000, Loss: 0.004906876012682915\n",
      "Iteration: 9963/10000, Loss: 0.012159234844148159\n",
      "Iteration: 9964/10000, Loss: 0.008780053816735744\n",
      "Iteration: 9965/10000, Loss: 0.011173333041369915\n",
      "Iteration: 9966/10000, Loss: 0.006929352413862944\n",
      "Iteration: 9967/10000, Loss: 0.008842294104397297\n",
      "Iteration: 9968/10000, Loss: 0.009363926947116852\n",
      "Iteration: 9969/10000, Loss: 0.011654323898255825\n",
      "Iteration: 9970/10000, Loss: 0.008420615456998348\n",
      "Iteration: 9971/10000, Loss: 0.008773651905357838\n",
      "Iteration: 9972/10000, Loss: 0.00578274205327034\n",
      "Iteration: 9973/10000, Loss: 0.00883745588362217\n",
      "Iteration: 9974/10000, Loss: 0.009246575646102428\n",
      "Iteration: 9975/10000, Loss: 0.011146209202706814\n",
      "Iteration: 9976/10000, Loss: 0.009649859741330147\n",
      "Iteration: 9977/10000, Loss: 0.009504969231784344\n",
      "Iteration: 9978/10000, Loss: 0.004099217709153891\n",
      "Iteration: 9979/10000, Loss: 0.010177996009588242\n",
      "Iteration: 9980/10000, Loss: 0.011589914560317993\n",
      "Iteration: 9981/10000, Loss: 0.008783985860645771\n",
      "Iteration: 9982/10000, Loss: 0.012953827157616615\n",
      "Iteration: 9983/10000, Loss: 0.006745681166648865\n",
      "Iteration: 9984/10000, Loss: 0.007135516498237848\n",
      "Iteration: 9985/10000, Loss: 0.006689090747386217\n",
      "Iteration: 9986/10000, Loss: 0.00992115680128336\n",
      "Iteration: 9987/10000, Loss: 0.010912907309830189\n",
      "Iteration: 9988/10000, Loss: 0.010463500395417213\n",
      "Iteration: 9989/10000, Loss: 0.010038008913397789\n",
      "Iteration: 9990/10000, Loss: 0.011759635992348194\n",
      "Iteration: 9991/10000, Loss: 0.009643163532018661\n",
      "Iteration: 9992/10000, Loss: 0.007796413265168667\n",
      "Iteration: 9993/10000, Loss: 0.00669685797765851\n",
      "Iteration: 9994/10000, Loss: 0.013811531476676464\n",
      "Iteration: 9995/10000, Loss: 0.007378268055617809\n",
      "Iteration: 9996/10000, Loss: 0.012775599025189877\n",
      "Iteration: 9997/10000, Loss: 0.013571619056165218\n",
      "Iteration: 9998/10000, Loss: 0.007677116431295872\n",
      "Iteration: 9999/10000, Loss: 0.005389975383877754\n",
      "Iteration: 10000/10000, Loss: 0.007723595947027206\n",
      "Average test loss:  0.0014\n",
      "Training took 126.653s in total.\n"
     ]
    }
   ],
   "source": [
    "# CUDA device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {0}'.format(device))\n",
    "\n",
    "# Build the model\n",
    "num_class = 4\n",
    "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
    "model = model.to(device)\n",
    "params = list(model.parameters())\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "# Segmentation loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Datasets\n",
    "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
    "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
    "\n",
    "# Train the model\n",
    "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
    "num_iter = 10000\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "start = time.time()\n",
    "for it in range(1, 1 + num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = train_set.get_random_batch(train_batch_size)\n",
    "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    logits = model(images)\n",
    "\n",
    "\n",
    "    # Perform optimisation and print out the training loss\n",
    "    ### Insert your code ###\n",
    "    optimizer.zero_grad()  # Clear the gradients\n",
    "    loss = criterion(logits, labels)  # Calculate the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update the model parameters\n",
    "\n",
    "    print(f'Iteration: {it}/{num_iter}, Loss: {loss.item()}')\n",
    "    ### End of your code ###\n",
    "\n",
    "    # Evaluate\n",
    "    if it % 100 == 0:\n",
    "        model.eval()\n",
    "        # Disabling gradient calculation during reference to reduce memory consumption\n",
    "        with torch.no_grad():\n",
    "            # Evaluate on a batch of test images and print out the test loss\n",
    "            ### Insert your code ###\n",
    "            total_loss = 0\n",
    "            input_images, real_labels = test_set.get_random_batch(eval_batch_size)\n",
    "            input_images, real_labels = torch.from_numpy(input_images), torch.from_numpy(real_labels)\n",
    "            input_images, real_labels = input_images.to(device, dtype=torch.float32), real_labels.to(device, dtype=torch.long)\n",
    "            outputs = model(input_images)\n",
    "            \n",
    "            loss = criterion(outputs, real_labels)\n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / eval_batch_size\n",
    "            \n",
    "            print(f\"Average test loss: {avg_loss: .4f}\")\n",
    "            \n",
    "            \n",
    "            ### End of your code ###\n",
    "\n",
    "    # Save the model\n",
    "    if it % 5000 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yjxjGyb6yT"
   },
   "source": [
    "## 5. Deploy the trained model to a random set of 4 test images and visualise the automated segmentation.\n",
    "\n",
    "You can show the images as a 4 x 3 panel. Each row shows one example, with the 3 columns being the test image, automated segmentation and ground truth segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wZeLE0qZjd2j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(images) = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Insert your code ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "deploy_size = 4\n",
    "img_dim = (120, 120)\n",
    "\n",
    "model.eval()\n",
    "## Get a random set of 4 test images\n",
    "test_images, test_labels = test_set.get_random_batch(deploy_size)\n",
    "d_test_images = torch.from_numpy(test_images).to(device, dtype=torch.float32)\n",
    "\n",
    "## Perform inference on the test images\n",
    "outputs = model(d_test_images)\n",
    "predicted_labels = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "## Visualize the test images, automated segmentation, and ground truth segmentation\n",
    "fig, grid = plt.subplots(deploy_size, 3, figsize=(10, 10))\n",
    "\n",
    "## Add titles\n",
    "titles = [\"Test Image\", \"Auto Segmentation\", \"Ground Truth Segmentation\"]\n",
    "[ax.set_title(col_title) for ax, col_title in zip(grid[0], titles)]\n",
    "\n",
    "for i in range(deploy_size):\n",
    "    grid[i, 0].imshow(test_images[i, 0], cmap=cmap_image)\n",
    "    grid[i, 0].axis('off')\n",
    "\n",
    "    grid[i, 1].imshow(predicted_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 1].axis('off')\n",
    "\n",
    "    grid[i, 2].imshow(test_labels[i], cmap = cmap_segmentation)\n",
    "    grid[i, 2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "\n",
    "### End of your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj3Qusin_s_r"
   },
   "source": [
    "## 6. Discussion. Does your trained model work well? How would you improve this model so it can be deployed to the real clinic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Does your trained model work well?**\n",
    "To be able to comment on these there are few factors we need to consider. Big part that plays into this is the models performance, in terms of the average loss the model performs pretty well (0.0031) However, to comment on the full performance we should also bring in other metrics such as precision, recall and even evaluate the F1 score to get a better idea of the model.\n",
    "\n",
    "#### **How would you improve this model...**\n",
    "In terms of improvements, we can use a more complex or deeper convolutional neural network that can extract and 'learn' more information about the training data set and leverage that to be a better image segmentator. On top of this we can tune other hyperparameeters such as batch sizes or the number of convolutional steps (increase n to be more than 128 ...) .\n",
    "\n",
    "There can also be some data set improvements such as balancing our data set (not sure if this one is or not) but addressing a possible inbalanace will result in a more performant model. We should also  augment the data inputting into the modelby transforming the input data by: rotating, resizing, mirroring ... so the overall robustness of the model can be increased and it will perform better with real life data.\n",
    "\n",
    "Finally we can regularly test and evaluate the model so that we can make small adjustments or improvements to keep the model performant and robust.\n",
    "\n",
    "\n",
    "#### **...so it can deployed to a real clinic?**\n",
    "\n",
    "I think the most obvious first step would be to give some sort of meaning to this segmentation. Right now some colours are shown \n",
    "and whoever is interacting with this needs to be able to quickly understand what they are looking at. \n",
    "\n",
    "A really important second point is to have some sort of expert validation of these results beyond the testing of the model, so that we can be sure the model is aligning with what the medical professionals are expecting.\n",
    "\n",
    "Then, continuing on from the final point above, we need to be able to keep the model current. It cannot be trained then left alone as more data will become available over its lifespan and can be used to train and make the mdoel more robust.\n",
    "\n",
    "And finally, as any real system getting deployed it needs to have security measures and backups. Security is extra important as personal medical information is quite a sensitive piece of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
